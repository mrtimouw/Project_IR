Euler–Maclaurin formula

In mathematics, the Euler–Maclaurin formula is a formula for the difference between an integral and a closely related sum. It can be used to approximate integrals by finite sums, or conversely to evaluate finite sums and infinite series using integrals and the machinery of calculus. For example, many asymptotic expansions are derived from the formula, and Faulhaber's formula for the sum of powers is an immediate consequence.

The formula was discovered independently by Leonhard Euler and Colin Maclaurin around 1735. Euler needed it to compute slowly converging infinite series while Maclaurin used it to calculate integrals. It was later generalized to Darboux's formula.

If and are natural numbers and is a real or complex valued continuous function for real numbers in the interval , then the integral
formula_1
can be approximated by the sum (or vice versa)
formula_2
(see rectangle method). The Euler–Maclaurin formula provides expressions for the difference between the sum and the integral in terms of the higher derivatives evaluated at the endpoints of the interval, that is to say and .

Explicitly, for a positive integer and a function that is times continuously differentiable on the interval , we have
formula_3
where is the th Bernoulli number (with ) and is an error term which depends on , , , and and is usually small for suitable values of .

The formula is often written with the subscript taking only even values, since the odd Bernoulli numbers are zero except for . In this case we have
formula_4
or alternatively
formula_5

The remainder term arises because the integral is usually not exactly equal to the sum. The formula may be derived by applying repeated integration by parts to successive intervals for . The boundary terms in these integrations lead to the main terms of the formula, and the leftover integrals form the remainder term.

The remainder term has an exact expression in terms of the periodized Bernoulli functions . The Bernoulli polynomials may be defined recursively by and, for ,
formula_6
The periodized Bernoulli functions are defined as
formula_7
where denotes the largest integer less than or equal to , so that always lies in the interval .

With this notation, the remainder term equals
formula_8

When , it can be shown that
formula_9
where denotes the Riemann zeta function; one approach to prove this inequality is to obtain the Fourier series for the polynomials . The bound is achieved for even when is zero. The term may be omitted for odd but the proof in this case is more complex (see Lehmer). Using this inequality, the size of the remainder term can be estimated as
formula_10

The Bernoulli numbers from to are . Therefore the low-order cases of the Euler–Maclaurin formula are:
formula_11

The Basel problem is to determine the sum
formula_12

Euler computed this sum to 20 decimal places with only a few terms of the Euler–Maclaurin formula in 1735. This probably convinced him that the sum equals , which he proved in the same year.

If is a polynomial and is big enough, then the remainder term vanishes. For instance, if , we can choose to obtain, after simplification,
formula_13

The formula provides a means of approximating a finite integral. Let be the endpoints of the interval of integration. Fix , the number of points to use in the approximation, and denote the corresponding step size by . Set , so that and . Then:
formula_14

This may be viewed as an extension of the trapezoid rule by the inclusion of correction terms. Note that this asymptotic expansion is usually not convergent; there is some , depending upon and , such that the terms past order increase rapidly. Thus, the remainder term generally demands close attention.

The Euler–Maclaurin formula is also used for detailed error analysis in numerical quadrature. It explains the superior performance of the trapezoidal rule on smooth periodic functions and is used in certain extrapolation methods. Clenshaw–Curtis quadrature is essentially a change of variables to cast an arbitrary integral in terms of integrals of periodic functions where the Euler–Maclaurin approach is very accurate (in that particular case the Euler–Maclaurin formula takes the form of a discrete cosine transform). This technique is known as a periodizing transformation.

In the context of computing asymptotic expansions of sums and series, usually the most useful form of the Euler–Maclaurin formula is
formula_15

where and are integers. Often the expansion remains valid even after taking the limits or or both. In many cases the integral on the right-hand side can be evaluated in closed form in terms of elementary functions even though the sum on the left-hand side cannot. Then all the terms in the asymptotic series can be expressed in terms of elementary functions. For example,
formula_16

Here the left-hand side is equal to , namely the first-order polygamma function defined by
the gamma function is equal to when is a positive integer. This results in an asymptotic expansion for . That expansion, in turn, serves as the starting point for one of the derivations of precise error estimates for Stirling's approximation of the factorial function.

If is an integer greater than 1 we have:
formula_18

Collecting the constants into a value of the Riemann zeta function, we can write an asymptotic expansion:
formula_19

For equal to 2 this simplifies to
formula_20
or
formula_21

When , the corresponding technique gives an asymptotic expansion for the harmonic numbers:
formula_22
where is the Euler–Mascheroni constant.

We outline the argument given in Apostol.

The Bernoulli polynomials and the periodic Bernoulli functions for were introduced above.

The first several Bernoulli polynomials are
formula_23

The values are the Bernoulli numbers . Notice that for we have
formula_24
and for ,
formula_25

The functions agree with the Bernoulli polynomials on the interval and are periodic with period 1. Furthermore, except when , they are also continuous. Thus,
formula_26

Let be an integer, and consider the integral
formula_27
where
formula_28

Integrating by parts, we get
formula_29

Using , , and summing the above from to , we get
formula_30

Adding to both sides and rearranging, we have
formula_31

This is the case of the summation formula. To continue the induction, we apply integration by parts to the error term:
formula_32
where
formula_33

The result of integrating by parts is
formula_34

Summing from to and substituting this for the lower order error term results in the case of the formula,
formula_35

This process can be iterated. In this way we get a proof of the Euler–Maclaurin summation formula which can be formalized by mathematical induction, in which the induction step relies on integration by parts and on identities for periodic Bernoulli functions.


Epimenides paradox

The Epimenides paradox reveals a problem with self-reference in logic. It is named after the Cretan philosopher Epimenides of Knossos (alive circa 600 BC) who is credited with the original statement. A typical description of the problem is given in the book "Gödel, Escher, Bach", by Douglas Hofstadter:

A paradox of self-reference arises when one considers whether it is possible for Epimenides to have spoken the truth.

According to Ptolemaeus Chennus, Thetis and Medea had once argued in Thessaly over which was the most beautiful; they appointed the Cretan Idomeneus as the judge, who gave the victory to Thetis. In her anger, Medea called all Cretans liars, and cursed them to never say the truth.

Thomas Fowler (1869) states the paradox as follows: "Epimenides the Cretan says, 'that all the Cretans are liars,' but Epimenides is himself a Cretan; therefore he is himself a liar. But if he is a liar, what he says is untrue, and consequently, the Cretans are veracious; but Epimenides is a Cretan, and therefore what he says is true; saying the Cretans are liars, Epimenides is himself a liar, and what he says is untrue. Thus we may go on alternately proving that Epimenides and the Cretans are truthful and untruthful."

If we assume the statement is false and that Epimenides is lying about all Cretans being liars, then there must exist at least one Cretan who is honest. This does not lead to a contradiction since it is not required that this Cretan be Epimenides. This means that Epimenides can say the false statement that all Cretans are liars while knowing at least one honest Cretan and lying about this particular Cretan. Hence, from the assumption that the statement is false, it does not follow that the statement is true. So we can avoid a paradox as seeing the statement "all Cretans are liars" as a false statement, which is made by a lying Cretan, Epimenides. The mistake made by Thomas Fowler (and many other people) above is to think that the negation of "all Cretans are liars" is "all Cretans are honest" (a paradox) when in fact the negation is "there exists a Cretan who is honest", or "not all Cretans are liars". The Epimenides paradox can be slightly modified as to not allow the kind of solution described above, as it was in the first paradox of Eubulides but instead leading to a non-avoidable self-contradiction. Paradoxical versions of the Epimenides problem are closely related to a class of more difficult logical problems, including the liar paradox, Socratic paradox and the Burali-Forti paradox, all of which have self-reference in common with Epimenides. The Epimenides paradox is usually classified as a variation on the liar paradox, and sometimes the two are not distinguished. The study of self-reference led to important developments in logic and mathematics in the twentieth century.

In other words, it is not a paradox once one realizes "All Cretans are liars" being untrue only means "Not all Cretans are liars" instead of the assumption that "All Cretans are honest".

Perhaps better put, for "All Cretans are liars" to be a true statement, it does not mean that all Cretans must lie all the time. In fact, Cretans could tell the truth quite often, but still all be liars in the sense that liars are people prone to deception for dishonest gain. Considering that "All Cretans are liars" has been seen as a paradox only since the 19th century, this seems to resolve the alleged paradox. If 'all Cretans are continuous liars' is actually true, then asking a Cretan if they are honest would always elicit the dishonest answer 'yes'. So arguably the original proposition is not so much paradoxical as invalid.

A contextual reading of the contradiction may also provide an answer to the paradox. The original phrase, "The Cretans, always liars, evil beasts, idle bellies!" asserts not an intrinsic paradox, but rather an opinion of the Cretans from Epimenides. A stereotyping of his people not intended to be an absolute statement about the people as a whole. Rather it is a claim made about their position regarding their religious beliefs and socio-cultural attitudes. Within the context of his poem the phrase is specific to a certain belief, a context that Callimachus repeats in his poem regarding Zeus. Further, a more poignant answer to the paradox is simply that to be a "liar" is to state falsehoods, nothing in the statement asserts everything said is false, but rather they're "always" lying. This is not an absolute statement of fact and thus we cannot conclude there's a true contradiction made by Epimenides with this statement.

Epimenides was a 6th-century BC philosopher and religious prophet who, against the general sentiment of Crete, proposed that Zeus was immortal, as in the following poem:
Denying the immortality of Zeus, then, was the lie of the Cretans.

The phrase "Cretans, always liars" was quoted by the poet Callimachus in his "Hymn to Zeus", with the same theological intent as Epimenides:

The logical inconsistency of a Cretan asserting all Cretans are always liars may not have occurred to Epimenides, nor to Callimachus, who both used the phrase to emphasize their point, without irony, perhaps meaning that all Cretans lie routinely, but not exclusively.

In the 1st century AD, the quote is mentioned by the author of the Epistle to Titus as having been spoken truly by "one of their own prophets."

Clement of Alexandria, in the late 2nd century AD, fails to indicate that the concept of logical paradox is an issue:

During the early 4th century, Saint Augustine restates the closely related liar paradox in "Against the Academicians" (III.13.29), but without mentioning Epimenides.

In the Middle Ages, many forms of the liar paradox were studied under the heading of insolubilia, but these were not explicitly associated with Epimenides.

Finally, in 1740, the second volume of Pierre Bayle's "Dictionnaire Historique et Critique" explicitly connects Epimenides with the paradox, though Bayle labels the paradox a "sophisme".

All of the works of Epimenides are now lost, and known only through quotations by other authors. The quotation from the "Cretica" of Epimenides is given by R.N. Longenecker, "Acts of the Apostles", in volume 9 of "The Expositor's Bible Commentary", Frank E. Gaebelein, editor (Grand Rapids, Michigan: Zondervan Corporation, 1976–1984), page 476. Longenecker in turn cites M.D. Gibson, "Horae Semiticae X" (Cambridge: Cambridge University Press, 1913), page 40, "in Syriac". Longenecker states the following in a footnote:

An oblique reference to Epimenides in the context of logic appears in "The Logical Calculus" by W. E. Johnson, "Mind" (New Series), volume 1, number 2 (April, 1892), pages 235–250. Johnson writes in a footnote,

The Epimenides paradox appears explicitly in "Mathematical Logic as Based on the Theory of Types", by Bertrand Russell, in the "American Journal of Mathematics", volume 30, number 3 (July, 1908), pages 222–262, which opens with the following:

In that article, Russell uses the Epimenides paradox as the point of departure for discussions of other problems, including the Burali-Forti paradox and the paradox now called Russell's paradox. Since Russell, the Epimenides paradox has been referenced repeatedly in logic. Typical of these references is "Gödel, Escher, Bach" by Douglas Hofstadter, which accords the paradox a prominent place in a discussion of self-reference.

It is also believed that the "Cretan tales" told by Odysseus in "The Odyssey" by Homer are a reference to this paradox.

In "The Second Sex" (1949) Simone de Beauvoir writes "I think certain women are still best suited to elucidate the situation of women. It is a sophism to claim that Epimenides should be enclosed within the concept of Cretan and all Cretans within the concept of liar: it is not a mysterious essence that dictates good or bad faith to men and women".

Engine

An engine or motor is a machine designed to convert one or more forms of energy into mechanical energy. 

Available energy sources include potential energy (e.g. energy of the Earth's gravitational field as exploited in hydroelectric power generation), heat energy (e.g. geothermal), chemical energy, electric potential and nuclear energy (from nuclear fission or nuclear fusion). Many of these processes generate heat as an intermediate energy form, so heat engines have special importance. Some natural processes, such as atmospheric convection cells convert environmental heat into motion (e.g. in the form of rising air currents). Mechanical energy is of particular importance in transportation, but also plays a role in many industrial processes such as cutting, grinding, crushing, and mixing.

Mechanical heat engines convert heat into work via various thermodynamic processes. The internal combustion engine is perhaps the most common example of a mechanical heat engine, in which heat from the combustion of a fuel causes rapid pressurisation of the gaseous combustion products in the combustion chamber, causing them to expand and drive a piston, which turns a crankshaft. Unlike internal combustion engines, a reaction engine (such as a jet engine) produces thrust by expelling reaction mass, in accordance with Newton's third law of motion.

Apart from heat engines, electric motors convert electrical energy into mechanical motion, pneumatic motors use compressed air, and clockwork motors in wind-up toys use elastic energy. In biological systems, molecular motors, like myosins in muscles, use chemical energy to create forces and ultimately motion (a chemical engine, but not a heat engine).

Chemical heat engines which employ air (ambient atmospheric gas) as a part of the fuel reaction are regarded as airbreathing engines. Chemical heat engines designed to operate outside of Earth's atmosphere (e.g. rockets, deeply submerged submarines) need to carry an additional fuel component called the oxidizer (although there exist super-oxidizers suitable for use in rockets, such as fluorine, a more powerful oxidant than oxygen itself); or the application needs to obtain heat by non-chemical means, such as by means of nuclear reactions.

All chemically fueled heat engines emit exhaust gases. The cleanest engines emit water only. Strict zero-emissions generally means zero emissions other than water and water vapour. Only heat engines which combust pure hydrogen (fuel) and pure oxygen (oxidizer) achieve zero-emission by a strict definition (in practice, one type of rocket engine). If hydrogen is burnt in combination with air (all airbreathing engines), a side reaction occurs between atmospheric oxygen and atmospheric nitrogen resulting in small emissions of , which is adverse even in small quantities. If a hydrocarbon (such as alcohol or gasoline) is burnt as fuel, large quantities of are emitted, a potent greenhouse gas. Hydrogen and oxygen from air can be reacted into water by a fuel cell without side production of , but this is an electrochemical engine not a heat engine.

The word "engine" derives from Old French , from the Latin –the root of the word . Pre-industrial weapons of war, such as catapults, trebuchets and battering rams, were called "siege engines", and knowledge of how to construct them was often treated as a military secret. The word "gin", as in "cotton gin", is short for "engine". Most mechanical devices invented during the industrial revolution were described as engines—the steam engine being a notable example. However, the original steam engines, such as those by Thomas Savery, were not mechanical engines but pumps. In this manner, a fire engine in its original form was merely a water pump, with the engine being transported to the fire by horses.

In modern usage, the term "engine" typically describes devices, like steam engines and internal combustion engines, that burn or otherwise consume fuel to perform mechanical work by exerting a torque or linear force (usually in the form of thrust). Devices converting heat energy into motion are commonly referred to simply as "engines". Examples of engines which exert a torque include the familiar automobile gasoline and diesel engines, as well as turboshafts. Examples of engines which produce thrust include turbofans and rockets.

When the internal combustion engine was invented, the term "motor" was initially used to distinguish it from the steam engine—which was in wide use at the time, powering locomotives and other vehicles such as steam rollers. The term "motor" derives from the Latin verb which means 'to set in motion', or 'maintain motion'. Thus a motor is a device that imparts motion.

"Motor" and "engine" are interchangeable in standard English. In some engineering jargons, the two words have different meanings, in which "engine" is a device that burns or otherwise consumes fuel, changing its chemical composition, and a motor is a device driven by electricity, air, or hydraulic pressure, which does not change the chemical composition of its energy source. However, rocketry uses the term rocket motor, even though they consume fuel.

A heat engine may also serve as a "prime mover"—a component that transforms the flow or changes in pressure of a fluid into mechanical energy. An automobile powered by an internal combustion engine may make use of various motors and pumps, but ultimately all such devices derive their power from the engine. Another way of looking at it is that a motor receives power from an external source, and then converts it into mechanical energy, while an engine creates power from pressure (derived directly from the explosive force of combustion or other chemical reaction, or secondarily from the action of some such force on other substances such as air, water, or steam).

Simple machines, such as the club and oar (examples of the lever), are prehistoric. More complex engines using human power, animal power, water power, wind power and even steam power date back to antiquity. Human power was focused by the use of simple engines, such as the capstan, windlass or treadmill, and with ropes, pulleys, and block and tackle arrangements; this power was transmitted usually with the forces multiplied and the speed reduced. These were used in cranes and aboard ships in Ancient Greece, as well as in mines, water pumps and siege engines in Ancient Rome. The writers of those times, including Vitruvius, Frontinus and Pliny the Elder, treat these engines as commonplace, so their invention may be more ancient. By the 1st century AD, cattle and horses were used in mills, driving machines similar to those powered by humans in earlier times.

According to Strabo, a water-powered mill was built in Kaberia of the kingdom of Mithridates during the 1st century BC. Use of water wheels in mills spread throughout the Roman Empire over the next few centuries. Some were quite complex, with aqueducts, dams, and sluices to maintain and channel the water, along with systems of gears, or toothed-wheels made of wood and metal to regulate the speed of rotation. More sophisticated small devices, such as the Antikythera Mechanism used complex trains of gears and dials to act as calendars or predict astronomical events. In a poem by Ausonius in the 4th century AD, he mentions a stone-cutting saw powered by water. Hero of Alexandria is credited with many such wind and steam powered machines in the 1st century AD, including the Aeolipile and the vending machine, often these machines were associated with worship, such as animated altars and automated temple doors.

Medieval Muslim engineers employed gears in mills and water-raising machines, and used dams as a source of water power to provide additional power to watermills and water-raising machines. In the medieval Islamic world, such advances made it possible to mechanize many industrial tasks previously carried out by manual labour.

In 1206, al-Jazari employed a crank-conrod system for two of his water-raising machines. A rudimentary steam turbine device was described by Taqi al-Din in 1551 and by Giovanni Branca in 1629.

In the 13th century, the solid rocket motor was invented in China. Driven by gunpowder, this simplest form of internal combustion engine was unable to deliver sustained power, but was useful for propelling weaponry at high speeds towards enemies in battle and for fireworks. After invention, this innovation spread throughout Europe.

The Watt steam engine was the first type of steam engine to make use of steam at a pressure just above atmospheric to drive the piston helped by a partial vacuum. Improving on the design of the 1712 Newcomen steam engine, the Watt steam engine, developed sporadically from 1763 to 1775, was a great step in the development of the steam engine. Offering a dramatic increase in fuel efficiency, James Watt's design became synonymous with steam engines, due in no small part to his business partner, Matthew Boulton. It enabled rapid development of efficient semi-automated factories on a previously unimaginable scale in places where waterpower was not available. Later development led to steam locomotives and great expansion of railway transportation.

As for internal combustion piston engines, these were tested in France in 1807 by de Rivaz and independently, by the Niépce brothers. They were theoretically advanced by Carnot in 1824. In 1853–57 Eugenio Barsanti and Felice Matteucci invented and patented an engine using the free-piston principle that was possibly the first 4-cycle engine.

The invention of an internal combustion engine which was later commercially successful was made during 1860 by Etienne Lenoir.

In 1877, the Otto cycle was capable of giving a far higher power-to-weight ratio than steam engines and worked much better for many transportation applications such as cars and aircraft.

The first commercially successful automobile, created by Karl Benz, added to the interest in light and powerful engines. The lightweight gasoline internal combustion engine, operating on a four-stroke Otto cycle, has been the most successful for light automobiles, while the more efficient Diesel engine is used for trucks and buses. However, in recent years, turbo Diesel engines have become increasingly popular, especially outside of the United States, even for quite small cars.

In 1896, Karl Benz was granted a patent for his design of the first engine with horizontally opposed pistons. His design created an engine in which the corresponding pistons move in horizontal cylinders and reach top dead center simultaneously, thus automatically balancing each other with respect to their individual momentum. Engines of this design are often referred to as flat engines because of their shape and lower profile. They were used in the Volkswagen Beetle, the Citroën 2CV, some Porsche and Subaru cars, many BMW and Honda motorcycles, and propeller aircraft engines.

Continuance of the use of the internal combustion engine for automobiles is partly due to the improvement of engine control systems (onboard computers providing engine management processes, and electronically controlled fuel injection). Forced air induction by turbocharging and supercharging have increased power outputs and engine efficiencies. Similar changes have been applied to smaller diesel engines giving them almost the same power characteristics as gasoline engines. This is especially evident with the popularity of smaller diesel engine propelled cars in Europe. Larger diesel engines are still often used in trucks and heavy machinery, although they require special machining not available in most factories. Diesel engines produce lower hydrocarbon and emissions, but greater particulate and pollution, than gasoline engines. Diesel engines are also 40% more fuel efficient than comparable gasoline engines.

In the first half of the 20th century, a trend of increasing engine power occurred, particularly in the U.S models. Design changes incorporated all known methods of increasing engine capacity, including increasing the pressure in the cylinders to improve efficiency, increasing the size of the engine, and increasing the rate at which the engine produces work. The higher forces and pressures created by these changes created engine vibration and size problems that led to stiffer, more compact engines with V and opposed cylinder layouts replacing longer straight-line arrangements.

Optimal combustion efficiency in passenger vehicles is reached with a coolant temperature of around .

Earlier automobile engine development produced a much larger range of engines than is in common use today. Engines have ranged from 1- to 16-cylinder designs with corresponding differences in overall size, weight, engine displacement, and cylinder bores. Four cylinders and power ratings from 19 to 120 hp (14 to 90 kW) were followed in a majority of the models. Several three-cylinder, two-stroke-cycle models were built while most engines had straight or in-line cylinders. There were several V-type models and horizontally opposed two- and four-cylinder makes too. Overhead camshafts were frequently employed. The smaller engines were commonly air-cooled and located at the rear of the vehicle; compression ratios were relatively low. The 1970s and 1980s saw an increased interest in improved fuel economy, which caused a return to smaller V-6 and four-cylinder layouts, with as many as five valves per cylinder to improve efficiency. The Bugatti Veyron 16.4 operates with a W16 engine, meaning that two V8 cylinder layouts are positioned next to each other to create the W shape sharing the same crankshaft.

The largest internal combustion engine ever built is the Wärtsilä-Sulzer RTA96-C, a 14-cylinder, 2-stroke turbocharged diesel engine that was designed to power the "Emma Mærsk", the largest container ship in the world when launched in 2006. This engine has a mass of 2,300 tonnes, and when running at 102 rpm (1.7 Hz) produces over 80 MW, and can use up to 250 tonnes of fuel per day.

An engine can be put into a category according to two criteria: the form of energy it accepts in order to create motion, and the type of motion it outputs.

Combustion engines are heat engines driven by the heat of a combustion process.

The "internal combustion engine" is an engine in which the combustion of a fuel (generally, fossil fuel) occurs with an oxidizer (usually air) in a combustion chamber. In an internal combustion engine the expansion of the high temperature and high pressure gases, which are produced by the combustion, directly applies force to components of the engine, such as the pistons or turbine blades or a nozzle, and by moving it over a distance, generates mechanical work.

An "external combustion engine" (EC engine) is a heat engine where an internal working fluid is heated by combustion of an external source, through the engine wall or a heat exchanger. The fluid then, by expanding and acting on the mechanism of the engine produces motion and usable work. The fluid is then cooled, compressed and reused (closed cycle), or (less commonly) dumped, and cool fluid pulled in (open cycle air engine).

"Combustion" refers to burning fuel with an oxidizer, to supply the heat. Engines of similar (or even identical) configuration and operation may use a supply of heat from other sources such as nuclear, solar, geothermal or exothermic reactions not involving combustion; but are not then strictly classed as external combustion engines, but as external thermal engines.

The working fluid can be a gas as in a Stirling engine, or steam as in a steam engine or an organic liquid such as n-pentane in an Organic Rankine cycle. The fluid can be of any composition; gas is by far the most common, although even single-phase liquid is sometimes used. In the case of the steam engine, the fluid changes phases between liquid and gas.

"Air-breathing combustion engines" are combustion engines that use the oxygen in atmospheric air to oxidise ('burn') the fuel, rather than carrying an oxidiser, as in a rocket. Theoretically, this should result in a better specific impulse than for rocket engines.

A continuous stream of air flows through the air-breathing engine. This air is compressed, mixed with fuel, ignited and expelled as the exhaust gas. In reaction engines, the majority of the combustion energy (heat) exits the engine as exhaust gas, which provides thrust directly.

Typical air-breathing engines include:

The operation of engines typically has a negative impact upon air quality and ambient sound levels. There has been a growing emphasis on the pollution producing features of automotive power systems. This has created new interest in alternate power sources and internal-combustion engine refinements. Though a few limited-production battery-powered electric vehicles have appeared, they have not proved competitive owing to costs and operating characteristics. In the 21st century the diesel engine has been increasing in popularity with automobile owners. However, the gasoline engine and the Diesel engine, with their new emission-control devices to improve emission performance, have not yet been significantly challenged. A number of manufacturers have introduced hybrid engines, mainly involving a small gasoline engine coupled with an electric motor and with a large battery bank, these are starting to become a popular option because of their environment awareness.

Exhaust gas from a spark ignition engine consists of the following: nitrogen 70 to 75% (by volume), water vapor 10 to 12%, carbon dioxide 10 to 13.5%, hydrogen 0.5 to 2%, oxygen 0.2 to 2%, carbon monoxide: 0.1 to 6%, unburnt hydrocarbons and partial oxidation products (e.g. aldehydes) 0.5 to 1%, nitrogen monoxide 0.01 to 0.4%, nitrous oxide <100 ppm, sulfur dioxide 15 to 60 ppm, traces of other compounds such as fuel additives and lubricants, also halogen and metallic compounds, and other particles. Carbon monoxide is highly toxic, and can cause carbon monoxide poisoning, so it is important to avoid any build-up of the gas in a confined space. Catalytic converters can reduce toxic emissions, but not eliminate them. Also, resulting greenhouse gas emissions, chiefly carbon dioxide, from the widespread use of engines in the modern industrialized world is contributing to the global greenhouse effect – a primary concern regarding global warming.

Some engines convert heat from noncombustive processes into mechanical work, for example a nuclear power plant uses the heat from the nuclear reaction to produce steam and drive a steam engine, or a gas turbine in a rocket engine may be driven by decomposing hydrogen peroxide. Apart from the different energy source, the engine is often engineered much the same as an internal or external combustion engine.

Another group of noncombustive engines includes thermoacoustic heat engines (sometimes called "TA engines") which are thermoacoustic devices that use high-amplitude sound waves to pump heat from one place to another, or conversely use a heat difference to induce high-amplitude sound waves. In general, thermoacoustic engines can be divided into standing wave and travelling wave devices.

Stirling engines can be another form of non-combustive heat engine. They use the Stirling thermodynamic cycle to convert heat into work. An example is the alpha type Stirling engine, whereby gas flows, via a recuperator, between a hot cylinder and a cold cylinder, which are attached to reciprocating pistons 90° out of phase. The gas receives heat at the hot cylinder and expands, driving the piston that turns the crankshaft. After expanding and flowing through the recuperator, the gas rejects heat at the cold cylinder and the ensuing pressure drop leads to its compression by the other (displacement) piston, which forces it back to the hot cylinder.

Non-thermal motors usually are powered by a chemical reaction, but are not heat engines. Examples include:

An "electric motor" uses electrical energy to produce mechanical energy, usually through the interaction of magnetic fields and current-carrying conductors. The reverse process, producing electrical energy from mechanical energy, is accomplished by a generator or dynamo. Traction motors used on vehicles often perform both tasks. Electric motors can be run as generators and vice versa, although this is not always practical.
Electric motors are ubiquitous, being found in applications as diverse as industrial fans, blowers and pumps, machine tools, household appliances, power tools, and disk drives. They may be powered by direct current (for example a battery powered portable device or motor vehicle), or by alternating current from a central electrical distribution grid. The smallest motors may be found in electric wristwatches. Medium-size motors of highly standardized dimensions and characteristics provide convenient mechanical power for industrial uses. The very largest electric motors are used for propulsion of large ships, and for such purposes as pipeline compressors, with ratings in the thousands of kilowatts. Electric motors may be classified by the source of electric power, by their internal construction, and by their application.

The physical principle of production of mechanical force by the interactions of an electric current and a magnetic field was known as early as 1821. Electric motors of increasing efficiency were constructed throughout the 19th century, but commercial exploitation of electric motors on a large scale required efficient electrical generators and electrical distribution networks.

To reduce the electric energy consumption from motors and their associated carbon footprints, various regulatory authorities in many countries have introduced and implemented legislation to encourage the manufacture and use of higher efficiency electric motors. A well-designed motor can convert over 90% of its input energy into useful power for decades. When the efficiency of a motor is raised by even a few percentage points, the savings, in kilowatt hours (and therefore in cost), are enormous. The electrical energy efficiency of a typical industrial induction motor can be improved by: 1) reducing the electrical losses in the stator windings (e.g., by increasing the cross-sectional area of the conductor, improving the winding technique, and using materials with higher electrical conductivities, such as copper), 2) reducing the electrical losses in the rotor coil or casting (e.g., by using materials with higher electrical conductivities, such as copper), 3) reducing magnetic losses by using better quality magnetic steel, 4) improving the aerodynamics of motors to reduce mechanical windage losses, 5) improving bearings to reduce friction losses, and 6) minimizing manufacturing tolerances. "For further discussion on this subject, see Premium efficiency)."

By convention, "electric engine" refers to a railroad electric locomotive, rather than an electric motor.

Some motors are powered by potential or kinetic energy, for example some funiculars, gravity plane and ropeway conveyors have used the energy from moving water or rocks, and some clocks have a weight that falls under gravity. Other forms of potential energy include compressed gases (such as pneumatic motors), springs (clockwork motors) and elastic bands.

Historic military siege engines included large catapults, trebuchets, and (to some extent) battering rams were powered by potential energy.

A "pneumatic motor" is a machine that converts potential energy in the form of compressed air into mechanical work. Pneumatic motors generally convert the compressed air to mechanical work through either linear or rotary motion. Linear motion can come from either a diaphragm or piston actuator, while rotary motion is supplied by either a vane type air motor or piston air motor. Pneumatic motors have found widespread success in the hand-held tool industry and continual attempts are being made to expand their use to the transportation industry. However, pneumatic motors must overcome efficiency deficiencies before being seen as a viable option in the transportation industry.

A "hydraulic motor" derives its power from a pressurized liquid. This type of engine is used to move heavy loads and drive machinery.

Some motor units can have multiple sources of energy. For example, a plug-in hybrid electric vehicle's electric motor could source electricity from either a battery or from fossil fuels inputs via an internal combustion engine and a generator.

The following are used in the assessment of the performance of an engine.

Speed refers to crankshaft rotation in piston engines and the speed of compressor/turbine rotors and electric motor rotors. It is measured in revolutions per minute (rpm).

Thrust is the force exerted on an airplane as a consequence of its propeller or jet engine accelerating the air passing through it. It is also the force exerted on a ship as a consequence of its propeller accelerating the water passing through it.

Torque is a turning moment on a shaft and is calculated by multiplying the force causing the moment by its distance from the shaft.

Power is the measure of how fast work is done.

Efficiency is a proportion of useful energy output compared to total input.

Vehicle noise is predominantly from the engine at low vehicle speeds and from tires and the air flowing past the vehicle at higher speeds. Electric motors are quieter than internal combustion engines. Thrust-producing engines, such as turbofans, turbojets and rockets emit the greatest amount of noise due to the way their thrust-producing, high-velocity exhaust streams interact with the surrounding stationary air.
Noise reduction technology includes intake and exhaust system mufflers (silencers) on gasoline and diesel engines and noise attenuation liners in turbofan inlets.

Particularly notable kinds of engines include:


Economic and monetary union

An economic and monetary union (EMU) is a type of trade bloc that features a combination of a common market, customs union, and monetary union. Established via a trade pact, an EMU constitutes the sixth of seven stages in the process of economic integration. An EMU agreement usually combines a customs union with a common market. A typical EMU establishes free trade and a common external tariff throughout its jurisdiction. It is also designed to protect freedom in the movement of goods, services, and people. This arrangement is distinct from a monetary union (e.g., the Latin Monetary Union), which does not usually involve a common market. As with the economic and monetary union established among the 27 member states of the European Union (EU), an EMU may affect different parts of its jurisdiction in different ways. Some areas are subject to separate customs regulations from other areas subject to the EMU. These various arrangements may be established in a formal agreement, or they may exist on a "de facto" basis. For example, not all EU member states use the Euro established by its currency union, and not all EU member states are part of the Schengen Area. Some EU members participate in both unions, and some in neither.

Territories of the United States, Australian External Territories and New Zealand territories each share a currency and, for the most part, the market of their respective mainland states. However, they are generally not part of the same customs territories.

Several countries initially attempted to form an EMU at the Hague Summit in 1969. Afterward, a "draft plan" was announced. During this time, the main member presiding over this decision was Pierre Werner, Prime Minister of Luxembourg. The decision to form the Economic and Monetary Union of the European Union (EMU) was accepted in which later became part of the Maastricht Treaty (the Treaty on European Union).

The EMU involves four main activities.

The first responsibility is to be in charge of implementing effective monetary policy for the euro area with price stability. There is a group of economists whose only role is studying how to improve the monetary policy while maintaining price stability. They conduct research, and their results are presented to the leaders of the EMU. Thereafter, the role of the leaders is to find a suitable way to implement the economists' work into their country's policies. Maintaining price stability is a long-term goal for all states in the EU, due to the effects it might have on the Euro as a currency.

Secondly, the EMU must coordinate economic and fiscal policies in EU countries. They must find an equilibrium between the implementation of monetary and fiscal policies. They will advise countries to have greater coordination, even if that means having countries tightly coupled with looser monetary and tighter fiscal policy. Not coordinating the monetary market could result in risking an unpredictable situation. The EMU also deliberates on a mixed policy option, which has been shown to be beneficial in some empirical studies.

Thirdly, the EMU ensures that the single market runs smoothly. The member countries respect the decisions made by the EMU and ensure that their actions will be in favor of a stable market.

Finally, regulations of the EMU aid in supervising and monitoring financial institutions. There is an imperative need for all members of the EMU to act in unison. Therefore, the EMU has to have institutions supervising all the member states to protect the main aim of the EMU.

The economic roles of nations within the EMU are to:






European Environment Agency

The European Environment Agency (EEA) is the agency of the European Union (EU) which provides independent information on the environment.

The European Environment Agency (EEA) is the agency of the European Union (EU) which provides independent information on the environment. 
Its goal is to help those involved in developing, implementing and evaluating environmental policy, and to inform the general public.

The EEA was established by the European Economic Community (EEC) Regulation 1210/1990 (amended by EEC Regulation 933/1999 and EC Regulation 401/2009) and became operational in 1994, headquartered in Copenhagen, Denmark.

The agency is governed by a management board composed of representatives of the governments of its 32 member states, a European Commission representative and two scientists appointed by the European Parliament, assisted by its Scientific Committee. 

The current Executive Director of the agency is Leena Ylä-Mononen, who has been appointed for a five-year term, starting on 1 June 2023. Ms Ylä-Mononen is the successor of professor Hans Bruyninckx.

The member states of the European Union are members; however other states may become members of it by means of agreements concluded between them and the EU.

It was the first EU body to open its membership to the 13 candidate countries (pre-2004 enlargement).

The EEA has 32 member countries and six cooperating countries. The members are the 27 European Union member states together with Iceland, Liechtenstein, Norway, Switzerland and Turkey.

Since Brexit in 2020, the UK is not a member of the EU anymore and therefore not a member state of the EEA.

The six Western Balkan countries are cooperating countries: Albania, Bosnia and Herzegovina, Montenegro, North Macedonia, Serbia as well as Kosovo under the UN Security Council Resolution 1244/99. These cooperation activities are integrated into Eionet and are supported by the EU under the "Instrument for Pre-Accession Assistance".

The EEA is an active member of the EPA Network.

The European Environment Agency (EEA) produces assessments based on quality-assured data on a wide range of issues from biodiversity, air quality, transport to climate change. These assessments are closely linked to the European Union's environment policies and legislation and help monitor progress in some areas and indicate areas where additional efforts are needed. 

As required in its founding regulation, the EEA publishes its flagship report the State and Outlook of Europe's environment (SOER), which is an integrated assessment, analysing trends, progress to targets as well as outlook for the mid- to long-term. The agency publishes annually a report on Europe's most polluted provinces for air quality, detailing fine particulate matter PM 2.5.

The EEA shares this information, including the datasets used in its assessments, through its main website and a number of thematic information platforms such as Biodiversity Information System for Europe (BISE), Water Information System for Europe (WISE) and ClimateADAPT. The Climate-ADAPT knowledge platform presents information and data on expected climatic changes, the vulnerability of regions and sectors, adaptation case studies, and adaptation options, adaptation planning tools, and EU policy.

The European Nature Information System (EUNIS) provides access to the publicly available data in the EUNIS database for species, habitat types and protected sites across Europe. It is part of the European Biodiversity data centre (BDC), and is maintained by the EEA.

The database contains data

The European Environment Information and Observation Network (Eionet) is a collaboration network between EEA member countries and non-member, cooperating nations. Cooperation is facilitated through different national environmental agencies, ministries, or offices. Eionet encourages the sharing of data and highlights specific topics for discussion and cooperation among participating countries.

Eionet currently includes covers seven European Topic Centres (ETCs):

The European Environment Agency (EEA) implements the "Shared Environmental Information System" principles and best practices via projects such as the "ENI SEIS II EAST PROJECT" & the "ENI SEIS II SOUTH PROJECT" to support environmental protection within the six eastern partnership countries (ENP) & to contribute to the reduction in marine pollution in the Mediterranean through the shared availability and access to relevant environmental information. 

As for every EU body and institution, the EEA's budget is subject to a discharge process, consisting of external examination of its budget execution and financial management, to ensure sound financial management of its budget. Since its establishment, the EEA has been granted discharge for its budget without exception. The EEA provides full access to its administrative and budgetary documents in its public documents register. 

The discharge process for the 2010 budget required additional clarifications. In February 2012, the European Parliament's Committee on Budgetary Control published a draft report, identifying areas of concern in the use of funds and its influence for the 2010 budget such as a 26% budget increase from 2009 to 2010 to €50 600 000. and questioned that maximum competition and value-for-money principles were honored in hiring, also possible fictitious employees.

The EEA's Executive Director refuted allegations of irregularities in a public hearing. On 27 March 2012 Members of the European Parliament (MEPs) voted on the report and commended the cooperation between the Agency and NGOs working in the environmental area. On 23 October 2012, the European Parliament voted and granted the discharge to the European Environment Agency for its 2010 budget.

In addition to its 32 members and six Balkan cooperating countries, the EEA also cooperates and fosters partnerships with its neighbours and other countries and regions, mostly in the context of the European Neighbourhood Policy:
Additionally the EEA cooperates with multiple international organizations and the corresponding agencies of the following countries:

The 26 official languages used by the EEA are: Bulgarian, Czech, Croatian, Danish, German, Greek, English, Spanish, Estonian, Finnish, French, Hungarian, Icelandic, Italian, Lithuanian, Latvian, Malti, Dutch, Norwegian, Polish, Portuguese, Romanian, Slovak, Slovene, Swedish and Turkish.



Erlang (programming language)

Erlang ( ) is a general-purpose, concurrent, functional high-level programming language, and a garbage-collected runtime system. The term Erlang is used interchangeably with Erlang/OTP, or Open Telecom Platform (OTP), which consists of the Erlang runtime system, several ready-to-use components (OTP) mainly written in Erlang, and a set of design principles for Erlang programs.

The Erlang runtime system is designed for systems with these traits:


The Erlang programming language has immutable data, pattern matching, and functional programming. The sequential subset of the Erlang language supports eager evaluation, single assignment, and dynamic typing.

A normal Erlang application is built out of hundreds of small Erlang processes.

It was originally proprietary software within Ericsson, developed by Joe Armstrong, Robert Virding, and Mike Williams in 1986, but was released as free and open-source software in 1998. Erlang/OTP is supported and maintained by the Open Telecom Platform (OTP) product unit at Ericsson.

The name "Erlang", attributed to Bjarne Däcker, has been presumed by those working on the telephony switches (for whom the language was designed) to be a reference to Danish mathematician and engineer Agner Krarup Erlang and a syllabic abbreviation of "Ericsson Language". Erlang was designed with the aim of improving the development of telephony applications. The initial version of Erlang was implemented in Prolog and was influenced by the programming language PLEX used in earlier Ericsson exchanges. By 1988 Erlang had proven that it was suitable for prototyping telephone exchanges, but the Prolog interpreter was far too slow. One group within Ericsson estimated that it would need to be 40 times faster to be suitable for production use. In 1992, work began on the BEAM virtual machine (VM) which compiles Erlang to C using a mix of natively compiled code and threaded code to strike a balance between performance and disk space. According to co-inventor Joe Armstrong, the language went from lab product to real applications following the collapse of the next-generation AXE telephone exchange named in 1995. As a result, Erlang was chosen for the next Asynchronous Transfer Mode (ATM) exchange "AXD".

In February 1998, Ericsson Radio Systems banned the in-house use of Erlang for new products, citing a preference for non-proprietary languages. The ban caused Armstrong and others to make plans to leave Ericsson. In March 1998 Ericsson announced the AXD301 switch, containing over a million lines of Erlang and reported to achieve a high availability of nine "9"s. In December 1998, the implementation of Erlang was open-sourced and most of the Erlang team resigned to form a new company Bluetail AB. Ericsson eventually relaxed the ban and re-hired Armstrong in 2004.

In 2006, native symmetric multiprocessing support was added to the runtime system and VM.

Erlang applications are built of very lightweight Erlang processes in the Erlang runtime system. Erlang processes can be seen as "living" objects (object-oriented programming), with data encapsulation and message passing, but capable of changing behavior during runtime. The Erlang runtime system provides strict process isolation between Erlang processes (this includes data and garbage collection, separated individually by each Erlang process) and transparent communication between processes (see Location transparency) on different Erlang nodes (on different hosts).

Joe Armstrong, co-inventor of Erlang, summarized the principles of processes in his PhD thesis:


Joe Armstrong remarked in an interview with Rackspace in 2013: "If Java is 'write once, run anywhere', then Erlang is 'write once, run forever'."

In 2014, Ericsson reported Erlang was being used in its support nodes, and in GPRS, 3G and LTE mobile networks worldwide and also by Nortel and T-Mobile.

Erlang is used in RabbitMQ. As Tim Bray, director of Web Technologies at Sun Microsystems, expressed in his keynote at O'Reilly Open Source Convention (OSCON) in July 2008:
Erlang is the programming language used to code WhatsApp.

It is also the language of choice for Ejabberd – an XMPP messaging server.

Elixir is a programming language that compiles into BEAM byte code (via Erlang Abstract Format).

Since being released as open source, Erlang has been spreading beyond telecoms, establishing itself in other vertical markets such as FinTech, gaming, healthcare, automotive, internet of things and blockchain. Apart from WhatsApp, there are other companies listed as Erlang's success stories: Vocalink (a MasterCard company), Goldman Sachs, Nintendo, AdRoll, Grindr, BT Mobile, Samsung, OpenX, and SITA.

A factorial algorithm implemented in Erlang:

-module(fact). % This is the file 'fact.erl', the module and the filename must match
-export([fac/1]). % This exports the function 'fac' of arity 1 (1 parameter, no type, no name)

fac(0) -> 1; % If 0, then return 1, otherwise (note the semicolon ; meaning 'else')
fac(N) when N > 0, is_integer(N) -> N * fac(N-1).
% Recursively determine, then return the result
% (note the period . meaning 'endif' or 'function end')
%% This function will crash if anything other than a nonnegative integer is given.
%% It illustrates the "Let it crash" philosophy of Erlang.

A tail recursive algorithm that produces the Fibonacci sequence:
%% The module declaration must match the file name "series.erl" 
-module(series).

%% The export statement contains a list of all those functions that form
%% the module's public API. In this case, this module exposes a single
%% function called fib that takes 1 argument (I.E. has an arity of 1)
%% The general syntax for -export is a list containing the name and
%% arity of each public function
-export([fib/1]).
%% Public API

%% Handle cases in which fib/1 receives specific values
%% The order in which these function signatures are declared is a vital
%% part of this module's functionality

%% If fib/1 is passed precisely the integer 0, then return 0
fib(0) -> 0;

%% If fib/1 receives a negative number, then return the atom err_neg_val
%% Normally, such defensive coding is discouraged due to Erlang's 'Let
%% it Crash' philosophy; however, in this case we should explicitly
%% prevent a situation that will crash Erlang's runtime engine
fib(N) when N < 0 -> err_neg_val;

%% If fib/1 is passed an integer less than 3, then return 1
%% The preceding two function signatures handle all cases where N < 1,
%% so this function signature handles cases where N = 1 or N = 2
fib(N) when N < 3 -> 1;

%% For all other values, call the private function fib_int/3 to perform
%% the calculation
fib(N) -> fib_int(N, 0, 1).
%% Private API

%% If fib_int/3 receives a 1 as its first argument, then we're done, so
%% return the value in argument B. Since we are not interested in the
%% value of the second argument, we denote this using _ to indicate a
%% "don't care" value
fib_int(1, _, B) -> B;

%% For all other argument combinations, recursively call fib_int/3
%% where each call does the following:
%% - decrement counter N
%% - Take the previous fibonacci value in argument B and pass it as
%% argument A
%% - Calculate the value of the current fibonacci number and pass it
%% as argument B
fib_int(N, A, B) -> fib_int(N-1, B, A+B).
Here is the same program without the explanatory comments:
-module(series).
-export([fib/1]).

fib(0) -> 0;
fib(N) when N < 0 -> err_neg_val;
fib(N) when N < 3 -> 1;
fib(N) -> fib_int(N, 0, 1).

fib_int(1, _, B) -> B;
fib_int(N, A, B) -> fib_int(N-1, B, A+B).
Quicksort in Erlang, using list comprehension:
%% qsort:qsort(List)
%% Sort a list of items
-module(qsort). % This is the file 'qsort.erl'
-export([qsort/1]). % A function 'qsort' with 1 parameter is exported (no type, no name)

qsort([]) -> []; % If the list [] is empty, return an empty list (nothing to sort)
qsort([Pivot|Rest]) ->
The above example recursively invokes the function codice_1 until nothing remains to be sorted. The expression codice_2 is a list comprehension, meaning "Construct a list of elements codice_3 such that codice_3 is a member of codice_5, and codice_3 is less than codice_7." codice_8 is the list concatenation operator.

A comparison function can be used for more complicated structures for the sake of readability.

The following code would sort lists according to length:

% This is file 'listsort.erl' (the compiler is made this way)
-module(listsort).
% Export 'by_length' with 1 parameter (don't care about the type and name)
-export([by_length/1]).

by_length(Lists) -> % Use 'qsort/2' and provides an anonymous function as a parameter

qsort([], _)-> []; % If list is empty, return an empty list (ignore the second parameter)
qsort([Pivot|Rest], Smaller) ->
A codice_7 is taken from the first parameter given to codice_10 and the rest of codice_11 is named codice_5. Note that the expression

[X || X <- Rest, Smaller(X,Pivot)]

is no different in form from

[Front || Front <- Rest, Front < Pivot]

(in the previous example) except for the use of a comparison function in the last part, saying "Construct a list of elements codice_13 such that codice_13 is a member of codice_5, and codice_16 is true", with codice_16 being defined earlier as

fun(A,B) -> length(A) < length(B) end

The anonymous function is named codice_16 in the parameter list of the second definition of codice_1 so that it can be referenced by that name within that function. It is not named in the first definition of codice_1, which deals with the base case of an empty list and thus has no need of this function, let alone a name for it.

Erlang has eight primitive data types:


And three compound data types:


Two forms of syntactic sugar are provided:


Erlang has no method to define classes, although there are external libraries available.

Erlang is designed with a mechanism that makes it easy for external processes to monitor for crashes (or hardware failures), rather than an in-process mechanism like exception handling used in many other programming languages. Crashes are reported like other messages, which is the only way processes can communicate with each other, and subprocesses can be spawned cheaply (see below). The "let it crash" philosophy prefers that a process be completely restarted rather than trying to recover from a serious failure. Though it still requires handling of errors, this philosophy results in less code devoted to defensive programming where error-handling code is highly contextual and specific.

A typical Erlang application is written in the form of a supervisor tree. This architecture is based on a hierarchy of processes in which the top level process is known as a "supervisor". The supervisor then spawns multiple child processes that act either as workers or more, lower level supervisors. Such hierarchies can exist to arbitrary depths and have proven to provide a highly scalable and fault-tolerant environment within which application functionality can be implemented.

Within a supervisor tree, all supervisor processes are responsible for managing the lifecycle of their child processes, and this includes handling situations in which those child processes crash. Any process can become a supervisor by first spawning a child process, then calling codice_35 on that process. If the monitored process then crashes, the supervisor will receive a message containing a tuple whose first member is the atom codice_36. The supervisor is responsible firstly for listening for such messages and secondly, for taking the appropriate action to correct the error condition.

Erlang's main strength is support for concurrency. It has a small but powerful set of primitives to create processes and communicate among them. Erlang is conceptually similar to the language occam, though it recasts the ideas of communicating sequential processes (CSP) in a functional framework and uses asynchronous message passing. Processes are the primary means to structure an Erlang application. They are neither operating system processes nor threads, but lightweight processes that are scheduled by BEAM. Like operating system processes (but unlike operating system threads), they share no state with each other. The estimated minimal overhead for each is 300 words. Thus, many processes can be created without degrading performance. In 2005, a benchmark with 20 million processes was successfully performed with 64-bit Erlang on a machine with 16 GB random-access memory (RAM; total 800 bytes/process). Erlang has supported symmetric multiprocessing since release R11B of May 2006.

While threads need external library support in most languages, Erlang provides language-level features to create and manage processes with the goal of simplifying concurrent programming. Though all concurrency is explicit in Erlang, processes communicate using message passing instead of shared variables, which removes the need for explicit locks (a locking scheme is still used internally by the VM).

Inter-process communication works via a shared-nothing asynchronous message passing system: every process has a "mailbox", a queue of messages that have been sent by other processes and not yet consumed. A process uses the codice_37 primitive to retrieve messages that match desired patterns. A message-handling routine tests messages in turn against each pattern, until one of them matches. When the message is consumed and removed from the mailbox the process resumes execution. A message may comprise any Erlang structure, including primitives (integers, floats, characters, atoms), tuples, lists, and functions.

The code example below shows the built-in support for distributed processes:

As the example shows, processes may be created on remote nodes, and communication with them is transparent in the sense that communication with remote processes works exactly as communication with local processes.

Concurrency supports the primary method of error-handling in Erlang. When a process crashes, it neatly exits and sends a message to the controlling process which can then take action, such as starting a new process that takes over the old process's task.

The official reference implementation of Erlang uses BEAM. BEAM is included in the official distribution of Erlang, called Erlang/OTP. BEAM executes bytecode which is converted to threaded code at load time. It also includes a native code compiler on most platforms, developed by the High Performance Erlang Project (HiPE) at Uppsala University. Since October 2001 the HiPE system is fully integrated in Ericsson's Open Source Erlang/OTP system. It also supports interpreting, directly from source code via abstract syntax tree, via script as of R11B-5 release of Erlang.

Erlang supports language-level Dynamic Software Updating. To implement this, code is loaded and managed as "module" units; the module is a compilation unit. The system can keep two versions of a module in memory at the same time, and processes can concurrently run code from each. The versions are referred to as the "new" and the "old" version. A process will not move into the new version until it makes an external call to its module.

An example of the mechanism of hot code loading:

For the second version, we add the possibility to reset the count to zero.

Only when receiving a message consisting of the atom codice_38 will the loop execute an external call to codeswitch/1 (codice_39 is a preprocessor macro for the current module). If there is a new version of the "counter" module in memory, then its codeswitch/1 function will be called. The practice of having a specific entry-point into a new version allows the programmer to transform state to what is needed in the newer version. In the example, the state is kept as an integer.

In practice, systems are built up using design principles from the Open Telecom Platform, which leads to more code upgradable designs. Successful hot code loading is exacting. Code must be written with care to make use of Erlang's facilities.

In 1998, Ericsson released Erlang as free and open-source software to ensure its independence from a single vendor and to increase awareness of the language. Erlang, together with libraries and the real-time distributed database Mnesia, forms the OTP collection of libraries. Ericsson and a few other companies support Erlang commercially.

Since the open source release, Erlang has been used by several firms worldwide, including Nortel and T-Mobile. Although Erlang was designed to fill a niche and has remained an obscure language for most of its existence, its popularity is growing due to demand for concurrent services.
Erlang has found some use in fielding massively multiplayer online role-playing game (MMORPG) servers.



Euphoria (programming language)

Euphoria is a programming language created by Robert Craig of Rapid Deployment Software in Toronto, Ontario, Canada. Initially developed (though not publicly released) on the Atari ST, the first commercial release was for MS-DOS as proprietary software. In 2006, with the release of version 3, Euphoria became open-source software. The openEuphoria Group continues to administer and develop the project. In December 2010, the openEuphoria Group released version 4 of openEuphoria along with a new identity and mascot for the project. OpenEuphoria is currently available for Windows, Linux, macOS and three flavors of *BSD.

Euphoria is a general-purpose high-level imperative-procedural interpreted language. A translator generates C source code and the GNU compiler collection (GCC) and Open Watcom compilers are supported. Alternatively, Euphoria programs may be bound with the interpreter to create stand-alone executables. A number of graphical user interface (GUI) libraries are supported including Win32lib and wrappers for wxWidgets, GTK+ and IUP. Euphoria has a simple built-in database and wrappers for a variety of other databases.

The Euphoria language is a general purpose procedural language that focuses on simplicity, legibility, rapid development and performance via several means.

Developed as a personal project to invent a programming language from scratch, Euphoria was created by Robert Craig on an Atari Mega-ST. Many design ideas for the language came from Craig's Master's thesis in computer science at the University of Toronto. Craig's thesis was heavily influenced by the work of John Backus on functional programming (FP) languages.

Craig ported his original Atari implementation to the 16-bit DOS platform and Euphoria was first released, version 1.0, in July 1993 under a proprietary licence. The original Atari implementation is described by Craig as "primitive" and has not been publicly released. Euphoria continued to be developed and released by Craig via his company Rapid Deployment Software (RDS) and website rapideuphoria.com. In October 2006 RDS released version 3 of Euphoria and announced that henceforth Euphoria would be freely distributed under an open-source software licence.

RDS continued to develop Euphoria, culminating with the release of version 3.1.1 in August, 2007. Subsequently, RDS ceased unilateral development of Euphoria and the openEuphoria Group took over ongoing development. The openEuphoria Group released version 4 in December, 2010 along with a new logo and mascot for the openEuphoria project.

Version 3.1.1 remains an important milestone release, being the last version of Euphoria which supports the DOS platform.

Euphoria is an acronym for "End-User Programming with Hierarchical Objects for Robust Interpreted Applications" although there is some suspicion that this is a backronym.

The Euphoria interpreter was originally written in C. With the release of version 2.5 in November 2004 the Euphoria interpreter was split into two parts: a front-end parser, and a back-end interpreter. The front-end is now written in Euphoria (and used with the Euphoria-to-C translator and the Binder). The main back-end and run time library are written in C.

Euphoria was conceived and developed with the following design goals and features:



Euphoria is designed to readily facilitate handling of dynamic sets of data of varying types and is particularly useful for string and image processing. Euphoria has been used in artificial intelligence experiments, the study of mathematics, for teaching programming, and to implement fonts involving thousands of characters. A large part of the Euphoria interpreter is written in Euphoria.

Euphoria has two basic data types:

Euphoria has two additional data types predefined:

There is no character string data type. Strings are represented by a "sequence" of "integer" values. However, because literal strings are so commonly used in programming, Euphoria interprets double-quote enclosed characters as a sequence of integers. Thus
is seen as if the coder had written:
which is the same as:

 puts(1, "Hello, World!\n")

Program comments start with a double hyphen codice_1 and go through the end of line.

The following code looks for an old item in a group of items. If found, it removes it by concatenating all the elements before it with all the elements after it. Note that the first element in a sequence has the index one [1] and that $ refers to the length (i.e., total number of elements) of the sequence.

The following modification to the above example replaces an old item with a new item. As the variables "old" and "new" have been defined as objects, they could be "atoms" or "sequences". Type checking is not needed as the function will work with any sequence of data of any type and needs no external libraries.

Furthermore, no pointers are involved and subscripts are automatically checked. Thus the function cannot access memory out-of-bounds. There is no need to allocate or deallocate memory explicitly and no chance of a memory leak.

The line

shows some of the "sequence" handling facilities. A "sequence" may contain a set of any types, and this can be sliced (to take a subset of the data in a "sequence") and concatenated in expressions with no need for special functions.

Arguments to routines are always passed by value; there is no pass-by-reference facility. However, parameters are allowed to be modified "locally" (i.e., within the callee) which is implemented very efficiently as sequences have automatic copy-on-write semantics. In other words, when you pass a sequence to a routine, initially only a reference to it is passed, but at the point the routine modifies this sequence parameter the sequence is copied and the routine updates only a copy of the original.


Free downloads of Euphoria for the various platforms, packages, Windows IDE, Windows API libraries, a cross-platform GTK3 wrapper for Linux and Windows, graphics libraries (DOS, OpenGL, etc.).

Energy

In physics, energy () is the quantitative property that is transferred to a body or to a physical system, recognizable in the performance of work and in the form of heat and light. Energy is a conserved quantity—the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The unit of measurement for energy in the International System of Units (SI) is the joule (J).

Common forms of energy include the kinetic energy of a moving object, the potential energy stored by an object (for instance due to its position in a field), the elastic energy stored in a solid object, chemical energy associated with chemical reactions, the radiant energy carried by electromagnetic radiation, and the internal energy contained within a thermodynamic system. All living organisms constantly take in and release energy.

Due to mass–energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. 

Human civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The Earth's climate and ecosystems processes are driven by the energy the planet receives from the Sun (although a small amount is also contributed by geothermal energy).

The total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object – or the composite motion of the object's components – while potential energy reflects the potential of an object to have motion, generally being based upon the object's position within a field or what is stored within the field itself.

While these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, the sum of translational and rotational kinetic and potential energy within a system is referred to as mechanical energy, whereas nuclear energy refers to the combined potentials within an atomic nucleus from either the nuclear force or the weak force, among other examples.

The word "energy" derives from the , which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.

In the late 17th century, Gottfried Leibniz proposed the idea of the , or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total "vis viva" was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the motions of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from "vis viva" only by a factor of two. Writing in the early 18th century, Émilie du Châtelet proposed the concept of conservation of energy in the marginalia of her French language translation of Newton's "Principia Mathematica", which represented the first formulation of a conserved measurable quantity that was distinct from momentum, and which would later be called "energy".

In 1807, Thomas Young was possibly the first to use the term "energy" instead of "vis viva", in its modern sense. Gustave-Gaspard Coriolis described "kinetic energy" in 1829 in its modern sense, and in 1853, William Rankine coined the term "potential energy". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.

These developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jožef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.

In 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the "Joule apparatus": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.

In the International System of Units (SI), the unit of energy is the joule, named after Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British thermal units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.

The SI unit of energy rate (energy per unit time) is the watt, which is a joule per second. Thus, one joule is one watt-second, and 3600 joules equal one watt-hour. The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.

In classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.

Work, a function of energy, is force times distance.

This says that the work (formula_2) is equal to the line integral of the force F along a path "C"; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.

The total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.

Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy "minus" the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).

Noether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.

In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular, or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is usually accompanied by a decrease, and sometimes an increase, of the total energy of the substances involved. Some energy may be transferred between the surroundings and the reactants in the form of heat or light; thus the products of a reaction have sometimes more but usually less energy than the reactants. A reaction is said to be exothermic or exergonic if the final state is lower on the energy scale than the initial state; in the less common case of endothermic reactions the situation is the reverse. Chemical reactions are usually not possible unless the reactants surmount an energy barrier known as the activation energy. The "speed" of a chemical reaction (at a given temperature "T") is related to the activation energy "E" by the Boltzmann's population factor e; that is, the probability of a molecule to have energy greater than or equal to "E" at a given temperature "T". This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction can be provided in the form of thermal energy.

In biology, energy is an attribute of all biological systems, from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or organelle of a biological organism. Energy used in respiration is stored in substances such as carbohydrates (including sugars), lipids, and proteins stored by cells. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, using as a standard an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 ÷ 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a "feel" for the use of a given amount of energy.

Sunlight's radiant energy is also captured by plants as "chemical potential energy" in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into carbohydrates, lipids, proteins and oxygen. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark in a forest fire, or it may be made available more slowly for animal or human metabolism when organic molecules are ingested and catabolism is triggered by enzyme action.

All living creatures rely on an external source of energy to be able to grow and reproduce – radiant energy from the Sun in the case of green plants and chemical energy (in some form) in the case of animals. The daily 1500–2000 Calories (6–8 MJ) recommended for a human adult are taken as food molecules, mostly carbohydrates and fats, of which glucose (CHO) and stearin (CHO) are convenient examples. The food molecules are oxidized to carbon dioxide and water in the mitochondria
<chem display="block">C6H12O6 + 6O2 -> 6CO2 + 6H2O</chem>
<chem display="block">C57H110O6 + (81 1/2) O2 -> 57CO2 + 55H2O</chem>
and some of the energy is used to convert ADP into ATP:

The rest of the chemical energy of the carbohydrate or fat are converted into heat: the ATP is used as a sort of "energy currency", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:

It would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy); most machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe ("the surroundings"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology. As an example, to take just the first step in the food chain: of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.

In geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations in our atmosphere brought about by solar energy.

Sunlight is the main input to Earth's energy budget which accounts for its temperature and climate stability. Sunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example when) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives most weather phenomena, save a few exceptions, like those generated by volcanic events for example. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, suddenly give up some of their thermal energy to power a few days of violent air movement.

In a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may later be transformed into active kinetic energy during landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars (which created these atoms).

In cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.

In quantum mechanics, energy is defined in terms of the energy operator
(Hamiltonian) as a time derivative of the wave function. The Schrödinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schrödinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schrödinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: formula_3 (where formula_4 is the Planck constant and formula_5 the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.

When calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically – using Lorentz transformations instead of Newtonian mechanics – Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:

formula_6
where

For example, consider electron–positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles. This is a reversible process – the inverse process is called pair creation – in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.

In general relativity, the stress–energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.

Energy and mass are manifestations of one and the same underlying physical property of a system. This property is responsible for the inertia and strength of gravitational interaction of the system ("mass manifestations"), and is also responsible for the potential ability of the system to perform work or heating ("energy manifestations"), subject to the limitations of other physical laws.

In classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy–momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of spacetime (= boosts).

Energy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery (from chemical energy to electric energy), a dam (from gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator), and a heat engine (from heat to work).

Examples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. The Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that itself (since it still contains the same total energy even in different forms) but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.

There are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.

Energy transformations in the universe over time are characterized by various kinds of potential energy, that has been available since the Big Bang, being "released" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae to "store" energy in the creation of heavy isotopes (such as uranium and thorium), and nuclear decay, a process in which energy is released that was originally stored in these heavy elements, before they were incorporated into the Solar System and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic and thermal energy in a very short time.

Yet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at its maximum. At its lowest point the kinetic energy is at its maximum and is equal to the decrease in potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.

Energy is also transferred from potential energy (formula_8) to kinetic energy (formula_9) and then back to potential energy constantly. This is referred to as conservation of energy. In this isolated system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:
The equation can then be simplified further since formula_10 (mass times acceleration due to gravity times the height) and formula_11 (half mass times velocity squared). Then the total amount of energy can be found by adding formula_12.

Energy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass–energy equivalence. The formula "E" = "mc"², derived by Albert Einstein (1905) quantifies the relationship between relativistic mass and energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J.J. Thomson (1881), Henri Poincaré (1900), Friedrich Hasenöhrl (1904) and others (see Mass–energy equivalence#History for further information).

Part of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since formula_13 is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~formula_14 joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics. Often, however, the complete conversion of matter (such as atoms) to non-matter (such as photons) is forbidden by conservation laws.

Thermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as thermal energy and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomization in a crystal).

As the universe evolves with time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or as other kinds of increases in disorder). This has led to the hypothesis of the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), continues to decrease.

The fact that energy can be neither created nor destroyed is called the law of conservation of energy. In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out as work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.

While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.

Richard Feynman said during a 1961 lecture:
Most kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.

This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle – it is impossible to define the exact amount of energy during any definite time interval (though this is practically significant only for very short time intervals). The uncertainty principle should not be confused with energy conservation – rather it provides mathematical limits to which energy can in principle be defined and measured.

Each of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appear as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.

In quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by

which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since "H" and "t" are not dynamically conjugate variables, neither in classical nor in quantum mechanics).

In particle physics, this inequality permits a qualitative understanding of virtual particles, which carry momentum. The exchange of virtual particles with real particles is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons are also responsible for the electrostatic interaction between electric charges (which results in Coulomb's law), for spontaneous radiative decay of excited atomic and nuclear states, for the Casimir force, for the Van der Waals force and some other observable phenomena.

Energy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, tidal interactions, and the conductive transfer of thermal energy.

Energy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:

where formula_16 is the amount of energy transferred, formula_2  represents the work done on or by the system, and formula_18 represents the heat flow into or out of the system. As a simplification, the heat term, formula_18, can sometimes be ignored, especially for fast processes involving gases, which are poor conductors of heat, or when the thermal efficiency of the transfer is high. For such adiabatic processes,

This simplified equation is the one used to define the joule, for example.

Beyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (this process is illustrated by injection of an air-fuel mixture into a car engine, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by formula_20, one may write

Internal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.

The first law of thermodynamics asserts that the total energy of a system and its surroundings (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a "gain" in energy signified by a positive quantity) is given as

where the first term on the right is the heat transferred into the system, expressed in terms of temperature "T" and entropy "S" (in which entropy increases and its change d"S" is positive when heat is added to the system), and the last term on the right hand side is identified as work done on the system, where pressure is "P" and volume "V" (the negative sign results since compression of the system requires work to be done on it and so the volume change, d"V", is negative when work is done on the system).

This equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and "PV"-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a "closed" system is expressed in a general form by

where formula_23 is the heat supplied to the system and formula_24 is the work applied to the system.

The energy of a mechanical harmonic oscillator (a mass on a spring) is alternately kinetic and potential energy. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over a whole cycle, or over many cycles, average energy is equally split between kinetic and potential. This is an example of the equipartition principle: the total energy of a system with many degrees of freedom is equally split among all available degrees of freedom, on average.

This principle is vitally important to understanding the behavior of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between "new" and "old" degrees. This mathematical result is part of the second law of thermodynamics. The second law of thermodynamics is simple only for systems which are near or in a physical equilibrium state. For non-equilibrium systems, the laws governing the systems' behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way as to maximize their entropy production.




Expected value

In probability theory, the expected value (also called expectation, expectancy, expectation operator, mathematical expectation, mean, expectation value, or first moment) is a generalization of the weighted average. Informally, the expected value is the arithmetic mean of the possible values a random variable can take, weighted by the probability of those outcomes. Since it is obtained through arithmetic, the expected value sometimes may not even be included in the sample data set; it is not the value you would "expect" to get in reality.

The expected value of a random variable with a finite number of outcomes is a weighted average of all possible outcomes. In the case of a continuum of possible outcomes, the expectation is defined by integration. In the axiomatic foundation for probability provided by measure theory, the expectation is given by Lebesgue integration.

The expected value of a random variable is often denoted by , , or , with also often stylized as or formula_1

The idea of the expected value originated in the middle of the 17th century from the study of the so-called problem of points, which seeks to divide the stakes "in a fair way" between two players, who have to end their game before it is properly finished. This problem had been debated for centuries. Many conflicting proposals and solutions had been suggested over the years when it was posed to Blaise Pascal by French writer and amateur mathematician Chevalier de Méré in 1654. Méré claimed that this problem could not be solved and that it showed just how flawed mathematics was when it came to its application to the real world. Pascal, being a mathematician, was provoked and determined to solve the problem once and for all.

He began to discuss the problem in the famous series of letters to Pierre de Fermat. Soon enough, they both independently came up with a solution. They solved the problem in different computational ways, but their results were identical because their computations were based on the same fundamental principle. The principle is that the value of a future gain should be directly proportional to the chance of getting it. This principle seemed to have come naturally to both of them. They were very pleased by the fact that they had found essentially the same solution, and this in turn made them absolutely convinced that they had solved the problem conclusively; however, they did not publish their findings. They only informed a small circle of mutual scientific friends in Paris about it.

In Dutch mathematician Christiaan Huygens' book, he considered the problem of points, and presented a solution based on the same principle as the solutions of Pascal and Fermat. Huygens published his treatise in 1657, (see Huygens (1657)) ""De ratiociniis in ludo aleæ"" on probability theory just after visiting Paris. The book extended the concept of expectation by adding rules for how to calculate expectations in more complicated situations than the original problem (e.g., for three or more players), and can be seen as the first successful attempt at laying down the foundations of the theory of probability.

In the foreword to his treatise, Huygens wrote:

During his visit to France in 1655, Huygens learned about de Méré's Problem. From his correspondence with Carcavine a year later (in 1656), he realized his method was essentially the same as Pascal's. Therefore, he knew about Pascal's priority in this subject before his book went to press in 1657.

In the mid-nineteenth century, Pafnuty Chebyshev became the first person to think systematically in terms of the expectations of random variables.

Neither Pascal nor Huygens used the term "expectation" in its modern sense. In particular, Huygens writes:

More than a hundred years later, in 1814, Pierre-Simon Laplace published his tract ""Théorie analytique des probabilités"", where the concept of expected value was defined explicitly:

The use of the letter to denote "expected value" goes back to W. A. Whitworth in 1901. The symbol has since become popular for English writers. In German, stands for "Erwartungswert", in Spanish for "esperanza matemática", and in French for "espérance mathématique."

When "E" is used to denote "expected value", authors use a variety of stylizations: the expectation operator can be stylized as (upright), (italic), or formula_2 (in blackboard bold), while a variety of bracket notations (such as , , and ) are all used.

Another popular notation is , whereas , , and formula_3 are commonly used in physics, and in Russian-language literature.

As discussed above, there are several context-dependent ways of defining the expected value. The simplest and original definition deals with the case of finitely many possible outcomes, such as in the flip of a coin. With the theory of infinite series, this can be extended to the case of countably many possible outcomes. It is also very common to consider the distinct case of random variables dictated by (piecewise-)continuous probability density functions, as these arise in many natural contexts. All of these specific definitions may be viewed as special cases of the general definition based upon the mathematical tools of measure theory and Lebesgue integration, which provide these different contexts with an axiomatic foundation and common language.

Any definition of expected value may be extended to define an expected value of a multidimensional random variable, i.e. a random vector . It is defined component by component, as . Similarly, one may define the expected value of a random matrix with components by .

Consider a random variable with a "finite" list of possible outcomes, each of which (respectively) has probability of occurring. The expectation of is defined as

Since the probabilities must satisfy , it is natural to interpret as a weighted average of the values, with weights given by their probabilities .

In the special case that all possible outcomes are equiprobable (that is, ), the weighted average is given by the standard average. In the general case, the expected value takes into account the fact that some outcomes are more likely than others.



Informally, the expectation of a random variable with a countably infinite set of possible outcomes is defined analogously as the weighted average of all possible outcomes, where the weights are given by the probabilities of realizing each given value. This is to say that
where are the possible outcomes of the random variable and are their corresponding probabilities. In many non-mathematical textbooks, this is presented as the full definition of expected values in this context.

However, there are some subtleties with infinite summation, so the above formula is not suitable as a mathematical definition. In particular, the Riemann series theorem of mathematical analysis illustrates that the value of certain infinite sums involving positive and negative summands depends on the order in which the summands are given. Since the outcomes of a random variable have no naturally given order, this creates a difficulty in defining expected value precisely.

For this reason, many mathematical textbooks only consider the case that the infinite sum given above converges absolutely, which implies that the infinite sum is a finite number independent of the ordering of summands. In the alternative case that the infinite sum does not converge absolutely, one says the random variable "does not have finite expectation."


Now consider a random variable which has a probability density function given by a function on the real number line. This means that the probability of taking on a value in any given open interval is given by the integral of over that interval. The expectation of is then given by the integral
A general and mathematically precise formulation of this definition uses measure theory and Lebesgue integration, and the corresponding theory of "absolutely continuous random variables" is described in the next section. The density functions of many common distributions are piecewise continuous, and as such the theory is often developed in this restricted setting. For such functions, it is sufficient to only consider the standard Riemann integration. Sometimes "continuous random variables" are defined as those corresponding to this special class of densities, although the term is used differently by various authors.

Analogously to the countably-infinite case above, there are subtleties with this expression due to the infinite region of integration. Such subtleties can be seen concretely if the distribution of is given by the Cauchy distribution , so that . It is straightforward to compute in this case that
The limit of this expression as and does not exist: if the limits are taken so that , then the limit is zero, while if the constraint is taken, then the limit is .

To avoid such ambiguities, in mathematical textbooks it is common to require that the given integral converges absolutely, with left undefined otherwise. However, measure-theoretic notions as given below can be used to give a systematic definition of for more general random variables .

All definitions of the expected value may be expressed in the language of measure theory. In general, if is a real-valued random variable defined on a probability space , then the expected value of , denoted by , is defined as the Lebesgue integral
Despite the newly abstract situation, this definition is extremely similar in nature to the very simplest definition of expected values, given above, as certain weighted averages. This is because, in measure theory, the value of the Lebesgue integral of is defined via weighted averages of "approximations" of which take on finitely many values. Moreover, if given a random variable with finitely or countably many possible values, the Lebesgue theory of expectation is identical with the summation formulas given above. However, the Lebesgue theory clarifies the scope of the theory of probability density functions. A random variable is said to be "absolutely continuous" if any of the following conditions are satisfied:
These conditions are all equivalent, although this is nontrivial to establish. In this definition, is called the "probability density function" of (relative to Lebesgue measure). According to the change-of-variables formula for Lebesgue integration, combined with the law of the unconscious statistician, it follows that
for any absolutely continuous random variable . The above discussion of continuous random variables is thus a special case of the general Lebesgue theory, due to the fact that every piecewise-continuous function is measurable.
The expected value of any real-valued random variable formula_5 can also be defined on the graph of its cumulative distribution function formula_26 by a nearby equality of areas. In fact, formula_27 with a real number formula_28 if and only if the two surfaces in the formula_29-formula_30-plane, described by
respectively, have the same finite area, i.e. if
and both improper Riemann integrals converge. Finally, this is equivalent to the representation
also with convergent integrals.

Expected values as defined above are automatically finite numbers. However, in many cases it is fundamental to be able to consider expected values of . This is intuitive, for example, in the case of the St. Petersburg paradox, in which one considers a random variable with possible outcomes , with associated probabilities , for ranging over all positive integers. According to the summation formula in the case of random variables with countably many outcomes, one has
formula_35
It is natural to say that the expected value equals .

There is a rigorous mathematical theory underlying such ideas, which is often taken as part of the definition of the Lebesgue integral. The first fundamental observation is that, whichever of the above definitions are followed, any "nonnegative" random variable whatsoever can be given an unambiguous expected value; whenever absolute convergence fails, then the expected value can be defined as . The second fundamental observation is that any random variable can be written as the difference of two nonnegative random variables. Given a random variable , one defines the positive and negative parts by and . These are nonnegative random variables, and it can be directly checked that . Since and are both then defined as either nonnegative numbers or , it is then natural to define:
formula_36

According to this definition, exists and is finite if and only if and are both finite. Due to the formula , this is the case if and only if is finite, and this is equivalent to the absolute convergence conditions in the definitions above. As such, the present considerations do not define finite expected values in any cases not previously considered; they are only useful for infinite expectations.

The following table gives the expected values of some commonly occurring probability distributions. The third column gives the expected values both in the form immediately given by the definition, as well as in the simplified form obtained by computation therefrom. The details of these computations, which are not always straightforward, can be found in the indicated references.
The basic properties below (and their names in bold) replicate or follow immediately from those of Lebesgue integral. Note that the letters "a.s." stand for "almost surely"—a central property of the Lebesgue integral. Basically, one says that an inequality like formula_37 is true almost surely, when the probability measure attributes zero-mass to the complementary event formula_38


Concentration inequalities control the likelihood of a random variable taking on large values. Markov's inequality is among the best-known and simplest to prove: for a "nonnegative" random variable and any positive number , it states that formula_85

If is any random variable with finite expectation, then Markov's inequality may be applied to the random variable to obtain Chebyshev's inequality formula_86
where is the variance. These inequalities are significant for their nearly complete lack of conditional assumptions. For example, for any random variable with finite expectation, the Chebyshev inequality implies that there is at least a 75% probability of an outcome being within two standard deviations of the expected value. However, in special cases the Markov and Chebyshev inequalities often give much weaker information than is otherwise available. For example, in the case of an unweighted die, Chebyshev's inequality says that odds of rolling between 1 and 6 is at least 53%; in reality, the odds are of course 100%. The Kolmogorov inequality extends the Chebyshev inequality to the context of sums of random variables.

The following three inequalities are of fundamental importance in the field of mathematical analysis and its applications to probability theory.
The Hölder and Minkowski inequalities can be extended to general measure spaces, and are often given in that context. By contrast, the Jensen inequality is special to the case of probability spaces.

In general, it is not the case that formula_91 even if formula_92 pointwise. Thus, one cannot interchange limits and expectation, without additional conditions on the random variables. To see this, let formula_93 be a random variable distributed uniformly on formula_94 For formula_95 define a sequence of random variables
with formula_97 being the indicator function of the event formula_98 Then, it follows that formula_99 pointwise. But, formula_100 for each formula_101 Hence, formula_102

Analogously, for general sequence of random variables formula_103 the expected value operator is not formula_104-additive, i.e.

An example is easily obtained by setting formula_106 and formula_107 for formula_108 where formula_109 is as in the previous example.

A number of convergence results specify exact conditions which allow one to interchange limits and expectations, as specified below.

The probability density function formula_134 of a scalar random variable formula_5 is related to its characteristic function formula_136 by the inversion formula:

For the expected value of formula_138 (where formula_139 is a Borel function), we can use this inversion formula to obtain

If formula_141 is finite, changing the order of integration, we get, in accordance with Fubini–Tonelli theorem,
where
is the Fourier transform of formula_144 The expression for formula_141 also follows directly from the Plancherel theorem.

The expectation of a random variable plays an important role in a variety of contexts.

In statistics, where one seeks estimates for unknown parameters based on available data gained from samples, the sample mean serves as an estimate for the expectation, and is itself a random variable. In such settings, the sample mean is considered to meet the desirable criterion for a "good" estimator in being unbiased; that is, the expected value of the estimate is equal to the true value of the underlying parameter. 

For a different example, in decision theory, an agent making an optimal choice in the context of incomplete information is often assumed to maximize the expected value of their utility function.

It is possible to construct an expected value equal to the probability of an event by taking the expectation of an indicator function that is one if the event has occurred and zero otherwise. This relationship can be used to translate properties of expected values into properties of probabilities, e.g. using the law of large numbers to justify estimating probabilities by frequencies.

The expected values of the powers of "X" are called the moments of "X"; the moments about the mean of "X" are expected values of powers of . The moments of some random variables can be used to specify their distributions, via their moment generating functions.

To empirically estimate the expected value of a random variable, one repeatedly measures observations of the variable and computes the arithmetic mean of the results. If the expected value exists, this procedure estimates the true expected value in an unbiased manner and has the property of minimizing the sum of the squares of the residuals (the sum of the squared differences between the observations and the estimate). The law of large numbers demonstrates (under fairly mild conditions) that, as the size of the sample gets larger, the variance of this estimate gets smaller.

This property is often exploited in a wide variety of applications, including general problems of statistical estimation and machine learning, to estimate (probabilistic) quantities of interest via Monte Carlo methods, since most quantities of interest can be written in terms of expectation, e.g. formula_146 where formula_147 is the indicator function of the set formula_148
In classical mechanics, the center of mass is an analogous concept to expectation. For example, suppose "X" is a discrete random variable with values "x" and corresponding probabilities "p." Now consider a weightless rod on which are placed weights, at locations "x" along the rod and having masses "p" (whose sum is one). The point at which the rod balances is E["X"].

Expected values can also be used to compute the variance, by means of the computational formula for the variance

A very important application of the expectation value is in the field of quantum mechanics. The expectation value of a quantum mechanical operator formula_150 operating on a quantum state vector formula_151 is written as formula_152 The uncertainty in formula_150 can be calculated by the formula formula_154.



Electric light

An electric light, lamp, or light bulb is an electrical component that produces light. It is the most common form of artificial lighting. Lamps usually have a base made of ceramic, metal, glass, or plastic, which secures the lamp in the socket of a light fixture, which is often called a "lamp" as well. The electrical connection to the socket may be made with a screw-thread base, two metal pins, two metal caps or a bayonet mount.

The three main categories of electric lights are incandescent lamps, which produce light by a filament heated white-hot by electric current, gas-discharge lamps, which produce light by means of an electric arc through a gas, such as fluorescent lamps, and LED lamps, which produce light by a flow of electrons across a band gap in a semiconductor.

The energy efficiency of electric lighting has increased radically since the first demonstration of arc lamps and the incandescent light bulb of the 19th century. Modern electric light sources come in a profusion of types and sizes adapted to many applications. Most modern electric lighting is powered by centrally generated electric power, but lighting may also be powered by mobile or standby electric generators or battery systems. Battery-powered light is often reserved for when and where stationary lights fail, often in the form of flashlights or electric lanterns, as well as in vehicles.

Before electric lighting became common in the early 20th century, people used candles, gas lights, oil lamps, and fires. In 1799–1800, Alessandro Volta created the voltaic pile, the first electric battery. Current from these batteries could heat copper wire to incandescence. Vasily Vladimirovich Petrov developed the first persistent electric arc in 1802, and English chemist Humphry Davy gave a practical demonstration of an arc light in 1806.

In 1840, Warren de la Rue enclosed a platinum coil in a vacuum tube and passed an electric current through it, thus creating one of the world's first electric light bulbs. The design was based on the concept that the high melting point of platinum would allow it to operate at high temperatures and that the evacuated chamber would contain fewer gas molecules to react with the platinum, improving its longevity. Although it was an efficient design, the cost of the platinum made it impractical for commercial use.

William Greener, an English inventor, made significant contributions to early electric lighting with his lamp in 1846 (patent specification 11076), laying the groundwork for future innovations such as Thomas Edison.

The late 1870s and 1880s were marked by intense competition and innovation, with inventors like Joseph Swan in the UK and Thomas Edison in the US independently developing functional incandescent lamps. Swan's bulbs, based on designs by William Staite, were successful, but the filaments were too thick. Edison worked to create bulbs with thinner filaments, leading to a better design. The rivalry between Swan and Edison eventually led to a merger, forming the Edison and Swan Electric Light Company. By the early twentieth century these had completely replaced arc lamps.

While the ability of wires to illuminate when supplied with current was first discovered during the Enlightenment, it took more than a century of continuous and incremental improvement, including numerous designs, patents, and resulting intellectual property disputes, until incandescent light bulbs became commercially available in the 1920s. The first home to be lit by an electric light was Underhill, the home of Joseph Swan, around 1880.

The turn of the century saw further improvements in bulb longevity and efficiency, notably with the introduction of the tungsten filament by William D. Coolidge, who applied for a patent in 1912. This innovation became a standard for incandescent bulbs for many years.

In 1910, Georges Claude introduced the first neon light, paving the way for neon signs which would become ubiquitous in advertising.

In 1934, Arthur Compton, a renowned physicist and GE consultant, reported to the GE lamp department on successful experiments with fluorescent lighting at General Electric Co., Ltd. in Great Britain (unrelated to General Electric in the United States). Stimulated by this report, and with all of the key elements available, a team led by George E. Inman built a prototype fluorescent lamp in 1934 at General Electric’s Nela Park (Ohio) engineering laboratory. This was not a trivial exercise; as noted by Arthur A. Bright, "A great deal of experimentation had to be done on lamp sizes and shapes, cathode construction, gas pressures of both argon and mercury vapor, colors of fluorescent powders, methods of attaching them to the inside of the tube, and other details of the lamp and its auxiliaries before the new device was ready for the public."

The first practical LED arrived in 1962.

In the United States, incandescent light bulbs including halogen bulbs stopped being sold as of August 1, 2023, because they do not meet minimum lumens per watt performance metrics established by the U.S. Department of Energy. Compact fluorescent bulbs are also banned despite their lumens per watt performance, because of their toxic mercury that can be released into the home if broken and widespread problems with proper disposal of mercury-containing bulbs.

In its modern form, the incandescent light bulb consists of a coiled filament of tungsten sealed in a globular glass chamber, either a vacuum or full of an inert gas such as argon. When an electric current is connected, the tungsten is heated to 2,000 to 3,300 K (1,730 to 3,030 °C; 3,140 to 5,480 °F) and glows, emitting light that approximates a continuous spectrum.

Incandescent bulbs are highly inefficient, in that just 2–5% of the energy consumed is emitted as visible, usable light. The remaining 95% is lost as heat. In warmer climates, the emitted heat must then be removed, putting additional pressure on ventilation or air conditioning systems. In colder weather, the heat byproduct has some value, and has been successfully harnessed for warming in devices such as heat lamps. Incandescent bulbs are nonetheless being phased out in favor of technologies like CFLs and LED bulbs in many countries due to their low energy efficiency. The European Commission estimated in 2012 that a complete ban on incandescent bulbs would contribute 5 to 10 billion euros to the economy and save 15 billion metric tonnes of carbon dioxide emissions.

Halogen lamps are usually much smaller than standard incandescent lamps, because for successful operation a bulb temperature over 200 °C is generally necessary. For this reason, most have a bulb of fused silica (quartz) or aluminosilicate glass. This is often sealed inside an additional layer of glass. The outer glass is a safety precaution, to reduce ultraviolet emission and to contain hot glass shards should the inner envelope explode during operation. Oily residue from fingerprints may cause a hot quartz envelope to shatter due to excessive heat buildup at the contamination site. The risk of burns or fire is also greater with bare bulbs, leading to their prohibition in some places, unless enclosed by the luminaire.

Those designed for 12- or 24-volt operation have compact filaments, useful for good optical control. Also, they have higher efficacies (lumens per watt) and longer lives than non-halogen types. The light output remains almost constant throughout their life.

Fluorescent lamps consist of a glass tube that contains mercury vapour or argon under low pressure. Electricity flowing through the tube causes the gases to give off ultraviolet energy. The inside of the tubes are coated with phosphors that give off visible light when struck by ultraviolet photons. They have much higher efficiency than incandescent lamps. For the same amount of light generated, they typically use around one-quarter to one-third the power of an incandescent. The typical luminous efficacy of fluorescent lighting systems is 50–100 lumens per watt, several times the efficacy of incandescent bulbs with comparable light output. Fluorescent lamp fixtures are more costly than incandescent lamps, because they require a ballast to regulate the current through the lamp, but the lower energy cost typically offsets the higher initial cost. Compact fluorescent lamps are available in the same popular sizes as incandescent lamps and are used as an energy-saving alternative in homes. Because they contain mercury, many fluorescent lamps are classified as hazardous waste. The United States Environmental Protection Agency recommends that fluorescent lamps be segregated from general waste for recycling or safe disposal, and some jurisdictions require recycling of them.

The solid-state light-emitting diode (LED) has been popular as an indicator light in consumer electronics and professional audio gear since the 1970s. In the 2000s, efficacy and output have risen to the point where LEDs are now being used in lighting applications such as car headlights and brake lights, in flashlights and bicycle lights, as well as in decorative applications, such as holiday lighting. Indicator LEDs are known for their extremely long life, up to 100,000 hours, but lighting LEDs are operated much less conservatively, and consequently have shorter lives. LED technology is useful for lighting designers, because of its low power consumption, low heat generation, instantaneous on/off control, and in the case of single color LEDs, continuity of color throughout the life of the diode and relatively low cost of manufacture. LED lifetime depends strongly on the temperature of the diode. Operating an LED lamp in conditions that increase the internal temperature can greatly shorten the lamp's life. Some lasers have been adapted as an alternative to LEDs to provide highly focused illumination.

Carbon arc lamps consist of two carbon rod electrodes in open air, supplied by a current-limiting ballast. The electric arc is struck by touching the rod tips then separating them. The ensuing arc produces a white-hot plasma between the rod tips. These lamps have higher efficacy than filament lamps, but the carbon rods are short-lived and require constant adjustment in use, as the intense heat of the arc erodes them. The lamps produce significant ultraviolet output, they require ventilation when used indoors, and due to their intensity they need protection from direct sight.

Invented by Humphry Davy around 1805, the carbon arc was the first practical electric light. It was used commercially beginning in the 1870s for large building and street lighting until it was superseded in the early 20th century by the incandescent light. Carbon arc lamps operate at high power and produce high intensity white light. They also are a point source of light. They remained in use in limited applications that required these properties, such as movie projectors, stage lighting, and searchlights, until after World War II.

A discharge lamp has a glass or silica envelope containing two metal electrodes separated by a gas. Gases used include, neon, argon, xenon, sodium, metal halides, and mercury. The core operating principle is much the same as the carbon arc lamp, but the term "arc lamp" normally refers to carbon arc lamps, with more modern types of gas discharge lamp normally called discharge lamps. With some discharge lamps, very high voltage is used to strike the arc. This requires an electrical circuit called an igniter, which is part of the electrical ballast circuitry. After the arc is struck, the internal resistance of the lamp drops to a low level, and the ballast limits the current to the operating current. Without a ballast, excess current would flow, causing rapid destruction of the lamp.

Some lamp types contain a small amount of neon, which permits striking at normal running voltage with no external ignition circuitry. Low-pressure sodium lamps operate this way. The simplest ballasts are just an inductor, and are chosen where cost is the deciding factor, such as street lighting. More advanced electronic ballasts may be designed to maintain constant light output over the life of the lamp, may drive the lamp with a square wave to maintain completely flicker-free output, and shut down in the event of certain faults.

The most efficient source of electric light is the low-pressure sodium lamp. It produces, for all practical purposes, a monochromatic orange-yellow light, which gives a similarly monochromatic perception of any illuminated scene. For this reason, it is generally reserved for outdoor public lighting applications. Low-pressure sodium lights are favoured for public lighting by astronomers, since the light pollution that they generate can be easily filtered, contrary to broadband or continuous spectra.

Many lamp units, or light bulbs, are specified in standardized shape codes and socket names. Incandescent bulbs and their retrofit replacements are often specified as "A19/A60 E26/E27", a common size for those kinds of light bulbs. In this example, the "A" parameters describe the bulb size and shape within the A-series light bulb while the "E" parameters describe the Edison screw base size and thread characteristics.

Common comparison parameters include:
Less common parameters include color rendering index (CRI).

Life expectancy for many types of lamp is defined as the number of hours of operation at which 50% of them fail, that is the median life of the lamps. Production tolerances as low as 1% can create a variance of 25% in lamp life, so in general some lamps will fail well before the rated life expectancy, and some will last much longer. For LEDs, lamp life is defined as the operation time at which 50% of lamps have experienced a 70% decrease in light output. In the 1900s the Phoebus cartel formed in an attempt to reduce the life of electric light bulbs, an example of planned obsolescence. 

Some types of lamp are also sensitive to switching cycles. Rooms with frequent switching, such as bathrooms, can expect much shorter lamp life than what is printed on the box. Compact fluorescent lamps are particularly sensitive to switching cycles.

The total amount of artificial light (especially from street light) is sufficient for cities to be easily visible at night from the air, and from space. External lighting grew at a rate of 3–6 percent for the later half of the 20th century and is the major source of light pollution that burdens astronomers and others with 80% of the world's population living in areas with night time light pollution. Light pollution has been shown to have a negative effect on some wildlife.

Electric lamps can be used as heat sources, for example in incubators, as infrared lamps in fast food restaurants and toys such as the Kenner Easy-Bake Oven.

Lamps can also be used for light therapy to deal with such issues as vitamin D deficiency, skin conditions such as acne and dermatitis, skin cancers, and seasonal affective disorder. Lamps which emit a specific frequency of blue light are also used to treat neonatal jaundice with the treatment which was initially undertaken in hospitals being able to be conducted at home.

Electric lamps can also be used as a grow light to aid in plant growth especially in indoor hydroponics and aquatic plants with recent research into the most effective types of light for plant growth.

Due to their nonlinear resistance characteristics, tungsten filament lamps have long been used as fast-acting thermistors in electronic circuits. Popular uses have included:

In Western culture, a lightbulb — in particular, the appearance of an illuminated lightbulb above a person's head — signifies sudden inspiration.

In the Middle East, a light bulb symbol has a sexual connotation.

A stylized depiction of a light bulb features as the logo of the Turkish AK Party.



Edgar Rice Burroughs

Edgar Rice Burroughs (September 1, 1875 – March 19, 1950) was an American writer, best known for his prolific output in the adventure, science fiction, and fantasy genres. Best known for creating the characters Tarzan and John Carter, he also wrote the "Pellucidar" series, the "Amtor" series, and the "Caspak" trilogy.

Tarzan was immediately popular, and Burroughs capitalized on it in every possible way, including a syndicated Tarzan comic strip, films, and merchandise. Tarzan remains one of the most successful fictional characters to this day and is a cultural icon. Burroughs's California ranch is now the center of the Tarzana neighborhood in Los Angeles, named after the character. Burroughs was an explicit supporter of eugenics and scientific racism in both his fiction and nonfiction; Tarzan was meant to reflect these concepts.

Burroughs was born on September 1, 1875, in Chicago (he later lived for many years in the suburb of Oak Park), the fourth son of Major George Tyler Burroughs, a businessman and Civil War veteran, and his wife, Mary Evaline (Zieger) Burroughs. His middle name is from his paternal grandmother, Mary Coleman Rice Burroughs.

Burroughs was of almost entirely English ancestry, with a family line that had been in North America since the Colonial era.

Through his Rice grandmother, Burroughs was descended from settler Edmund Rice, one of the English Puritans who moved to Massachusetts Bay Colony in the early 17th century. He once remarked: "I can trace my ancestry back to Deacon Edmund Rice."

The Burroughs side of the family was also of English origin, having emigrated to Massachusetts around the same time. Many of his ancestors fought in the American Revolution. Some of his ancestors settled in Virginia during the colonial period, and Burroughs often emphasized his connection with that side of his family, seeing it as romantic and warlike.

Burroughs was educated at a number of local schools. He then attended Phillips Academy, in Andover, Massachusetts, and then the Michigan Military Academy. Graduating in 1895, but failing the entrance exam for the United States Military Academy at West Point, he instead became an enlisted soldier with the 7th U.S. Cavalry in Fort Grant, Arizona Territory. After being diagnosed with a heart problem and thus ineligible to serve, he was discharged in 1897.

After his discharge, Burroughs worked at a number of different jobs. During the Chicago influenza epidemic of 1891, he spent half a year at his brother's ranch on the Raft River in Idaho, as a cowboy, drifted somewhat afterward, then worked at his father's Chicago battery factory in 1899, marrying his childhood sweetheart, Emma Hulbert (1876–1944), in January 1900.

In 1903, Burroughs joined his brothers, Yale graduates George and Harry, who were, by then, prominent Pocatello area ranchers in southern Idaho, and partners in the Sweetser-Burroughs Mining Company, where he took on managing their ill-fated Snake River gold dredge, a classic bucket-line dredge. The Burroughs brothers were also the sixth cousins, once removed, of famed miner Kate Rice who, in 1914, became the first female prospector in the Canadian North. Journalist and publisher C. Allen Thorndike Rice was also his third cousin.

When the new mine proved unsuccessful, the brothers secured for Burroughs a position with the Oregon Short Line Railroad in Salt Lake City. Burroughs resigned from the railroad in October 1904.

By 1911, around age 36, after seven years of low wages as a pencil-sharpener wholesaler, Burroughs began to write fiction. By this time, Emma and he had two children, Joan (1908–1972), and Hulbert (1909–1991). During this period, he had copious spare time and began reading pulp-fiction magazines. In 1929, he recalled thinking that:

In 1913, Burroughs and Emma had their third and last child, John Coleman Burroughs (1913–1979), later known for his illustrations of his father's books.

In the 1920s, Burroughs became a pilot, purchased a Security Airster S-1, and encouraged his family to learn to fly.

Daughter Joan married "Tarzan" film actor James Pierce. She starred with her husband as the voice of "Jane", during 1932–1934 for the "Tarzan" radio series.

Burroughs divorced Emma in 1934, and, in 1935, married the former actress Florence Gilbert Dearholt, who was the former wife of his friend (who was then himself remarrying), Ashton Dearholt, with whom he had co-founded Burroughs-Tarzan Enterprises while filming "The New Adventures of Tarzan". Burroughs adopted the Dearholts' two children. He and Florence divorced in 1942.

Burroughs was in his late 60s and was in Honolulu at the time of the Japanese attack on Pearl Harbor. Despite his age, he applied for and received permission to become a war correspondent, becoming one of the oldest U.S. war correspondents during World War II. This period of his life is mentioned in William Brinkley's bestselling novel "Don't Go Near the Water".

After the war ended, Burroughs moved back to Encino, California, where after many health problems, he died of a heart attack on March 19, 1950, having written almost 80 novels. He is buried in Tarzana, California, US.

At the time of his death he was believed to have been the writer who had made the most from films, earning over US$2 million in royalties from 27 Tarzan pictures.

The Science Fiction Hall of Fame inducted Burroughs in 2003.

Aiming his work at the pulps—under the name "Norman Bean" to protect his reputation—Burroughs had his first story, "Under the Moons of Mars", serialized by Frank Munsey in the February to July 1912 issues of "The All-Story". "Under the Moons of Mars" inaugurated the "Barsoom" series, introduced John Carter, and earned Burroughs ($11,922 today). It was first published as a book by A. C. McClurg of Chicago in 1917, entitled "A Princess of Mars", after three Barsoom sequels had appeared as serials and McClurg had published the first four serial Tarzan novels as books.

Burroughs soon took up writing full-time, and by the time the run of "Under the Moons of Mars" had finished, he had completed two novels, including "Tarzan of the Apes", published from October 1912 and one of his most successful series.

Burroughs also wrote popular science fiction and fantasy stories involving adventurers from Earth transported to various planets (notably Barsoom, Burroughs's fictional name for Mars, and Amtor, his fictional name for Venus), lost islands (Caspak), and into the interior of the Hollow Earth in his "Pellucidar" stories. He also wrote Westerns and historical romances. Besides those published in "All-Story", many of his stories were published in "The Argosy" magazine.

Tarzan was a cultural sensation when introduced. Burroughs was determined to capitalize on Tarzan's popularity in every way possible. He planned to exploit Tarzan through several different media including a syndicated Tarzan comic strip, movies, and merchandise. Experts in the field advised against this course of action, stating that the different media would just end up competing against each other. Burroughs went ahead, however, and proved the experts wrong – the public wanted Tarzan in whatever fashion he was offered. Tarzan remains one of the most successful fictional characters to this day and is a cultural icon.

In either 1915 or 1919, Burroughs purchased a large ranch north of Los Angeles, California, which he named "Tarzana". The citizens of the community that sprang up around the ranch voted to adopt that name when their community, Tarzana, California, was formed in 1927. Also, the unincorporated community of Tarzan, Texas, was formally named in 1927 when the US Postal Service accepted the name, reputedly coming from the popularity of the first (silent) "Tarzan of the Apes" film, starring Elmo Lincoln, and an early "Tarzan" comic strip.

In 1923, Burroughs set up his own company, Edgar Rice Burroughs, Inc., and began printing his own books through the 1930s.

Because of the part Burroughs's science fiction played in inspiring real exploration of Mars, an impact crater on Mars was named in his honor after his death. In a "Paris Review" interview, Ray Bradbury said of Burroughs: 

In "Something of Myself" (published posthumously in 1937) Rudyard Kipling wrote: "My "Jungle Books" begat Zoos of <nowiki>[imitators]</nowiki>. But the genius of all the genii was one who wrote a series called "Tarzan of the Apes". I read it, but regret I never saw it on the films, where it rages most successfully. He had 'jazzed' the motif of the "Jungle Books" and, I imagine, had thoroughly enjoyed himself. He was reported to have said that he wanted to find out how bad a book he could write and 'get away with', which is a legitimate ambition."

By 1963, Floyd C. Gale of "Galaxy Science Fiction" wrote when discussing reprints of several Burroughs novels by Ace Books, "an entire generation has grown up inexplicably Burroughs-less". He stated that most of the author's books had been out of print for years and that only the "occasional laughable Tarzan film" reminded public of his fiction. Gale reported his surprise that after two decades his books were again available, with Canaveral Press, Dover Publications, and Ballantine Books also reprinting them.

Few critical books have been written about Burroughs. From an academic standpoint, the most helpful are Erling Holtsmark's two books: "Tarzan and Tradition" and "Edgar Rice Burroughs"; Stan Galloway's "The Teenage Tarzan: A Literary Analysis of Edgar Rice Burroughs' "Jungle Tales of Tarzan; and Richard Lupoff's two books: "Master of Adventure: Edgar Rice Burroughs" and "Barsoom: Edgar Rice Burroughs and the Martian Vision". Galloway was identified by James Edwin Gunn as "one of the half-dozen finest Burroughs scholars in the world"; Galloway called Holtsmark his "most important predecessor".

Burroughs strongly supported eugenics and scientific racism. His views held that English nobles made up a particular heritable elite among Anglo-Saxons. Tarzan was meant to reflect this, with him being born to English nobles and then adopted by talking apes (the Mangani). They express eugenicist views themselves, but Tarzan is permitted to live despite being deemed "unfit" in comparison, and grows up to surpass not only them but black Africans, whom Burroughs clearly presents as inherently inferior, even not wholly human. In one Tarzan story, he finds an ancient civilization where eugenics has been practiced for over 2,000 years, with the result that it is free of all crime. Criminal behavior is held to be entirely hereditary, with the solution having been to kill not only criminals but also their families. "Lost on Venus", a later novel, presents a similar utopia where forced sterilization is practiced and the "unfit" are killed. Burroughs explicitly supported such ideas in his unpublished nonfiction essay "I See A New Race". Additionally, his "Pirate Blood", which is not speculative fiction and remained unpublished after his death, portrayed the characters as victims of their hereditary criminal traits (one a descendant of the corsair Jean Lafitte, another from the Jukes family). These views have been compared with Nazi eugenics (though noting that they were popular and common at the time), with his "Lost on Venus" being released the same year the Nazis took power (in 1933).

In 2003, Burroughs was inducted into the Science Fiction and Fantasy Hall of Fame.






These three texts have been published by various houses in one or two volumes. Adding to the confusion, some editions have the original (significantly longer) introduction to Part I from the first publication as a magazine serial, and others have the shorter version from the first book publication, which included all three parts under the title "The Moon Maid".












Eugène Viollet-le-Duc

Eugène Emmanuel Viollet-le-Duc (; 27 January 181417 September 1879) was a French architect and author, famous for his restoration of the most prominent medieval landmarks in France. His major restoration projects included Notre-Dame de Paris, the Basilica of Saint Denis, Mont Saint-Michel, Sainte-Chapelle, the medieval walls of the city of Carcassonne, and Roquetaillade castle in the Bordeaux region.

His writings on decoration and on the relationship between form and function in architecture had a fundamental influence on a whole new generation of architects, including all the major Art Nouveau artists: Antoni Gaudí, Victor Horta, Hector Guimard, Henry van de Velde, Henri Sauvage and the École de Nancy, Paul Hankar, Otto Wagner, Eugène Grasset, Émile Gallé, and Hendrik Petrus Berlage. He also influenced the first modern architects, Frank Lloyd Wright, Mies van der Rohe, Auguste Perret, Louis Sullivan, and Le Corbusier, who considered Viollet-le-Duc as the father of modern architecture. The English architect William Burges admitted in his late life "We all cribbed on Viollet-le-Duc even though no one could read French".

His writings also influenced John Ruskin, William Morris, and the Arts and Crafts movement. At the International Exhibition of 1862 in London, the aesthetic works of Edward Burne-Jones, Christina Rossetti, Philip Webb, William Morris, Simeon Solomon, and Edward Poynter were directly influenced from drawings in Viollet-le-Duc's Dictionary.

Viollet-le-Duc was born in Paris in 1814. His grandfather was an architect, and his father was a high-ranking civil servant, who in 1816 became the overseer of the royal residences of Louis XVIII. His uncle Étienne-Jean Delécluze was a painter, a former student of Jacques-Louis David, an art critic and hosted a literary salon, which was attended by Stendhal and Sainte-Beuve. His mother hosted her own salon, which women could attend as well as men. There, in 1822 or 1823, Eugène met Prosper Mérimée, a writer who would play a decisive role in his career.

In 1825 he began his education at the Pension Moran, in Fontenay-aux-Roses. He returned to Paris in 1829 as a student at the college de Bourbon (now the Lycée Condorcet). He passed his baccalaureate examination in 1830. His uncle urged him to enter the École des Beaux-Arts, which had been created in 1806, but the "École " had an extremely rigid system, based entirely on copying classical models, and Eugène was not interested. Instead he decided to get practical experience in the architectural offices of Jacques-Marie Huvé and Achille Leclère, while devoting much of his time to drawing medieval churches and monuments around Paris.

At sixteen he participated in the July 1830 revolution which overthrew Charles X, building a barricade. Following the revolution, which brought Louis Philippe to power, his father became chief of the bureau of royal residences. The new government created, for the first time, the position of Inspector General of Historic Monuments. Eugène's uncle Delécluze agreed to take Eugène on a long tour of France to see monuments. They travelled from July to October 1831 throughout the south of France, and he returned with a large collection of detailed paintings and watercolours of churches and monuments.

On his return to Paris, he moved with his family into the Tuileries Palace, where his father was now governor of royal residences. His family again urged him to attend the École des Beaux-Arts, but he still refused. He wrote in his journal in December 1831, "the "École" is just a mould for architects. they all come out practically identical." He was a talented and meticulous artist; he travelled around France to visit monuments, cathedrals, and other medieval architecture, made detailed drawings and watercolours. In 1834, at the age of twenty, he married Élisabeth Templier, and in the same year he was named an associate professor of ornamental decoration at the Royal School of Decorative Arts, which gave him a more regular income. His first pupils there included Léon Gaucherel.

With the money from the sale of his drawings and paintings, Viollet-le-Duc set off on a long tour of the monuments of Italy, visiting Rome, Venice, Florence and other sites, drawing and painting. In 1838, he presented several of his drawings at the Paris Salon, and began making a travel book, "Picturesque and romantic images of the old France", for which, between 1838 and 1844, he made nearly three hundred engravings.

In October 1838, with the recommendation of Achille Leclère, the architect with whom he had trained, he was named deputy inspector of the enlargement of the Hôtel Soubise, the new home of the French National Archives. His uncle, Delécluze, then recommended him to the new Commission of Historic Monuments of France, led by Prosper Mérimée, who had just published a book on medieval French monuments. Though he was just twenty-four years old and had no degree in architecture, he was asked to go to Narbonne to propose a plan for the completion of the cathedral there. The project was rejected by the local authorities as too ambitious and too expensive.

His first real project was a restoration of the Vézelay Abbey, which many considered as impossible. The church had been sacked by the Huguenots in 1569, and during the French Revolution, the facade and statuary on the facade were destroyed. The vaults of the roof were weakened, and many of the stones had been carried off for other projects. When Mérimée visited to inspect the structure he heard stones falling around him. In February 1840 he gave Viollet-le-Duc the mission of restoring and reconstructing the church so it would not collapse, while "respecting exactly in his project of restoration all the ancient dispositions of the church".

The task was all the more difficult because up until that time no scientific studies had been made of medieval building techniques, and there were no schools of restoration. He had no plans for the original building to work from. Viollet-le-Duc had to discover the flaws of construction that had caused the building to start to collapse in the first place and to construct a more solid and stable structure. He lightened the roof and built new arches to stabilize the structure, and slightly changed the shape of the vaults and arches. He was criticized for these modifications in the 1960s, though, as his defenders pointed out, without them the roof would have collapsed under its own weight. Mérimée's deputy, Lenormant, inspected the construction and reported to Mérimée: "The young Leduc seems entirely worthy of your confidence. He needed a magnificent audacity to take charge of such a desperate enterprise; it's certain that he arrived just in time, and if we had waited only ten years the church would have been a pile of stones." This restoration work lasted 19 years.

Viollet-le-Duc's success at Vezelay led to a large series of projects. In 1840, in collaboration with his friend the architect Jean-Baptiste Lassus he began the restoration of Sainte-Chapelle in Paris, which had been turned into a storage depot after the Revolution. In February 1843, King Louis Philippe sent him to the Château of Amboise, to restore the stained glass windows in the chapel holding the tomb of Leonardo da Vinci. The windows were unfortunately destroyed in 1940 during World War II.

In 1843, Mérimée took Viollet-le-Duc with him to Burgundy and the south of France, on one of his long inspection tours of monuments. Viollet-le-Duc made drawings of the buildings and wrote detailed accounts of each site, illustrated with his drawing, which were published in architectural journals. With his experience he became the most prominent academic scholar on French medieval architecture and his medieval dictionnary, with over 4000 drawings, contains the largest iconography on the subject to this day.

In 1844, with the backing of Mérimée, Viollet-le-Duc, just thirty years old, and Lassus, then thirty-seven, won a competition for the restoration of Notre-Dame Cathedral which lasted twenty-five years. Their project involved primarily the facade, where many of the statues over the portals had been beheaded or smashed during the Revolution. They proposed two major changes to the interior: rebuilding two of the bays to their original medieval height of four storeys, and removing the marble neoclassical structures and decoration which had been added to the choir during the reign of Louis XIV. Mérimée warned them to be careful: "In such a project, one cannot act with too much prudence or discretion...A restoration may be more disastrous for a monument than the ravages of centuries." The Commission on Historical Monuments approved most of Viollet-le-Duc's plans, but rejected his proposal to remove the choir built under Louis XIV. Viollet-le-Duc himself turned down a proposal to add two new spires atop the towers, arguing that such a monument "would be remarkable but would not be Notre-Dame de Paris". Instead, he proposed to rebuild the original medieval spire and bell tower over the transept, which had been removed in 1786 because it was unstable in the wind.

Once the project was approved, Viollet-le-Duc made drawings and photographs of the existing decorative elements; then they were removed and a stream of sculptors began making new statues of saints, gargoyles, chimeras and other architectural elements in a workshop he established, working from his drawings and photographs of similar works in other cathedrals of the same period. He also designed a new treasury in the Gothic style to serve as the museum of the cathedral, replacing the residence of the Archbishop, which had been destroyed in a riot in 1831.

The bells in the two towers had been taken out in 1791 and melted down to make cannons. Viollet-le-Duc had new bells cast for the north tower and a new structure built inside to support them. Viollet-le-Duc and Lassus also rebuilt the sacristy, on the south side of the church, which had been built in 1756, but had been burned by rioters during the July Revolution of 1830. The new spire was completed, taller and more strongly built to withstand the weather; it was decorated with statues of the apostles, and the face of Saint Thomas, patron saint of architects, bore a noticeable resemblance to Viollet-le-Duc. The spire was destroyed on 15 April 2019, as a result of the Notre-Dame de Paris fire.

When not engaged in Paris, Viollet-le-Duc continued his long tours into the French provinces, inspecting and checking the progress of more than twenty different restoration projects that were under his control, including seven in Burgundy alone. New projects included the Basilica of Saint-Sernin, Toulouse, and the Basilica of Saint-Denis just outside Paris. Saint-Denis had undergone a restoration by a different architect, Francois Debret, who had rebuilt one of the two towers. However, in 1846, the new tower, overloaded with masonry, began to crack, and Viollet-le-Duc was called in. He found no way the building could be saved and had to oversee the demolition of the tower, saving the stones. He concentrated on restoring the interior of the church, and was able to restore the original burial chamber of the kings of France.

In May 1849, he was named the architect for the restoration of Amiens Cathedral, one of the largest in France, which had been built over many centuries in a variety of different styles. He wrote, "his goal should be to save in each part of the monument its own character, and yet to make it so that the united parts don't conflict with each other; and that can be maintained in a state that is durable and simple."

The French coup d'état of 1851 brought Napoleon III to power and transformed France from a republic to an empire. The coup accelerated some of Viollet-le-Duc's projects as his patron Prosper Mérimée had introduced him to the new Emperor. He moved forward with the slow work of restoration of the Cathedral of Reims and Cathedral of Amiens. In Amiens, he cleared the interior of the French classical decoration added under Louis XIV, and proposed to make it resolutely Gothic. He gave the Emperor a tour of his project in September 1853; the Empress immediately offered to pay two-thirds of the cost of the restoration. In the same year he undertook the restoration of the Château de Vincennes, long occupied by the military, along with its chapel, similar to Sainte-Chapelle. A devotee of the pure Gothic, he described the chapel as "one of the finest specimens of Gothic in decline".

In November 1853, he provided the costs and plans for the medieval ramparts of Carcassonne which he had first begun planning in 1849. The first fortifications had been built by the Visigoths; on top of these, in the Middle Ages Louis XI and then Philip the Bold had built a formidable series of towers, galleries, walls, gates and interlocking defences that resisted all sieges until 1355. The fortifications were largely intact, since the surroundings of the city were still a military defensive zone in the 19th century, but the towers were without tops and a large number of structures had been built up against the old walls. Once he obtained funding and made his plans, he began demolishing all structures which had been added to the ramparts over the centuries, and restored the gates, walls and towers to their original form, including the defence platforms, roofs on the towers and shelters for archers that would have been used during a siege. He found many of the original mountings for weapons still in place. To accompany his work, he published a detailed history of the city and its fortifications, with his drawings. Carcassonne became the best example of medieval military architecture in France, and also an important tourist attraction.

Napoleon III provided additional funding for the continued restoration of Notre-Dame. Viollet-le-Duc was also to replace the great bestiary of mythical beasts and animals which had decorated the cathedral in the 18th century. In 1856, using examples from other medieval churches and debris from Notre-Dame as his model, his workshop produced dragons, chimeras, grotesques, and gargoyles, as well as an assortment of picturesque pinnacles and fleurons. He engaged in a new project for restoration of the Cathedral of Clermont-Ferrand, a project which continued for ten years. He also undertook an unusual project for Napoleon III; the design and construction of six railway coaches with neo-Gothic interior décor for the Emperor and his entourage. Two of the cars still exist; the salon of honour car, with a fresco on the ceiling, is at the Château de Compiègne, and the dining car, with a massive golden eagle as the centrepiece of the décor, is at the Railroad Museum of Mulhouse.

Napoleon III asked Viollet-le-Duc if he could restore a medieval chateau for the Emperor's own use near Compiègne, where the Emperor traditionally passed September and October. Viollet-le-Duc first studied a restoration of the Château de Coucy, which had the highest medieval tower in France. When this proved too complicated, he settled upon Château de Pierrefonds, a castle begun by Louis of Orleans in 1396, then dismantled in 1617 after several sieges by Louis XIII of France. Napoleon bought the ruin for 5000 francs in 1812, and Mérimée declared it an historic monument in 1848. In 1857 Viollet-le-Duc began designing an entirely new chateau on the ruins. This structure was not designed to recreate anything exactly that had existed, but a castle which recaptured the spirit of the Gothic, with lavish neo-Gothic decoration and 19th-century comforts. Pierrefonds and its inside decorations would not only influence William Burges and his Cardiff and Coch castles but also the castles of Ludwig II of Bavaria (Neuschwanstein Castle) and the Haut-Kœnigsbourg of the Emperor Wilhelm II.
----While most of his attention was devoted to restorations, Viollet-le-Duc designed and built a number of private residences and new buildings in Paris. He also participated in the most important competition of the period, for the new Paris Opera. There were one hundred seventy-one projects proposed in the original competition, presented the 1855 Paris Universal Exposition. A jury of noted architects narrowed it down to five, including projects from Viollet-le-Duc and Charles Garnier, age thirty-five. Viollet-le-Duc was finally eliminated and this put an end to Viollet le Duc's wish to construct public buildings.

Napoleon III also called upon Viollet-le-Duc for a wide variety of archeological and architectural tasks. When he wished to put up a monument to mark the Battle of Alesia, where Julius Caesar defeated the Gauls, a siege whose actual site was disputed by historians, he asked Viollet-le-Duc to locate the exact battlefield. Viollet-le-Duc conducted excavations at various purported sites, and finally found vestiges of the walls built at the time. He also designed the metal frame for the six-metre-high statue of the Gallic chief Vercingétorix that would be placed on the site. He later designed a similar frame for a much larger statue, the Statue of Liberty, but died before that statue was finished.

In 1863, Viollet-le-Duc was named a professor at the École des Beaux-Arts, the school where he had refused to become a student. In the fortress of neoclassical Beaux-Arts architecture there was much resistance against him, but he attracted two hundred students to his course, who applauded his lecture at the end. But while he had many supporters, the faculty professors and certain students campaigned against him. His critics complained that, aside from having little formal architectural training himself, he had only built a handful of new buildings. He tired of the confrontations and resigned on 16 May 1863, and continued his writing and teaching outside the Beaux-Arts. In response to the Beaux-Arts he initiated the creation of the École Spéciale d'Architecture in Paris in 1865.

In the beginning of 1864, he celebrated the conclusion of his most important project, the restoration of Notre-Dame. In January of the same year he completed the first phase of the restoration of the Cathedral of Saint Sernin in Toulouse, one of the landmarks of French Romanesque architecture. Napoleon III invited Viollet-le-Duc to study possible restorations overseas, including in Algeria, Corsica, and in Mexico, where Napoleon had installed a new Emperor, Maximilian, under French sponsorship. He also saw the consecration of the third church that he had designed, the neo-Gothic church of Saint-Denis de l'Estree, in the Paris suburb of Saint-Denis. Between 1866 and 1870, his major project was the ongoing transformation of Pierrefonds from a ruin into a royal residence. His plans for the metal framework he had designed for Pierrefonds were displayed at the Paris Universal Exposition of 1867. He also began a new area of study, researching the geology and geography of the region around Mont Blanc in the Alps. While on his mapping excursion in the Alps in July 1870, he learned that war had been declared between Prussia and France.

As the Franco-Prussian War commenced, Viollet-le-Duc hurried back to Paris, and offered his services as a military engineer; he was put into service as a colonel of engineers, preparing the defenses of Paris. In September, the Emperor was captured at the Battle of Sedan, a new Republican government took power, and the Empress Eugénie fled into exile, as Germans marched as far as Paris and put it under siege. At the same time, on September 23, Viollet-le-Duc's primary patron and supporter, Prosper Mérimée, died peacefully in the south of France. Viollet-le-Duc supervised the construction of new defensive works outside Paris. The war was a disaster as he wrote in his journal on the 14th December 1870: "Disorganization is everywhere. The officers have no confidence in the troops, and the troops have no confidence in the officers. Each day, new orders and new projects which contravene those of the day before." He fought with the French army against the Germans at Buzenval on 24 January 1871. The battle was lost, and the French capitulated on 28 January. Viollet-le-Duc wrote to his wife on February 28, "I don't know what will become of me, but I do not want to return any more to administration. I am disgusted by it forever, and want nothing more than to pass the years that remain to me in study and in the most modest possible life." Always the scholar, he wrote a detailed study of the effectiveness and deficiencies of the fortifications of Paris during the siege, which was to be used for the 1917 defense of Verdun and the construction of the Maginot line in 1938.

In May 1871 he left his home in Paris just before national guardsmen arrived to draft him into the armed force of the Paris Commune who subsequently condemned him to death. He escaped to Pierrefonds, where he had a small apartment before going in exile in Lausanne, where he engage in his passion for mountains, making detailed maps and a series of thirty-two drawings of the alpine scenery. While in Lausanne he was also asked to undertake the restoration of the cathedral.

He returned later to Paris after the Commune had been suppressed and saw the ruins of most of the public buildings of the city, burned by the Commune in its last days. He received his only commission from the new government of the French Third Republic; Jules Simon, the new Minister of Culture and Public Instruction, asked him to design a plaque to be placed before Notre-Dame to honor the hostages killed by the Paris Commune in its final days.

The new government of the French Third Republic made little use of his expertise in the restoration of the major government buildings which had been burned by the Paris Commune, including the Tuileries Palace, the Palace of the Legion of Honor, the Palais-Royal, the library of the Louvre, the Ministry of Justice and the Ministry of Finance. The only reconstruction on which he was consulted was that of the Hotel de Ville. The writer Edmond de Goncourt called for leaving the ruin of the Hotel de Ville exactly as it was, "a ruin of a magical palace, A marvel of the picturesque. The country should not condemn it without appeal to restoration by Viollet-le-Duc." The government asked Viollet-le-Duc to organize a competition. He presented two options; to either restore the building to its original state, with its historic interior; or to demolish it and build a new city hall. In July 1872 the government decided to preserve the Renaissance facade, but otherwise to completely demolish and rebuild the building.

Throughout his life Viollet le Duc wrote over 100 publications on architecture, decoration, history, archeology etc... some of which would become international best-sellers: "Dictionary of French Architecture from 11th to 16th Century" (1854–1868), "Entretiens sur l'architecture" (1863–1872), "L'histoire d'une Maison" (1873) and "Histoire d'un Dessinateur: Comment on Apprend à Dessiner" (1879).

In his "Entretiens sur l'architecture" he concentrated in particular on the use of iron and other new materials, and the importance of designing buildings whose architecture was adapted to their function, rather than to a particular style. The book was translated into English in 1881 and won a large following in the United States. The Chicago architect Louis Sullivan, one of the inventors of the skyscraper, often invoked the phrase, "Form follows function."

Lausanne Cathedral was his final major restoration project; it was rebuilt following his plans between 1873 and 1876. Work continued after his death. His reconstruction of the bell tower was later criticized; he eliminated the original octagonal base and added a new spire, which rested on the walls, and not on the vaulting, like the original spire. He also added new decoration, crowning the spire at mid-height with gables, another original element, and removing the original tiles. He was also criticized for the materials and ornaments he added to the towers, including gargoyles. His structural design was preserved, but in 1925 his gargoyles and original ornamentation were removed, and the spire was recovered with tiles.

His reputation had reached outside of France. The spire and roof of Strasbourg Cathedral had been damaged by German artillery during the Franco-Prussian War, and the city was now part of Germany. The German government invited Viollet-le-Duc to comment on their plans for the restoration, which involved a more grandiose Romanesque tower. Viollet-le-Duc informed the German architect that the planned new tower was completely out of character with the original facade and style of the cathedral. His advice was accepted, and the church was restored to its original form.

In 1872 Viollet-le-Duc was engaged in the reconstruction of the Château d'Amboise, owned by the descendants of the former King, Louis-Philippe. The chateau had been confiscated by Napoleon III in 1848 but was returned to the family in 1872. It was a massive project to turn it into a residence, involving at times three hundred workers. Viollet-le-Duc designed all the work to the finest details, including the floor tiles, the gas lights in the salons, the ovens in the kitchen, and the electric bells for summoning servants.

In 1874 Viollet-le-Duc resigned as diocesan architect of Paris and was succeeded by his contemporary, Paul Abadie. In his final years, he continued to supervise the restoration projects that were underway for the Commission of Historical Monuments. He engaged in polemics about architecture in the press, and was elected to the Paris municipal council.

While planning the design and construction of the Statue of Liberty ("Liberty Enlightening the World") sculptor Frédéric Auguste Bartholdi interested Viollet-le-Duc, his friend and mentor, in the project. As chief engineer, Viollet-le-Duc designed a brick pier within the statue, to which the skin would be anchored.
After consultations with the metalwork foundry Gaget, Gauthier & Co., Viollet-le-Duc chose the metal which would be used for the skin, copper sheets, and the method used to shape it, repoussé, in which the sheets were heated and then struck with wooden hammers. An advantage of this choice was that the entire statue would be light for its volume, as the copper need be only thick.

He became engaged in the planning and construction of the Paris Universal Exposition of 1878. He proposed to the Minister of Education, Jules Ferry, that the Trocadéro Palace, the main building of the Exposition on the hilltop of Chaillot, be transformed after the Exposition into a museum of French monuments, displaying models of architecture and sculpture from landmarks around France. This idea was accepted. The National Museum of French Monuments opened in 1882, after his death. The Palais was reconstructed into the Palais de Chaillot in 1937, but the Museum of French Monuments was preserved and can be seen there today.

In his final years his son Eugène-Louis became the head of the Commission of Historic Monuments. He took on just one new project, the restoration of the cloister of the Augustines at Toulouse. He completed his series of dictionaries of architectural periods, designed for a general audience. He also devoted more time to studying the geography of the Alps around Mont-Blanc. He spent his summers hiking in the mountains and writing articles about his travels. He launched a public campaign for the re-forestation of the Alps, and published a detailed map of the area in 1876. He spent more and more time at "La Vedette", the villa he constructed in Lausanne, a house on the model of a Savoyard chalet, but with a minimum of decoration, illustrating his new doctrine of form following function. He made one last visit to inspect Carcassonne, whose work was now under his son's direction. After an exhausting summer of hiking in the Alps in 1879, he became ill and died in Lausanne on 17 September 1879. He was buried in the cemetery of La Sallaz in Lausanne. In 1946 his grave and monument were transferred to the Cemetery of Bois-le-Vaux (Section XVIII) in Lausanne.

Viollet-le-Duc married Elisabeth Tempier in Paris on 3 May 1834. The couple had two children, but separated a few years after marriage, and spent little time together; he was continually on the road. The writer Geneviève Viollet-le-Duc (winner of the prix Broquette-Gonin in 1978) was his great-granddaughter.

Viollet-le-Duc famously defined restoration in volume eight of his "Dictionnaire raisonné de l'architecture française du XI au XVI siecle" of 1858: "To restore a building is not to maintain it, repair it or remake it: it is to re-establish it in a complete state which may never have existed at any given moment." He then explained that it had to meet four conditions: (1) The "re-establishment" had to be scientifically documented with plans and photographs and archeological records, which would guarantee exactness. (2) The restoration had to involve not just the appearance of the monument, or the effect that it produced, but also its structure; it had to use the most efficient means to assure the long life of the building, including using more solid materials, used more wisely. (3) the restoration had to exclude any modification contrary to obvious evidence; but the structure could be adapted to conform to more modern or rational uses and practices, which meant alterations to the original plan; and (4) The restoration should preserve older modifications made to the building, with the exception of those which compromised its stability or its conservation, or those which gravely violated the value of its historical presence.

He drew conclusions from medieval architecture that he applied to modern architecture. He noted that it was sometimes necessary to employ an iron frame in restoration to avoid the danger of fires, as long as the new structure was not heavier than the original, and kept the original balance of forces found in medieval structures. "The monuments of the Middle Ages were carefully calculated, and their organism is delicate. There is nothing in excess in their works, nothing useless. If you change one of the conditions of these organisms, you change all the others. Many people consider this a fault; for us, this is a quality which we too often neglect in our modern construction...Why should we build expensive walls two meters thick, if walls fifty centimeters thick [with reinforced supports], offer sufficient stability? In the structure of the Middle Ages, every portion of a work fulfilled a function and possessed an action."

During the entire career of Viollet-le-Duc, he was engaged in a dispute with the doctrines of the École des Beaux-Arts, the leading architectural school of France, which he refused to attend as a student, and where he taught briefly as a professor, before being pressured to depart. In 1846 he engaged in a fervent exchange in print with Quatremère de Quincy, the Perpetual Secretary of the French Academy, on the question, "Is it suitable, in the 19th century, to build churches in the Gothic style?" De Quincy and his followers denounced the Gothic style as incoherent, disorderly, unintelligent, decadent and without taste. Viollet-le-Duc responded, "What we want, "messieurs", is the return of an art which was born in our country...Leave to Rome what belongs to Rome, and to Athens what belongs to Athens. Rome didn't want our Gothic (and was perhaps the only one in Europe to reject it) and they were right, because when one has the good fortune to possess a national architecture, the best thing is to keep it."

"If you study for a moment a church of the 13th century", he wrote, "you see that all of the construction is carried out according to an invariable system. All the forces and the weights are thrust out to the exterior, a disposition which gives the interior the greatest open space possible. The flying buttresses and contreforts alone support the entire structure, and always have an aspect of resistance, of force and stability which reassures the eye and the spirit; The vaults, built with materials that are easy to mount and to place at a great height, are combined in a easy that places the totality of their weight on the piles; that the most simple means are always employed...and that all the parts of these constructions, independent of each other, even as they rely on each other, present an elasticity and a lightness needed in a building of such great dimensions. We can still see (and this is only found in Gothic architecture) that human proportions are the one fixed rule."

Viollet-le-Duc was often accused by certain critics, in his own time and later, of pursuing the spirit of the Gothic style in some of his restorations instead of strict historical accuracy. Many art historians also consider that the British architectural writer John Ruskin and William Morris were ferocious opponents of Viollet le Duc’s restorations. But Ruskin never criticised Viollet le Duc’s restoration work in itself, but criticised the principal of restoration itself. Indeed at the beginning of his career Ruskin had a very radical opinion on restoration: "a building should be looked after and if not it should be left to die". Viollet le Duc's position on the subject was more nuanced: "if a building has not been upkept it should be restored".

The existence of an opposition between Ruskin and Viollet le Duc on restoration is today questioned by new research based on Ruskin's own writtings: "there is no book on architecture which has everything correct apart from Viollet le Duc’s Dictionnary". And at the end of his life Ruskin expressed the regret that "no one in England had done the work that Viollet le Duc had done in France".

Viollet-le-Duc's restorations sometimes involved non-historical additions, either to assure the stability of the building, or sometimes simply to maintain the harmony of the design. The flèche or spire of Notre-Dame de Paris, which had been constructed in about 1250, was removed in 1786 after it was damaged by the wind. Viollet-le-Duc designed and constructed a new spire, ornamented with statuary, which was taller than the original and modified to resist the weather, but in harmony with the rest of the design. In the 19th and 20th century, his flèche was a target for critics.

He was also criticized later for his modifications of the choir of Notre-Dame, which had been rebuilt in the Louis XIV style during the reign of that king. Viollet-le-Duc took out the old choir, including the altar where Napoleon Bonaparte had been crowned Emperor and replaced them with a Gothic altar and decoration which he designed. When he modified the choir, he also constructed new bays with small Gothic rose windows modelled on those in the church of Chars, in the Oise Valley. Some historians condemned these restorations as non-historical invention. His defenders pointed out that Viollet-le-Duc did not make any decisions on the restoration of Notre-Dame by himself; all of his plans were approved by Prosper Mérimée, the Inspector of Historical Monuments, and by the Commission of historic monuments.

He was criticized for the abundance of Gothic gargoyles, chimeras, fleurons, and pinnacles which he added to Notre-Dame Cathedral. These decorations had existed in the Middle Ages but had largely been removed during the reign of Louis XIV. The last original gargoyles had been taken down in 1813. He modelled the new gargoyles and monsters on examples from other cathedrals of the period.

He was later criticized also for the stained glass windows he designed and had made for the chapels around the ground level of the cathedral, which feature intricate Gothic designs in grisaille, which allow more light into the church. The contemporary view of the controversy of his restoration is summarized on a descriptive panel near the altar of the cathedral: "The great restoration, carried to fruition by Viollet-le-Duc following the death of Lassus, supplied new radiance to the cathedral – whatever reservations one might have about the choices that were made. The work of the nineteenth century is now as much a part of the architectural history of Notre-Dame as that undertaken in previous centuries."

The restoration of ramparts of Carcassonne was also criticized in the 20th century. His critics pointed out that the pointed caps of the towers he constructed were more typical of northern France, not the region where Carcassonne was located, near the Spanish border. Similarly he added roofs of northern slate tiles rather than southern clay tiles, a choice that has been reversed in more recent restorations. His critics also claimed that Viollet-le-Duc sought a "condition of completeness" which never actually existed at any given time.
The principal counter-argument made by Viollet-le-Duc's defenders was that, without his prompt restorations, many of the buildings that he restored would have been lost, and that he did the best that he could with the knowledge that was then available.

Mortimer Wheeler's entry on English archaeologist Charles R Peers for the Dictionary of National Biography (1971) is worth quoting for its critique of Viollet-le-Duc:
“he [Peers] laid down the principles which have governed architectural conservation in the United Kingdom and have served as a model in other parts of the world. His cardinal principle was to retain but not to restore the surviving remains of an ancient structure; and in this respect he departed emphatically from the tradition of Viollet-le-Duc and his successors in France and Italy, where exuberant restoration frequently obscured the evidence upon which it was based ...”




Throughout his career Viollet-le-Duc made notes and drawings, not only for the buildings he was working on but also on Romanesque, Gothic and Renaissance buildings that were to be soon demolished. His notes were useful when preparing his published works. His study of medieval and Renaissance periods was not limited to architecture but extended also to such areas as furniture, clothing, musical instruments, armament, and geology.

His work was published, first in serial form, and then as full-scale books, as:


Viollet-le-Duc is considered by many to be the first theorist of modern architecture. Sir John Summerson wrote that "there have been two supremely eminent theorists in the history of European architecture – Leon Battista Alberti and Eugène Viollet-le-Duc."

His architectural theory was largely based on finding the ideal forms for specific materials and using these forms to create buildings. His writings centered on the idea that materials should be used "honestly". He believed that the outward appearance of a building should reflect the rational construction of the building. In "Entretiens sur l'architecture", Viollet-le-Duc praised the Greek temple for its rational representation of its construction. For him, "Greek architecture served as a model for the correspondence of structure and appearance."

Another component in Viollet-le-Duc's theory was how the design of a building should start from its program and the plan, and end with its decorations. If this resulted in an asymmetrical exterior, so be it. He dismissed the symmetry of classicist buildings as vain, caring too much about appearances at the expense of practicality and convenience for the inhabitants of the house.

In several unbuilt projects for new buildings, Viollet-le-Duc applied the lessons he had derived from Gothic architecture, applying its rational structural systems to modern building materials such as cast iron. For inspiration, he also examined organic structures, such as leaves and animal skeletons. He was especially interested in the wings of bats, an influence represented by his Assembly Hall project.

Viollet-le-Duc's drawings of iron trusswork were innovative for the time. Many of his designs emphasizing iron would later influence the Art Nouveau movement, most noticeably in the work of Hector Guimard, Victor Horta, Antoni Gaudí and Hendrik Petrus Berlage. His writings inspired several American architects, including Frank Furness, John Wellborn Root, Louis Sullivan, and Frank Lloyd Wright.

Viollet-le-Duc had a second career in the military, primarily in the defense of Paris during the Franco-Prussian War (1870–71). He was so influenced by the conflict that during his later years he described the idealized defense of France by the analogy of the military history of Le Roche-Pont, an imaginary castle, in his work "Histoire d'une Forteresse" ("Annals of a Fortress", twice translated into English). Accessible and well researched, it is partly fictional.

"Annals of a Fortress" strongly influenced French military defensive thinking. Viollet-le-Duc's critique of the effect of artillery (applying his practical knowledge from the 1870–1871 war) is so complete that it accurately describes the principles applied to the defense of France until World War II. The physical results of his theories are present in the fortification of Verdun prior to World War I and the Maginot Line prior to World War II. His theories are also represented by the French military theory of "Deliberate Advance", which stresses that artillery and a strong system of fortresses in the rear of an army are essential.

The English architect Benjamin Bucknall (1833–1895) was a devotee of Viollet-le-Duc and during 1874 to 1881 translated several of his publications into English to popularise his principles in Great Britain. The later works of the English designer and architect William Burges were greatly influenced by Viollet-le-Duc, most strongly in Burges's designs for his own home, The Tower House in London's Holland Park district, and Burges's designs for Castell Coch near Cardiff, Wales.

An exhibition, "Eugène Viollet-le-Duc 1814–1879" was presented in Paris in 1965, and there was a larger, centennial exhibition in 1980.

Viollet-le-Duc was the subject of a Google Doodle on January 27, 2014.





Endocarditis

Endocarditis is an inflammation of the inner layer of the heart, the endocardium. It usually involves the heart valves. Other structures that may be involved include the interventricular septum, the chordae tendineae, the mural endocardium, or the surfaces of intracardiac devices. Endocarditis is characterized by lesions, known as "vegetations", which are masses of platelets, fibrin, microcolonies of microorganisms, and scant inflammatory cells. In the subacute form of infective endocarditis, a vegetation may also include a center of granulomatous tissue, which may fibrose or calcify.

There are several ways to classify endocarditis. The simplest classification is based on cause: either "infective" or "non-infective", depending on whether a microorganism is the source of the inflammation or not. Regardless, the diagnosis of endocarditis is based on clinical features, investigations such as an echocardiogram, and blood cultures demonstrating the presence of endocarditis-causing microorganisms.

Signs and symptoms include fever, chills, sweating, malaise, weakness, anorexia, weight loss, splenomegaly, flu-like feeling, cardiac murmur, heart failure, petechia (red spots on the skin), Osler's nodes (subcutaneous nodules found on hands and feet), Janeway lesions (nodular lesions on palms and soles), and Roth's spots (retinal hemorrhages).

Infective endocarditis is an infection of the inner surface of the heart, usually the valves. Symptoms may include fever, small areas of bleeding into the skin, heart murmur, feeling tired, and low red blood cells. Complications may include valvular insufficiency, heart failure, stroke, and kidney failure.
The cause is typically a bacterial infection and less commonly a fungal infection. Risk factors include valvular heart disease including rheumatic disease, congenital heart disease, artificial valves, hemodialysis, intravenous drug use, and electronic pacemakers. The bacterial most commonly involved are streptococci or staphylococci.

The diagnosis of infective endocarditis relies on the Duke criteria, which were originally described in 1994 and modified in 2000. Clinical features and microbiological examinations are the first steps to diagnose an infective endocarditis. The imaging is also crucial. Echocardiography is the cornerstone of imaging modality in the diagnosis of infective endocarditis. Alternative imaging modalities as computer tomography, magnetic resonance imaging, and positron emission tomography/computer tomography (PET/CT) with 2-[18F]fluorodeoxyglucose (FDG) are playing an increasing role in the diagnosis and management of infective endocarditis.
The usefulness of antibiotics following dental procedures has changed over time. Prevention is recommended in patients at high risk. Treatment is generally with intravenous antibiotics. The choice of antibiotics is based on the blood cultures. Occasionally heart surgery is required. Populations at high risk of infective endocarditis include patients with previous infective endocarditis, patients with surgical or transcatheter prosthetic valves or post-cardiac valve repair, and patients with untreated CHD and surgically corrected congenital heart disease.
The number of people affected is about 5 per 100,000 per year. Rates, however, vary between regions of the world. Males are affected more often than females. The risk of death among those infected is about 25%. Without treatment it is almost universally fatal.

Nonbacterial thrombotic endocarditis (NBTE) is most commonly found on previously undamaged valves. As opposed to infective endocarditis, the vegetations in NBTE are small, sterile, and tend to aggregate along the edges of the valve or the cusps. Also unlike infective endocarditis, NBTE does not cause an inflammation response from the body. NBTE usually occurs during a hypercoagulable state such as system-wide bacterial infection, or pregnancy, though it is also sometimes seen in patients with venous catheters. NBTE may also occur in patients with cancer, particularly mucinous adenocarcinoma where Trousseau syndrome can be encountered. Typically NBTE does not cause many problems on its own, but parts of the vegetations may break off and embolize to the heart or brain, or they may serve as a focus where bacteria can lodge, thus causing infective endocarditis.

Another form of sterile endocarditis is termed Libman–Sacks endocarditis; this form occurs more often in patients with lupus erythematosus and is thought to be due to the deposition of immune complexes. Like NBTE, Libman-Sacks endocarditis involves small vegetations, while infective endocarditis is composed of large vegetations. These immune complexes precipitate an inflammation reaction, which helps to differentiate it from NBTE. Also unlike NBTE, Libman-Sacks endocarditis does not seem to have a preferred location of deposition and may form on the undersurfaces of the valves or even on the endocardium.


Euler's sum of powers conjecture

In number theory, Euler's conjecture is a disproved conjecture related to Fermat's Last Theorem. It was proposed by Leonhard Euler in 1769. It states that for all integers and greater than 1, if the sum of many th powers of positive integers is itself a th power, then is greater than or equal to :

formula_1

The conjecture represents an attempt to generalize Fermat's Last Theorem, which is the special case : if formula_2 then .

Although the conjecture holds for the case (which follows from Fermat's Last Theorem for the third powers), it was disproved for and . It is unknown whether the conjecture fails or holds for any value .

Euler was aware of the equality involving sums of four fourth powers; this, however, is not a counterexample because no term is isolated on one side of the equation. He also provided a complete solution to the four cubes problem as in Plato's number or the taxicab number 1729. The general solution of the equation formula_3
is

formula_4

where and are any integers.

Euler's conjecture was disproven by L. J. Lander and T. R. Parkin in 1966 when, through a direct computer search on a CDC 6600, they found a counterexample for . This was published in a paper comprising just two sentences. A total of three primitive (that is, in which the summands do not all have a common factor) counterexamples are known:
formula_5
(Lander & Parkin, 1966); (Scher & Seidl, 1996); (Frye, 2004).

In 1988, Noam Elkies published a method to construct an infinite sequence of counterexamples for the case. His smallest counterexample was
formula_6

A particular case of Elkies' solutions can be reduced to the identity
formula_7
where
formula_8
This is an elliptic curve with a rational point at . From this initial rational point, one can compute an infinite collection of others. Substituting into the identity and removing common factors gives the numerical example cited above.

In 1988, Roger Frye found the smallest possible counterexample 
formula_9
for by a direct computer search using techniques suggested by Elkies. This solution is the only one with values of the variables below 1,000,000.

In 1967, L. J. Lander, T. R. Parkin, and John Selfridge conjectured that if 
where are positive integers for all and , then . In the special case , the conjecture states that if
(under the conditions given above) then .

The special case may be described as the problem of giving a partition of a perfect power into few like powers. For and or , there are many known solutions. Some of these are listed below. 

See for more data.

formula_12

formula_13

formula_14
(R. Frye, 1988); (R. Norrie, smallest, 1911).
formula_15

(Lander & Parkin, 1966); (Lander, Parkin, Selfridge, smallest, 1967); (Lander, Parkin, Selfridge, second smallest, 1967); (Sastry, 1934, third smallest).
As of 2002, there are no solutions for whose final term is ≤ 730000. 
formula_16

(M. Dodrill, 1999).
formula_17

(S. Chase, 2000).



Book of Exodus

The Book of Exodus (from ; "Šəmōṯ", 'Names'; ) is the second book of the Bible. It is a narrative of the Exodus, the origin myth of the Israelites leaving slavery in Biblical Egypt through the strength of their deity named Yahweh, who according to the story chose them as his people. The Israelites then journey with the legendary prophet Moses to Mount Sinai, where Yahweh gives the 10 commandments and they enter into a covenant with Yahweh, who promises to make them a "holy nation, and a kingdom of priests" on condition of their faithfulness. He gives them their laws and instructions to build the Tabernacle, the means by which he will come from heaven and dwell with them and lead them in a holy war to conquer Canaan (the "Promised Land"), which has earlier, according to the myth of Genesis, been promised to the "seed" of Abraham, the legendary patriarch of the Israelites.

Traditionally ascribed to Moses himself, modern scholars see its initial composition as a product of the Babylonian exile (6th century BCE), based on earlier written sources and oral traditions, with final revisions in the Persian post-exilic period (5th century BCE). American biblical scholar Carol Meyers, in her commentary on Exodus, suggests that it is arguably the most important book in the Bible, as it presents the defining features of Israel's identity—memories of a past marked by hardship and escape, a binding covenant with their God, who chooses Israel, and the establishment of the life of the community and the guidelines for sustaining it. The consensus of modern scholars is that the Pentateuch does not give an accurate account of the origins of the Israelites, who appear instead to have formed as an entity in the central highlands of Canaan in the late second millennium BCE (around the time of the Late Bronze Age collapse) from the indigenous Canaanite culture.

The English name "Exodus" comes from the , from and . In Hebrew the book's title is שְׁמוֹת, "shemōt", "Names", from the beginning words of the text: "These are the names of the sons of Israel" ().

Most mainstream scholars do not accept the biblical Exodus account as historical for a number of reasons. It is generally agreed that the Exodus stories were written centuries after the apparent setting of the stories. Archaeologists Israel Finkelstein and Neil Asher Silberman argue that archaeology has not found evidence for even a small band of wandering Israelites living in the Sinai: "The conclusion – that Exodus did not happen at the time and in the manner described in the Bible – seems irrefutable [...] repeated excavations and surveys throughout the entire area have not provided even the slightest evidence". Instead, they argue how modern archaeology suggests continuity between Canaanite and Israelite settlements, indicating a heavily Canaanite origin for Israel, with little suggestion that a group of foreigners from Egypt comprised early Israel.

However, a majority of scholars believe that the story has some historical basis, though disagreeing widely about what that historical kernel might have been. Kenton Sparks refers to it as "mythologized history". However, there is an increasing trend among scholars to see the biblical exodus traditions as the invention of the exilic and post-exilic Jewish community, with little to no historical basis.

There is no unanimous agreement among scholars on the structure of Exodus. One strong possibility is that it is a diptych (i.e., divided into two parts), with the division between parts 1 and 2 at the crossing of the Red Sea or at the beginning of the theophany (appearance of God) in chapter 19. On this plan, the first part tells of God's rescue of his people from Egypt and their journey under his care to Sinai (chapters 1–19) and the second tells of the covenant between them (chapters 20–40).

The text of the Book of Exodus begins after the events at the end of the Book of Genesis where Jacob's sons and their families joined their brother Joseph in Egypt, which Joseph had saved from famine. It is 400 years later and Egypt's new Pharaoh, who does not remember Joseph, is fearful that the enslaved and now numerous Israelites could become a fifth column. He hardens their labor and orders the killing of all newborn boys. A Levite woman named Jochebed saves her baby by setting him adrift on the Nile in an ark of bulrushes. Pharaoh's daughter finds the child, names him Moses, and brings him up as her own.
Later, a grown Moses goes out to see his kinsmen. He witnesses the abuse of a Hebrew slave by an Egyptian overseer. Angered, Moses kills him and flees into Midian to escape punishment. There, he marries Zipporah, daughter of Jethro, a Midianite priest. While tending Jethro's flock, Moses encounters God in a burning bush. Moses asks God for his name, to which God replies with three words, often translated as "I Am that I Am." This is the book's explanation for the origin of the name Yahweh, as God is thereafter known. God tells Moses to return to Egypt, free the Hebrews from slavery and lead them into Canaan, the land promised to the seed of Abraham in Genesis. On the journey back to Egypt, God seeks to kill Moses. Zipporah circumcises their son and the attack stops. "(See Zipporah at the inn.)"

Moses reunites with his brother Aaron and, returning to Egypt, convenes the Israelite elders, preparing them to go into the wilderness to worship God. Pharaoh refuses to release the Israelites from their work for the festival, and so God curses the Egyptians with ten terrible plagues, such as a , an outbreak of frogs, and the . Moses is commanded by God to fix the spring month of Aviv at the head of the Hebrew calendar. The Israelites are to take a lamb on the 10th day of the month, sacrifice the lamb on the 14th day, daub its blood on their mezuzot—doorposts and lintels, and to observe the Passover meal that night, during the full moon. The 10th plague comes that night, causing the death of all Egyptian firstborn sons, prompting Pharaoh to expel the Israelites. Regretting his decision, Pharaoh commands his chariot army after the Israelites, who appear trapped at the Red Sea. God parts the sea, allowing the Israelites to pass through, before drowning Pharaoh's pursuing forces.
As desert life proves arduous, the Israelites complain and long for Egypt, but God miraculously provides manna for them to eat and water to drink. The Israelites arrive at the mountain of God, where Moses's father-in-law Jethro visits Moses; at his suggestion, Moses appoints judges over Israel. God asks whether they will agree to be his people – They accept. The people gather at the foot of the mountain, and with thunder and lightning, fire and clouds of smoke, the sound of trumpets, and the trembling of the mountain, God appears on the peak, and the people see the cloud and hear the voice (or possibly sound) of God. God tells Moses to ascend the mountain. God pronounces the Ten Commandments (the Ethical Decalogue) in the hearing of all Israel. Moses goes up the mountain into the presence of God, who pronounces the Covenant Code of ritual and civil law and promises Canaan to them if they obey. Moses comes down from the mountain and writes down God's words, and the people agree to keep them. God calls Moses up the mountain again, where he remains for forty days and forty nights, after which he returns, bearing the set of stone tablets.

God gives Moses instructions for the construction of the tabernacle so that God may dwell permanently among his chosen people, along with instructions for the priestly vestments, the altar and its appurtenances, procedures for the ordination of priests, and the daily sacrifice offerings. Aaron becomes the first hereditary high priest. God gives Moses the two tablets of stone containing the words of the ten commandments, written with the "finger of God".
While Moses is with God, Aaron casts a golden calf, which the people worship. God informs Moses of their apostasy and threatens to kill them all, but relents when Moses pleads for them. Moses comes down from the mountain, smashes the stone tablets in anger, and commands the Levites to massacre the unfaithful Israelites. God commands Moses to construct two new tablets. Moses ascends the mountain again, where God dictates the Ten Commandments for Moses to write on the tablets.

Moses descends from the mountain with a transformed face; from that time onwards he must hide his face with a veil. Moses assembles the Hebrews and repeats to them the commandments he has received from God, which are to keep the Sabbath and to construct the Tabernacle. The Israelites do as they are commanded. From that time God dwells in the Tabernacle and orders the travels of the Hebrews.

Jewish and Christian tradition viewed Moses as the author of Exodus and the entire Torah, but by the end of the 19th century the increasing awareness of discrepancies, inconsistencies, repetitions and other features of the Pentateuch had led scholars to abandon this idea. In approximate round dates, the process which produced Exodus and the Pentateuch probably began around 600 BCE when existing oral and written traditions were brought together to form books recognizable as those we know, reaching their final form as unchangeable sacred texts around 400 BCE.

Although patent mythical elements are not so prominent in Exodus as in Genesis, ancient legends may have an influence on the book's form or content: for example, the story of the infant Moses's salvation from the Nile is argued to be based on an earlier legend of king Sargon of Akkad, while the story of the parting of the Red Sea may trade on Mesopotamian creation mythology. Similarly, the Covenant Code (the law code in Exodus 20:22–23:33) has some similarities in both content and structure with the Laws of Hammurabi. These potential influences serve to reinforce the conclusion that the Book of Exodus originated in the exiled Jewish community of 6th-century BCE Babylon, but not all the potential sources are Mesopotamian: the story of Moses's flight to Midian following the murder of the Egyptian overseer may draw on the Egyptian "Story of Sinuhe".

Biblical scholars describe the Bible's theologically-motivated history writing as "salvation history", meaning a history of God's saving actions that give identity to Israel – the promise of offspring and land to the ancestors, the Exodus from Egypt (in which God saves Israel from slavery), the wilderness wandering, the revelation at Sinai, and the hope for the future life in the promised land.

A theophany is a manifestation (appearance) of a god – in the Bible, an appearance of the God of Israel, accompanied by storms – the earth trembles, the mountains quake, the heavens pour rain, thunder peals and lightning flashes. The theophany in Exodus begins "the third day" from their arrival at Sinai in chapter 19: Yahweh and the people meet at the mountain, God appears in the storm and converses with Moses, giving him the Ten Commandments while the people listen. The theophany is therefore a public experience of divine law.

The second half of Exodus marks the point at which, and describes the process through which, God's theophany becomes a permanent presence for Israel via the Tabernacle. That so much of the book (chapters 25–31, 35–40) describes the plans of the Tabernacle demonstrates the importance it played in the perception of Second Temple Judaism at the time of the text's redaction by the Priestly writers: the Tabernacle is the place where God is physically present, where, through the priesthood, Israel could be in direct, literal communion with him.

The heart of Exodus is the Sinaitic covenant. A covenant is a legal document binding two parties to take on certain obligations towards each other. There are several covenants in the Bible, and in each case they exhibit at least some of the elements in real-life treaties of the ancient Middle East: a preamble, historical prologue, stipulations, deposition and reading, list of witnesses, blessings and curses, and ratification by animal sacrifice. Biblical covenants, in contrast to Eastern covenants in general, are between a god, Yahweh, and a people, Israel, instead of between a strong ruler and a weaker vassal.

God elects Israel for salvation because the "sons of Israel" are "the firstborn son" of the God of Israel, descended through Shem and Abraham to the chosen line of Jacob whose name is changed to Israel. The goal of the divine plan in Exodus is a return to humanity's state in Eden, so that God can dwell with the Israelites as he had with Adam and Eve through the Ark and Tabernacle, which together form a model of the universe; in later Abrahamic religions Israel becomes the guardian of God's plan for humanity, to bring "God's creation blessing to mankind" begun in Adam.

List of Torah portions in the Book of Exodus:




Electronics

Electronics is a scientific and engineering discipline that studies and applies the principles of physics to design, create, and operate devices that manipulate electrons and other electrically charged particles. Electronics is a subfield of electrical engineering, but it differs from it in that it focuses on using active devices such as transistors, diodes, and integrated circuits to control and amplify the flow of electric current and to convert it from one form to another, such as from alternating current (AC) to direct current (DC) or from analog signals to digital signals. Electronics also encompasses the fields of microelectronics, nanoelectronics, optoelectronics, and quantum electronics, which deal with the fabrication and application of electronic devices at microscopic, nanoscopic, optical, and quantum scales.
Electronics have a profound impact on various aspects of modern society and culture, such as telecommunications, entertainment, education, health care, industry, and security. The main driving force behind the advancement of electronics is the semiconductor industry, which produces the basic materials and components for electronic devices and circuits. The semiconductor industry is one of the largest and most profitable sectors in the global economy, with annual revenues exceeding $481 billion in 2018. The electronics industry also encompasses other sectors that rely on electronic devices and systems, such as e-commerce, which generated over $29 trillion in online sales in 2017.

Electronics has hugely influenced the development of modern society. The identification of the electron in 1897, along with the subsequent invention of the vacuum tube which could amplify and rectify small electrical signals, inaugurated the field of electronics and the electron age. Practical applications started with the invention of the diode by Ambrose Fleming and the triode by Lee De Forest in the early 1900s, which made the detection of small electrical voltages such as radio signals from a radio antenna possible with a non-mechanical device.

Vacuum tubes (thermionic valves) were the first active electronic components which controlled current flow by influencing the flow of individual electrons, They were responsible for the electronics revolution of the first half of the twentieth century, They enabled the construction of equipment that used current amplification and rectification to give us radio, television, radar, long-distance telephony and much more. The early growth of electronics was rapid, and by the 1920s, commercial radio broadcasting and telecommunications were becoming widespread and electronic amplifiers were being used in such diverse applications as long-distance telephony and the music recording industry.

The next big technological step took several decades to appear, when the first working point-contact transistor was invented by John Bardeen and Walter Houser Brattain at Bell Labs in 1947.
However, vacuum tubes played a leading role in the field of microwave and high power transmission as well as television receivers until the middle of the 1980s.
Since then, solid-state devices have all but completely taken over. Vacuum tubes are still used in some specialist applications such as high power RF amplifiers, cathode-ray tubes, specialist audio equipment, guitar amplifiers and some microwave devices.

In April 1955, the IBM 608 was the first IBM product to use transistor circuits without any vacuum tubes and is believed to be the first all-transistorized calculator to be manufactured for the commercial market. The 608 contained more than 3,000 germanium transistors. Thomas J. Watson Jr. ordered all future IBM products to use transistors in their design. From that time on transistors were almost exclusively used for computer logic circuits and peripheral devices. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.

The MOSFET (MOS transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959. The MOSFET was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. Its advantages include high scalability, affordability, low power consumption, and high density. It revolutionized the electronics industry, becoming the most widely used electronic device in the world. The MOSFET is the basic element in most modern electronic equipment.

As the complexity of circuits grew, problems arose. One problem was the size of the circuit. A complex circuit like a computer was dependent on speed. If the components were large, the wires interconnecting them must be long. The electric signals took time to go through the circuit, thus slowing the computer. The invention of the integrated circuit by Jack Kilby and Robert Noyce solved this problem by making all the components and the chip out of the same block (monolith) of semiconductor material. The circuits could be made smaller, and the manufacturing process could be automated. This led to the idea of integrating all components on a single-crystal silicon wafer, which led to small-scale integration (SSI) in the early 1960s, and then medium-scale integration (MSI) in the late 1960s, followed by VLSI. In 2008, billion-transistor processors became commercially available.

An electronic component is any component in an electronic system either active or passive. Components are connected together, usually by being soldered to a printed circuit board (PCB), to create an electronic circuit with a particular function. Components may be packaged singly, or in more complex groups as integrated circuits. Passive electronic components are capacitors, inductors, resistors, whilst active components are such as semiconductor devices; transistors and thyristors, which control current flow at electron level.

Electronic circuit functions can be divided into two function groups: analog and digital. A particular device may consist of circuitry that has either or a mix of the two types. Analog circuits are becoming less common, as many of their functions are being digitized.

Most analog electronic appliances, such as radio receivers, are constructed from combinations of a few types of basic circuits. Analog circuits use a continuous range of voltage or current as opposed to discrete levels as in digital circuits.

The number of different analog circuits so far devised is huge, especially because a 'circuit' can be defined as anything from a single component, to systems containing thousands of components.

Analog circuits are sometimes called linear circuits although many non-linear effects are used in analog circuits such as mixers, modulators, etc. Good examples of analog circuits include vacuum tube and transistor amplifiers, operational amplifiers and oscillators.

One rarely finds modern circuits that are entirely analog – these days analog circuitry may use digital or even microprocessor techniques to improve performance. This type of circuit is usually called "mixed signal" rather than analog or digital.

Sometimes it may be difficult to differentiate between analog and digital circuits as they have elements of both linear and non-linear operation. An example is the comparator which takes in a continuous range of voltage but only outputs one of two levels as in a digital circuit. Similarly, an overdriven transistor amplifier can take on the characteristics of a controlled switch having essentially two levels of output. In fact, many digital circuits are actually implemented as variations of analog circuits similar to this example – after all, all aspects of the real physical world are essentially analog, so digital effects are only realized by constraining analog behaviour.

Digital circuits are electric circuits based on a number of discrete voltage levels. Digital circuits are the most common physical representation of Boolean algebra and are the basis of all digital computers. To most engineers, the terms "digital circuit", "digital system" and "logic" are interchangeable in the context of digital circuits.
Most digital circuits use a binary system with two voltage levels labelled "0" and "1". Often logic "0" will be a lower voltage and referred to as "Low" while logic "1" is referred to as "High". However, some systems use the reverse definition ("0" is "High") or are current based. Quite often the logic designer may reverse these definitions from one circuit to the next as they see fit to facilitate their design. The definition of the levels as "0" or "1" is arbitrary.

Ternary (with three states) logic has been studied, and some prototype computers made. Mass-produced binary systems have caused lower significance for using ternary logic. Computers, electronic clocks, and programmable logic controllers (used to control industrial processes) are constructed of digital circuits. Digital signal processors, which measure, filter or compress continuous real-world analog signals, are another example. Transistors such as MOSFET are used to control binary states.

Highly integrated devices:

Electronic systems design deals with the multi-disciplinary design issues of complex electronic devices and systems, such as mobile phones and computers. The subject covers a broad spectrum, from the design and development of an electronic system (new product development) to assuring its proper function, service life and disposal. Electronic systems design is therefore the process of defining and developing complex electronic devices to satisfy specified requirements of the user.

Due to the complex nature of electronics theory, laboratory experimentation is an important part of the development of electronic devices. These experiments are used to test or verify the engineer's design and detect errors. Historically, electronics labs have consisted of electronics devices and equipment located in a physical space, although in more recent years the trend has been towards electronics lab simulation software, such as CircuitLogix, Multisim, and PSpice.

Today's electronics engineers have the ability to design circuits using premanufactured building blocks such as power supplies, semiconductors (i.e. semiconductor devices, such as transistors), and integrated circuits. Electronic design automation software programs include schematic capture programs and printed circuit board design programs. Popular names in the EDA software world are NI Multisim, Cadence (ORCAD), EAGLE PCB and Schematic, Mentor (PADS PCB and LOGIC Schematic), Altium (Protel), LabCentre Electronics (Proteus), gEDA, KiCad and many others.

Heat generated by electronic circuitry must be dissipated to prevent immediate failure and improve long term reliability. Heat dissipation is mostly achieved by passive conduction/convection. Means to achieve greater dissipation include heat sinks and fans for air cooling, and other forms of computer cooling such as water cooling. These techniques use convection, conduction, and radiation of heat energy.

Electronic noise is defined as unwanted disturbances superposed on a useful signal that tend to obscure its information content. Noise is not the same as signal distortion caused by a circuit. Noise is associated with all electronic circuits. Noise may be electromagnetically or thermally generated, which can be decreased by lowering the operating temperature of the circuit. Other types of noise, such as shot noise cannot be removed as they are due to limitations in physical properties.

Many different methods of connecting components have been used over the years. For instance, early electronics often used point to point wiring with components attached to wooden breadboards to construct circuits. Cordwood construction and wire wrap were other methods used. Most modern day electronics now use printed circuit boards made of materials such as FR4, or the cheaper (and less hard-wearing) Synthetic Resin Bonded Paper (SRBP, also known as Paxoline/Paxolin (trade marks) and FR2) – characterised by its brown colour. Health and environmental concerns associated with electronics assembly have gained increased attention in recent years, especially for products destined to go to European markets.

Electrical components are generally mounted in the following ways:

The electronics industry consists of various sectors. The central driving force behind the entire electronics industry is the semiconductor industry sector, which has annual sales of over as of 2018. The largest industry sector is e-commerce, which generated over in 2017. The most widely manufactured electronic device is the metal-oxide-semiconductor field-effect transistor (MOSFET), with an estimated 13sextillion MOSFETs having been manufactured between 1960 and 2018. In the 1960s, U.S. manufacturers were unable to compete with Japanese companies such as Sony and Hitachi who could produce high-quality goods at lower prices. By the 1980s, however, U.S. manufacturers became the world leaders in semiconductor development and assembly.

However, during the 1990s and subsequently, the industry shifted overwhelmingly to East Asia (a process begun with the initial movement of microchip mass-production there in the 1970s), as plentiful, cheap labor, and increasing technological sophistication, became widely available there.

Over three decades, the United States' global share of semiconductor manufacturing capacity fell, from 37% in 1990, to 12% in 2022. America's pre-eminent semiconductor manufacturer, Intel Corporation, fell far behind its subcontractor Taiwan Semiconductor Manufacturing Company (TSMC) in manufacturing technology.

By that time, Taiwan had become the world's leading source of advanced semiconductors—followed by South Korea, the United States, Japan, Singapore, and China.

Important semiconductor industry facilities (which often are subsidiaries of a leading producer based elsewhere) also exist in Europe (notably the Netherlands), Southeast Asia, South America, and Israel.



Erewhon

Erewhon: or, Over the Range () is a novel by English writer Samuel Butler, first published anonymously in 1872, set in a fictional country discovered and explored by the protagonist. The book is a satire on Victorian society.

The first few chapters of the novel dealing with the discovery of Erewhon are in fact based on Butler's own experiences in New Zealand, where, as a young man, he worked as a sheep farmer on Mesopotamia Station for about four years (1860–64), and explored parts of the interior of the South Island and wrote about in his "A First Year in Canterbury Settlement" (1863).

The novel is one of the first to explore ideas of artificial intelligence, as influenced by Darwin's recently published "On the Origin of Species" (1859) and the machines developed out of the Industrial Revolution (late 18th to early 19th centuries). Specifically, it concerns itself, in the three-chapter "Book of the Machines", with the potentially dangerous ideas of machine consciousness and self-replicating machines.

The greater part of the book consists of a description of Erewhon. The nature of this nation is intended to be ambiguous. At first glance, Erewhon appears to be a Utopia, yet it soon becomes clear that this is far from the case. Yet for all the failings of Erewhon, it is also clearly not a dystopia, such as that depicted in 1949 in George Orwell's "Nineteen Eighty-Four".

As a satirical utopia, "Erewhon" has sometimes been compared to "Gulliver's Travels" (1726), a classic novel by Jonathan Swift; the image of Utopia in this latter case also bears strong parallels with the self-view of the British Empire at the time. It can also be compared to the William Morris novel, "News from Nowhere" (1890).

"Erewhon" satirises various aspects of Victorian society, including criminal punishment, religion, and anthropocentrism. For example, according to Erewhonian law, offenders are treated as if they were ill, whereas ill people are looked upon as criminals. Another feature of Erewhon is the absence of machines; this is due to the widely shared perception by the Erewhonians that machines are potentially dangerous.

Butler developed the three chapters of "Erewhon" that make up "The Book of the Machines" from a number of articles he had contributed to "The Press", which had just begun publication in Christchurch, New Zealand, beginning with "Darwin among the Machines" (1863). Butler was the first to write about the possibility that machines might develop consciousness by natural selection.

Many dismissed this as a joke, but, in his preface to the second edition, Butler wrote, "I regret that reviewers have in some cases been inclined to treat the chapters on Machines as an attempt to reduce Mr Darwin's theory to an absurdity. Nothing could be further from my intention, and few things would be more distasteful to me than any attempt to laugh at Mr Darwin."


In a 1945 broadcast, George Orwell praised the book and said that when Butler wrote "Erewhon" it needed "imagination of a very high order to see that machinery could be dangerous as well as useful". He recommended the novel, though not its sequel, "Erewhon Revisited".

The French philosopher Gilles Deleuze used ideas from Butler's book at various points in the development of his philosophy of difference. In "Difference and Repetition" (1968), Deleuze refers to what he calls "Ideas" as "Erewhon". "Ideas are not concepts", he argues, but rather "a form of eternally positive differential multiplicity, distinguished from the identity of concepts." "Erewhon" refers to the "nomadic distributions" that pertain to simulacra, which "are not universals like the categories, nor are they the "hic et nunc" or "nowhere", the diversity to which categories apply in representation." "Erewhon", in this reading, is "not only a disguised "no-where" but a rearranged "now-here"."

In his collaboration with Félix Guattari, "Anti-Oedipus" (1972), Deleuze draws on Butler's "The Book of the Machines" to "go beyond" the "usual polemic between vitalism and mechanism" as it relates to their concept of "desiring-machines":
C. S. Lewis alludes to the book in his essay, "The Humanitarian Theory of Punishment" in the posthumously published collection, "God in the Dock" (1970).

Aldous Huxley alludes to the book in his novels "Island" (1962) and "The Doors of Perception" (1954), as does Agatha Christie in "Death on the Nile" (1937). A copy of the book figures in Elizabeth Bowen's short story 'The Cat Jumps' (1934).

In 1994, a group of ex-Yugoslavian writers in Amsterdam, who had established the PEN centre of Yugoslav Writers in Exile, published a single issue of a literary journal "Erewhon".

The 1973 movie "The Day of the Dolphin" features a boat named "Erewhon."

New Zealand sound art organisation, the Audio Foundation, published in 2012 an anthology edited by Bruce Russell named "Erewhon Calling" after Butler's book.

In 2014, New Zealand artist Gavin Hipkins released his first feature film, titled "Erewhon" and based on Butler's book. It premiered at the New Zealand International Film Festival and the Edinburgh Art Festival.

In "Smile", the second episode of the 2017 season of "Doctor Who", the Doctor and Bill explore a spaceship named "Erehwon". Despite the slightly different spelling, the episode writer Frank Cottrell-Boyce confirmed that this was a reference to Butler's novel.

The book "The Open Society and Its Enemies", by Karl Popper, reproduces on its first page the following citation of Butler: ""It will be seen ... that the Erewhonians are a meek and long-suffering people easily led by the nose, and quick to offer up common sense at the shrine of logic, when a philosopher arises among them who carries them away ... by convincing them that their existing institutions are not based on the strictest principles of morality"."

"Erewhon" is the unofficial name US astronauts gave Regan Station, a military space station in David Brin's 1990 novel "Earth".

The 'Butlerian Jihad' is the name of the crusade to wipe out 'thinking machines' in the novel, "Dune", by Frank Herbert.

Erewhon is the name of a Los Angeles-based natural foods grocery store originally founded in Boston in 1966.

Erewhon is also the name of an independent speculative fiction publishing company founded in 2018 by Liz Gorinsky.

A copy of Erewhon figures prominently in the video for "A Barely Lit Path," the lead single from Oneohtrix Point Never's 2023 album "Again."




Ectopia (medicine)

An ectopia () is a displacement or malposition of an organ or other body part, which is then referred to as ectopic ().



Entorhinal cortex

The entorhinal cortex (EC) is an area of the brain's allocortex, located in the medial temporal lobe, whose functions include being a widespread network hub for memory, navigation, and the perception of time. The EC is the main interface between the hippocampus and neocortex. The EC-hippocampus system plays an important role in declarative (autobiographical/episodic/semantic) memories and in particular spatial memories including memory formation, memory consolidation, and memory optimization in sleep. The EC is also responsible for the pre-processing (familiarity) of the input signals in the reflex nictitating membrane response of classical trace conditioning; the association of impulses from the eye and the ear occurs in the entorhinal cortex.

The entorhinal cortex is a portion of the rostral parahippocampal gyrus.

It is usually divided into medial and lateral regions with three bands with distinct properties and connectivity running perpendicular across the whole area. A distinguishing characteristic of the EC is the lack of cell bodies where layer IV should be; this layer is called the "Lamina dissecans".

The superficial layers – layers II and III – of EC project to the dentate gyrus and hippocampus: Layer II projects primarily to dentate gyrus and hippocampal region CA3; layer III projects primarily to hippocampal region CA1 and the subiculum. These layers receive input from other cortical areas, especially associational, perirhinal, and parahippocampal cortices, as well as prefrontal cortex. EC as a whole, therefore, receives highly processed input from every sensory modality, as well as input relating to ongoing cognitive processes, though it should be stressed that, within EC, this information remains at least partially segregated.

The deep layers, especially layer V, receive one of the three main outputs of the hippocampus and, in turn, reciprocate connections from other cortical areas that project to superficial EC.


In 2005, it was discovered that entorhinal cortex contains a neural map of the spatial environment in rats. In 2014, John O'Keefe, May-Britt Moser and Edvard Moser received the Nobel Prize in Physiology or Medicine, partly because of this discovery.

In rodents, neurons in the lateral entorhinal cortex exhibit little spatial selectivity, whereas neurons of the medial entorhinal cortex (MEC), exhibit multiple "place fields" that are arranged in a hexagonal pattern, and are, therefore, called "grid cells". These fields and spacing between fields increase from the dorso-lateral MEA to the ventro-medial MEA.

The same group of researchers has found speed cells in the medial entorhinal cortex of rats. The speed of movement is translated from proprioceptive information and is represented as firing rates in these cells. The cells are known to fire in correlation to future speed of the rodent.

Recently, a general theory has been proposed to elucidate the function of the reelin positive cells in the layer II of the entorhinal cortex. According to this concept, these cells would be generally organized into 1-dimensional ring attractors, and in the "medial" (in humans: "posteromedial") portion, would function as grid cells (anatomically: stellate cells) while in "lateral" (in humans: "anterolateral") portion, where they appear as fan cells, would enable the encoding of new episodic memories. This concept is underscored by the fact that fan cells of the entorhinal cortex are indispensable for the formation of episodic-like memories in rodents.

Single-unit recording of neurons in humans playing video games find path cells in the EC, the activity of which indicates whether a person is taking a clockwise or counterclockwise path. Such EC "direction" path cells show this directional activity irrespective of the location of where a person experiences themselves, which contrasts them to place cells in the hippocampus, which are activated by specific locations.

EC neurons process general information such as directional activity in the environment, which contrasts to that of the hippocampal neurons, which usually encode information about specific places. This suggests that EC encodes general properties about current contexts that are then used by hippocampus to create unique representations from combinations of these properties.

Research generally highlights a useful distinction in which the medial entorhinal cortex (MEC) mainly supports processing of space, whereas the lateral entorhinal cortex (LEC) mainly supports the processing of time. 

The MEC exhibits a strong ~8 Hz rhythmic neural activity known as theta. Alterations in the neural activity across the brain region results in an observed "traveling wave" phenomena across the MEC long-axis, similar to that of the hippocampus, due to asymmetric theta oscillations. The underlying cause of these phase shifts and their waveform changes is unknown. 

Individual variation in the volume of EC is linked to taste perception. People with a larger EC in the left hemisphere found quinine, the source of bitterness in tonic water, less bitter.

The entorhinal cortex is the first area of the brain to be affected in Alzheimer's disease; in year 2013, a functional magnetic resonance imaging study has localised the area to the lateral entorhinal cortex. Lopez "et al." have shown, in a multimodal study, that there are differences in the volume of the left entorhinal cortex between progressing (to Alzheimer's disease) and stable mild cognitive impairment patients. These authors also found that the volume of the left entorhinal cortex inversely correlates with the level of alpha band phase synchronization between the right anterior cingulate and temporo-occipital regions.

In 2012, neuroscientists at UCLA conducted an experiment using a virtual taxi video game connected to seven epilepsy patients with electrodes already implanted in their brains, allowing the researchers to monitor neuronal activity whenever memories were being formed. As the researchers stimulated the nerve fibers of each of the patients' entorhinal cortex as they were learning, they were then able to better navigate themselves through various routes and recognize landmarks more quickly. This signified an improvement in the patients' spatial memory.

Effect of aerobic exercise

A study on young subjects found aerobic fitness to be positively correlated with entorhinal cortex volume, indicating that aerobic exercise may have a positive effect on the medial temporal lobe memory system (which includes the entorhinal cortex).

In rodents, the EC is located at the caudal end of the temporal lobe. The rodent entorhinal cortex shows a modular organization, with different properties and connections in different areas.

In primates it is located at the rostral end of the temporal lobe and stretches dorsolaterally.


Ernst Haeckel

Ernst Heinrich Philipp August Haeckel (; 16 February 1834 – 9 August 1919) was a German zoologist, naturalist, eugenicist, philosopher, physician, professor, marine biologist and artist. He discovered, described and named thousands of new species, mapped a genealogical tree relating all life forms and coined many terms in biology, including "ecology", "phylum", "phylogeny", and "Protista." Haeckel promoted and popularised Charles Darwin's work in Germany and developed the influential but no longer widely held recapitulation theory ("ontogeny recapitulates phylogeny") claiming that an individual organism's biological development, or ontogeny, parallels and summarises its species' evolutionary development, or phylogeny.

The published artwork of Haeckel includes over 100 detailed, multi-colour illustrations of animals and sea creatures, collected in his "Kunstformen der Natur" ("Art Forms of Nature"), a book which would go on to influence the Art Nouveau artistic movement. As a philosopher, Ernst Haeckel wrote "Die Welträthsel" (1895–1899; in English: "The Riddle of the Universe", 1900), the genesis for the term "world riddle" ("Welträtsel"); and "Freedom in Science and Teaching" to support teaching evolution.

Haeckel was also a promoter of scientific racism and embraced the idea of Social Darwinism. He was the first person to characterize the Great War the "first" World War, which he did as early as 1914.

Ernst Haeckel was born on 16 February 1834, in Potsdam (then part of the Kingdom of Prussia).
In 1852 Haeckel completed studies at the "Domgymnasium", the cathedral high-school of Merseburg. He then studied medicine in Berlin and Würzburg, particularly with Albert von Kölliker, Franz Leydig, Rudolf Virchow (with whom he later worked briefly as assistant), and with the anatomist-physiologist Johannes Peter Müller (1801–1858). Together with Hermann Steudner he attended botany lectures in Würzburg. In 1857 Haeckel attained a doctorate in medicine, and afterwards he received the license to practice medicine. The occupation of physician appeared less worthwhile to Haeckel after contact with suffering patients.
Haeckel studied under Carl Gegenbaur at the University of Jena for three years. In 1861 he earned a habilitation in comparative anatomy and became a professor of zoology at the University at Jena, where he remained for 47 years, from 1862 to 1909. Between 1859 and 1866 Haeckel worked on many phyla, such as radiolarians, poriferans (sponges) and annelids (segmented worms). During a trip to the Mediterranean, Haeckel named nearly 150 new species of radiolarians.

From 1866 to 1867 Haeckel made an extended journey to the Canary Islands with Hermann Fol. On 17 October 1866 he arrived in London. Over the next few days he met Charles Lyell, and visited Thomas Huxley and family at their home. On 21 October he visited Charles Darwin at Down House in Kent. In 1867 he married Agnes Huschke. Their son Walter was born in 1868, their daughters Elizabeth in 1871 and Emma in 1873. In 1869 he traveled as a researcher to Norway, in 1871 to Croatia (where he lived on the island of Hvar in a monastery), and in 1873 to Egypt, Turkey, and Greece. In 1907 he had a museum built in Jena to teach the public about evolution. Haeckel retired from teaching in 1909, and in 1910 he withdrew from the Evangelical Church of Prussia.

On the occasion of his 80th birthday celebration he was presented with a two-volume work entitled "Was wir Ernst Haeckel verdanken (What We Owe to Ernst Haeckel)", edited at the request of the German Monistenbund by Heinrich Schmidt of Jena.

In 1864, his first wife, Anna Sethe, died. Haeckel dedicated some species of jellyfish that he found beautiful (such as "Desmonema annasethe") to her.
Haeckel's second wife, Agnes, died in 1915, and he became substantially frailer, breaking his leg and arm. He sold his "Villa Medusa" in Jena in 1918 to the Carl Zeiss foundation, which preserved his library. 
Haeckel died on 9 August 1919.

In "Monism as Connecting Religion and Science" (1892), he argued in favor of monism as the view most compatible with the current scientific understanding of the natural world. His perspective of monism was pantheistic and impersonal. The monistic idea of God, which alone is compatible with our present knowledge of nature, recognizes the divine spirit in all things. It can never recognise in God a "personal being," or, in other words, an individual of limited extension in space, or even of human form. God is everywhere.
Haeckel became the most famous proponent of Monism in Germany.
In 1906 Haeckel belonged to the founders of the Monist League (), which took a stance against philosophical materialism and promote a "natural Weltanschauung". This organization lasted until 1933 and included such notable members as Wilhelm Ostwald, Georg von Arco (1869–1940), Helene Stöcker and Walter Arthur Berendsohn.

Haeckel's affinity for the German Romantic movement, coupled with his acceptance of a form of Lamarckism, influenced his political beliefs. Rather than being a strict Darwinian, Haeckel believed that the characteristics of an organism were acquired through interactions with the environment and that ontogeny reflected phylogeny. He saw the social sciences as instances of "applied biology", and that phrase was picked up and used for Nazi propaganda.

He was the first person to use the term "first world war" about World War I.

However, Haeckel's books were banned by the Nazi Party, which refused Monism and Haeckel's freedom of thought. Moreover, it is worth mentioning that Haeckel had often overtly recognized the great contribution of educated Jews to the German culture.

Haeckel was a zoologist, an accomplished artist and illustrator, and later a professor of comparative anatomy. Although Haeckel's ideas are important to the history of evolutionary theory, and although he was a competent invertebrate anatomist most famous for his work on radiolaria, many speculative concepts that he championed are now considered incorrect. For example, Haeckel described and named hypothetical ancestral microorganisms that have never been found.

He was one of the first to consider psychology as a branch of physiology. He also proposed the kingdom "Protista" in 1866. His chief interests lay in evolution and life development processes in general, including development of nonrandom form, which culminated in the beautifully illustrated "Kunstformen der Natur" ("Art forms of nature"). Haeckel did not support natural selection, rather believing in Lamarckism.

Haeckel advanced a version of the earlier recapitulation theory previously set out by Étienne Serres in the 1820s and supported by followers of Étienne Geoffroy Saint-Hilaire including Robert Edmond Grant. It proposed a link between ontogeny (development of form) and phylogeny (evolutionary descent), summed up by Haeckel in the phrase "ontogeny recapitulates phylogeny". His concept of recapitulation has been refuted in the form he gave it (now called "strong recapitulation"), in favour of the ideas first advanced by Karl Ernst von Baer. The strong recapitulation hypothesis views ontogeny as repeating forms of adult ancestors, while weak recapitulation means that what is repeated (and built upon) is the ancestral embryonic development process. Haeckel supported the theory with embryo drawings that have since been shown to be oversimplified and in part inaccurate, and the theory is now considered an oversimplification of quite complicated relationships, however comparison of embryos remains a powerful way to demonstrate that all animals are related. Haeckel introduced the concept of heterochrony, the change in timing of embryonic development over the course of evolution.

Haeckel was a flamboyant figure, who sometimes took great, non-scientific leaps from available evidence. For example, at the time when Darwin published "On the Origin of Species by Means of Natural Selection" (1859), Haeckel postulated that evidence of human evolution would be found in the Dutch East Indies (now Indonesia). At that time, no remains of human ancestors had yet been identified. He described these theoretical remains in great detail and even named the as-yet unfound species, "Pithecanthropus alalus", and instructed his students such as Richard and Oskar Hertwig to go and find it.

One student did find some remains: a Dutchman named Eugène Dubois searched the East Indies from 1887 to 1895, discovering the remains of Java Man in 1891, consisting of a skullcap, thighbone, and a few teeth. These remains are among the oldest hominid remains ever found. Dubois classified Java Man with Haeckel's "Pithecanthropus" label, though they were later reclassified as "Homo erectus". Some scientists of the day suggested Dubois' Java Man as a potential intermediate form between modern humans and the common ancestor we share with the other great apes. The current consensus of anthropologists is that the direct ancestors of modern humans were African populations of "Homo erectus" (possibly "Homo ergaster"), rather than the Asian populations exemplified by Java Man and Peking Man. (Ironically, a new human species, Homo floresiensis, a dwarf human type, has recently been discovered in the island of Flores).

The creationist polygenism of Samuel George Morton and Louis Agassiz, which presented human races as separately created species, was rejected by Charles Darwin, who argued for the monogenesis of the human species and the African origin of modern humans. In contrast to most of Darwin's supporters, Haeckel put forward a doctrine of evolutionary polygenism based on the ideas of the linguist August Schleicher, in which several different language groups had arisen separately from speechless prehuman "Urmenschen" (), which themselves had evolved from simian ancestors. These separate languages had completed the transition from animals to man, and under the influence of each main branch of languages, humans had evolved – in a kind of Lamarckian use-inheritance – as separate species, which could be subdivided into races. From this, Haeckel drew the implication that languages with the most potential yield the human races with the most potential, led by the Semitic and Indo-Germanic groups, with Berber, Jewish, Greco-Roman and Germanic varieties to the fore. As Haeckel stated:

Haeckel's view can be seen as a forerunner of the views of Carleton Coon, who also believed that human races evolved independently and in parallel with each other. These ideas eventually fell from favour.

Haeckel also applied the hypothesis of polygenism to the modern diversity of human groups. He became a key figure in social darwinism and leading proponent of scientific racism, stating for instance:

Haeckel divided human beings into ten races, of which the Caucasian was the highest and the primitives were doomed to extinction. In his view, 'Negroes' were savages and Whites were the most civilised: for instance, he claimed that '[t]he Negro' had stronger and more freely movable toes than any other race, which, he argued, was evidence of their being less evolved, and which led him to compare them to four-handed" Apes'.

In his "Ontogeny and Phylogeny" Harvard paleontologist Stephen Jay Gould wrote: "[Haeckel's] evolutionary racism; his call to the German people for racial purity and unflinching devotion to a 'just' state; his belief that harsh, inexorable laws of evolution ruled human civilization and nature alike, conferring upon favored races the right to dominate others ... all contributed to the rise of Nazism."

In his introduction to the Nazi party ideologue Alfred Rosenberg's 1930 book, "[The Myth of the Twentieth Century]", Peter Peel affirms that Rosenberg had indeed read Haeckel.

In the same line of thought, historian Daniel Gasman states that Haeckel's ideology stimulated the birth of Fascist ideology in Italy and France.

However, in 2009 Robert J. Richards noted: "Haeckel, on his travels to Ceylon and Indonesia, often formed closer and more intimate relations with natives, even members of the untouchable classes, than with the European colonials." and says the Nazis rejected Haeckel, since he opposed antisemitism, while supporting ideas they disliked (for instance atheism, feminism, internationalism, pacifism etc.).

The Jena Declaration, published by the German Zoological Society, rejects the idea of human "races" and distances itself from the racial theories of Ernst Haeckel and other 20th century scientists. It claims that genetic variation between human populations is smaller than within them, demonstrating that the biological concept of "races" is invalid. The statement highlights that there are no specific genes or genetic markers that match with conventional racial categorizations. It also indicates that the idea of "races" is based on racism rather than any scientific factuality.

Haeckel claimed the origin of humanity was to be found in Asia: he believed that Hindustan (Indian subcontinent) was the actual location where the first humans had evolved. Haeckel argued that humans were closely related to the primates of Southeast Asia and rejected Darwin's hypothesis of Africa.

Haeckel later claimed that the missing link was to be found on the lost continent of Lemuria located in the Indian Ocean. He believed that Lemuria was the home of the first humans and that Asia was the home of many of the earliest primates; he thus supported that Asia was the cradle of hominid evolution. Haeckel also claimed that Lemuria connected Asia and Africa, which allowed the migration of humans to the rest of the world.

In Haeckel's book "The History of Creation" (1884) he included migration routes which he thought the first humans had used outside of Lemuria.

When Haeckel was a student in the 1850s he showed great interest in embryology, attending the rather unpopular lectures twice and in his notes sketched the visual aids: textbooks had few illustrations, and large format plates were used to show students how to see the tiny forms under a reflecting microscope, with the translucent tissues seen against a black background. Developmental series were used to show stages within a species, but inconsistent views and stages made it even more difficult to compare different species. It was agreed by all European evolutionists that all vertebrates looked very similar at an early stage, in what was thought of as a common ideal type, but there was a continuing debate from the 1820s between the Romantic recapitulation theory that human embryos developed through stages of the forms of all the major groups of adult animals, literally manifesting a sequence of organisms on a linear chain of being, and Karl Ernst von Baer's opposing view, stated in von Baer's laws of embryology, that the early general forms diverged into four major groups of specialised forms without ever resembling the adult of another species, showing affinity to an archetype but no relation to other types or any transmutation of species. By the time Haeckel was teaching he was able to use a textbook with woodcut illustrations written by his own teacher Albert von Kölliker, which purported to explain human development while also using other mammalian embryos to claim a coherent sequence. Despite the significance to ideas of transformism, this was not really polite enough for the new popular science writing, and was a matter for medical institutions and for experts who could make their own comparisons.

Darwin's "On the Origin of Species", which made a powerful impression on Haeckel when he read it in 1864, was very cautious about the possibility of ever reconstructing the history of life, but did include a section reinterpreting von Baer's embryology and revolutionising the field of study, concluding that "Embryology rises greatly in interest, when we thus look at the embryo as a picture, more or less obscured, of the common parent-form of each great class of animals." It mentioned von Baer's 1828 anecdote (misattributing it to Louis Agassiz) that at an early stage embryos were so similar that it could be impossible to tell whether an unlabelled specimen was of a mammal, a bird, or of a reptile, and Darwin's own research using embryonic stages of barnacles to show that they are crustaceans, while cautioning against the idea that one organism or embryonic stage is "higher" or "lower", or more or less evolved. Haeckel disregarded such caution, and in a year wrote his massive and ambitious "Generelle Morphologie", published in 1866, presenting a revolutionary new synthesis of Darwin's ideas with the German tradition of "Naturphilosophie" going back to Goethe and with the progressive evolutionism of Lamarck in what he called "Darwinismus". He used morphology to reconstruct the evolutionary history of life, in the absence of fossil evidence using embryology as evidence of ancestral relationships. He invented new terms, including ontogeny and phylogeny, to present his evolutionised recapitulation theory that "ontogeny recapitulated phylogeny". The two massive volumes sold poorly, and were heavy going: with his limited understanding of German, Darwin found them impossible to read. Haeckel's publisher turned down a proposal for a "strictly scholarly and objective" second edition.

Haeckel's aim was a reformed morphology with evolution as the organising principle of a cosmic synthesis unifying science, religion, and art. He was giving successful "popular lectures" on his ideas to students and townspeople in Jena, in an approach pioneered by his teacher Rudolf Virchow. To meet his publisher's need for a popular work he used a student's transcript of his lectures as the basis of his "Natürliche Schöpfungsgeschichte" of 1868, presenting a comprehensive presentation of evolution. In the Spring of that year he drew figures for the book, synthesising his views of specimens in Jena and published pictures to represent types. After publication he told a colleague that the images "are completely exact, partly copied from nature, partly assembled from all illustrations of these early stages that have hitherto become known". There were various styles of embryological drawings at that time, ranging from more schematic representations to "naturalistic" illustrations of specific specimens. Haeckel believed privately that his figures were both exact and synthetic, and in public asserted that they were schematic like most figures used in teaching. The images were reworked to match in size and orientation, and though displaying Haeckel's own views of essential features, they support von Baer's concept that vertebrate embryos begin similarly and then diverge. Relating different images on a grid conveyed a powerful evolutionary message. As a book for the general public, it followed the common practice of not citing sources.
The book sold very well, and while some anatomical experts hostile to Haeckel's evolutionary views expressed some private concerns that certain figures had been drawn rather freely, the figures showed what they already knew about similarities in embryos. The first published concerns came from Ludwig Rütimeyer, a professor of zoology and comparative anatomy at the University of Basel who had placed fossil mammals in an evolutionary lineage early in the 1860s and had been sent a complimentary copy. At the end of 1868 his review in the "Archiv für Anthropologie" wondered about the claim that the work was "popular and scholarly", doubting whether the second was true, and expressed horror about such public discussion of man's place in nature with illustrations such as the evolutionary trees being shown to non-experts. Though he made no suggestion that embryo illustrations should be directly based on specimens, to him the subject demanded the utmost "scrupulosity and conscientiousness" and an artist must "not arbitrarily model or generalise his originals for speculative purposes" which he considered proved by comparison with works by other authors. In particular, "one and the same, moreover incorrectly interpreted woodcut, is presented to the reader three times in a row and with three different captions as [the] embryo of the dog, the chick, [and] the turtle". He accused Haeckel of "playing fast and loose with the public and with science", and failing to live up to the obligation to the truth of every serious researcher. Haeckel responded with angry accusations of bowing to religious prejudice, but in the second (1870) edition changed the duplicated embryo images to a single image captioned "embryo of a mammal or bird". Duplication using galvanoplastic stereotypes (clichés) was a common technique in textbooks, but not on the same page to represent different eggs or embryos. In 1891 Haeckel made the excuse that this "extremely rash foolishness" had occurred in undue haste but was "bona fide", and since repetition of incidental details was obvious on close inspection, it is unlikely to have been intentional deception.

The revised 1870 second edition of 1,500 copies attracted more attention, being quickly followed by further revised editions with larger print runs as the book became a prominent part of the optimistic, nationalist, anticlerical "culture of progress" in Otto von Bismarck's new German Empire. The similarity of early vertebrate embryos became common knowledge, and the illustrations were praised by experts such as Michael Foster of the University of Cambridge. In the introduction to his 1871 "The Descent of Man, and Selection in Relation to Sex", Darwin gave particular praise to Haeckel, writing that if "Natürliche Schöpfungsgeschichte" "had appeared before my essay had been written, I should probably never have completed it". The first chapter included an illustration: "As some of my readers may never have seen a drawing of an embryo, I have given one of man and another of a dog, at about the same early stage of development, carefully copied from two works of undoubted accuracy" with a footnote citing the sources and noting that "Häckel has also given analogous drawings in his "Schöpfungsgeschichte."" The fifth edition of Haeckel's book appeared in 1874, with its frontispiece a heroic portrait of Haeckel himself, replacing the previous controversial image of the heads of apes and humans.

Later in 1874, Haeckel's simplified embryology textbook "Anthropogenie" made the subject into a battleground over Darwinism aligned with Bismarck's "Kulturkampf" ("culture struggle") against the Catholic Church. Haeckel took particular care over the illustrations, changing to the leading zoological publisher Wilhelm Engelmann of Leipzig and obtaining from them use of illustrations from their other textbooks as well as preparing his own drawings including a dramatic double page illustration showing "early", "somewhat later" and "still later" stages of 8 different vertebrates. Though Haeckel's views had attracted continuing controversy, there had been little dispute about the embryos and he had many expert supporters, but Wilhelm His revived the earlier criticisms and introduced new attacks on the 1874 illustrations. Others joined in: both expert anatomists and Catholic priests and supporters were politically opposed to Haeckel's views.

While it has been widely claimed that Haeckel was charged with fraud by five professors and convicted by a university court at Jena, there does not appear to be an independently verifiable source for this claim. Recent analyses (Richardson 1998, Richardson and Keuck 2002) have found that some of the criticisms of Haeckel's embryo drawings were legitimate, but others were unfounded. There were multiple versions of the embryo drawings, and Haeckel rejected the claims of fraud. It was later said that "there is evidence of sleight of hand" on both sides of the feud between Haeckel and Wilhelm His. Robert J. Richards, in a paper published in 2008, defends the case for Haeckel, shedding doubt against the fraud accusations based on the material used for comparison with what Haeckel could access at the time.

Haeckel was elected as a member to the American Philosophical Society in 1885. He was awarded the title of Excellency by Kaiser Wilhelm II in 1907 and the Linnean Society of London's prestigious Darwin-Wallace Medal in 1908. In the United States, "Mount Haeckel", a summit in the Eastern Sierra Nevada, overlooking the Evolution Basin, is named in his honour, as is another "Mount Haeckel", a summit in New Zealand; and the asteroid 12323 Haeckel.

In Jena he is remembered with a monument at Herrenberg (erected in 1969), an exhibition at Ernst-Haeckel-Haus, and at the Jena Phyletic Museum, which continues to teach about evolution and share his work to this day.

The ratfish, "Harriotta haeckeli" is named in his honor.

The research vessel "Ernst Haeckel" is named in his honor.

In 1981, a botanical journal called "Ernstia" was started being published in the city of Maracay, Venezuela.

In 2013, "Ernstia", a genus of calcareous sponges in the family Clathrinidae. The genus was erected to contain five species previously assigned to "Clathrina". The genus name honors Ernst Haeckel for his contributions towards sponge taxonomy and phylogeny.

Darwin's 1859 book "On the Origin of Species" had immense popular influence, but although its sales exceeded its publisher's hopes it was a technical book rather than a work of popular science: long, difficult and with few illustrations. One of Haeckel's books did a great deal to explain his version of "Darwinism" to the world. It was a bestselling, provocatively illustrated book in German, titled "Natürliche Schöpfungsgeschichte", published in Berlin in 1868, and translated into English as "The History of Creation" in 1876. Until 1909, eleven editions had appeared, as well as 25 translations into other languages. The "Natürliche Schöpfungsgeschichte" cemented Haeckel's reputation as one of Germany's most forceful popularizers of science. His "Welträthsel" were reprinted ten times after the book's first publication in 1899; ultimately, over 400,000 copies were sold.

Haeckel argued that human evolution consisted of precisely 22 phases, the 21st – the "missing link" – being a halfway step between apes and humans. He even formally named this missing link "Pithecanthropus alalus", translated as "ape man without speech".

Haeckel's literary output was extensive, including many books, scientific papers, and illustrations.





For a fuller list of works of and about Haeckel, see his entry in the .

Some historians have seen Haeckel's social Darwinism as a forerunner to Nazi ideology. Others have denied the relationship altogether.

The evidence is in some respects ambiguous. On one hand, Haeckel was an advocate of scientific racism. He held that evolutionary biology had definitively proven that races were unequal in intelligence and ability, and that their lives were also of unequal value, e.g., "These lower races (such as the Veddahs or Australian negroes) are psychologically nearer to the mammals (apes or dogs) than to civilised Europeans; we must therefore, assign a totally different value to their lives." As a result of the "struggle for existence", it followed that the "lower" races would eventually be exterminated. He was also a social Darwinist who believed that "survival of the fittest" was a natural law, and that struggle led to improvement of the race. As an advocate of eugenics, he also believed that about 200,000 mentally and congenitally ill should be killed by a medical control board. This idea was later put into practice by Nazi Germany, as part of the Aktion T4 program. Alfred Ploetz, founder of the German Society for Racial Hygiene, praised Haeckel repeatedly, and invited him to become an honorary member. Haeckel accepted the invitation. Haeckel also believed that Germany should be governed by an authoritarian political system, and that inequalities both within and between societies were an inevitable product of evolutionary law. Haeckel was also an extreme German nationalist who believed strongly in the superiority of German culture.

On the other hand, Haeckel was not an anti-Semite. In the racial hierarchies he constructed Jews tended to appear closer to the top, rather than closer to the bottom as in Nazi racial thought. He was also a pacifist until the First World War, when he wrote propaganda in favor of the war. The principal arguments of historians who deny a meaningful connection between Haeckel and Nazism are that Haeckel's ideas were very common at the time, that Nazis were much more strongly influenced by other thinkers, and that Haeckel is properly classified as a 19th-century German liberal, rather than a forerunner to Nazism. They also point to incompatibilities between evolutionary biology and Nazi ideology.

Nazis themselves divided on the question of whether Haeckel should be counted as a pioneer of their ideology. SS captain and biologist Heinz Brücher wrote a biography of Haeckel in 1936, in which he praised Haeckel as a "pioneer in biological state thinking". This opinion was also shared by the scholarly journal, "Der Biologe", which celebrated Haeckel's 100th birthday, in 1934, with several essays acclaiming him as a pioneering thinker of Nazism. Other Nazis kept their distance from Haeckel. Nazi propaganda guidelines issued in 1935 listed books which popularized Darwin and evolution on an "expunged list". Haeckel was included by name as a forbidden author. Gunther Hecht, a member of the Nazi Department of Race Politics, also issued a memorandum rejecting Haeckel as a forerunner of Nazism. Kurt Hildebrandt, a Nazi political philosopher, also rejected Haeckel. Eventually Haeckel was rejected by Nazi bureaucrats.




Evolutionism

Evolutionism is a term used (often derogatorily) to denote the theory of evolution. Its exact meaning has changed over time as the study of evolution has progressed. In the 19th century, it was used to describe the belief that organisms deliberately improved themselves through progressive inherited change (orthogenesis). The teleological belief went on to include cultural evolution and social evolution. In the 1970s, the term "Neo-Evolutionism" was used to describe the idea that "human beings sought to preserve a familiar style of life unless change was forced on them by factors that were beyond their control."

The term is most often used by creationists to describe adherence to the scientific consensus on evolution as equivalent to a secular religion. The term is very seldom used within the scientific community, since the scientific position on evolution is accepted by the overwhelming majority of scientists. Because evolutionary biology is the default scientific position, it is assumed that "scientists" or "biologists" are "evolutionists" unless specifically noted otherwise. In the creation–evolution controversy, creationists often call those who accept the validity of the modern evolutionary synthesis "evolutionists" and the theory itself "evolutionism".

Before its use to describe biological evolution, the term "evolution" was originally used to refer to any orderly sequence of events with the outcome somehow contained at the start. The first five editions of Darwin's in "Origin of Species" used the word "evolved", but the word "evolution" was only used in its sixth edition in 1872. By then, Herbert Spencer had developed the concept theory that organisms strive to evolve due to an internal "driving force" (orthogenesis) in 1862. Edward B. Tylor and Lewis H Morgan brought the term "evolution" to anthropology though they tended toward the older pre-Spencerian definition helping to form the concept of unilineal (social) evolution used during the later part of what Trigger calls the Antiquarianism-Imperial Synthesis period (c1770-c1900). The term evolutionism subsequently came to be used for the now discredited theory that evolution contained a deliberate component, rather than the selection of beneficial traits from random variation by differential survival.

The term "evolution" is widely used, but the term "evolutionism" is not used in the scientific community to refer to evolutionary biology as it is redundant and anachronistic.

However, the term has been used by creationists in discussing the creation–evolution controversy. For example, the Institute for Creation Research, in order to imply placement of evolution in the category of 'religions', including atheism, fascism, humanism and occultism, commonly uses the words "evolutionism" and "evolutionist" to describe the consensus of mainstream science and the scientists subscribing to it, thus implying through language that the issue is a matter of religious belief. The BioLogos Foundation, an organization that promotes the idea of theistic evolution, uses the term "evolutionism" to describe "the atheistic worldview that so often accompanies the acceptance of biological evolution in public discourse." It views this as a subset of scientism.



Entscheidungsproblem

In mathematics and computer science, the ; ) is a challenge posed by David Hilbert and Wilhelm Ackermann in 1928. The problem asks for an algorithm that considers, as input, a statement and answers "yes" or "no" according to whether the statement is "universally valid", i.e., valid in every structure.

By the completeness theorem of first-order logic, a statement is universally valid if and only if it can be deduced using logical rules and axioms, so the "" can also be viewed as asking for an algorithm to decide whether a given statement is provable using the rules of logic.

In 1936, Alonzo Church and Alan Turing published independent papers showing that a general solution to the " is impossible, assuming that the intuitive notion of "effectively calculable" is captured by the functions computable by a Turing machine (or equivalently, by those expressible in the lambda calculus). This assumption is now known as the Church–Turing thesis.

The origin of the goes back to Gottfried Leibniz, who in the seventeenth century, after having constructed a successful mechanical calculating machine, dreamt of building a machine that could manipulate symbols in order to determine the truth values of mathematical statements. He realized that the first step would have to be a clean formal language, and much of his subsequent work was directed toward that goal. In 1928, David Hilbert and Wilhelm Ackermann posed the question in the form outlined above.

In continuation of his "program", Hilbert posed three questions at an international conference in 1928, the third of which became known as "Hilbert's ". In 1929, Moses Schönfinkel published one paper on special cases of the decision problem, that was prepared by Paul Bernays.

As late as 1930, Hilbert believed that there would be no such thing as an unsolvable problem.

Before the question could be answered, the notion of "algorithm" had to be formally defined. This was done by Alonzo Church in 1935 with the concept of "effective calculability" based on his λ-calculus, and by Alan Turing the next year with his concept of Turing machines. Turing immediately recognized that these are equivalent models of computation.

A negative answer to the was then given by Alonzo Church in 1935–36 (Church's theorem) and independently shortly thereafter by Alan Turing in 1936 (Turing's proof). Church proved that there is no computable function which decides, for two given λ-calculus expressions, whether they are equivalent or not. He relied heavily on earlier work by Stephen Kleene. Turing reduced the question of the existence of an 'algorithm' or 'general method' able to solve the to the question of the existence of a 'general method' which decides whether any given Turing machine halts or not (the halting problem). If 'algorithm' is understood as meaning a method that can be represented as a Turing machine, and with the answer to the latter question negative (in general), the question about the existence of an algorithm for the also must be negative (in general). In his 1936 paper, Turing says: "Corresponding to each computing machine 'it' we construct a formula 'Un(it)' and we show that, if there is a general method for determining whether 'Un(it)' is provable, then there is a general method for determining whether 'it' ever prints 0".

The work of both Church and Turing was heavily influenced by Kurt Gödel's earlier work on his incompleteness theorem, especially by the method of assigning numbers (a Gödel numbering) to logical formulas in order to reduce logic to arithmetic.

The " is related to Hilbert's tenth problem, which asks for an algorithm to decide whether Diophantine equations have a solution. The non-existence of such an algorithm, established by the work of Yuri Matiyasevich, Julia Robinson, Martin Davis, and Hilary Putnam, with the final piece of the proof in 1970, also implies a negative answer to the "Entscheidungsproblem".

Using the deduction theorem, the Entscheidungsproblem encompasses the more general problem of deciding whether a given first-order sentence is entailed by a given finite set of sentences, but validity in first-order theories with infinitely many axioms cannot be directly reduced to the Entscheidungsproblem. Such more general decision problems are, however, of practical interest. Some first-order theories are algorithmically decidable; examples of this include Presburger arithmetic, real closed fields, and static type systems of many programming languages. On the other hand, the first-order theory of the natural numbers with addition and multiplication expressed by Peano's axioms cannot be decided with an algorithm.

By default, the citations in the section are from Pratt-Hartmann (2023).

The classical "Entscheidungsproblem" asks that, given a first-order formula, whether it is true in all models. The finitary problem asks whether it is true in all finite models. Trakhtenbrot's theorem shows that this is also undecidable.

Some notations: formula_1 means the problem of deciding whether there exists a model for a set of logical formulas formula_2. formula_3 is the same problem, but for "finite" models. The formula_4-problem for a logical fragment is called decidable if there exists a program that can decide, for each formula_2 finite set of logical formulas in the fragment, whether formula_1 or not.

There is a hierarchy of decidabilities. On the top are the undecidable problems. Below it are the decidable problems. Furthermore, the decidable problems can be divided into a complexity hierarchy.

Aristotelean logic considers 4 kinds of sentences: "All p are q", "All p are not q", "Some p is q", "Some p is not q". We can formalize these kinds of sentences as a fragment of first-order logic:formula_7where formula_8 are atomic predicates, and formula_9. Given a finite set of Aristotelean logic formulas, it is NLOGSPACE-complete to decide its formula_4. It is also NLOGSPACE-complete to decide formula_4 for a slight extension (Theorem 2.7):formula_12Relational logic extends Aristotelean logic by allowing a relational predicate. For example, "Everybody loves somebody" can be written as formula_13. Generally, we have 8 kinds of sentences:formula_14It is NLOGSPACE-complete to decide its formula_4 (Theorem 2.15). Relational logic can be extended to 32 kinds of sentences by allowing formula_16, but this extension is EXPTIME-complete (Theorem 2.24).

The first-order logic fragment where the only variable names are formula_17 is NEXPTIME-complete (Theorem 3.18). With formula_18, it is RE-complete to decide its formula_4, and co-RE-complete to decide formula_20 (Theorem 3.15), thus undecidable.

The monadic predicate calculus is the fragment where each formula contains only 1-ary predicates and no function symbols. Its formula_4 is NEXPTIME-complete (Theorem 3.22).

Any first-order formula has a prenex normal form. For each possible quantifier prefix to the prenex normal form, we have a fragment of first-order logic. For example, the Bernays–Schönfinkel class, formula_22, is the class of first-order formulas with quantifier prefix formula_23, equality symbols, and no function symbols.

For example, Turing's 1936 paper (p. 263) observed that since the halting problem for each Turing machine is equivalent to a first-order logical formula of form formula_24, the problem formula_25 is undecidable.

The precise boundaries are known, sharply:


Börger et al. (2001) describes the level of computational complexity for every possible fragment with every possible combination of quantifier prefix, functional arity, predicate arity, and equality/no-equality.

Having practical decision procedures for classes of logical formulas is of considerable interest for program verification and circuit verification. Pure Boolean logical formulas are usually decided using SAT-solving techniques based on the DPLL algorithm.

For more general decision problems of first-order theories, conjunctive formulas over linear real or rational arithmetic can be decided using the simplex algorithm, formulas in linear integer arithmetic (Presburger arithmetic) can be decided using Cooper's algorithm or William Pugh's Omega test. Formulas with negations, conjunctions and disjunctions combine the difficulties of satisfiability testing with that of decision of conjunctions; they are generally decided nowadays using SMT-solving techniques, which combine SAT-solving with decision procedures for conjunctions and propagation techniques. Real polynomial arithmetic, also known as the theory of real closed fields, is decidable; this is the Tarski–Seidenberg theorem, which has been implemented in computers by using the cylindrical algebraic decomposition.



Einhard

Einhard (also Eginhard or Einhart; ; 775 – 14 March 840) was a Frankish scholar and courtier. Einhard was a dedicated servant of Charlemagne and his son Louis the Pious; his main work is a biography of Charlemagne, the "Vita Karoli Magni", "one of the most precious literary bequests of the early Middle Ages".

Einhard was from the eastern German-speaking part of the Frankish Kingdom. Born into a family of landowners of some importance, his parents sent him to be educated by the monks of Fulda, one of the most impressive centers of learning in the Frank lands. Perhaps due to his small stature, which restricted his riding and sword-fighting ability, Einhard concentrated his energies on scholarship, especially the mastering of Latin. He was accepted into the hugely wealthy court of Charlemagne around 791 or 792. Charlemagne actively sought to amass scholarly men around him and established a royal school led by the Northumbrian scholar Alcuin. Einhard was evidently a talented builder and construction manager, because Charlemagne put him in charge of the completion of several palace complexes including Aachen and Ingelheim. Despite the fact that Einhard was on intimate terms with Charlemagne, he never achieved office in his reign. In 814, on Charlemagne's death, his son Louis the Pious made Einhard his private secretary. Einhard retired from court during the time of the disputes between Louis and his sons in the spring of 830.

He died at Seligenstadt in 840.

Einhard was married to Emma, of whom little is known. There is a possibility that their marriage bore a son, Vussin. Their marriage also appears to have been exceptionally liberal for the period, with Emma being as active as Einhard, if not more so, in the handling of their property. It is said that in the later years of their marriage Emma and Einhard abstained from sexual relations, choosing instead to focus their attentions on their many religious commitments. Though he was undoubtedly devoted to her, Einhard wrote nothing of his wife until after her death on 13 December 835, when he wrote to a friend that he was reminded of her loss in ‘every day, in every action, in every undertaking, in all the administration of the house and household, in everything needing to be decided upon and sorted out in my religious and earthly responsibilities’.
Einhard made numerous references to himself as a "sinner" according to his strong Christian faith. He erected churches at both of his estates in Michelstadt and Mulinheim. In Michelstadt, he also saw fit to build a basilica completed in 827 and then sent a servant, Ratleic, to Rome with an end to find relics for the new building. Once in Rome, Ratleic robbed a catacomb of the bones of the Martyrs Marcellinus and Peter and had them translated to Michelstadt. Once there, the relics made it known they were unhappy with their new tomb and thus had to be moved again to Mulinheim. Once established there, they proved to be miracle workers. Although unsure as to why these saints should choose such a "sinner" as their patron, Einhard nonetheless set about ensuring they continued to receive a resting place fitting of their honour. Between 831 and 834 he founded a Benedictine Monastery and, after the death of his wife, served as its Abbot until his own death in 840.

Local lore from Seligenstadt portrays Einhard as the lover of Emma, one of Charlemagne's daughters, and has the couple elope from court. Charlemagne found them at Seligenstadt (then called Obermühlheim) and forgave them. This account is used to explain the name "Seligenstadt" by folk etymology. Einhard and his wife were originally buried in one sarcophagus in the choir of the church in Seligenstadt, but in 1810 the sarcophagus was presented by the Grand Duke of Hesse to the count of Erbach, who claims descent from Einhard as the husband of Imma, the reputed daughter of Charlemagne. The count put it in the famous chapel of his castle at Erbach in the Odenwald.

The most famous of Einhard's works is his biography of Charlemagne, the "Vita Karoli Magni", "The Life of Charlemagne" (c. 817–836), which provides much direct information about Charlemagne's life and character, written sometime between 817 and 830. In composing this he relied heavily upon the Royal Frankish Annals. Einhard's literary model was the classical work of the Roman historian Suetonius, the "Lives of the Caesars", though it is important to stress that the work is very much Einhard's own, that is to say he adapts the models and sources for his own purposes. His work was written as a praise of Charlemagne, whom he regarded as a foster-father ("nutritor") and to whom he was a debtor "in life and death". The work thus contains an understandable degree of bias, Einhard taking care to exculpate Charlemagne in some matters, not mention others, and to gloss over certain issues which would be of embarrassment to Charlemagne, such as the morality of his daughters; by contrast, other issues are curiously not glossed over, like his concubines. 

Einhard is also responsible for three other extant works: a collection of letters, "On the Translations and the Miracles of SS. Marcellinus and Petrus", and "On the Adoration of the Cross". The latter dates from ca. 830 and was not rediscovered until 1885, when Ernst Dümmler identified a text in a manuscript in Vienna as the missing "Libellus de adoranda cruce", which Einhard had dedicated to his pupil Lupus Servatus.

The Arch of Einhard was a reliquary made by Einhard, which reproduced on a small scale a Roman triumphal arch that represented the victory of Christianity. It has not survived.




Ester

In chemistry, an ester is a compound derived from an acid (organic or inorganic) in which the hydrogen atom (H) of at least one acidic hydroxyl group () of that acid is replaced by an organyl group (). Analogues derived from oxygen replaced by other chalcogens belong to the ester category as well. According to some authors, organyl derivatives of acidic hydrogen of other acids are esters as well (e.g. amides), but not according to the IUPAC.

Glycerides are fatty acid esters of glycerol; they are important in biology, being one of the main classes of lipids and comprising the bulk of animal fats and vegetable oils. Lactones are cyclic carboxylic esters; naturally occurring lactones are mainly 5- and 6-membered ring lactones. Lactones contribute to the aroma of fruits, butter, cheese, vegetables like celery and other foods.

Esters can be formed from oxoacids (e.g. esters of acetic acid, carbonic acid, sulfuric acid, phosphoric acid, nitric acid, xanthic acid), but also from acids that do not contain oxygen (e.g. esters of thiocyanic acid and trithiocarbonic acid). An example of an ester formation is the substitution reaction between a carboxylic acid () and an alcohol (), forming an ester (), where R stands for any group (typically hydrogen or organyl) and R stands for organyl group.

Organyl esters of carboxylic acids typically have a pleasant smell; those of low molecular weight are commonly used as fragrances and are found in essential oils and pheromones. They perform as high-grade solvents for a broad array of plastics, plasticizers, resins, and lacquers, and are one of the largest classes of synthetic lubricants on the commercial market. Polyesters are important plastics, with monomers linked by ester moieties. Esters of phosphoric acid form the backbone of DNA molecules. Esters of nitric acid, such as nitroglycerin, are known for their explosive properties.

There are compounds in which an acidic hydrogen of acids mentioned in this article are not replaced by an organyl, but by some other group. According to some authors, those compounds are esters as well, especially when the first carbon atom of the organyl group replacing acidic hydrogen, is replaced by another atom from the group 14 elements (Si, Ge, Sn, Pb); for example, according to them, trimethylstannyl acetate (or trimethyltin acetate) is a trimethylstannyl ester of acetic acid, and dibutyltin dilaurate is a dibutylstannylene ester of lauric acid, and the Phillips catalyst is a trimethoxysilyl ester of chromic acid ().

The word "ester" was coined in 1848 by a German chemist Leopold Gmelin, probably as a contraction of the German , "acetic ether".

The names of esters that are formed from an alcohol and an acid, are derived from the parent alcohol and the parent acid, where the latter may be organic or inorganic. Esters derived from the simplest carboxylic acids are commonly named according to the more traditional, so-called "trivial names" e.g. as formate, acetate, propionate, and butyrate, as opposed to the IUPAC nomenclature methanoate, ethanoate, propanoate, and butanoate. Esters derived from more complex carboxylic acids are, on the other hand, more frequently named using the systematic IUPAC name, based on the name for the acid followed by the suffix "-oate". For example, the ester hexyl octanoate, also known under the trivial name hexyl caprylate, has the formula .

The chemical formulas of organic esters formed from carboxylic acids and alcohols usually take the form or RCOOR', where R and R' are the organyl parts of the carboxylic acid and the alcohol, respectively, and R can be a hydrogen in the case of esters of formic acid. For example, butyl acetate (systematically butyl ethanoate), derived from butanol and acetic acid (systematically ethanoic acid) would be written . Alternative presentations are common including BuOAc and .

Cyclic esters are called lactones, regardless of whether they are derived from an organic or inorganic acid. One example of an organic lactone is γ-valerolactone.

An uncommon class of esters are the orthoesters. One of them are the esters of orthocarboxylic acids. Those esters have the formula , where R stands for any group (organic or inorganic) and R stands for organyl group. For example, triethyl orthoformate () is derived, in terms of its name (but not its synthesis) from esterification of orthoformic acid () with ethanol.

Esters can also be derived from inorganic acids.

Inorganic acids that exist as tautomers form two or more types of esters.

Some inorganic acids that are unstable or elusive form stable esters.

In principle, a part of metal and metalloid alkoxides, of which many hundreds are known, could be classified as esters of the corresponding acids (e.g. aluminium triethoxide () could be classified as an ester of aluminic acid which is aluminium hydroxide, tetraethyl orthosilicate () could be classified as an ester of orthosilicic acid, and titanium ethoxide () could be classified as an ester of orthotitanic acid).

Esters derived from carboxylic acids and alcohols contain a carbonyl group C=O, which is a divalent group at C atom, which gives rise to C–C–O and O–C–O angles. Unlike amides, carboxylic acid esters are structurally flexible functional groups because rotation about the C–O–C bonds has a low barrier. Their flexibility and low polarity is manifested in their physical properties; they tend to be less rigid (lower melting point) and more volatile (lower boiling point) than the corresponding amides. The p"K" of the alpha-hydrogens on esters of carboxylic acids is around 25 (alpha-hydrogen is a hydrogen bound to the carbon adjacent to the carbonyl group (C=O) of carboxylate esters).

Many carboxylic acid esters have the potential for conformational isomerism, but they tend to adopt an "S"-"cis" (or "Z") conformation rather than the "S"-"trans" (or "E") alternative, due to a combination of hyperconjugation and dipole minimization effects. The preference for the "Z" conformation is influenced by the nature of the substituents and solvent, if present. Lactones with small rings are restricted to the "s"-trans (i.e. "E") conformation due to their cyclic structure.

Esters derived from carboxylic acids and alcohols are more polar than ethers but less polar than alcohols. They participate in hydrogen bonds as hydrogen-bond acceptors, but cannot act as hydrogen-bond donors, unlike their parent alcohols. This ability to participate in hydrogen bonding confers some water-solubility. Because of their lack of hydrogen-bond-donating ability, esters do not self-associate. Consequently, esters are more volatile than carboxylic acids of similar molecular weight.

Esters are generally identified by gas chromatography, taking advantage of their volatility. IR spectra for esters feature an intense sharp band in the range 1730–1750 cm assigned to "ν". This peak changes depending on the functional groups attached to the carbonyl. For example, a benzene ring or double bond in conjugation with the carbonyl will bring the wavenumber down about 30 cm.

Esters are widespread in nature and are widely used in industry. In nature, fats are, in general, triesters derived from glycerol and fatty acids. Esters are responsible for the aroma of many fruits, including apples, durians, pears, bananas, pineapples, and strawberries. Several billion kilograms of polyesters are produced industrially annually, important products being polyethylene terephthalate, acrylate esters, and cellulose acetate.

Esterification is the general name for a chemical reaction in which two reactants (typically an alcohol and an acid) form an ester as the reaction product. Esters are common in organic chemistry and biological materials, and often have a pleasant characteristic, fruity odor. This leads to their extensive use in the fragrance and flavor industry. Ester bonds are also found in many polymers.

The classic synthesis is the Fischer esterification, which involves treating a carboxylic acid with an alcohol in the presence of a dehydrating agent:
The equilibrium constant for such reactions is about 5 for typical esters, e.g., ethyl acetate. The reaction is slow in the absence of a catalyst. Sulfuric acid is a typical catalyst for this reaction. Many other acids are also used such as polymeric sulfonic acids. Since esterification is highly reversible, the yield of the ester can be improved using Le Chatelier's principle:

Reagents are known that drive the dehydration of mixtures of alcohols and carboxylic acids. One example is the Steglich esterification, which is a method of forming esters under mild conditions. The method is popular in peptide synthesis, where the substrates are sensitive to harsh conditions like high heat. DCC (dicyclohexylcarbodiimide) is used to activate the carboxylic acid to further reaction. 4-Dimethylaminopyridine (DMAP) is used as an acyl-transfer catalyst.

Another method for the dehydration of mixtures of alcohols and carboxylic acids is the Mitsunobu reaction:

Carboxylic acids can be esterified using diazomethane:
Using this diazomethane, mixtures of carboxylic acids can be converted to their methyl esters in near quantitative yields, e.g., for analysis by gas chromatography. The method is useful in specialized organic synthetic operations but is considered too hazardous and expensive for large-scale applications.

Carboxylic acids are esterified by treatment with epoxides, giving β-hydroxyesters:
This reaction is employed in the production of vinyl ester resin from acrylic acid.

Alcohols react with acyl chlorides and acid anhydrides to give esters:

The reactions are irreversible simplifying work-up. Since acyl chlorides and acid anhydrides also react with water, anhydrous conditions are preferred. The analogous acylations of amines to give amides are less sensitive because amines are stronger nucleophiles and react more rapidly than does water. This method is employed only for laboratory-scale procedures, as it is expensive.

Trimethyloxonium tetrafluoroborate can be used for esterification of carboxylic acids under conditions where acid-catalyzed reactions are infeasible: 
Although rarely employed for esterifications, carboxylate salts (often generated "in situ") react with electrophilic alkylating agents, such as alkyl halides, to give esters. Anion availability can inhibit this reaction, which correspondingly benefits from phase transfer catalysts or such highly polar aprotic solvents as DMF. An additional iodide salt may, via the Finkelstein reaction, catalyze the reaction of a recalcitrant alkyl halide. Alternatively, salts of a coordinating metal, such as silver, may improve the reaction rate by easing halide elimination.

Transesterification, which involves changing one ester into another one, is widely practiced:
Like the hydrolysation, transesterification is catalysed by acids and bases. The reaction is widely used for degrading triglycerides, e.g. in the production of fatty acid esters and alcohols. Poly(ethylene terephthalate) is produced by the transesterification of dimethyl terephthalate and ethylene glycol: 

A subset of transesterification is the alcoholysis of diketene. This reaction affords 2-ketoesters.

Alkenes undergo "hydroesterification" in the presence of metal carbonyl catalysts. Esters of propanoic acid are produced commercially by this method:
A preparation of methyl propionate is one illustrative example. 

The carbonylation of methanol yields methyl formate, which is the main commercial source of formic acid. The reaction is catalyzed by sodium methoxide:

In hydroesterification, alkenes and alkynes insert into the bond of carboxylic acids. Vinyl acetate is produced industrially by the addition of acetic acid to acetylene in the presence of zinc acetate catalysts: Presently, zinc acetate is used as the catalyst:

Vinyl acetate can also be produced by palladium-catalyzed reaction of ethylene, acetic acid, and oxygen:

Silicotungstic acid is used to manufacture ethyl acetate by the alkylation of acetic acid by ethylene:

The Tishchenko reaction involve disproportionation of an aldehyde in the presence of an anhydrous base to give an ester. Catalysts are aluminium alkoxides or sodium alkoxides. Benzaldehyde reacts with sodium benzyloxide (generated from sodium and benzyl alcohol) to generate benzyl benzoate. The method is used in the production of ethyl acetate from acetaldehyde.


Esters react with nucleophiles at the carbonyl carbon. The carbonyl is weakly electrophilic but is attacked by strong nucleophiles (amines, alkoxides, hydride sources, organolithium compounds, etc.). The C–H bonds adjacent to the carbonyl are weakly acidic but undergo deprotonation with strong bases. This process is the one that usually initiates condensation reactions. The carbonyl oxygen in esters is weakly basic, less so than the carbonyl oxygen in amides due to resonance donation of an electron pair from nitrogen in amides, but forms adducts.

Esterification is a reversible reaction. Esters undergo hydrolysis under acidic and basic conditions. Under acidic conditions, the reaction is the reverse reaction of the Fischer esterification. Under basic conditions, hydroxide acts as a nucleophile, while an alkoxide is the leaving group. This reaction, saponification, is the basis of soap making.

The alkoxide group may also be displaced by stronger nucleophiles such as ammonia or primary or secondary amines to give amides: (ammonolysis reaction)
This reaction is not usually reversible. Hydrazines and hydroxylamine can be used in place of amines. Esters can be converted to isocyanates through intermediate hydroxamic acids in the Lossen rearrangement.

Sources of carbon nucleophiles, e.g., Grignard reagents and organolithium compounds, add readily to the carbonyl.

Compared to ketones and aldehydes, esters are relatively resistant to reduction. The introduction of catalytic hydrogenation in the early part of the 20th century was a breakthrough; esters of fatty acids are hydrogenated to fatty alcohols.
A typical catalyst is copper chromite. Prior to the development of catalytic hydrogenation, esters were reduced on a large scale using the Bouveault–Blanc reduction. This method, which is largely obsolete, uses sodium in the presence of proton sources.

Especially for fine chemical syntheses, lithium aluminium hydride is used to reduce esters to two primary alcohols. The related reagent sodium borohydride is slow in this reaction. DIBAH reduces esters to aldehydes.

Direct reduction to give the corresponding ether is difficult as the intermediate hemiacetal tends to decompose to give an alcohol and an aldehyde (which is rapidly reduced to give a second alcohol). The reaction can be achieved using triethylsilane with a variety of Lewis acids.

As for aldehydes, the hydrogen atoms on the carbon adjacent ("α to") the carboxyl group in esters are sufficiently acidic to undergo deprotonation, which in turn leads to a variety of useful reactions. Deprotonation requires relatively strong bases, such as alkoxides. Deprotonation gives a nucleophilic enolate, which can further react, e.g., the Claisen condensation and its intramolecular equivalent, the Dieckmann condensation. This conversion is exploited in the malonic ester synthesis, wherein the diester of malonic acid reacts with an electrophile (e.g., alkyl halide), and is subsequently decarboxylated. Another variation is the Fráter–Seebach alkylation.


As a class, esters serve as protecting groups for carboxylic acids. Protecting a carboxylic acid is useful in peptide synthesis, to prevent self-reactions of the bifunctional amino acids. Methyl and ethyl esters are commonly available for many amino acids; the "t"-butyl ester tends to be more expensive. However, "t"-butyl esters are particularly useful because, under strongly acidic conditions, the "t"-butyl esters undergo elimination to give the carboxylic acid and isobutylene, simplifying work-up.

Esters react with strong oxidizing acids, which may cause a violent reaction that is sufficiently exothermic to ignite the esters and the reaction products. Heat is also generated by the interaction of esters with alkali solutions. Very flammable hydrogen gas is generated by mixing esters with alkali metals and ionic hydrides.

Many esters have distinctive fruit-like odors, and many occur naturally in the essential oils of plants. This has also led to their common use in artificial flavorings and fragrances which aim to mimic those odors.



Endosymbiont

An endosymbiont or endobiont is any organism that lives within the body or cells of another organism most often, though not always, in a mutualistic relationship. This phenomenon is known as endosymbiosis (from the Greek: ἔνδον "endon" "within", σύν "syn" "together" and βίωσις "biosis" "living"). Examples are nitrogen-fixing bacteria (called rhizobia), which live in the root nodules of legumes, single-cell algae inside reef-building corals and bacterial endosymbionts that provide essential nutrients to insects.

The history behind the concept of endosymbiosis stems from the postulates of the endosymbiotic theory. The endosymbiotic theory (symbiogenesis) pushes the notion of bacteria exclusively living in eukaryotic organisms after being engulfed by them. This is popular with the concept of organelle development observed with eukaryotes. Two major types of organelle in eukaryotic cells, mitochondria and plastids such as chloroplasts, are considered to be obtained from bacterial endosymbionts.

There are two main types of symbiont transmissions. In horizontal transmission, each new generation acquires free living symbionts from the environment. An example is the nitrogen-fixing bacteria in certain plant roots. Vertical transmission takes place when the symbiont is transferred directly from parent to offspring. An example is pea aphid symbionts. Also, it is possible for both to be involved in a mixed-mode transmission, where symbionts are transferred vertically for some generation before a switch of host occurs and new symbionts are horizontally acquired from the environment. Other examples include "Wigglesworthia" nutritional symbionts of tse-tse flies, or in sponges. When a symbiont reaches this stage, it begins to resemble a cellular organelle, similar to mitochondria or chloroplasts.

Many instances of endosymbiosis are obligate; that is, either the endosymbiont or the host cannot survive without the other, such as the gutless marine worms of the genus "Riftia", which obtain nutrition from their endosymbiotic bacteria. The most common examples of obligate endosymbioses are mitochondria and chloroplasts. Some human parasites, e.g. "Wuchereria bancrofti" and "Mansonella perstans", thrive in their intermediate insect hosts because of an obligate endosymbiosis with "Wolbachia spp." They can both be eliminated from hosts by treatments that target this bacterium. However, not all endosymbioses are obligate and some endosymbioses can be harmful to either of the organisms involved.

Symbiogenesis explains the origins of eukaryotes, whose cells contain two major kinds of organelle: mitochondria and chloroplasts. The theory proposes that these organelles evolved from certain types of bacteria that eukaryotic cells engulfed through phagocytosis. These cells and the bacteria trapped inside them entered an endosymbiotic relationship, meaning that the bacteria took up residence and began living exclusively within the eukaryotic cells.

Numerous insect species have endosymbionts at different stages of symbiogenesis. A common theme of symbiogenesis involves the reduction of the genome to only essential genes for the host and symbiont collective genome. A remarkable example of this is the fractionation of the "Hodgkinia" genome of "Magicicada" cicadas. Because the cicada life cycle takes years underground, natural selection on endosymbiont populations is relaxed for many bacterial generations. This allows the symbiont genomes to diversify within the host for years with only punctuated periods of selection when the cicadas reproduce. As a result, the ancestral "Hodgkinia" genome has split into three groups of primary endosymbiont, each encoding only a fraction of the essential genes for the symbiosis—an instance of punctuated equilibrium producing distinct lineages of the symbiont. The host now requires all three sub-groups of symbiont, each with degraded genomes lacking most essential genes for bacterial viability.

Symbiont transmission is the process where the host in a symbiotic relationship between two organisms acquires an organism (internally or externally) that serves as its symbiont. Most symbionts are either obligatory (require their host to survive) or facultative (do not necessarily need their host to survive). Many instances of endosymbiosis are obligate; that is, either the endosymbiont or the host cannot survive without the other, such as the gutless marine worms of the genus "Riftia", which get nutrition from their endosymbiotic bacteria. The most common examples of obligate endosymbiosis are mitochondria and chloroplasts. Some human parasites, e.g. "Wuchereria bancrofti" and "Mansonella perstans", thrive in their intermediate insect hosts because of an obligate endosymbiosis with "Wolbachia" spp. They can both be eliminated from hosts by treatments that target this bacterium.

Horizontal (lateral), vertical, and mix-mode (hybrid of horizonal and vertical) transmission are the three paths for symbiont transfer. Horizontal symbiont transfer (horizontal transmission) is a process where a host acquires a facultative symbiont from the environment or from another host. The Rhizobia-Legume symbiosis (bacteria-plant endosymbiosis) is a prime example of horizontal symbiont transmission. The Rhizobia-legume symbiotic relationship is important for processes like the formation of root nodules. It starts with flavonoids released by the plant host (Legume), which causes the rhizobia species (endosymbiont) to activate its "nod" genes. These "Nod" genes generate lipooligosaccharide signals which the legume(host) detects, thus leading to root nodule formation. This process bleeds on to other unique processes like nitrogen fixation in plants. The evolutionary advantage of such an interaction allows genetic exchange between both organisms involved increasing the propensity for novel functions as seen in the plant-bacterium interaction (holobiont formation).

In vertical transmission, the symbionts often have a reduced genome and are no longer able to survive on their own. As a result, the symbiont depends on the host, resulting in a highly intimate co-dependent relationship. For instance, pea aphid symbionts have lost genes for essential molecules, now relying on the host to supply them with nutrients. In return, the symbionts synthesize essential amino acids for the aphid host. Other examples include "Wigglesworthia" nutritional symbionts of tsetse flies, or in sponges. When a symbiont reaches this stage, it begins to resemble a cellular organelle, similar to mitochondria or chloroplasts. The evolutionary consequences causes the host and the symbiont to be dependent and form a holobiont, and in the event of a bottleneck a decrease in symbiont diversity could affect the host-symbiont interactions adversely, when deleterious mutations build up over time.

The best-studied examples of endosymbiosis are known from invertebrates. These symbioses affect organisms with global impact, including "Symbiodinium" of corals, or "Wolbachia" of insects. Many insect agricultural pests and human disease vectors have intimate relationships with primary endosymbionts.

Scientists classify insect endosymbionts in two broad categories, 'Primary' and 'Secondary'. Primary endosymbionts (sometimes referred to as P-endosymbionts) have been associated with their insect hosts for many millions of years (from 10 to several hundred million years in some cases). They form obligate associations (see below), and display cospeciation with their insect hosts. Secondary endosymbionts exhibit a more recently developed association, are sometimes horizontally transferred between hosts, live in the hemolymph of the insects (not specialized bacteriocytes, see below), and are not obligate.

Among primary endosymbionts of insects, the best-studied are the pea aphid ("Acyrthosiphon pisum") and its endosymbiont "Buchnera sp." APS, the tsetse fly "Glossina morsitans morsitans" and its endosymbiont "Wigglesworthia glossinidia brevipalpis" and the endosymbiotic protists in lower termites. As with endosymbiosis in other insects, the symbiosis is obligate in that neither the bacteria nor the insect is viable without the other. Scientists have been unable to cultivate the bacteria in lab conditions outside of the insect. With special nutritionally-enhanced diets, the insects can survive, but are unhealthy, and at best survive only a few generations.

In some insect groups, these endosymbionts live in specialized insect cells called bacteriocytes (also called "mycetocytes"), and are maternally-transmitted, i.e. the mother transmits her endosymbionts to her offspring. In some cases, the bacteria are transmitted in the egg, as in "Buchnera"; in others like "Wigglesworthia", they are transmitted via milk to the developing insect embryo. In termites, the endosymbionts reside within the hindguts and are transmitted through trophallaxis among colony members.

The primary endosymbionts are thought to help the host either by providing nutrients that the host cannot obtain itself or by metabolizing insect waste products into safer forms. For example, the putative primary role of "Buchnera" is to synthesize essential amino acids that the aphid cannot acquire from its natural diet of plant sap. Likewise, the primary role of "Wigglesworthia", it is presumed, is to synthesize vitamins that the tsetse fly does not get from the blood that it eats. In lower termites, the endosymbiotic protists play a major role in the digestion of lignocellulosic materials that constitute a bulk of the termites' diet.

Bacteria benefit from the reduced exposure to predators and competition from other bacterial species, the ample supply of nutrients and relative environmental stability inside the host.

Genome sequencing reveals that obligate bacterial endosymbionts of insects have among the smallest of known bacterial genomes and have lost many genes that are commonly found in closely related bacteria. Several theories have been put forth to explain the loss of genes. It is presumed that some of these genes are not needed in the environment of the host insect cell. A complementary theory suggests that the relatively small numbers of bacteria inside each insect decrease the efficiency of natural selection in 'purging' deleterious mutations and small mutations from the population, resulting in a loss of genes over many millions of years. Research in which a parallel phylogeny of bacteria and insects was inferred supports the belief that the primary endosymbionts are transferred only vertically (i.e., from the mother), and not horizontally (i.e., by escaping the host and entering a new host).

Attacking obligate bacterial endosymbionts may present a way to control their insect hosts, many of which are pests or carriers of human disease. For example, aphids are crop pests and the tsetse fly carries the organism "Trypanosoma brucei" that causes African sleeping sickness. Other motivations for their study involve understanding the origins of symbioses in general, as a proxy for understanding e.g. how chloroplasts or mitochondria came to be obligate symbionts of eukaryotes or plants.

The pea aphid ("Acyrthosiphon pisum") is known to contain at least three secondary endosymbionts, "Hamiltonella defensa", "Regiella insecticola", and "Serratia symbiotica". "Hamiltonella defensa" defends its aphid host from parasitoid wasps. This defensive symbiosis improves the survival of aphids, which have lost some elements of the insect immune response.

One of the best-understood defensive symbionts is the spiral bacteria "Spiroplasma poulsonii". "Spiroplasma sp." can be reproductive manipulators, but also defensive symbionts of "Drosophila" flies. In "Drosophila neotestacea", "S. poulsonii" has spread across North America owing to its ability to defend its fly host against nematode parasites. This defence is mediated by toxins called "ribosome-inactivating proteins" that attack the molecular machinery of invading parasites. These "Spiroplasma" toxins represent one of the first examples of a defensive symbiosis with a mechanistic understanding for defensive symbiosis between an insect endosymbiont and its host.

"Sodalis glossinidius" is a secondary endosymbiont of tsetse flies that lives inter- and intracellularly in various host tissues, including the midgut and hemolymph. Phylogenetic studies have not indicated a correlation between evolution of "Sodalis" and tsetse. Unlike tsetse's primary symbiont "Wigglesworthia", though, "Sodalis" has been cultured "in vitro".

Many other insects have secondary endosymbionts not reviewed here.

The best-studied endosymbiont of ants are bacteria of the genus Blochmannia, which are the primary endosymbiont of "Camponotus" ants. In 2018 a new ant-associated symbiont was discovered in "Cardiocondyla" ants. This symbiont was named Candidatus Westeberhardia Cardiocondylae and it is also believed to be a primary symbiont.

Extracellular endosymbionts are also represented in all four extant classes of Echinodermata (Crinoidea, Ophiuroidea, Echinoidea, and Holothuroidea). Little is known of the nature of the association (mode of infection, transmission, metabolic requirements, etc.) but phylogenetic analysis indicates that these symbionts belong to the class Alphaproteobacteria, relating them to "Rhizobium" and "Thiobacillus". Other studies indicate that these subcuticular bacteria may be both abundant within their hosts and widely distributed among the Echinoderms in general.

Some marine oligochaeta (e.g., "Olavius algarvensis" and "Inanidrillus spp.") have obligate extracellular endosymbionts that fill the entire body of their host. These marine worms are nutritionally dependent on their symbiotic chemoautotrophic bacteria lacking any digestive or excretory system (no gut, mouth, or nephridia).

The sea slug "Elysia chlorotica" lives in endosymbiotic relationship with the algae "Vaucheria litorea", and the jellyfish "Mastigias" have a similar relationship with an algae. "Elysia chlorotica" forms this relationship intracellularly with the chloroplasts from the algae. These chloroplast retain their photosynthetic capabilities and structures for several months after being taken into the cells of the slug.

The very simple animal "Trichoplax" have two bacterial endosymbionts. One of them is called Ruthmannia, and lives inside the animal's digestive cells. The other is Grellia which lives permanently inside the endoplasmic reticulum (ER) of Trichoplax, the first known symbiont to do so. 

"Paracatenula" is a flatworm which have lived in symbiosis with an endosymbiotic bacteria for 500 million years. The bacteria, which have lost much of its genome as a symbiont, produce numerous small, droplet-like vesicles which provide the host with all the nutrients it needs.

Dinoflagellate endosymbionts of the genus "Symbiodinium", commonly known as zooxanthellae, are found in corals, mollusks (esp. giant clams, the "Tridacna"), sponges, and the unicellular foraminifera. These endosymbionts drive the formation of coral reefs by capturing sunlight and providing their hosts with energy for carbonate deposition.

Previously thought to be a single species, molecular phylogenetic evidence over the past couple decades has shown there to be great diversity in "Symbiodinium". In some cases, there is specificity between host and "Symbiodinium" clade. More often, however, there is an ecological distribution of "Symbiodinium", the symbionts switching between hosts with apparent ease. When reefs become environmentally stressed, this distribution of symbionts is related to the observed pattern of coral bleaching and recovery. Thus, the distribution of "Symbiodinium" on coral reefs and its role in coral bleaching presents one of the most complex and interesting current problems in reef ecology.

In marine environments, bacterial endosymbionts have more recently been discovered. These endosymbiotic relationships are especially prevalent in oligotrophic or nutrient-poor regions of the ocean like that of the North Atlantic. In these oligotrophic waters, cell growth of larger phytoplankton like that of diatoms is limited by low nitrate concentrations.  Endosymbiotic bacteria fix nitrogen for their diatom hosts and in turn receive organic carbon from photosynthesis. These symbioses play an important role in global carbon cycling in oligotrophic regions.

One known symbiosis between the diatom "Hemialus" spp. and the cyanobacterium "Richelia intracellularis" has been found in the North Atlantic, Mediterranean, and Pacific Ocean. The "Richelia" endosymbiont is found within the diatom frustule of "Hemiaulus" spp., and has a reduced genome likely losing genes related to pathways the host now provides.  Research by Foster et al. (2011) measured nitrogen fixation by the cyanobacterial host "Richelia intracellularis" well above intracellular requirements, and found the cyanobacterium was likely fixing excess nitrogen for Hemiaulus host cells. Additionally, both host and symbiont cell growth were much greater than free-living "Richelia intracellularis" or symbiont-free "Hemiaulus" spp. The "Hemaiulus"-"Richelia" symbiosis is not obligatory especially in areas with excess nitrogen (nitrogen replete).

"Richelia intracellularis" is also found in "Rhizosolenia" spp., a diatom found in oligotrophic oceans. Compared to the "Hemaiulus" host, the endosymbiosis with "Rhizosolenia" is much more consistent, and "Richelia intracellularis" is generally found in "Rhizosolenia". There are some asymbiotic (occurs without an endosymbiont) Rhizosolenia, however there appears to be mechanisms limiting growth of these organisms in low nutrient conditions. Cell division for both the diatom host and cyanobacterial symbiont can be uncoupled and mechanisms for passing bacterial symbionts to daughter cells during cell division are still relatively unknown.

Other endosymbiosis with nitrogen fixers in open oceans include "Calothrix" in "Chaetoceros" spp. and UNCY-A in prymnesiophyte microalga.  The "Chaetoceros"-"Calothrix" endosymbiosis is hypothesized to be more recent, as the "Calothrix" genome is generally intact. While other species like that of the UNCY-A symbiont and Richelia have reduced genomes. This reduction in genome size occurs within nitrogen metabolism pathways indicating endosymbiont species are generating nitrogen for their hosts and losing the ability to use this nitrogen independently. This endosymbiont reduction in genome size, might be a step that occurred in the evolution of organelles (above).

"Mixotricha paradoxa" is a protozoan that lacks mitochondria. However, spherical bacteria live inside the cell and serve the function of the mitochondria. "Mixotricha" also has three other species of symbionts that live on the surface of the cell.

"Paramecium bursaria", a species of ciliate, has a mutualistic symbiotic relationship with green alga called "Zoochlorella". The algae live inside the cell, in the cytoplasm.

"Platyophrya chlorelligera" is a freshwater ciliate which harbors Chlorella that performs photosynthesis.

"Strombidium purpureum", a marine ciliate which use endosymbiotic purple non-sulphur bacteria for anoxygenic photosynthesis.

"Paulinella chromatophora" is a freshwater amoeboid which has recently (evolutionarily speaking) taken on a cyanobacterium as an endosymbiont.

Many foraminifera are hosts to several types of algae, such as red algae, diatoms, dinoflagellates and chlorophyta. These endosymbionts can be transmitted vertically to the next generation via asexual reproduction of the host, but because the endosymbionts are larger than the foraminiferal gametes, they need to acquire new algae again after sexual reproduction.

Several species of radiolaria have photosynthetic symbionts. In some species the host will sometimes digest algae to keep their population at a constant level.

"Hatena arenicola" is a flagellate protist with a complicated feeding apparaturs that feed on other microbes. But when it engulfs a green alga from the genus "Nephroselmis", the feeding apparatus disappears and it becomes photosynthetic. During mitosis the algae is transferred to only one of the two cells, and the cell without the algae needs to start the cycle all over again.

In 1966, biologist Kwang W. Jeon found that a lab strain of "Amoeba proteus" had been infected by bacteria that lived inside the cytoplasmic vacuoles. This infection killed all the protists except for a few individuals. After the equivalent of 40 host generations, the two organisms gradually became mutually interdependent. Over many years of study, it has been confirmed that a genetic exchange between the prokaryotes and protists had occurred.

The spotted salamander ("Ambystoma maculatum") lives in a relationship with the algae "Oophila amblystomatis", which grows in the egg cases.

Plants are diverse photosynthetic eukaryotes having wide variety of cell morphologies and lifestyles. Plants are considered one of the primary producers. Plants with all photosynthetic eukaryotes are dependent on an intracellular organelle known as plastid or chloroplast (in case of plants and green algae). The chloroplast is derived from a cyanobacterial primary endosymbiosis over one billion years ago. The oxygenic photosynthetic free-living cyanobacterium was engulfed and kept by a heterotrophic protist and eventually evolved into the present intracellular organelle over the course of many years.  

The plant symbioses can be categorized into epiphytic, endophytic, and mycorrhizal. The mycorrhizal category is only used for fungi. The endosymbiosis relation of plants and endosymbionts can also be categorized into beneficial, mutualistic, neutral, and pathogenic. Typically, most of the studies related to plant symbioses or plant endosymbionts such as endophytic bacteria or fungi, are focused on a single category or specie to better understand the biological processes and functions one at a time. But this approach is not helping to understand the complex endosymbiotic interactions and biological functions in natural habitat. Microorganisms living in association as endosymbionts with plants can enhance the primary productivity of plants either by producing or capturing the limiting resources. These endosymbionts can also enhance the productivity of plants by the production of toxic metabolites helping plant defenses against herbivores . Although, the role and potential of microorganisms in community regulations has been neglected since long, may because of the microscopic size and unseen lifestyle. Theoretically, all the vascular plants harbor endosymbionts (e.g., fungi and bacteria). these endosymbionts colonize the plants cells and tissue predominantly but not exclusively. Plant endosymbionts can be categorized into different types based on the function, relation and location, some common plant endosymbionts are discussed as follow.

Plant endosymbionts, also called endophytes, include bacteria, fungi, viruses, protozoa and even microalgae. Endophytes help plant in biological processes such as growth and development, nutrient uptake and defense against biotic and abiotic stresses like drought, salinity, heat, and herbivores.

All vascular plants have fungal and bacterial endophytes or endosymbionts which colonize predominantly but not exclusively, roots. Fungal endosymbionts can be found all out the plant tissues and based on their location in the plant, fungal endosymbionts can be defined in multiple ways like fungi living in plant tissues above the ground are termed as endophytes, while fungi living below the ground (roots) are known as mycorrhizal, but the mycorrhizal fungi also have different names based on their location inside the root which are ecto, endo, arbuscular, ericoid, etc. Furthermore, the fungal endosymbionts living in the roots and extending their extraradical hyphae into the outer rhizosphere are known as ectendosymbionts.

Among the plant microbial endosymbionts arbuscular mycorrhizal fungi or AMF are the most diverse group. With some exceptions Ericaceae family, almost all vascular plants are harboring the AMF endosymbionts both as endo and ecto as well. The AMF plant endosymbionts systematically colonize the plant roots and helping plant host by soil nutrients and as a return it takes the plant organic carbon sources. Plant roots exudates contain a diversity of secondary metabolites especially flavonoids and strigolactones which acts as chemical signals and attracts the AMF. Arbuscular mycyrrizal fungus "Gigaspora margarita" not only lives as a plant endosymbiont but also harbor further endosymbiont intracytoplasmic bacterium-like organisms. By isolating the pure cultures of AMF endosymbionts, it has been reported that it has different effects to the different plant hosts. By introducing the AMF of one plant can reduce the net growth of the other plant host which might have to do something with already present AMF. Furthermore, the AMF are reported in numerous studies as plant health and growth promoting and as an alleviating agent for abiotic stresses like salinity, drought, heat, poor nutrition and metal toxicity.

In addition to mycorrhizal endosymbionts, the endophytic fungi are also catching the interest of scientist by showing so much potential not only in its mutualistic relation where it is benefiting host plant and taking advantages as well but also showing promising results in other domains like helping plant to grow in polluted environment such as high polluted environment with toxic metals. Fungal endophytes are taxonomically diverse group of omnipresent fungi which is divided into different categories based on mode of transmission, biodiversity, in planta colonization and host plant type. These categories are clavicipitaceous and non-clavicipitaceous, the former one systematically colonizes the temperate season grasses while the later one colonizes higher plants and even roots and that’s why can be divided into further categories. "Bacillus amyloliquefaciens" is a seed born endophytic fungi which produces gibberellins and promotes the physiology. "Bacillus amyloliquefaciens" has been evaluated in a study for its growth promoting potential where it promotes the longer height of transgenic dwarf rice plants. Similarly, "Aureobasidium "and "preussia" species of endophytic fungi isolated from Boswellia sacra are producing indole acetic acid hormone to promote plant health and development.

Aphids are most common insects and can be found in most of the plants and carnivorous ladybirds are the specialized predators of the aphids. These ladybirds are used in different programs for the pest control. A study conducted on the effect of plant-endophyte symbiosis on the population and fitness of carnivorous ladybirds. The plant endophytic fungus "Neotyphodium lolii" is producing alkaloid mycotoxins in response to aphid invasions. The ladybirds picking on the aphids from the infected plants exhibited reduced rate of fertility and abnormal reproductive performance. Adult ladybirds were not significantly affected in terms of their body symmetries and size. But the consistently strong negative effects of endophytes overall fitness of ladybirds suggest that the mycotoxins are transmitted along the food chain and effecting the top predators.

Endophytic bacteria belong to a diverse group of plant endosymbionts and characterized by systematically colonization of plant internal tissues. Endophytic bacteria most common genera include "Pseudomonas", "Bacillus", "Acinetobacter", "Actinobacteria", "Sphingomonas." Some endophytic bacteria genera additionally belong to the Enterobacteriaceae family (Pirttila and Frank, 2011). Endophytic bacteria mostly colonize the leaf tissues from plant roots, but can also enter the plant through the leaves through leaf stomata (Senthilkumar et al., 2011).Generally, the endophytic bacteria are isolated from the plant tissues by surface sterilization of the plant tissue in a sterile environment.  Moreover, the isolation of endophytic bacteria according to their essential needs in niche occupations has been explored. That’s why the endophytic bacterial community can be divided into "passenger" and "true" endophytes. The passenger endophytic bacteria are those who eventually colonize inner tissue of plant by stochastic events while the true endophytes possess adaptive traits because of which they live in association with plants strictly. the in vitro cultivated endophytic bacteria association with plant is considered a more intimate relationship where it helps plant acclimatize to the conditions and promotes health and growth. The endophytic bacteria are considered as plant's essential endosymbionts because virtually all plants harbor it, and these endosymbionts play essential roles in host plant survival. This plant-endosymbiont relation is important in terms of ecology, evolution and diversity. Moreover, the endophytic bacteria such as "Sphingomonas" sp. and "Serratia" sp. being isolated from arid land plants regulate endogenous hormone content and promote growth in crop plants.

Archaea are members of most microbiomes. While archaea are highly abundant in extreme environments, they are less abundant and diverse in association with eukaryotic hosts. Nevertheless, archaea are a substantial constituent of plant-associated ecosystems in the aboveground and belowground phytobiome, and play a role in host plant’s health, growth and survival in biotic and abiotic stresses. However, only a few studies have investigated the role of archaea in plant health and its potential symbiosis in ecosystems. Generally, most of the plant endosymbiont related studies focus on fungal or bacterial endosymbionts using metagenomic approaches.

The characterization of archaea is not only limited to crop plants like rice and maize but also identified in many aquatic plant species. The abundance of archaea is different in different tissues for example archaea are more abundant in the rhizosphere than the phyllosphere and endosphere. This archaeal abundance is highly associated with plant species type, environment and plant’s developmental stage. In a study conducted on the detection of plant-genotype specific archaeal and bacterial endophytes, 35% of archaeal sequences were detected in overall sequences (achieved using amplicon sequencing and verified by real time-PCR). The archaeal sequences belong to the phyla "Thaumarchaeota", "Crenarchaeota," and "Euryarchaeota".

Some Betaproteobacteria have Gammaproteobacteria endosymbionts.

Fungi harbor endohyphal bacteria; however, the effects of the bacteria on the fungi are not well studied. Many fungi that harbor these endohyphal bacteria in turn live within plants. These fungi are otherwise known as fungal endophytes. It is hypothesized that the fungi offers a safe haven for the bacteria, and diverse bacteria colonize these refugia creating a micro-ecosystem. These interactions are important because they may impact the way that fungi interact with the environment by modulating their phenotypes.

The way in which the bacteria do this is by altering the gene expression of the fungi. For example, "Luteibacter" sp. has been shown to naturally infect the ascomycetous endophyte "Pestalotiopsis" sp. isolated from "Platycladus orientalis." The "Luteibacter" sp. influences the auxin and enzyme production within its host, which, in turn, may influence the effect the fungus has on its plant host"." Another interesting example of a bacteria living in symbiosis with a fungus is with the fungus "Mortierella." This soil-dwelling fungus lives in close association with a toxin-producing bacteria, "Mycoavidus", which helps the fungus to defend against nematodes. This is a very new, but potentially very important, area of study within the study of symbiosis.

The human genome project found several thousand endogenous retroviruses, endogenous viral elements in the genome that closely resemble and can be derived from retroviruses, organized into 24 families.

Exponential function

The exponential function is a mathematical function denoted by formula_1 or formula_2 (where the argument is written as an exponent). Unless otherwise specified, the term generally refers to the positive-valued function of a real variable, although it can be extended to the complex numbers or generalized to other mathematical objects like matrices or Lie algebras. The exponential function originated from the operation of taking powers of a number (repeated multiplication), but various modern definitions allow it to be rigorously extended to all real arguments formula_3, including irrational numbers. Its ubiquitous occurrence in pure and applied mathematics led mathematician Walter Rudin to consider the exponential function to be "the most important function in mathematics". 

The functions formula_4 for positive real numbers formula_5 are also known as exponential functions, and satisfy the exponentiation identity:formula_6This implies formula_7 (with formula_8 factors) for positive integers formula_8, where formula_10, relating exponential functions to the elementary notion of exponentiation. The natural base formula_11 is a ubiquitous mathematical constant called Euler's number. To distinguish it, formula_12 is called "the" exponential function or the natural exponential function: it is the unique real-valued function of a real variable whose derivative is itself and whose value at is : formula_13 for all formula_14, and formula_15The relation formula_16 for formula_17 and real or complex formula_3 allows general exponential functions to be expressed in terms of the natural exponential.

More generally, especially in applied settings, any function formula_19 defined by 

formula_20

is also known as an exponential function, as it solves the initial value problem formula_21, meaning its rate of change at each point is proportional to the value of the function at that point. This behavior models diverse phenomena in the biological, physical, and social sciences, for example the unconstrained growth of a self-reproducing population, the decay of a radioactive element, the compound interest accruing on a financial fund, or a growing body of manufacturing expertise.

The real exponential function can also be defined as a power series, which is readily extended to complex arguments to define the complex exponential function formula_22. This function takes on all complex values except for 0 and is closely related to the complex trigonometric functions, as shown by Euler's formula: formula_23 Motivated by its more abstract properties and characterizations, the exponential function can be generalized to much larger contexts such as square matrices and Lie groups. Even further, the differential equation definition can be generalized to a Riemannian manifold.

The real exponential function is a bijection from formula_24 to the interval formula_25. Its inverse function is the natural logarithm, denoted formula_26, formula_27, or formula_28, and some old texts called it the "antilogarithm". 
The graph of formula_29 is upward-sloping, and increases faster as increases. The graph always lies above the -axis, but becomes arbitrarily close to it for large negative ; thus, the -axis is a horizontal asymptote. The equation formula_30 means that the slope of the tangent to the graph at each point is equal to its -coordinate at that point.

The exponential function formula_31 is sometimes called the "natural exponential function" in order to distinguish it from the other exponential functions. The study of any exponential function can easily be reduced to that of the natural exponential function, since per definition, for positive ,
formula_32

As functions of a real variable, exponential functions are uniquely characterized by the fact that the derivative of such a function is directly proportional to the value of the function. The constant of proportionality of this relationship is the natural logarithm of the base :
formula_33

For , the function formula_34 is increasing (as depicted for and ), because formula_35 makes the derivative always positive; this is often referred to as exponential growth. For positive , the function is decreasing (as depicted for ); this is often referred to as exponential decay. For , the function is constant.

Euler's number is the unique base for which the constant of proportionality is 1, since formula_36, so that the function is its own derivative:
formula_37

This function, also denoted as , is called the "natural exponential function", or simply "the exponential function". Since any exponential function defined by formula_38 can be written in terms of the natural exponential as formula_16, it is computationally and conceptually convenient to reduce the study of exponential functions to this particular one. The natural exponential is hence denoted by
formula_40 or formula_41

The former notation is commonly used for simpler exponents, while the latter is preferred when the exponent is more complicated and harder to read in a small font.

For real numbers and , a function of the form formula_42 is also an exponential function, since it can be rewritten as 
formula_43

The real exponential function formula_44 can be characterized in a variety of equivalent ways. It is commonly defined by the following power series:
formula_45

Since the radius of convergence of this power series is infinite, this definition is, in fact, applicable to all complex numbers; see for the extension of formula_46 to the complex plane. Using the power series, the constant can be defined as formula_47

The term-by-term differentiation of this power series reveals that formula_48 for all real , leading to another common characterization of formula_46 as the unique solution of the differential equation
formula_50
that satisfies the initial condition formula_51

Based on this characterization, the chain rule shows that its inverse function, the natural logarithm, satisfies formula_52 for formula_53 or formula_54 This relationship leads to a less common definition of the real exponential function formula_55 as the solution formula_56 to the equation
formula_57

Solving the ordinary differential equation formula_58 with the initial condition formula_59 using Euler's method gives the product limit formula, valid for all complex values of formula_3:
formula_61

It can be shown that every continuous, nonzero solution of the functional equation formula_62 for formula_63 is an exponential function, formula_64 with formula_65

The exponential function arises whenever a quantity grows or decays at a rate proportional to its current value. One such situation is continuously compounded interest, and in fact it was this observation that led Jacob Bernoulli in 1683 to the number
formula_66
now known as . Later, in 1697, Johann Bernoulli studied the calculus of the exponential function.

If a principal amount of 1 earns interest at an annual rate of compounded monthly, then the interest earned each month is times the current value, so each month the total value is multiplied by , and the value at the end of the year is . If instead interest is compounded daily, this becomes . Letting the number of time intervals per year grow without bound leads to the limit definition of the exponential function,
formula_67
first given by Leonhard Euler.
This is one of a number of characterizations of the exponential function; others involve series or differential equations.

From any of these definitions it can be shown that is the reciprocal of . For example from the differential equation definition, when and its derivative using the product rule is for all , so for all .

From any of these definitions it can be shown that the exponential function obeys the basic exponentiation identity. For example from the power series definition,
formula_68
This justifies the notation for .

The derivative (rate of change) of the exponential function is the exponential function itself. More generally, a function with a rate of change "proportional" to the function itself (rather than equal to it) is expressible in terms of the exponential function. This function property leads to exponential growth or exponential decay.

The exponential function extends to an entire function on the complex plane. Euler's formula relates its values at purely imaginary arguments to trigonometric functions. The exponential function also has analogues for which the argument is a matrix, or even an element of a Banach algebra or a Lie algebra.

The importance of the exponential function in mathematics and the sciences stems mainly from its property as the unique function which is equal to its derivative and is equal to 1 when . That is,
formula_69

Functions of the form for constant are the only functions that are equal to their derivative (by the Picard–Lindelöf theorem). Other ways of saying the same thing include:

If a variable's growth or decay rate is proportional to its size—as is the case in unlimited population growth (see Malthusian catastrophe), continuously compounded interest, or radioactive decay—then the variable can be written as a constant times an exponential function of time. Explicitly for any real constant , a function satisfies if and only if for some constant . The constant "k" is called the decay constant, disintegration constant, rate constant, or transformation constant.

Furthermore, for any differentiable function , we find, by the chain rule:
formula_70

A continued fraction for can be obtained via an identity of Euler:
formula_71

The following generalized continued fraction for converges more quickly:
formula_72

or, by applying the substitution :
formula_73
with a special case for :
formula_74

This formula also converges, though more slowly, for . For example:
formula_75

As in the real case, the exponential function can be defined on the complex plane in several equivalent forms. 

The most common definition of the complex exponential function parallels the power series definition for real arguments, where the real variable is replaced by a complex one:
formula_76

Alternatively, the complex exponential function may be defined by modelling the limit definition for real arguments, but with the real variable replaced by a complex one:
formula_77

For the power series definition, term-wise multiplication of two copies of this power series in the Cauchy sense, permitted by Mertens' theorem, shows that the defining multiplicative property of exponential functions continues to hold for all complex arguments:
formula_78

The definition of the complex exponential function in turn leads to the appropriate definitions extending the trigonometric functions to complex arguments.

In particular, when ( real), the series definition yields the expansion
formula_79

In this expansion, the rearrangement of the terms into real and imaginary parts is justified by the absolute convergence of the series. The real and imaginary parts of the above expression in fact correspond to the series expansions of and , respectively.

This correspondence provides motivation for cosine and sine for all complex arguments in terms of formula_80 and the equivalent power series:
formula_81

for all formula_82

The functions , , and so defined have infinite radii of convergence by the ratio test and are therefore entire functions (that is, holomorphic on formula_83). The range of the exponential function is formula_84, while the ranges of the complex sine and cosine functions are both formula_83 in its entirety, in accord with Picard's theorem, which asserts that the range of a nonconstant entire function is either all of formula_83, or formula_83 excluding one lacunary value.

These definitions for the exponential and trigonometric functions lead trivially to Euler's formula:
formula_88

We could alternatively define the complex exponential function based on this relationship. If , where and are both real, then we could define its exponential as
formula_89
where , , and on the right-hand side of the definition sign are to be interpreted as functions of a real variable, previously defined by other means.

For formula_90, the relationship formula_91 holds, so that formula_92 for real formula_93 and formula_94 maps the real line (mod ) to the unit circle in the complex plane. Moreover, going from formula_95 to formula_96, the curve defined by formula_97 traces a segment of the unit circle of length
formula_98
starting from in the complex plane and going counterclockwise. Based on these observations and the fact that the measure of an angle in radians is the arc length on the unit circle subtended by the angle, it is easy to see that, restricted to real arguments, the sine and cosine functions as defined above coincide with the sine and cosine functions as introduced in elementary mathematics via geometric notions.

The complex exponential function is periodic with period and formula_99 holds for all formula_100.

When its domain is extended from the real line to the complex plane, the exponential function retains the following properties:
formula_101

for all formula_102

Extending the natural logarithm to complex arguments yields the complex logarithm , which is a multivalued function.

We can then define a more general exponentiation:
formula_103
for all complex numbers and . This is also a multivalued function, even when is real. This distinction is problematic, as the multivalued functions and are easily confused with their single-valued equivalents when substituting a real number for . The rule about multiplying exponents for the case of positive real numbers must be modified in a multivalued context:
See failure of power and logarithm identities for more about problems with combining powers.

The exponential function maps any line in the complex plane to a logarithmic spiral in the complex plane with the center at the origin. Two special cases exist: when the original line is parallel to the real axis, the resulting spiral never closes in on itself; when the original line is parallel to the imaginary axis, the resulting spiral is a circle of some radius.

Considering the complex exponential function as a function involving four real variables:
formula_104
the graph of the exponential function is a two-dimensional surface curving through four dimensions.

Starting with a color-coded portion of the formula_105 domain, the following are depictions of the graph as variously projected into two or three dimensions.

The second image shows how the domain complex plane is mapped into the range complex plane:

The third and fourth images show how the graph in the second image extends into one of the other two dimensions not shown in the second image.

The third image shows the graph extended along the real formula_3 axis. It shows the graph is a surface of revolution about the formula_3 axis of the graph of the real exponential function, producing a horn or funnel shape.

The fourth image shows the graph extended along the imaginary formula_56 axis. It shows that the graph's surface for positive and negative formula_56 values doesn't really meet along the negative real formula_107 axis, but instead forms a spiral surface about the formula_56 axis. Because its formula_56 values have been extended to , this image also better depicts the 2π periodicity in the imaginary formula_56 value.

Complex exponentiation can be defined by converting to polar coordinates and using the identity :
formula_117

However, when is not an integer, this function is multivalued, because is not unique (see "").

The power series definition of the exponential function makes sense for square matrices (for which the function is called the matrix exponential) and more generally in any unital Banach algebra . In this setting, , and is invertible with inverse for any in . If , then , but this identity can fail for noncommuting and .

Some alternative definitions lead to the same function. For instance, can be defined as
formula_118

Or can be defined as , where is the solution to the differential equation , with initial condition ; it follows that for every in .

Given a Lie group and its associated Lie algebra formula_119, the exponential map is a map formula_119 satisfying similar properties. In fact, since is the Lie algebra of the Lie group of all positive real numbers under multiplication, the ordinary exponential function for real arguments is a special case of the Lie algebra situation. Similarly, since the Lie group of invertible matrices has as Lie algebra , the space of all matrices, the exponential function for square matrices is a special case of the Lie algebra exponential map.

The identity formula_121 can fail for Lie algebra elements and that do not commute; the Baker–Campbell–Hausdorff formula supplies the necessary correction terms.

The function is not in the rational function ring formula_122: it is not the quotient of two polynomials with complex coefficients.

If are distinct complex numbers, then are linearly independent over formula_122, and hence is transcendental over formula_122.

When computing (an approximation of) the exponential function near the argument , the result will be close to 1, and computing the value of the difference formula_125 with floating-point arithmetic may lead to the loss of (possibly all) significant figures, producing a large calculation error, possibly even a meaningless result.

Following a proposal by William Kahan, it may thus be useful to have a dedicated routine, often called codice_1, for computing directly, bypassing computation of . For example, if the exponential is computed by using its Taylor series
formula_126
one may use the Taylor series of formula_125:
formula_128

This was first implemented in 1979 in the Hewlett-Packard HP-41C calculator, and provided by several calculators, operating systems (for example Berkeley UNIX 4.3BSD), computer algebra systems, and programming languages (for example C99).

In addition to base , the IEEE 754-2008 standard defines similar exponential functions near 0 for base 2 and 10: formula_129 and formula_130.

A similar approach has been used for the logarithm (see lnp1).

An identity in terms of the hyperbolic tangent,
formula_131
gives a high-precision value for small values of on systems that do not implement .

Prince Eugene of Savoy

Prince Eugene Francis of Savoy-Carignano (18 October 1663 – 21 April 1736), better known as Prince Eugene, was a field marshal in the Army of the Holy Roman Empire and of the Austrian Habsburg dynasty during the 17th and 18th centuries. He was one of the most successful military commanders of his time, and rose to the highest offices of state at the Imperial court in Vienna.

Born in Paris, Eugene was brought up in the court of King Louis XIV of France. Based on the custom that the youngest sons of noble families were destined for the priesthood, the Prince was initially prepared for a clerical career, but by the age of 19, he had determined on a military career. Based on his poor physique and bearing, and perhaps due to a scandal involving his mother Olympe, he was rejected by Louis for service in the French Royal Army. Eugene moved to Austria and transferred his loyalty to the Holy Roman Empire.

In a career spanning six decades, Eugene served three Holy Roman Emperors: Leopold I, Joseph I, and Charles VI. His first battle experiences were fought against the Ottomans at the Siege of Vienna in 1683 and the subsequent War of the Holy League, before serving in the Nine Years' War, in which he fought alongside his cousin, the Duke of Savoy. The Prince's fame was secured with his decisive victory against the Ottomans at the Battle of Zenta in 1697, earning him Europe-wide fame. Eugene enhanced his standing during the War of the Spanish Succession, where his partnership with the Duke of Marlborough secured victories against the French on the fields of Blenheim (1704), Oudenarde (1708), and Malplaquet (1709); he gained further success in the war as Imperial commander in northern Italy, most notably at the Battle of Turin (1706). Renewed hostilities against the Ottomans in the Austro-Turkish War consolidated his reputation, with victories at the battles of Petrovaradin (1716), and the decisive encounter at the Siege of Belgrade in 1717.

Throughout the late 1720s, Eugene's influence and skilful diplomacy managed to secure the Emperor powerful allies in his dynastic struggles with the Bourbon powers, but physically and mentally fragile in his later years, Eugene enjoyed less success as commander-in-chief of the army during his final conflict, the War of the Polish Succession. Nevertheless, in Austria, Eugene's reputation remains unrivalled. Although opinions differ as to his character, there is no dispute over his great achievements: he helped to save the Habsburg Empire from French conquest; he broke the westward thrust of the Ottomans, re-occupying areas that had been under Turkish control for a century and a half; and he was one of the great patrons of the arts whose building legacy can still be seen in Vienna today. Eugene died in his sleep at his home on 21 April 1736, aged 72.

Prince Eugene was born at the Hôtel de Soissons in Paris on 18 October 1663. His mother, Olympia Mancini, was one of Cardinal Mazarin's nieces whom the Cardinal had brought to Paris from Rome in 1647 to further his (and, to a lesser extent, their) ambitions. The Mancinis were raised at the Palais-Royal along with the young Louis XIV, with whom Olympia formed an intimate relationship. Yet to her great disappointment, her chance to become queen passed by, and in 1657, she married Eugene Maurice, Count of Soissons, Count of Dreux and Prince of Savoy.

Together they had had five sons (Eugene being the youngest) and three daughters, but neither parent spent much time with the children: the father, a French general officer, spent much of his time away campaigning, while Olympia's passion for court intrigue meant the children received little attention from her.
The King remained strongly attached to Olympia, so much so that many believed them to be lovers; but her scheming eventually led to her downfall. After falling out of favour at court, Olympia turned to Catherine Deshayes (known as "La Voisin"), and to the arts of black magic and astrology. It proved a fatal relationship. She became embroiled in the "Affaire des poisons"; suspicions abounded of her involvement in her husband's premature death in 1673, and even implicated her in a plot to kill the King himself. Whatever the truth, Olympia, rather than face trial, subsequently fled France for Brussels in January 1680, leaving Eugene in the care of his paternal grandmother, Marie de Bourbon, Countess of Soissons, and of his paternal aunt, Louise Christine of Savoy, Hereditary Princess of Baden, mother of Prince Louis of Baden.

From the age of ten, Eugene had been brought up for a career in the church since he was the youngest of his family. Eugene's appearance was not impressive—"He was never good-looking ..." wrote the Duchess of Orléans, "It is true that his eyes are not ugly, but his nose ruins his face; he has two large teeth which are visible at all times" According to the duchess, who was married to Louis XIV's bisexual brother, the Duke of Orléans, Eugene lived a life of "debauchery" and belonged to a small, effeminate set that included the famous cross-dresser Abbé François-Timoléon de Choisy. In February 1683, to the surprise of his family, the 19-year-old Eugene declared his intention of joining the army. Eugene applied directly to Louis XIV for command of a company in French service, but the King—who had shown no compassion for Olympia's children since her disgrace—refused him out of hand. "The request was modest, not so the petitioner", he remarked. "No one else ever presumed to stare me out so insolently." Whatever the case, Louis XIV's choice would cost him dearly twenty years later, for it would be precisely Eugene, in collaboration with the Duke of Marlborough, who would defeat the French army at Blenheim, a decisive battle which checked French military supremacy and political power.

Denied a military career in France, Eugene decided to seek service abroad. One of Eugene's brothers, Louis Julius, had entered Imperial service the previous year, but he had been immediately killed fighting the Ottoman Empire in 1683. When news of his death reached Paris, Eugene decided to travel to Austria in the hope of taking over his brother's command. It was not an unnatural decision: his cousin, Louis of Baden, was already a leading general in the Imperial army, as was a more distant cousin, Maximilian II Emanuel, Elector of Bavaria. On the night of 26 July 1683, Eugene left Paris and headed east. Years later, in his memoirs, Eugene recalled his early years in France:

By May 1683, the Ottoman threat to Emperor Leopold I's capital, Vienna, was very evident. The Grand Vizier, Kara Mustafa Pasha—encouraged by Imre Thököly's Magyar rebellion—had invaded Hungary with between 100,000 and 200,000 men; within two months approximately 90,000 were beneath Vienna's walls. With the 'Turks at the gates', the Emperor fled for the safe refuge of Passau up the Danube. It was at Leopold I's camp that Eugene arrived in mid-August.

Although Eugene was not of Austrian extraction, he did have Habsburg antecedents. His grandfather, Thomas Francis, founder of the Carignano line of the House of Savoy, was the son of Catherine Michaela of Spain—a daughter of Philip II of Spain—and the great-grandson of the Emperor Charles V. But of more immediate consequence to Leopold I was the fact that Eugene was the second cousin of Victor Amadeus II, the Duke of Savoy, a connection that the Emperor hoped might prove useful in any future confrontation with France. These ties, together with his ascetic manner and appearance (a positive advantage to him at the sombre court of Leopold I), ensured the refugee from the hated French king a warm welcome at Passau, and a position in Imperial service. Though French was his favoured language, he communicated with Leopold in Italian, as the Emperor (though he knew it perfectly) disliked French. But Eugene also had a reasonable command of German, which he understood very easily, something that helped him much in the military.
Eugene had no doubt as to where his new allegiance lay, and this loyalty was immediately put to the test. By September, the Imperial forces under the Duke of Lorraine, together with a powerful Polish army under King John III Sobieski, were poised to strike the Sultan's army. On the morning of 12 September, the Christian forces drew up in line of battle on the south-eastern slopes of the Vienna Woods, looking down on the massed enemy camp. The day-long Battle of Vienna resulted in the lifting of the 60-day siege, and the Sultan's forces were routed. Serving under Baden, as a twenty-year-old volunteer, Eugene distinguished himself in the battle, earning commendation from Lorraine and the Emperor; he later received the nomination for the colonelcy and was awarded the Kufstein regiment of dragoons by Leopold I.

In March 1684, Leopold I formed the Holy League with Poland and Venice to counter the Ottoman threat. For the next two years, Eugene continued to perform with distinction on campaign and establish himself as a dedicated, professional soldier; by the end of 1685, still only 22 years old, he was made a Major-General. Little is known of Eugene's life during these early campaigns. Contemporary observers make only passing comments of his actions, and his own surviving correspondence, largely to his cousin Victor Amadeus, are typically reticent about his own feelings and experiences. Nevertheless, it is clear that Baden was impressed with Eugene's qualities—"This young man will, with time, occupy the place of those whom the world regards as great leaders of armies."

In June 1686, the Duke of Lorraine besieged Buda (Budapest), the centre of Ottoman Hungary and the old royal capital. After resisting for 78 days, the city fell on 2 September, and Turkish resistance collapsed throughout the region as far away as Transylvania and Serbia. Further success followed in 1687, where, commanding a cavalry brigade, Eugene made an important contribution to the victory at the Battle of Mohács on 12 August. Such was the scale of their defeat that the Ottoman army mutinied—a revolt which spread to Constantinople. The Grand Vizier, Sarı Süleyman Pasha, was executed and Sultan Mehmed IV, deposed. Once again, Eugene's courage earned him recognition from his superiors, who granted him the honour of personally conveying the news of victory to the Emperor in Vienna. For his services, Eugene was promoted to Lieutenant-General in November 1687. He was also gaining wider recognition. King Charles II of Spain bestowed upon him the Order of the Golden Fleece, while his cousin, Victor Amadeus, provided him with money and two profitable abbeys in Piedmont. Eugene's military career suffered a temporary setback in 1688 when, on 6 September, the Prince suffered a severe wound to his knee by a musket ball during the Siege of Belgrade, and did not return to active service until January 1689.

Just as Belgrade was falling to Imperial forces under Max Emmanuel in the east, French troops in the west were crossing the Rhine into the Holy Roman Empire. Louis XIV had hoped that a show of force would lead to a quick resolution to his dynastic and territorial disputes with the princes of the Empire along his eastern border, but his intimidatory moves only strengthened German resolve, and in May 1689, Leopold I and the Dutch signed an offensive compact aimed at repelling French aggression.

The Nine Years' War was professionally and personally frustrating for the prince. Initially fighting on the Rhine with Max Emmanuel—receiving a slight head wound at the Siege of Mainz in 1689—Eugene subsequently transferred himself to Piedmont after Victor Amadeus joined the Alliance against France in 1690. Promoted to general of cavalry, he arrived in Turin with his friend the Prince of Commercy; but it proved an inauspicious start. Against Eugene's advice, Amadeus insisted on engaging the French at Staffarda and suffered a serious defeat—only Eugene's handling of the Savoyard cavalry in retreat saved his cousin from disaster. Eugene remained unimpressed with the men and their commanders throughout the war in Italy. "The enemy would long ago have been beaten", he wrote to Vienna, "if everyone had done their duty." So contemptuous was he of the Imperial commander, Count Carafa, he threatened to leave Imperial service.

In Vienna, Eugene's attitude was dismissed as the arrogance of a young upstart, but so impressed was the Emperor by his passion for the Imperial cause, he promoted him to Field-Marshal in 1693. When Carafa's replacement, Count Caprara, was himself transferred in 1694, it seemed that Eugene's chance for command and decisive action had finally arrived. But Amadeus, doubtful of victory and now more fearful of Habsburg influence in Italy than he was of French, had begun secret dealings with Louis XIV aimed at extricating himself from the war. By 1696, the deal was done, and Amadeus transferred his troops and his loyalty to the enemy. Eugene was never to fully trust his cousin again; although he continued to pay due reverence to the Duke as head of his family, their relationship would forever after remain strained.

Military honours in Italy undoubtedly belonged to the French commander Marshal Catinat, but Eugene, the one Allied general determined on action and decisive results, did well to emerge from the Nine Years' War with an enhanced reputation. With the signing of the Treaty of Ryswick in September/October 1697, the desultory war in the west was finally brought to an inconclusive end, and Leopold I could once again devote all his martial energies into defeating the Ottoman Turks in the east.

The distractions of the war against Louis XIV had enabled the Turks to recapture Belgrade in 1690. In August 1691, the Austrians, under Louis of Baden, regained the advantage by heavily defeating the Turks at the Battle of Slankamen on the Danube, securing Habsburg possession of Hungary and Transylvania. When Baden was transferred west to fight the French in 1692, his successors, first Caprara, then from 1696, Augustus the Strong, the Elector of Saxony, proved incapable of delivering the final blow. On the advice of the President of the Imperial War Council, Ernst Rüdiger von Starhemberg, thirty-four-year old Eugene was offered supreme command of Imperial forces in April 1697. This was Eugene's first truly independent command—no longer need he suffer under the excessively cautious generalship of Caprara and Carafa, or be thwarted by the deviations of Victor Amadeus. But on joining his army, he found it in a state of 'indescribable misery'. Confident and self-assured, the Prince of Savoy (ably assisted by Commercy and Guido Starhemberg) set about restoring order and discipline.

Leopold I had warned Eugene that "he should act with extreme caution, forgo all risks and avoid engaging the enemy unless he has overwhelming strength and is practically certain of being completely victorious", but when the Imperial commander learnt of Sultan Mustafa II's march on Transylvania, Eugene abandoned all ideas of a defensive campaign and moved to intercept the Turks as they crossed the River Tisza at Zenta on 11 September 1697.

It was late in the day before the Imperial army struck. The Ottoman cavalry had already crossed the river so Eugene decided to attack immediately, arranging his men in a half-moon formation. The vigour of the assault wrought terror and confusion amongst the Turks, and by nightfall, the battle was won. For the loss of some 2,000 dead and wounded, Eugene had inflicted an overwhelming defeat upon the enemy with approximately 25,000 Turks killed—including the Grand Vizier, Elmas Mehmed Pasha, the pashas of Adana, Anatolia, and Bosnia, plus more than thirty aghas of the Janissaries, sipahis, and silihdars, as well as seven horsetails (symbols of high authority), 100 pieces of heavy artillery, 423 banners, and the revered seal which the sultan always entrusted to the Grand Vizier on an important campaign, Eugene had annihilated the Ottoman army and brought to an end the War of the Holy League. Although the Ottomans lacked western organization and training, the Savoyard prince had revealed his tactical skill, his capacity for bold decision, and his ability to inspire his men to excel in battle against a dangerous foe.

After a brief terror-raid into Ottoman Bosnia, culminating in the sack of Sarajevo, Eugene returned to Vienna in November to a triumphal reception. His victory at Zenta had turned him into a European hero, and with victory came reward. Land in Hungary, given him by the Emperor, yielded a good income, enabling the Prince to cultivate his newly acquired tastes in art and architecture (see below); but for all his new-found wealth and property, he was, nevertheless, without personal ties or family commitments. Of his four brothers, only one was still alive at this time. His fourth brother, Emmanuel, had died aged 14 in 1676; his third, Louis Julius (already mentioned) had died on active service in 1683, and his second brother, Philippe, died of smallpox in 1693. Eugene's remaining brother, Louis Thomas—ostracized for incurring the displeasure of Louis XIV—travelled Europe in search of a career, before arriving in Vienna in 1699. With Eugene's help, Louis found employment in the Imperial army, only to be killed in action against the French in 1702. Of Eugene's sisters, the youngest had died in childhood. The other two, Marie Jeanne-Baptiste and Louise Philiberte, led dissolute lives. Expelled from France, Marie joined her mother in Brussels, before eloping with a renegade priest to Geneva, living with him unhappily until her premature death in 1705. Of Louise, little is known after her early salacious life in Paris, but in due course, she lived for a time in a convent in Savoy before her death in 1726.

The Battle of Zenta proved to be the decisive victory in the long war against the Turks. With Leopold I's interests now focused on Spain and the imminent death of Charles II, the Emperor terminated the conflict with the Sultan; he signed the Treaty of Karlowitz on 26 January 1699.

With the death of the infirm and childless Charles II of Spain on 1 November 1700, the succession of the Spanish throne and subsequent control over her empire once again embroiled Europe in war—the War of the Spanish Succession. On his deathbed Charles II had bequeathed the entire Spanish inheritance to Louis XIV's grandson, Philip, Duke of Anjou. This threatened to unite the Spanish and French kingdoms under the House of Bourbon—something unacceptable to England, the Dutch Republic, and Leopold I, who had himself a claim to the Spanish throne. From the beginning, the Emperor had refused to accept the will of Charles II, and he did not wait for England and the Dutch Republic to begin hostilities. Before a new Grand Alliance could be concluded Leopold I prepared to send an expedition to seize the Spanish lands in Italy.

Eugene crossed the Alps with some 30,000 men in May/June 1701. After a series of brilliant manoeuvres the Imperial commander defeated Catinat at the Battle of Carpi on 9 July. "I have warned you that you are dealing with an enterprising young prince", wrote Louis XIV to his commander, "he does not tie himself down to the rules of war." On 1 September Eugene defeated Catinat's successor, Marshal Villeroi, at the Battle of Chiari, in a clash as destructive as any in the Italian theatre. But as so often throughout his career the Prince faced war on two fronts—the enemy in the field and the government in Vienna.

Starved of supplies, money, and men, Eugene was forced into unconventional means against the vastly superior enemy. During a daring raid on Cremona on the night of 31 January/1 February 1702 Eugene captured the French commander-in-chief. Yet the coup was less successful than hoped: Cremona remained in French hands, and the Duke of Vendôme, whose talents far exceeded Villeroi's, became the theatre's new commander. Villeroi's capture caused a sensation in Europe and had a galvanizing effect on English public opinion. "The surprise at Cremona", wrote the diarist John Evelyn, "... was the great discourse of this week"; but appeals for succour from Vienna remained unheeded, forcing Eugene to seek battle and gain a 'lucky hit'. The resulting Battle of Luzzara on 15 August proved inconclusive. Although Eugene's forces inflicted double the number of casualties on the French the battle settled little except to deter Vendôme trying an all-out assault on Imperial forces that year, enabling Eugene to hold on south of the Alps. With his army rotting away, and personally grieving for his long-standing friend Prince Commercy who had died at Luzzara, Eugene returned to Vienna in January 1703.

Eugene's European reputation was growing (Cremona and Luzzara had been celebrated as victories throughout the Allied capitals), yet because of the condition and morale of his troops the 1702 campaign had not been a success. Austria itself was now facing the direct threat of invasion from across the border in Bavaria where the state's Elector, Maximilian Emanuel, had declared for the Bourbons in August the previous year. Meanwhile, in Hungary a small-scale revolt had broken out in May and was fast gaining momentum. With the monarchy at the point of complete financial breakdown Leopold I was at last persuaded to change the government. At the end of June 1703 Gundaker Starhemberg replaced Gotthard Salaburg as President of the Treasury, and Prince Eugene succeeded Henry Mansfeld as the new President of the Imperial War Council ("Hofkriegsratspräsident").

As head of the war council Eugene was now part of the Emperor's inner circle, and the first president since Raimondo Montecuccoli to remain an active commander. Immediate steps were taken to improve efficiency within the army: encouragement and, where possible, money, was sent to the commanders in the field; promotion and honours were distributed according to service rather than influence; and discipline improved. But the Austrian monarchy faced severe peril on several fronts in 1703: by June the Duke of Villars had reinforced the Elector of Bavaria on the Danube thus posing a direct threat to Vienna, while Vendôme remained at the head of a large army in northern Italy opposing Guido Starhemberg's weak Imperial force. Of equal alarm was Francis II Rákóczi's revolt which, by the end of the year, had reached as far as Moravia and Lower Austria.

Dissension between Villars and the Elector of Bavaria had prevented an assault on Vienna in 1703, but in the Courts of Versailles and Madrid, ministers confidently anticipated the city's fall. The Imperial ambassador in London, Count Wratislaw, had pressed for Anglo-Dutch assistance on the Danube as early as February 1703, but the crisis in southern Europe seemed remote from the Court of St. James's where colonial and commercial considerations were more to the fore of men's minds. Only a handful of statesmen in England or the Dutch Republic realized the true implications of Austria's peril; foremost amongst these was the English Captain-General, the Duke of Marlborough.

By early 1704 Marlborough had resolved to march south and rescue the situation in southern Germany and on the Danube, personally requesting the presence of Eugene on campaign so as to have "a supporter of his zeal and experience". The Allied commanders met for the first time at the small village of Mundelsheim on 10 June, and immediately formed a close rapport—the two men becoming, in the words of Thomas Lediard, 'Twin constellations in glory'. This professional and personal bond ensured mutual support on the battlefield, enabling many successes during the Spanish Succession war. The first of these victories, and the most celebrated, came on 13 August 1704 at the Battle of Blenheim. Eugene commanded the right wing of the Allied army, holding the Elector of Bavaria's and Marshal Marsin's superior forces, while Marlborough broke through the Marshal Tallard's center, inflicting over 30,000 casualties. The battle proved decisive: Vienna was saved and Bavaria was knocked out of the war. Both Allied commanders were full of praise for each other's performance. Eugene's holding operation, and his pressure for action leading up to the battle, proved crucial for the Allied success.

In Europe Blenheim is regarded as much a victory for Eugene as it is for Marlborough, a sentiment echoed by Sir Winston Churchill (Marlborough's descendant and biographer), who pays tribute to "the glory of Prince Eugene, whose fire and spirit had exhorted the wonderful exertions of his troops." France now faced the real danger of invasion, but Leopold I in Vienna was still under severe strain: Rákóczi's revolt was a major threat; and Guido Starhemberg and Victor Amadeus (who had once again switched loyalties and rejoined the Grand Alliance in 1703) had been unable to halt the French under Vendôme in northern Italy. Only Amadeus' capital, Turin, held on.

Eugene returned to Italy in April 1705, but his attempts to move west towards Turin were thwarted by Vendôme's skilful manoeuvres. Lacking boats and bridging materials, and with desertion and sickness rife within his army, the outnumbered Imperial commander was helpless. Leopold I's assurances of money and men had proved illusory, but desperate appeals from Amadeus and criticism from Vienna goaded the Prince into action, resulting in the Imperialists' bloody defeat at the Battle of Cassano on 16 August. Following Leopold I's death and the accession of Joseph I to the Imperial throne in May 1705, Eugene began to receive the personal backing he desired. Joseph I proved to be a strong supporter of Eugene's supremacy in military affairs; he was the most effective emperor the Prince served and the one he was happiest under. Promising support, Joseph I persuaded Eugene to return to Italy and restore Habsburg honour.

The Imperial commander arrived in theatre in mid-April 1706, just in time to organize an orderly retreat of what was left of Count Reventlow's inferior army following his defeat by Vendôme at the Battle of Calcinato on 19 April. Vendôme now prepared to defend the lines along the River Adige, determined to keep Eugene cooped to the east while the Marquis of La Feuillade threatened Turin. Feigning attacks along the Adige, Eugene descended south across the river Po in mid-July, outmanoeuvring the French commander and gaining a favourable position from which he could at last move west towards Piedmont and relieve Savoy's capital.

Events elsewhere now had major consequences for the war in Italy. With Villeroi's crushing defeat by Marlborough at the Battle of Ramillies on 23 May, Louis XIV recalled Vendôme north to take command of French forces in Flanders. It was a transfer that Saint-Simon considered something of a deliverance for the French commander who was "now beginning to feel the unlikelihood of success (in Italy) ... for Prince Eugene, with the reinforcements that had joined him after the Battle of Calcinato, had entirely changed the outlook in that theatre of the war." The Duke of Orléans, under the direction of Marsin, replaced Vendôme, but indecision and disorder in the French camp led to their undoing. After uniting his forces with Victor Amadeus at Villastellone in early September, Eugene attacked, overwhelmed, and decisively defeated the French forces besieging Turin on 7 September. Eugene's success broke the French hold on northern Italy, and the whole Po valley fell under Allied control. Eugene had gained a victory as signal as his colleague had at Ramillies—"It is impossible for me to express the joy it has given me;" wrote Marlborough, "for I not only esteem but I really love the prince. This glorious action must bring France so low, that if our friends could but be persuaded to carry on the war with vigour one year longer, we cannot fail, with the blessing of God, to have such a peace as will give us quiet for all our days."

The Imperial victory in Italy marked the beginning of Austrian rule in Lombardy, and earned Eugene the Governorship of Milan. But the following year was to prove a disappointment for the Prince and the Grand Alliance as a whole. The Emperor and Eugene (whose main goal after Turin was to take Naples and Sicily from Philip duc d'Anjou's supporters), reluctantly agreed to Marlborough's plan for an attack on Toulon—the seat of French naval power in the Mediterranean. Disunion between the Allied commanders—Victor Amadeus, Eugene, and the English Admiral Cloudesley Shovell—doomed the Toulon enterprise to failure. Although Eugene favoured some sort of attack on France's south-eastern border it was clear he felt the expedition impractical, and showed none of the "alacrity which he had displayed on other occasions." Substantial French reinforcements finally brought an end to the venture, and on 22 August 1707, the Imperial army began its retirement. The subsequent capture of Susa could not compensate for the total collapse of the Toulon expedition and with it any hope of an Allied war-winning blow that year.

At the beginning of 1708 Eugene successfully evaded calls for him to take charge in Spain (in the end Guido Starhemberg was sent), thus enabling him to take command of the Imperial army on the Moselle and once again unite with Marlborough in the Spanish Netherlands. Eugene (without his army) arrived at the Allied camp at Assche, west of Brussels, in early July, providing a welcome boost to morale after the early defection of Bruges and Ghent to the French. " ... our affairs improved through God's support and Eugene's aid", wrote the Prussian General Natzmer, "whose timely arrival raised the spirits of the army again and consoled us." Heartened by the Prince's confidence the Allied commanders devised a bold plan to engage the French army under Vendôme and the Duke of Burgundy. On 10 July the Anglo-Dutch army made a forced march to surprise the French, reaching the River Scheldt just as the enemy was crossing to the north. The ensuing battle on 11 July—more a contact action rather than a set-piece engagement—ended in a resounding success for the Allies, aided by the dissension of the two French commanders. While Marlborough remained in overall command, Eugene had led the crucial right flank and centre. Once again the Allied commanders had co-operated remarkably well. "Prince Eugene and I", wrote the Duke, "shall never differ about our share of the laurels."

Marlborough now favoured a bold advance along the coast to bypass the major French fortresses, followed by a march on Paris. But fearful of unprotected supply-lines, the Dutch and Eugene favoured a more cautious approach. Marlborough acquiesced and resolved upon the siege of Vauban's great fortress, Lille. While the Duke commanded the covering force, Eugene oversaw the siege of the town which surrendered on 22 October but Marshal Boufflers did not yield the citadel until 10 December. Yet for all the difficulties of the siege (Eugene was badly wounded above his left eye by a musket ball, and even survived an attempt to poison him), the campaign of 1708 had been a remarkable success. The French were driven out of almost all the Spanish Netherlands. "He who has not seen this", wrote Eugene, "has seen nothing."

The recent defeats, together with the severe winter of 1708–09, had caused extreme famine and privation in France. Louis XIV was close to accepting Allied terms, but the conditions demanded by the leading Allied negotiators, Anthonie Heinsius, Charles Townshend, Marlborough, and Eugene—principally that Louis XIV should use his own troops to force Philip V off the Spanish throne—proved unacceptable to the French. Neither Eugene nor Marlborough had objected to the Allied demands at the time, but neither wanted the war with France to continue, and would have preferred further talks to deal with the Spanish issue. But the French King offered no further proposals. Lamenting the collapse of the negotiations, and aware of the vagaries of war, Eugene wrote to the Emperor in mid-June 1709. "There can be no doubt that the next battle will be the biggest and bloodiest that has yet been fought."

After the fall of Tournai on 3 September (itself a major undertaking), the Allied generals turned their attention towards Mons. Marshal Villars, recently joined by Boufflers, moved his army south-west of the town and began to fortify his position. Marlborough and Eugene favoured an engagement before Villars could render his position impregnable; but they also agreed to wait for reinforcements from Tournai which did not arrive until the following night, thus giving the French further opportunity to prepare their defences. Notwithstanding the difficulties of the attack, the Allied generals did not shrink from their original determination. The subsequent Battle of Malplaquet, fought on 11 September 1709, was the bloodiest engagement of the war. On the left flank, the Prince of Orange led his Dutch infantry in desperate charges only to have it cut to pieces; on the other flank, Eugene attacked and suffered almost as severely. But sustained pressure on his extremities forced Villars to weaken his centre, thus enabling Marlborough to breakthrough and claim victory. Villars was unable to save Mons, which subsequently capitulated on 21 October, but his resolute defence at Malplaquet—inflicting up to 25% casualties on the Allies—may have saved France from destruction.

In August 1709 Eugene's chief political opponent and critic in Vienna, Prince Salm, retired as court chamberlain. Eugene and Wratislaw were now the undisputed leaders of the Austrian government: all major departments of state were in their hands or those of their political allies. Another attempt at a negotiated settlement at Geertruidenberg in April 1710 failed, largely because the English Whigs still felt strong enough to refuse concessions, while Louis XIV saw little reason to accept what he had refused the previous year. Eugene and Marlborough could not be accused of wrecking the negotiations, but neither showed regret at the breakdown of the talks. There was no alternative but to continue the war, and in June the Allied commanders captured Douai. This success was followed by a series of minor sieges, and by the close of 1710 the Allies had cleared much of France's protective ring of fortresses. Yet there had been no final, decisive breakthrough, and this was to be the last year that Eugene and Marlborough would work together.

Following the death of Joseph I on 17 April 1711 his brother, Charles, the pretender to the Spanish throne, became emperor. In England the new Tory government (the 'peace party' who had deposed the Whigs in October 1710) declared their unwillingness to see Charles VI become Emperor as well as King of Spain, and had already begun secret negotiations with the French. In January 1712 Eugene arrived in England hoping to divert the government away from its peace policy, but despite the social success the visit was a political failure: Queen Anne and her ministers remained determined to end the war regardless of the Allies. Eugene had also arrived too late to save Marlborough who, seen by the Tories as the main obstacle to peace, had already been dismissed on charges of embezzlement. Elsewhere the Austrians had made some progress—the Hungarian revolt had finally came to end. Although Eugene would have preferred to crush the rebels the Emperor had offered lenient conditions, leading to the signing of the Treaty of Szatmár on 30 April 1711.

Hoping to influence public opinion in England and force the French into making substantial concessions, Eugene prepared for a major campaign. But on 21 May 1712—when the Tories felt they had secured favourable terms with their unilateral talks with the French—the Duke of Ormonde (Marlborough's successor) received the so-called 'restraining orders', forbidding him to take part in any military action. Eugene took the fortress of Le Quesnoy in early July, before besieging Landrecies, but Villars, taking advantage of Allied disunity, outmanoeuvred Eugene and defeated the Earl of Albermarle's Dutch garrison at the Battle of Denain on 24 July. The French followed the victory by seizing the Allies' main supply magazine at Marchiennes, before reversing their earlier losses at Douai, Le Quesnoy and Bouchain. In one summer the whole forward Allied position laboriously built up over the years to act as the springboard into France had been precipitously abandoned.

With the death in December of his friend and close political ally, Count Wratislaw, Eugene became undisputed 'first minister' in Vienna. His position was built on his military successes, but his actual power was expressed through his role as president of the war council, and as "de facto" president of the conference which dealt with foreign policy. In this position of influence Eugene took the lead in pressing Charles VI towards peace. The government had come to accept that further war in the Netherlands or Spain was impossible without the aid of the Maritime Powers; yet the Emperor, still hoping that somehow he could place himself on the throne in Spain, refused to make peace at the Utrecht conference along with the other Allies. Reluctantly, Eugene prepared for another campaign, but lacking troops, finance, and supplies his prospects in 1713 were poor. Villars, with superior numbers, was able to keep Eugene guessing as to his true intent. Through successful feints and stratagems Landau fell to the French commander in August, followed in November by Freiburg. Eugene was reluctant to carry on the war, and wrote to the Emperor in June that a bad peace would be better than being 'ruined equally by friend and foe'. With Austrian finances exhausted and the German states reluctant to continue the war, Charles VI was compelled to enter into negotiations. Eugene and Villars (who had been old friends since the Turkish campaigns of the 1680s) initiated talks on 26 November. Eugene proved an astute and determined negotiator, and gained favourable terms by the Treaty of Rastatt signed on 7 March 1714 and the Treaty of Baden signed on 7 September 1714. Despite the failed campaign in 1713 the Prince was able to declare that, "in spite of the military superiority of our enemies and the defection of our Allies, the conditions of peace will be more advantageous and more glorious than those we would have obtained at Utrecht."

Eugene's main reason for desiring peace in the west was the growing danger posed by the Turks in the east. Turkish military ambitions had revived after 1711 when they had mauled Peter the Great's army on the River Pruth (Pruth River Campaign): in December 1714 Sultan Ahmed III's forces attacked the Venetians in the Kingdom of the Morea. To Vienna it was clear that the Turks intended to attack Hungary and undo the whole Karlowitz settlement of 1699. After the Sublime Porte rejected an offer of mediation in April 1716, Charles VI despatched Eugene to Hungary to lead his relatively small but professional army. Of all Eugene's wars this was the one in which he exercised most direct control; it was also a war which, for the most part, Austria fought and won on her own.Eugene left Vienna in early June 1716 with a field army of between 80,000 and 90,000 men. By early August 1716 the Ottoman Turks, some 200,000 men under the sultan's son-in-law, the Grand Vizier Damat Ali Pasha, were marching from Belgrade towards Eugene's position on the north bank of the Danube west of the fortress of Petrovaradin. The Grand Vizier had intended to seize the fortress; but Eugene gave him no chance to do so. After resisting calls for caution and forgoing a council of war, the Prince decided to attack immediately on the morning of 5 August with approximately 70,000 men. The Turkish janissaries had some initial success, but after an Imperial cavalry attack on their flank, Ali Pasha's forces fell into confusion. Although the Imperials lost almost 5,000 dead or wounded, the Turks, who retreated in disorder to Belgrade, seem to have lost double that amount, including the Grand Vizier himself who had entered the mêlée and subsequently died of his wounds.

Eugene proceeded to take the Banat fortress of Temeswar in mid-October 1716 (thus ending 164 years of Turkish rule), before turning his attention to the next campaign and to what he considered the main goal of the war, Belgrade. Situated at the confluence of the Rivers Danube and Sava, Belgrade held a garrison of 30,000 men under Serasker Mustapha Pasha.
Imperial troops besieged the place in mid-June 1717, and by the end of July large parts of the city had been destroyed by artillery fire. By the first days of August, however, a huge Turkish field army (150,000–200,000 strong), under the new Grand Vizier Hacı Halil Pasha had arrived on the plateau east of the city to relieve the garrison. News spread through Europe of Eugene's imminent destruction; but he had no intention of lifting the siege. With his men suffering from dysentery, and continuous bombardment from the plateau, Eugene, aware that a decisive victory alone could extricate his army, decided to attack the relief force. On the morning of 16 August, 40,000 Imperial troops marched through the fog, caught the Turks unaware, and routed Halil Pasha's army; a week later Belgrade surrendered, effectively bringing an end to the war. The victory was the crowning point of Eugene's military career and had confirmed him as the leading European general. His ability to snatch victory at the moment of defeat had shown the prince at his best.

The principal objectives of the war had been achieved: the task Eugene had begun at Zenta was complete, and the Karlowitz settlement secured. By the terms of the Treaty of Passarowitz, signed on 21 July 1718, the Turks surrendered the Banat of Temeswar, along with Belgrade and most of Serbia, although they regained the Morea from the Venetians. The war had dispelled the immediate Turkish threat to Hungary and was a triumph for Austria and for Eugene personally.

While Eugene fought the Turks in the east, unresolved issues following the Utrecht/Rastatt settlements led to hostilities between the Emperor and Philip V of Spain in the west. Charles VI had refused to recognise Philip V as King of Spain, a title which he himself claimed; in return, Philip V had refused to renounce his claims to Naples, Milan, and the Netherlands, all of which had transferred to the House of Austria following the Spanish Succession war. Philip V was roused by his influential wife, Elisabeth Farnese, daughter of the Hereditary Prince of Parma, who personally held dynastic claims in the name of her son, Charles, to the duchies of Tuscany, Parma and Piacenza. Representatives from a newly formed Anglo-French alliance—who were desirous of European peace for their own dynastic securities and trade opportunities—called on both parties to recognise each other's sovereignty. Yet Philip V remained intractable, and on 22 August 1717 his chief minister, Alberoni, effected the invasion of Austrian Sardinia in what seemed like the beginning of the reconquest of Spain's former Italian empire.

Eugene returned to Vienna from his recent victory at Belgrade (before the conclusion of the Turkish war) determined to prevent an escalation of the conflict, complaining that, "two wars cannot be waged with one army"; only reluctantly did the Prince release some troops from the Balkans for the Italian campaign. Rejecting all diplomatic overtures Philip V unleashed another assault in June 1718, this time against Savoyard Sicily as a preliminary to attacking the Italian mainland. Realizing that only the British fleet could prevent further Spanish landings, and that pro-Spanish groups in France might push the regent, Duke of Orléans, into war against Austria, Charles VI had no option but to sign the Quadruple Alliance on 2 August 1718, and formally renounce his claim to Spain. Despite the Spanish fleet's destruction off Cape Passaro, Philip V and Elisabeth remained resolute, and rejected the treaty.

Although Eugene could have gone south after the conclusion of the Turkish war, he chose instead to conduct operations from Vienna; but Austria's military effort in Sicily proved derisory, and Eugene's chosen commanders, Zum Jungen, and later Count Mercy, performed poorly. It was only from pressure exerted by the French army advancing into the Basque provinces of northern Spain in April 1719, and the British Navy's attacks on the Spanish fleet and shipping, that compelled Philip V and Elisabeth to dismiss Alberoni and join the Quadruple Alliance on 25 January 1720. Nevertheless, the Spanish attacks had strained Charles VI's government, causing tension between the Emperor and his Spanish Council on the one hand, and the conference, headed by Eugene, on the other. Despite Charles VI's own personal ambitions in the Mediterranean it was clear to the Emperor that Eugene had put the safeguarding of his conquests in Hungary before everything else, and that military failure in Sicily also had to rest on Eugene. Consequently, the Prince's influence over the Emperor declined considerably.

Eugene had become governor of the Austrian Netherlands—in June 1716, but he was an absent ruler, directing policy from Vienna through his chosen representative the Marquis of Prié. Prié proved unpopular with the local population and the guilds who, following the Barrier Treaty of 1715, were obliged to meet the financial demands of the administration and the Dutch barrier garrisons; with Eugene's backing and encouragement, civil disturbances in Antwerp and Brussels were forcibly suppressed. After displeasing the Emperor over his initial opposition to the formation of the Ostend Company, Prié also lost the support of the native nobility from within his own council of state in Brussels, particularly from the Marquis de Mérode-Westerloo. One of Eugene's former favourites, General Bonneval, also joined the noblemen in opposition to Prié, further undermining the Prince. When Prié's position became untenable, Eugene felt compelled to resign his post as governor of the Austrian Netherlands on 16 November 1724. As compensation, Charles VI conferred on him the honorary position as vicar-general of Italy, worth 140,000 gulden a year, and an estate at Siebenbrunn in Lower Austria said to be worth double that amount. But his resignation distressed him, and to compound his concerns Eugene caught a severe bout of influenza that Christmas, marking the beginning of permanent bronchitis and acute infections every winter for the remaining twelve years of his life.

The 1720s saw rapidly changing alliances between the European powers and almost constant diplomatic confrontation, largely over unsolved issues regarding the Quadruple Alliance. The Emperor and the Spanish king continued to use each other's titles, and Charles VI still refused to remove the remaining legal obstacles to Don Charles' eventual succession to the duchies of Parma and Tuscany. Yet in a surprise move Spain and Austria moved closer with the signing of the Treaty of Vienna in April/May 1725. In response Britain, France, and Prussia joined together in the Alliance of Hanover to counter the danger to Europe of an Austro-Spanish hegemony. For the next three years there was the continual threat of war between the Hanover Treaty powers and the Austro-Spanish bloc.

From 1726, Eugene gradually began to regain his political influence. With his many contacts throughout Europe Eugene, backed by Gundaker Starhemberg and Count Schönborn, the Imperial vice-chancellor, managed to secure powerful allies and strengthen the Emperor's position—his skill in managing the vast secret diplomatic network over the coming years was the main reason why Charles VI once again came to depend upon him. In August 1726 Russia acceded to the Austro-Spanish alliance, and in October Frederick William I of Prussia followed suit by defecting from the Allies with the signing of a mutual defensive treaty with the Emperor.
Despite the conclusion of the brief Anglo-Spanish conflict, manoeuvring between the European powers persisted throughout 1727–28. In 1729 Elisabeth Farnese abandoned the Austro-Spanish alliance. Realizing that Charles VI could not be drawn into the marriage pact she wanted, Elisabeth concluded that the best way to secure her son's succession to Parma and Tuscany now lay with Britain and France. To Eugene it was 'an event that which is seldom to be found in history'. Following the Prince's determined lead to resist all pressure, Charles VI sent troops into Italy to prevent the entry of Spanish garrisons into the contested duchies. By the beginning of 1730 Eugene, who had remained bellicose throughout the whole period, was again in control of Austrian policy.

In Britain there now emerged a new political re-alignment as the Anglo-French "entente" became increasingly defunct. Believing that a resurgent France now posed the greatest danger to their security British ministers, headed by Robert Walpole, moved to reform the Anglo-Austrian Alliance, leading to the signing of the Second Treaty of Vienna on 16 March 1731. Eugene had been the Austrian minister most responsible for the alliance, believing once again it would provide security against France and Spain. The treaty compelled Charles VI to sacrifice the Ostend Company and accept, unequivocally, the accession of Don Charles to Parma and Tuscany. In return King George II as King of Great Britain and Elector of Electorate of Hanover guaranteed the Pragmatic Sanction, the device to secure the rights of the Emperor's daughter, Maria Theresa, to the entire Habsburg inheritance. It was largely through Eugene's diplomacy that in January 1732 the Imperial diet also guaranteed the Pragmatic Sanction which, together with the Treaties with Britain, Russia, and Prussia, marked the culmination of the Prince's diplomacy. But the Treaty of Vienna had infuriated the court of King Louis XV: the French had been ignored and the Pragmatic Sanction guaranteed, thus increasing Habsburg influence and confirming Austria's vast territorial size. The Emperor also intended Maria Theresa to marry Duke Francis Stephen of Lorraine which would present an unacceptable threat on France's border. By the beginning of 1733 the French army was ready for war: all that was needed was the excuse.

In 1733 the Polish King and Elector of Saxony, Augustus the Strong, died. There were two candidates for his successor: first, Stanisław Leszczyński, the father-in-law of Louis XV; second, the Elector of Saxony's son, Augustus, supported by Russia, Austria, and Prussia. The Polish succession had afforded Louis XV's chief minister, Fleury, the opportunity to attack Austria and take Lorraine from Francis Stephen. To gain Spanish support France backed the succession of Elisabeth Farnese's sons to further Italian lands.

Eugene entered the War of the Polish Succession as President of the Imperial War Council and commander-in-chief of the army, but he was severely handicapped by the quality of his troops and the shortage of funds; now in his seventies, the Prince was also burdened by rapidly declining physical and mental powers. France declared war on Austria on 10 October 1733, but without the funds from the Maritime Powers — who, despite the Vienna treaty, remained neutral throughout the war — Austria could not hire the necessary troops to wage an offensive campaign. "The danger to the monarchy", wrote Eugene to the Emperor in October, "cannot be exaggerated". By the end of the year French forces had seized Lorraine and Milan; by early 1734 Spanish troops had taken Sicily.

Eugene took command on the Rhine in April 1734, but vastly outnumbered he was forced onto the defensive. In June Eugene set out to relieve Philippsburg, yet his former drive and energy was now gone. Accompanying Eugene was a young prince Frederick of Prussia, sent by his father to learn the art of war. Frederick gained considerable knowledge from Eugene, recalling in later life his great debt to his Austrian mentor, but the Prussian prince was aghast at Eugene's condition, writing later, "his body was still there but his soul had gone." Eugene conducted another cautious campaign in 1735, once again pursuing a sensible defensive strategy on limited resources; but his short-term memory was by now practically non-existent, and his political influence disappeared completely—Gundaker Starhemberg and Johann Christoph von Bartenstein now dominated the conference in his place. Fortunately for Charles VI, Fleury was determined to limit the scope of the war, and in October 1735 he granted generous peace preliminaries to the Emperor.

Eugene returned to Vienna from the War of the Polish Succession in October 1735, weak and feeble; when Maria Theresa and Francis Stephen married in February 1736 Eugene was too ill to attend. After playing cards at Countess Batthyány's on the evening of 20 April until nine in the evening, he returned home to the Stadtpalais, his attendant offered him to take his prescribed medicine which Eugene declined.

When his servants arrived to wake him the next morning on 21 April 1736, they found Prince Eugene dead after passing away quietly during the night. It has been said that on the same morning he was discovered dead, the great lion in his menagerie was also found dead.

Eugene's heart was buried with the ashes of his ancestors in Turin, in the Basilica of Superga. His remains were carried in a long procession to St. Stephen's Cathedral, where his embalmed body was buried in the "Kreuzkapelle". It is said that the emperor himself attended as a mourner without anybody's knowledge.

The Prince's niece Maria Anna Victoria, whom he had never met, inherited Eugene's immense possessions. Within a few years she sold off the palaces, the country estates and the art collection of a man who had become one of the wealthiest in Europe, after arriving in Vienna as a refugee with empty pockets.

Being an Italian by descent, a Frenchman by birth, and a German by adoption, Prince Eugene signed himself appropriately using the trilingual form "Eugenio von Savoye" (Italian: Eugenio, German:von, French:Savoye).

Eugene never married and was reported to have said that a woman was a hindrance in a war, and that a soldier should never marry; according to some of his contemporaries, Eugene's loss at the 1712 Battle of Denain was due to the presence of an Italian lady that he took with him on the campaign; this was confirmed by Voltaire who reported meeting the lady in question. According to Nicholas Henderson, Eugene was called "Mars without Venus" for being a lifelong bachelor. Winston Churchill in his of the 1st Duke of Marlborough described Eugene as "a bachelor, almost a misogynist, disdainful of money, content with his bright sword and his lifelong animosity against Louis XIV".

During the last 20 years of his life Eugène had a relationship with one woman, Hungarian Countess Eleonore Batthyány-Strattmann, the widowed daughter of the former Theodor von Strattman. Much of their acquaintance remains speculative since Eugene left no personal papers: only letters of war, diplomacy, and politics. Eugène and Eleonore were constant companions, meeting for dinner, receptions and card games almost every day till his death; although they lived apart most foreign diplomats assumed that Eleonore was his long time mistress. It is not known precisely when their relationship began, but his acquisition of a property in Hungary after the Battle of Zenta, near Rechnitz Castle, made them neighbours. In the years immediately following the War of the Spanish Succession she began to be mentioned regularly in diplomatic correspondence as "Eugen's Egeria" and within a few years she was referred to as his constant companion and his mistress. When asked if she and the Prince would marry, Countess Batthyány replied: "I love him too well for that, I would rather have a bad reputation than deprive him of his".

Rumours about Eugene's sexual orientation can be traced back to his teenage years. It has since been established that the source of these rumours was Elizabeth Charlotte, Duchess of Orléans, a renowned gossipmonger at Versailles, whose husband Philippe I, Duke of Orléans happened to be the brother of French King Louis XIV, Eugene's lifelong adversary. The Duchess documented what she claimed were youthful indiscretions involving Eugene, including alleged incidents with lackeys and pages. According to her, he was denied an ecclesiastical benefice due to his "depravity". Eugene's biographer, historian Helmut Oehler, acknowledged the Duchess's comments but attributed them to her personal animosity toward the Prince. 
In his memoirs, Eugene, aware of the malicious rumours, derisively addressed them, calling them "the invented anecdotes from the gallery of Versailles”. Whether or not Eugene had homosexual relationships in his youth, the Duchess's remarks about him were made years later, and only after Eugene had severely humiliated the armies of her brother-in-law, the King of France. Following Eugene's departure from France at nineteen, and spanning until his death at seventy-two, there were no subsequent insinuations of homosexuality.

Being among the wealthiest and most celebrated figures of his era inevitably led to animosity for Eugene, as envy and malice trailed him from the battlefields to Vienna. His former subordinate Guido Starhemberg emerged as a persistent and bitter critic of Eugene's renown. Starhemberg, according to Montesquieu, gained notoriety at the court of Vienna as Eugene's primary rival. In a letter to a friend, Johann Matthias von der Schulenburg, another bitter rival who had served under Eugene in the War of the Spanish Succession, expressed disdain for the prince. Schulenburg, whose ambitions to command the Austrian army had been thwarted by Eugene, wrote that the prince "has no idea but to fight whenever the opportunity offers; he thinks that nothing equals the name of Imperialists, before whom all should bend the knee. He loves . German journalist Curt Martin Riess, reads it as "a testament to sodomy," while Eugene's primary biographer, German historian Max Braubach, interpreted "la p..." as referring to Paillardize (fornication), Prostitution, or Puterie, i.e. Whoring.

During his tenure as Governor-General of the Austrian Netherlands, Eugene developed a reputation for frequenting an exclusive brothel on Amsterdam's Prinsengracht. The keeper of the establishment, known as Madame Therese, was familiar with Eugene's patronage. Notably, Eugene once brought the English consul in Amsterdam with him. A drawing by Cornelis Troost, housed at the Rijksmuseum, the national museum of the Netherlands, illustrates a scene in which Prince Eugene had "the 'available' women parade in review, just as he did his own troops," according to the museum. Troost based his drawing on an anecdote circulating at the time.

Eugene's other friends such as the papal nuncio, Passionei, who delivered the funeral oration of Prince Eugene, made up for the family he lacked. For his only surviving nephew, Emmanuel, the son of his brother Louis Thomas, Eugene arranged marriage with one of the daughters of Prince Liechtenstein, but Emmanuel died of smallpox in 1729. With the death of Emmanuel's son in 1734, no close male relatives remained to succeed the Prince. His closest relative, therefore, was Louis Thomas's unmarried daughter, Princess Maria Anna Victoria of Savoy, daughter of his eldest brother, the count of Soissons, whom Eugene had never met and had made no effort to do so.
Eugene's rewards for his victories, his share of booty, his revenues from his abbeys in Savoy, and a steady income from his Imperial offices and governorships, enabled him to contribute to the landscape of Baroque architecture Eugene spent most of his life in Vienna at his Winter Palace, the Stadtpalais, built by Fischer von Erlach. The palace acted as his official residence and home, but for reasons that remain speculative the Prince's association with Fischer ended before the building was complete, favouring instead Johann Lukas von Hildebrandt as his chief architect. Eugene first employed Hildebrandt to finish the Stadtpalais before commissioning him to prepare plans for a palace (Savoy Castle) on his Danubian island at Ráckeve. Begun in 1701 the single-story building took twenty years to complete; yet, probably because of the Rákóczi revolt, the Prince seems to have visited it only once—after the siege of Belgrade in 1717.

Of more importance was the grandiose complex of the two Belvedere palaces in Vienna. The single-storey Lower Belvedere, with its exotic gardens and zoo, was completed in 1716. The Upper Belvedere, completed between 1720 and 1722, is a more substantial building; with sparkling white stucco walls and copper roof, it became a wonder of Europe. Eugene and Hildebrandt also converted an existing structure on his Marchfeld estate into a country seat, the Schloss Hof, situated between the Rivers Danube and Morava. The building, completed in 1729, was far less elaborate than his other projects but it was strong enough to serve as a fortress in case of need. Eugene spent much of his spare time there in his last years accommodating large hunting parties.

In the years following the Peace of Rastatt Eugene became acquainted with a large number of scholarly men. Given his position and responsiveness, they were keen to meet him: few could exist without patronage and this was probably the main reason for Gottfried Leibniz's association with him in 1714. Eugene also befriended the French writer Jean-Baptiste Rousseau who, by 1716, was receiving financial support from Eugene. Rousseau stayed on attached to the Prince's household, probably helping in the library, until he left for the Netherlands in 1722. Another acquaintance, Montesquieu, already famous for his "Persian Letters" when he arrived in Vienna in 1728, favourably recalled his time spent at the Prince's table. Nevertheless, Eugene had no literary pretensions of his own, and was not tempted like Maurice de Saxe or Marshal Villars to write his memoirs or books on the art of war. He did, however, become a collector on the grandest scale: his picture galleries were filled with 16th- and 17th-century Italian, Dutch and Flemish art; his library at the Stadtpalais crammed with over 15,000 books, 237 manuscripts as well as a huge collection of prints (of particular interest were books on natural history and geography). "It is hardly believable", wrote Rousseau, "that a man who carries on his shoulders the burden of almost all the affairs of Europe ... should find as much time to read as though he had nothing else to do."

At Eugene's death his possessions and estates, except those in Hungary which the crown reclaimed, went to his niece, Princess Maria Anna Victoria, who at once decided to sell everything. The artwork was bought by Charles Emmanuel III of Sardinia. Eugene's library, prints and drawings were purchased by the Emperor in 1737 and have since passed into Austrian national collections.

Napoleon considered Eugene one of the seven greatest commanders of history. Although later military critics have disagreed with that assessment, Eugene was undoubtedly the greatest Austrian general. He was no military innovator, but he had the ability to make an inadequate system work. He was equally adept as an organiser, strategist, and tactician, believing in the primacy of battle and his ability to seize the opportune moment to launch a successful attack. "The important thing", wrote Maurice de Saxe in his "Reveries", "is to see the opportunity and to know how to use it. Prince Eugene possessed this quality which is the greatest in the art of war and which is the test of the most elevated genius." This fluidity was key to his battlefield successes in Italy and in his wars against the Turks. Nevertheless, in the Low Countries, particularly after the battle of Oudenarde in 1708, Eugene, like his cousin Louis of Baden, tended to play safe and become bogged down in a conservative strategy of sieges and defending supply lines. After the attempt on Toulon in 1707, he also became very wary of combined land/sea operations. To historian Derek McKay the main criticism of him as a general is his legacy—he left no school of officers nor an army able to function without him.

Eugene was a disciplinarian—when ordinary soldiers disobeyed orders he was prepared to shoot them himself—but he rejected blind brutality, writing "you should only be harsh when, as often happens, kindness proves useless".

On the battlefield Eugene demanded courage in his subordinates, and expected his men to fight where and when he wanted; his criteria for promotion were based primarily on obedience to orders and courage on the battlefield rather than social position. On the whole, his men responded because he was willing to push himself as hard as them. His position as President of the Imperial War Council proved less successful. Following the long period of peace after the Austro-Turkish War, the idea of creating a separate field army or providing garrison troops with effective training for them to be turned into such an army quickly was never considered by Eugene. By the time of the War of the Polish Succession, therefore, the Austrians were outclassed by a better prepared French force. For this Eugene was largely to blame—in his view (unlike the drilling and manoeuvres carried out by the Prussians which to Eugene seemed irrelevant to real warfare) the time to create actual fighting men was when war came.

Although Frederick II of Prussia had been struck by the muddle of the Austrian army and its poor organisation during the Polish Succession war, he later amended his initial harsh judgements. "If I understand anything of my trade", commented Frederick in 1758, "especially in the more difficult aspects, I owe that advantage to Prince Eugene. From him I learnt to hold grand objectives constantly in view, and direct all my resources to those ends." To historian Christopher Duffy it was this awareness of the 'grand strategy' that was Eugene's legacy to Frederick.

To his responsibilities, Eugene attached his own personal values — physical courage, loyalty to his sovereign, honesty, self-control in all things — and he expected these qualities from his commanders. Eugene's approach was dictatorial, but he was willing to co-operate with someone he regarded as his equal, such as Baden or Marlborough. Yet the contrast with his co-commander of the Spanish Succession war was stark. According to Churchill, "Marlborough was the model husband and father, concerned with building up a home, founding a family, and gathering a fortune to sustain it", whereas Eugene, the bachelor, was "disdainful of money, content with his bright sword and his lifelong animosities against Louis XIV".
The result was an austere figure, inspiring respect and admiration rather than affection.

Sicco van Goslinga, one of the Dutch field deputies who worked very close with Eugene during his campaigns with Marlborough, described him in his memoires as follows:


Several ships have been named in Eugene's honour:




Emanuel Leutze

Emanuel Gottlieb Leutze (May 24, 1816July 18, 1868) was a German-born American history painter best known for his 1851 painting "Washington Crossing the Delaware". He is associated with the Düsseldorf school of painting.

Leutze was born in Schwäbisch Gmünd, Kingdom of Württemberg. Later he was brought to the United States as a child in 1825. His parents settled first in Fredericksburg, Virginia, and then at Philadelphia. The first development of his artistic talent occurred while he was attending the sickbed of his father, when he attempted drawing to occupy the long hours of waiting. His father died in 1831. At 14, he was painting portraits for $5 apiece. Through such work, he supported himself after the death of his father. In 1834, he received his first instruction in art at the classes of John Rubens Smith, a portrait painter in Philadelphia. He soon became skilled, and promoted a plan for publishing, in Washington, portraits of eminent American statesmen; however, he was met with slight encouragement.

In 1840, one of his paintings attracted attention and gave him several orders, which enabled him to attend the Kunstakademie Düsseldorf in his native Germany. Due to his anti-academic attitude, he studied only one year at the academy, in the class of Director Schadow. Leutze was mostly influenced by the painter Karl Friedrich Lessing. In 1842 he went to Munich, studying the works of Cornelius and Kaulbach, and, while there, finished his "Columbus before the Queen". The following year he visited Venice and Rome, making studies from Titian and Michelangelo. His first work, "Columbus before the Council of Salamanca" (1841) was purchased by the Düsseldorf Art Union. A companion picture, "Columbus in Chains", procured him the gold medal of the Brussels Art Exhibition, and was subsequently purchased by the Art Union in New York; it was the basis of the 1893 $2 Columbian Issue stamp. In 1845, after a tour in Italy, he returned to Düsseldorf, marrying Juliane Lottner and making his home there for 14 years.

During his years in Düsseldorf, he was a resource for visiting Americans: he found them places to live and work, provided introductions, and gave them emotional and even financial support. For many years, he was the president of the Düsseldorf Artists' Association; in 1848, he was an early promoter of the "Malkasten" art association; and in 1857, he led the call for a gathering of artists which originated the founding of the Allgemeine deutsche Kunstgenossenschaft.
A strong supporter of Europe's Revolutions of 1848, Leutze decided to paint an image that would encourage Europe's liberal reformers with the example of the American Revolution. Using American tourists and art students as models and assistants, Leutze finished a first version of "Washington Crossing the Delaware" in 1850. Just after it was completed, the first version was damaged by fire in his studio, subsequently restored, and acquired by the Kunsthalle Bremen. On September 5, 1942, during World War II, it was destroyed in a bombing raid by the Allied forces. The second painting, a replica of the first, only larger, was ordered in 1850 by the Parisian art trader Adolphe Goupil for his New York branch and placed on exhibition on Broadway in October 1851. It is now owned by the Metropolitan Museum of Art in New York. In 1854, Leutze finished his depiction of the Battle of Monmouth, "Washington rallying the troops at Monmouth," commissioned by an important patron, the banker David Leavitt of New York City and Great Barrington, Massachusetts.

In 1859, Leutze returned to the United States and opened a studio in New York City. He divided his time between New York City and Washington, D.C. In 1859, he painted a portrait of Chief Justice Roger Brooke Taney, which hangs in the Harvard Law School. In a 1992 opinion, Justice Antonin Scalia described the portrait of Taney, made two years after Taney's infamous decision in "Dred Scott v. Sandford", as showing Taney "in black, sitting in a shadowed red armchair, left hand resting upon a pad of paper in his lap, right hand hanging limply, almost lifelessly, beside the inner arm of the chair. He sits facing the viewer and staring straight out. There seems to be on his face, and in his deep-set eyes, an expression of profound sadness and disillusionment."

Leutze also executed other portraits, including one of fellow painter William Morris Hunt. That portrait was owned by Hunt's brother Leavitt Hunt, a New York attorney and sometime Vermont resident, and was shown at an exhibition devoted to William Morris Hunt's work at the Museum of Fine Arts, Boston in 1878.

In 1860 Leutze was commissioned by the U.S. Congress to decorate a stairway in the Capitol Building in Washington, DC, for which he painted a large composition, "Westward the Course of Empire Takes Its Way", which is also commonly known as "Westward Ho!".

Late in life, he became a member of the National Academy of Design. He was also a member of the Union League Club of New York, which has a number of his paintings. At age 52, he died in Washington, D.C. of heat stroke. He was interred at Glenwood Cemetery. At the time of his death, a painting, "The Emancipation of the Slaves", was in preparation.Leutze's portraits are known for the artistic quality of their patriotic romanticism, and his epic "Washington Crossing the Delaware" ranks in the utmost echelon of American national iconography.
Additional References:


Erasmus Alberus

Erasmus Alberus (c. 15005 May 1553) was a German humanist, Lutheran reformer, and poet.

He was born in the village of Bruchenbrücken (now part of Friedberg, Hesse) about the year 1500. Although his father Tilemann Alber was a schoolmaster, his early education was neglected.
Ultimately in 1518, he found his way to the University of Wittenberg, where he studied theology. He had the good fortune to attract the attention of Martin Luther and Philipp Melanchthon, and subsequently became one of Luther's most active helpers in the Protestant Reformation.

Not only did he fight for the Protestant cause as a preacher and theologian, but he was almost the only member of Luther's party who was able to confront the Roman Catholics with the weapon of literary satire. In 1542 he published a prose satire to which Luther wrote the preface, "Der Barfusser Monche Eulenspiegel und Alkoran," a parodic adaptation of the "Liber conformitatum" of the Franciscan Bartolommeo Rinonico of Pisa, in which the Franciscan order is held up to ridicule. This drew reactions from Catholic scholars such as Henricus Sedulius, who published the "Apologeticus aduersus Alcoranum Franciscanorum, pro Libro Conformitatum," which criticized Alberus' arguments in this satire. 

Of higher literary value is the didactic and satirical "Buch von der Tugend und Weisheit" (1550), a collection of forty-nine fables in which Alberus embodies his views on the relations of Church and State. His satire is incisive, but in a scholarly and humanistic way; it does not appeal to popular passions with the fierce directness which enabled the master of Catholic satire, Thomas Murner, to inflict such telling blows.

Several of Alberus's hymns, all of which show the influence of his master Luther, have been retained in the German Protestant hymnal.

After Luther's death, Alberus was for a time a deacon in Wittenberg; he became involved, however, in the political conflicts of the time, and was in Magdeburg in 1550–1551, while that town was besieged by Maurice, Elector of Saxony. In 1552 he was appointed General Superintendent at Neubrandenburg in Mecklenburg, where he died on 5 May 1553.


Attribution:

Earley parser

In computer science, the Earley parser is an algorithm for parsing strings that belong to a given context-free language, though (depending on the variant) it may suffer problems with certain nullable grammars. The algorithm, named after its inventor, Jay Earley, is a chart parser that uses dynamic programming; it is mainly used for parsing in computational linguistics. It was first introduced in his dissertation in 1968 (and later appeared in an abbreviated, more legible, form in a journal).

Earley parsers are appealing because they can parse all context-free languages, unlike LR parsers and LL parsers, which are more typically used in compilers but which can only handle restricted classes of languages. The Earley parser executes in cubic time in the general case formula_1, where "n" is the length of the parsed string, quadratic time for unambiguous grammars formula_2, and linear time for all deterministic context-free grammars. It performs particularly well when the rules are written left-recursively.

The following algorithm describes the Earley recogniser. The recogniser can be modified to create a parse tree as it recognises, and in that way can be turned into a parser.

In the following descriptions, α, β, and γ represent any string of terminals/nonterminals (including the empty string), X and Y represent single nonterminals, and "a" represents a terminal symbol.

Earley's algorithm is a top-down dynamic programming algorithm. In the following, we use Earley's dot notation: given a production X → αβ, the notation X → α • β represents a condition in which α has already been parsed and β is expected.

Input position 0 is the position prior to input. Input position "n" is the position after accepting the "n"th token. (Informally, input positions can be thought of as locations at token boundaries.) For every input position, the parser generates a "state set". Each state is a tuple (X → α • β, "i"), consisting of


A state is finished when its current position is the last position of the right side of the production, that is, when there is no symbol to the right of the dot • in the visual representation of the state.

The state set at input position "k" is called S("k"). The parser is seeded with S(0) consisting of only the top-level rule. The parser then repeatedly executes three operations: "prediction", "scanning", and "completion".


Duplicate states are not added to the state set, only new ones. These three operations are repeated until no new states can be added to the set. The set is generally implemented as a queue of states to process, with the operation to be performed depending on what kind of state it is.

The algorithm accepts if (X → γ •, 0) ends up in S("n"), where (X → γ) is the top level-rule and "n" the input length, otherwise it rejects.

Adapted from Speech and Language Processing by Daniel Jurafsky and James H. Martin, 
DECLARE ARRAY S;

function INIT(words)

function EARLEY_PARSE(words, grammar)

procedure PREDICTOR((A → α•Bβ, j), k, grammar)

procedure SCANNER((A → α•aβ, j), k, words)

procedure COMPLETER((B → γ•, x), k)
Consider the following simple grammar for arithmetic expressions:

<P> ::= <S> # the start rule
<S> ::= <S> "+" <M> | <M>
<M> ::= <M> "*" <T> | <T>
<T> ::= "1" | "2" | "3" | "4"

With the input:

This is the sequence of state sets:

The state (P → S •, 0) represents a completed parse. This state also appears in S(3) and S(1), which are complete sentences.

Earley's dissertation briefly describes an algorithm for constructing parse trees by adding a set of pointers from each non-terminal in an Earley item back to the items that caused it to be recognized. But Tomita noticed that this does not take into account the relations between symbols, so if we consider the grammar S → SS | b and the string bbb, it only notes that each S can match one or two b's, and thus produces spurious derivations for bb and bbbb as well as the two correct derivations for bbb.

Another method is to build the parse forest as you go, augmenting each Earley item with a pointer to a shared packed parse forest (SPPF) node labelled with a triple (s, i, j) where s is a symbol or an LR(0) item (production rule with dot), and i and j give the section of the input string derived by this node. A node's contents are either a pair of child pointers giving a single derivation, or a list of "packed" nodes each containing a pair of pointers and representing one derivation. SPPF nodes are unique (there is only one with a given label), but may contain more than one derivation for ambiguous parses. So even if an operation does not add an Earley item (because it already exists), it may still add a derivation to the item's parse forest.


SPPF nodes are never labeled with a completed LR(0) item: instead they are labelled with the symbol that is produced so that all derivations are combined under one node regardless of which alternative production they come from.

Philippe McLean and R. Nigel Horspool in their paper "A Faster Earley Parser" combine Earley parsing with LR parsing and achieve an improvement in an order of magnitude.
















Ethiopian cuisine

Ethiopian cuisine ( "Ye-Ītyōṗṗyā məgəb") characteristically consists of vegetable and often very spicy meat dishes. This is usually in the form of "wat," a thick stew, served on top of "injera" (), a large sourdough flatbread, which is about in diameter and made out of fermented teff flour. Ethiopians usually eat with their right hands, using pieces of to pick up bites of entrées and side dishes.

The Ethiopian Orthodox Tewahedo Church prescribes a number of fasting periods known as "tsom" ( "ṣōm"), including all Wednesdays and Fridays and the whole Lenten season (including fifteen days outside Lent proper). Per Oriental Orthodox tradition, the faithful may not consume any kind of animal products (including dairy products and eggs) during fasts; therefore, Ethiopian cuisine contains many dishes that are vegan.

A typical dish consists of accompanied by a spicy stew, which frequently includes beef, lamb, vegetables and various types of legumes, such as lentils is traditionally consumed on the mesob. The cuisines of the Southern Nations, Nationalities and People's Region and the Sidama region also make use of the false banana plant (, Ge'ez: እንሰት "ïnset"), a type of ensete. The plant is pulverized and fermented to make various foods, including a bread-like food called "kocho" (Ge'ez: ቆጮ "ḳōč̣ō"), which is eaten with kitfo. The root of this plant may be powdered and prepared as a hot drink called "bulla" (Ge'ez: ቡላ "būlā"), which is often given to those who are tired or ill. Another typical Gurage preparation is coffee with butter ("kebbeh"). "Kita" herb bread is also baked.

Due in part to the brief Italian occupation, pasta is popular and frequently available throughout Ethiopia, including rural areas. Coffee is also a large part of Ethiopian culture and cuisine. After every meal, a coffee ceremony is enacted and coffee is served.

Ethiopian Orthodox Christians, Ethiopian Jews and Ethiopian Muslims avoid eating pork or shellfish, for religious reasons. Pork is considered unclean in Ethiopian Orthodox Christianity, Judaism and Islam. Most Ethiopian Protestants or P'ent'ay also abstain from eating food already prohibited from the Orthodox church. Many Ethiopians abstain from eating certain meats, eating mostly vegetarian foods, partially from the high cost of meat, eggs, dairy products.

"Berbere", a combination of powdered chili pepper and other spices (cardamom, fenugreek, coriander, cloves, ginger, nutmeg, cumin and allspice) is an important ingredient used to add flavor to many varied dishes like chicken stews and baked fish dishes. Also essential is "niter kibbeh", a clarified butter infused with ginger, garlic, and several spices.

"Mitmita" (, ) is a powdered seasoning mix used in Ethiopian cuisine. It is orange-red in color and contains ground birdseye chili peppers (piri-piri), cardamom seed, cloves and salt. It occasionally has other spices including cinnamon, cumin and ginger.

In their adherence to strict fasting, Ethiopian cooks have developed a rich array of cooking oil sources—besides sesame and safflower—for use as a substitute for animal fats which are forbidden during fasting periods. Ethiopian cuisine also uses "nug" (also spelled "noog", also known as "niger seed").

"Wat" begins with a large amount of chopped red onion, which is simmered or sauteed in a pot. Once the onions have softened, "niter kebbeh" (or, in the case of vegan dishes, vegetable oil) is added. Following this, "berbere" is added to make a spicy "keiy wat" or "keyyih tsebhi". Turmeric is used instead of "berbere" for a milder "alicha wat" or both spices are omitted when making vegetable stews, such as "atkilt wat". Meat such as beef ("ሥጋ", "səga"), chicken ("ዶሮ", "doro" or "derho"), fish ("ዓሣ", "asa"), goat or lamb ("በግ", "beg" or "beggi") is also added. Legumes such as split peas ("ክክ", "kək" or "kikki") and lentils ("ምስር", "məsər" or "birsin"); or vegetables such as potatoes ("ድንች", "Dənəch"), carrots and chard (ቆስጣ) are also used instead in vegan dishes.

Each variation is named by appending the main ingredient to the type of "wat" (e.g. ). However, the word "keiy" is usually not necessary, as the spicy variety is assumed when it is omitted (e.g. "doro wat"). The term is sometimes used to refer to all vegetable dishes, but a more specific name can also be used (as in , which translates to "potatoes and carrots stew"; but the word "atkilt" is usually omitted when using the more specific term).

Meat along with vegetables are sautéed to make "tibs" (also "tebs", "t'ibs", "tibbs", etc., Ge'ez: ጥብስ "ṭïbs"). "Tibs" is served in a variety of manners, and can range from hot to mild or contain little to no vegetables. There are many variations of the delicacy, depending on type, size or shape of the cuts of meat used. Beef, mutton, and goat are the most common meats used in the preparation of "tibs".
The mid-18th-century European visitor to Ethiopia describes "tibs" as a portion of grilled meat served "to pay a particular compliment or show especial respect to someone." It may still be seen this way; today the dish is prepared to commemorate special events and holidays.

"Kinche" ("qinch’e"), a porridge, is a very common Ethiopian breakfast or supper. It is simple, inexpensive, and nutritious. It is made from cracked wheat, Ethiopian oats, barley or a mixture of those. It can be boiled in either milk or water with a little salt. The flavor of "kinche" comes from the "nit'ir qibe", which is a spiced butter.

Azifa is an Ethiopian lentil salad made with mustard seed, jalapeños, and onions, and it is a dish often served cold. Buticha is an Ethiopian chickpea salad which is often served cold, and is sometimes compared to hummus.

The Oromos' cuisine consists of various vegetable or meat side dishes and entrées. As part of a long-established custom, practice, or belief, people do not eat pork in Oromia.


Another distinctively Ethiopian dish is "kitfo" (frequently spelled "ketfo"). It consists of raw (or rare) beef mince marinated in "mitmita" (Ge'ez: ሚጥሚጣ "mīṭmīṭā" a very spicy chili powder similar to ) and . "Gored gored" is very similar to , but uses cubed rather than ground beef.

 (or "Ayeb") is a local cheese made from the curds of buttermilk that is mild and crumbly, close in texture to crumbled feta. Although not quite pressed, the whey has been drained and squeezed out. It is often served as a side dish to soften the effect of very spicy food. It has little to no distinct taste of its own. However, when served separately, is often mixed with a variety of mild or hot spices typical of Gurage cuisine.

"Gomen kitfo" is another typical Gurage dish. Collard greens (ጎመን "gōmen") are boiled, dried and then finely chopped and served with butter, chili and spices. It is a dish specially prepared for the occasion of Meskel, a very popular holiday marking the discovery of the True Cross. It is served along with or sometimes even "kitfo" in this tradition called .

The enset plant (called "wesse" in the Sidamo language) is central to Sidama cuisine and after grinding and fermenting the root to produce "wassa", it is used in the preparation of several foods.

"Borasaame" is a cooked mixture of "wassa" and butter sometimes eaten with Ethiopian mustard greens and/or beans. It is traditionally eaten by hand using a false banana leaf and is served in a ', a vase-like ceramic vessel. A common variant of "borasaame" uses maize flour instead of "wassa" and is called "badela borasaame". "Borasaame" is typically paired with a seasoned yogurt drink called "wätät". Both are common foods for funerals and the celebration of "Fichee Chambalaalla", the Sidama new year.

 is an enset flatbread used similarly to to eat wats made from beef, mushrooms, beans, gomen, or pumpkin.

Gomen ba siga (ጎመን በስጋ, Amharic: "cabbage with meat") is a stewed mixture of beef and Ethiopian mustard served under a layer of bread.

A commonly grown crop in Sidama, maize ("badela" in Sidaamu; also known as "corn" in North America) is often eaten as a snack with coffee. It can be ground into flour to make bread, roasted on the cob, or the kernels can be picked off to make "bokolo", which is served either boiled or roasted.

"Fit-fit" or "fir-fir" is a common breakfast dish. It is made from shredded "" or "kitcha" stir-fried with spices or "wat". Another popular breakfast food is , a large fried pancake made with flour, often with a layer of egg, eaten with honey.

"Chechebsa" (or "kita firfir") resembles a pancake covered with "berbere" and "niter kibbeh", or other spices, and may be eaten with a spoon. "Genfo" is a kind of porridge, which is another common breakfast dish. It is usually served in a large bowl with a dug-out made in the middle of the genfo and filled with spiced "niter kibbeh".

A variation of "ful", a fava bean stew with condiments, served with baked rolls instead of , is also common for breakfast.

Typical Ethiopian snacks are "dabo kolo" (small pieces of baked bread that are similar to pretzels), or "kolo" (roasted barley sometimes mixed with other local grains). "Kolo" made from roasted and spiced barley, safflower kernels, chickpeas and/or peanuts are often sold by kiosks and street vendors, wrapped in a paper cone. Snacking on popcorn and traditional lentil samosa is also common.

There are many different traditional alcoholic drinks which are home made and of natural ingredients.

"Tella" is a home-brewed beer served in "tella bet" ("tella houses") which specialize in serving only "tella". "Tella" is the most common beverage made and served in households during holidays.

It is an alcoholic drink which is prepared from "bikil" (barley) as main ingredient and "gesho" ("Rhamnus prinoides") for fermentation purpose.

In Oromiffaa the drink is called "farso" and in Tigrinya "siwa".

"Tej" is a potent honey wine. It is similar to mead, and is frequently served in bars, particularly in a "tej bet" or ""tej" house".

It is prepared from honey and gesho. It has a sweet taste and the alcoholic content is relatively higher than "tella". This drink can be stored for a long time; the longer it is stored, the higher the alcohol content, and the stronger the taste.

"Areki", also known as "katikala", is probably the strongest alcoholic drink of Ethiopia. It is a home distilled spirit that is often filtered through charcoal to remove off tastes or flavored by smoking or infusion with garlic.

Ethiopians have diverse traditional non-alcoholic drinks which include natural and healthy ingredients.

"Kenetto", also known as "keribo", is a non-alcoholic traditional drink. It is mostly used as substitute for "tella" for those who don't drink alcohol.

"Borde" is a cereal-based traditional fermented beverage famous in southern Ethiopia.

Just like the rest of the world, Ethiopians also enjoy several locally manufactured beers, wine and non-alcoholic products like Coca-Cola and other similar products.
Ambo Mineral Water or "Ambo wuha" is a bottled carbonated mineral water, sourced from the springs in Ambo Senkele near the town of Ambo.

"Atmet" is a barley- and oat-flour based drink that is cooked with water, sugar and "kibe" (Ethiopian clarified butter) until the ingredients have combined to create a consistency slightly thicker than eggnog. Though this drink is often given to women who are nursing, the sweetness and smooth texture make it a comfort drink for anyone who enjoys its flavor.

According to some sources, drinking of coffee ("buna") is likely to have originated in Ethiopia. A key national beverage, it is an important part of local commerce.

The coffee ceremony is the traditional serving of coffee, usually after a big meal. It often involves the use of a "jebena" (ጀበና), a clay coffee pot in which the coffee is boiled. The preparer roasts the coffee beans in front of guests, then walks around wafting the smoke throughout the room so participants may sample the scent of coffee. Then the preparer grinds the coffee beans in a traditional tool called a . The coffee is put into the "jebena", boiled with water, and then served in small cups called "si'ni". Coffee is usually served with sugar, but is also served with salt in many parts of Ethiopia. In some parts of the country, "niter kibbeh" is added instead of sugar or salt.

Snacks, such as popcorn or toasted barley (or "kolo"), are often served with the coffee. In most homes, a dedicated coffee area is surrounded by fresh grass, with special furniture for the coffee maker. A complete ceremony has three rounds of coffee ("abol", "tona" and "bereka") and is accompanied by the burning of frankincense.

Tea will most likely be served if coffee is declined. Tea is grown in Ethiopia at Gumaro and Wushwush.

Across southern Ethiopia, many groups drink boiled coffee leaves, called "kuti" among the Harari in the east and "kaari" among the Majang in the west. This is often made with widely varying seasonings and spices, such as sugar, salt, rue, hot peppers, ginger. The Ethiopian Food Safety Authority has registered the safety of coffee leaf infusions with the European Union.



Epistle of James

The Epistle of James is a general epistle and one of the 21 epistles (didactic letters) in the New Testament. It was written originally in Koine Greek.

James 1:1 identifies the author as "James, a servant of God and of the Lord Jesus Christ" who is writing to "the twelve tribes scattered abroad". Traditionally, the epistle is attributed to James the brother of Jesus (James the Just), and the audience is considered generally to be Jewish Christians, who were dispersed outside Israel.

Framing his letter within an overall theme of patient perseverance during trials and temptations, James writes in order to encourage his readers to live consistently with what they have learned in Christ. He condemns various sins, including pride, hypocrisy, favouritism, and slander. He encourages and implores believers to live humbly by godly, rather than worldly, wisdom; he encourages prayer in all situations. 

For the most part, until the late 20th century, the epistle of James was relegated to benign disregard – though it was shunned by many early theologians and scholars due to its advocacy of Torah observance and good works. Famously, Luther at one time considered the epistle to be among the disputed books, and sidelined it to an appendix, although in his Large Catechism he treated it as the authoritative word of God.

The epistle aims to reach a wide Jewish audience. During the last decades, the epistle of James has attracted increasing scholarly interest due to a surge in the quest for the historical James, his role within the Jesus movement, his beliefs, and his relationships and views. This James revival is also associated with an increasing level of awareness of the Jewish grounding of both the epistle and the early Jesus movement.

The author is identified as “James, a servant of God and of the Lord Jesus Christ” (James 1:1). James (Jacob, , ) was an extremely common name in antiquity, and a number of early Christian figures are named James, including: James the son of Zebedee, James the son of Alphaeus, and James the brother of Jesus. Of these, James the brother of Jesus has the most prominent role in the early church, and is often understood as either the author of the epistle, or the implied author.

The earliest recorded references to the Epistle of James highlight the contentious nature of the epistle’s authorship. Origen may be the first person to link the epistle to "James the brother of Lord" ("Comm. on Romans" 4.8.2), though this is only preserved in Rufinus’s Latin translation of Origen. Eusebius writes that "James, who is said to be the author of the first of the so-called catholic epistles. But it is to be observed that it is disputed" ("Historia ecclesiae" 2.23.25). Jerome reported that the Epistle of James "is claimed by some to have been published by some one else under his name, and gradually, as time went on, to have gained authority" ("De viris illustribus" 2).

The link between James the brother of Jesus and the epistle continued to strengthen, and is now considered the traditional view on the authorship of the work. The traditional view can be divided into at least three further positions that relate also to the date of the epistle:


Many who affirm traditional authorship think James had a sufficient proficiency in Greek education to write the letter himself. Some argue that James the brother of Jesus made use of an amanuensis, which explains the quality of Greek in the letter. Dan McCartney notes this position has garnered little support. Others have advocated for a two-stage composition theory, in which many of the sayings of epistle originate with James the brother of Jesus. They were collected by James’ disciples and redacted into the current form of the letter.

John Calvin and others suggested that the author was the James, son of Alphaeus, who is referred to as James the Less. The Protestant reformer Martin Luther denied it was the work of an apostle and termed it an "epistle of straw".

The Holy Tradition of the Eastern Orthodox Church teaches that the Book of James was "written not by either of the apostles, but by the 'brother of the Lord' who was the first bishop of the Church in Jerusalem."

A prevalent view within scholarship considers the Epistle of James to be pseudonymous. The real author chose to write under the name James, intending that the audience perceive James the brother of Jesus as the author. Scholars who maintain pseudonymous authorship differ on whether this was a deceitful or pious practice.

The following arguments are often cited in support of pseudepigraphy: 

The original manuscript of this letter is lost. The earliest extant manuscripts of James date to the mid-to-late 3rd century.

According to Josephus ("Jewish Antiquities" 20.197–203), James the brother of Jesus was killed in 62 CE, during the high priesthood of Ananus. Those who hold to traditional authorship date the epistle to sometime before 62 CE, in the forties or fifties, making it one of the earliest writings of the New Testament.

Those who maintain that the epistle is pseudonymous generally date the epistle later, from the late first to mid-second century. This is based on a number of considerations, including the epistle's potential dependence on 1 Peter, potential response to Paul's writings or Paul's later followers, late attestation in the historical record, and the 3rd and 4th century disputes concerning the epistle's authorship.

The historiographic debate currently seems to be leaning to the side of those in favor of early dating, although not through irrefutable evidence but through indications and probabilities.

Some of the oldest surviving manuscripts that contain some or all of this letter include:

An ancient manuscript containing this chapter in the Coptic language is: 

And in Latin:

The Epistle of James is a letter, and includes an epistolary prescript that identifies the sender (“James”) and the recipients (“to the twelve tribes in the diaspora”) and provides a greeting (Jas 1:1). The epistle resembles the form of a Diaspora letter, written to encourage Jewish-Christian communities living outside of Israel amid the hardships of diaspora life. James stands in the tradition of the Jewish genre of "Letters to the Diaspora", including the letters of the members of the family of Gamaliel, the one preserved in 2 Maccabees 1:1-9, or some copied by Josephus, all of which are characterised by a double opening and an abrupt ending.

Many consider James to have affinities to Jewish wisdom literature: "like Proverbs and Sirach, it consists largely of moral exhortations and precepts of a traditional and eclectic nature." The epistle also has affinities with many of the sayings of Jesus which are found in the gospels of Luke and Matthew (i.e., those attributed to the hypothetical Q source, in the two-source hypothesis). Some scholars have argued that the author of James is familiar with a version of Q rather than Luke or Matthew.

Other scholars have noted the epistle's affinities with Greco-Roman philosophical literature. The author's use and transformation of Q materials resembles the Hellenistic practice of "aemulatio", in which the author must "rival and vie ["aemulatio"] with the original in the expression of the same thoughts” (Quintilian, "Inst". 10.5.5). Other studies have analysed sections of James in light of Greco-Roman rhetorical conventions.

Some view the epistle as having no overarching outline: "James may have simply grouped together small 'thematic essays' without having more linear, Greco-Roman structures in mind." That view is generally supported by those who believe that the epistle may not be a true piece of correspondence between specific parties but an example of wisdom literature, formulated as a letter for circulation. The "Catholic Encyclopedia" says, "the subjects treated of in the Epistle are many and various; moreover, St. James not infrequently, whilst elucidating a certain point, passes abruptly to another, and presently resumes once more his former argument."

Others view the letter as having only broad topical or thematic structure. They generally organize James under three (in the views of Ralph Martin) to seven (in the views of Luke Johnson) general key themes or segments.

A third group believes that James was more purposeful in structuring his letter, linking each paragraph theologically and thematically:

The third view of the structuring of James is a historical approach that is supported by scholars who are not content with leaving the book as "New Testament wisdom literature, like a small book of proverbs" or "like a loose collection of random pearls dropped in no particular order onto a piece of string."

A fourth group uses modern discourse analysis or Greco-Roman rhetorical structures to describe the structure of James.

The United Bible Societies' "Greek New Testament" divides the letter into the following sections:
The exact historical circumstances that occasioned the epistle are unknown. Those who understand James 2 as a polemic against Paul or Paul’s followers suggest an occasion for the letter aimed at opposing Pauline justification. Others have argued that James' discussion on faith and works does not have Pauline categories in view.

Some scholars have suggested that the epistle was written to both Christian and non-Christian Jews, who continued to worship together before the parting of the ways between Christianity and Judaism. The warning against cursing people (Jas 3:9–10) has been read in light of this historical reconstruction, and Dale Allison has argued that “James reflects an environment in which some Jews, unhappy with Jewish Christians, were beginning to use the "Birkat ha-minim" or something very much like it” to curse Christians.

Poverty and wealth are key concerns throughout the epistle, and these issues are likely to reflect the epistle's historical context. The author shows concern for vulnerable and marginalised groups, such as "orphans and widows" (Jas 1:27), believers who are "poorly clothed and lacking in daily food" (Jas 2:15), and the oppressed waged-worker (Jas 5:4). He writes strongly against the rich (Jas 1:10; 5:1–6) and those who show partiality towards them (Jas 2:1–7).

The epistle contains the following famous passage concerning salvation and justification:
This passage has been contrasted with the teachings of Paul the Apostle on justification. Some scholars even believe that the passage is a response to Paul. One issue in the debate is the meaning of the Greek word (, 'render righteous or such as he ought to be'), with some among the participants taking the view that James is responding to a misunderstanding of Paul.

Roman Catholicism and Eastern Orthodoxy have historically argued that the passage disproves the doctrine of justification by faith alone ("sola fide"). The early (and many modern) Protestants resolve the apparent conflict between James and Paul regarding faith and works in alternate ways from the Catholics and Orthodox:
According to Ben Witherington III, differences exist between the Apostle Paul and James, but both used the law of Moses, the teachings of Jesus and other Jewish and non-Jewish sources, and "Paul was not anti-law any more than James was a legalist". A more recent article suggests that the current confusion regarding the Epistle of James about faith and works resulted from Augustine of Hippo's anti-Donatist polemic in the early fifth century. This approach reconciles the views of Paul and James on faith and works.

The epistle is also the chief biblical text for the anointing of the sick. James wrote:
G. A. Wells suggested that the passage was evidence of late authorship of the epistle, on the grounds that the healing of the sick being done through an official body of presbyters (elders) indicated a considerable development of ecclesiastical organisation "whereas in Paul's day to heal and work miracles pertained to believers indiscriminately (I Corinthians, XII:9)."

James and the M Source material in Matthew are unique in the canon in their stand against the rejection of works and deeds. According to Sanders, traditional Christian theology wrongly divested the term "works" of its ethical grounding, part of the effort to characterize Judaism as legalistic. However, for James and for all Jews, faith is alive only through Torah observance. In other words, belief demonstrates itself through practice and manifestation. For James, claims about belief are empty, unless they are alive in action, works and deeds.

The epistle emphasizes the importance of acts of charity or works to go along with having the Christian faith by means the following three verses in Chapter 2 of his Epistle:

-2:14. What shall it profit, my brethren, if a man say he hath faith, but hath not works? Shall faith be able to save him?

-2:18. But some man will say: Thou hast faith, and I have works. Shew me thy faith without works; and I will shew thee, by works, my faith.

-2:20. But wilt thou know, O vain man, that faith without works is dead?

James is unique in the canon by its explicit and wholehearted support of Torah observance (the Law). According to Bibliowicz, not only is this text a unique view into the milieu of the Jewish founders – its inclusion in the canon signals that as canonization began (fourth century onward) Torah observance among believers in Jesus was still authoritative. According to modern scholarship James, Q, Matthew, the Didache, and the pseudo-Clementine literature reflect a similar ethos, ethical perspective, and stand on, or assume, Torah observance. James call to Torah observance (James 1:22-27) ensures salvation (James 2:12–13, 14–26). Hartin is supportive of the focus on Torah observance and concludes that these texts support faith through action and sees them as reflecting the milieu of the Jewish followers of Jesus. Hub van de Sandt sees Matthew's and James' Torah observance reflected in a similar use of the Jewish Two Ways theme which is detectable in the Didache too (Didache 3:1–6). McKnight thinks that Torah observance is at the heart of James's ethics. A strong message against those advocating the rejection of Torah observance characterizes, and emanates from, this tradition: "Some have attempted while I am still alive, to transform my words by certain various interpretations, in order to teach the dissolution of the law; as though I myself were of such a mind, but did not freely proclaim it, which God forbid! For such a thing were to act in opposition to the law of God which was spoken by Moses, and was borne witness to by our Lord in respect of its eternal continuance; for thus he spoke: 'The heavens and the earth shall pass away, but one jot or one tittle shall in no wise pass away from the law.

James seem to propose a more radical and demanding interpretation of the law than mainstream Judaism. According to Painter, there is nothing in James to suggest any relaxation of the demands of the law. "No doubt James takes for granted his readers' observance of the whole law, while focusing his attention on its moral demands."

This verse has particular importance in the Latter Day Saint tradition. Joseph Smith claims that the reading and contemplation of this verse inspired him to ask God for wisdom, leading to his First Vision, and thus what his followers consider to be the Restoration—the creation of the LDS church.

The first explicit references to the Epistle of James are found in the writings of Origen of Alexandria (e.g. "Comm. on John.," 19.23) in the third century. Scholars have generally rejected the possible second-century allusions to James in the Apostolic Fathers and Irenaeus of Lyons "Against Heresies". Neither is James mentioned by Tertullian (c. 155–220 CE) or Cyprian (c. 210–258 CE), and its authenticity of the epistle doubted by Theodore of Mopsuestia (c. 350–428 CE). In "Historia ecclesiae" 2.23.25, Eusebius classes James among the Antilegomena or disputed works, stating "it is to be observed that it is disputed; at least, not many of the ancients have mentioned it, as is the case likewise with the epistle that bears the name of Jude, which is also one of the seven so-called catholic epistles. Nevertheless we know that these also, with the rest, have been read publicly in very many churches."

Its late recognition in the Church, especially in the West, was a consequence primarily of its sparse attestation by earlier Christian authors and its disputed authorship. Jerome reported that the Epistle of James "is claimed by some to have been published by some one else under his name, and gradually, as time went on, to have gained authority" ("De viris illustribus" 2).

The Epistle of James is missing from the Muratorian fragment (poss. 2nd to 4th century), the Cheltenham list (c. 360 CE), but was listed with the twenty-seven New Testament books by Athanasius of Alexandria in his "Thirty-Ninth Festal Epistle" (367 CE), and subsequently affirmed by the Councils of Laodicea (c. 363 CE), of Rome (382 CE) and of Carthage (397 and 419).

During the Reformation era, Martin Luther took issue with the epistle on theological grounds, finding James' description of faith and works incompatible with his understanding of justification. Reportedly, he once went as far as to assert "I almost feel like throwing Jimmy into the stove", a metaphor for his being tempted to remove the Epistle of James from the Bible. Luther nonetheless chose to include James from his German translation of the Bible, though he moved it (along with Hebrews, Jude, and Revelation) to the end of the Bible.




Epistle of Jude

The Epistle of Jude is the penultimate book of the New Testament as well as the Christian Bible. It is traditionally attributed to Jude, brother of James the Just, and thus possibly a brother of Jesus as well.

Jude is a short epistle written in Koine Greek. It condemns in fierce terms certain people the author sees as a threat to the early Christian community, but describes these opponents only vaguely. According to Jude, these opponents are within the Christian community, but are not true Christians: they are scoffers, false teachers, malcontents, given to their lusts, and so on. The epistle reassures its readers that these people will soon be judged by God. It is possible that the group being referred to would have been obvious to the original recipients of the letter, but if a specific group was being referred to, knowledge of the details has since been lost. The one bit of their potential ideology discussed in the letter is that these opponents denigrate angels and their role. If this was indeed a part of the ideology of this group the author opposed, then the epistle is possibly a counterpoint to the Epistle to the Colossians. Colossians condemns those who give angels undue prominence and worship them; this implies the two letters might be part of an early Christian debate on Christian angelology.

The epistle introduces itself with a simple claim of authorship: "Jude, a servant of Jesus Christ and brother of James" (NRSV). "James" is generally taken to mean James, brother of Jesus, a prominent leader in the early church. Introductions would typically refer to a father in the era, so the use of a brother suggests that this would only be done if the brother was famous within the community. Little is known about Jude himself. As the brother of James, it has traditionally meant Jude was also a brother of Jesus, since James is described as being the brother of Jesus. This is why Clement of Alexandria (c. 150–215 AD) wrote in his work "Comments on the Epistle of Jude" that Jude, the author, was a son of Joseph and a brother of Jesus. However, there is a dispute as to whether "brother" means someone who has the same father and mother, or a half-brother, cousin, or more distant familial relationship. This dispute over the true meaning of "brother" grew as the doctrine of the Virgin Birth evolved. For example, Saint Jerome believed that not only Mary but also Joseph were virgins their entire lives, and thus James and by extension Jude were cousins.

Outside the book of Jude, a "Jude" is mentioned five times in the New Testament: three times as Jude the Apostle, and twice as Jude the brother of Jesus (aside from references to Judas Iscariot and Judah (son of Jacob)). Debate continues as to whether the author of the epistle is the apostle, the brother of Jesus, both, or neither. Scholars have argued that since the author of the letter has not identified himself as an apostle and also refers to the apostles as a third party, he cannot be identified with Jude the Apostle. Other scholars have drawn the opposite conclusion, which is that, as an apostle, he would not have made a claim of apostleship on his own behalf.

Some scholars defend the traditional authorship of Jude, however, a reason to doubt that a relative of Jesus wrote the book is that they are unlikely to have been literate. Jesus's family were common laborers from Aramaic-speaking Galilee, and literary composition skills were overwhelmingly concentrated in the elite in antiquity. Few knew how to read, fewer how to write, and fewer still how to write complicated literary treatises. Jesus himself may have been able to read, presumably in Hebrew, but he was also exceptional and the star of the family. Even if somehow Jude had learned a little of how to read Hebrew, the epistle is written in excellent, complicated Koine Greek, with knowledge of common forms of rhetoric and argument of the era, as well as seeming knowledge of the scriptures in Hebrew. All this would be exceptional for a countryside Galilean. Scholars who support the authorship of Jude generally assume that he must have embarked upon extensive travel and missionary work among Hellenized Jews to master Greek as the author did. Ultimately, it is impossible to know more details of Jude's life for sure. One early Christian tradition states that Jude's grandchildren were brought before Emperor Domitian and interrogated; in the story, they defended themselves as not rebels and mere poor laborers eking out what they could from a single patch of land. While the story is clearly apocryphal – Roman emperors did not generally interrogate Galilean peasants – it does suggest that early Christians remembered Jude's family as lower-class laborers, not literate elites.

If the Jude writing the letter was not Jude the Apostle mentioned in the gospels, then he was possibly an unknown Christian who happened to share the name and coincidentally also had a brother named James. A final possibility is that the epistle is pseudepigrapha – that the author intentionally hinted to readers that it was from the more famous Jude, but only as a false attribution to give the letter more authority.

The date of composition is not known, but is loosely speculated to be between the years 50 and 110. Among those who favor the authorship of the Jude mentioned in the gospels, the letter is generally placed before the destruction of the Temple in Jerusalem in 70 AD. Among those who favor the authorship of an unknown Christian, it is assumed to be a work of the early second century. Scholars who consider the letter a pseudonymous work generally favor the later dates due to the letter's references to the apostles (as if they lived in the past) and to tradition and because of its competent Greek style. Bo Reicke suggests around 90 AD; Heikki Räisänen concurs and believes that it may have been written at the end of the first century. Bart Ehrman suggests an even later date, in the second half of the second century, due to use of certain terminology in ways similar to the pastoral epistles that was uncommon in the first century.

Jude urges his readers to "contend for the faith" against "certain intruders [who] have stolen in among you." He warns about false teachers who twist the grace of Christ as a pretext for wantonness. Jude asks the reader to recall how even after the Lord saved his own people out of the land of Egypt, he did not hesitate to destroy those who fell into unbelief, much as he punished the angels who fell from their original exalted status and the inhabitants of Sodom and Gomorrah. He also paraphrases (verse 9) an incident apparently from the Assumption of Moses that has since been lost about Satan and Michael the Archangel quarreling over the body of Moses.

Continuing the analogy from Israel's history, he says that the false teachers have followed in the way of Cain, have rushed after reward into the error of Balaam, and have perished in the rebellion of Korach. He describes in vivid terms the opponents he warns of, calling them "clouds without rain", "trees without fruit", "foaming waves of the sea", and "wandering stars". He exhorts believers to remember the words spoken by the Apostles, using language similar to the second epistle of Peter to answer concerns that the Lord seemed to tarry: "In the last time there will be scoffers, indulging their own ungodly lusts," and to keep themselves in God's love, before delivering a doxology to God.

Jude quotes directly from the Book of Enoch, a widely distributed work among the Old Testament pseudepigrapha, citing a section of 1 Enoch 1:8 that is based on Deuteronomy 33:2.

Consisting of just 1 chapter with 25 verses, the Epistle of Jude is among the shortest books of the Bible. (The Epistle to Philemon also contains 25 verses, while the 21-verse Book of Obadiah, the 14-verse 3 John, and the 13-verse 2 John are shorter.)

The wording and syntax of this epistle in its original Greek demonstrates that the author was capable and fluent. The epistle's style is combative, impassioned, and rushed. Many examples of evildoers and warnings about their fates are given in rapid succession.

The epistle concludes with a doxology, which is considered by Peter H. Davids to be one of the highest in quality contained in the Bible.<refame=Davids2006></ref>

It may have been composed as an encyclical letter—that is, one not directed to the members of one church in particular, but intended rather to be circulated and read in all churches. While addressed to the Christian Church as a whole, the references to Old Testament figures such as Michael, Cain, and Korah's sons, the Book of Enoch, and the invocation of James as head of the church of Jerusalem suggests a Jewish Christian main audience that would be familiar with Enochian literature and revere James.

The letter of Jude was one of the disputed books of the biblical canon of the New Testament. Despite some opposition, it seems to have been accepted by most churches around the end of the second century. Clement of Alexandria, Tertullian, and the Muratorian canon considered the letter canonical. The letter was eventually accepted as part of the canon by later Church Fathers such as Athanasius of Alexandria. The canon list at the Council of Carthage (c. 397) included the epistle of Jude. 

The first historical record of doubts as to authorship are found in the writings of Origen of Alexandria, who spoke of the doubts held by some in the early third century. Eusebius classified it with the "disputed writings, the "antilegomena"" in the early fourth century. Eusebius doubted its authenticity partially because it was rarely quoted among ancient sources, although he acknowledges it was read in many churches. The links between the Epistle and 2 Peter and its use of the biblical apocrypha raised concern: Saint Jerome wrote in 392 AD that the book was "rejected by many" since it quotes the Book of Enoch.

Early manuscripts containing the text of the epistle of Jude include:

The epistle fiercely condemns the opponents it warns of and declares that God will judge and punish them, despite them being a part of the Christian community. However, the exact nature of these opponents has been a continuing interest for both theologians and historians, as the epistle does not describe them in any more detail than calling them corrupt and ungodly. Several theories have been proposed. The most specific verse describing the opponents is verse 8:
Reject "authority" (κυριότητα, "kyriotēta"; alternate translations include "dominion" or "lordship") could mean several things. The most direct would be rejection of civil or ecclesiastical authority: the opponents were ignoring guidance from leaders. Martin Luther and Jean Calvin agreed with this interpretation, and it is the most common one. Another possibility is that this specifically referred to rejecting the authority of Jesus or God, which would agree with verse 4 and be reinforcing the claim that these opponents are not true Christians. A third possibility is that this is the singular of "kyriotētes" (Dominions), a class of angels. This would fit with the final part of the sentence of "heap abuse on celestial beings", but it is unusual that the singular is used. Versions of Jude vary, and some manuscripts such as the Codex Sinaiticus indeed use the plural form. 

"Heap abuse on celestial beings" is also a relevant statement, as it stands in some tension with the works of Paul the Apostle as well as the Epistle to the Hebrews. Paul's undisputed works indicate that believers are already on the same level as angels, that all existing powers are subject to Christ, and believers are the future judges of angels. Later writings attributed to Paul such as Colossians and Ephesians go even further, with Colossians decrying the alleged worship of angels. A hypothesis is thus that the author may have been attacking forms of Pauline Christianity that were not suitably deferential to angels in their opinion. "Rejecting authority" may be a reference to Paul's preaching that gentiles did not need to comply with Jewish Law. As James was known to be a major figure among Jewish Christians, this might indicate tension between the more Jewish strands of early Christianity represented by James and Jude set against Paul's message to the gentiles. However, the line about "heap abuse on celestial beings" might have essentially been just another insult, in which case this entire line of thought is rendered moot.

The inherent vagueness of the epistle means that the identities of these opponents may never be known.

Part of Jude is very similar to 2 Peter (mainly 2 Peter chapter 2); so much so that most scholars agree that either one letter used the other directly, or they both drew on a common source. Comparing the Greek text portions of 2 Peter 2:1–3:3 (426 words) to Jude 4–18 (311 words) results in 80 words in common and 7 words of substituted synonyms.

Because this epistle is much shorter than 2 Peter, and due to various stylistic details, some scholars consider Jude the source for the similar passages of 2 Peter. However, other writers, arguing that Jude 18 quotes as past tense, consider Jude to have come after 2 Peter.

Some scholars who consider Jude to predate 2 Peter note that the latter appears to quote the former but omits the reference to the non-canonical book of Enoch.

The Epistle of Jude references at least three other books, with two (Book of Zechariah & 2 Peter) being canonical in all churches and the other (Book of Enoch) non-canonical in most churches.

Verse 9 refers to a dispute between Michael the Archangel and the devil about the body of Moses. Some interpreters understand this reference to be an allusion to the events described in Zechariah 3:1–2. The classical theologian Origen, as well as Clement of Alexandria, Didymus the Blind, and others, attributes this reference to the non-canonical Assumption of Moses. However, no extant copies of the Assumption of Moses contain this story, leading most scholars to conclude the section covering this dispute has been lost – perhaps a lost ending, since a story involving Moses's body would logically occur at the end. Some scholars disagree; James Charlesworth argues that the Assumption of Moses never contained any such content, and other ancient Church writers supported a different origin.

Verses 14–15 contain a direct quotation of a prophecy from 1 Enoch 1:9. The title "Enoch, the seventh from Adam" is also sourced from 1 En. 60:1. Most commentators assume that this indicates that Jude accepts the antediluvian patriarch Enoch as the author of the Book of Enoch which contains the same quotation. An alternative explanation is that Jude quotes the Book of Enoch aware that verses 14–15 are an expansion of the words of Moses from Deuteronomy 33:2.

The Book of Enoch is not considered canonical by most churches, although it is by the Ethiopian Orthodox church. According to Western scholars, the older sections of the Book of Enoch (mainly in the "Book of the Watchers") date from about 300 BC and the latest part ("Book of Parables") probably was composed at the end of the 1st century BC. 1 Enoch 1:9, mentioned above, is part of the pseudepigrapha and is among the Dead Sea Scrolls [4Q Enoch (4Q204[4QENAR]) COL I 16–18]. It is largely accepted by scholars that the author of the Epistle of Jude was familiar with the Book of Enoch and was influenced by it in thought and diction.

The epistle also closely mirrors the Epistle of James, with many similar sentences and borrowed phrases.



Online translations of the Epistle of Jude:
Audiobook Version:

Additional information:

Eusebius Amort

Eusebius Amort (November 15, 1692February 5, 1775) was a German Roman Catholic theologian.

Amort was born at Bibermuhle, near Tolz, in Upper Bavaria. He studied at Munich, and at an early age joined the Canons Regular at Polling, where, shortly after his ordination in 1717, he taught theology and philosophy.
The Parnassus Boicus learned society was based on a plan started in 1720 by three Augustinian fathers: Eusebius Amort, Gelasius Hieber (1671–1731), a famous preacher in the German language and Agnellus Kandler (1692–1745), a genealogist and librarian. The initial plans fell through, but in 1722 they issued the first volume of the "Parnassus Boicus" journal, communicating interesting information from the arts and sciences.

An academy formed by him at Polling became in time the model on which was based the Academy of Sciences of Munich.

In 1733 Amort went to Rome as theologian to Cardinal Niccolo Maria Lercari (died 1757).
He returned to Polling in 1735 and devoted the rest of his life to the revival of learning in Bavaria. He died at Polling in 1775.

Amort, who had the reputation of being the most learned man of his age, was a voluminous writer on every conceivable subject, from poetry to astronomy, from dogmatic theology to mysticism. His best known works are:


A treatise on mysticism, "De Revelationibus et Visionibus, etc." (2 vols, Augsburg 1744) was directed against the "Mystic City of God," by the Spanish Franciscan nun, Maria de Agreda, and brought him into conflict with several of her Franciscan defenders.

The list of his other works, including his three erudite contributions to the question of authorship of the "Imitatio Christi", will be found in C. Toussaint's scholarly article in Alfred Vacant's "Dictionnaire de theologie" (1900, cols 1115-1117).

Citations

Sources

Episcopus vagans

In Christianity, an episcopus vagans (plural episcopi vagantes; Latin for 'wandering bishops' or 'stray bishops') is a person consecrated, in a "clandestine or irregular way", as a bishop outside the structures and canon law of the established churches; a person regularly consecrated but later excommunicated, and not in communion with any generally recognized diocese; or a person who has in communion with them small groups that appear to exist solely for the bishop's sake.

David V. Barrett, in the "Encyclopedia of New Religious Movements", specifies that now "" are "those independent bishops who collect several different lines of transmission of apostolic succession, and who will happily (and sometimes for a fee) consecrate anyone who requests it". Those described as wandering bishops often see the term as pejorative. The general term for "wandering" clerics, as were common in the Middle Ages, is "clerici vagantes"; the general term for those recognising no leader is "acephali".

The "Oxford Dictionary of the Christian Church" mentions as the main lines of succession deriving from "episcopi vagantes" in the 20th century those founded by Arnold Mathew, Joseph René Vilatte and Leon Chechemian. Others that could be added are those derived from, Carlos Duarte Costa, Paolo Miraglia-Gulotti, Emmanuel Milingo, Pierre Martin Ngô Đình Thục and Richard Williamson.

According to Buchanan, "the real rise of the problem" happened in the 19th century, in the "wake of the Anglo-Catholic movement", "through mischievous activities of a tiny number of independently acting bishops". They exist worldwide, he writes, "mostly without congregations", and "many in different stages of delusion and fantasy, not least in the Episcopal titles they confer on themselves"; "the distinguishing mark" to "specifically identif[y]" an "episcopus vagans" is "the lack of a true see or the lack of a real church life to oversee".

Paul Halsall, on the Internet History Sourcebooks Project, did not list a single church edifice of independent bishops, in a 1996–1998 New York City building architecture survey of religious communities, which maintain bishops claiming apostolic succession and claim cathedral status but noted there "are now literally hundreds of these ", of lesser or greater spiritual probity. They seem to have a tendency to call living room sanctuaries 'cathedrals';" those buildings were not perceived as cultural symbols and did not meet the survey criteria. David V. Barrett wrote, in "A Brief Guide to Secret Religions", that "one hallmark of such bishops is that they often collect as many lineages as they can to strengthen their Episcopal legitimacy—at least in their own eyes" and their groups have more clergy than members.

Barrett wrote that leaders "of some esoteric movements, are also priests or bishops in small non-mainstream Christian Churches"; he explains, this type of "independent or autocephalous" group has "little in common with the Church it developed from, the Old Catholic Church, and even less in common with the Roman Catholic Church" but still claims its authority from apostolic succession.

Buchanan writes that based the criteria of having "a true see" or having "a real church life to oversee", the bishops of most forms of the Continuing Anglican movement are not necessarily classified as vagantes, but "are always in danger of becoming such".

A Roman or Eastern Catholic ordained to the episcopacy without a mandate from the Pope is automatically excommunicated and is thereby forbidden to celebrate the sacraments, according to canon law. Through the concept of "valid but illicit" ordinations however, and the dogma of sacramental character, though excommunicated and forbidden to celebrate sacraments within any church in communion with the Holy See, the person still holds a valid episcopacy though unrecognized at large.

According to a theological view affirmed, for instance, by the International Bishops' Conference of the Old Catholic Church with regard to ordinations by Arnold Mathew, an episcopal ordination is for service within a specific Christian church, and an ordination ceremony that concerns only the individual himself does not make him truly a bishop. The Holy See has not commented on the validity of this theory, but has declared with regard to ordinations of this kind carried out, for example, by Emmanuel Milingo toward Peter Paul Brennan and others, that the Roman Church "does not recognize and does not intend to recognize in the future those ordinations or any of the ordinations derived from them and therefore the canonical state of the alleged bishops remains that in which they were before the ordination conferred by Mr Milingo", thereby recognizing their previous stance as "illicit but valid" clergy prior to Milingo.

Vlassios Pheidas, on an official Church of Greece site, uses the canonical language of the Eastern Orthodox tradition, to describe the conditions in ecclesial praxis when sacraments, including Holy Orders, are real, valid, and efficacious. He notes language is itself part of the ecclesiological problem.
This applies to the validity and efficacy of the ordination of bishops and the other sacraments, not only of the Independent Catholic churches, but also of all other Christian churches, including the Roman Catholic Church, Oriental Orthodoxy and the Assyrian Church of the East. However, although strict adherence to law supersedes economy by their Cyprian understanding, some mainstream Eastern Orthodox bodies recognize Roman Catholic orders and don't conditionally ordain clergy as each autocephalous church determines the validity of another's ordination. The Ecumenical Patriarchate of Constantinople likewise teaches that through "extreme oikonomia [economy]", those who are baptized in the Oriental Orthodox, Roman Catholic, Lutheran, Old Catholic, Moravian, Anglican, Methodist, Reformed, Presbyterian, Church of the Brethren, Assemblies of God, or Baptist traditions can be received into the Eastern Orthodox Church through the sacrament of Chrismation and not through re-baptism.

Anglican bishop Colin Buchanan, in the "Historical Dictionary of Anglicanism", says that the Anglican Communion has held an Augustinian view of orders, by which "the validity of Episcopal ordinations (to whichever order) is based solely upon the historic succession in which the ordaining bishop stands, irrespective of their contemporary ecclesial context".

He describes the circumstances of Archbishop Matthew Parker's consecration as one of the reasons why this theory is "generally held". Parker was chosen by Queen Elizabeth I of England to be the first Church of England Archbishop of Canterbury after the death of the previous office holder, Cardinal Reginald Pole, the last Roman Catholic Archbishop of Canterbury. Buchanan notes the Roman Catholic Church also focuses on issues of intention and not just breaks in historical succession. He does not explain whether intention has an ecclesiological role, for Anglicans, in conferring or receiving sacraments.

Arnold Mathew, according to Buchanan, "lapsed into the vagaries of an """. Stephen Edmonds, in the "Oxford Dictionary of National Biography", wrote that in 1910 Mathew's wife separated from him; that same year, he declared himself and his church seceded from the Union of Utrecht. Within a few months, on 2 November 1911, he was excommunicated by the Roman Catholic Church. He later sued "The Times" for libel based on the words "pseudo-bishop" used to describe him in the newspaper's translation from the Latin text """", and, lost his case in 1913.

Henry R.T. Brandreth wrote, in "Episcopi Vagantes and the Anglican Church", "[o]ne of the most regrettable features of Mathew's episcopate was the founding of the Order of Corporate Reunion (OCR) in 1908. This claimed to be a revival of Frederick George Lee's movement, but was in fact unconnected with it". Brandreth thought it "seems still to exist in a shadowy underground way" in 1947, but disconnected. Colin Holden, in "Ritualist on a Tricycle", places Mathew and his into perspective, he wrote Mathew was an "", lived in a cottage provided for him, and performed his conditional acts, sometimes called according to Holden "bedroom ordinations", in his cottage. Mathew questioned the validity of Anglican ordinations and became involved with the OCR, in 1911 according to Edmonds, and he openly advertised his offer to reordain Anglican clergy who requested it. This angered the Church of England.

In 1912, D. J. Scannell O'Neill wrote in "The Fortnightly Review" that London "seems to have more than her due share of bishops" and enumerates what he refers to as "these hireling shepherds". He also announces that one of them, Mathew, revived the OCR and published "The Torch", a monthly review, advocating the reconstruction of Western Christianity and reunion with Eastern Christianity. "The Torch" stated "that the ordinations of the Church of England are not recognized by any church claiming to be Catholic" so the promoters involved Mathew to conditionally ordain group members who are "clergy of the Established Church" and "sign a profession of the Catholic Faith". It stipulated Mathew's services were not a system of simony and given without simoniac expectations. The group sought to enroll "earnest-minded Catholics who sincerely desire to help forward the work of [c]orporate [r]eunion with the Holy See". Nigel Yates, in "Anglican Ritualism in Victorian Britain, 1830-1910", described it as "an even more bizarre scheme to promote a Catholic Uniate Church in Britain" than Lee and Ambrose Lisle March Phillipps de Lisle's Association for the Promotion of the Unity of Christendom. It was editorialized by O'Neill that the "most charitable construction to be placed on this latest move of Mathew is that he is not mentally sound. Being an Irishman, it is strange that he has not sufficient humor to see the absurdity of falling away from the Catholic Church in order to assist others to unite with the Holy See". Edmonds reports that "anything between 4 and 265 was suggested" as to how many took up his offer of reordination.

When it declared devoid of canonical effect the consecration ceremony conducted by Archbishop Pierre Martin Ngô Đình Thục for the Carmelite Order of the Holy Face group at midnight of 31 December 1975, the Holy See refrained from pronouncing on its validity. It also made the same statement with regard to later ordinations by those bishops, saying that, "as for those who have already thus unlawfully received ordination or any who may yet accept ordination from these, whatever may be the validity of the orders (), the Church does not and will not recognise their ordination (), and will consider them, for all legal effects, as still in the state in which they were before, except that the ... penalties remain until they repent".

A similar declaration was issued with regard to Archbishop Emmanuel Milingo's conferring of episcopal ordination on four men - all of whom, by virtue of previous Independent Catholic consecrations, claimed already to be bishops - on 24 September 2006: the Holy See, as well as stating that, in accordance with Canon 1382 of the Code of Canon Law, all five men involved incurred automatic () excommunication through their actions, declared that "the Church does not recognise and does not intend in the future to recognise these ordinations or any ordinations derived from them, and she holds that the canonical state of the four alleged bishops is the same as it was prior to the ordination". 

Consecrations that the late Archbishop Marcel Lefebvre performed in 1988 for the service of the relatively numerous followers of the Traditionalist Catholic Society of St. Pius X that he had founded, and of the bishops who, under pressure from the Catholic Patriotic Association, "have been ordained without the Pontifical mandate and who have not asked for, or have not yet obtained, the necessary legitimation", and who consequently, Pope Benedict XVI declared, "are to be considered illegitimate, but validly ordained".


Elizabeth Garrett Anderson

Elizabeth Garrett Anderson (9 June 1836 – 17 December 1917) was an English physician and suffragist. She is known for being the first woman to qualify in Britain as a physician and surgeon and as a co-founder and dean of the London School of Medicine for Women, which was the first medical school in Britain to train women as doctors. She was the first female dean of a British medical school, the first woman in Britain to be elected to a school board and, as mayor of Aldeburgh, the first female mayor in Britain.

Elizabeth was born in Whitechapel, London, and was the second of eleven children of Newson Garrett (1812–1893), from Leiston, Suffolk, and his wife, Louisa (born Dunnell; 1813–1903), from London.

Her paternal ancestors had been ironworkers in East Suffolk since the early seventeenth century. Newson was the youngest of three sons and not academically inclined, although he possessed the family's entrepreneurial spirit. When he finished school, Newson found few opportunities in Leiston, so he moved to London to make his fortune. There, he fell in love with his brother's sister-in-law, Louisa Dunnell, the daughter of an innkeeper of Suffolk origin. After their wedding, the couple went to live in a pawnbroker's shop at 1 Commercial Road, Whitechapel. The Garretts had their first three children in quick succession: Louie, Elizabeth, and a son, Dunnell, who died at the age of six months. When Garrett was three years old, the family moved to 142 Long Acre, where they lived for two years, while one more child was born and her father advanced in his career, becoming not only the manager of a larger pawnbroker's shop, but also a silversmith. Garrett's grandfather, owner of the family engineering works, Richard Garrett & Sons, had died in 1837, leaving the business to his eldest son, Garrett's uncle. Despite his lack of capital, Newson was determined to be successful and in 1841, at the age of 29, he moved his family to Suffolk, where he bought a barley and coal merchants business in Snape, constructing Snape Maltings from 1846. 

The Garretts lived in a square Georgian house opposite the church in Aldeburgh until 1852. Newson's malting business expanded and more children were born, Edmund (1840), Alice (1842), Agnes (1845), Millicent (1847), who was to become a leader in the constitutional campaign for women's suffrage, Sam (1850), Josephine (1853) and George (1854). By 1850, Newson was a prosperous businessman and was able to build Alde House, a mansion on a hill behind Aldeburgh. A "by-product of the industrial revolution", Garrett grew up in an atmosphere of "triumphant economic pioneering" and the Garrett children were to grow up to become achievers in the professional classes of late-Victorian England. Elizabeth was encouraged to take an interest in local politics and, contrary to practices at the time, was allowed the freedom to explore the town with its nearby salt-marshes, beach and the small port of Slaughden with its boatbuilders' yards and sailmakers' lofts.

There was no school in Aldeburgh, so Garrett learned reading, writing, and arithmetic from her mother. When she was 10 years old, a governess, Miss Edgeworth, a poor gentlewoman, was employed to educate Garrett and her sister. Mornings were spent in the schoolroom; there were regimented afternoon walks; educating the young ladies continued at mealtimes when Edgeworth ate with the family; at night, the governess slept in a curtained off area in the girls' bedroom. Garrett reportedly despised her governess and sought to outwit the teacher in the classroom. When Garrett was 13 and her sister 15, they were sent to a private school, the Boarding School for Ladies in Blackheath, London, which was run by the step aunts of the poet Robert Browning. There, English literature, French, Italian and German as well as deportment, were taught.
Later in life, Garrett recalled the stupidity of her teachers there, though her schooling there did help establish a love of reading. Her main complaint about the school was the lack of science and mathematics instruction. Her reading there included works of Tennyson, Wordsworth, Milton, Coleridge, Trollope, Thackeray and George Eliot. Elizabeth and Louie were known as "the bathing Garretts", as their father had insisted they be allowed a hot bath once a week. However, they made what were to be lifelong friends there. When they finished in 1851, they were sent on a short tour abroad, ending with a memorable visit to the Great Exhibition in Hyde Park, London.

After this formal education, Garrett spent the next nine years tending to domestic duties, but she continued to study Latin and arithmetic in the mornings and also read widely. Her sister Millicent recalled Garrett's weekly lectures, "Talks on Things in General", when her younger siblings would gather while she discussed politics and current affairs from Garibaldi to Macaulay's "History of England". In 1854, when she was eighteen, Garrett and her sister went on a long visit to their school friends, Jane and Anne Crow, in Gateshead where she met Emily Davies, the early feminist and future co-founder of Girton College, Cambridge. Davies was to be a lifelong friend and confidante, always ready to give sound advice during the important decisions of Garrett's career. It may have been in the "English Woman's Journal", first issued in 1858, that Garrett first read of Elizabeth Blackwell, who had become the first female doctor in the United States in 1849. When Blackwell visited London in 1859, Garrett travelled to the capital. By then, her sister Louie was married and living in London. Garrett joined the Society for Promoting the Employment of Women, which organised Blackwell's lectures on "Medicine as a Profession for Ladies" and set up a private meeting between Garrett and the doctor. It is said that during a visit to Alde House around 1860, one evening while sitting by the fireside, Garrett and Davies selected careers for advancing the frontiers of women's rights; Garrett was to open the medical profession to women, Davies the doors to a university education for women, while 13-year-old Millicent was allocated politics and votes for women. At first Newson was opposed to the radical idea of his daughter becoming a physician but came round and agreed to do all in his power, both financially and otherwise, to support Garrett.

After an initial unsuccessful visit to leading doctors in Harley Street, Garrett decided to first spend six months as a surgery nurse at Middlesex Hospital, London in August 1860. On proving to be a good nurse, she was allowed to attend an outpatients' clinic, then her first operation. She unsuccessfully attempted to enroll in the hospital's Medical School but was allowed to attend private tuition in Latin, Greek and pharmacology with the hospital's apothecary, while continuing her work as a nurse. She also employed a tutor to study anatomy and physiology three evenings a week. Eventually she was allowed into the dissecting room and the chemistry lectures. Gradually, Garrett became an unwelcome presence among the male students, who in 1861 presented a memorial to the school against her admittance as a fellow student, despite the support she enjoyed from the administration. She was obliged to leave the Middlesex Hospital but she did so with an honours certificate in chemistry and "materia medica". Garrett then applied to several medical schools, including Oxford, Cambridge, Glasgow, Edinburgh, St Andrews and the Royal College of Surgeons, all of which refused her admittance.

A companion to Garrett in this effort was the lesser known Sophia Jex-Blake. While both are considered "outstanding" medical figures of the late 19th century, Garrett was able to obtain her credentials by way of a "side door" through a loophole in admissions at the Worshipful Society of Apothecaries. Having privately obtained a certificate in anatomy and physiology, she was admitted in 1862 by the Society of Apothecaries who, as a condition of their charter, could not legally exclude her on account of her sex. She was the only woman in the Apothecaries Hall who sat the exam that year. Among the 51 male candidates was William Heath Strange, who went on to found the Hampstead General Hospital, which was on the site now occupied by the Royal Free Hospital. She continued her battle to qualify by studying privately with various professors, including some at the University of St Andrews, the Edinburgh Royal Maternity and the London Hospital Medical School.

In 1865, Garrett finally took her exam and obtained a licence (LSA) from the Society of Apothecaries to practise medicine, the first woman qualified in Britain to do so openly (previously there was Dr James Barry who was born and raised female but presented as male from the age of 20). On the day, three out of seven candidates passed the exam, Garrett with the highest marks. The Society of Apothecaries immediately amended its regulations to prevent other women obtaining a licence meaning that Jex-Blake could not follow this same path; the new rule disallowed privately educated women to be eligible for examination. It was not until 1876 that the new Medical Act (39 and 40 Vict, Ch. 41) passed, which allowed British medical authorities to license all qualified applicants whatever their gender.

Though she was now a licentiate of the Society of Apothecaries, as a woman, Garrett could not hold a medical post in any hospital. So in late 1865, Garrett opened her own practice at 20 Upper Berkeley Street, London. At first patients were scarce, but the practice gradually grew. After six months in practice, she wished to open an outpatients dispensary, to enable poor women to obtain medical help from a qualified practitioner of their own gender. In 1865, there was an outbreak of cholera in Britain, affecting both rich and poor, and in their panic, some people forgot any prejudices they had in relation to a female physician. The first death due to cholera occurred in 1866, but by then Garrett had already opened St Mary's Dispensary for Women and Children, at 69 Seymour Place. In the first year, she tended to 3,000 new patients, who made 9,300 outpatient visits to the dispensary. On hearing that the Dean of the faculty of medicine at the University of Sorbonne, Paris was in favour of admitting women as medical students, Garrett studied French so that she could apply for a medical degree, which she obtained in 1870 after some difficulty.
The same year she was elected to the first London School Board, an office newly opened to women; Garrett's was the highest vote among all the candidates. Also in that year, she was made a visiting physician of the East London Hospital for Children (later the Queen Elizabeth Hospital for Children), becoming the first woman in Britain to be appointed to a medical post, but she found the duties of these two positions to be incompatible with her principal work in her private practice and the dispensary, as well as her role as a new mother, so she resigned from these posts by 1873. In 1872, the dispensary became the New Hospital for Women and Children, treating women from all over London for gynaecological conditions; the hospital moved to new premises in Marylebone Street in 1874. Around this time, Garrett also entered into discussion with male medical views regarding women. In 1874, Henry Maudsley's article on Sex and Mind in Education appeared, which argued that education for women caused over-exertion and thus reduced their reproductive capacity, sometimes causing "nervous and even mental disorders". Garrett's counter-argument was that the real danger for women was not education but boredom and that fresh air and exercise were preferable to sitting by the fire with a novel. In the same year, she co-founded London School of Medicine for Women with Sophia Jex-Blake and became a lecturer in what was then the only teaching hospital in Britain to offer courses for women. She continued to work there for the rest of her career and was dean of the school from 1883 to 1902. This school was later called the Royal Free Hospital of Medicine, which later became part of what is now the medical school of University College London.

In 1873, Garrett gained membership of the British Medical Association (BMA). In 1878, a motion was proposed to exclude women following the election of Garrett Anderson and Frances Hoggan. The motion was opposed by Dr Norman Kerr who maintained the equal rights of members. This was "one of several instances where Garrett, uniquely, was able to enter a hitherto all male medical institution which subsequently moved formally to exclude any women who might seek to follow her." In 1892, women were again admitted to the British Medical Association. In 1897, Garrett Anderson was elected president of the East Anglian branch of the BMA.
Garrett Anderson worked steadily at the development of the New Hospital for Women and Children and in 1874 co-founded and served as dean of the London School of Medicine for Women (LSMW). Both institutions were handsomely and suitably housed and equipped. The New Hospital for Women commissioned a building in the Euston Road; the architect was J. M. Brydon, who took into his employment Anderson's sister Agnes Garrett and her cousin Rhoda Garrett, who contributed to its design. For many years, the hospital was staffed entirely by medical women. The schools (in Hunter Street, WC1) had over 200 students, most of them preparing for the medical degree of London University (the present-day University College London), which was opened to women in 1877.

Garrett Anderson was also active in the women's suffrage movement. In 1866, Garrett Anderson and Davies presented petitions with more than 1,500 signatures asking that female heads of household be given the right to vote. That year, Garrett Anderson joined the first British Women's Suffrage Committee. She was not as active as her sister, Millicent Garrett Fawcett, though Garrett Anderson became a member of the Central Committee of the National Society for Women's Suffrage in 1889. After her husband's death in 1907, she became more active. As mayor of Aldeburgh, she gave speeches for suffrage, before the increasing militant activity in the movement led to her withdrawal in 1911. Her daughter Louisa, also a physician, was more active and more militant, spending time in prison in 1912 for her suffrage activities.

Elizabeth Garrett Anderson once remarked that "a doctor leads two lives, the professional and the private, and the boundaries between the two are never traversed". In 1871, she married James George Skelton Anderson (died 1907) of the Orient Steamship Company, but she did not give up her medical practice. She had three children, Louisa (1873–1943), Margaret (1874–1875), who died of meningitis, and Alan (1877–1952). Louisa also became a pioneering doctor of medicine and feminist activist.

They retired to Aldeburgh in 1902, moving to Alde House in 1903, after the death of Elizabeth's mother. Skelton died of a stroke in 1907. She enjoyed a happy marriage and in later life, devoted time to Alde House, gardening, and travelling with younger members of the extended family.

On 9 November 1908, she was elected mayor of Aldeburgh, the first female mayor in England. Her father had been mayor in 1889.

She died in 1917 and is buried in the churchyard of St Peter and St Paul's Church, Aldeburgh.

The New Hospital for Women was renamed the Elizabeth Garrett Anderson Hospital in 1918 and amalgamated with the Obstetric Hospital in 2001 to form the Elizabeth Garrett Anderson and Obstetric Hospital before relocating to become the University College Hospital Elizabeth Garrett Anderson Wing at UCH.

The former Elizabeth Garrett Anderson Hospital buildings are incorporated into the new National Headquarters for the public service trade union UNISON. The Elizabeth Garrett Anderson Gallery, a permanent installation set within the restored hospital building, uses a variety of media to set the story of Garrett Anderson, her hospital, and women's struggle to achieve equality in the field of medicine within the wider framework of 19th and 20th century social history.

The critical care centre at Ipswich Hospital was named the Garrett Anderson Centre in her honour and in recognition of her connection to the county of Suffolk.

The new medical school at the University of Worcester, due to accept its first students in 2023, is to be called the Elizabeth Garrett Anderson Building.

Elizabeth Garrett Anderson School, a secondary school for girls in Islington, London, is named after her.

The archives of Elizabeth Garrett Anderson are held at the Women's Library at the London School of Economics. The archives of the Elizabeth Garrett Anderson Hospital (formerly the New Hospital for Women) are held at the London Metropolitan Archives.

On 9 June 2016, Google Doodle commemorated her 180th birthday.

The Elizabeth Garrett Anderson Programme of the NHS Leadership Academy is a master's degree in leadership and management.



Erosion

Erosion is the action of surface processes (such as water flow or wind) that removes soil, rock, or dissolved material from one location on the Earth's crust and then transports it to another location where it is deposited. Erosion is distinct from weathering which involves no movement. Removal of rock or soil as clastic sediment is referred to as "physical" or "mechanical" erosion; this contrasts with "chemical" erosion, where soil or rock material is removed from an area by dissolution. Eroded sediment or solutes may be transported just a few millimetres, or for thousands of kilometres.

Agents of erosion include rainfall; bedrock wear in rivers; coastal erosion by the sea and waves; glacial plucking, abrasion, and scour; areal flooding; wind abrasion; groundwater processes; and mass movement processes in steep landscapes like landslides and debris flows. The rates at which such processes act control how fast a surface is eroded. Typically, physical erosion proceeds the fastest on steeply sloping surfaces, and rates may also be sensitive to some climatically controlled properties including amounts of water supplied (e.g., by rain), storminess, wind speed, wave fetch, or atmospheric temperature (especially for some ice-related processes). Feedbacks are also possible between rates of erosion and the amount of eroded material that is already carried by, for example, a river or glacier. The transport of eroded materials from their original location is followed by deposition, which is arrival and emplacement of material at a new location.

While erosion is a natural process, human activities have increased by 10–40 times the rate at which soil erosion is occurring globally. At agriculture sites in the Appalachian Mountains, intensive farming practices have caused erosion at up to 100 times the natural rate of erosion in the region. Excessive (or accelerated) erosion causes both "on-site" and "off-site" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, this leads to desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems worldwide.

Intensive agriculture, deforestation, roads, anthropogenic climate change and urban sprawl are amongst the most significant human activities in regard to their effect on stimulating erosion. However, there are many prevention and remediation practices that can curtail or limit erosion of vulnerable soils.

Rainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: "splash erosion", "sheet erosion", "rill erosion", and "gully erosion". Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).

In "splash erosion", the impact of a falling raindrop creates a small crater in the soil, ejecting soil particles. The distance these soil particles travel can be as much as vertically and horizontally on level ground.

If the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope. "Sheet erosion" is the transport of loosened soil particles by overland flow.

"Rill erosion" refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimetres (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.
"Gully erosion" occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth. A gully is distinguished from a rill based on a critical cross-sectional area of at least one square foot, i.e. the size of a channel that can no longer be erased via normal tillage operations.

Extreme gully erosion can progress to formation of badlands. These form under conditions of high relief on easily eroded bedrock in climates favorable to erosion. Conditions or disturbances that limit the growth of protective vegetation (rhexistasy) are a key element of badland formation.

"Valley" or "stream erosion" occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical V-shaped cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles, and boulders can also act erosively as they traverse a surface, in a process known as "traction".

"Bank erosion" is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as "scour". Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.

"Thermal erosion" is the result of melting and weakening permafrost due to moving water. It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials. Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a segment of the Beaufort Sea shoreline averaged per year from 1955 to 2002.

Most river erosion happens nearer to the mouth of a river. On a river bend, the longest least sharp side has slower moving water. Here deposits build up. On the narrowest sharpest side of the bend, there is faster moving water so this side tends to erode away mostly.

Rapid erosion by a large river can remove enough sediments to produce a river anticline, as isostatic rebound raises rock beds unburdened by erosion of overlying beds.

Shoreline erosion, which occurs on both exposed and sheltered coasts, primarily occurs through the action of currents and waves but sea level (tidal) change can also play a role.
"Hydraulic action" takes place when the air in a joint is suddenly compressed by a wave closing the entrance of the joint. This then cracks it. "Wave pounding" is when the sheer energy of the wave hitting the cliff or rock breaks pieces off. "Abrasion" or "corrasion" is caused by waves launching sea load at the cliff. It is the most effective and rapid form of shoreline erosion (not to be confused with "corrosion"). "Corrosion" is the dissolving of rock by carbonic acid in sea water. Limestone cliffs are particularly vulnerable to this kind of erosion. "Attrition" is where particles/sea load carried by the waves are worn down as they hit each other and the cliffs. This then makes the material easier to wash away. The material ends up as shingle and sand. Another significant source of erosion, particularly on carbonate coastlines, is boring, scraping and grinding of organisms, a process termed "bioerosion".

Sediment is transported along the coast in the direction of the prevailing current (longshore drift). When the upcurrent supply of sediment is less than the amount being carried away, erosion occurs. When the upcurrent amount of sediment is greater, sand or gravel banks will tend to form as a result of deposition. These banks may slowly migrate along the coast in the direction of the longshore drift, alternately protecting and exposing parts of the coastline. Where there is a bend in the coastline, quite often a buildup of eroded material occurs forming a long narrow bank (a spit). Armoured beaches and submerged offshore sandbanks may also protect parts of a coastline from erosion. Over the years, as the shoals gradually shift, the erosion may be redirected to attack different parts of the shore.

Erosion of a coastal surface, followed by a fall in sea level, can produce a distinctive landform called a raised beach.

Chemical erosion is the loss of matter in a landscape in the form of solutes. Chemical erosion is usually calculated from the solutes found in streams. Anders Rapp pioneered the study of chemical erosion in his work about Kärkevagge published in 1960.

Formation of sinkholes and other features of karst topography is an example of extreme chemical erosion.

Glaciers erode predominantly by three different processes: abrasion/scouring, plucking, and ice thrusting. In an abrasion process, debris in the basal ice scrapes along the bed, polishing and gouging the underlying rocks, similar to sandpaper on wood. Scientists have shown that, in addition to the role of temperature played in valley-deepening, other glaciological processes, such as erosion also control cross-valley variations. In a homogeneous bedrock erosion pattern, curved channel cross-section beneath the ice is created. Though the glacier continues to incise vertically, the shape of the channel beneath the ice eventually remain constant, reaching a U-shaped parabolic steady-state shape as we now see in glaciated valleys. Scientists also provide a numerical estimate of the time required for the ultimate formation of a steady-shaped U-shaped valley—approximately 100,000 years. In a weak bedrock (containing material more erodible than the surrounding rocks) erosion pattern, on the contrary, the amount of over deepening is limited because ice velocities and erosion rates are reduced.

Glaciers can also cause pieces of bedrock to crack off in the process of plucking. In ice thrusting, the glacier freezes to its bed, then as it surges forward, it moves large sheets of frozen sediment at the base along with the glacier. This method produced some of the many thousands of lake basins that dot the edge of the Canadian Shield. Differences in the height of mountain ranges are not only being the result tectonic forces, such as rock uplift, but also local climate variations. Scientists use global analysis of topography to show that glacial erosion controls the maximum height of mountains, as the relief between mountain peaks and the snow line are generally confined to altitudes less than 1500 m. The erosion caused by glaciers worldwide erodes mountains so effectively that the term "glacial buzzsaw" has become widely used, which describes the limiting effect of glaciers on the height of mountain ranges. As mountains grow higher, they generally allow for more glacial activity (especially in the accumulation zone above the glacial equilibrium line altitude), which causes increased rates of erosion of the mountain, decreasing mass faster than isostatic rebound can add to the mountain. This provides a good example of a negative feedback loop. Ongoing research is showing that while glaciers tend to decrease mountain size, in some areas, glaciers can actually reduce the rate of erosion, acting as a "glacial armor". Ice can not only erode mountains but also protect them from erosion. Depending on glacier regime, even steep alpine lands can be preserved through time with the help of ice. Scientists have proved this theory by sampling eight summits of northwestern Svalbard using Be10 and Al26, showing that northwestern Svalbard transformed from a glacier-erosion state under relatively mild glacial maxima temperature, to a glacier-armor state occupied by cold-based, protective ice during much colder glacial maxima temperatures as the Quaternary ice age progressed.

These processes, combined with erosion and transport by the water network beneath the glacier, leave behind glacial landforms such as moraines, drumlins, ground moraine (till), glaciokarst, kames, kame deltas, moulins, and glacial erratics in their wake, typically at the terminus or during glacier retreat.

The best-developed glacial valley morphology appears to be restricted to landscapes with low rock uplift rates (less than or equal to 2mm per year) and high relief, leading to long-turnover times. Where rock uplift rates exceed 2mm per year, glacial valley morphology has generally been significantly modified in postglacial time. Interplay of glacial erosion and tectonic forcing governs the morphologic impact of glaciations on active orogens, by both influencing their height, and by altering the patterns of erosion during subsequent glacial periods via a link between rock uplift and valley cross-sectional shape.

At extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.

Wind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damage—especially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.

Wind erosion is of two primary varieties: "deflation", where the wind picks up and carries away loose particles; and "abrasion", where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) "surface creep", where larger, heavier particles slide or roll along the ground; (2) "saltation", where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) "suspension", where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50–70%) of wind erosion, followed by suspension (30–40%), and then surface creep (5–25%).

Wind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.

"Mass wasting" or "mass movement" is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.

Mass wasting is an important part of the erosional process and is often the first stage in the breakdown and transport of weathered materials in mountainous areas. It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-wasting processes are always occurring continuously on all slopes; some mass-wasting processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.

"Slumping" happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.

"Surface creep" is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles in diameter by wind along the soil surface.

On the continental slope, erosion of the ocean floor to create channels and submarine canyons can result from the rapid downslope flow of sediment gravity flows, bodies of sediment-laden water that move rapidly downslope as turbidity currents. Where erosion by turbidity currents creates oversteepened slopes it can also trigger underwater landslides and debris flows. Turbidity currents can erode channels and canyons into substrates ranging from recently deposited unconsolidated sediments to hard crystalline bedrock. Almost all continental slopes and deep ocean basins display such channels and canyons resulting from sediment gravity flows and submarine canyons act as conduits for the transfer of sediment from the continents and shallow marine environments to the deep sea. Turbidites, which are the sedimentary deposits resulting from turbidity currents, comprise some of the thickest and largest sedimentary sequences on Earth, indicating that the associated erosional processes must also have played a prominent role in Earth's history.

The amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.

In some areas of the world (e.g. the mid-western US), rainfall intensity is the primary determinant of erosivity (for a definition of "erosivity" check,) with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.

In other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto the previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water. According to the climate change projections, erosivity will increase significantly in Europe and soil erosion may increase by 13–22.5% by 2050 

In Taiwan, where typhoon frequency increased significantly in the 21st century, a strong link has been drawn between the increase in storm frequency with an increase in sediment load in rivers and reservoirs, highlighting the impacts climate change can have on erosion.

Vegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water and wind erosion. The removal of vegetation increases the rate of surface erosion.

The topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.

Tectonic processes control rates and distributions of erosion at the Earth's surface. If the tectonic action causes part of the Earth's surface (e.g., a mountain range) to be raised or lowered relative to surrounding areas, this must necessarily change the gradient of the land surface. Because erosion rates are almost always sensitive to the local slope (see above), this will change the rates of erosion in the uplifted area. Active tectonics also brings fresh, unweathered rock towards the surface, where it is exposed to the action of erosion.

However, erosion can also affect tectonic processes. The removal by erosion of large amounts of rock from a particular region, and its deposition elsewhere, can result in a lightening of the load on the lower crust and mantle. Because tectonic processes are driven by gradients in the stress field developed in the crust, this unloading can in turn cause tectonic or isostatic uplift in the region. In some cases, it has been hypothesised that these twin feedbacks can act to localize and enhance zones of very rapid exhumation of deep crustal rocks beneath places on the Earth's surface with extremely high erosion rates, for example, beneath the extremely steep terrain of Nanga Parbat in the western Himalayas. Such a place has been called a "tectonic aneurysm".

Human land development, in forms including agricultural and urban development, is considered a significant factor in erosion and sediment transport, which aggravate food insecurity. In Taiwan, increases in sediment load in the northern, central, and southern regions of the island can be tracked with the timeline of development for each region throughout the 20th century. The intentional removal of soil and rock by humans is a form of erosion that has been named "lisasion".

Mountain ranges are known to take many millions of years to erode to the degree they effectively cease to exist. Scholars Pitman and Golovchenko estimate that it takes probably more than 450 million years to erode a mountain mass similar to the Himalaya into an almost-flat peneplain if there are no major sea-level changes. Erosion of mountains massifs can create a pattern of equally high summits called summit accordance. It has been argued that extension during post-orogenic collapse is a more effective mechanism of lowering the height of orogenic mountains than erosion.

Examples of heavily eroded mountain ranges include the Timanides of Northern Russia. Erosion of this orogen has produced sediments that are now found in the East European Platform, including the Cambrian Sablya Formation near Lake Ladoga. Studies of these sediments indicate that it is likely that the erosion of the orogen began in the Cambrian and then intensified in the Ordovician.

If the rate of erosion is higher than the rate of soil formation the soils are being destroyed by erosion. Where soil is not destroyed by erosion, erosion can in some cases prevent the formation of soil features that form slowly. Inceptisols are common soils that form in areas of fast erosion.

While erosion of soils is a natural process, human activities have increased by 10-40 times the rate at which erosion is occurring globally. Excessive (or accelerated) erosion causes both "on-site" and "off-site" problems. On-site impacts include decreases in agricultural productivity and (on natural landscapes) ecological collapse, both because of loss of the nutrient-rich upper soil layers. In some cases, the eventual result is desertification. Off-site effects include sedimentation of waterways and eutrophication of water bodies, as well as sediment-related damage to roads and houses. Water and wind erosion are the two primary causes of land degradation; combined, they are responsible for about 84% of the global extent of degraded land, making excessive erosion one of the most significant environmental problems.

In the United States, farmers cultivating highly erodible land must comply with a conservation plan to be eligible for certain forms of agricultural assistance.



Euclidean space

Euclidean space is the fundamental space of geometry, intended to represent physical space. Originally, in Euclid's "Elements", it was the three-dimensional space of Euclidean geometry, but in modern mathematics there are "Euclidean spaces" of any positive integer dimension "n", which are called Euclidean "n"-spaces when one wants to specify their dimension. For "n" equal to one or two, they are commonly called respectively Euclidean lines and Euclidean planes. The qualifier "Euclidean" is used to distinguish Euclidean spaces from other spaces that were later considered in physics and modern mathematics.

Ancient Greek geometers introduced Euclidean space for modeling the physical space. Their work was collected by the ancient Greek mathematician Euclid in his "Elements", with the great innovation of "proving" all properties of the space as theorems, by starting from a few fundamental properties, called "postulates", which either were considered as evident (for example, there is exactly one straight line passing through two points), or seemed impossible to prove (parallel postulate).

After the introduction at the end of the 19th century of non-Euclidean geometries, the old postulates were re-formalized to define Euclidean spaces through axiomatic theory. Another definition of Euclidean spaces by means of vector spaces and linear algebra has been shown to be equivalent to the axiomatic definition. It is this definition that is more commonly used in modern mathematics, and detailed in this article. In all definitions, Euclidean spaces consist of points, which are defined only by the properties that they must have for forming a Euclidean space.

There is essentially only one Euclidean space of each dimension; that is, all Euclidean spaces of a given dimension are isomorphic. Therefore it is usually possible to work with a specific Euclidean space, denoted formula_1 or formula_2, which can be represented using Cartesian coordinates as the real -space formula_3 equipped with the standard dot product.

Euclidean space was introduced by ancient Greeks as an abstraction of our physical space. Their great innovation, appearing in Euclid's "Elements" was to build and "prove" all geometry by starting from a few very basic properties, which are abstracted from the physical world, and cannot be mathematically proved because of the lack of more basic tools. These properties are called postulates, or axioms in modern language. This way of defining Euclidean space is still in use under the name of synthetic geometry.

In 1637, René Descartes introduced Cartesian coordinates, and showed that these allow reducing geometric problems to algebraic computations with numbers. This reduction of geometry to algebra was a major change in point of view, as, until then, the real numbers were defined in terms of lengths and distances.

Euclidean geometry was not applied in spaces of dimension more than three until the 19th century. Ludwig Schläfli generalized Euclidean geometry to spaces of dimension , using both synthetic and algebraic methods, and discovered all of the regular polytopes (higher-dimensional analogues of the Platonic solids) that exist in Euclidean spaces of any dimension.

Despite the wide use of Descartes' approach, which was called analytic geometry, the definition of Euclidean space remained unchanged until the end of 19th century. The introduction of abstract vector spaces allowed their use in defining Euclidean spaces with a purely algebraic definition. This new definition has been shown to be equivalent to the classical definition in terms of geometric axioms. It is this algebraic definition that is now most often used for introducing Euclidean spaces.

One way to think of the Euclidean plane is as a set of points satisfying certain relationships, expressible in terms of distance and angles. For example, there are two fundamental operations (referred to as motions) on the plane. One is translation, which means a shifting of the plane so that every point is shifted in the same direction and by the same distance. The other is rotation around a fixed point in the plane, in which all points in the plane turn around that fixed point through the same angle. One of the basic tenets of Euclidean geometry is that two figures (usually considered as subsets) of the plane should be considered equivalent (congruent) if one can be transformed into the other by some sequence of translations, rotations and reflections (see below).

In order to make all of this mathematically precise, the theory must clearly define what is a Euclidean space, and the related notions of distance, angle, translation, and rotation. Even when used in physical theories, Euclidean space is an abstraction detached from actual physical locations, specific reference frames, measurement instruments, and so on. A purely mathematical definition of Euclidean space also ignores questions of units of length and other physical dimensions: the distance in a "mathematical" space is a number, not something expressed in inches or metres.

The standard way to mathematically define a Euclidean space, as carried out in the remainder of this article, is as a set of points on which a real vector space acts — the "space of translations" which is equipped with an inner product. The action of translations makes the space an affine space, and this allows defining lines, planes, subspaces, dimension, and parallelism. The inner product allows defining distance and angles.

The set formula_3 of -tuples of real numbers equipped with the dot product is a Euclidean space of dimension . Conversely, the choice of a point called the "origin" and an orthonormal basis of the space of translations is equivalent with defining an isomorphism between a Euclidean space of dimension and formula_3 viewed as a Euclidean space.

It follows that everything that can be said about a Euclidean space can also be said about formula_6 Therefore, many authors, especially at elementary level, call formula_3 the "standard Euclidean space" of dimension , or simply "the" Euclidean space of dimension .

A reason for introducing such an abstract definition of Euclidean spaces, and for working with it instead of formula_3 is that it is often preferable to work in a "coordinate-free" and "origin-free" manner (that is, without choosing a preferred basis and a preferred origin). Another reason is that there is no origin nor any basis in the physical world.

A is a finite-dimensional inner product space over the real numbers.

A Euclidean space is an affine space over the reals such that the associated vector space is a Euclidean vector space. Euclidean spaces are sometimes called "Euclidean affine spaces" to distinguish them from Euclidean vector spaces.

If is a Euclidean space, its associated vector space (Euclidean vector space) is often denoted formula_9 The "dimension" of a Euclidean space is the dimension of its associated vector space.

The elements of are called "points", and are commonly denoted by capital letters. The elements of formula_10 are called "Euclidean vectors" or "free vectors". They are also called "translations", although, properly speaking, a translation is the geometric transformation resulting from the action of a Euclidean vector on the Euclidean space.

The action of a translation on a point provides a point that is denoted . This action satisfies

formula_11

Note: The second in the left-hand side is a vector addition; each other denotes an action of a vector on a point. This notation is not ambiguous, as, to distinguish between the two meanings of , it suffices to look at the nature of its left argument.

The fact that the action is free and transitive means that, for every pair of points , there is exactly one displacement vector such that . This vector is denoted or formula_12

As previously explained, some of the basic properties of Euclidean spaces result from the structure of affine space. They are described in and its subsections. The properties resulting from the inner product are explained in and its subsections.

For any vector space, the addition acts freely and transitively on the vector space itself. Thus a Euclidean vector space can be viewed as a Euclidean space that has itself as the associated vector space.

A typical case of Euclidean vector space is formula_3 viewed as a vector space equipped with the dot product as an inner product. The importance of this particular example of Euclidean space lies in the fact that every Euclidean space is isomorphic to it. More precisely, given a Euclidean space of dimension , the choice of a point, called an "origin" and an orthonormal basis of formula_10 defines an isomorphism of Euclidean spaces from to formula_6

As every Euclidean space of dimension is isomorphic to it, the Euclidean space formula_3 is sometimes called the "standard Euclidean space" of dimension .

Some basic properties of Euclidean spaces depend only on the fact that a Euclidean space is an affine space. They are called affine properties and include the concepts of lines, subspaces, and parallelism, which are detailed in next subsections.

Let be a Euclidean space and formula_10 its associated vector space.

A "flat", "Euclidean subspace" or "affine subspace" of is a subset of such that

formula_18

as the associated vector space of is a linear subspace (vector subspace) of formula_9 A Euclidean subspace is a Euclidean space with formula_20 as the associated vector space. This linear subspace formula_20 is also called the "direction" of .

If is a point of then

formula_22

Conversely, if is a point of and formula_23 is a linear subspace of formula_24 then

formula_25

is a Euclidean subspace of direction formula_23. (The associated vector space of this subspace is formula_23.)

A Euclidean vector space formula_10 (that is, a Euclidean space that is equal to formula_10) has two sorts of subspaces: its Euclidean subspaces and its linear subspaces. Linear subspaces are Euclidean subspaces and a Euclidean subspace is a linear subspace if and only if it contains the zero vector.

In a Euclidean space, a "line" is a Euclidean subspace of dimension one. Since a vector space of dimension one is spanned by any nonzero vector, a line is a set of the form

formula_30

where and are two distinct points of the Euclidean space as a part of the line.

It follows that "there is exactly one line that passes through (contains) two distinct points." This implies that two distinct lines intersect in at most one point.

A more symmetric representation of the line passing through and is

formula_31

where is an arbitrary point (not necessary on the line).

In a Euclidean vector space, the zero vector is usually chosen for ; this allows simplifying the preceding formula into

formula_32

A standard convention allows using this formula in every Euclidean space, see .

The "line segment", or simply "segment", joining the points and is the subset of points such that in the preceding formulas. It is denoted or ; that is

formula_33

Two subspaces and of the same dimension in a Euclidean space are "parallel" if they have the same direction (i.e., the same associated vector space). Equivalently, they are parallel, if there is a translation vector that maps one to the other:

formula_34

Given a point and a subspace , there exists exactly one subspace that contains and is parallel to , which is formula_35 In the case where is a line (subspace of dimension one), this property is Playfair's axiom.

It follows that in a Euclidean plane, two lines either meet in one point or are parallel.

The concept of parallel subspaces has been extended to subspaces of different dimensions: two subspaces are parallel if the direction of one of them is contained in the direction to the other.

The vector space formula_10 associated to a Euclidean space is an inner product space. This implies a symmetric bilinear form

formula_37

that is positive definite (that is formula_38 is always positive for ).

The inner product of a Euclidean space is often called "dot product" and denoted . This is specially the case when a Cartesian coordinate system has been chosen, as, in this case, the inner product of two vectors is the dot product of their coordinate vectors. For this reason, and for historical reasons, the dot notation is more commonly used than the bracket notation for the inner product of Euclidean spaces. This article will follow this usage; that is formula_39 will be denoted in the remainder of this article.

The Euclidean norm of a vector is

formula_40

The inner product and the norm allows expressing and proving metric and topological properties of Euclidean geometry. The next subsection describe the most fundamental ones. "In these subsections," "denotes an arbitrary Euclidean space, and formula_10 denotes its vector space of translations."

The "distance" (more precisely the "Euclidean distance") between two points of a Euclidean space is the norm of the translation vector that maps one point to the other; that is

formula_42

The "length" of a segment is the distance between its endpoints "P" and "Q". It is often denoted formula_43.

The distance is a metric, as it is positive definite, symmetric, and satisfies the triangle inequality

formula_44

Moreover, the equality is true if and only if a point belongs to the segment . This inequality means that the length of any edge of a triangle is smaller than the sum of the lengths of the other edges. This is the origin of the term "triangle inequality".

With the Euclidean distance, every Euclidean space is a complete metric space.

Two nonzero vectors and of formula_10 (the associated vector space of a Euclidean space ) are "perpendicular" or "orthogonal" if their inner product is zero:

formula_46

Two linear subspaces of formula_10 are orthogonal if every nonzero vector of the first one is perpendicular to every nonzero vector of the second one. This implies that the intersection of the linear subspaces is reduced to the zero vector.

Two lines, and more generally two Euclidean subspaces (A line can be considered as one Euclidean subspace.) are orthogonal if their directions (the associated vector spaces of the Euclidean subspaces) are orthogonal. Two orthogonal lines that intersect are said "perpendicular".

Two segments and that share a common endpoint are "perpendicular" or "form a right angle" if the vectors formula_48 and formula_49 are orthogonal.

If and form a right angle, one has

formula_50

This is the Pythagorean theorem. Its proof is easy in this context, as, expressing this in terms of the inner product, one has, using bilinearity and symmetry of the inner product:

formula_51

Here, formula_52 is used since these two vectors are orthogonal.

The (non-oriented) "angle" between two nonzero vectors and in formula_10 is

formula_54

where is the principal value of the arccosine function. By Cauchy–Schwarz inequality, the argument of the arccosine is in the interval . Therefore is real, and (or if angles are measured in degrees).

Angles are not useful in a Euclidean line, as they can be only 0 or .

In an oriented Euclidean plane, one can define the "oriented angle" of two vectors. The oriented angle of two vectors and is then the opposite of the oriented angle of and . In this case, the angle of two vectors can have any value modulo an integer multiple of . In particular, a reflex angle equals the negative angle .

The angle of two vectors does not change if they are multiplied by positive numbers. More precisely, if and are two vectors, and and are real numbers, then

formula_55

If , , and are three points in a Euclidean space, the angle of the segments and is the angle of the vectors formula_56 and formula_57 As the multiplication of vectors by positive numbers do not change the angle, the angle of two half-lines with initial point can be defined: it is the angle of the segments and , where and are arbitrary points, one on each half-line. Although this is less used, one can define similarly the angle of segments or half-lines that do not share an initial point.

The angle of two lines is defined as follows. If is the angle of two segments, one on each line, the angle of any two other segments, one on each line, is either or . One of these angles is in the interval , and the other being in . The "non-oriented angle" of the two lines is the one in the interval . In an oriented Euclidean plane, the "oriented angle" of two lines belongs to the interval .

Every Euclidean vector space has an orthonormal basis (in fact, infinitely many in dimension higher than one, and two in dimension one), that is a basis formula_58 of unit vectors (formula_59) that are pairwise orthogonal (formula_60 for ). More precisely, given any basis formula_61 the Gram–Schmidt process computes an orthonormal basis such that, for every , the linear spans of formula_62 and formula_63 are equal.

Given a Euclidean space , a "Cartesian frame" is a set of data consisting of an orthonormal basis of formula_24 and a point of , called the "origin" and often denoted . A Cartesian frame formula_65 allows defining Cartesian coordinates for both and formula_10 in the following way.

The Cartesian coordinates of a vector of formula_10 are the coefficients of on the orthonormal basis formula_68 For example, the Cartesian coordinates of a vector formula_69 on an orthonormal basis formula_70 (that may be named as formula_71 as a convention) in a 3-dimensional Euclidean space is formula_72 if formula_73. As the basis is orthonormal, the -th coefficient formula_74 is equal to the dot product formula_75

The Cartesian coordinates of a point of are the Cartesian coordinates of the vector formula_76

As a Euclidean space is an affine space, one can consider an affine frame on it, which is the same as a Euclidean frame, except that the basis is not required to be orthonormal. This define affine coordinates, sometimes called "skew coordinates" for emphasizing that the basis vectors are not pairwise orthogonal.

An affine basis of a Euclidean space of dimension is a set of points that are not contained in a hyperplane. An affine basis define barycentric coordinates for every point.

Many other coordinates systems can be defined on a Euclidean space of dimension , in the following way. Let be a homeomorphism (or, more often, a diffeomorphism) from a dense open subset of to an open subset of formula_6 The "coordinates" of a point of are the components of . The polar coordinate system (dimension 2) and the spherical and cylindrical coordinate systems (dimension 3) are defined this way.

For points that are outside the domain of , coordinates may sometimes be defined as the limit of coordinates of neighbour points, but these coordinates may be not uniquely defined, and may be not continuous in the neighborhood of the point. For example, for the spherical coordinate system, the longitude is not defined at the pole, and on the antimeridian, the longitude passes discontinuously from –180° to +180°.

This way of defining coordinates extends easily to other mathematical structures, and in particular to manifolds.

An isometry between two metric spaces is a bijection preserving the distance, that is

formula_78

In the case of a Euclidean vector space, an isometry that maps the origin to the origin preserves the norm

formula_79

since the norm of a vector is its distance from the zero vector. It preserves also the inner product

formula_80

since

formula_81

An isometry of Euclidean vector spaces is a linear isomorphism.

An isometry formula_82 of Euclidean spaces defines an isometry formula_83 of the associated Euclidean vector spaces. This implies that two isometric Euclidean spaces have the same dimension. Conversely, if and are Euclidean spaces, , , and formula_84 is an isometry, then the map formula_82 defined by

formula_86

is an isometry of Euclidean spaces.

It follows from the preceding results that an isometry of Euclidean spaces maps lines to lines, and, more generally Euclidean subspaces to Euclidean subspaces of the same dimension, and that the restriction of the isometry on these subspaces are isometries of these subspaces.

If is a Euclidean space, its associated vector space formula_10 can be considered as a Euclidean space. Every point defines an isometry of Euclidean spaces

formula_88

which maps to the zero vector and has the identity as associated linear map. The inverse isometry is the map

formula_89

A Euclidean frame allows defining the map

formula_90

which is an isometry of Euclidean spaces. The inverse isometry is

formula_91

"This means that, up to an isomorphism, there is exactly one Euclidean space of a given dimension."

This justifies that many authors talk of formula_3 as "the" Euclidean space of dimension .

An isometry from a Euclidean space onto itself is called "Euclidean isometry", "Euclidean transformation" or "rigid transformation". The rigid transformations of a Euclidean space form a group (under composition), called the "Euclidean group" and often denoted of .

The simplest Euclidean transformations are translations

formula_93

They are in bijective correspondence with vectors. This is a reason for calling "space of translations" the vector space associated to a Euclidean space. The translations form a normal subgroup of the Euclidean group.

A Euclidean isometry of a Euclidean space defines a linear isometry formula_94 of the associated vector space (by "linear isometry", it is meant an isometry that is also a linear map) in the following way: denoting by the vector formula_95 if is an arbitrary point of , one has

formula_96

It is straightforward to prove that this is a linear map that does not depend from the choice of 

The map formula_97 is a group homomorphism from the Euclidean group onto the group of linear isometries, called the orthogonal group. The kernel of this homomorphism is the translation group, showing that it is a normal subgroup of the Euclidean group.

The isometries that fix a given point form the stabilizer subgroup of the Euclidean group with respect to . The restriction to this stabilizer of above group homomorphism is an isomorphism. So the isometries that fix a given point form a group isomorphic to the orthogonal group.

Let be a point, an isometry, and the translation that maps to . The isometry formula_98 fixes . So formula_99 and "the Euclidean group is the semidirect product of the translation group and the orthogonal group."

The special orthogonal group is the normal subgroup of the orthogonal group that preserves handedness. It is a subgroup of index two of the orthogonal group. Its inverse image by the group homomorphism formula_97 is a normal subgroup of index two of the Euclidean group, which is called the "special Euclidean group" or the "displacement group". Its elements are called "rigid motions" or "displacements".

Rigid motions include the identity, translations, rotations (the rigid motions that fix at least a point), and also screw motions.

Typical examples of rigid transformations that are not rigid motions are reflections, which are rigid transformations that fix a hyperplane and are not the identity. They are also the transformations consisting in changing the sign of one coordinate over some Euclidean frame.

As the special Euclidean group is a subgroup of index two of the Euclidean group, given a reflection , every rigid transformation that is not a rigid motion is the product of and a rigid motion. A glide reflection is an example of a rigid transformation that is not a rigid motion or a reflection.

All groups that have been considered in this section are Lie groups and algebraic groups.

The Euclidean distance makes a Euclidean space a metric space, and thus a topological space. This topology is called the Euclidean topology. In the case of formula_101 this topology is also the product topology.

The open sets are the subsets that contains an open ball around each of their points. In other words, open balls form a base of the topology.

The topological dimension of a Euclidean space equals its dimension. This implies that Euclidean spaces of different dimensions are not homeomorphic. Moreover, the theorem of invariance of domain asserts that a subset of a Euclidean space is open (for the subspace topology) if and only if it is homeomorphic to an open subset of a Euclidean space of the same dimension.

Euclidean spaces are complete and locally compact. That is, a closed subset of a Euclidean space is compact if it is bounded (that is, contained in a ball). In particular, closed balls are compact.

The definition of Euclidean spaces that has been described in this article differs fundamentally of Euclid's one. In reality, Euclid did not define formally the space, because it was thought as a description of the physical world that exists independently of human mind. The need of a formal definition appeared only at the end of 19th century, with the introduction of non-Euclidean geometries.

Two different approaches have been used. Felix Klein suggested to define geometries through their symmetries. The presentation of Euclidean spaces given in this article, is essentially issued from his Erlangen program, with the emphasis given on the groups of translations and isometries.

On the other hand, David Hilbert proposed a set of axioms, inspired by Euclid's postulates. They belong to synthetic geometry, as they do not involve any definition of real numbers. Later G. D. Birkhoff and Alfred Tarski proposed simpler sets of axioms, which use real numbers (see Birkhoff's axioms and Tarski's axioms).

In "Geometric Algebra", Emil Artin has proved that all these definitions of a Euclidean space are equivalent. It is rather easy to prove that all definitions of Euclidean spaces satisfy Hilbert's axioms, and that those involving real numbers (including the above given definition) are equivalent. The difficult part of Artin's proof is the following. In Hilbert's axioms, congruence is an equivalence relation on segments. One can thus define the "length" of a segment as its equivalence class. One must thus prove that this length satisfies properties that characterize nonnegative real numbers. Artin proved this with axioms equivalent to those of Hilbert.

Since ancient Greeks, Euclidean space is used for modeling shapes in the physical world. It is thus used in many sciences such as physics, mechanics, and astronomy. It is also widely used in all technical areas that are concerned with shapes, figure, location and position, such as architecture, geodesy, topography, navigation, industrial design, or technical drawing.

Space of dimensions higher than three occurs in several modern theories of physics; see Higher dimension. They occur also in configuration spaces of physical systems.

Beside Euclidean geometry, Euclidean spaces are also widely used in other areas of mathematics. Tangent spaces of differentiable manifolds are Euclidean vector spaces. More generally, a manifold is a space that is locally approximated by Euclidean spaces. Most non-Euclidean geometries can be modeled by a manifold, and embedded in a Euclidean space of higher dimension. For example, an elliptic space can be modeled by an ellipsoid. It is common to represent in a Euclidean space mathematical objects that are "a priori" not of a geometrical nature. An example among many is the usual representation of graphs.

Since the introduction, at the end of 19th century, of non-Euclidean geometries, many sorts of spaces have been considered, about which one can do geometric reasoning in the same way as with Euclidean spaces. In general, they share some properties with Euclidean spaces, but may also have properties that could appear as rather strange. Some of these spaces use Euclidean geometry for their definition, or can be modeled as subspaces of a Euclidean space of higher dimension. When such a space is defined by geometrical axioms, embedding the space in a Euclidean space is a standard way for proving consistency of its definition, or, more precisely for proving that its theory is consistent, if Euclidean geometry is consistent (which cannot be proved).

A Euclidean space is an affine space equipped with a metric. Affine spaces have many other uses in mathematics. In particular, as they are defined over any field, they allow doing geometry in other contexts.

As soon as non-linear questions are considered, it is generally useful to consider affine spaces over the complex numbers as an extension of Euclidean spaces. For example, a circle and a line have always two intersection points (possibly not distinct) in the complex affine space. Therefore, most of algebraic geometry is built in complex affine spaces and affine spaces over algebraically closed fields. The shapes that are studied in algebraic geometry in these affine spaces are therefore called affine algebraic varieties.

Affine spaces over the rational numbers and more generally over algebraic number fields provide a link between (algebraic) geometry and number theory. For example, the Fermat's Last Theorem can be stated "a Fermat curve of degree higher than two has no point in the affine plane over the rationals."

Geometry in affine spaces over a finite fields has also been widely studied. For example, elliptic curves over finite fields are widely used in cryptography.

Originally, projective spaces have been introduced by adding "points at infinity" to Euclidean spaces, and, more generally to affine spaces, in order to make true the assertion "two coplanar lines meet in exactly one point". Projective space share with Euclidean and affine spaces the property of being isotropic, that is, there is no property of the space that allows distinguishing between two points or two lines. Therefore, a more isotropic definition is commonly used, which consists as defining a projective space as the set of the vector lines in a vector space of dimension one more.

As for affine spaces, projective spaces are defined over any field, and are fundamental spaces of algebraic geometry.

"Non-Euclidean geometry" refers usually to geometrical spaces where the parallel postulate is false. They include elliptic geometry, where the sum of the angles of a triangle is more than 180°, and hyperbolic geometry, where this sum is less than 180°. Their introduction in the second half of 19th century, and the proof that their theory is consistent (if Euclidean geometry is not contradictory) is one of the paradoxes that are at the origin of the foundational crisis in mathematics of the beginning of 20th century, and motivated the systematization of axiomatic theories in mathematics.

A manifold is a space that in the neighborhood of each point resembles a Euclidean space. In technical terms, a manifold is a topological space, such that each point has a neighborhood that is homeomorphic to an open subset of a Euclidean space. Manifolds can be classified by increasing degree of this "resemblance" into topological manifolds, differentiable manifolds, smooth manifolds, and analytic manifolds. However, none of these types of "resemblance" respect distances and angles, even approximately.

Distances and angles can be defined on a smooth manifold by providing a smoothly varying Euclidean metric on the tangent spaces at the points of the manifold (these tangent spaces are thus Euclidean vector spaces). This results in a Riemannian manifold. Generally, straight lines do not exist in a Riemannian manifold, but their role is played by geodesics, which are the "shortest paths" between two points. This allows defining distances, which are measured along geodesics, and angles between geodesics, which are the angle of their tangents in the tangent space at their intersection. So, Riemannian manifolds behave locally like a Euclidean space that has been bent.

Euclidean spaces are trivially Riemannian manifolds. An example illustrating this well is the surface of a sphere. In this case, geodesics are arcs of great circle, which are called orthodromes in the context of navigation. More generally, the spaces of non-Euclidean geometries can be realized as Riemannian manifolds.

An inner product of a real vector space is a positive definite bilinear form, and so characterized by a positive definite quadratic form. A pseudo-Euclidean space is an affine space with an associated real vector space equipped with a non-degenerate quadratic form (that may be indefinite).

A fundamental example of such a space is the Minkowski space, which is the space-time of Einstein's special relativity. It is a four-dimensional space, where the metric is defined by the quadratic form

formula_102

where the last coordinate ("t") is temporal, and the other three ("x", "y", "z") are spatial.

To take gravity into account, general relativity uses a pseudo-Riemannian manifold that has Minkowski spaces as tangent spaces. The curvature of this manifold at a point is a function of the value of the gravitational field at this point.



Edwin Austin Abbey

Edwin Austin Abbey (April 1, 1852August 1, 1911) was an American muralist, illustrator, and painter. He flourished at the beginning of what is now referred to as the "golden age" of illustration, and is best known for his drawings and paintings of Shakespearean and Victorian subjects, as well as for his painting of Edward VII's coronation. His most famous set of murals, "The Quest and Achievement of the Holy Grail", adorns the Boston Public Library.

Abbey was born in Philadelphia on April 1, 1852 to commercial broker William Maxwell Abbey and Margery Ann Kiple. He studied art at the Pennsylvania Academy of the Fine Arts under Christian Schuessele. Abbey began as an illustrator, producing numerous illustrations and sketches for such magazines as Harper's Weekly (1871–1874) and Scribner's Magazine. His illustrations began appearing in Harper's Weekly before Abbey was twenty years old. He moved to New York City in 1871. His illustrations were strongly influenced by French and German black and white art. He also illustrated several best-selling books, including "Christmas Stories" by Charles Dickens (1875), "Selections from the Poetry of Robert Herrick" (1882), and "She Stoops to Conquer" by Oliver Goldsmith (1887). Abbey also illustrated a four-volume set of "The Comedies of Shakespeare" for Harper & Brothers in 1896.

He moved to England in 1878, at the request of his employers, to gather material for illustrations of the poems of Robert Herrick, published in 1882, and he settled permanently there in 1883. In 1883, he was elected to the Royal Institute of Painters in Water-Colours. About this time, he was appraised critically by the American writer, S.G.W. Benjamin:
He also created illustrations for Goldsmith's "She Stoops to Conquer" (1887), for a volume of "Old Songs" (1889), and for the comedies (and a few of the tragedies) of Shakespeare. Among his water-colours are "The Evil Eye" (1877), "The Rose in October" (1879), "An Old Song" (1886), "The Visitors" (1890), and "The Jongleur" (1892). Possibly his best known pastels are "Beatrice", "Phyllis", and "Two Noble Kinsmen".
In 1890 he made his first appearance with an oil painting, "A May Day Morn", at the Royal Academy in London. He exhibited "Richard duke of Gloucester and the Lady Anne" there in 1896, and in that year was elected A.R.A., becoming a full member in 1898. He received a gold medal at the Pan-American Exposition and was commissioned to paint the coronation of King Edward VII. in 1901; in the next year, he was chosen to paint the coronation. It was the official painting of the occasion and, hence, resides at Buckingham Palace. He did receive a knighthood, although some say he refused it in 1907. Friendly with other expatriate American artists, he summered at Broadway, Worcestershire, England, where he painted and vacationed alongside John Singer Sargent at the home of Francis Davis Millet.

He completed murals for the Boston Public Library in the 1890s. The frieze for the Library was titled "The Quest and Achievement of the Holy Grail". It took Abbey eleven years to complete this series of murals in his England studio. In 1897 he received the honorary degree of A.M. from Yale university.

In 1904 he painted a mural for the Royal Exchange, London "Reconciliation of the Skinners & Merchant Taylors' Companies by Lord Mayor Billesden, 1484".

In 1908–09, Abbey began an ambitious program of murals and other artworks for the newly completed Pennsylvania State Capitol in Harrisburg, Pennsylvania. These included allegorical medallion murals representing "Science", "Art", "Justice", and "Religion" for the dome of the Rotunda, four large lunette murals beneath the dome, and multiple works for the House and Senate Chambers. For the Senate chamber he finished only one painting, "Von Steuben Training the American Soldiers at Valley Forge", and he was working on the "Reading of the Declaration of Independence" mural in early 1911, when his health began to fail. He was diagnosed with cancer. Studio assistant William Simmonds continued work on the mural with little supervision from Abbey, and with small contributions by John Singer Sargent.

Abbey died in August 1911. William Simmonds travelled from England to install the completed murals with Abbey's widow Gertrude. The remaining two rooms, which Abbey had been unable to finish, were given to Violet Oakley, who completed the commission using her own designs.
Abbey was elected to the National Academy of Design, in 1902, and The American Academy of Arts and Letters. He was honorary member of the Royal Bavarian Society and the Société Nationale des Beaux-Arts, and was made a chevalier of the French Legion of Honour. He was a prolific illustrator, and attention to detail, including historical accuracy, influenced successive generations of illustrators.

In 1890, Edwin married Gertrude Mead, the daughter of a wealthy New York merchant. Mrs Abbey encouraged her husband to secure more ambitious commissions, although with their marriage commencing when both were in their forties, the couple remained childless. After her husband's death, Gertrude was active in preserving her husband's legacy, writing about his work and giving her substantial collection and archive to Yale. In 1932, through the Edwin Austin Abbey Memorial Fund for Mural Painting, she endowed the Abbey Mural Prize to support the creation and restoration of public murals in the United States. It is awarded each year by a jury of National Academicians through the National Academy of Design. She was a sponsor of the Survey of London. 

Edwin had been a keen supporter of the newly founded British School at Rome (BSR), so, in his memory, she donated £6000 to assist in building the artists' studio block and, in 1926, founded the Incorporated Edwin Austin Abbey Memorial Scholarships. The scholarships were established to enable British and American painters to pursue their practice. Recipients of Abbey funding – Scholars and, more recently, Fellows – devote their scholarship to working in the studios at the BSR, where there has, ever since, been at least one Abbey-funded artist in residence. Previous award holders include Stephen Farthing, Chantal Joffe and Spartacus Chetwynd. The Abbey Fellowships (formerly 'Awards') were established in their present form in 1990, and the Abbey studios also host the BSR's other Fine Art residencies, such as the Derek Hill Foundation Scholarship and the Sainsbury Scholarship in Painting and Drawing. A bust of Edwin Abbey, by Sir Thomas Brock, stands in the courtyard of the BSR. 

Edwin also left bequests of his works to the Metropolitan Museum of Art in New York, to the Museum of Fine Arts, Boston and to the National Gallery in London.

Abbey is buried in the churchyard of Old St Andrew's Church in Kingsbury, London. His grave is Grade II listed.




Evolutionary psychology

Evolutionary psychology is a theoretical approach in psychology that examines cognition and behavior from a modern evolutionary perspective. It seeks to identify human psychological adaptations with regards to the ancestral problems they evolved to solve. In this framework, psychological traits and mechanisms are either functional products of natural and sexual selection or non-adaptive by-products of other adaptive traits. 

Adaptationist thinking about physiological mechanisms, such as the heart, lungs, and the liver, is common in evolutionary biology. Evolutionary psychologists apply the same thinking in psychology, arguing that just as the heart evolved to pump blood, and the liver evolved to detoxify poisons, there is modularity of mind in that different psychological mechanisms evolved to solve different adaptive problems. These evolutionary psychologists argue that much of human behavior is the output of psychological adaptations that evolved to solve recurrent problems in human ancestral environments.

Some evolutionary psychologists argue that evolutionary theory can provide a foundational, metatheoretical framework that integrates the entire field of psychology in the same way evolutionary biology has for biology.

Evolutionary psychologists hold that behaviors or traits that occur universally in all cultures are good candidates for evolutionary adaptations, including the abilities to infer others' emotions, discern kin from non-kin, identify and prefer healthier mates, and cooperate with others. Findings have been made regarding human social behaviour related to infanticide, intelligence, marriage patterns, promiscuity, perception of beauty, bride price, and parental investment. The theories and findings of evolutionary psychology have applications in many fields, including economics, environment, health, law, management, psychiatry, politics, and literature.

Criticism of evolutionary psychology involves questions of testability, cognitive and evolutionary assumptions (such as modular functioning of the brain, and large uncertainty about the ancestral environment), importance of non-genetic and non-adaptive explanations, as well as political and ethical issues due to interpretations of research results. Evolutionary psychologists frequently engage with and respond to such criticisms.

Evolutionary psychology is an approach that views human nature as the product of a universal set of evolved psychological adaptations to recurring problems in the ancestral environment. Proponents suggest that it seeks to integrate psychology into the other natural sciences, rooting it in the organizing theory of biology (evolutionary theory), and thus understanding psychology as a branch of biology. Anthropologist John Tooby and psychologist Leda Cosmides note:

Just as human physiology and evolutionary physiology have worked to identify physical adaptations of the body that represent "human physiological nature," the purpose of evolutionary psychology is to identify evolved emotional and cognitive adaptations that represent "human psychological nature." According to Steven Pinker, it is "not a single theory but a large set of hypotheses" and a term that "has also come to refer to a particular way of applying evolutionary theory to the mind, with an emphasis on adaptation, gene-level selection, and modularity." Evolutionary psychology adopts an understanding of the mind that is based on the computational theory of mind. It describes mental processes as computational operations, so that, for example, a fear response is described as arising from a neurological computation that inputs the perceptional data, e.g. a visual image of a spider, and outputs the appropriate reaction, e.g. fear of possibly dangerous animals. Under this view, any domain-general learning is impossible because of the combinatorial explosion. Evolutionary Psychology specifies the domain as the problems of survival and reproduction.

While philosophers have generally considered the human mind to include broad faculties, such as reason and lust, evolutionary psychologists describe evolved psychological mechanisms as narrowly focused to deal with specific issues, such as catching cheaters or choosing mates. The discipline views the human brain as comprising many functional mechanisms called "psychological adaptations" or evolved cognitive mechanisms or "cognitive modules", designed by the process of natural selection. Examples include language-acquisition modules, incest-avoidance mechanisms, cheater-detection mechanisms, intelligence and sex-specific mating preferences, foraging mechanisms, alliance-tracking mechanisms, agent-detection mechanisms, and others. Some mechanisms, termed "domain-specific", deal with recurrent adaptive problems over the course of human evolutionary history. "Domain-general" mechanisms, on the other hand, are proposed to deal with evolutionary novelty.

Evolutionary psychology has roots in cognitive psychology and evolutionary biology but also draws on behavioral ecology, artificial intelligence, genetics, ethology, anthropology, archaeology, biology, and zoology. It is closely linked to sociobiology, but there are key differences between them including the emphasis on "domain-specific" rather than "domain-general" mechanisms, the relevance of measures of current fitness, the importance of mismatch theory, and psychology rather than behavior.

Nikolaas Tinbergen's four categories of questions can help to clarify the distinctions between several different, but complementary, types of explanations. Evolutionary psychology focuses primarily on the "why?" questions, while traditional psychology focuses on the "how?" questions.

Evolutionary psychology is founded on several core premises.


Evolutionary psychology has its historical roots in Charles Darwin's theory of natural selection. In "The Origin of Species", Darwin predicted that psychology would develop an evolutionary basis:

Two of his later books were devoted to the study of animal emotions and psychology; "The Descent of Man, and Selection in Relation to Sex" in 1871 and "The Expression of the Emotions in Man and Animals" in 1872. Darwin's work inspired William James's functionalist approach to psychology. Darwin's theories of evolution, adaptation, and natural selection have provided insight into why brains function the way they do.

The content of evolutionary psychology has derived from, on the one hand, the biological sciences (especially evolutionary theory as it relates to ancient human environments, the study of paleoanthropology and animal behavior) and, on the other, the human sciences, especially psychology.

Evolutionary biology as an academic discipline emerged with the modern synthesis in the 1930s and 1940s. In the 1930s the study of animal behavior (ethology) emerged with the work of the Dutch biologist Nikolaas Tinbergen and the Austrian biologists Konrad Lorenz and Karl von Frisch.

W.D. Hamilton's (1964) papers on inclusive fitness and Robert Trivers's (1972) theories on reciprocity and parental investment helped to establish evolutionary thinking in psychology and the other social sciences. In 1975, Edward O. Wilson combined evolutionary theory with studies of animal and social behavior, building on the works of Lorenz and Tinbergen, in his book "".

In the 1970s, two major branches developed from ethology. Firstly, the study of animal "social" behavior (including humans) generated sociobiology, defined by its pre-eminent proponent Edward O. Wilson in 1975 as "the systematic study of the biological basis of all social behavior" and in 1978 as "the extension of population biology and evolutionary theory to social organization." Secondly, there was behavioral ecology which placed less emphasis on "social" behavior; it focused on the ecological and evolutionary basis of animal and human behavior.

In the 1970s and 1980s university departments began to include the term "evolutionary biology" in their titles. The modern era of evolutionary psychology was ushered in, in particular, by Donald Symons' 1979 book "The Evolution of Human Sexuality" and Leda Cosmides and John Tooby's 1992 book "The Adapted Mind". David Buller observed that the term "evolutionary psychology" is sometimes seen as denoting research based on the specific methodological and theoretical commitments of certain researchers from the Santa Barbara school (University of California), thus some evolutionary psychologists prefer to term their work "human ecology", "human behavioural ecology" or "evolutionary anthropology" instead.

From psychology there are the primary streams of developmental, social and cognitive psychology. Establishing some measure of the relative influence of genetics and environment on behavior has been at the core of behavioral genetics and its variants, notably studies at the molecular level that examine the relationship between genes, neurotransmitters and behavior. Dual inheritance theory (DIT), developed in the late 1970s and early 1980s, has a slightly different perspective by trying to explain how human behavior is a product of two different and interacting evolutionary processes: genetic evolution and cultural evolution. DIT is seen by some as a "middle-ground" between views that emphasize human universals versus those that emphasize cultural variation.

The theories on which evolutionary psychology is based originated with Charles Darwin's work, including his speculations about the evolutionary origins of social instincts in humans. Modern evolutionary psychology, however, is possible only because of advances in evolutionary theory in the 20th century.

Evolutionary psychologists say that natural selection has provided humans with many psychological adaptations, in much the same way that it generated humans' anatomical and physiological adaptations. As with adaptations in general, psychological adaptations are said to be specialized for the environment in which an organism evolved, the environment of evolutionary adaptedness. Sexual selection provides organisms with adaptations related to mating. For male mammals, which have a relatively high maximal potential reproduction rate, sexual selection leads to adaptations that help them compete for females. For female mammals, with a relatively low maximal potential reproduction rate, sexual selection leads to choosiness, which helps females select higher quality mates. Charles Darwin described both natural selection and sexual selection, and he relied on group selection to explain the evolution of altruistic (self-sacrificing) behavior. But group selection was considered a weak explanation, because in any group the less altruistic individuals will be more likely to survive, and the group will become less self-sacrificing as a whole.

In 1964, the evolutionary biologist William D. Hamilton proposed inclusive fitness theory, emphasizing a gene-centered view of evolution. Hamilton noted that genes can increase the replication of copies of themselves into the next generation by influencing the organism's social traits in such a way that (statistically) results in helping the survival and reproduction of other copies of the same genes (most simply, identical copies in the organism's close relatives). According to Hamilton's rule, self-sacrificing behaviors (and the genes influencing them) can evolve if they typically help the organism's close relatives so much that it more than compensates for the individual animal's sacrifice. Inclusive fitness theory resolved the issue of how altruism can evolve. Other theories also help explain the evolution of altruistic behavior, including evolutionary game theory, tit-for-tat reciprocity, and generalized reciprocity. These theories help to explain the development of altruistic behavior, and account for hostility toward cheaters (individuals that take advantage of others' altruism).

Several mid-level evolutionary theories inform evolutionary psychology. The r/K selection theory proposes that some species prosper by having many offspring, while others follow the strategy of having fewer offspring but investing much more in each one. Humans follow the second strategy. Parental investment theory explains how parents invest more or less in individual offspring based on how successful those offspring are likely to be, and thus how much they might improve the parents' inclusive fitness. According to the Trivers–Willard hypothesis, parents in good conditions tend to invest more in sons (who are best able to take advantage of good conditions), while parents in poor conditions tend to invest more in daughters (who are best able to have successful offspring even in poor conditions). According to life history theory, animals evolve life histories to match their environments, determining details such as age at first reproduction and number of offspring. Dual inheritance theory posits that genes and human culture have interacted, with genes affecting the development of culture, and culture, in turn, affecting human evolution on a genetic level, in a similar way to the Baldwin effect.

Evolutionary psychology is based on the hypothesis that, just like hearts, lungs, livers, kidneys, and immune systems, cognition has a functional structure that has a genetic basis, and therefore has evolved by natural selection. Like other organs and tissues, this functional structure should be universally shared amongst a species and should solve important problems of survival and reproduction.

Evolutionary psychologists seek to understand psychological mechanisms by understanding the survival and reproductive functions they might have served over the course of evolutionary history. These might include abilities to infer others' emotions, discern kin from non-kin, identify and prefer healthier mates, cooperate with others and follow leaders. Consistent with the theory of natural selection, evolutionary psychology sees humans as often in conflict with others, including mates and relatives. For instance, a mother may wish to wean her offspring from breastfeeding earlier than does her infant, which frees up the mother to invest in additional offspring. Evolutionary psychology also recognizes the role of kin selection and reciprocity in evolving prosocial traits such as altruism. Like chimpanzees and bonobos, humans have subtle and flexible social instincts, allowing them to form extended families, lifelong friendships, and political alliances. In studies testing theoretical predictions, evolutionary psychologists have made modest findings on topics such as infanticide, intelligence, marriage patterns, promiscuity, perception of beauty, bride price and parental investment.

Another example would be the evolved mechanism in depression. Clinical depression is maladaptive and should have evolutionary approaches so it can become adaptive. Over the centuries animals and humans have gone through hard times to stay alive, which made our fight or flight senses evolve tremendously. For instances, mammalians have separation anxiety from their guardians which causes distress and sends signals to their hypothalamic pituitary adrenal axis, and emotional/behavioral changes. Going through these types of circumstances helps mammals cope with separation anxiety.

Proponents of evolutionary psychology in the 1990s made some explorations in historical events, but the response from historical experts was highly negative and there has been little effort to continue that line of research. Historian Lynn Hunt says that the historians complained that the researchers:
Hunt states that "the few attempts to build up a subfield of psychohistory collapsed under the weight of its presuppositions." She concludes that, as of 2014, the "'iron curtain' between historians and psychology...remains standing."

Not all traits of organisms are evolutionary adaptations. As noted in the table below, traits may also be exaptations, byproducts of adaptations (sometimes called "spandrels"), or random variation between individuals.

Psychological adaptations are hypothesized to be innate or relatively easy to learn and to manifest in cultures worldwide. For example, the ability of toddlers to learn a language with virtually no training is likely to be a psychological adaptation. On the other hand, ancestral humans did not read or write, thus today, learning to read and write requires extensive training, and presumably involves the repurposing of cognitive capacities that evolved in response to selection pressures unrelated to written language. However, variations in manifest behavior can result from universal mechanisms interacting with different local environments. For example, Caucasians who move from a northern climate to the equator will have darker skin. The mechanisms regulating their pigmentation do not change; rather the input to those mechanisms change, resulting in different outputs.

One of the tasks of evolutionary psychology is to identify which psychological traits are likely to be adaptations, byproducts or random variation. George C. Williams suggested that an "adaptation is a special and onerous concept that should only be used where it is really necessary." As noted by Williams and others, adaptations can be identified by their improbable complexity, species universality, and adaptive functionality.

A question that may be asked about an adaptation is whether it is generally obligate (relatively robust in the face of typical environmental variation) or facultative (sensitive to typical environmental variation). The sweet taste of sugar and the pain of hitting one's knee against concrete are the result of fairly obligate psychological adaptations; typical environmental variability during development does not much affect their operation. By contrast, facultative adaptations are somewhat like "if-then" statements. For example, The adaptation for skin to tan is conditional to exposure to sunlight; this is an example of another facultative adaptation. When a psychological adaptation is facultative, evolutionary psychologists concern themselves with how developmental and environmental inputs influence the expression of the adaptation.

Evolutionary psychologists hold that behaviors or traits that occur universally in all cultures are good candidates for evolutionary adaptations. Cultural universals include behaviors related to language, cognition, social roles, gender roles, and technology. Evolved psychological adaptations (such as the ability to learn a language) interact with cultural inputs to produce specific behaviors (e.g., the specific language learned).

Basic gender differences, such as greater eagerness for sex among men and greater coyness among women, are explained as sexually dimorphic psychological adaptations that reflect the different reproductive strategies of males and females.

Evolutionary psychologists contrast their approach to what they term the "standard social science model," according to which the mind is a general-purpose cognition device shaped almost entirely by culture.

Evolutionary psychology argues that to properly understand the functions of the brain, one must understand the properties of the environment in which the brain evolved. That environment is often referred to as the "environment of evolutionary adaptedness".

The idea of an "environment of evolutionary adaptedness" was first explored as a part of attachment theory by John Bowlby. This is the environment to which a particular evolved mechanism is adapted. More specifically, the environment of evolutionary adaptedness is defined as the set of historically recurring selection pressures that formed a given adaptation, as well as those aspects of the environment that were necessary for the proper development and functioning of the adaptation.

Humans, comprising the genus "Homo", appeared between 1.5 and 2.5 million years ago, a time that roughly coincides with the start of the Pleistocene 2.6 million years ago. Because the Pleistocene ended a mere 12,000 years ago, most human adaptations either newly evolved during the Pleistocene, or were maintained by stabilizing selection during the Pleistocene. Evolutionary psychology, therefore, proposes that the majority of human psychological mechanisms are adapted to reproductive problems frequently encountered in Pleistocene environments. In broad terms, these problems include those of growth, development, differentiation, maintenance, mating, parenting, and social relationships.

The environment of evolutionary adaptedness is significantly different from modern society. The ancestors of modern humans lived in smaller groups, had more cohesive cultures, and had more stable and rich contexts for identity and meaning. Researchers look to existing hunter-gatherer societies for clues as to how hunter-gatherers lived in the environment of evolutionary adaptedness. Unfortunately, the few surviving hunter-gatherer societies are different from each other, and they have been pushed out of the best land and into harsh environments, so it is not clear how closely they reflect ancestral culture. However, all around the world small-band hunter-gatherers offer a similar developmental system for the young ("hunter-gatherer childhood model," Konner, 2005; 
"evolved developmental niche" or "evolved nest;" Narvaez et al., 2013). The characteristics of the niche are largely the same as for social mammals, who evolved over 30 million years ago: soothing perinatal experience, several years of on-request breastfeeding, nearly constant affection or physical proximity, responsiveness to need (mitigating offspring distress), self-directed play, and for humans, multiple responsive caregivers. Initial studies show the importance of these components in early life for positive child outcomes.

Evolutionary psychologists sometimes look to chimpanzees, bonobos, and other great apes for insight into human ancestral behavior.

Since an organism's adaptations were suited to its ancestral environment, a new and different environment can create a mismatch. Because humans are mostly adapted to Pleistocene environments, psychological mechanisms sometimes exhibit "mismatches" to the modern environment. One example is the fact that although about 10,000 people are killed with guns in the US annually, whereas spiders and snakes kill only a handful, people nonetheless learn to fear spiders and snakes about as easily as they do a pointed gun, and more easily than an unpointed gun, rabbits or flowers. A potential explanation is that spiders and snakes were a threat to human ancestors throughout the Pleistocene, whereas guns (and rabbits and flowers) were not. There is thus a mismatch between humans' evolved fear-learning psychology and the modern environment.

This mismatch also shows up in the phenomena of the supernormal stimulus, a stimulus that elicits a response more strongly than the stimulus for which the response evolved. The term was coined by Niko Tinbergen to refer to non-human animal behavior, but psychologist Deirdre Barrett said that supernormal stimulation governs the behavior of humans as powerfully as that of other animals. She explained junk food as an exaggerated stimulus to cravings for salt, sugar, and fats, and she says that television is an exaggeration of social cues of laughter, smiling faces and attention-grabbing action. Magazine centerfolds and double cheeseburgers pull instincts intended for an environment of evolutionary adaptedness where breast development was a sign of health, youth and fertility in a prospective mate, and fat was a rare and vital nutrient. The psychologist Mark van Vugt recently argued that modern organizational leadership is a mismatch. His argument is that humans are not adapted to work in large, anonymous bureaucratic structures with formal hierarchies. The human mind still responds to personalized, charismatic leadership primarily in the context of informal, egalitarian settings. Hence the dissatisfaction and alienation that many employees experience. Salaries, bonuses and other privileges exploit instincts for relative status, which attract particularly males to senior executive positions.

Evolutionary theory is heuristic in that it may generate hypotheses that might not be developed from other theoretical approaches. One of the major goals of adaptationist research is to identify which organismic traits are likely to be adaptations, and which are byproducts or random variations. As noted earlier, adaptations are expected to show evidence of complexity, functionality, and species universality, while byproducts or random variation will not. In addition, adaptations are expected to manifest as proximate mechanisms that interact with the environment in either a generally obligate or facultative fashion (see above). Evolutionary psychologists are also interested in identifying these proximate mechanisms (sometimes termed "mental mechanisms" or "psychological adaptations") and what type of information they take as input, how they process that information, and their outputs. Evolutionary developmental psychology, or "evo-devo," focuses on how adaptations may be activated at certain developmental times (e.g., losing baby teeth, adolescence, etc.) or how events during the development of an individual may alter life-history trajectories.

Evolutionary psychologists use several strategies to develop and test hypotheses about whether a psychological trait is likely to be an evolved adaptation. Buss (2011) notes that these methods include:

Evolutionary psychologists also use various sources of data for testing, including experiments, archaeological records, data from hunter-gatherer societies, observational studies, neuroscience data, self-reports and surveys, public records, and human products.
Recently, additional methods and tools have been introduced based on fictional scenarios, mathematical models, and multi-agent computer simulations.

Foundational areas of research in evolutionary psychology can be divided into broad categories of adaptive problems that arise from evolutionary theory itself: survival, mating, parenting, family and kinship, interactions with non-kin, and cultural evolution.

Problems of survival are clear targets for the evolution of physical and psychological adaptations. Major problems the ancestors of present-day humans faced included food selection and acquisition; territory selection and physical shelter; and avoiding predators and other environmental threats.

Consciousness meets George Williams' criteria of species universality, complexity, and functionality, and it is a trait that apparently increases fitness.

In his paper "Evolution of consciousness," John Eccles argues that special anatomical and physical adaptations of the mammalian cerebral cortex gave rise to consciousness. In contrast, others have argued that the recursive circuitry underwriting consciousness is much more primitive, having evolved initially in pre-mammalian species because it improves the capacity for interaction with both social "and" natural environments by providing an energy-saving "neutral" gear in an otherwise energy-expensive motor output machine. Once in place, this recursive circuitry may well have provided a basis for the subsequent development of many of the functions that consciousness facilitates in higher organisms, as outlined by Bernard J. Baars. Richard Dawkins suggested that humans evolved consciousness in order to make themselves the subjects of thought. Daniel Povinelli suggests that large, tree-climbing apes evolved consciousness to take into account one's own mass when moving safely among tree branches. Consistent with this hypothesis, Gordon Gallup found that chimpanzees and orangutans, but not little monkeys or terrestrial gorillas, demonstrated self-awareness in mirror tests.

The concept of consciousness can refer to voluntary action, awareness, or wakefulness. However, even voluntary behavior involves unconscious mechanisms. Many cognitive processes take place in the cognitive unconscious, unavailable to conscious awareness. Some behaviors are conscious when learned but then become unconscious, seemingly automatic. Learning, especially implicitly learning a skill, can take place seemingly outside of consciousness. For example, plenty of people know how to turn right when they ride a bike, but very few can accurately explain how they actually do so.

Evolutionary psychology approaches self-deception as an adaptation that can improve one's results in social exchanges.

Sleep may have evolved to conserve energy when activity would be less fruitful or more dangerous, such as at night, and especially during the winter season.

Many experts, such as Jerry Fodor, write that the purpose of perception is knowledge, but evolutionary psychologists hold that its primary purpose is to guide action. For example, they say, depth perception seems to have evolved not to help us know the distances to other objects but rather to help us move around in space. Evolutionary psychologists say that animals from fiddler crabs to humans use eyesight for collision avoidance, suggesting that vision is basically for directing action, not providing knowledge.

Building and maintaining sense organs is metabolically expensive, so these organs evolve only when they improve an organism's fitness. More than half the brain is devoted to processing sensory information, and the brain itself consumes roughly one-fourth of one's metabolic resources, so the senses must provide exceptional benefits to fitness. Perception accurately mirrors the world; animals get useful, accurate information through their senses.

Scientists who study perception and sensation have long understood the human senses as adaptations to their surrounding worlds. Depth perception consists of processing over half a dozen visual cues, each of which is based on a regularity of the physical world. Vision evolved to respond to the narrow range of electromagnetic energy that is plentiful and that does not pass through objects. Sound waves go around corners and interact with obstacles, creating a complex pattern that includes useful information about the sources of and distances to objects. Larger animals naturally make lower-pitched sounds as a consequence of their size. The range over which an animal hears, on the other hand, is determined by adaptation. Homing pigeons, for example, can hear the very low-pitched sound (infrasound) that carries great distances, even though most smaller animals detect higher-pitched sounds. Taste and smell respond to chemicals in the environment that are thought to have been significant for fitness in the environment of evolutionary adaptedness. For example, salt and sugar were apparently both valuable to the human or pre-human inhabitants of the environment of evolutionary adaptedness, so present-day humans have an intrinsic hunger for salty and sweet tastes. The sense of touch is actually many senses, including pressure, heat, cold, tickle, and pain. Pain, while unpleasant, is adaptive. An important adaptation for senses is range shifting, by which the organism becomes temporarily more or less sensitive to sensation. For example, one's eyes automatically adjust to dim or bright ambient light. Sensory abilities of different organisms often coevolve, as is the case with the hearing of echolocating bats and that of the moths that have evolved to respond to the sounds that the bats make.

Evolutionary psychologists contend that perception demonstrates the principle of modularity, with specialized mechanisms handling particular perception tasks. For example, people with damage to a particular part of the brain have the specific defect of not being able to recognize faces (prosopagnosia). Evolutionary psychology suggests that this indicates a so-called face-reading module.

In evolutionary psychology, learning is said to be accomplished through evolved capacities, specifically facultative adaptations. Facultative adaptations express themselves differently depending on input from the environment. Sometimes the input comes during development and helps shape that development. For example, migrating birds learn to orient themselves by the stars during a critical period in their maturation. Evolutionary psychologists believe that humans also learn language along an evolved program, also with critical periods. The input can also come during daily tasks, helping the organism cope with changing environmental conditions. For example, animals evolved Pavlovian conditioning in order to solve problems about causal relationships. Animals accomplish learning tasks most easily when those tasks resemble problems that they faced in their evolutionary past, such as a rat learning where to find food or water. Learning capacities sometimes demonstrate differences between the sexes. In many animal species, for example, males can solve spatial problems faster and more accurately than females, due to the effects of male hormones during development. The same might be true of humans.

Motivations direct and energize behavior, while emotions provide the affective component to motivation, positive or negative. In the early 1970s, Paul Ekman and colleagues began a line of research which suggests that many emotions are universal. He found evidence that humans share at least five basic emotions: fear, sadness, happiness, anger, and disgust. Social emotions evidently evolved to motivate social behaviors that were adaptive in the environment of evolutionary adaptedness. For example, spite seems to work against the individual but it can establish an individual's reputation as someone to be feared. Shame and pride can motivate behaviors that help one maintain one's standing in a community, and self-esteem is one's estimate of one's status.
Motivation has a neurobiological basis in the reward system of the brain. Recently, it has been suggested that reward systems may evolve in such a way that there may be an inherent or unavoidable trade-off in the motivational system for activities of short versus long duration.

Cognition refers to internal representations of the world and internal information processing. From an evolutionary psychology perspective, cognition is not "general purpose", but uses heuristics, or strategies, that generally increase the likelihood of solving problems that the ancestors of present-day humans routinely faced. For example, present-day humans are far more likely to solve logic problems that involve detecting cheating (a common problem given humans' social nature) than the same logic problem put in purely abstract terms. Since the ancestors of present-day humans did not encounter truly random events, present-day humans may be cognitively predisposed to incorrectly identify patterns in random sequences. "Gamblers' Fallacy" is one example of this. Gamblers may falsely believe that they have hit a "lucky streak" even when each outcome is actually random and independent of previous trials. Most people believe that if a fair coin has been flipped 9 times and Heads appears each time, that on the tenth flip, there is a greater than 50% chance of getting Tails. Humans find it far easier to make diagnoses or predictions using frequency data than when the same information is presented as probabilities or percentages, presumably because the ancestors of present-day humans lived in relatively small tribes (usually with fewer than 150 people) where frequency information was more readily available.

Evolutionary psychology is primarily interested in finding commonalities between people, or basic human psychological nature. From an evolutionary perspective, the fact that people have fundamental differences in personality traits initially presents something of a puzzle. (Note: The field of behavioral genetics is concerned with statistically partitioning differences between people into genetic and environmental sources of variance. However, understanding the concept of heritability can be tricky – heritability refers only to the differences between people, never the degree to which the traits of an individual are due to environmental or genetic factors, since traits are always a complex interweaving of both.)

Personality traits are conceptualized by evolutionary psychologists as due to normal variation around an optimum, due to frequency-dependent selection (behavioral polymorphisms), or as facultative adaptations. Like variability in height, some personality traits may simply reflect inter-individual variability around a general optimum. Or, personality traits may represent different genetically predisposed "behavioral morphs" – alternate behavioral strategies that depend on the frequency of competing behavioral strategies in the population. For example, if most of the population is generally trusting and gullible, the behavioral morph of being a "cheater" (or, in the extreme case, a sociopath) may be advantageous. Finally, like many other psychological adaptations, personality traits may be facultative – sensitive to typical variations in the social environment, especially during early development. For example, later-born children are more likely than firstborns to be rebellious, less conscientious and more open to new experiences, which may be advantageous to them given their particular niche in family structure. It is important to note that shared environmental influences do play a role in personality and are not always of less importance than genetic factors. However, shared environmental influences often decrease to near zero after adolescence but do not completely disappear.

According to Steven Pinker, who builds on the work by Noam Chomsky, the universal human ability to learn to talk between the ages of 1 – 4, basically without training, suggests that language acquisition is a distinctly human psychological adaptation (see, in particular, Pinker's "The Language Instinct"). Pinker and Bloom (1990) argue that language as a mental faculty shares many likenesses with the complex organs of the body which suggests that, like these organs, language has evolved as an adaptation, since this is the only known mechanism by which such complex organs can develop.

Pinker follows Chomsky in arguing that the fact that children can learn any human language with no explicit instruction suggests that language, including most of grammar, is basically innate and that it only needs to be activated by interaction. Chomsky himself does not believe language to have evolved as an adaptation, but suggests that it likely evolved as a byproduct of some other adaptation, a so-called spandrel. But Pinker and Bloom argue that the organic nature of language strongly suggests that it has an adaptational origin.

Evolutionary psychologists hold that the FOXP2 gene may well be associated with the evolution of human language. In the 1980s, psycholinguist Myrna Gopnik identified a dominant gene that causes language impairment in the KE family of Britain. This gene turned out to be a mutation of the FOXP2 gene. Humans have a unique allele of this gene, which has otherwise been closely conserved through most of mammalian evolutionary history. This unique allele seems to have first appeared between 100 and 200 thousand years ago, and it is now all but universal in humans. However, the once-popular idea that FOXP2 is a 'grammar gene' or that it triggered the emergence of language in "Homo sapiens" is now widely discredited.

Currently, several competing theories about the evolutionary origin of language coexist, none of them having achieved a general consensus. Researchers of language acquisition in primates and humans such as Michael Tomasello and Talmy Givón, argue that the innatist framework has understated the role of imitation in learning and that it is not at all necessary to posit the existence of an innate grammar module to explain human language acquisition. Tomasello argues that studies of how children and primates actually acquire communicative skills suggest that humans learn complex behavior through experience, so that instead of a module specifically dedicated to language acquisition, language is acquired by the same cognitive mechanisms that are used to acquire all other kinds of socially transmitted behavior.

On the issue of whether language is best seen as having evolved as an adaptation or as a spandrel, evolutionary biologist W. Tecumseh Fitch, following Stephen J. Gould, argues that it is unwarranted to assume that every aspect of language is an adaptation, or that language as a whole is an adaptation. He criticizes some strands of evolutionary psychology for suggesting a pan-adaptionist view of evolution, and dismisses Pinker and Bloom's question of whether "Language has evolved as an adaptation" as being misleading. He argues instead that from a biological viewpoint the evolutionary origins of language is best conceptualized as being the probable result of a convergence of many separate adaptations into a complex system. A similar argument is made by Terrence Deacon who in "The Symbolic Species" argues that the different features of language have co-evolved with the evolution of the mind and that the ability to use symbolic communication is integrated in all other cognitive processes.

If the theory that language could have evolved as a single adaptation is accepted, the question becomes which of its many functions has been the basis of adaptation. Several evolutionary hypotheses have been posited: that language evolved for the purpose of social grooming, that it evolved as a way to show mating potential or that it evolved to form social contracts. Evolutionary psychologists recognize that these theories are all speculative and that much more evidence is required to understand how language might have been selectively adapted.

Given that sexual reproduction is the means by which genes are propagated into future generations, sexual selection plays a large role in human evolution. Human mating, then, is of interest to evolutionary psychologists who aim to investigate evolved mechanisms to attract and secure mates. Several lines of research have stemmed from this interest, such as studies of mate selection mate poaching, mate retention, mating preferences and conflict between the sexes.

In 1972 Robert Trivers published an influential paper on sex differences that is now referred to as parental investment theory. The size differences of gametes (anisogamy) is the fundamental, defining difference between males (small gametes – sperm) and females (large gametes – ova). Trivers noted that anisogamy typically results in different levels of parental investment between the sexes, with females initially investing more. Trivers proposed that this difference in parental investment leads to the sexual selection of different reproductive strategies between the sexes and to sexual conflict. For example, he suggested that the sex that invests less in offspring will generally compete for access to the higher-investing sex to increase their inclusive fitness. Trivers posited that differential parental investment led to the evolution of sexual dimorphisms in mate choice, intra- and inter- sexual reproductive competition, and courtship displays. In mammals, including humans, females make a much larger parental investment than males (i.e. gestation followed by childbirth and lactation). Parental investment theory is a branch of life history theory.

Buss and Schmitt's (1993) "Sexual Strategies Theory" proposed that, due to differential parental investment, humans have evolved sexually dimorphic adaptations related to "sexual accessibility, fertility assessment, commitment seeking and avoidance, immediate and enduring resource procurement, paternity certainty, assessment of mate value, and parental investment." Their "Strategic Interference Theory" suggested that conflict between the sexes occurs when the preferred reproductive strategies of one sex interfere with those of the other sex, resulting in the activation of emotional responses such as anger or jealousy.

Women are generally more selective when choosing mates, especially under long-term mating conditions. However, under some circumstances, short term mating can provide benefits to women as well, such as fertility insurance, trading up to better genes, reducing the risk of inbreeding, and insurance protection of her offspring.

Due to male paternity uncertainty, sex differences have been found in the domains of sexual jealousy. Females generally react more adversely to emotional infidelity and males will react more to sexual infidelity. This particular pattern is predicted because the costs involved in mating for each sex are distinct. Women, on average, should prefer a mate who can offer resources (e.g., financial, commitment), thus, a woman risks losing such resources with a mate who commits emotional infidelity. Men, on the other hand, are never certain of the genetic paternity of their children because they do not bear the offspring themselves. This suggests that for men sexual infidelity would generally be more aversive than emotional infidelity because investing resources in another man's offspring does not lead to the propagation of their own genes.

Another interesting line of research is that which examines women's mate preferences across the ovulatory cycle. The theoretical underpinning of this research is that ancestral women would have evolved mechanisms to select mates with certain traits depending on their hormonal status. Known as the ovulatory shift hypothesis, the theory posits that, during the ovulatory phase of a woman's cycle (approximately days 10–15 of a woman's cycle), a woman who mated with a male with high genetic quality would have been more likely, on average, to produce and bear a healthy offspring than a woman who mated with a male with low genetic quality. These putative preferences are predicted to be especially apparent for short-term mating domains because a potential male mate would only be offering genes to a potential offspring. This hypothesis allows researchers to examine whether women select mates who have characteristics that indicate high genetic quality during the high fertility phase of their ovulatory cycles. Indeed, studies have shown that women's preferences vary across the ovulatory cycle. In particular, Haselton and Miller (2006) showed that highly fertile women prefer creative but poor men as short-term mates. Creativity may be a proxy for good genes. Research by Gangestad et al. (2004) indicates that highly fertile women prefer men who display social presence and intrasexual competition; these traits may act as cues that would help women predict which men may have, or would be able to acquire, resources.

Reproduction is always costly for women, and can also be for men. Individuals are limited in the degree to which they can devote time and resources to producing and raising their young, and such expenditure may also be detrimental to their future condition, survival and further reproductive output.
Parental investment is any parental expenditure (time, energy etc.) that benefits one offspring at a cost to parents' ability to invest in other components of fitness (Clutton-Brock 1991: 9; Trivers 1972). Components of fitness (Beatty 1992) include the well-being of existing offspring, parents' future reproduction, and inclusive fitness through aid to kin (Hamilton, 1964). Parental investment theory is a branch of life history theory.

The benefits of parental investment to the offspring are large and are associated with the effects on condition, growth, survival, and ultimately, on the reproductive success of the offspring. However, these benefits can come at the cost of the parent's ability to reproduce in the future e.g. through the increased risk of injury when defending offspring against predators, the loss of mating opportunities whilst rearing offspring, and an increase in the time to the next reproduction. Overall, parents are selected to maximize the difference between the benefits and the costs, and parental care will likely evolve when the benefits exceed the costs.

The Cinderella effect is an alleged high incidence of stepchildren being physically, emotionally or sexually abused, neglected, murdered, or otherwise mistreated at the hands of their stepparents at significantly higher rates than their genetic counterparts. It takes its name from the fairy tale character Cinderella, who in the story was cruelly mistreated by her stepmother and stepsisters. Daly and Wilson (1996) noted: "Evolutionary thinking led to the discovery of the most important risk factor for child homicide – the presence of a stepparent. Parental efforts and investments are valuable resources, and selection favors those parental psyches that allocate effort effectively to promote fitness. The adaptive problems that challenge parental decision-making include both the accurate identification of one's offspring and the allocation of one's resources among them with sensitivity to their needs and abilities to convert parental investment into fitness increments…. Stepchildren were seldom or never so valuable to one's expected fitness as one's own offspring would be, and those parental psyches that were easily parasitized by just any appealing youngster must always have incurred a selective disadvantage"(Daly & Wilson, 1996, pp. 64–65). However, they note that not all stepparents will "want" to abuse their partner's children, or that genetic parenthood is any insurance against abuse. They see step parental care as primarily "mating effort" towards the genetic parent.

Inclusive fitness is the sum of an organism's classical fitness (how many of its own offspring it produces and supports) and the number of equivalents of its own offspring it can add to the population by supporting others. The first component is called classical fitness by Hamilton (1964).

From the gene's point of view, evolutionary success ultimately depends on leaving behind the maximum number of copies of itself in the population. Until 1964, it was generally believed that genes only achieved this by causing the individual to leave the maximum number of viable offspring. However, in 1964 W. D. Hamilton proved mathematically that, because close relatives of an organism share some identical genes, a gene can also increase its evolutionary success by promoting the reproduction and survival of these related or otherwise similar individuals. Hamilton concluded that this leads natural selection to favor organisms that would behave in ways that maximize their inclusive fitness. It is also true that natural selection favors behavior that maximizes personal fitness.

Hamilton's rule describes mathematically whether or not a gene for altruistic behavior will spread in a population:
where

The concept serves to explain how natural selection can perpetuate altruism. If there is an "altruism gene" (or complex of genes) that influences an organism's behavior to be helpful and protective of relatives and their offspring, this behavior also increases the proportion of the altruism gene in the population, because relatives are likely to share genes with the altruist due to common descent. Altruists may also have some way to recognize altruistic behavior in unrelated individuals and be inclined to support them. As Dawkins points out in "The Selfish Gene" (Chapter 6) and "The Extended Phenotype", this must be distinguished from the green-beard effect.

Although it is generally true that humans tend to be more altruistic toward their kin than toward non-kin, the relevant proximate mechanisms that mediate this cooperation have been debated (see kin recognition), with some arguing that kin status is determined primarily via social and cultural factors (such as co-residence, maternal association of sibs, etc.), while others have argued that kin recognition can also be mediated by biological factors such as facial resemblance and immunogenetic similarity of the major histocompatibility complex (MHC). For a discussion of the interaction of these social and biological kin recognition factors see Lieberman, Tooby, and Cosmides (2007) (PDF).

Whatever the proximate mechanisms of kin recognition there is substantial evidence that humans act generally more altruistically to close genetic kin compared to genetic non-kin.

Although interactions with non-kin are generally less altruistic compared to those with kin, cooperation can be maintained with non-kin via mutually beneficial reciprocity as was proposed by Robert Trivers. If there are repeated encounters between the same two players in an evolutionary game in which each of them can choose either to "cooperate" or "defect", then a strategy of mutual cooperation may be favored even if it pays each player, in the short term, to defect when the other cooperates. Direct reciprocity can lead to the evolution of cooperation only if the probability, w, of another encounter between the same two individuals exceeds the cost-to-benefit ratio of the altruistic act:

Reciprocity can also be indirect if information about previous interactions is shared. Reputation allows evolution of cooperation by indirect reciprocity. Natural selection favors strategies that base the decision to help on the reputation of the recipient: studies show that people who are more helpful are more likely to receive help. The calculations of indirect reciprocity are complicated and only a tiny fraction of this universe has been uncovered, but again a simple rule has emerged. Indirect reciprocity can only promote cooperation if the probability, q, of knowing someone's reputation exceeds the cost-to-benefit ratio of the altruistic act:

One important problem with this explanation is that individuals may be able to evolve the capacity to obscure their reputation, reducing the probability, q, that it will be known.

Trivers argues that friendship and various social emotions evolved in order to manage reciprocity. Liking and disliking, he says, evolved to help present-day humans' ancestors form coalitions with others who reciprocated and to exclude those who did not reciprocate. Moral indignation may have evolved to prevent one's altruism from being exploited by cheaters, and gratitude may have motivated present-day humans' ancestors to reciprocate appropriately after benefiting from others' altruism. Likewise, present-day humans feel guilty when they fail to reciprocate. These social motivations match what evolutionary psychologists expect to see in adaptations that evolved to maximize the benefits and minimize the drawbacks of reciprocity.

Evolutionary psychologists say that humans have psychological adaptations that evolved specifically to help us identify nonreciprocators, commonly referred to as "cheaters." In 1993, Robert Frank and his associates found that participants in a prisoner's dilemma scenario were often able to predict whether their partners would "cheat", based on a half-hour of unstructured social interaction. In a 1996 experiment, for example, Linda Mealey and her colleagues found that people were better at remembering the faces of people when those faces were associated with stories about those individuals cheating (such as embezzling money from a church).

Humans may have an evolved set of psychological adaptations that predispose them to be more cooperative than otherwise would be expected with members of their tribal in-group, and, more nasty to members of tribal out groups. These adaptations may have been a consequence of tribal warfare. Humans may also have predispositions for "altruistic punishment" – to punish in-group members who violate in-group rules, even when this altruistic behavior cannot be justified in terms of helping those you are related to (kin selection), cooperating with those who you will interact with again (direct reciprocity), or cooperating to better your reputation with others (indirect reciprocity).

Though evolutionary psychology has traditionally focused on individual-level behaviors, determined by species-typical psychological adaptations, considerable work has been done on how these adaptations shape and, ultimately govern, culture (Tooby and Cosmides, 1989). Tooby and Cosmides (1989) argued that the mind consists of many domain-specific psychological adaptations, some of which may constrain what cultural material is learned or taught. As opposed to a domain-general cultural acquisition program, where an individual passively receives culturally-transmitted material from the group, Tooby and Cosmides (1989), among others, argue that: "the psyche evolved to generate adaptive rather than repetitive behavior, and hence critically analyzes the behavior of those surrounding it in highly structured and patterned ways, to be used as a rich (but by no means the only) source of information out of which to construct a 'private culture' or individually tailored adaptive system; in consequence, this system may or may not mirror the behavior of others in any given respect." (Tooby and Cosmides 1989).

Biological explanations of human culture also brought criticism to evolutionary psychology: Evolutionary psychologists see the human psyche and physiology as a genetic product and assume that genes contain the information for the development and control of the organism and that this information is transmitted from one generation to the next via genes. Evolutionary psychologists thereby see physical and psychological characteristics of humans as genetically programmed. Even then, when evolutionary psychologists acknowledge the influence of the environment on human development, they understand the environment only as an activator or trigger for the programmed developmental instructions encoded in genes. Evolutionary psychologists, for example, believe that the human brain is made up of innate modules, each of which is specialised only for very specific tasks, e. g. an anxiety module. According to evolutionary psychologists, these modules are given before the organism actually develops and are then activated by some environmental event. Critics object that this view is reductionist and that cognitive specialisation only comes about through the interaction of humans with their real environment, rather than the environment of distant ancestors. Interdisciplinary approaches are increasingly striving to mediate between these opposing points of view and to highlight that biological and cultural causes need not be antithetical in explaining human behaviour and even complex cultural achievements.

According to Paul Baltes, the benefits granted by evolutionary selection decrease with age. Natural selection has not eliminated many harmful conditions and nonadaptive characteristics that appear among older adults, such as Alzheimer disease. If it were a disease that killed 20-year-olds instead of 70-year-olds this may have been a disease that natural selection could have eliminated ages ago. Thus, unaided by evolutionary pressures against nonadaptive conditions, modern humans suffer the aches, pains, and infirmities of aging and as the benefits of evolutionary selection decrease with age, the need for modern technological mediums against non-adaptive conditions increases.

As humans are a highly social species, there are many adaptive problems associated with navigating the social world (e.g., maintaining allies, managing status hierarchies, interacting with outgroup members, coordinating social activities, collective decision-making). Researchers in the emerging field of evolutionary social psychology have made many discoveries pertaining to topics traditionally studied by social psychologists, including person perception, social cognition, attitudes, altruism, emotions, group dynamics, leadership, motivation, prejudice, intergroup relations, and cross-cultural differences.

When endeavouring to solve a problem humans at an early age show determination while chimpanzees have no comparable facial expression. Researchers suspect the human determined expression evolved because when a human is determinedly working on a problem other people will frequently help.

Adaptationist hypotheses regarding the etiology of psychological disorders are often based on analogies between physiological and psychological dysfunctions, as noted in the table below. Prominent theorists and evolutionary psychiatrists include Michael T. McGuire, Anthony Stevens, and Randolph M. Nesse. They, and others, suggest that mental disorders are due to the interactive effects of both nature and nurture, and often have multiple contributing causes.

Evolutionary psychologists have suggested that schizophrenia and bipolar disorder may reflect a side-effect of genes with fitness benefits, such as increased creativity. (Some individuals with bipolar disorder are especially creative during their manic phases and the close relatives of people with schizophrenia have been found to be more likely to have creative professions.) A 1994 report by the American Psychiatry Association found that people with schizophrenia at roughly the same rate in Western and non-Western cultures, and in industrialized and pastoral societies, suggesting that schizophrenia is not a disease of civilization nor an arbitrary social invention. Sociopathy may represent an evolutionarily stable strategy, by which a small number of people who cheat on social contracts benefit in a society consisting mostly of non-sociopaths. Mild depression may be an adaptive response to withdraw from, and re-evaluate, situations that have led to disadvantageous outcomes (the "analytical rumination hypothesis") (see Evolutionary approaches to depression).

Some of these speculations have yet to be developed into fully testable hypotheses, and a great deal of research is required to confirm their validity.

Evolutionary psychology has been applied to explain criminal or otherwise immoral behavior as being adaptive or related to adaptive behaviors. Males are generally more aggressive than females, who are more selective of their partners because of the far greater effort they have to contribute to pregnancy and child-rearing. Males being more aggressive is hypothesized to stem from the more intense reproductive competition faced by them. Males of low status may be especially vulnerable to being childless. It may have been evolutionary advantageous to engage in highly risky and violently aggressive behavior to increase their status and therefore reproductive success. This may explain why males are generally involved in more crimes, and why low status and being unmarried are associated with criminality. Furthermore, competition over females is argued to have been particularly intensive in late adolescence and young adulthood, which is theorized to explain why crime rates are particularly high during this period. Some sociologists have underlined differential exposure to androgens as the cause of these behaviors, notably Lee Ellis in his evolutionary neuroandrogenic (ENA) theory.

Many conflicts that result in harm and death involve status, reputation, and seemingly trivial insults. Steven Pinker in his book "The Better Angels of Our Nature" argues that in non-state societies without a police it was very important to have a credible deterrence against aggression. Therefore, it was important to be perceived as having a credible reputation for retaliation, resulting in humans developing instincts for revenge as well as for protecting reputation ("honor"). Pinker argues that the development of the state and the police have dramatically reduced the level of violence compared to the ancestral environment. Whenever the state breaks down, which can be very locally such as in poor areas of a city, humans again organize in groups for protection and aggression and concepts such as violent revenge and protecting honor again become extremely important.

Rape is theorized to be a reproductive strategy that facilitates the propagation of the rapist's progeny. Such a strategy may be adopted by men who otherwise are unlikely to be appealing to women and therefore cannot form legitimate relationships, or by high-status men on socially vulnerable women who are unlikely to retaliate to increase their reproductive success even further. The sociobiological theories of rape are highly controversial, as traditional theories typically do not consider rape to be a behavioral adaptation, and objections to this theory are made on ethical, religious, political, as well as scientific grounds.

Adaptationist perspectives on religious belief suggest that, like all behavior, religious behaviors are a product of the human brain. As with all other organ functions, cognition's functional structure has been argued to have a genetic foundation, and is therefore subject to the effects of natural selection and sexual selection. Like other organs and tissues, this functional structure should be universally shared amongst humans and should have solved important problems of survival and reproduction in ancestral environments. However, evolutionary psychologists remain divided on whether religious belief is more likely a consequence of evolved psychological adaptations, or a byproduct of other cognitive adaptations.

Coalitional psychology is an approach to explain political behaviors between different coalitions and the conditionality of these behaviors in evolutionary psychological perspective. This approach assumes that since human beings appeared on the earth, they have evolved to live in groups instead of living as individuals to achieve benefits such as more mating opportunities and increased status. Human beings thus naturally think and act in a way that manages and negotiates group dynamics.

Coalitional psychology offers falsifiable ex ante prediction by positing five hypotheses on how these psychological adaptations operate:

Critics of evolutionary psychology accuse it of promoting genetic determinism, pan-adaptationism (the idea that all behaviors and anatomical features are adaptations), unfalsifiable hypotheses, distal or ultimate explanations of behavior when proximate explanations are superior, and malevolent political or moral ideas.

Critics have argued that evolutionary psychology might be used to justify existing social hierarchies and reactionary policies. It has also been suggested by critics that evolutionary psychologists' theories and interpretations of empirical data rely heavily on ideological assumptions about race and gender.

In response to such criticism, evolutionary psychologists often caution against committing the naturalistic fallacy – the assumption that "what is natural" is necessarily a moral good. However, their caution against committing the naturalistic fallacy has been criticized as means to stifle legitimate ethical discussions.

Some criticisms of evolutionary psychology point at contradictions between different aspects of adaptive scenarios posited by evolutionary psychology. One example is the evolutionary psychology model of extended social groups selecting for modern human brains, a contradiction being that the synaptic function of modern human brains require high amounts of many specific essential nutrients so that such a transition to higher requirements of the same essential nutrients being shared by all individuals in a population would decrease the possibility of forming large groups due to bottleneck foods with rare essential nutrients capping group sizes. It is mentioned that some insects have societies with different ranks for each individual and that monkeys remain socially functioning after the removal of most of the brain as additional arguments against big brains promoting social networking. The model of males as both providers and protectors is criticized for the impossibility of being in two places at once, the male cannot both protect his family at home and be out hunting at the same time. In the case of the claim that a provider male could buy protection service for his family from other males by bartering food that he had hunted, critics point at the fact that the most valuable food (the food that contained the rarest essential nutrients) would be different in different ecologies and as such vegetable in some geographical areas and animal in others, making it impossible for hunting styles relying on physical strength or risk-taking to be universally of similar value in bartered food and instead of making it inevitable that in some parts of Africa, food gathered with no need for major physical strength would be the most valuable to barter for protection. A contradiction between evolutionary psychology's claim of men needing to be more sexually visual than women for fast speed of assessing women's fertility than women needed to be able to assess the male's genes and its claim of male sexual jealousy guarding against infidelity is also pointed at, as it would be pointless for a male to be fast to assess female fertility if he needed to assess the risk of there being a jealous male mate and in that case his chances of defeating him before mating anyway (pointlessness of assessing one necessary condition faster than another necessary condition can possibly be assessed).

Evolutionary psychology has been entangled in the larger philosophical and social science controversies related to the debate on nature versus nurture. Evolutionary psychologists typically contrast evolutionary psychology with what they call the standard social science model (SSSM). They characterize the SSSM as the "blank slate", "relativist", "social constructionist", and "cultural determinist" perspective that they say dominated the social sciences throughout the 20th century and assumed that the mind was shaped almost entirely by culture.

Critics have argued that evolutionary psychologists created a false dichotomy between their own view and the caricature of the SSSM. Other critics regard the SSSM as a rhetorical device or a straw man and suggest that the scientists whom evolutionary psychologists associate with the SSSM did not believe that the mind was a blank state devoid of any natural predispositions.

Some critics view evolutionary psychology as a form of genetic reductionism and genetic determinism, a common critique being that evolutionary psychology does not address the complexity of individual development and experience and fails to explain the influence of genes on behavior in individual cases. Evolutionary psychologists respond that they are working within a nature-nurture interactionist framework that acknowledges that many psychological adaptations are facultative (sensitive to environmental variations during individual development). The discipline is generally not focused on proximate analyses of behavior, but rather its focus is on the study of distal/ultimate causality (the evolution of psychological adaptations). The field of behavioral genetics is focused on the study of the proximate influence of genes on behavior.

A frequent critique of the discipline is that the hypotheses of evolutionary psychology are frequently arbitrary and difficult or impossible to adequately test, thus questioning its status as an actual scientific discipline, for example because many current traits probably evolved to serve different functions than they do now. Thus because there are a potentially infinite number of alternative explanations for why a trait evolved, critics contend that it is impossible to determine the exact explanation. While evolutionary psychology hypotheses are difficult to test, evolutionary psychologists assert that it is not impossible. Part of the critique of the scientific base of evolutionary psychology includes a critique of the concept of the Environment of Evolutionary Adaptation (EEA). Some critics have argued that researchers know so little about the environment in which "Homo sapiens" evolved that explaining specific traits as an adaption to that environment becomes highly speculative. Evolutionary psychologists respond that they do know many things about this environment, including the facts that present day humans' ancestors were hunter-gatherers, that they generally lived in small tribes, etc. Edward Hagen argues that the human past environments were not radically different in the same sense as the Carboniferous or Jurassic periods and that the animal and plant taxa of the era were similar to those of the modern world, as was the geology and ecology. Hagen argues that few would deny that other organs evolved in the EEA (for example, lungs evolving in an oxygen rich atmosphere) yet critics question whether or not the brain's EEA is truly knowable, which he argues constitutes selective scepticism. Hagen also argues that most evolutionary psychology research is based on the fact that females can get pregnant and males cannot, which Hagen observes was also true in the EEA.

John Alcock describes this as the "No Time Machine Argument", as critics are arguing that since it is not possible to travel back in time to the EEA, then it cannot be determined what was going on there and thus what was adaptive. Alcock argues that present-day evidence allows researchers to be reasonably confident about the conditions of the EEA and that the fact that so many human behaviours are adaptive in the "current" environment is evidence that the ancestral environment of humans had much in common with the present one, as these behaviours would have evolved in the ancestral environment. Thus Alcock concludes that researchers can make predictions on the adaptive value of traits. Similarly, Dominic Murphy argues that alternative explanations cannot just be forwarded but instead need their own evidence and predictions - if one explanation makes predictions that the others cannot, it is reasonable to have confidence in that explanation. In addition, Murphy argues that other historical sciences also make predictions about modern phenomena to come up with explanations about past phenomena, for example, cosmologists look for evidence for what we would expect to see in the modern-day if the Big Bang was true, while geologists make predictions about modern phenomena to determine if an asteroid wiped out the dinosaurs. Murphy argues that if other historical disciplines can conduct tests without a time machine, then the onus is on the critics to show why evolutionary psychology is untestable if other historical disciplines are not, as "methods should be judged across the board, not singled out for ridicule in one context."

Evolutionary psychologists generally presume that, like the body, the mind is made up of many evolved modular adaptations, although there is some disagreement within the discipline regarding the degree of general plasticity, or "generality," of some modules. It has been suggested that modularity evolves because, compared to non-modular networks, it would have conferred an advantage in terms of fitness and because connection costs are lower.

In contrast, some academics argue that it is unnecessary to posit the existence of highly domain specific modules, and, suggest that the neural anatomy of the brain supports a model based on more domain general faculties and processes. Moreover, empirical support for the domain-specific theory stems almost entirely from performance on variations of the Wason selection task which is extremely limited in scope as it only tests one subtype of deductive reasoning.

Psychologist Cecilia Heyes has argued that the picture presented by some evolutionary psychology of the human mind as a collection of cognitive instinctsorgans of thought shaped by genetic evolution over very long time periodsdoes not fit research results. She posits instead that humans have cognitive gadgets"special-purpose organs of thought" built in the course of development through social interaction. Similar criticisms are articulated by Subrena E. Smith of the University of New Hampshire.

Evolutionary psychologists have addressed many of their critics (e.g. in books by Segerstråle (2000), Barkow (2005), and Alcock (2001)). Among their rebuttals are that some criticisms are straw men, or are based on an incorrect nature versus nurture dichotomy or on basic misunderstandings of the discipline. 

Robert Kurzban suggested that "...critics of the field, when they err, are not slightly missing the mark. Their confusion is deep and profound. It's not like they are marksmen who can't quite hit the center of the target; they're holding the gun backwards." Many have written specifically to correct basic misconceptions.





Languages of Europe

There are over 250 languages indigenous to Europe, and most belong to the Indo-European language family. Out of a total European population of 744 million as of 2018, some 94% are native speakers of an Indo-European language. The three largest phyla of the Indo-European language family in Europe are Romance, Germanic, and Slavic; they have more than 200 million speakers each, and together account for close to 90% of Europeans. 

Smaller phyla of Indo-European found in Europe include Hellenic (Greek, 13 million), Baltic ( 7 million), Albanian ( 5 million), Celtic ( 4 million), and Armenian ( 4 million). Indo-Aryan, though a large subfamily of Indo-European, has a relatively small number of languages in Europe, and a small number of speakers (Romani, 1.5 million). However, a number of Indo-Aryan languages not native to Europe are spoken in Europe today.

Of the approximately 45 million Europeans speaking non-Indo-European languages, most speak languages within either the Uralic or Turkic families. Still smaller groups — such as Basque (language isolate), Semitic languages (Maltese, 0.5 million), and various languages of the Caucasus — account for less than 1% of the European population among them. Immigration has added sizeable communities of speakers of African and Asian languages, amounting to about 4% of the population, with Arabic being the most widely spoken of them.

Five languages have more than 50 million native speakers in Europe: Russian, English, French, Italian, and German. Russian is the most-spoken native language in Europe, and English has the largest number of speakers in total, including some 200 million speakers of English as a second or foreign language. (See English language in Europe.)

The Indo-European language family is descended from Proto-Indo-European, which is believed to have been spoken thousands of years ago. Early speakers of Indo-European daughter languages most likely expanded into Europe with the incipient Bronze Age, around 4,000 years ago (Bell-Beaker culture).

The Germanic languages make up the predominant language family in Western, Northern and Central Europe. It is estimated that over 500 million Europeans are speakers of Germanic languages, the largest groups being German ( 95 million), English ( 400 million), Dutch ( 24 million), Swedish ( 10 million), Danish ( 6 million), Norwegian ( 5 million) and Limburgish (c. 1.3 million).

There are two extant major sub-divisions: "West Germanic" and "North Germanic". A third group, East Germanic, is now extinct; the only known surviving East Germanic texts are written in the Gothic language. West Germanic is divided into Anglo-Frisian (including English), Low German, Low Franconian (including Dutch) and High German (including Standard German).

The Anglo-Frisian language family is now mostly represented by English (Anglic), descended from the Old English language spoken by the Anglo-Saxons:

The Frisian languages are spoken by about 400,000 () Frisians, who live on the southern coast of the North Sea in the Netherlands and Germany. These languages include West Frisian, East Frisian (of which the only surviving dialect is Saterlandic) and North Frisian.

Dutch is spoken throughout the Netherlands, the northern half of Belgium, as well as the Nord-Pas de Calais region of France. The traditional dialects of the Lower Rhine region of Germany are linguistically more closely related to Dutch than to modern German. In Belgian and French contexts, Dutch is sometimes referred to as Flemish. Dutch dialects are numerous and varied.

German is spoken throughout Germany, Austria, Liechtenstein, much of Switzerland (including the northeast areas bordering on Germany and Austria), northern Italy (South Tyrol), Luxembourg, the East Cantons of Belgium and the Alsace and Lorraine regions of France.

There are several groups of German dialects:


Low German is spoken in various regions throughout Northern Germany and the northern and eastern parts of the Netherlands. It is an official language in Germany. It may be separated into West Low German and East Low German.

The "North Germanic languages" are spoken in Nordic countries and include 
Swedish (Sweden and parts of Finland), 
Danish (Denmark), 
Norwegian (Norway), 
Icelandic (Iceland),
Faroese (Faroe Islands), 
and Elfdalian (in a small part of central Sweden).

English has a long history of contact with Scandinavian languages, given the immigration of Scandinavians early in the history of Britain, and shares various features with the Scandinavian languages. Even so, especially Dutch and Swedish, but also Danish and Norwegian, have strong vocabulary connections to the German language.

Limburgish (also called Limburgan, Limburgian, or Limburgic) Is a West Germanic language spoken in the province of Limburg in the Netherlands, Belgium and neighboring regions of Germany. It is distinct from German and Dutch, but originates from areas near where both are spoken.

Roughly 215 million Europeans (primarily in Southern and Western Europe) are native speakers of Romance languages, the largest groups including:

French ( 72 million),
Italian ( 65 million),
Spanish ( 40 million), 
Romanian ( 24 million),
Portuguese ( 10 million),
Catalan ( 7 million),
Sicilian ( 5 million, also subsumed under Italian), 
Venetian ( 4 million),
Galician ( 2 million),
Sardinian ( 1 million),
Occitan ( 500,000), besides numerous smaller communities.

The Romance languages evolved from varieties of Vulgar Latin spoken in the various parts of the Roman Empire in Late Antiquity. Latin was itself part of the (otherwise extinct) Italic branch of Indo-European.
Romance languages are divided phylogenetically into "Italo-Western", "Eastern Romance" (including Romanian) and "Sardinian". The Romance-speaking area of Europe is occasionally referred to as "Latin Europe".

Italo-Western can be further broken down into the "Italo-Dalmatian languages" (sometimes grouped with Eastern Romance), including the Tuscan-derived Italian and numerous local Romance languages in Italy as well as Dalmatian, and the "Western Romance languages". The Western Romance languages in turn separate into the Gallo-Romance languages, including Langues d'oïl such as French, the Francoprovencalic languages Arpitan and Faetar, the Rhaeto-Romance languages, and the Gallo-Italic languages; the Occitano-Romance languages, grouped with either Gallo-Romance or East Iberian, including Occitanic languages such as Occitan and Gardiol, and Catalan; Aragonese, grouped in with either Occitano-Romance or West Iberian, and finally the West Iberian languages, including the Astur-Leonese languages, the Galician-Portuguese languages, and the Castilian languages.

Slavic languages are spoken in large areas of Southern, Central and Eastern Europe. An estimated 315 million people speak of Slavic languages, the largest groups being 
Russian ( 110 million in European Russia and adjacent parts of Eastern Europe, Russian forming the largest linguistic community in Europe),
Polish ( 40.6 million),
Ukrainian ( 33 million), 
Serbo-Croatian ( 21 million),
Czech ( 12 million),
Bulgarian ( 7.7 million), 
Slovak ( 5 million)
Belarusian (c. 3.7 million) and Slovene ( 2.3 million)
and Macedonian ( 2 million).

Phylogenetically, Slavic is divided into three subgroups:





Uralic language family is native to northern Eurasia.
Finnic languages include Finnish ( 5 million) and Estonian ( 1 million), as well as smaller languages such as Kven ( 8,000). Other languages of the Finno-Permic branch of the family include e.g. Mari (c. 400,000), and the Sami languages ( 30,000).

The Ugric branch of the language family is represented in Europe by the Hungarian language ( 13 million), historically introduced with the Hungarian conquest of the Carpathian Basin of the 9th century.
The Samoyedic Nenets language is spoken in Nenets Autonomous Okrug of Russia, located in the far northeastern corner of Europe (as delimited by the Ural Mountains).


Several dozen manual languages exist across Europe, with the most widespread sign language family being the Francosign languages, with its languages found in countries from Iberia to the Balkans and the Baltics. Accurate historical information of sign and tactile languages is difficult to come by, with folk histories noting the existence signing communities across Europe hundreds of years ago. British Sign Language (BSL) and French Sign Language (LSF) are probably the oldest confirmed, continuously used sign languages. Alongside German Sign Language (DGS) according to Ethnologue, these three have the most numbers of signers, though very few institutions take appropriate statistics on contemporary signing populations, making legitimate data hard to find.

Notably, few European sign languages have overt connections with the local majority/oral languages, aside from standard language contact and borrowing, meaning grammatically the sign languages and the oral languages of Europe are quite distinct from one another. Due to (visual/aural) modality differences, most sign languages are named for the larger ethnic nation in which they are spoken, plus the words "sign language", rendering what is spoken across much of France, Wallonia and Romandy as French Sign Language or LSF for: "langue des signes française".

Recognition of non-oral languages varies widely from region to region. Some countries afford legal recognition, even to official on a state level, whereas others continue to be actively suppressed.

Though "there is a widespread belief—among both Deaf people and sign language linguists—that there "are" sign language families," the actual relationship between sign languages is difficult to ascertain. Concepts and methods used in historical linguistics to describe language families for written and spoken languages are not easily mapped onto signed languages. Some of the current understandings of sign language relationships, however, provide some reasonable estimates about potential sign language families:


In the Middle Ages the two most important defining elements of Europe were "Christianitas" and "Latinitas".

The earliest dictionaries were glossaries: more or less structured lists of lexical pairs (in alphabetical order or according to conceptual fields). The Latin-German (Latin-Bavarian) "Abrogans" was among the first. A new wave of lexicography can be seen from the late 15th century onwards (after the introduction of the printing press, with the growing interest in standardisation of languages).

The concept of the nation state began to emerge in the early modern period. Nations adopted particular dialects as their national language. This, together with improved communications, led to official efforts to standardise the national language, and a number of language academies were established: 1582 "Accademia della Crusca" in Florence, 1617 "Fruchtbringende Gesellschaft" in Weimar, 1635 "Académie française" in Paris, 1713 "Real Academia Española" in Madrid. Language became increasingly linked to nation as opposed to culture, and was also used to promote religious and ethnic identity: e.g. different Bible translations in the same language for Catholics and Protestants.

The first languages whose standardisation was promoted included Italian ("questione della lingua": Modern Tuscan/Florentine vs. Old Tuscan/Florentine vs. Venetian → Modern Florentine + archaic Tuscan + Upper Italian), French (the standard is based on Parisian), English (the standard is based on the London dialect) and (High) German (based on the dialects of the chancellery of Meissen in Saxony, Middle German, and the chancellery of Prague in Bohemia ("Common German")). But several other nations also began to develop a standard variety in the 16th century.

Europe has had a number of languages that were considered linguae francae over some ranges for some periods according to some historians. Typically in the rise of a national language the new language becomes a lingua franca to peoples in the range of the future nation until the consolidation and unification phases. If the nation becomes internationally influential, its language may become a lingua franca among nations that speak their own national languages. Europe has had no lingua franca ranging over its entire territory spoken by all or most of its populations during any historical period. Some linguae francae of past and present over some of its regions for some of its populations are:


Historical attitudes towards linguistic diversity are illustrated by two French laws: the Ordonnance de Villers-Cotterêts (1539), which said that every document in France should be written in French (neither in Latin nor in Occitan) and the Loi Toubon (1994), which aimed to eliminate anglicisms from official documents. States and populations within a state have often resorted to war to settle their differences. There have been attempts to prevent such hostilities: two such initiatives were promoted by the Council of Europe, founded in 1949, which affirms the right of minority language speakers to use their language fully and freely. The Council of Europe is committed to protecting linguistic diversity. Currently all European countries except France, Andorra and Turkey have signed the Framework Convention for the Protection of National Minorities, while Greece, Iceland and Luxembourg have signed it, but have not ratified it; this framework entered into force in 1998. Another European treaty, the European Charter for Regional or Minority Languages, was adopted in 1992 under the auspices of the Council of Europe: it entered into force in 1998, and while it is legally binding for 24 countries, France, Iceland, Italy, North Macedonia, Moldova and Russia have chosen to sign without ratifying the convention.

The main scripts used in Europe today are the Latin and Cyrillic.

The Greek alphabet was derived from the Phoenician alphabet, and Latin was derived from the Greek via the Old Italic alphabet. In the Early Middle Ages, Ogham was used in Ireland and runes (derived from Old Italic script) in Scandinavia. Both were replaced in general use by the Latin alphabet by the Late Middle Ages. The Cyrillic script was derived from the Greek with the first texts appearing around 940 AD.
Around 1900 there were mainly two typeface variants of the Latin alphabet used in Europe: Antiqua and Fraktur. Fraktur was used most for German, Estonian, Latvian, Norwegian and Danish whereas Antiqua was used for Italian, Spanish, French, Polish, Portuguese, English, Romanian, Swedish and Finnish. The Fraktur variant was banned by Hitler in 1941, having been described as "Schwabacher Jewish letters". Other scripts have historically been in use in Europe, including Phoenician, from which modern Latin letters descend, Ancient Egyptian hieroglyphs on Egyptian artefacts traded during Antiquity, various runic systems used in Northern Europe preceding Christianisation, and Arabic during the era of the Ottoman Empire.

Hungarian rovás was used by the Hungarian people in the early Middle Ages, but it was gradually replaced with the Latin-based Hungarian alphabet when Hungary became a kingdom, though it was revived in the 20th century and has certain marginal, but growing area of usage since then.

The European Union (as of 2021) had 27 member states accounting for a population of 447 million, or about 60% of the population of Europe.

The European Union has designated by agreement with the member states 24 languages as "official and working": Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish. This designation provides member states with two "entitlements": the member state may communicate with the EU in any of the designated languages, and view "EU regulations and other legislative documents" in that language.

The European Union and the Council of Europe have been collaborating in education of member populations in languages for "the promotion of plurilingualism" among EU member states. The joint document, "Common European Framework of Reference for Languages: Learning, Teaching, Assessment (CEFR)", is an educational standard defining "the competencies necessary for communication" and related knowledge for the benefit of educators in setting up educational programs. 
In a 2005 independent survey requested by the EU's Directorate-General for Education and Culture regarding the extent to which major European languages were spoken in member states. The results were published in a 2006 document, "Europeans and Their Languages", or "Eurobarometer 243". In this study, statistically relevant samples of the population in each country were asked to fill out a survey form concerning the languages that they spoke with sufficient competency "to be able to have a conversation".

The following is a table of European languages. The number of speakers as a first or second language (L1 and L2 speakers) listed are speakers in Europe only; see list of languages by number of native speakers and list of languages by total number of speakers for global estimates on numbers of speakers.

The list is intended to include any language variety with an ISO 639 code. However, it omits sign languages. Because the ISO-639-2 and ISO-639-3 codes have different definitions, this means that some communities of speakers may be listed more than once. For instance, speakers of Bavarian are listed both under "Bavarian" (ISO-639-3 code "bar") as well as under "German" (ISO-639-2 code "de").

There are various definitions of Europe, which may or may not include all or parts of Turkey, Cyprus, Armenia, Azerbaijan, and Georgia. For convenience, the languages and associated statistics for all five of these countries are grouped together on this page, as they are usually presented at a national, rather than subnational, level.

Recent (post–1945) immigration to Europe introduced substantial communities of speakers of non-European languages.

The largest such communities include Arabic speakers (see Arabs in Europe)
and Turkish speakers (beyond European Turkey and the historical sphere of influence of the Ottoman Empire, see Turks in Europe).
Armenians, Berbers, and Kurds have diaspora communities of 1–2,000,000 each. The various languages of Africa and languages of India form numerous smaller diaspora communities.




Eindhoven University of Technology

The Eindhoven University of Technology (), abbr. TU/e, is a public technical university in the Netherlands, situated at Eindhoven. In 2020–21, around 14,000 students were enrolled in its BSc and MSc programs and around 1350 students were enrolled in its PhD and PDEng programs. In 2021, the TU/e employed around 3900 people.

TU/e is the Dutch member of the EuroTech Universities Alliance, a strategic partnership of universities of science & technology in Europe: Technical University of Denmark (DTU), École Polytechnique Fédérale de Lausanne (EPFL), École Polytechnique (L’X), The Technion, Eindhoven University of Technology (TU/e), and Technical University of Munich (TUM).

The Eindhoven University of Technology was founded as the "Technische Hogeschool Eindhoven" (THE) on 23 June 1956 by the Dutch government. It was the second institute of its kind in the Netherlands, preceded only by Delft University of Technology.

Undergraduate education was given in four- or five-year programs until 2002, styled along the lines of the German system of education; graduates of these programs were granted an engineering title and allowed to prefix their name with the title "ir." (an abbreviation of ingenieur; not to be confused with graduates of technical "hogescholen", who were engineers abbreviated "ing."). Starting in 2002, following the entry into force of the Bologna Accords, the university switched to the bachelor/master structure (students graduating in 2002 were given both an old-style engineering title and a new master's title). The undergraduate programs are now split into two parts, a three-year bachelor program and a two-year master program.

On 3 January 2011, the university's strategic vision document for the period up to 2020, the "Strategic Plan 2020", was presented. This vision included establishing a University College to foster both depth, breadth, and societal relevance in engineering education; establishing a combined Graduate School to manage the graduate programs; an increase of the student body by 50 percent; a 50 percent increase in the number of annual PhDs awarded; an increase of knowledge "valorisation" (exploitation by industry and society) to a campus-wide score of 4.2; increasing the international position of the university to within the top-100 universities; and increasing the embedding of the university within the city and the Brainport region by transforming the campus into a high-grade science park with laboratories, housing facilities for 700 students and researchers and supporting facilities. The science park was one of the more costly elements of the plan.

All departments and student facilities are centered along the full length of the Groene Loper.

A number of existing buildings have been renovated and some new buildings erected. For existing buildings, the aim is to retain as much of the present materials as possible, supplemented with redeveloped portions of the existing premises and new, sustainable materials. The approach adopted for new buildings is to pursue optimal energy neutrality. There are four large projects.

The Eindhoven University of Technology is a public university of the Netherlands. As such its general structure and management is determined by the "Wet op het Hoger Onderwijs en Wetenschappelijk Onderzoek" (English: "Law on Higher Education and Scientific Research"). Between that law and the statutes of the university itself, the management of the university is organized according to the following chart:

The day-to-day running of the university is in the hands of the executive board (Dutch: "College van Bestuur"). The executive board (EB) monitors the academic departments and service organizations, plus the local activities of the Stan Ackermans Institute. The EB consists of three people, plus a secretary:


There are two bodies that supervise the Executive Board:


Most of the work at the university is done in the departments and the service organizations:


Both for the departments and the service organizations, the staff (and students) are involved with the running of the body. For that reason, both types of bodies have advisory councils which have advisory and co-decision authorities.

Over the past two decades, the TU/e has increasingly developed commercial interests and off-campus ties. These include commercial agreements and contracts directly between the university and external companies, but also interests in spinoff companies. In order to manage these kinds of contractual obligations the university started the TU/e Holding B.V. in 1997. The Holding is a limited company, dedicated to the commercial exploitation of scientific knowledge.

There university is more than just the departments, research bodies and the students. There are several ancillary activities necessary to the running of the university, activities that cross the boundaries and interests of the different departments. These activities are carried out by the universities' service organizations.

The university has the following service organizations:

Eindhoven is currently (2018) ranked between 51 and 141 in the world (the university itself provides a survey), and a top ten technical university in Europe.

In a 2003 European Commission report, TU/e was ranked as third among European research universities (after Cambridge and Oxford, at equality with TU Munich and thus making it the highest ranked Technical University in Europe), based on the impact of its scientific research.
In 2011 Academic Ranking of World Universities (ARWU) rankings, TU/e was placed at the 52-75 bucket internationally in Engineering/Technology and Computer Science ( ENG ) category and at 34th place internationally in the Computer Science subject field.

The scientific departments (or faculties; Dutch: "faculteiten") are the primary vehicles for teaching and research in the university. They employ the majority of the academic staff, are responsible for teaching and sponsor the research schools and institutions.

The departments also offer PhD programs (Dutch: "promotiefase") whereby a qualified master may earn a PhD Unlike in anglo-saxon countries these are not educational programs, however; rather, a person working towards obtaining the PhD is a research employee of the university.

The TU/e has nine departments:

The university offers honors programs aimed at both bachelor and master students. At the bachelor level it consists of intensive study within eight possible areas or tracks. At the master level it consists of personal leadership and professional development components, over and above the normal masters study.

In 1986, the university started a number of programs for a postgraduate doctorate of engineering (PDEng) together with two other Dutch technological universities (TU Delft and University of Twente). These programs are managed by the Stan Ackermans Institute on behalf of the 4TU Federation. Each program is two years in length. Ten programs are available at the TU/e:


Nationally, more than 3,500 students have earned the postgraduate PDEng degree through this program. On 13 February, Ravi Thakkar was awarded 3000th PDEng diploma at TU/e

The university hosts a number of other educational programs that are in some way related to the main educational programs. These include the teacher's program and an MBA program.


The TU/e participates in a large number of research institutes which balance in different ways between pure science and applied science research. Some of these institutes are bound strictly to the university, others combine research across different universities.

The TU/e is among the world's ten best-performing research universities in terms of research cooperation with industry in 2011 (Number 1 in 2009). Ten to 20 percent of the scientific publications of these ten universities in the period 2006–2008 were the result of partnerships with researchers in industry. As well as TU/e and Delft University of Technology, the top 10 also includes two universities in Japan (Tokyo Institute of Technology and Keio University in Tokyo), two in Sweden (CTH Chalmers University of Technology and KTH Royal Institute of Technology in Stockholm), and one each in Denmark (DTU Technical University of Denmark in Lyngby), Finland (University of Helsinki), Norway (Norwegian University of Science and Technology in Trondheim) and the USA (Rensselaer Polytechnic Institute in Troy, New York).

The admission process is similar to other universities in the Netherlands, especially other 4TU institutions. The university provides various infographics to explain the process in their website.

Some bachelors have a numerus fixus, while others do not. This may differ from year to year.

Due to an agreement, students that have graduated from another 4TU institution may qualify for direct admission.

Fees at the TU/e differ between students, according to the following table from the official website:
Students from countries of the European Economic Area (EEA) may be eligible for a grant or loan from the Dutch government.

TU/e offers a small number of graduate scholarships. Some have requirements in terms of study focus, while others are available to all students. However, in order to qualify one must have already been accepted at the university.

The TU/e plays a central role in the academic, economic and social life of Eindhoven and the surrounding region. In addition the university maintains relations with institutions far beyond that region as well and participates in national and international events (sometimes through the student body).

The TU/e is enormously important to the economy of the Eindhoven region, as well as the wider areas of BrabantStad and the Samenwerkingsverband Regio Eindhoven. It provides highly skilled labor for the local knowledge economy and is a knowledge and research partner for technology companies in the area.

The historic basis for the university's role as an economy and research motor was the interaction with Philips. The university was founded primarily to address the need of Philips for local personnel with academic levels of education in electronics, physics, chemistry and later computer science. Later that interest spread to DAF and Royal Dutch Shell (which became the primary employer for graduates of the chemistry department). There was also a synergy with these companies in that senior personnel were hired from them to form the academic staff of the university (which led to the Eindhoven joke that the university trains the engineers and Philips trains the professors).

Changing economic times and business strategies changed the relationship during the 1980s and 1990s. As Philips started moving away from the region, its importance to the region and the university decreased. A struggle for economic survival forced the university to seek closer ties with the city and region of Eindhoven in the 1989–1995 period, resulting in the creation of the Brainport initiative to draw high tech business and industry to the region. The university started expending more effort in knowledge valorisation, in incubating technology startups, in providing direct knowledge support for local technology companies. Also the academic interests of the research shifted with the times, with more effort going into energy efficiency research, green technologies, and other areas of interest driven by social relevance (the call for better technology in the medical field, for example, led to cooperation with the Catharina Hospital and the University of Maastricht medical department and finally the creation of the Biomedical Technology department).

The TU/e is host (and in some cases also commissioner) of a number of highly successful research schools, including the ESI and the DPI. These research institutes are a source of high-tech knowledge for high-tech companies in the area, such as ASML, NXP and FEI. The university also plays a large role as knowledge and personnel supplier to other companies in the High Tech Campus Eindhoven and helps incubate startups through the Eindhoven Twinning Center and The Gate. It is also a knowledge supporter of the automotive industry in the Helmond region. The valorization strategy of TU/e has already led to various spin-offs, including Lusoco, NC Biomatrix, Taylor, SMART Photonics, EFFECT Photonics and MicroAlign. This appears especially the case around integrated photonics, as the last three examples are part of the photonic chip ecosystem PhotonDelta.

In the extended region, the TU/e is part of the backbone of the Eindhoven-Leuven-Aachen triangle. This economic cooperation agreement between three cities in three countries has created one of the most innovative regions in the European Union (measured in terms of money invested in technology and knowledge economy); the agreement is based on the cooperative triangle that connects the three technical universities in those cities.

As of the summer of 2010, the TU/e is host to the Eindhoven Energy Institute (EEI). The EEI is a virtual research institute (meaning that it doesn't have any actual offices or facilities), which manages and coordinates the activities of a large number of groups and subinstitutes in the general area of sustainable and alternative energy technologies.

The scientific director of the institute is prof.dr.ir. David Smeulders. He is pro forma head of the research department, which is split into four key areas: "Built Environment" (energy usage and patterns in building, headed by prof.dr.ir. Jan Hensen from the Department of the Built Environment), "Future Fuels" (headed by prof.dr. Philip de Goey of Mechanical Engineering), "Energy Conversion" (headed by prof.dr.ir. René Janssen from Chemical Engineering) and "Fusion and Plasma" (headed by prof.dr. Niek Lopes Cardozo from Physics). The EEI also incorporates the Graduate School on Sustainable Energy, which the TU/e had already established together with the TU Munich and DTU Lyngby. Secretarial services will be provided by the Center Technology for Sustainable Development (TDO) which also already existed at the TU/e (since 1994).

Energy research at the TU/e is among the best in academic Europe (a February 2010 study by Reed Elsevier puts it second only to Imperial College London). This fact, as well as the unique attention to energy in the built-up environment, drew the attention of the European Institute of Innovation and Technology. The EEI is now a full co-location of EIT's KIC on Sustainable Energy (InnoEnergy).

The TU/e maintains active academic cooperation with sister institutions in many different countries, for example:


The TU/e also provides education to an increasing number of foreign students and graduates. According to the 2009 annual report in the academic year 2008–2009 there were 490 exchange students, 103 foreign nationals registered in a bachelor program, 430 in a master program, 158 in a professional doctorate program (79% of the total). In 2009 the university employed 37 foreign professors (15.9% of the total) and 16 foreign associate professors (12.8%). Overall, 29.5% of the university staff was non-Dutch.

In 2011/2012, the TU/e has Erasmus bilateral agreements with many universities in 30 countries across Europe in a diverse range of subjects for student exchange.

In addition to the "regular" types of sports practiced among the student body and by the staff, the TU/e collaborates with the student body in a number of "technology sporting efforts". These usually take the form of cross-department projects, which makes them multidisciplinary efforts. Some examples include:


TU Eindhoven has over 110 community bodies that members of TU may participate in. They are related to sports, culture, faith, staff, international students and hobbies, as well as university political parties, student teams, and study associations for each faculty.

Currently TU/e has various accredited student teams which address challenges in the fields of sustainability, artificial intelligence, health and mobility.





Electronegativity

Electronegativity, symbolized as "χ", is the tendency for an atom of a given chemical element to attract shared electrons (or electron density) when forming a chemical bond. An atom's electronegativity is affected by both its atomic number and the distance at which its valence electrons reside from the charged nucleus. The higher the associated electronegativity, the more an atom or a substituent group attracts electrons. Electronegativity serves as a simple way to quantitatively estimate the bond energy, and the sign and magnitude of a bond's chemical polarity, which characterizes a bond along the continuous scale from covalent to ionic bonding. The loosely defined term electropositivity is the opposite of electronegativity: it characterizes an element's tendency to donate valence electrons.

On the most basic level, electronegativity is determined by factors like the nuclear charge (the more protons an atom has, the more "pull" it will have on electrons) and the number and location of other electrons in the atomic shells (the more electrons an atom has, the farther from the nucleus the valence electrons will be, and as a result, the less positive charge they will experience—both because of their increased distance from the nucleus and because the other electrons in the lower energy core orbitals will act to shield the valence electrons from the positively charged nucleus).

The term "electronegativity" was introduced by Jöns Jacob Berzelius in 1811,
though the concept was known before that and was studied by many chemists including Avogadro.
In spite of its long history, an accurate scale of electronegativity was not developed until 1932, when Linus Pauling proposed an electronegativity scale which depends on bond energies, as a development of valence bond theory. It has been shown to correlate with a number of other chemical properties. Electronegativity cannot be directly measured and must be calculated from other atomic or molecular properties. Several methods of calculation have been proposed, and although there may be small differences in the numerical values of the electronegativity, all methods show the same periodic trends between elements.

The most commonly used method of calculation is that originally proposed by Linus Pauling. This gives a dimensionless quantity, commonly referred to as the Pauling scale ("χ"), on a relative scale running from 0.79 to 3.98 (hydrogen = 2.20). When other methods of calculation are used, it is conventional (although not obligatory) to quote the results on a scale that covers the same range of numerical values: this is known as an electronegativity in "Pauling units".

As it is usually calculated, electronegativity is not a property of an atom alone, but rather a property of an atom in a molecule. Even so, the electronegativity of an atom is strongly correlated with the first ionization energy. The electronegativity is slightly negatively correlated (for smaller electronegativity values) and rather strongly positively correlated (for most and larger electronegativity values) with the electron affinity. It is to be expected that the electronegativity of an element will vary with its chemical environment, but it is usually considered to be a transferable property, that is to say that similar values will be valid in a variety of situations.

Caesium is the least electronegative element (0.79); fluorine is the most (3.98).

Pauling first proposed the concept of electronegativity in 1932 to explain why the covalent bond between two different atoms (A–B) is stronger than the average of the A–A and the B–B bonds. According to valence bond theory, of which Pauling was a notable proponent, this "additional stabilization" of the heteronuclear bond is due to the contribution of ionic canonical forms to the bonding.

The difference in electronegativity between atoms A and B is given by:
formula_1
where the dissociation energies, "E", of the A–B, A–A and B–B bonds are expressed in electronvolts, the factor (eV) being included to ensure a dimensionless result. Hence, the difference in Pauling electronegativity between hydrogen and bromine is 0.73 (dissociation energies: H–Br, 3.79 eV; H–H, 4.52 eV; Br–Br 2.00 eV)

As only differences in electronegativity are defined, it is necessary to choose an arbitrary reference point in order to construct a scale. Hydrogen was chosen as the reference, as it forms covalent bonds with a large variety of elements: its electronegativity was fixed first at 2.1, later revised to 2.20. It is also necessary to decide which of the two elements is the more electronegative (equivalent to choosing one of the two possible signs for the square root). This is usually done using "chemical intuition": in the above example, hydrogen bromide dissolves in water to form H and Br ions, so it may be assumed that bromine is more electronegative than hydrogen. However, in principle, since the same electronegativities should be obtained for any two bonding compounds, the data are in fact overdetermined, and the signs are unique once a reference point has been fixed (usually, for H or F).

To calculate Pauling electronegativity for an element, it is necessary to have data on the dissociation energies of at least two types of covalent bonds formed by that element. A. L. Allred updated Pauling's original values in 1961 to take account of the greater availability of thermodynamic data, and it is these "revised Pauling" values of the electronegativity that are most often used.

The essential point of Pauling electronegativity is that there is an underlying, quite accurate, semi-empirical formula for dissociation energies, namely:
formula_2
or sometimes, a more accurate fit
formula_3

These are approximate equations but they hold with good accuracy. Pauling obtained the first equation by noting that a bond can be approximately represented as a quantum mechanical superposition of a covalent bond and two ionic bond-states. The covalent energy of a bond is approximate, by quantum mechanical calculations, the geometric mean of the two energies of covalent bonds of the same molecules, and there is additional energy that comes from ionic factors, i.e. polar character of the bond.

The geometric mean is approximately equal to the arithmetic mean—which is applied in the first formula above—when the energies are of a similar value, e.g., except for the highly electropositive elements, where there is a larger difference of two dissociation energies; the geometric mean is more accurate and almost always gives positive excess energy, due to ionic bonding. The square root of this excess energy, Pauling notes, is approximately additive, and hence one can introduce the electronegativity. Thus, it is these semi-empirical formulas for bond energy that underlie the concept of Pauling electronegativity.

The formulas are approximate, but this rough approximation is in fact relatively good and gives the right intuition, with the notion of the polarity of the bond and some theoretical grounding in quantum mechanics. The electronegativities are then determined to best fit the data.

In more complex compounds, there is an additional error since electronegativity depends on the molecular environment of an atom. Also, the energy estimate can be only used for single, not for multiple bonds. The enthalpy of formation of a molecule containing only single bonds can subsequently be estimated based on an electronegativity table, and it depends on the constituents and the sum of squares of differences of electronegativities of all pairs of bonded atoms. Such a formula for estimating energy typically has a relative error on the order of 10% but can be used to get a rough qualitative idea and understanding of a molecule.

Robert S. Mulliken proposed that the arithmetic mean of the first ionization energy (E) and the electron affinity (E) should be a measure of the tendency of an atom to attract electrons:
formula_4

As this definition is not dependent on an arbitrary relative scale, it has also been termed absolute electronegativity, with the units of kilojoules per mole or electronvolts. However, it is more usual to use a linear transformation to transform these absolute values into values that resemble the more familiar Pauling values. For ionization energies and electron affinities in electronvolts,
formula_5
and for energies in kilojoules per mole,
formula_6

The Mulliken electronegativity can only be calculated for an element whose electron affinity is known. Measured values are available for 72 elements, while approximate values have been estimated or calculated for the remaining elements.

The Mulliken electronegativity of an atom is sometimes said to be the negative of the chemical potential. By inserting the energetic definitions of the ionization potential and electron affinity into the Mulliken electronegativity, it is possible to show that the Mulliken chemical potential is a finite difference approximation of the electronic energy with respect to the number of electrons., i.e.,
formula_7

A. Louis Allred and Eugene G. Rochow considered that electronegativity should be related to the charge experienced by an electron on the "surface" of an atom: The higher the charge per unit area of atomic surface the greater the tendency of that atom to attract electrons. The effective nuclear charge, "Z", experienced by valence electrons can be estimated using Slater's rules, while the surface area of an atom in a molecule can be taken to be proportional to the square of the covalent radius, "r". When "r" is expressed in picometres,
formula_8

R.T. Sanderson has also noted the relationship between Mulliken electronegativity and atomic size, and has proposed a method of calculation based on the reciprocal of the atomic volume. With a knowledge of bond lengths, Sanderson's model allows the estimation of bond energies in a wide range of compounds. Sanderson's model has also been used to calculate molecular geometry, "s"-electron energy, NMR spin-spin coupling constants and other parameters for organic compounds. This work underlies the concept of electronegativity equalization, which suggests that electrons distribute themselves around a molecule to minimize or to equalize the Mulliken electronegativity. This behavior is analogous to the equalization of chemical potential in macroscopic thermodynamics.

Perhaps the simplest definition of electronegativity is that of Leland C. Allen, who has proposed that it is related to the average energy of the valence electrons in a free atom,

formula_9

where "ε" are the one-electron energies of s- and p-electrons in the free atom and "n" are the number of s- and p-electrons in the valence shell. It is usual to apply a scaling factor, 1.75×10 for energies expressed in kilojoules per mole or 0.169 for energies measured in electronvolts, to give values that are numerically similar to Pauling electronegativities.

The one-electron energies can be determined directly from spectroscopic data, and so electronegativities calculated by this method are sometimes referred to as spectroscopic electronegativities. The necessary data are available for almost all elements, and this method allows the estimation of electronegativities for elements that cannot be treated by the other methods, e.g. francium, which has an Allen electronegativity of 0.67. However, it is not clear what should be considered to be valence electrons for the d- and f-block elements, which leads to an ambiguity for their electronegativities calculated by the Allen method.

On this scale, neon has the highest electronegativity of all elements, followed by fluorine, helium, and oxygen.

The wide variety of methods of calculation of electronegativities, which all give results that correlate well with one another, is one indication of the number of chemical properties that might be affected by electronegativity. The most obvious application of electronegativities is in the discussion of bond polarity, for which the concept was introduced by Pauling. In general, the greater the difference in electronegativity between two atoms the more polar the bond that will be formed between them, with the atom having the higher electronegativity being at the negative end of the dipole. Pauling proposed an equation to relate the "ionic character" of a bond to the difference in electronegativity of the two atoms, although this has fallen somewhat into disuse.

Several correlations have been shown between infrared stretching frequencies of certain bonds and the electronegativities of the atoms involved: however, this is not surprising as such stretching frequencies depend in part on bond strength, which enters into the calculation of Pauling electronegativities. More convincing are the correlations between electronegativity and chemical shifts in NMR spectroscopy or isomer shifts in Mössbauer spectroscopy (see figure). Both these measurements depend on the s-electron density at the nucleus, and so are a good indication that the different measures of electronegativity really are describing "the ability of an atom in a molecule to attract electrons to itself".

In general, electronegativity increases on passing from left to right along a period and decreases on descending a group. Hence, fluorine is the most electronegative of the elements (not counting noble gases), whereas caesium is the least electronegative, at least of those elements for which substantial data is available. This would lead one to believe that caesium fluoride is the compound whose bonding features the most ionic character.

There are some exceptions to this general rule. Gallium and germanium have higher electronegativities than aluminium and silicon, respectively, because of the d-block contraction. Elements of the fourth period immediately after the first row of the transition metals have unusually small atomic radii because the 3d-electrons are not effective at shielding the increased nuclear charge, and smaller atomic size correlates with higher electronegativity (see Allred-Rochow electronegativity and Sanderson electronegativity above). The anomalously high electronegativity of lead, in particular when compared to thallium and bismuth, is an artifact of electronegativity varying with oxidation state: its electronegativity conforms better to trends if it is quoted for the +2 state with a Pauling value of 1.87 instead of the +4 state.

In inorganic chemistry, it is common to consider a single value of electronegativity to be valid for most "normal" situations. While this approach has the advantage of simplicity, it is clear that the electronegativity of an element is "not" an invariable atomic property and, in particular, increases with the oxidation state of the element.

Allred used the Pauling method to calculate separate electronegativities for different oxidation states of the handful of elements (including tin and lead) for which sufficient data were available. However, for most elements, there are not enough different covalent compounds for which bond dissociation energies are known to make this approach feasible. This is particularly true of the transition elements, where quoted electronegativity values are usually, of necessity, averages over several different oxidation states and where trends in electronegativity are harder to see as a result.

The chemical effects of this increase in electronegativity can be seen both in the structures of oxides and halides and in the acidity of oxides and oxoacids. Hence CrO and MnO are acidic oxides with low melting points, while CrO is amphoteric and MnO is a completely basic oxide.

The effect can also be clearly seen in the dissociation constants p"K" of the oxoacids of chlorine. The effect is much larger than could be explained by the negative charge being shared among a larger number of oxygen atoms, which would lead to a difference in p"K" of log() = –0.6 between hypochlorous acid and perchloric acid. As the oxidation state of the central chlorine atom increases, more electron density is drawn from the oxygen atoms onto the chlorine, diminishing the partial negative charge of individual oxygen atoms. At the same time, the positive partial charge on the hydrogen increases with a higher oxidation state. This explains the observed increased acidity with an increasing oxidation state in the oxoacids of chlorine.

The electronegativity of an atom changes depending on the hybridization of the orbital employed in bonding. Electrons in s orbitals are held more tightly than electrons in p orbitals. Hence, a bond to an atom that employs an sp"" hybrid orbital for bonding will be more heavily polarized to that atom when the hybrid orbital has more s character. That is, when electronegativities are compared for different hybridization schemes of a given element, the order holds (the trend should apply to non-integer hybridization indices as well). While this holds true in principle for any main-group element, values for the hybridization-specific electronegativity are most frequently cited for carbon. In organic chemistry, these electronegativities are frequently invoked to predict or rationalize bond polarities in organic compounds containing double and triple bonds to carbon.
In organic chemistry, electronegativity is associated more with different functional groups than with individual atoms. The terms group electronegativity and substituent electronegativity are used synonymously. However, it is common to distinguish between the inductive effect and the resonance effect, which might be described as σ- and π-electronegativities, respectively. There are a number of linear free-energy relationships that have been used to quantify these effects, of which the Hammett equation is the best known. Kabachnik parameters are group electronegativities for use in organophosphorus chemistry.

Electropositivity is a measure of an element's ability to donate electrons, and therefore form positive ions; thus, it is antipode to electronegativity.

Mainly, this is an attribute of metals, meaning that, in general, the greater the metallic character of an element the greater the electropositivity. Therefore, the alkali metals are the most electropositive of all. This is because they have a single electron in their outer shell and, as this is relatively far from the nucleus of the atom, it is easily lost; in other words, these metals have low ionization energies.

While electronegativity increases along periods in the periodic table, and decreases down groups, electropositivity "decreases" along periods (from left to right) and "increases" down groups. This means that elements in the upper right of the periodic table of elements (oxygen, sulfur, chlorine, etc.) will have the greatest electronegativity, and those in the lower-left (rubidium, caesium, and francium) the greatest electropositivity.




European Charter for Regional or Minority Languages

The European Charter for Regional or Minority Languages (ECRML) is a European treaty (CETS 148) adopted in 1992 under the auspices of the Council of Europe to protect and promote historical regional and minority languages in Europe. However, the charter does not provide any criterion or definition for an idiom to be a minority or a regional language, and the classification stays in the hands of the national state.

The preparation for the charter was undertaken by the predecessor to the current Congress of Local and Regional Authorities, the Standing Conference of Local and Regional Authorities of Europe because involvement of local and regional government was essential. The actual charter was written in the Parliamentary Assembly based on the Congress' Recommendations. It only applies to languages traditionally used by the nationals of the State Parties (thus excluding languages used by recent immigrants from other states, see immigrant languages), which significantly differ from the majority or official language (thus excluding what the state party wishes to consider as mere local dialects of the official or majority language) and that either have a territorial basis (and are therefore traditionally spoken by populations of regions or areas within the State) or are used by linguistic minorities within the State as a whole (thereby including such languages as Yiddish, Romani and Lemko, which are used over a wide geographic area).

Some states, such as Ukraine and Sweden, have tied the status of minority language to the recognized national minorities, which are defined by ethnic, cultural and/or religious criteria, thereby circumventing the Charter's notion of linguistic minority.

Languages that are official within regions, provinces or federal units within a State (for example Catalan in Spain) are not classified as official languages of the State and may therefore benefit from the Charter. On the other hand, Ireland has not been able to sign the Charter on behalf of the Irish language (although a minority language) as it is defined as the first official language of the state. The United Kingdom has ratified the Charter in respect to (among other languages) Welsh in Wales, Scots and Gaelic in Scotland, and Irish in Northern Ireland. France, although a signatory, has been constitutionally blocked from ratifying the Charter in respect to the languages of France.

The charter provides many actions state parties can take to protect and promote historical regional and minority languages. There are two levels of protection—all signatories must apply the lower level of protection to qualifying languages. Signatories may further declare that a qualifying language or languages will benefit from the higher level of protection, which lists a range of actions from which states must agree to undertake at least 35.

Countries can ratify the charter in respect of its minority languages based on Part II or Part III of the charter, which contain varying principles. Countries can treat languages differently under the charter, for example, in the United Kingdom, the Welsh language is ratified under the general Part II principles as well as the more specific Part III commitments, while the Cornish language is ratified only under Part II.

Part II of the Charter details eight main principles and objectives upon which States must base their policies and legislation. They are seen as a framework for the preservation of the languages concerned.

Part III details comprehensive rules, across a number of sectors, by which states agree to abide. Each language to which Part III of the Charter is applied must be named specifically by the government. States must select at least thirty-five of the undertakings in respect to each language. Many provisions contain several options, of varying degrees of stringency, one of which has to be chosen "according to the situation of each language". The areas from which these specific undertakings must be chosen are as follows:



English Civil War

The English Civil War refers to a series of civil wars and political machinations between Royalists and Parliamentarians in the Kingdom of England from 1642 to 1651. Part of the wider 1639 to 1653 Wars of the Three Kingdoms, the struggle consisted of the First English Civil War and the Second English Civil War. The Anglo-Scottish War of 1650 to 1652 is sometimes referred to as "the Third English Civil War."

While the conflicts in the three kingdoms of England, Scotland and Ireland had similarities, each had their own specific issues and objectives. The First English Civil War was fought primarily over the correct balance of power between Parliament and Charles I. It ended in June 1646 with Royalist defeat and the king in custody.

However, victory exposed Parliamentarian divisions over the nature of the political settlement. The vast majority went to war in 1642 to assert Parliament's right to participate in government, not abolish the monarchy, which meant Charles' refusal to make concessions led to a stalemate. Concern over the political influence of radicals within the New Model Army like Oliver Cromwell led to an alliance between moderate Parliamentarians and Royalists, supported by the Covenanters. Royalist defeat in the 1648 Second English Civil War resulted in the execution of Charles I in January 1649, and establishment of the Commonwealth of England.

In 1650, Charles II was crowned king of Scotland, in return for agreeing to create a Presbyterian church in both England and Scotland. The subsequent Anglo-Scottish War ended with Parliamentarian victory at Worcester on 3 September 1651. Both Ireland and Scotland were incorporated into the Commonwealth, and Britain became a unitary state until the Stuart Restoration in 1660.

The term "English Civil War" appears most often in the singular, but historians often divide the conflict into two or three separate wars. They were not restricted to England alone, as Wales (having been annexed into the Kingdom of England) was affected by the same political instabilities. The conflicts also involved wars with Scotland and Ireland and civil wars within them. Some historians have favoured the term "the British Civil Wars". From the Restoration to the 19th century, the common phrase for the civil wars was "the rebellion" or "the great rebellion".

The wars spanning all four countries are known as the Wars of the Three Kingdoms. In the early 19th century, Sir Walter Scott referred to it as "the Great Civil War". The 1911 "Encyclopædia Britannica" called the series of conflicts the "Great Rebellion". Some historians, notably Marxists such as Christopher Hill (1912–2003), favoured the term "English Revolution".

Each side had a geographical stronghold, such that minority elements were silenced or fled. The Royalist areas included the countryside, the shires, the cathedral city of Oxford, and the less economically developed areas of northern and western England. Parliament's strengths spanned the industrial centres, ports, and economically advanced regions of southern and eastern England, including the remaining cathedral cities (except York, Chester, Worcester). Lacey Baldwin Smith says, "the words "populous, rich, and rebellious" seemed to go hand in hand".

Many officers and veteran soldiers had fought in European wars, notably the Eighty Years' War between the Spanish and the Dutch, which began in 1568, as well as earlier phases of the Thirty Years' War which began in 1618 and concluded in 1648.

The war was of unprecedented scale for the English. During the campaign seasons, 120,000 to 150,000 soldiers would be in the field, a higher proportion of the population than were fighting in Germany in the Thirty Years' War.

The main battle tactic came to be known as pike and shot infantry. The two sides would line up opposite one another, with infantry brigades of musketeers in the centre. These carried matchlock muskets, an inaccurate weapon which nevertheless could be lethal at a range of up to 300 yards. Musketeers would assemble three rows deep, the first kneeling, second crouching, and third standing. At times, troops divided into two groups, allowing one to reload while the other fired. Among the musketeers were pike men, carrying pikes of to long, whose main purpose was to protect the musketeers from cavalry charges. Positioned on each side of the infantry were cavalry, with a right wing led by the lieutenant-general and left by the commissary general. Its main aim was to rout the opponents' cavalry, then turn and overpower their infantry.

The Royalist cavaliers' skill and speed on horseback led to many early victories. Prince Rupert, commanding the king's cavalry, used a tactic learned while fighting in the Dutch army, where cavalry would charge at full speed into the opponent's infantry, firing their pistols just before impact.

However, with Oliver Cromwell and the introduction of the more disciplined New Model Army, a group of disciplined pike men would stand its ground, which could have a devastating effect. The Royalist cavalry had a tendency to chase down individual targets after the initial charge, leaving their forces scattered and tired, whereas Cromwell's cavalry was slower but better disciplined. Trained to operate as a single unit, it went on to win many decisive victories.

The English Civil War broke out in 1642, less than 40 years after the death of Queen Elizabeth I. Elizabeth had been succeeded by her first cousin twice-removed, King James VI of Scotland, as James I of England, creating the first personal union of the Scottish and English kingdoms. As King of Scots, James had become accustomed to Scotland's weak parliamentary tradition since assuming control of the Scottish government in 1583, so that upon assuming power south of the border, the new King of England was affronted by the constraints the English Parliament attempted to place on him in exchange for money. Consequently, James's personal extravagance, which resulted in his being perennially short of money, meant that he had to resort to extra-parliamentary sources of income. Moreover, increasing inflation during this period meant that even though Parliament was granting the King the same nominal value of subsidy, the income was actually worth less.

This extravagance was tempered by James's peaceful disposition, so that by the succession of his son Charles I in 1625 the two kingdoms had both experienced relative peace, internally and in their relations with each other. Charles followed his father's dream in hoping to unite the kingdoms of England, Scotland and Ireland into a single kingdom. Many English Parliamentarians were suspicious of such a move, fearing that such a new kingdom might destroy old English traditions that had bound the English monarchy. Because James had described kings as "little gods on Earth", chosen by God to rule in accordance with the doctrine of the "Divine Right of Kings", and Charles shared his father's position, the suspicions of the Parliamentarians had some justification.

At the time, the Parliament of England did not have a large permanent role in the English system of government. Instead, it functioned as a temporary advisory committee and was summoned only if and when the monarch saw fit. Once summoned, a Parliament's continued existence was at the King's pleasure since it was subject to dissolution by him at any time.

Yet in spite of this limited role, Parliament had acquired over the centuries "de facto" powers of enough significance that monarchs could not simply ignore them indefinitely. For a monarch, Parliament's most indispensable power was its ability to raise tax revenues far in excess of all other sources of revenue at the Crown's disposal. By the 17th century, Parliament's tax-raising powers had come to be derived from the fact that the gentry was the only stratum of society with the ability and authority to collect and remit the most meaningful forms of taxation then available at the local level. So, if the king wanted to ensure smooth revenue collection, he needed the gentry's cooperation. For all of the Crown's legal authority, its resources were limited by any modern standard to the extent that if the gentry refused to collect the king's taxes on a national scale, the Crown lacked a practical means of compelling them.

From the thirteenth century, monarchs ordered the election of representatives to sit in the House of Commons, with most voters being the owners of property, although in some potwalloper boroughs every male householder could vote. When assembled along with the House of Lords, these elected representatives formed a Parliament. So the concept of Parliaments allowed representatives of the property-owning class to meet, primarily, at least from the point of view of the monarch, to sanction whatever taxes the monarch wished to collect. In the process, the representatives could debate and enact statutes, or acts. However, Parliament lacked the power to force its will upon the monarch; its only leverage was the threat of withholding the financial means required to implement his plans.

Many concerns were raised over Charles's marriage in 1625 to a Roman Catholic French princess, Henrietta Maria. Parliament refused to assign him the traditional right to collect customs duties for his entire reign, deciding instead to grant it only on a provisional basis and negotiate with him.

Charles, meanwhile, decided to send an expeditionary force to relieve the French Huguenots, whom French royal troops held besieged in La Rochelle. Such military support for Protestants on the Continent potentially alleviated concerns about the King's marriage to a Catholic. However, Charles's insistence on giving command of the English force to his unpopular royal favourite George Villiers, the Duke of Buckingham, undermined that support. Unfortunately for Charles and Buckingham, the relief expedition proved a fiasco (1627), and Parliament, already hostile to Buckingham for his monopoly on royal patronage, opened impeachment proceedings against him. Charles responded by dissolving Parliament. This saved Buckingham but confirmed the impression that Charles wanted to avoid Parliamentary scrutiny of his ministers.

Having dissolved Parliament and unable to raise money without it, the king assembled a new one in 1628. (The elected members included Oliver Cromwell, John Hampden, and Edward Coke.) The new Parliament drew up a Petition of Right, which Charles accepted as a concession to obtain his subsidy. The Petition made reference to Magna Carta, but did not grant him the right of tonnage and poundage, which Charles had been collecting without Parliamentary authorisation since 1625. Several more active members of the opposition were imprisoned, which caused outrage; one, John Eliot, subsequently died in prison and came to be seen as a martyr for the rights of Parliament.

Charles avoided calling a Parliament for the next decade, a period known as the "personal rule of Charles I", or by its critics as the "Eleven Years' Tyranny". During this period, Charles's policies were determined by his lack of money. First and foremost, to avoid Parliament, the King needed to avoid war. Charles made peace with France and Spain, effectively ending England's involvement in the Thirty Years' War. However, that in itself was far from enough to balance the Crown's finances.

Unable to raise revenue without Parliament and unwilling to convene it, Charles resorted to other means. One was to revive conventions, often outdated. For example, a failure to attend and receive knighthood at Charles's coronation became a finable offence with the fine paid to the Crown. The King also tried to raise revenue through ship money, demanding in 1634–1636 that the inland English counties pay a tax for the Royal Navy to counter the threat of privateers and pirates in the English Channel. Established law supported the policy of coastal counties and inland ports such as London paying ship money in times of need, but it had not been applied to inland counties before.

Authorities had ignored it for centuries, and many saw it as yet another extra-Parliamentary, illegal tax, which prompted some prominent men to refuse to pay it. Charles issued a writ against John Hampden for his failure to pay, and although five judges including Sir George Croke supported Hampden, seven judges found in favour of the King in 1638. The fines imposed on people who refused to pay ship money and standing out against its illegality aroused widespread indignation.

During his "Personal Rule", Charles aroused most antagonism through his religious measures. He believed in High Anglicanism, a sacramental version of the Church of England, theologically based upon Arminianism, a creed shared with his main political adviser, Archbishop William Laud. In 1633, Charles appointed Laud Archbishop of Canterbury and started making the Church more ceremonial, replacing the wooden communion tables with stone altars. Puritans accused Laud of reintroducing Catholicism, and when they complained he had them arrested. In 1637, John Bastwick, Henry Burton, and William Prynne had their ears cut off for writing pamphlets attacking Laud's views – a rare penalty for gentlemen, and one that aroused anger. Moreover, the Church authorities revived statutes from the time of Elizabeth I about church attendance and fined Puritans for not attending Anglican services.

The end of Charles's independent governance came when he attempted to apply the same religious policies in Scotland. The Church of Scotland, reluctantly episcopal in structure, had independent traditions. Charles wanted one uniform Church throughout Britain and introduced a new, High Anglican version of the English Book of Common Prayer to Scotland in the middle of 1637. This was violently resisted. A riot broke out in Edinburgh, which may have been started in St Giles' Cathedral, according to legend, by Jenny Geddes. In February 1638, the Scots formulated their objections to royal policy in the National Covenant. This document took the form of a "loyal protest", rejecting all innovations not first tested by free Parliaments and General Assemblies of the Church.

In the spring of 1639, King Charles I accompanied his forces to the Scottish border to end the rebellion known as the Bishops' War, but after an inconclusive campaign, he accepted the offered Scottish truce: the Pacification of Berwick. This truce proved temporary, and a second war followed in mid-1640. A Scots army defeated Charles's forces in the north, then captured Newcastle. Charles eventually agreed not to interfere in Scotland's religion.

Charles needed to suppress the rebellion in Scotland but had insufficient funds to do so. He needed to seek money from a newly elected English Parliament in 1640. Its majority faction, led by John Pym, used this appeal for money as a chance to discuss grievances against the Crown and oppose the idea of an English invasion of Scotland. Charles took exception to this "lèse-majesté" (offense against the ruler) and, after negotiations went nowhere, dissolved the Parliament after only a few weeks; hence its name, "the Short Parliament".

Without Parliament's support, Charles attacked Scotland again, breaking the truce at Berwick, and suffered comprehensive defeat. The Scots went on to invade England, occupying Northumberland and Durham. Meanwhile, another of Charles's chief advisers, Thomas Wentworth, 1st Viscount Wentworth, had risen to the role of Lord Deputy of Ireland in 1632, and brought in much-needed revenue for Charles by persuading the Irish Catholic gentry to pay new taxes in return for promised religious concessions.

In 1639, Charles had recalled Wentworth to England and in 1640 made him Earl of Strafford, attempting to have him achieve similar results in Scotland. This time he proved less successful and the English forces fled the field at their second encounter with the Scots in 1640. Almost the whole of Northern England was occupied and Charles forced to pay £850 per day to keep the Scots from advancing. Had he not done so they would have pillaged and burnt the cities and towns of Northern England.

All this put Charles in a desperate financial state. As King of Scots, he had to find money to pay the Scottish army in England; as King of England, he had to find money to pay and equip an English army to defend England. His means of raising English revenue without an English Parliament fell critically short of achieving this. Against this backdrop, and according to advice from the Magnum Concilium (the House of Lords, but without the Commons, so not a Parliament), Charles finally bowed to pressure and summoned another English Parliament in November 1640.

The new Parliament proved even more hostile to Charles than its predecessor. It immediately began to discuss grievances against him and his government, with Pym and Hampden (of ship money fame) in the lead. They took the opportunity presented by the King's troubles to force various reforming measures – including many with strong "anti-Papist" themes – upon him. The members passed a law stating that a new Parliament would convene at least once every three years – without the King's summons if need be. Other laws passed making it illegal for the king to impose taxes without Parliamentary consent and later gave Parliament control over the King's ministers.

Finally, the Parliament passed a law forbidding the King to dissolve it without its consent, even if the three years were up. These laws equated to a tremendous increase in Parliamentary power. Ever since, this Parliament has been known as the Long Parliament. However, Parliament did attempt to avert conflict by requiring all adults to sign The Protestation, an oath of allegiance to Charles.

Early in the Long Parliament, the house overwhelmingly accused Thomas Wentworth, Earl of Strafford, of high treason and other crimes and misdemeanors. Henry Vane the Younger supplied evidence of Strafford's claimed improper use of the army in Ireland, alleging that he had encouraged the King to use his Ireland-raised forces to threaten England into compliance. This evidence was obtained from Vane's father, Henry Vane the Elder, a member of the King's Privy Council, who refused to confirm it in Parliament out of loyalty to Charles. On 10 April 1641, Pym's case collapsed, but Pym made a direct appeal to the Younger Vane to produce a copy of the notes from the King's Privy Council, discovered by the Younger Vane and secretly turned over to Pym, to the great anguish of the Elder Vane. These notes contained evidence that Strafford had told the King, "Sir, you have done your duty, and your subjects have failed in theirs; and therefore you are absolved from the rules of government, and may supply yourself by extraordinary ways; you have an army in Ireland, with which you may reduce the kingdom."

Pym immediately launched a Bill of Attainder stating Strafford's guilt and demanding that he be put to death. Unlike a guilty verdict in a court case, attainder did not require a legal burden of proof to be met, but it did require the king's approval. Charles, however, guaranteed Strafford that he would not sign the attainder, without which the bill could not be passed. Furthermore, the Lords opposed the severity of a death sentence on Strafford. Yet increased tensions and a plot in the army to support Strafford began to sway the issue.

On 21 April, the Commons passed the Bill (204 in favour, 59 opposed, and 250 abstained), and the Lords acquiesced. Charles, still incensed over the Commons' handling of Buckingham, refused his assent. Strafford himself, hoping to head off the war he saw looming, wrote to the king and asked him to reconsider. Charles, fearing for the safety of his family, signed on 10 May. Strafford was beheaded two days later. In the meantime, both Parliament and the King agreed to an independent investigation into the king's involvement in Strafford's plot.

The Long Parliament then passed the Triennial Act 1640, also known as the Dissolution Act, in May 1641, to which royal assent was readily granted. The Triennial Act required Parliament to be summoned at least once in three years. When the king failed to issue a proper summons, the members could assemble on their own. This act also forbade ship money without Parliament's consent, fines in distraint of knighthood, and forced loans. Monopolies were cut back sharply, the courts of the Star Chamber and High Commission abolished by the Habeas Corpus Act 1640, and the Triennial Act respectively.

All remaining forms of taxation were legalised and regulated by the Tonnage and Poundage Act 1640. On 3 May, Parliament decreed The Protestation, attacking the 'wicked counsels' of Charles's government, whereby those who signed the petition undertook to defend 'the true reformed religion', Parliament, and the king's person, honour and estate. Throughout May, the House of Commons launched several bills attacking bishops and Episcopalianism in general, each time defeated in the Lords.

Charles and his Parliament hoped that the execution of Strafford and the Protestation would end the drift towards war, but in fact, they encouraged it. Charles and his supporters continued to resent Parliament's demands, and Parliamentarians continued to suspect Charles of wanting to impose episcopalianism and unfettered royal rule by military force. Within months, the Irish Catholics, fearing a resurgence of Protestant power, struck first, and all Ireland soon descended into chaos. Rumours circulated that the King supported the Irish, and Puritan members of the Commons soon started murmuring that this exemplified the fate that Charles had in store for them all.

On 4 January 1642, Charles, followed by 400 soldiers, entered the House of Commons and attempted to arrest five members on a charge of treason. The members had learned that he was coming and escaped. Charles not only failed to arrest them but turned more people against him.

In the summer of 1642, these national troubles helped to polarise opinion, ending indecision about which side to support or what action to take. Opposition to Charles also arose from many local grievances. For example, imposed drainage schemes in The Fens disrupted the livelihood of thousands after the King awarded a number of drainage contracts. Many saw the King as indifferent to public welfare, and this played a role in bringing much of eastern England into the Parliamentarian camp. This sentiment brought with it such people as the Earl of Manchester and Oliver Cromwell, each a notable wartime adversary of the King. Conversely, one of the leading drainage contractors, the Earl of Lindsey, was to die fighting for the King at the Battle of Edgehill.

In early January 1642, a few days after failing to capture five members of the House of Commons, Charles feared for the safety of his family and retinue and left the London area for the north country.

Further frequent negotiations by letter between the King and the Long Parliament, through to early summer, proved fruitless. On 1 June 1642 the English Lords and Commons approved a list of proposals known as the Nineteen Propositions. In these demands, the Parliament sought a larger share of power in the governance of the kingdom. Before the end of the month the King rejected the Propositions.

As the summer progressed, cities and towns declared their sympathies for one faction or the other: for example, the garrison of Portsmouth commanded by Sir George Goring declared for the King, but when Charles tried to acquire arms from Kingston upon Hull, the weaponry depository used in the previous Scottish campaigns, Sir John Hotham, the military governor appointed by Parliament in January, refused to let Charles enter the town, and when Charles returned with more men later, Hotham drove them off. Charles issued a warrant for Hotham's arrest as a traitor but was powerless to enforce it. Throughout the summer, tensions rose and there was brawling in several places, the first death from the conflict taking place in Manchester.
At the outset of the conflict, much of the country remained neutral, though the Royal Navy and most English cities favoured Parliament, while the King found marked support in rural communities. The war quickly spread and eventually involved every level of society. Many areas attempted to remain neutral. Some formed bands of Clubmen to protect their localities from the worst excesses of the armies of both sides, but most found it impossible to withstand both King and Parliament.

On one side, the King and his supporters fought for traditional government in church and state. On the other, most Parliamentarians initially took up arms to defend what they saw as a traditional balance of government in church and state, which the bad advice the King received from his advisers had undermined before and during the "Eleven Years' Tyranny". The views of the members of Parliament ranged from unquestioning support of the King – at one point during the First Civil War, more members of the Commons and Lords gathered in the King's Oxford Parliament than at Westminster — through to radicals who sought major reforms in religious independence and redistribution of power at a national level.

After the debacle at Hull, Charles moved on to Nottingham, raising the royal standard there on 22 August 1642. At the time, Charles had with him about 2,000 cavalry and a small number of Yorkshire infantrymen, and using the archaic system of a Commission of Array, his supporters started to build a larger army around the standard. Charles moved in a westerly direction, first to Stafford, then on to Shrewsbury, as support for his cause seemed particularly strong in the Severn valley area and in North Wales. While passing through Wellington, he declared in what became known as the "Wellington Declaration" that he would uphold the "Protestant religion, the laws of England, and the liberty of Parliament".

The Parliamentarians who opposed the King did not remain passive in this pre-war period. As in Hull, they took measures to secure strategic towns and cities by appointing to office men sympathetic to their cause. On 9 June they voted to raise an army of 10,000 volunteers and appointed Robert Devereux, 3rd Earl of Essex its commander three days later. He received orders "to rescue His Majesty's person, and the persons of the Prince [of Wales] and the Duke of York [James II] out of the hands of those desperate persons who were about them." The Lords Lieutenant whom Parliament appointed used the Militia Ordinance to order the militia to join Essex's army.
Two weeks after the King had raised his standard at Nottingham, Essex led his army north towards Northampton, picking up support along the way (including a detachment of Huntingdonshire cavalry raised and commanded by Oliver Cromwell). By mid-September Essex's forces had grown to 21,000 infantry and 4,200 cavalry and dragoons. On 14 September he moved his army to Coventry and then to the north of the Cotswolds, a strategy that placed it between the Royalists and London. With the size of both armies now in the tens of thousands and only Worcestershire between them, it was inevitable that cavalry reconnaissance units would meet sooner or later. This happened in the first major skirmish of the Civil War, when a troop of about 1,000 Royalist cavalry under Prince Rupert, a German nephew of the King and one of the outstanding cavalry commanders of the war, defeated a Parliamentary cavalry detachment under Colonel John Brown at the Battle of Powick Bridge, which crossed the River Teme close to Worcester.

Rupert withdrew to Shrewsbury, where a council-of-war discussed two courses of action: whether to advance towards Essex's new position near Worcester, or march down the now open road towards London. The Council decided on the London route, but not to avoid a battle, for the Royalist generals wanted to fight Essex before he grew too strong, and the temper of both sides made it impossible to postpone the decision. In the Earl of Clarendon's words, "it was considered more counsellable to march towards London, it being morally sure that the earl of Essex would put himself in their way." Hence, the army left Shrewsbury on 12 October, gaining two days' start on the enemy, and moved south-east. This had the desired effect of forcing Essex to move to intercept them.

The first pitched battle of the war, at Edgehill on 23 October 1642, proved inconclusive, both Royalists and Parliamentarians claiming victory. The second field action, the stand-off at Turnham Green, saw Charles forced to withdraw to Oxford, which would serve as his base for the rest of the war.

In 1643, Royalist forces won at Adwalton Moor, gaining control of most of Yorkshire. In the Midlands, a Parliamentary force under Sir John Gell besieged and captured the cathedral city of Lichfield, after the death of the original commander, Lord Brooke. This group then joined forces with Sir William Brereton at the inconclusive Battle of Hopton Heath (19 March 1643), where the Royalist commander, the Earl of Northampton, was killed. John Hampden died after being wounded in the Battle of Chalgrove Field (18 June 1643). Subsequent battles in the west of England at Lansdowne and Roundway Down also went to the Royalists. Prince Rupert could then take Bristol. In the same year, however, Cromwell formed his troop of "Ironsides", a disciplined unit that demonstrated his military leadership ability. With their assistance he won a victory at the Battle of Gainsborough in July.
At this stage, from 7 to 9 August 1643, there were some popular demonstrations in London – both for and against war. They were protesting at Westminster. A peace demonstration by London women, which turned violent, was suppressed; the women were beaten and fired upon with live ammunition, leaving several dead. Many were arrested and incarcerated in Bridewell and other prisons. After these August events, the Venetian ambassador in England reported to the doge that the London government took considerable measures to stifle dissent.

In general, the early part of the war went well for the Royalists. The turning point came in the late summer and early autumn of 1643, when the Earl of Essex's army forced the king to raise the Siege of Gloucester and then brushed the Royalists aside at the First Battle of Newbury (20 September 1643), to return triumphantly to London. Parliamentarian forces led by the Earl of Manchester besieged the port of King's Lynn, Norfolk, which under Sir Hamon L'Estrange held out until September. Other forces won the Battle of Winceby, giving them control of Lincoln. Political manoeuvring to gain an advantage in numbers led Charles to negotiate a ceasefire in Ireland, freeing up English troops to fight on the Royalist side in England, while Parliament offered concessions to the Scots in return for aid and assistance.

Helped by the Scots, Parliament won at Marston Moor (2 July 1644), gaining York and the north of England. Cromwell's conduct in the battle proved decisive, and showed his potential as a political and as an important military leader. The defeat at the Battle of Lostwithiel in Cornwall, however, marked a serious reverse for Parliament in the south-west of England. Subsequent fighting around Newbury (27 October 1644), though tactically indecisive, strategically gave another check to Parliament.

In 1645, Parliament reaffirmed its determination to fight the war to a finish. It passed the Self-denying Ordinance, by which all members of either House of Parliament laid down their commands and re-organised its main forces into the New Model Army, under the command of Sir Thomas Fairfax, with Cromwell as his second-in-command and Lieutenant-General of Horse. In two decisive engagements – the Battle of Naseby on 14 June and the Battle of Langport on 10 July – the Parliamentarians effectively destroyed Charles's armies.

In the remains of his English realm, Charles tried to recover a stable base of support by consolidating the Midlands. He began to form an axis between Oxford and Newark-on-Trent in Nottinghamshire. These towns had become fortresses and showed more reliable loyalty to him than others. He took Leicester, which lies between them, but found his resources exhausted. Having little opportunity to replenish them, in May 1646 he sought shelter with a Presbyterian Scottish army at Southwell in Nottinghamshire. Charles was eventually handed over to the English Parliament by the Scots and imprisoned. This marked the end of the First English Civil War.

The end of the First Civil War, in 1646, left a partial power vacuum in which any combination of the three English factions, Royalists, Independents of the New Model Army ("the Army"), and Presbyterians of the English Parliament, as well as the Scottish Parliament allied with the Scottish Presbyterians (the "Kirk"), could prove strong enough to dominate the rest. Armed political Royalism was at an end, but despite being a prisoner, Charles I was considered by himself and his opponents (almost to the last) as necessary to ensure the success of whichever group could come to terms with him. Thus, he passed successively into the hands of the Scots, the Parliament and the Army.

The King attempted to reverse the verdict of arms by "coquetting" with each in turn. On 3 June 1647, Cornet George Joyce of Sir Thomas Fairfax's horse seized the King for the Army, after which the English Presbyterians and the Scots began to prepare for a fresh civil war, less than two years after the conclusion of the first, this time against "Independency", as embodied in the Army. After making use of the Army's sword, its opponents attempted to disband it, to send it on foreign service and to cut off its arrears of pay.

The result was that the Army leadership was exasperated beyond control, and, remembering not merely its grievances but also the principle for which the Army had fought, it soon became the most powerful political force in the realm. From 1646 to 1648 the breach between Army and Parliament widened day by day, until finally the Presbyterian party, combined with the Scots and the remaining Royalists, felt itself strong enough to begin a Second Civil War.

Charles I took advantage of the deflection of attention away from himself to negotiate on 28 December 1647 a secret treaty with the Scots, again promising church reform. Under the agreement, called the "Engagement", the Scots undertook to invade England on Charles's behalf and restore him to the throne.

A series of Royalist uprisings throughout England and a Scottish invasion occurred in the summer of 1648. Forces loyal to Parliament put down most of those in England after little more than a skirmish, but uprisings in Kent, Essex and Cumberland, the rebellion in Wales, and the Scottish invasion involved pitched battles and prolonged sieges.

In the spring of 1649, unpaid Parliamentarian troops in Wales changed sides. Colonel Thomas Horton defeated the Royalist rebels at the Battle of St Fagans (8 May) and the rebel leaders surrendered to Cromwell on 11 July after a protracted two-month siege of Pembroke. Sir Thomas Fairfax defeated a Royalist uprising in Kent at the Battle of Maidstone on 1 June. Fairfax, after his success at Maidstone and the pacification of Kent, turned north to reduce Essex, where, under an ardent, experienced and popular leader, Sir Charles Lucas, the Royalists had taken up arms in great numbers. Fairfax soon drove the enemy into Colchester, but his first attack on the town met with a repulse and he had to settle down to a long siege.

In the North of England, Major-General John Lambert fought a successful campaign against several Royalist uprisings, the largest being that of Sir Marmaduke Langdale in Cumberland. Thanks to Lambert's successes, the Scottish commander, the Duke of Hamilton, had to take a western route through Carlisle in his pro-Royalist Scottish invasion of England. The Parliamentarians under Cromwell engaged the Scots at the Battle of Preston (17–19 August). The battle took place largely at Walton-le-Dale near Preston, Lancashire, and resulted in a victory for Cromwell's troops over the Royalists and Scots commanded by Hamilton. This victory marked the end of the Second English Civil War.

Nearly all the Royalists who had fought in the First Civil War had given their word not to bear arms against Parliament, and many, like Lord Astley, were therefore bound by oath not to take any part in the second conflict. So, the victors in the Second Civil War showed little mercy to those who had brought war into the land again. On the evening of the surrender of Colchester, Parliamentarians had Sir Charles Lucas and Sir George Lisle shot. Parliamentary authorities sentenced the leaders of the Welsh rebels, Major-General Rowland Laugharne, Colonel John Poyer and Colonel Rice Powel to death, but executed only Poyer (25 April 1649), having selected him by lot. Of five prominent Royalist peers who had fallen into Parliamentary hands, three – the Duke of Hamilton, the Earl of Holland, and Lord Capel, one of the Colchester prisoners and a man of high character – were beheaded at Westminster on 9 March.

Charles's secret pacts and encouragement of supporters to break their parole caused Parliament to debate whether to return the King to power at all. Those who still supported Charles's place on the throne, such as the army leader and moderate Fairfax, tried again to negotiate with him. The Army, furious that Parliament continued to countenance Charles as a ruler, then marched on Parliament and conducted "Pride's Purge", named after the commanding officer of the operation, Thomas Pride, in December 1648.

Troops arrested 45 members and kept 146 out of the chamber. They allowed only 75 members in, and then only at the Army's bidding. This Rump Parliament received orders to set up, in the name of the people of England, a High Court of Justice for the trial of Charles I for treason. Fairfax, a constitutional monarchist, declined to have anything to do with the trial. He resigned as head of the army, so clearing Cromwell's road to power.

At the end of the trial the 59 Commissioners (judges) found Charles I guilty of high treason as a "tyrant, traitor, murderer and public enemy". His beheading took place on a scaffold in front of the Banqueting House of the Palace of Whitehall on 30 January 1649. After the Restoration in 1660, nine of the surviving regicides not living in exile were executed and most others sentenced to life imprisonment.

After the regicide, Charles, Prince of Wales as the eldest son was publicly proclaimed King Charles II in the Royal Square of St. Helier, Jersey, on 17 February 1649 (after a first such proclamation in Edinburgh on 5 February 1649). It took longer for the news to reach the trans-Atlantic colonies, with the Somers Isles (also known as Bermuda) becoming the first to proclaim Charles II King on 5 July 1649.

Ireland had undergone continual war since the rebellion of 1641, with most of the island controlled by the Irish Confederates. Increasingly threatened by the armies of the English Parliament after Charles I's arrest in 1648, the Confederates signed a treaty of alliance with the English Royalists. The joint Royalist and Confederate forces under the Duke of Ormonde tried to eliminate the Parliamentary army holding Dublin by laying siege, but their opponents routed them at the Battle of Rathmines (2 August 1649). As the former Member of Parliament Admiral Robert Blake blockaded Prince Rupert's fleet in Kinsale, Cromwell could land at Dublin on 15 August 1649 with an army to quell the Royalist alliance.

Cromwell's suppression of the Royalists in Ireland in 1649 is still remembered by many Irish people. After the Siege of Drogheda, the massacre of nearly 3,500 people – around 2,700 Royalist soldiers and 700 others, including civilians, prisoners and Catholic priests (Cromwell claimed all had carried arms) – became one of the historical memories that has driven Irish-English and Catholic-Protestant strife during the last three centuries. The Parliamentarian conquest of Ireland ground on for another four years until 1653, when the last Irish Confederate and Royalist troops surrendered. In the wake of the conquest, the victors confiscated almost all Irish Catholic-owned land and distributed it to Parliament's creditors, to Parliamentary soldiers who served in Ireland, and to English who had settled there before the war.

The execution of Charles I altered the dynamics of the Civil War in Scotland, which had raged between Royalists and Covenanters since 1644. By 1649, the struggle had left the Royalists there in disarray and their erstwhile leader, the Marquess of Montrose, had gone into exile. At first, Charles II encouraged Montrose to raise a Highland army to fight on the Royalist side. When the Scottish Covenanters, who did not agree with the execution of Charles I and who feared for the future of Presbyterianism under the new Commonwealth, offered him the crown of Scotland, Charles abandoned Montrose to his enemies.

Montrose, who had raised a mercenary force in Norway, had already landed and could not abandon the fight. He did not succeed in raising many Highland clans and the Covenanters defeated his army at the Battle of Carbisdale in Ross-shire on 27 April 1650. The victors captured Montrose shortly afterwards and took him to Edinburgh. On 20 May the Scottish Parliament sentenced him to death and had him hanged the next day.
Charles II landed in Scotland at Garmouth in Morayshire on 23 June 1650 and signed the 1638 National Covenant and the 1643 Solemn League and Covenant shortly after coming ashore. With his original Scottish Royalist followers and his new Covenanter allies, Charles II became the greatest threat facing the new English republic. In response to the threat, Cromwell left some of his lieutenants in Ireland to continue the suppression of the Irish Royalists and returned to England.

He arrived in Scotland on 22 July 1650 and proceeded to lay siege to Edinburgh. By the end of August, disease and a shortage of supplies had reduced his army, and he had to order a retreat towards his base at Dunbar. A Scottish army under the command of David Leslie tried to block the retreat, but Cromwell defeated them at the Battle of Dunbar on 3 September. Cromwell's army then took Edinburgh, and by the end of the year his army had occupied much of southern Scotland.

In July 1651, Cromwell's forces crossed the Firth of Forth into Fife and defeated the Scots at the Battle of Inverkeithing (20 July 1651). The New Model Army advanced towards Perth, which allowed Charles, at the head of the Scottish army, to move south into England. Cromwell followed Charles into England, leaving George Monck to finish the campaign in Scotland. Monck took Stirling on 14 August and Dundee on 1 September. The next year, 1652, saw a mopping up of the remnants of Royalist resistance, and under the terms of the "Tender of Union", the Scots received 30 seats in a united Parliament in London, with General Monck as the military governor of Scotland.

Although Cromwell's New Model Army had defeated a Scottish army at Dunbar, Cromwell could not prevent Charles II from marching from Scotland deep into England at the head of another Royalist army. They marched to the west of England where English Royalist sympathies were strongest, but although some English Royalists joined the army, they were far fewer in number than Charles and his Scottish supporters had hoped. Cromwell finally engaged and defeated the new Scottish king at Worcester on 3 September 1651.

For several reasons most of Wales was not as engaged in the English Civil Wars to the same degree as other parts of the British Isles. Wales was isolated from England, both physically and linguistically, so the Welsh were not as much engaged as England in the issues between the king and Parliament.  The English considered Wales a remote land, with Welsh, not English, as the primary language. Since England had formally assimilated Wales into the kingdom, starting in 1536 formal agreements had been put in place under Henry VIII and continued under Charles I that allowed for Welsh local administrative authority and economic control, which allowed the Welsh to function to some degree independently.  Another factor was the Puritan religion, which played a major role in the English Civil Wars but was not widely practised throughout Wales.  Welsh Puritan religious dominance was found in northeast Wales near Wrexham, Denbighshire, and an indirect Puritan influence found along the southwestern coast near Haverfordwest, Pembroke, and Tenby due to a combination of a strong influence by the third earl of Essex and their strong trade relations with Bristol, England, a fervent Puritan stronghold. In addition, Wales comparatively more rural in character than England at this time, and thereby lacking the large number of urban settlements home to mercantile, trade, and manufacturing interests who were a bulwark of support for both Puritanism and eventually the Parliamentarian cause.

Many of the key Welsh Civil Wars leaders were from the gentry class holding Royalist sympathies, or from the Church. Those Welsh who did participate in the Civil Wars battles were underequipped, underfed, and not properly trained for warfare.  The majority of Welsh followed the Protestant faith with a religious perspective that differed from the English puritan zeal. They were also leery of the Irish Catholics invading Wales.  The Welsh also did not want to lose what they had, for the gentry were aware of the destruction the Thirty Years' War caused in Europe.

Most of those English Civil War battles where Wales was impacted occurred near the border with England and in south Wales. Some of the more significant engagements were:



In addition to the Civil Wars' impact on the monarchy and the changes in national leadership, unexpected outcomes of the English Civil Wars to Wales included a significant degradation of the country's road system, a deterioration of government administrative functions to the general population, destruction of castles with only the remnants of them remaining, and the desecration of churches.

After the Royalist defeat at Worcester, Charles II escaped via safe houses and an oak tree to France. Parliament was left in "de facto" control of England. Resistance continued for a time in Ireland and Scotland, but with the pacification of England, resistance elsewhere did not threaten the military supremacy of the New Model Army and its Parliamentary paymasters.

During the Wars, the Parliamentarians established a number of successive committees to oversee the war effort. The first, the Committee of Safety set up in July 1642, comprised 15 members of Parliament. After the Anglo-Scottish alliance against the Royalists, the Committee of Both Kingdoms replaced the Committee of Safety between 1644 and 1648. Parliament dissolved the Committee of Both Kingdoms when the alliance ended, but its English members continued to meet as the Derby House Committee. A second Committee of Safety then replaced it.

During the English Civil War, the role of bishops as wielders of political power and upholders of the established church became a matter of heated political controversy. John Calvin of Geneva had formulated a doctrine of Presbyterianism, which held that the offices of "presbyter" and "episkopos" in the New Testament were identical; he rejected the doctrine of apostolic succession. Calvin's follower John Knox brought Presbyterianism to Scotland when the Scottish church was reformed in 1560. In practice, Presbyterianism meant that committees of lay elders had a substantial voice in church government, as opposed to merely being subjects to a ruling hierarchy.

This vision of at least partial democracy in ecclesiology paralleled the struggles between Parliament and the King. A body within the Puritan movement in the Church of England sought to abolish the office of bishop and remake the Church of England along Presbyterian lines. The Martin Marprelate tracts (1588–1589), applying the pejorative name of "prelacy" to the church hierarchy, attacked the office of bishop with satire that deeply offended Elizabeth I and her Archbishop of Canterbury John Whitgift. The vestments controversy also related to this movement, seeking further reductions in church ceremony, and labelling the use of elaborate vestments as "unedifying" and even idolatrous.

King James I, reacting against the perceived contumacy of his Presbyterian Scottish subjects, adopted "No Bishop, no King" as a slogan. He tied the hierarchical authority of the bishop to the absolute authority he sought as King and viewed attacks on the authority of the bishops as attacks on his authority. Matters came to a head when Charles I appointed William Laud as Archbishop of Canterbury. Laud aggressively attacked the Presbyterian movement and sought to impose the full Book of Common Prayer. The controversy eventually led to Laud's impeachment for treason by a bill of attainder in 1645 and subsequent execution. Charles also attempted to impose episcopacy on Scotland. The Scots' violent rejection of bishops and liturgical worship sparked the Bishops' Wars in 1639–1640.

During the height of Puritan power under the Commonwealth and the Protectorate, episcopacy was formally abolished in the Church of England on 9 October 1646. The Church of England remained Presbyterian until the Restoration of the monarchy.

During the English Civil War, the English overseas possessions became highly involved. In the Channel Islands, the island of Jersey and Castle Cornet in Guernsey supported the King until a surrender with honour in December 1651.

Although the newer, Puritan settlements in North America, notably Massachusetts, were dominated by Parliamentarians, the older colonies sided with the Crown. Friction between Royalists and Puritans in Maryland came to a head in the Battle of the Severn. The Virginia Company's settlements, Bermuda and Virginia, as well as Antigua and Barbados, were conspicuous in their loyalty to the Crown. Bermuda's Independent Puritans were expelled, settling the Bahamas under William Sayle as the Eleutheran Adventurers. Parliament passed An Act for prohibiting Trade with the Barbadoes, Virginia, Bermuda and Antego in October 1650, which stated that:
The Act also authorised Parliamentary privateers to act against English vessels trading with the rebellious colonies:
Far to the North, Bermuda's regiment of Militia and its coastal batteries prepared to resist an invasion that never came. Built-up inside the natural defence of a nearly impassable barrier reef, to fend off the might of Spain, these defences would have been a formidable obstacle for the Parliamentary fleet sent in 1651 under the command of Admiral Sir George Ayscue to subdue the trans-Atlantic colonies, but after the fall of Barbados, the Bermudians made a separate peace that respected the internal status quo. The Parliament of Bermuda avoided the Parliament of England's fate during The Protectorate, becoming one of the oldest continuous legislatures in the world.

Virginia's population swelled with Cavaliers during and after the English Civil War. Even so, Virginia Puritan Richard Bennett was made Governor answering to Cromwell in 1652, followed by two more nominal "Commonwealth Governors". The loyalty of Virginia's Cavaliers to the Crown was rewarded after the 1660 Restoration of the Monarchy when Charles II dubbed it the "Old Dominion".

Figures for casualties during this period are unreliable, but some attempt has been made to provide rough estimates.

In England, a conservative estimate is that roughly 100,000 people died from war-related disease during the three civil wars. Historical records count 84,830 combat dead from the wars themselves. Counting in accidents and the two Bishops' wars, an estimate of 190,000 dead is achieved, out of a total population of about five million. It is estimated that from 1638 to 1651, 15%–20% of all adult males in England and Wales served in the military. Around 4% of the total population died from war-related causes, compared to 2.23% in the First World War.

As was typical for the era, most combat deaths occurred in minor skirmishes rather than large, pitched battles. There were a total of 645 engagements throughout the wars: 588 of these involved fewer than 250 casualties in total, with these 588 accounting for 39,838 fatalities (average count of less than 68) or nearly half of the conflict's combat deaths. There were only 9 major pitched battles (at least 1,000 fatalities) which in total accounted for 15% of casualties.

An anecdotal example of how high casualties in England may have been perceived is to be found in the posthumously published writing (generally titled "The History of Myddle"), by a Shropshire man, Richard Gough (lived 1635–1723) of Myddle near Shrewsbury, who, writing in about 1701, commented of men from his rural home parish who joined the Royalist forces: "And out of these three townes ["sic" - ie townships], Myddle, Marton and Newton, there went noe less than twenty men, of which number thirteen were kill'd in the warrs". After listing those he recalled did not return home, four of whose exact fates were unknown, he concluded: "And if soe many dyed out of these 3 townes [townships] wee may reasonably guess that many thousands dyed in England in that warre."

Figures for Scotland are less reliable and should be treated with caution. Casualties include the deaths of prisoners-of-war in conditions that accelerated their deaths, with estimates of 10,000 prisoners not surviving or not returning home (8,000 captured during and immediately after the Battle of Worcester were deported to New England, Bermuda and the West Indies to work for landowners as indentured labourers). There are no figures to calculate how many died from war-related diseases, but if the same ratio of disease to battle deaths from English figures is applied to the Scottish figures, a not unreasonable estimate of 60,000 people is achieved, from a population of about one million.

Figures for Ireland are described as "miracles of conjecture". Certainly, the devastation inflicted on Ireland was massive, with the best estimate provided by Sir William Petty, the father of English demography. Petty estimated that 112,000 Protestants and 504,000 Catholics were killed through plague, war and famine, giving an estimated total of 616,000 dead, out of a pre-war population of about one and a half million. Although Petty's figures are the best available, they are still acknowledged as tentative; they do not include an estimated 40,000 driven into exile, some of whom served as soldiers in European continental armies, while others were sold as indentured servants to New England and the West Indies. Many of those sold to landowners in New England eventually prospered, but many sold to landowners in the West Indies were worked to death.

These estimates indicate that England suffered a 4 per cent loss of population, Scotland a loss of 6 per cent, while Ireland suffered a loss of 41 per cent of its population. Putting these numbers into the context of other catastrophes helps to understand the devastation of Ireland in particular. The Great Famine of 1845–1852 resulted in a loss of 16 per cent of the population, while during the Soviet famine and Holodomor of 1932–33 the population of the Soviet Ukraine fell by 14 per cent.

Ordinary people took advantage of the dislocation of civil society in the 1640s to gain personal advantages. The contemporary guild democracy movement won its greatest successes among London's transport workers. Rural communities seized timber and other resources on the sequestrated estates of Royalists and Catholics, and on the estates of the royal family and church hierarchy. Some communities improved their conditions of tenure on such estates.

The old "status quo" began a retrenchment after the end of the First Civil War in 1646, and more especially after the Restoration in 1660, but some gains were long-term. The democratic element introduced into the watermen's company in 1642, for example, survived with vicissitudes until 1827.

The wars left England, Scotland, and Ireland among the few countries in Europe without a monarch. In the wake of victory, many of the ideals (and many idealists) became sidelined. The republican government of the Commonwealth of England ruled England (and later all of Scotland and Ireland) from 1649 to 1653 and from 1659 to 1660. Between the two periods, and due to in-fighting among various factions in Parliament, Oliver Cromwell ruled over the Protectorate as Lord Protector (effectively a military dictator) until his death in 1658.

On Oliver Cromwell's death, his son Richard became Lord Protector, but the Army had little confidence in him. After seven months the Army removed Richard. In May 1659 it re-installed the Rump. Military force shortly afterward dissolved this as well. After the second dissolution of the Rump, in October 1659, the prospect of a total descent into anarchy loomed, as the Army's pretense of unity dissolved into factions.
Into this atmosphere General George Monck, Governor of Scotland under the Cromwells, marched south with his army from Scotland. On 4 April 1660, in the Declaration of Breda, Charles II made known the conditions of his acceptance of the Crown of England. Monck organised the Convention Parliament, which met for the first time on 25 April 1660.

On 8 May 1660, it declared that Charles II had reigned as the lawful monarch since the execution of Charles I in January 1649. Charles returned from exile on 23 May 1660. On 29 May 1660, the populace in London acclaimed him as king. His coronation took place at Westminster Abbey on 23 April 1661. These events became known as the "Restoration".

Although the monarchy was restored, it was still with the consent of Parliament. So the civil wars effectively set England and Scotland on course towards a parliamentary monarchy form of government. The outcome of this system was that the future Kingdom of Great Britain, formed in 1707 under the Acts of Union, managed to forestall the kind of revolution typical of European republican movements which generally resulted in total abolition of their monarchies. Thus, the United Kingdom was spared the wave of revolutions that occurred in Europe in the 1840s. Specifically, future monarchs became wary of pushing Parliament too hard, and Parliament effectively chose the line of royal succession in 1688 with the Glorious Revolution.

Thomas Hobbes gave an early historical account of the English Civil War in his "Behemoth", written in 1668 and published in 1681. He assessed the causes of the war to be the conflicting political doctrines of the time. "Behemoth" offered a uniquely historical and philosophical approach to naming the catalysts for the war. It also attempted to explain why Charles I could not hold his throne and maintain peace in his kingdom.

Hobbes analysed the following aspects of English thought during the war: the opinions of divinity and politics that spurred rebellion; rhetoric and doctrine used by the rebels against the king; and how opinions about "taxation, the conscription of soldiers, and military strategy" affected the outcomes of battles and shifts of sovereignty.

Hobbes attributed the war to the novel theories of intellectuals and divines spread for their own pride of reputation. He held that clerical pretensions had contributed significantly to the troubles — "whether those of puritan fundamentalists, papal supremacists or divine right Episcopalians". Hobbes wanted to abolish the independence of the clergy and bring it under the control of the civil state.

Some scholars suggest that Hobbes's "Behemoth" has not received its due as an academic work, being comparatively overlooked and under-rated in the shadow of the same author's "Leviathan". Its scholarly reputation may have suffered because it takes the form of a dialogue, which, while common in philosophy, is rarely adopted by historians. Other factors that hindered its success include Charles II's refusing its publication and Hobbes' lack of empathy with views different from his own.

In the early decades of the 20th century, the Whig school was the dominant theoretical view. It explained the Civil War as resulting from centuries of struggle between Parliament (notably the House of Commons) and the Monarchy, with Parliament defending the traditional rights of Englishmen, while the Stuart monarchy continually attempted to expand its right to dictate law arbitrarily. The major Whig historian, S. R. Gardiner, popularised the idea that the English Civil War was a "Puritan Revolution" that challenged the repressive Stuart Church and prepared the way for religious toleration. Thus, Puritanism was seen as the natural ally of a people preserving their traditional rights against arbitrary monarchical power.

The Whig view was challenged and largely superseded by the Marxist school, which became popular in the 1940s, and saw the English Civil War as a bourgeois revolution. According to Marxist historian Christopher Hill:

In the 1970s, revisionist historians challenged both the Whig and the Marxist theories, notably in the 1973 anthology "The Origins of the English Civil War" (Conrad Russell ed.). These historians focused on the minutiae of the years immediately before the civil war, returning to the contingency-based historiography of Clarendon's "History of the Rebellion and Civil Wars in England". This, it was claimed, demonstrated that patterns of war allegiance did not fit either Whig or Marxist theories. Parliament was not inherently progressive, nor the events of 1640 a precursor for the Glorious Revolution. Many members of the bourgeoisie fought for the King, while many landed aristocrats supported Parliament.

From the 1990s, a number of historians replaced the historical title "English Civil War" with "Wars of the Three Kingdoms" and "British Civil Wars", positing that the civil war in England cannot be understood apart from events in other parts of Britain and Ireland. King Charles I remains crucial, not just as King of England, but through his relationship with the peoples of his other realms. For example, the wars began when Charles forced an Anglican Prayer Book upon Scotland, and when this was met with resistance from the Covenanters, he needed an army to impose his will. However, this need of military funds forced Charles I to call an English Parliament, which was not willing to grant the needed revenue unless he addressed their grievances.

By the early 1640s, Charles was left in a state of near-permanent crisis management, confounded by the demands of the various factions. For example, Charles finally made terms with the Covenanters in August 1641, but although this might have weakened the position of the English Parliament, the Irish Rebellion of 1641 broke out in October 1641, largely negating the political advantage he had obtained by relieving himself of the cost of the Scottish invasion.

A number of revisionist historians such as William M. Lamont regarded the conflict as a religious war, with John Morrill (1993) stating: 'The English Civil War was not the first European revolution: it was the last of the Wars of Religion.' This view has been criticised by various pre-, post- and anti-revisionist historians. Glen Burgess (1998) examined political propaganda written by the Parliamentarian politicians and clerics at the time, noting that many were or may have been motivated by their Puritan religious beliefs to support the war against the 'Catholic' king Charles I, but tried to express and legitimise their opposition and rebellion in terms of a legal revolt against a monarch who had violated crucial constitutional principles and thus had to be overthrown. They even warned their Parliamentarian allies to not make overt use of religious arguments in making their case for war against the king.

However, in some cases it may be argued that they hid their pro-Anglican and anti-Catholic motives behind legal parliance, for example by emphasising that the Church of England was the "legally established" religion: 'Seen in this light, the defences of Parliament's war, with their apparent legal-constitutional thrust, are not at all ways of saying that the struggle was not religious. On the contrary, they are ways of saying that it was.' Burgess concluded: '[T]he Civil War left behind it just the sort of evidence that we could reasonably expect a war of religion to leave.'

Two large historical societies exist, The Sealed Knot and The English Civil War Society, which regularly re-enact events and battles of the Civil War in full period costume.


Attribution:



Elementary algebra

Elementary algebra, also known as college algebra, encompasses the basic concepts of algebra. It is often contrasted with arithmetic: arithmetic deals with specified numbers, whilst algebra introduces variables (quantities without fixed values).

This use of variables entails use of algebraic notation and an understanding of the general rules of the operations introduced in arithmetic: addition, subtraction, multiplication, division, etc. Unlike abstract algebra, elementary algebra is not concerned with algebraic structures outside the realm of real and complex numbers.

It is typically taught to secondary school students and at introductory college level in the United States, and builds on their understanding of arithmetic. The use of variables to denote quantities allows general relationships between quantities to be formally and concisely expressed, and thus enables solving a broader scope of problems. Many quantitative relationships in science and mathematics are expressed as algebraic equations.

Algebraic notation describes the rules and conventions for writing mathematical expressions, as well as the terminology used for talking about parts of expressions. For example, the expression formula_1 has the following components:

A "coefficient" is a numerical value, or letter representing a numerical constant, that multiplies a variable (the operator is omitted). A "term" is an addend or a summand, a group of coefficients, variables, constants and exponents that may be separated from the other terms by the plus and minus operators. Letters represent variables and constants. By convention, letters at the beginning of the alphabet (e.g. formula_2) are typically used to represent constants, and those toward the end of the alphabet (e.g. formula_3 and ) are used to represent variables. They are usually printed in italics.

Algebraic operations work in the same way as arithmetic operations, such as addition, subtraction, multiplication, division and exponentiation. and are applied to algebraic variables and terms. Multiplication symbols are usually omitted, and implied when there is no space between two variables or terms, or when a coefficient is used. For example, formula_4 is written as formula_5, and formula_6 may be written formula_7.

Usually terms with the highest power (exponent), are written on the left, for example, formula_8 is written to the left of . When a coefficient is one, it is usually omitted (e.g. formula_9 is written formula_8). Likewise when the exponent (power) is one, (e.g. formula_11 is written formula_12). When the exponent is zero, the result is always 1 (e.g. formula_13 is always rewritten to ). However formula_14, being undefined, should not appear in an expression, and care should be taken in simplifying expressions in which variables may appear in exponents.

Other types of notation are used in algebraic expressions when the required formatting is not available, or can not be implied, such as where only letters and symbols are available. As an illustration of this, while exponents are usually formatted using superscripts, e.g., formula_8, in plain text, and in the TeX mark-up language, the caret symbol represents exponentiation, so formula_8 is written as "x^2". This also applies to some programming languages such as Lua. In programming languages such as Ada, Fortran, Perl, Python and Ruby, a double asterisk is used, so formula_8 is written as "x**2". Many programming languages and calculators use a single asterisk to represent the multiplication symbol, and it must be explicitly used, for example, formula_12 is written "3*x".

Elementary algebra builds on and extends arithmetic by introducing letters called variables to represent general (non-specified) numbers. This is useful for several reasons.


Algebraic expressions may be evaluated and simplified, based on the basic properties of arithmetic operations (addition, subtraction, multiplication, division and exponentiation). For example,

An equation states that two expressions are equal using the symbol for equality, (the equals sign). One of the best-known equations describes Pythagoras' law relating the length of the sides of a right angle triangle:

This equation states that formula_39, representing the square of the length of the side that is the hypotenuse, the side opposite the right angle, is equal to the sum (addition) of the squares of the other two sides whose lengths are represented by and .

An equation is the claim that two expressions have the same value and are equal. Some equations are true for all values of the involved variables (such as formula_40); such equations are called identities. Conditional equations are true for only some values of the involved variables, e.g. formula_41 is true only for formula_42 and formula_43. The values of the variables which make the equation true are the solutions of the equation and can be found through equation solving.

Another type of equation is inequality. Inequalities are used to show that one side of the equation is greater, or less, than the other. The symbols used for this are: formula_44 where formula_45 represents 'greater than', and formula_46 where formula_47 represents 'less than'. Just like standard equality equations, numbers can be added, subtracted, multiplied or divided. The only exception is that when multiplying or dividing by a negative number, the inequality symbol must be flipped.

By definition, equality is an equivalence relation, meaning it is reflexive (i.e. formula_48), symmetric (i.e. if formula_49 then formula_50), and transitive (i.e. if formula_49 and formula_52 then formula_53). It also satisfies the important property that if two symbols are used for equal things, then one symbol can be substituted for the other in any true statement about the first and the statement will remain true. This implies the following properties:


The relations "less than" formula_47 and greater than formula_45 have the property of transitivity:
By reversing the inequation, formula_47 and formula_45 can be swapped, for example:

Substitution is replacing the terms in an expression to create a new expression. Substituting 3 for in the expression makes a new expression with meaning . Substituting the terms of a statement makes a new statement. When the original statement is true independently of the values of the terms, the statement created by substitutions is also true. Hence, definitions can be made in symbolic terms and interpreted through substitution: if formula_81 is meant as the definition of formula_82 as the product of with itself, substituting for informs the reader of this statement that formula_83 means . Often it's not known whether the statement is true independently of the values of the terms. And, substitution allows one to derive restrictions on the possible values, or show what conditions the statement holds under. For example, taking the statement , if is substituted with , this implies , which is false, which implies that if then cannot be .

If and are integers, rationals, or real numbers, then implies or . Consider . Then, substituting for and for , we learn or . Then we can substitute again, letting and , to show that if then or . Therefore, if , then or ( or ), so implies or or .

If the original fact were stated as " implies or ", then when saying "consider ," we would have a conflict of terms when substituting. Yet the above logic is still valid to show that if then or or if, instead of letting and , one substitutes for and for (and with , substituting for and for ). This shows that substituting for the terms in a statement isn't always the same as letting the terms from the statement equal the substituted terms. In this situation it's clear that if we substitute an expression into the term of the original equation, the substituted does not refer to the in the statement " implies or ."

The following sections lay out examples of some of the types of algebraic equations that may be encountered.

Linear equations are so-called, because when they are plotted, they describe a straight line. The simplest equations to solve are linear equations that have only one variable. They contain only constant numbers and a single variable without an exponent. As an example, consider:

To solve this kind of equation, the technique is add, subtract, multiply, or divide both sides of the equation by the same number in order to isolate the variable on one side of the equation. Once the variable is isolated, the other side of the equation is the value of the variable. This problem and its solution are as follows:
In words: the child is 4 years old.

The general form of a linear equation with one variable, can be written as: formula_85

Following the same procedure (i.e. subtract from both sides, and then divide by ), the general solution is given by formula_86

A linear equation with two variables has many (i.e. an infinite number of) solutions. For example:

That cannot be worked out by itself. If the son's age was made known, then there would no longer be two unknowns (variables). The problem then becomes a linear equation with just one variable, that can be solved as described above.

To solve a linear equation with two variables (unknowns), requires two related equations. For example, if it was also revealed that:

Now there are two related linear equations, each with two unknowns, which enables the production of a linear equation with just one variable, by subtracting one from the other (called the elimination method):

In other words, the son is aged 12, and since the father 22 years older, he must be 34. In 10 years, the son will be 22, and the father will be twice his age, 44. This problem is illustrated on the associated plot of the equations.

For other ways to solve this kind of equations, see below, System of linear equations.

A quadratic equation is one which includes a term with an exponent of 2, for example, formula_30, and no term with higher exponent. The name derives from the Latin "quadrus", meaning square. In general, a quadratic equation can be expressed in the form formula_92, where is not zero (if it were zero, then the equation would not be quadratic but linear). Because of this a quadratic equation must contain the term formula_93, which is known as the quadratic term. Hence formula_94, and so we may divide by and rearrange the equation into the standard form

where formula_96 and formula_97. Solving this, by a process known as completing the square, leads to the quadratic formula

where the symbol "±" indicates that both

are solutions of the quadratic equation.

Quadratic equations can also be solved using factorization (the reverse process of which is expansion, but for two linear terms is sometimes denoted foiling). As an example of factoring:

which is the same thing as

It follows from the zero-product property that either formula_102 or formula_103 are the solutions, since precisely one of the factors must be equal to zero. All quadratic equations will have two solutions in the complex number system, but need not have any in the real number system. For example,

has no real number solution since no real number squared equals −1.
Sometimes a quadratic equation has a root of multiplicity 2, such as:

For this equation, −1 is a root of multiplicity 2. This means −1 appears twice, since the equation can be rewritten in factored form as

All quadratic equations have exactly two solutions in complex numbers (but they may be equal to each other), a category that includes real numbers, imaginary numbers, and sums of real and imaginary numbers. Complex numbers first arise in the teaching of quadratic equations and the quadratic formula. For example, the quadratic equation

has solutions

Since formula_109 is not any real number, both of these solutions for "x" are complex numbers.

An exponential equation is one which has the form formula_110 for formula_111, which has solution

when formula_113. Elementary algebraic techniques are used to rewrite a given equation in the above way before arriving at the solution. For example, if

then, by subtracting 1 from both sides of the equation, and then dividing both sides by 3 we obtain

whence

or

A logarithmic equation is an equation of the form formula_118 for formula_111, which has solution

For example, if

then, by adding 2 to both sides of the equation, followed by dividing both sides by 4, we get

whence

from which we obtain

A radical equation is one that includes a radical sign, which includes square roots, formula_125 cube roots, formula_126, and "n"th roots, formula_127. Recall that an "n"th root can be rewritten in exponential format, so that formula_127 is equivalent to formula_129. Combined with regular exponents (powers), then formula_130 (the square root of cubed), can be rewritten as formula_131. So a common form of a radical equation is formula_132 (equivalent to formula_133) where and are integers. It has real solution(s):
For example, if:

then

and thus 

There are different methods to solve a system of linear equations with two variables.

An example of solving a system of linear equations is by using the elimination method:

Multiplying the terms in the second equation by 2:

Adding the two equations together to get:

which simplifies to

Since the fact that formula_102 is known, it is then possible to deduce that formula_143 by either of the original two equations (by using "2" instead of ) The full solution to this problem is then

This is not the only way to solve this specific system; could have been resolved before .

Another way of solving the same system of linear equations is by substitution.

An equivalent for can be deduced by using one of the two equations. Using the second equation:

Subtracting formula_147 from each side of the equation:

and multiplying by −1:

Using this value in the first equation in the original system:

Adding "2" on each side of the equation:

which simplifies to

Using this value in one of the equations, the same solution as in the previous method is obtained.

This is not the only way to solve this specific system; in this case as well, could have been solved before .

In the above example, a solution exists. However, there are also systems of equations which do not have any solution. Such a system is called inconsistent. An obvious example is

As 0≠2, the second equation in the system has no solution. Therefore, the system has no solution.
However, not all inconsistent systems are recognized at first sight. As an example, consider the system 

Multiplying by 2 both sides of the second equation, and adding it to the first one results in
which clearly has no solution.

There are also systems which have infinitely many solutions, in contrast to a system with a unique solution (meaning, a unique pair of values for and ) For example:

Isolating in the second equation:

And using this value in the first equation in the system:

The equality is true, but it does not provide a value for . Indeed, one can easily verify (by just filling in some values of ) that for any there is a solution as long as formula_160. There is an infinite number of solutions for this system.

Systems with more variables than the number of linear equations are called underdetermined. Such a system, if it has any solutions, does not have a unique one but rather an infinitude of them. An example of such a system is

When trying to solve it, one is led to express some variables as functions of the other ones if any solutions exist, but cannot express "all" solutions numerically because there are an infinite number of them if there are any.

A system with a higher number of equations than variables is called overdetermined. If an overdetermined system has any solutions, necessarily some equations are linear combinations of the others.


ERP

ERP or Erp may refer to:







Ernest Thayer

Ernest Lawrence Thayer (; August 14, 1863 – August 21, 1940) was an American writer and poet who wrote the poem "Casey" (or "Casey at the Bat"), which is "the single most famous baseball poem ever written" according to the Baseball Almanac, and "the nation’s best-known piece of comic verse—a ballad that began a native legend as colorful and permanent as that of Johnny Appleseed or Paul Bunyan."

Thayer was born in Lawrence, Massachusetts, and raised in nearby Worcester. He graduated "magna cum laude" in philosophy from Harvard University in 1885, where he had been editor of the "Harvard Lampoon" and a member of the theatrical society Hasty Pudding. William Randolph Hearst, a friend from both activities, hired Thayer as humor columnist for "The San Francisco Examiner" 1886–88.

Thayer's last piece for the "Examiner", dated June 3, 1888, was a ballad entitled "Casey" ("Casey at the Bat") which made him "a prize specimen of the one-poem poet" according to "American Heritage".

It was not until several months after the publication of the poem that Thayer became famous for it, since he was hardly the boastful type and had signed the June 24 poem with the nickname "Phin" which he had used since his time as a writer for the "Harvard Lampoon". Two mysteries remain about the poem: whether Casey and Mudville were based on a real person or place, and, if so, their actual identities. On March 31, 2007, Katie Zezima of "The New York Times" wrote an article called "In 'Casey' Rhubarb, 2 Cities Cry 'Foul!'" on the competing claims of two towns to such renown: Stockton, California, and Holliston, Massachusetts.
On the possible model for Casey, Thayer dismissed the notion that any single living baseball player was an influence. However, late 1880s Boston star Mike "King" Kelly is likely as a model for Casey's baseball situations. Besides being a native of a town close to Boston, Thayer, as a "San Francisco Examiner" baseball reporter in the off-season of 1887–88, covered exhibition games featuring Kelly. During November 1887, some of his reportage about a Kelly at-bat has the same ring as Casey's famous at-bat in the poem. A 2004 book by Howard W. Rosenberg, "Cap Anson 2: The Theatrical and Kingly Mike Kelly: U.S. Team Sport's First Media Sensation and Baseball's Original Casey at the Bat," reprints a 1905 Thayer letter to a Baltimore scribe who was asking about the poem's roots. In the letter, Thayer named Kelly (d. 1894), as having shown "impudence" in claiming to have inspired it. Rosenberg argues that if Thayer still felt offended, Thayer may have later denied Kelly as an influence. Kelly had also performed as a vaudeville actor, and recited the poem dozens of times.

The first public performance of the poem was on August 14, 1888, by actor De Wolf Hopper, on Thayer's 25th birthday. Thayer recited of the poem at a Harvard class reunion in 1895.

During the mid-1890s, Thayer contributed several other comic poems for Hearst's newspaper "New York Journal" and then began overseeing his family's mills in Worcester full-time. Thayer relocated to Santa Barbara in 1912, where he married Rosalind Buel Hammett and retired. He died in 1940, seven days after his 77th birthday.

"The New York Times"' obituary of Thayer on August 22, 1940, p. 19 quotes comedian DeWolf Hopper, who helped make the poem famous: 


List of English-language poets

This is a list of English-language poets, who have written much of their poetry in English. Main country of residence as a poet (not place of birth): A = Australia, Ag = Antigua, B = Barbados, Bo = Bosnia, C = Canada, Ch = Chile, Cu = Cuba, D = Dominica, De = Denmark, E = England, F = France, G = Germany, Ga = Gambia, Gd = Grenada, Gh = Ghana/Gold Coast, Gr = Greece, Gu = Guyana/British Guiana, Gy = Guernsey, HK = Hong Kong, In = India, IoM = Isle of Man, Is = Israel, Ir = Ireland, It = Italy, J = Jamaica, Je = Jersey, Jp = Japan, K = Kenya, L = Lebanon, M = Malta, Me = Mexico, Mo = Montserrat, Ne = Nepal, Nf = Newfoundland (colony), Ni = Nigeria, NI = Northern Ireland, Nt = Netherlands, NZ = New Zealand, P = Pakistan, Pa = Palestine, Ph = Philippines, PI = Pitcairn Islands, RE = Russian Empire, S = Scotland, SA = South Africa, Se = Serbia, SL = Saint Lucia, SLe = Sierra Leone, SLk = Sri Lanka, So = Somalia, Sw = Sweden, T = Trinidad and Tobago, US = United States/preceding colonies, W = Wales, Z = Zimbabwe/Rhodesia


















Excalibur

Excalibur is the mythical sword of King Arthur that may possess magical powers or be associated with the rightful sovereignty of Britain. Traditionally, the sword in the stone that is the proof of Arthur's lineage and the sword given him by a Lady of the Lake are not the same weapon, even as in some versions of the legend both of them share the name of Excalibur. Several similar swords and other weapons also appear within Arthurian texts, as well as in other legends.

The name "Excalibur" ultimately derives from the Welsh (Breton , Middle Cornish ), which is a compound of , , and , . Caledfwlch appears in several early Welsh works, including the prose tale "Culhwch and Olwen" (). The name was later used in Welsh adaptations of foreign material such as the s (chronicles), which were based on Geoffrey of Monmouth. It is often considered to be related to the phonetically similar , a sword borne by several figures from Irish mythology, although a borrowing of from the Irish has been considered unlikely by Rachel Bromwich and D. Simon Evans. They suggest instead that both names "may have similarly arisen at a very early date as generic names for a sword". In the late 15th to early 16th-century Middle Cornish play , Arthur's sword is called , which is etymologically an exact Middle Cornish cognate of the Welsh . It is unclear if the name was borrowed from the Welsh (if so, it must have been an early loan, for phonological reasons), or represents an early, pan-Brittonic traditional name for Arthur's sword.

Welsh author Geoffrey of Monmouth, in his Latin chronicle ("The History of the Kings of Britain", ), Latinised the name of Arthur's sword as (possibly influenced by the Medieval Latin spelling of Classical Latin , from the Greek (), ). Most Celticists consider Geoffrey's to be derivative of a lost Old Welsh text in which (Old Welsh ) had not yet been lenited to (Middle Welsh or ). Geoffrey Gaimar, in his Old French chronicle (1134–1140), mentions Arthur and his sword: "this Constantine was the nephew of Arthur, who had the sword Caliburc" (""). In Wace's (), composed in Old French, the sword is called (, , ), , , , , and (with additional variant spellings such as , , , , , found in various continental manuscripts). Various other spellings in the later medieval Arthurian literature have included "Calibourch", "Calibourn", "Calibourne", "Caliburc", "Escaliber", "Escalibur", "Excalibor", and finally the familiar "Excalibur".

Romance tradition elaborates on how Arthur came into possession of Excalibur. In Robert de Boron's c. 1200 French poem "Merlin", the first known tale to mention the "sword in the stone" motif, Arthur obtained the British throne by pulling a sword from an anvil sitting atop a stone that appeared in a churchyard on Christmas Eve. In this account, as foretold by Merlin, the act could not be performed except by "the true king", meaning the divinely appointed king or true heir of Uther Pendragon. (As Thomas Malory related in his English-language Arthurian compilation, the 15th-century "Le Morte d'Arthur", "whoso pulleth out this sword of this stone and anvil, is rightwise king born of all England.") The scene is set by different authors at either London (historical Londinium) or generally in the land of Logres, and might have been inspired by a miracle attributed to the 11th-century Bishop Wulfstan of Worcester. After many of the gathered nobles try and fail to complete Merlin's challenge, the teenage Arthur, who up to this point had believed himself to be biological son of Ector and went there as a squire to his foster brother Kay, succeeds effortlessly. Arthur first achieves this feat by accident while unaware of the contest and unseen. He then returns the sword to its place in the anvil on a stone, and later repeats the act publicly as Merlin comes to announce his true parentage.

The identity of this sword as Excalibur is made explicit in the Prose "Merlin", a part of the 13th-century "Lancelot-Grail" cycle of French romances also known as the Vulgate Cycle. Eventually, in the cycle's finale Vulgate "Mort Artu", when Arthur is at the brink of death, he enigmatically orders his surviving knight Griflet to cast Excalibur into a nearby lake. After two failed attempts to deceive Arthur, since Griflet felt that such a great sword should not be thrown away, he finally does comply with the wounded king's request. A woman's hand emerges from the lake to catch Excalibur, after which Morgan appears to take Arthur to Avalon. This motif then became attached to Bedivere (or Yvain in the chronicle "Scalacronica"), instead of Griflet, in the English Arthurian tradition. 

However, in the subsequent Post-Vulgate Cycle variants of the "Merlin" and the "Merlin Continuation", written soon afterwards, Arthur's sword drawn from the stone is unnamed. Furthermore, the young Arthur promptly breaks it in his duel against King Pellinore very early in his reign. On Merlin's advice, Arthur then goes with him to be given the actual Excalibur by a Lady of the Lake in exchange for a later boon for her (some time later, she arrives at Arthur's court to demand the head of Balin). In the Post-Vulgate "Mort Artu", it is this sword that is eventually hurled into the pool at Camlann (or actually Salisbury Plain where both cycles locate the battle, as do the English romances) by Griflet in the same circumstances as told in the story's Vulgate version. Malory included both of these stories in his now-iconic "Le Morte d'Arthur" while naming each of the swords as Excalibur: both the first one (from the stone) soon shattered in combat in the story taken from the Post-Vulgate "Merlin Continuation", and its replacement (from the lake) thrown away by Bedivere in the end.

In the Welsh tales, Arthur's sword is known as "Caledfwlch". In "Culhwch and Olwen", it is one of Arthur's most valuable possessions and is used by Arthur's warrior Llenlleawg the Irishman to kill the Irish king Diwrnach while stealing his magical cauldron. Though not named as Caledfwlch, Arthur's sword is described vividly in "The Dream of Rhonabwy", one of the tales associated with the "Mabinogion" (as translated by Jeffrey Gantz): "Then they heard Cadwr Earl of Cornwall being summoned, and saw him rise with Arthur's sword in his hand, with a design of two chimeras on the golden hilt; when the sword was unsheathed what was seen from the mouths of the two chimeras was like two flames of fire, so dreadful that it was not easy for anyone to look."

Geoffrey's "Historia" is the first non-Welsh text to speak of the sword. Geoffrey says the sword was forged in Avalon and Latinises the name Caledfwlch as "Caliburnus". When his influential pseudo-history made it to continental Europe, writers altered the name further until it finally took on the popular form "Excalibur". Its role was expanded upon in the Vulgate Cycle and in the Post-Vulgate Cycle which emerged in its wake. Both of these prose cycles incorporated the Prose "Merlin", however the Post-Vulgate authors left out the original "Merlin" continuation from the earlier cycle, choosing to add an original account of Arthur's early days including a new origin for Excalibur. In some versions, Excalibur's blade was engraved with phrases on opposite sides: "Take me up" and "Cast me away" (or similar). In addition, it said that when Excalibur was first drawn in combat, in the first battle testing Arthur's sovereignty, its blade shone so bright it blinded his enemies.

In Chrétien de Troyes' late 12th-century Old French "Perceval", Arthur's nephew and best knight Gawain carries Excalibur, "for at his belt hung Escalibor, the finest sword that there was, which sliced through iron as through wood" (""). This statement was probably picked up by the author of the "Estoire Merlin", or Vulgate "Merlin", where the author asserts that Escalibor "is a Hebrew name which means in French 'cuts iron, steel, and wood (""; the word for 'steel' here, "achier", also means 'blade' or 'sword') and comes from medieval Latin , a derivative of 'sharp', so there is no direct connection with Latin ). It is from this fanciful etymological musing that Thomas Malory got the notion that Excalibur meant 'cut steel' ("the name of it,' said the lady, 'is Excalibur, that is as moche to say, as cut stele").

In the Post-Vulgate version, used in Malory's "Le Morte d'Arthur" for the second Excalibur, the sword's scabbard is also said to have powers of its own, as any wounds received while wearing it would not bleed at all, thus preventing the wearer from ever bleeding to death in battle. For this reason, Merlin chides Arthur for preferring Excalibur over its sheath, saying that the latter is the greater treasure. The scabbard is, however, soon stolen from Arthur by his half-sister Morgan le Fay in revenge for the death of her beloved Accolon, he having been slain by Arthur with Excalibur in a duel involving a false Excalibur (Morgan also secretly makes at least one duplicate of Excalibur during the time when the sword is entrusted to her by Arthur earlier in the different French, Iberian and English variants of that story). During Morgan's flight from the pursuit by Arthur, the sheath is then thrown by her into a deep lake and lost. This act later enables the death of Arthur, deprived of its magical protection, many years later in his final battle. In Malory's telling, the scabbard is never found again. In the Post-Vulgate, however, it is recovered and claimed by another fay, Marsique, who then briefly gives it to Gawain to help him fight Naborn the Enchanter (a Mabon figure).

As mentioned above, Excalibur is wielded also by Gawain in some French romances, including the Vulgate "Lancelot". The Prose "Merlin" also uniquely tells of Gawain killing the Roman leader Lucius with Excalibur. This is, however, in contrast to most versions, where Excalibur belongs solely to Arthur. A few texts, such as the English Alliterative "Morte Arthure" and one copy of the Welsh "Ymddiddan Arthur a'r Eryr", tell of Arthur using Excalibur to kill his son Mordred (in the first of these, he also uses it to kill Lucius). In the Iberian post-Arthurian romance "Florambel de Lucea", Morgan later gifts Excalibur ("Esclariber") to the eponymous hero. Another late Iberian romance, "Tirant lo Blanch", features Arthur who was brought back to life by Morgan and then wandered the world for a long time while mad and able to talk only when having Excalibur in his hands. Finally, Morgan finds her brother imprisoned in the contemporary (15th-century) Constantinople, where she restores him to his mind by making him gaze upon his reflection in Excalibur's blade.

The challenge of drawing a sword from a stone (placed on the river just outside Camelot) also appears in the later Arthurian story of Galahad, whose achievement of the task indicates that he is destined to find the Holy Grail, as also foretold in Merlin's prophecies. This powerful yet cursed weapon, known as the Adventurous Sword among other names, has also come from Avalon; it is first stolen and wielded by Balin until his death while killing his own brother, then is briefly taken up by Galahad, and eventually is used by Lancelot to give his former friend Gawain a mortal wound in their long final duel. In the Old French "Perlesvaus", Lancelot pulls other weapons from stone on two occasions. In the Post-Vulgate "Merlin", Morgan creates the copies of Excalibur itself as well as of its scabbard.

In Welsh mythology, the Dyrnwyn ("White-Hilt"), one of the Thirteen Treasures of the Island of Britain, is said to be a powerful sword belonging to Rhydderch Hael, one of the Three Generous Men of Britain mentioned in the Welsh Triads. When drawn by a worthy or well-born man, the entire blade would blaze with fire. Rhydderch was never reluctant to hand the weapon to anyone, hence his nickname Hael "the Generous", but the recipients, as soon as they had learned of its peculiar properties, always rejected the sword. There are other similar weapons described in other mythologies as well. Irish mythology features Caladbolg, the sword of Fergus mac Róich, which was also known for its incredible power and was carried by some of Ireland's greatest heroes. The name, which can also mean "hard cleft" in Irish, appears in the plural, "caladbuilc", as a generic term for "great swords" in "Togail Troi" ("The Destruction of Troy"), a 10th-century Irish translation of the classical tale. A sword named Claíomh Solais, which is an Irish term meaning "sword of light", or "shining sword", appears in a number of orally transmitted Irish folk-tales. The Sword in the Stone has an analogue in some versions of the story of Sigurd, whose father, Sigmund, draws the sword Gram out of the tree Barnstokkr where it is embedded by the Norse god Odin. Apart from legendary swords, the only real ancient Sword in the Stone which still exists nowadays, is kept since the medieval ages in the Chapel of Saint Galgano at Montesiepi, in Siena Province, Tuscany, Italy and is associated with the 12th-century Italian legend of that Saint, in the tale of "Tuscany's Excalibur".

A number of different swords and other weapons have been also associated with Arthur. In the Alliterative "Morte Arthure", Clarent is the royal sword of peace meant for knighting and ceremonies as opposed to battle, which Mordred stole and then used to kill Arthur at Camlann. The Prose "Lancelot" of the Vulgate Cycle mentions a sword called Sequence (also "Secace" or "Seure") as borrowed from Arthur by Lancelot. In the Vulgate "Merlin", Arthur captures Marmiadoise (Marmydoyse), the marvelous sword of Hercules, from the latter's descendant King Rions. Marmiadoise's powers (such as causing wounds that would never heal) are in fact so superior compared to those of Excalibur that Arthur gives his old sword to Gawain.

Early-Arthurian Welsh tradition knew of a dagger named Carnwennan and a spear named Rhongomyniad that belonged to him. Carnwennan ("little white-hilt") first appears in "Culhwch and Olwen", where Arthur uses it to slice the witch Orddu in half. Rhongomyniad ("spear" + "striker, slayer") is also mentioned in "Culhwch", although only in passing; it appears as simply Ron ("spear") in Geoffrey's "Historia". Geoffrey also names Arthur's shield as Pridwen; in "Culhwch", however, Prydwen ("fair face") is the name of Arthur's ship while his shield is named Wynebgwrthucher ("face of evening").

Historically, a sword identified as Excalibur (Caliburn) was supposedly discovered during the exhumation of Arthur's purported grave at Glastonbury Abbey in 1191. On 6 March 1191, after the Treaty of Messina, either this or another claimed Excalibur was given as a gift of goodwill by the English king Richard I of England (Richard the Lionheart) to his ally Tancred, King of Sicily. It was one of a series of symbolic Arthurian acts by the Anglo-Norman monarchs, such as their association of the crown of King Arthur with the crown they won from the slain Welsh prince Llywelyn ap Gruffudd.





Eight-bar blues

In music, an eight-bar blues is a common blues chord progression. Music writers have described it as "the second most common blues form" being "common to folk, rock, and jazz forms of the blues". It is often notated in or time with eight bars to the verse.

Early examples of eight-bar blues standards include:
One variant using this progression is to couple one eight-bar blues melody with a different eight-bar blues bridge to create a blues variant of the standard 32-bar song: "I Want a Little Girl" (T-Bone Walker) and "Great Balls of Fire" (Jerry Lee Lewis)(

Eight-bar blues progressions have more variations than the more rigidly defined twelve bar format. The move to the IV chord usually happens at bar 3 (as opposed to 5 in twelve bar); however, "the I chord moving to the V chord right away, in the second measure, is a characteristic of the eight-bar blues."

In the following examples each box represents a 'bar' of music (the specific time signature is not relevant). The chord in the box is played for the full bar. If two chords are in the box they are each played for half a bar, etc. The chords are represented as scale degrees in Roman numeral analysis. Roman numerals are used so the musician may understand the progression of the chords regardless of the key it is played in.

"Eight-bar blues chord progression":

"Worried Life Blues" (probably the most common eight-bar blues progression):

"Heartbreak Hotel" (variation with the I on the first half):

J. B. Lenoir's "Slow Down" and "Key to the Highway" (variation with the V at bar 2):

"Get a Haircut" by George Thorogood (simple progression):

Jimmy Rogers' "Walkin' By Myself" (somewhat unorthodox example of the form):

Howlin Wolf's version of "Sitting on Top of the World" is actually a 9 bar blues that adds an extra "V" chord at the end of the progression. The song uses movement between major and dominant 7th and major and minor fourth:

The first four bar progression used by Wolf is also used in Nina Simone's 1965 version of "Trouble in Mind", but with a more uptempo beat than "Sitting on Top of the World":

The progression may be created by dropping the first four bars from the twelve-bar blues, as in the solo section of Bonnie Raitt's "Love Me Like a Man" and Buddy Guy's "Mary Had a Little Lamb":

There are at least a few very successful songs using somewhat unusual chord progressions as well. For example, the song "Ain't Nobody's Business" as performed by Freddie King at least, uses a I–III–IV–iv progression in each of the first four bars. The same four bar progression is used by the band Radiohead to make up the bulk of the song "Creep".

The same chord progression can also be called a sixteen-bar blues, if each symbol above is taken to be a half note in or time. Examples are "Nine Pound Hammer" and Ray Charles's original instrumental "Sweet Sixteen Bars".


Echidna (disambiguation)

Echidnas are Australian egg-laying mammals also known as spiny anteaters.

Echidna may also refer to:




Edward Waring

Edward Waring (15 August 1798) was a British mathematician. He entered Magdalene College, Cambridge as a sizar and became Senior wrangler in 1757. He was elected a Fellow of Magdalene and in 1760 Lucasian Professor of Mathematics, holding the chair until his death. He made the assertion known as Waring's problem without proof in his writings "Meditationes Algebraicae". Waring was elected a Fellow of the Royal Society in 1763 and awarded the Copley Medal in 1784.

Waring was the eldest son of John and Elizabeth Waring, a prosperous farming couple. He received his early education in Shrewsbury School under a Mr Hotchkin and was admitted as a sizar at Magdalene College, Cambridge, on 24 March 1753, being also Millington exhibitioner. 

His extraordinary talent for mathematics was recognised from his early years in Cambridge. In 1757 he graduated BA as senior wrangler and on 24 April 1758 was elected to a fellowship at Magdalene. He belonged to the Hyson Club, whose members included William Paley.

At the end of 1759 Waring published the first chapter of "Miscellanea Analytica". On 28 January the next year he was appointed Lucasian professor of mathematics, one of the highest positions in Cambridge. William Samuel Powell, then tutor in St John's College, Cambridge opposed Waring's election and instead supported the candidacy of William Ludlam. In the polemic with Powell, Waring was backed by John Wilson. In fact Waring was very young and did not hold the MA, necessary for qualifying for the Lucasian chair, but this was granted him in 1760 by royal mandate. In 1762 he published the full "Miscellanea Analytica", mainly devoted to the theory of numbers and algebraic equations. In 1763 he was elected to the Royal Society. He was awarded its Copley Medal in 1784 but withdrew from the society in 1795, after he had reached sixty, 'on account of [his] age'. Waring was also a member of the academies of sciences of Göttingen and Bologna. In 1767 he took an MD degree, but his activity in medicine was quite limited. He carried out dissections with Richard Watson, professor of chemistry and later bishop of Llandaff. From about 1770 he was physician at Addenbrooke's Hospital at Cambridge, and he also practised at St Ives, Huntingdonshire, where he lived for some years after 1767. His career as a physician was not very successful since he was seriously short-sighted and a very shy man.

Waring had a younger brother, Humphrey, who obtained a fellowship at Magdalene in 1775. In 1776 Waring married Mary Oswell, sister of a draper in Shrewsbury; they moved to Shrewsbury and then retired to Plealey, 8 miles out of the town, where Waring owned an estate of 215 acres in 1797

Waring wrote a number of papers in the "Philosophical Transactions of the Royal Society", dealing with the resolution of algebraic equations, number theory, series, approximation of roots, interpolation, the geometry of conic sections, and dynamics. The "Meditationes Algebraicae" (1770), where many of the results published in "Miscellanea Analytica" were reworked and expanded, was described by Joseph-Louis Lagrange as 'a work full of excellent researches'. In this work Waring published many theorems concerning the solution of algebraic equations which attracted the attention of continental mathematicians, but his best results are in number theory. Included in this work was the so-called Goldbach conjecture (every even integer is the sum of two primes), and also the following conjecture: every odd integer is a prime or the sum of three primes. Lagrange had proved that every positive integer is the sum of not more than four squares; Waring suggested that every positive integer is either a cube or the sum of not more than nine cubes. He also advanced the hypothesis that every positive integer is either a biquadrate (fourth power) or the sum of not more than nineteen biquadrates. These hypotheses form what is known as Waring's problem. He also published a theorem, due to his friend John Wilson, concerning prime numbers; it was later proven rigorously by Lagrange.

In "Proprietates Algebraicarum Curvarum" (1772) Waring reissued in a much revised form the first four chapters of the second part of "Miscellanea Analytica". He devoted himself to the classification of higher plane curves, improving results obtained by Isaac Newton, James Stirling, Leonhard Euler, and Gabriel Cramer. In 1794 he published a few copies of a philosophical work entitled "An Essay on the Principles of Human Knowledge", which were circulated among his friends.

Waring's mathematical style is highly analytical. In fact he criticised those British mathematicians who adhered too strictly to geometry. It is indicative that he was one of the subscribers of John Landen's "Residual Analysis" (1764), one of the works in which the tradition of the Newtonian fluxional calculus was more severely criticised. In the preface of "Meditationes Analyticae" Waring showed a good knowledge of continental mathematicians such as Alexis Clairaut, Jean le Rond d'Alembert, and Euler. He lamented the fact that in Great Britain mathematics was cultivated with less interest than on the continent, and clearly desired to be considered as highly as the great names in continental mathematics—there is no doubt that he was reading their work at a level never reached by any other eighteenth-century British mathematician. Most notably, at the end of chapter three of "Meditationes Analyticae" Waring presents some partial fluxional equations (partial differential equations in Leibnizian terminology); such equations are a mathematical instrument of great importance in the study of continuous bodies which was almost completely neglected in Britain before Waring's researches. One of the most interesting results in "Meditationes Analyticae" is a test for the convergence of series generally attributed to d'Alembert (the 'ratio test'). The theory of convergence of series (the object of which is to establish when the summation of an infinite number of terms can be said to have a finite 'sum') was not much advanced in the eighteenth century.

Waring's work was known both in Britain and on the continent, but it is difficult to evaluate his impact on the development of mathematics. His work on algebraic equations contained in "Miscellanea Analytica" was translated into Italian by Vincenzo Riccati in 1770. Waring's style is not systematic and his exposition is often obscure. It seems that he never lectured and did not habitually correspond with other mathematicians. After Jérôme Lalande in 1796 observed, in "Notice sur la vie de Condorcet", that in 1764 there was not a single first-rate analyst in England, Waring's reply, published after his death as 'Original letter of Dr Waring' in the "Monthly Magazine", stated that he had given 'somewhere between three and four hundred new propositions of one kind or another'.

During his last years he sank into a deep religious melancholy, and a violent cold caused his death, in Plealey, on 15 August 1798. He was buried in the churchyard at Fitz, Shropshire.


Eden Phillpotts

Eden Phillpotts (4 November 1862 – 29 December 1960) was an English author, poet and dramatist. He was born in Mount Abu, India, was educated in Plymouth, Devon, and worked as an insurance officer for ten years before studying for the stage and eventually becoming a writer.

Eden Phillpotts was a great-nephew of Henry Phillpotts, Bishop of Exeter. His father Henry Phillpotts was a son of the bishop's younger brother Thomas Phillpotts. James Surtees Phillpotts the reforming headmaster of Bedford School was his second cousin.

Eden Phillpotts was born on 4 November 1862 at Mount Abu in Rajasthan. His father Henry was an officer in the Indian Army, while his mother Adelaide was the daughter of an Indian Civil Service officer posted in Madras, George Jenkins Waters.

Henry Phillpotts died in 1865, leaving Adelaide a widow at the age of 21. With her three small sons, of whom Eden was the eldest, she returned to England and settled in Plymouth.

Phillpotts was educated at Mannamead School in Plymouth. At school he showed no signs of a literary bent. In 1879, aged 17, he left home and went to London to earn his living. He found a job as a clerk with the Sun Fire Office.

Phillpotts' ambition was to be an actor and he attended evening classes at a drama school for two years. He came to the conclusion that he would never make a name as an actor but might have success as a writer. In his spare time out of office hours he proceeded to create a stream of small works which he was able to sell. In due course he left the insurance company to concentrate on his writing, while also working part-time as assistant editor for the weekly "Black and White" magazine.

Eden Phillpotts maintained a steady output of three or four books a year for the next half century. He produced poetry, short stories, novels, plays and mystery tales. Many of his novels were about rural Devon life and some of his plays were distinguished by their effective use of regional dialect.

Eden Phillpotts died at his home in Broadclyst near Exeter, Devon, on 29 December 1960.

Phillpotts was for many years the President of the Dartmoor Preservation Association and cared passionately about the conservation of Dartmoor. He was an agnostic and a supporter of the Rationalist Press Association.

Phillpotts was a friend of Agatha Christie, who was an admirer of his work and a regular visitor to his home. She dedicated her 1932 novel "Peril at End House" to Phillpotts, and in her autobiography, she expressed gratitude for his early advice on fiction writing and quoted some of it. Jorge Luis Borges was another Phillpotts admirer. Borges mentioned him numerous times, wrote at least two reviews of his novels, and included him in his "Personal Library", a collection of works selected to reflect his personal literary preferences.

Philpotts allegedly sexually abused his daughter Adelaide. In a 1976 interview for a book about her father, Adelaide described an incestuous "relationship" with him that she says lasted from the age of five or six until her early thirties, when he remarried. When she herself finally married at the age of 55 her father never forgave her, and never communicated with her again.

Phillpotts wrote a great many books with a Dartmoor setting. One of his novels, "Widecombe Fair" (1913), inspired by an annual fair at the village of Widecombe-in-the-Moor, provided the scenario for his comic play "The Farmer's Wife" (1916). It went on to become a 1928 silent film of the same name, directed by Alfred Hitchcock. It was followed by a 1941 remake, directed by Norman Lee and Leslie Arliss. It became a BBC TV drama in 1955, directed by Owen Reed. Jan Stewer played Churdles Ash. The BBC had broadcast the play in 1934.

He co-wrote several plays with his daughter Adelaide Phillpotts, "The Farmer's Wife" and "Yellow Sands" (1926); she later claimed their relationship was incestuous. Eden is best known as the author of many novels, plays and poems about Dartmoor. His Dartmoor cycle of 18 novels and two volumes of short stories still has many avid readers despite the fact that many titles are out of print.

Philpotts also wrote a series of novels, each set against the background of a different trade or industry. Titles include: "Brunel's Tower" (a pottery) and "Storm in a Teacup" (hand-papermaking). Among his other works is "The Grey Room", the plot of which is centred on a haunted room in an English manor house. He also wrote a number of other mystery novels, both under his own name and the pseudonym Harrington Hext. These include: "The Thing at Their Heels", "The Red Redmaynes", "The Monster", "The Clue from the Stars", and "The Captain's Curio". "The Human Boy" was a collection of schoolboy stories in the same genre as Rudyard Kipling's "Stalky & Co.", though different in mood and style. Late in his long writing career he wrote a few books of interest to science fiction and fantasy readers, the most noteworthy being "Saurus", which involves an alien reptilian observing human life.

Eric Partridge praised the immediacy and impact of his dialect writing.

Novels

Short Fiction Books

Poetry

Plays

Nonfiction



Ecuador–United States relations

Ecuador and the United States maintained close ties based on mutual interests in maintaining democratic institutions; combating cannabis and cocaine; building trade, investment, and financial ties; cooperating in fostering Ecuador's economic development; and participating in inter-American organizations. Ties are further strengthened by the presence of an estimated 150,000-200,000 Ecuadorians living in the United States and by 24,000 U.S. citizens visiting Ecuador annually, and by approximately 15,000 U.S. citizens living in Ecuador.

Relations between the two nations have been strained following Julian Assange's bid to seek political asylum in the Ecuadorian embassy in London following repeated claims that the US government was pursuing his extradition due to his work with Wikileaks.

Both nations were early signatories of the Inter-American Treaty of Reciprocal Assistance (the "Rio Treaty") of 1947, the Western Hemisphere's regional mutual security treaty. However, under the Correa administration, Ecuador denounced the treaty in February 2014, a legal prerequisite by which Ecuador would leave the treaty in 2016. Ecuador shares U.S. concern over increasing narcotrafficking and international terrorism and has energetically condemned terrorist actions, whether directed against government officials or private citizens. The government has maintained Ecuador virtually free of coca production since the mid-1980s and is working to combat money laundering and the transhipment of drugs and chemicals essential to the processing of cocaine.

According to CIA critic and former CIA agent who was stationed in Ecuador Philip Agee, the CIA carried out extensive operations and political manipulation in Ecuador in the early 1960s.

Ecuador and the U.S. agreed in 1999 to a 10-year arrangement whereby U.S. military surveillance aircraft could use the airbase at Manta, Ecuador, as a "Forward Operating Location" to detect drug trafficking flights through the region. The arrangement expired in 2009; former president Rafael Correa vowed not to renew it, and since then the Ecuador has not had any foreign military facilities in the country.

In fisheries issues, the United States claims jurisdiction for the management of coastal fisheries up to 200 mile (370 km) from its coast, but excludes highly migratory species; Ecuador, on the other hand, claims a 200-mile (370-km) territorial sea, and imposes license fees and fines on foreign fishing vessels in the area, making no exceptions for catches of migratory species. In the early 1970s, Ecuador seized about 100 foreign-flag vessels (many of them U.S.) and collected fees and fines of more than $6 million. After a drop-off in such seizures for some years, several U.S. tuna boats were again detained and seized in 1980 and 1981.

The U.S. Magnuson Fishery Conservation and Management Act then triggered an automatic prohibition of U.S. imports of tuna products from Ecuador. The prohibition was lifted in 1983, and although fundamental differences between U.S. and Ecuadorian legislation still exist, there is no current conflict. During the period that has elapsed since seizures which triggered the tuna import ban, successive Ecuadorian governments have declared their willingness to explore possible solutions to this problem with mutual respect for longstanding positions and principles of both sides. The election of Rafael Correa in October 2006, has strained relations between the two countries and relations have since been fraught with tension. Rafael Correa was heavily critical of U.S. foreign policy whilst in office.

In April 2011, relations between Ecuador and the United States soured particularly after Ecuador expelled the U.S. ambassador after a leaked diplomatic cable was shown accusing president Correa of knowingly ignoring police corruption. In reciprocation, the Ecuadorian ambassador Luis Gallegos was expelled from the United States.

In 2013, when Ecuador unilaterally pulled out of a preferential trade pact with the United States over claiming the U.S. used it as blackmail in regards to the asylum request of Edward Snowden, relations between Ecuador and the United States reached an all-time low. The pact offered Ecuador US$23 million, which it offered to the U.S. for human rights training. Tariff free imports had been offered to Ecuador in exchange for drug elimination efforts.

Julian Assange applied for Ecuadorian citizenship on 16 September 2017, which Ecuador granted on 12 December 2017. However, this development was not announced until 25 January 2018.

In April 2019, Assange was arrested by the Metropolitan Police. President of Ecuador, Lenin Moreno, stated that he had 'violated the terms of his asylum'. British Foreign Secretary, Jeremy Hunt stated that the British and Ecuadorian governments had been co-operating since Moreno's inauguration and aimed to resolve the situation. Assange extradition to the United States was denied, due to a combination of his ill health and the nature of the US carceral system.

The relations with the United States improved significantly during the presidency of Lenin Moreno since 2017. In February 2020, his visit to Washington was the first meeting between an Ecuadorian and U.S. president in 17 years. In June 2019, Ecuador had agreed to allow US military planes to operate from an airport on the Galapagos Islands.

American schools in Ecuador:





Eight-ball

Eight-ball (also spelled 8-ball or eightball, and sometimes called solids and stripes, spots and stripes, big ones and little ones, or rarely highs and lows) is a discipline of pool played on a billiard table with six pockets, cue sticks, and sixteen billiard balls (a and fifteen s). The object balls include seven solid-colored balls numbered 1 through 7, seven striped balls numbered 9 through 15, and the black 8 ball. After the balls are scattered with a shot, a player is assigned either the group of solid or striped balls once they have legally pocketed a ball from that group. The object of the game is to legally pocket the 8-ball in a "called" pocket, which can only be done after all of the balls from a player's assigned group have been cleared from the table.

The game is the most frequently played discipline of pool, and is often thought of as synonymous with "pool". The game has numerous variations, mostly regional. It is the second most played professional pool game, after nine-ball, and for the last several decades ahead of straight pool.

The game of eight-ball arose around 1900 in the United States as a development of pyramid pool, which allows any eight of the fifteen object balls to be pocketed to win. The game arose from two changes made, namely that the 8 ball must be pocketed last to win, and that each player may pocket only half of the other object balls. By 1925, the game was popular enough for the Brunswick-Balke-Collender Company to introduce purpose-made ball sets with seven , seven , one , and the cue ball, which allowed spectators to more easily see which suit each ball belonged to. (Such colors became standard in the later British-originating variant, blackball.) The rules, as officially codified in the Billiard Congress of America's rule book, were periodically revised in the years following.

American-style eight-ball rules are played around the world by professionals and in many amateur leagues. Nevertheless, the rules for eight-ball may be the most inconsistent of any billiard game, as there are several competing sets of "official" rules.

The World Pool-Billiard Association (WPA), the governing body of pool which has continental and national affiliates around the world, promulgates standardized rules as "Pool Billiards – The Rules of Play". These are used for amateur and professional play.

Meanwhile, many amateur leagues – such as the American Poolplayers Association (APA) and its affiliate the Canadian Poolplayers Association (CPA), the Valley National Eight-ball Association (VNEA) and the BCA Pool League (BCAPL) – use their own rulesets which have slight differences from WPA rules and from each other. Millions of individuals play casually, using informal "house rules" which vary not only from area to area but even from venue to venue.

The regulation size of the table's playing surface is , though exact dimensions may vary slightly by manufacturer. Some leagues and tournaments using the World Standardized Rules may allow smaller sizes, down to . Early 20th-century models are occasionally also still used. WPA professional competition generally employs regulation tables, while the amateur league championships of various leagues, including BCAPL, VNEA, and APA, use the seven-foot tables in order to fit more of them into the hosting venue.

There are seven numbered 1 through 7, seven numbered 9 through 15, an , and a . The balls are usually colored as follows:

Special sets designed to be more easily discernible on television substitute pink for the dark purple of the 4 and 12 and light tan for the darker maroon of the 7 and 15 balls, and these alternative-color sets are now also available to consumers.

To start the game, the s are placed in a triangular rack. The base of the rack is parallel to the (the short end of the pool table) and positioned so the apex ball of the rack is located on the . The balls in the rack are ideally placed so that they are all in contact with one another; this is accomplished by pressing the balls together toward the apex ball. The order of the balls should be random, with the exceptions of the 8-ball, which must be placed in the center of the rack (i.e., the middle of the third row), and the two back corner balls, one of which must be a stripe and the other a solid. The cue ball is placed anywhere the breaker desires behind the .

One person is chosen by some predetermined method (e.g., coin toss, , or win or loss of previous game or match) to shoot first, using the cue ball to the object-ball rack apart. In most leagues it is the breaker's opponent who racks the balls, but in some, players break their own racks. If the breaker fails to make a successful break—usually defined as at least four balls hitting cushions or an object ball being pocketed—then the opponent can opt either to play from the current position or to call for a and either re-break or have the original breaker repeat the break.
If the 8 ball is pocketed on the break, then the breaker can choose either to the 8 ball and play from the current position or to re-rack and re-break; but if the cue ball is also pocketed on the break then the opponent is the one who has the choice: either to re-spot the 8 ball and shoot with behind the , accepting the current position, or to re-break or have the breaker re-break.

A player (or team) continues to shoot until committing a or failing to legally pocket an object ball (whether or not); thereupon it is the turn of the opposing players. Play alternates in this manner for the remainder of the game. Following a foul, the incoming player has anywhere on the table, unless the foul occurred on the break shot, as noted previously.

The table is "open" at the start of the game, meaning that either player may shoot at any ball. It remains open until one player legally pockets any called ball other than the 8 after the break. That player is assigned the "group", or "suit", of the pocketed and the other suit is assigned to the opponent. Balls pocketed on the break, or as the result of a foul while the table is still open, are not used to assign the suits. Once the suits are assigned, they remain fixed throughout the game. If any balls from a player's suit are on the table, the player must hit one of them first on every shot; otherwise a foul is called and the turn ends. After all balls from the suit have been pocketed, the player's target becomes the 8 for the remainder of the game.

Once all of a player's (or team's) group of object balls are pocketed, the player attempts to sink the 8 ball. In order to win the game, the player first designates which pocket the 8 ball will be pocketed into and then successfully pockets the 8 ball into that pocket. If the player knocks the 8 ball off the table, the player loses the game. If the player pockets the 8 ball and commits a foul or pockets it into another pocket than the one designated, the player loses the game. Otherwise (i.e., if the 8 ball is neither pocketed nor knocked off the table), the shooter's turn is simply over, even if a foul occurs. In short, a world-standardized rules game of eight-ball, like a game of nine-ball, is not over until the "" is no longer on the table. The rule has been increasingly adopted by amateur leagues.

A player wins the game if that player legally pockets the 8 ball into a designated pocket after all of their object balls have been pocketed. Because of this, it is possible for a game to end with only one of the players having shot, which is known as "running the table" or a "denial"; conversely, it's also possible to win a game "without" taking a shot; such a scenario may occur if the opposing player illegally pockets the 8 ball on any shot other than the break (such as sinking the 8 ball in an uncalled pocket, knocking the 8 ball off the table, sinking the 8 ball when a player is not yet on the black ball, or sinking both the 8 ball and the cue ball off a single shot). The rules on what happens when the 8 ball is pocketed off the break vary by the rules in question .

The general rules of pool apply to eight-ball, such as the requirements that the cue ball not be pocketed and that a cushion be hit by any of the balls after the cue ball has struck an object ball. Fouls specific to eight-ball are:

The British version of eight-ball, known internationally as either blackball or simply eight-ball, has evolved into a separate game, retaining significant elements of earlier pub versions of the game, with additional influences from English billiards and snooker. It is popular in amateur and professional competition in the UK, Ireland, Australia and some other countries.

The game uses unnumbered, solid-colored object balls, typically red and yellow, with one black 8 ball. They are usually or in diameter, the latter being the same size as the balls used in snooker and English billiards. Tables are usually long, and feature pockets with rounded cushion openings, like snooker tables. Smaller tables are sometimes used in places where a larger table would be too large.

The rules of blackball differ from standard eight-ball in numerous ways, including the handling of fouls, which may give the opponent two shots, racking (the 8 ball, not the apex ball, goes on the spot), selection of which group of balls will be shot by which player, handling of balls and s, and many other details.

Internationally, the World Pool-Billiard Association and the World Eightball Pool Federation both publish rules and promote events. The two rule sets differ in some details regarding the penalties for fouls.

The version of eight-ball played in China uses rules that are essentially the same as standard WPA rules; and the game is played with standard solids-and-stripes balls. However, the tables are constructed similarly to snooker tables, with rounded pocket openings, napped cloth and flat-faced rail cushions. This results in some differences in gameplay approach. The variant arose in the mid-1980s and 1990s as eight-ball gained popularity in China, where snooker was the most popular cue sport at the time. With standard American-style pool tables rare, Chinese players made do with playing eight-ball on small snooker tables. It has since become the most popular cue sport in China, and the major tournaments have some of the largest prize money in pool.

The hybrid game eight-ball rotation is a combination of eight-ball and rotation, in which the players must pocket their balls (other than the 8, which remains last) in numerical order. Specifically, the solids player starts by pocketing the 1 ball and ascends to the 7 ball, and the stripes player starts by pocketing the 15 ball and descends to the 9 ball.

Backwards eight-ball, also called reverse eight-ball, is a variant in which, instead of shooting the cue ball at an object ball to force the object ball into a pocket, the player strikes the object ball with their cue so it s off the cue ball and into a pocket, in a fashion similar to Russian pyramid.



Earned value management

Earned value management (EVM), earned value project management, or earned value performance management (EVPM) is a project management technique for measuring project performance and progress in an objective manner.

Earned value management is a project management technique for measuring project performance and progress. It has the ability to combine measurements of the project management triangle: scope, time, and costs.

In a single integrated system, EVM is able to provide accurate forecasts of project performance problems, which is an important aspect of project management.

Early EVM research showed that the areas of planning and control are significantly impacted by its use; and similarly, using the methodology improves both scope definition as well as the analysis of overall project performance. More recent research studies have shown that the principles of EVM are positive predictors of project success. The popularity of EVM has grown in recent years beyond government contracting, a sector in which its importance continues to rise (e.g. recent new DFARS rules), in part because EVM can also surface in and help substantiate contract disputes.

Essential features of any EVM implementation include:

EVM implementations for large or complex projects include many more features, such as indicators and forecasts of cost performance (over budget or under budget) and schedule performance (behind schedule or ahead of schedule). Large projects usually need to use quantitative forecasts associated with earned value management. Although deliverables in these large projects can use adaptive development methods, the forecasting metrics found in earned value management are mostly used in projects using the predictive approach. However, the most basic requirement of an EVM system is that it quantifies progress using PV and EV.

Project A has been approved for a duration of one year and with a budget. It was also planned that the project spends 50% of the approved budget and expects 50% of the work to be complete in the first six months. If now, six months after the start of the project, a project manager reports that he has spent 50% of the budget, one may presume that the project is perfectly on plan. However, in reality the provided information is not sufficient to come to such a conclusion. The project can spend 50% of the budget, whilst finishing only 25% of the work, which would mean the project is not doing well; or the project can spend 50% of the budget, whilst completing 75% of the work, which would mean that project is doing better than planned. EVM is meant to address such and similar issues.

EVM emerged as a financial analysis specialty in United States government programs in the 1960s, with the government requiring contractors to implement an EVM system (EVMS). It has since become a significant branch of project management and cost engineering. Project management research investigating the contribution of EVM to project success suggests a moderately strong positive relationship. Implementations of EVM can be scaled to fit projects of all sizes and complexities.

The genesis of EVM occurred in industrial manufacturing at the turn of the 20th century, based largely on the principle of "earned time" popularized by Frank and Lillian Gilbreth.

In 1979, EVM was introduced to the architecture and engineering industry in a "Public Works Magazine" article by David Burstein, a project manager with a national engineering firm. In the late 1980s and early 1990s, EVM emerged more widely as a project management methodology to be understood and used by managers and executives, not just EVM specialists. Many industrialized nations also began to utilize EVM in their own procurement programs.

An overview of EVM was included in the Project Management Institute (PMI)'s first Project Management Body of Knowledge (PMBOK) Guide in 1987 and was expanded in subsequent editions. In the most recent edition of the PMBOK guide, EVM is listed among the general tools and techniques for processes to control project costs.

The construction industry was an early commercial adopter of EVM. Closer integration of EVM with the practice of project management accelerated in the 1990s. In 1999, the Performance Management Association merged with the PMI to become its first college, the College of Performance Management (CPM). The United States Office of Management and Budget began to mandate the use of EVM across all government agencies, and, for the first time, for certain internally managed projects (not just for contractors). EVM also received greater attention by publicly traded companies in response to the Sarbanes–Oxley Act of 2002.

In Australia, EVM has been codified as the standards AS 4817-2003 and AS 4817–2006.

The EVM concept took root in the United States Department of Defense in the 1960s. The original concept was called the Program Evaluation and Review Technique, but it was considered overly burdensome and not very adaptable by contractors whom were mandated to use it, and many variations of it began to proliferate among various procurement programs. In 1967, the DoD established a criterion-based approach, using a set of 35 criteria, called the Cost/Schedule Control Systems Criteria (C/SCSC). In the 1970s and early 1980s, a subculture of C/SCSC analysis grew, but the technique was often ignored or even actively resisted by project managers in both government and industry. C/SCSC was often considered a financial control tool that could be delegated to analytical specialists.

In 1989, EVM leadership was elevated to the Undersecretary of Defense for Acquisition, thus making EVM an element of program management and procurement. In 1991, Secretary of Defense Dick Cheney canceled the Navy A-12 Avenger II Program because of performance problems detected by EVM. This demonstrated that EVM mattered to secretary-level leadership. In the 1990s, many U.S. Government regulations were eliminated or streamlined. However, EVM not only survived the acquisition reform movement, but became strongly associated with the acquisition reform movement itself. Most notably, from 1995 to 1998, ownership of EVM criteria (reduced to 32) was transferred to industry by adoption of ANSI EIA 748-A standard.

The use of EVM has expanded beyond the U.S. Department of Defense. It was adopted by the National Aeronautics and Space Administration, the United States Department of Energy and other technology-related agencies.

It is helpful to see an example of project tracking that does not include earned value performance management. Consider a project that has been planned in detail, including a time-phased spend plan for all elements of work. Figure 1 shows the cumulative budget (cost) for this project as a function of time (the blue line, labeled PV). It also shows the cumulative actual cost of the project (red line, labeled AC) through week 8. To those unfamiliar with EVM, it might appear that this project was over budget through week 4 and then under budget from week 6 through week 8. However, what is missing from this chart is any understanding of how much work has been accomplished during the project. If the project was actually completed at week 8, then the project would actually be well under budget and well ahead of schedule. If, on the other hand, the project is only 10% complete at week 8, the project is significantly over budget and behind schedule. A method is needed to measure technical performance objectively and quantitatively, and that is what EVM accomplishes.

Progress can be measured using a measurement sheet and employing various techniques including milestones, weighted steps, value of work done, physical percent complete, earned value, Level of Effort, earn as planned, and more. Progress can be tracked based on any measure – cost, hours, quantities, schedule, directly input percent complete, and more.

Progress can be assessed using fundamental earned value calculations and variance analysis (Planned Cost, Actual Cost, and Earned Value); these calculations can determine where project performance currently is using the estimated project baseline's cost and schedule information.

Consider the same project, except this time the project plan includes pre-defined methods of quantifying the accomplishment of work. At the end of each week, the project manager identifies every detailed element of work that has been completed, and sums the EV for each of these completed elements. Earned value may be accumulated monthly, weekly, or as progress is made. The Value of Work Done (VOWD) is mainly used in Oil & Gas and is similar to the Actual Cost in EVM.

formula_1

EV is calculated by multiplying %complete of each task (completed or in progress) by its planned value

Figure 2 shows the EV curve (in green) along with the PV curve from Figure 1. The chart indicates that technical performance (i.e. progress) started more rapidly than planned, but slowed significantly and fell behind schedule at week 7 and 8. This chart illustrates the schedule performance aspect of EVM. It is complementary to critical path or critical chain schedule management.

Figure 3 shows the same EV curve (green) with the actual cost data from Figure 1 (in red). It can be seen that the project was actually under budget, relative to the amount of work accomplished, since the start of the project. This is a much better conclusion than might be derived from Figure 1.

Figure 4 shows all three curves together – which is a typical EVM line chart. The best way to read these three-line charts is to identify the EV curve first, then compare it to PV (for schedule performance) and AC (for cost performance). It can be seen from this illustration that a true understanding of cost performance and schedule performance "relies first on measuring technical performance objectively." This is the "foundational principle" of EVM.

The "foundational principle" of EVM, mentioned above, does not depend on the size or complexity of the project. However, the "implementations" of EVM can vary significantly depending on the circumstances. In many cases, organizations establish an all-or-nothing threshold; projects above the threshold require a full-featured (complex) EVM system and projects below the threshold are exempted. Another approach that is gaining favor is to scale EVM implementation according to the project at hand and skill level of the project team.

There are many more small and simple projects than there are large and complex ones, yet historically only the largest and most complex have enjoyed the benefits of EVM. Still, lightweight implementations of EVM are achievable by any person who has basic spreadsheet skills. In fact, spreadsheet implementations are an excellent way to learn basic EVM skills.

The "first step" is to define the work. This is typically done in a hierarchical arrangement called a work breakdown structure (WBS), although the simplest projects may use a simple list of tasks. In either case, it is important that the WBS or list be comprehensive. It is also important that the elements be mutually exclusive, so that work is easily categorized into one and only one element of work. The most detailed elements of a WBS hierarchy (or the items in a list) are called work packages. Work packages are then often devolved further in the project schedule into tasks or activities.

The "second step" is to assign a value, called planned value (PV), to each work package. For large projects, PV is almost always an allocation of the total project budget, and may be in units of currency (e.g. dollar, euro or naira) or in labor hours, or both. However, in very simple projects, each activity may be assigned a weighted "point value" which might not be a budget number. Assigning weighted values and achieving consensus on all PV quantities yields an important benefit of EVM, because it exposes misunderstandings and miscommunications about the scope of the project, and resolving these differences should always occur as early as possible. Some terminal elements can not be known (planned) in great detail in advance, and that is expected, because they can be further refined at a later time.

The "third step" is to define "earning rules" for each work package. The simplest method is to apply just one earning rule, such as the 0/100 rule, to all activities. Using the 0/100 rule, no credit is earned for an element of work until it is finished. A related rule is called the 50/50 rule, which means 50% credit is earned when an element of work is started, and the remaining 50% is earned upon completion. Other fixed earning rules such as a 25/75 rule or 20/80 rule are gaining favor, because they assign more weight to finishing work than for starting it, but they also motivate the project team to identify when an element of work is started, which can improve awareness of work-in-progress. These simple earning rules work well for small or simple projects because generally, each activity tends to be fairly short in duration.

These initial three steps define the minimal amount of planning for simplified EVM. The "final step" is to execute the project according to the plan and measure progress. When activities are started or finished, EV is accumulated according to the earning rule. This is typically done at regular intervals (e.g. weekly or monthly), but there is no reason why EV cannot be accumulated in near real-time, when work elements are started/completed. In fact, waiting to update EV only once per month (simply because that is when cost data are available) only detracts from a primary benefit of using EVM, which is to create a technical performance scoreboard for the project team.

In a lightweight implementation such as described here, the project manager has not accumulated cost nor defined a detailed project schedule network (i.e. using a critical path or critical chain methodology). While such omissions are inappropriate for managing large projects, they are a common and reasonable occurrence in many very small or simple projects. Any project can benefit from using EV alone as a real-time score of progress. One useful result of this very simple approach (without schedule models and actual cost accumulation) is to compare EV curves of similar projects, as illustrated in Figure 5. In this example, the progress of three residential construction projects are compared by aligning the starting dates. If these three home construction projects were measured with the same PV valuations, the "relative" schedule performance of the projects can be easily compared.

The actual critical path is ultimately the determining factor of every project's duration. Because earned value schedule metrics take no account of critical path data, big budget activities that are not on the critical path have the potential to dwarf the impact of performing small budget critical path activities. This can lead to gaming the SV and Schedule Performance Index (SPI) metrics by ignoring critical path activities in favor of big-budget activities that may have more float. This can sometimes even lead to performing activities out-of-sequence just to improve the schedule tracking metrics, which can cause major problems with quality.

A simple two-step process has been suggested to fix this:

In this way, the distorting aspect of float would be eliminated. There would be no benefit to performing a non-critical activity with many floats until it is due in proper sequence. Also, an activity would not generate a negative schedule variance until it had used up its float. Under this method, one way of gaming the schedule metrics would be eliminated. The only way of generating a positive schedule variance (or SPI over 1.0) would be by completing work on the current critical path ahead of schedule, which is in fact the only way for a project to get ahead of schedule.

In addition to managing technical and schedule performance, large and complex projects require cost performance to be monitored and reviewed at regular intervals. To measure cost performance, planned value (BCWS) and earned value (BCWP) must be in the same currency units as actual costs.

In large implementations, the planned value curve is commonly called a Performance Measurement Baseline (PMB) and may be arranged in control accounts, summary-level planning packages, planning packages and work packages.

In large projects, establishing control accounts is the primary method of delegating responsibility and authority to various parts of the performing organization. Control accounts are cells of a responsibility assignment (RACI) matrix, which is the intersection of the project WBS and the organizational breakdown structure (OBS). Control accounts are assigned to Control Account Managers (CAMs).

Large projects require more elaborate processes for controlling baseline revisions, more thorough integration with subcontractor EVM systems, and more elaborate management of procured materials.

In the United States, the primary standard for full-featured EVM systems is the ANSI/EIA-748A standard, published in May 1998 and reaffirmed in August 2002. The standard defines 32 criteria for full-featured EVM system compliance. As of the year 2007, a draft of ANSI/EIA-748B, a revision to the original is available from ANSI. Other countries have established similar standards.

In addition to using BCWS and BCWP, implementations often use the term actual cost of work performed (ACWP) instead of AC. Additional acronyms and formulas include:

According to the PMBOK (7th edition) by the Project Management Institute (PMI), Budget at Completion (BAC) is the "sum of all budgets established for the work to be performed."

It is the total planned value (PV or BCWS) at the end of the project. If a project has a management reserve (MR), it is typically "not" included in the BAC, and respectively, in the performance measurement baseline.

According to the PMBOK (7th edition) by the Project Management Institute (PMI), Cost variance (CV) is a "The amount of budget deficit or surplus at a given point in time, expressed as the difference between the earned value and the actual cost." Cost variance compares the estimated cost of a deliverable with the actual cost.

formula_2

CV greater than 0 is good (under budget).

According to the PMBOK (7th edition) by the Project Management Institute (PMI), Cost performance index is a "measure of the cost efficiency of budgeted resources expressed at the ratio of earned value to actual cost."

formula_3

CPI greater than 1 is favorable (under budget).

CPI that is less than 1 means that the cost of completing the work is higher than planned (bad).

When CPI is equal to 1, it means that the cost of completing the work is right on plan (good).

CPI greater than 1 means that the cost of completing the work is less than planned (good or sometimes bad).

Having a CPI that is very high (in some cases, very high is only 1.2) may mean that the plan was too conservative, and thus a very high number may in fact not be good, as the CPI is being measured against a poor baseline. Management or the customer may be upset with the planners as an overly conservative baseline ties up available funds for other purposes, and the baseline is also used for manpower planning.

According to the PMBOK (7th edition) by the Project Management Institute (PMI), Estimate at completion (EAC) is the "expected total cost of completing all work expressed as the sum of the actual cost to date and the estimate to complete."

EAC is the manager's projection of total cost of the project at completion.

formula_4

This formula is based on the assumption, that the performance of the project (or rather a deviation of the actual performance from a baseline) to date gives a good indication of what a performance (or rather deviation of a performance from a baseline) will be in the future. In other words, this formula is using statistics of the project to date to predict future results. Therefore, it has to be used carefully, when the nature of the project in the future is likely to be different from the one to date (e.g. performance of the project compare to baseline at the design phase may not be a good indication of what it will be during a construction phase).

According to the PMBOK (7th edition) by the Project Management Institute (PMI), Estimate to complete (ETC) is the "expected cost to finish all the remaining project work."

ETC is the estimate to complete the remaining work of the project. ETC must be based on objective measures of the outstanding work remaining, typically based on the measures or estimates used to create the original planned value (PV) profile, including any adjustments to predict performance based on historical performance, actions being taken to improve performance, or acknowledgement of degraded performance.
While algebraically, ETC = EAC-AC is correct, ETC should "never" be computed using either EAC or AC.

In the following equation:

formula_5

ETC is the independent variable, EAC is the dependent variable, and AC is fixed based on expenditures to date. ETC should always be reported truthfully to reflect the project team estimate to complete the outstanding work. If ETC pushes EAC to exceed BAC, then project management skills are employed to either recommend performance improvements or scope change, but never force ETC to give the "correct" answer so that EAC=BAC. Managing project activities to keep the project within budget is a human factors activity, not a mathematical function.

To-complete performance index (TCPI) is an earned value management measure that estimates the cost performance needed to achieve a particular management objective.
The TCPI provides a projection of the anticipated performance required to achieve either the BAC or the EAC. TCPI indicates the future required cost efficiency needed to achieve a target BAC (Budget At Complete) or EAC (Estimate At Complete). Any significant difference between CPI, the cost performance to date, and the TCPI, the cost performance needed to meet the BAC or the EAC, should be accounted for by management in their forecast of the final cost.

For the TCPI based on BAC (describing the performance required to meet the original BAC budgeted total):

formula_6

or for the TCPI based on EAC (describing the performance required to meet a new, revised budget total EAC):

formula_7

This implies, that if revised budget (EAC) is calculated using Earned Value methodology formula (BAC/CPI), then at the moment, when TCPI based on EAC is first time calculated, it will always be equal to CPI of a project at that moment. This happens because when EAC is calculated using formula BAC/CPI it is assumed, that cost performance of the remaining part of the project will be the same as the cost performance of the project to date.

The IEAC is a metric to project total cost using the performance to date to project overall performance. This can be compared to the EAC, which is the manager's projection.

formula_8

Proponents of EVM note a number of issues with implementing it, and further limitations may be inherent to the concept itself.

Because EVM requires quantification of a project plan, it is often perceived to be inapplicable to discovery-driven or Agile software development projects. For example, it may be impossible to plan certain research projects far in advance, because research itself uncovers some opportunities (research paths) and actively eliminates others. However, another school of thought holds that all work can be planned, even if in weekly timeboxes or other short increments.

Traditional EVM is not intended for non-discrete (continuous) effort. In traditional EVM standards, non-discrete effort is called "level of effort" (LOE). If a project plan contains a significant portion of LOE, and the LOE is intermixed with discrete effort, EVM results will be contaminated. This is another area of EVM research.

Traditional definitions of EVM typically assume that project accounting and project network schedule management are prerequisites to achieving any benefit from EVM. Many small projects don't satisfy either of these prerequisites, but they too can benefit from EVM, as described for simple implementations, above. Other projects can be planned with a project network, but do not have access to true and timely actual cost data. In practice, the collection of true and timely actual cost data can be the most difficult aspect of EVM. Such projects can benefit from EVM, as described for intermediate implementations, above, and earned schedule.

As a means of overcoming objections to EVM's lack of connection to qualitative performance issues, the Naval Air Systems Command (NAVAIR) PEO(A) organization initiated a project in the late 1990s to integrate true technical achievement into EVM projections by utilizing risk profiles. These risk profiles anticipate opportunities that may be revealed and possibly be exploited as development and testing proceeds. The published research resulted in a Technical Performance Management (TPM) methodology and software application that is still used by many DoD agencies in informing EVM estimates with technical achievement.
The research was peer-reviewed and was the recipient of the Defense Acquisition University Acquisition Research Symposium 1997 Acker Award for excellence in the exchange of information in the field of acquisition research.

There is the difficulty inherent for any periodic monitoring of synchronizing data timing: actual deliveries, actual invoicing, and the date the EVM analysis is done are all independent, so that some items have arrived but their invoicing has not and by the time analysis is delivered the data will likely be weeks behind events. This may limit EVM to a less tactical or less definitive role where use is combined with other forms to explain why or add recent news and manage future expectations.

There is a measurement limitation for how precisely EVM can be used, stemming from classic conflict between accuracy and precision, as the mathematics can calculate deceptively far beyond the precision of the measurements of data and the approximation that is the plan estimation. The limitation on estimation is commonly understood (such as the ninety–ninety rule in software) but is not visible in any margin of error. The limitations on measurement are largely a form of digitization error as EVM measurements ultimately can be no finer than by item, which may be the work breakdown structure terminal element size, to the scale of reporting period, typically end summary of a month, and by the means of delivery measure. (The delivery measure may be actual deliveries, may include estimates of partial work done at the end of month subject to estimation limits, and typically does not include QC check or risk offsets.)

As traditionally implemented, EVM deals with, and is based in, budget and cost. It has no relationship to the investment value or benefit for which the project has been funded and undertaken. Yet due to the use of the word "value" in the name, this fact is often misunderstood. However, earned value metrics can be used to compute the cost and schedule inputs to Devaux's Index of Project Performance (the DIPP), which integrates schedule and cost performance with the planned investment value of the project's scope across the project management triangle.

Darling & Whitty (2019) conducted an ethnographic study to see how EVM is implemented, applying Goffman's Dramaturgy (sociology), they found there is a sham act occurring through impressionable acts presenting statistical data as fact even when the data may be worthless. Findings include sham progress reporting can emerge in an environment where senior management’s ignorance of project work creates unworkable binds for project staff. Moreover, the sham behaviour succeeds at its objective because senior management are vulnerable to false impressions. This situation raises ethical issues for those involved, and creates an overhead in dealing with the reality of project work. Further the Darling & Whitty study is pertinent as it provides sociological insight to how a scientific management technique has been implemented.




Electron microscope

An electron microscope is a microscope that uses a beam of electrons as a source of illumination. They use electron optics that are analogous to the glass lenses of an optical light microscope to control the electron beam, for instance focusing them to produce magnified images or electron diffraction patterns. As the wavelength of an electron can be up to 100,000 times smaller than that of visible light, electron microscopes have a much higher resolution of about 0.1 nm, which compares to about 200 nm for light microscopes. "Electron microscope" may refer to:
Additional details can be found in the above links. This article contains some general information mainly about transmission electron microscopes.

Many developments laid the groundwork of the electron optics used in microscopes. One significant step was the work of Hertz in 1883 who made a cathode-ray tube with electrostatic and magnetic deflection, demonstrating manipulation of the direction of an electron beam. Others were focusing of the electrons by an axial magnetic field by Emil Wiechert in 1899, improved oxide-coated cathodes which produced more electrons by Arthur Wehnelt in 1905 and the development of the electromagnetic lens in 1926 by Hans Busch. According to Dennis Gabor, the physicist Leó Szilárd tried in 1928 to convince him to build an electron microscope, for which Szilárd had filed a patent. 

To this day the issue of who invented the transmission electron microscope is controversial. In 1928, at the Technical University of Berlin, Adolf Matthias (Professor of High Voltage Technology and Electrical Installations) appointed Max Knoll to lead a team of researchers to advance research on electron beams and cathode-ray oscilloscopes. The team consisted of several PhD students including Ernst Ruska. In 1931, Max Knoll and Ernst Ruska successfully generated magnified images of mesh grids placed over an anode aperture. The device, a replicate of which is shown in the figure, used two magnetic lenses to achieve higher magnifications, the first electron microscope. (Max Knoll died in 1969, so did not receive a share of the 1986 Nobel prize for the invention of electron microscopes.)

Apparently independent of this effort was work at Siemens-Schuckert by Reinhold Rüdenberg. According to patent law (U.S. Patent No. 2058914 and 2070318, both filed in 1932), he is the inventor of the electron microscope, but it is not clear when he had a working instrument. He stated in a very brief article in 1932 that Siemens had been working on this for some years before the patents were filed in 1932, claiming that his effort was parallel to the university development. He died in 1961, so similar to Max Knoll, was not eligible for a share of the 1986 Nobel prize.

In the following year, 1933, Ruska and Knoll built the first electron microscope that exceeded the resolution of an optical (light) microscope. Four years later, in 1937, Siemens financed the work of Ernst Ruska and Bodo von Borries, and employed Helmut Ruska, Ernst's brother, to develop applications for the microscope, especially with biological specimens. Also in 1937, Manfred von Ardenne pioneered the scanning electron microscope. Siemens produced the first commercial electron microscope in 1938. The first North American electron microscopes were constructed in the 1930s, at the Washington State University by Anderson and Fitzsimmons and at the University of Toronto by Eli Franklin Burton and students Cecil Hall, James Hillier, and Albert Prebus. Siemens produced a transmission electron microscope (TEM) in 1939. Although current transmission electron microscopes are capable of two million times magnification, as scientific instruments they remain similar but with improved optics.

In a typical electron gun, individual electrons, which have an elementary charge formula_1 (about formula_2 coulombs) and a mass formula_3 (about formula_4 kg), with a potential of formula_5 volts, have an energy amount of formula_6 joules. The wavelength is
where formula_8 is the speed of light in vacuum (about formula_9 m/s). See electron diffraction for a full explanation.

The original form of the electron microscope, the transmission electron microscope (TEM), uses a high voltage electron beam to illuminate the specimen and create an image. An electron beam is produced by an electron gun, with the electrons typically at 40 to 400 keV, focused by electromagnetic lenses, and transmitted through the specimen. When it emerges from the specimen, the electron beam carries information about the structure of the specimen that is magnified by lenses of the microscope. The spatial variation in this information (the "image") may be viewed by projecting the magnified electron image onto a detector. For example, the image may be viewed directly by an operator using a fluorescent viewing screen coated with a phosphor or scintillator material such as zinc sulfide. A high-resolution phosphor may also be coupled by means of a lens optical system or a fibre optic light-guide to the sensor of a digital camera. Direct electron detectors have no scintillator and are directly exposed to the electron beam, which addresses some of the limitations of scintillator-coupled cameras.

The resolution of TEMs is limited primarily by spherical aberration, but a new generation of hardware correctors can reduce spherical aberration to increase the resolution in high-resolution transmission electron microscopy (HRTEM) to below 0.5 angstrom (50 picometres), enabling magnifications above 50 million times. The ability of HRTEM to determine the positions of atoms within materials is useful for nano-technologies research and development.
Transmission electron microscopes are often used in electron diffraction mode. The advantages of electron diffraction over X-ray crystallography are that the specimen need not be a single crystal or even a polycrystalline powder.

The STEM rasters a focused incident probe across a specimen. The high resolution of the TEM is thus possible in STEM. The focusing action (and aberrations) occur before the electrons hit the specimen in the STEM, but afterward in the TEM. The STEMs use of SEM-like beam rastering simplifies annular dark-field imaging, and other analytical techniques, but also means that image data is acquired in serial rather than in parallel fashion.

The SEM produces images by probing the specimen with a focused electron beam that is scanned across the specimen (raster scanning). When the electron beam interacts with the specimen, it loses energy by a variety of mechanisms. The lost energy is converted into alternative forms such as heat, emission of low-energy secondary electrons and high-energy backscattered electrons, light emission (cathodoluminescence) or X-ray emission, all of which provide signals carrying information about the properties of the specimen surface, such as its topography and composition. The image displayed by an SEM maps the varying intensity of any of these signals into the image in a position corresponding to the position of the beam on the specimen when the signal was generated. In the SEM image of an ant shown, the image was constructed from signals produced by a secondary electron detector, the normal or conventional imaging mode in most SEMs.

Generally, the image resolution of an SEM is lower than that of a TEM. However, because the SEM images the surface of a sample rather than its interior, the electrons do not have to travel through the sample. This reduces the need for extensive sample preparation to thin the specimen to electron transparency. The SEM also has a great depth of field, and so can produce images that are good representations of the three-dimensional surface shape of the sample. 

In their most common configurations, electron microscopes produce images with a single brightness value per pixel, with the results usually rendered in greyscale. However, often these images are then colourized through the use of feature-detection software, or simply by hand-editing using a graphics editor. This may be done to clarify structure or for aesthetic effect and generally does not add new information about the specimen.

Materials to be viewed in a transmission electron microscope may require processing to produce a suitable sample. The technique required varies depending on the specimen and the analysis required:


Early electron microscopy of biological specimens was often descriptive, making use of the newly available higher resolution. This is still the case for various applications, such as diagnostic electron microscopy.

However, electron microscopes are now frequently used in more complex workflows, with each workflow typically using multiple technologies to enable more complex and/or more quantitative analyses of a sample. A few examples are outlined below, but this should not be considered an exhaustive list. The choice of workflow will be highly dependent on the application and the requirements of the corresponding scientific questions, such as resolution, volume, nature of the target molecule, etc.

For example, images from light and electron microscopy of the same region of a sample can be overlaid to correlate the data from the two modalities. This is commonly used to provide higher resolution contextual EM information about a fluorescently labelled structure. This correlative light and electron microscopy (CLEM) is one of a range of correlative workflows now available. Another example is high resolution mass spectrometry (ion microscopy), which has been used to provide correlative information about subcellular antibiotic localisation, data that would be difficult to obtain by other means.

The initial role of electron microscopes in imaging two-dimensional slices (TEM) or a specimen surface (SEM with secondary electrons) has also increasingly expanded into the depth of samples. An early example of these ‘volume EM’ workflows was simply to stack TEM images of serial sections cut through a sample. The next development was virtual reconstruction of a thick section (200-500 nm) volume by backprojection of a set of images taken at different tilt angles - TEM tomography.

To acquire volume EM datasets of larger depths than TEM tomography (micrometers or millimeters in the z axis), a series of images taken through the sample depth can be used. For example, ribbons of serial sections can be imaged in a TEM as described above, and when thicker sections are used, serial TEM tomography can be used to increase the z-resolution. More recently, back scattered electron (BSE) images can be acquired of a larger series of sections collected on silicon wafers, known as SEM array tomography. An alternative approach is to use BSE SEM to image the block surface instead of the section, after each section has been removed. By this method, an ultramicrotome installed in an SEM chamber can increase automation of the workflow; the specimen block is loaded in the chamber and the system programmed to continuously cut and image through the sample. This is known as serial block face SEM. A related method uses focused ion beam milling instead of an ultramicrotome to remove sections. In these serial imaging methods, the output is essentially a sequence of images through a specimen block that can be digitally aligned in sequence and thus reconstructed into a volume EM dataset. The increased volume available in these methods has expanded the capability of electron microscopy to address new questions, such as mapping neural connectivity in the brain, and membrane contact sites between organelles.

Electron microscopes are expensive to build and maintain. Microscopes designed to achieve high resolutions must be housed in stable buildings (sometimes underground) with special services such as magnetic field canceling systems.

The samples largely have to be viewed in vacuum, as the molecules that make up air would scatter the electrons. An exception is liquid-phase electron microscopy using either a closed liquid cell or an environmental chamber, for example, in the environmental scanning electron microscope, which allows hydrated samples to be viewed in a low-pressure (up to ) wet environment. Various techniques for in situ electron microscopy of gaseous samples have been developed.

Scanning electron microscopes operating in conventional high-vacuum mode usually image conductive specimens; therefore non-conductive materials require conductive coating (gold/palladium alloy, carbon, osmium, etc.). The low-voltage mode of modern microscopes makes possible the observation of non-conductive specimens without coating. Non-conductive materials can be imaged also by a variable pressure (or environmental) scanning electron microscope.

Small, stable specimens such as carbon nanotubes, diatom frustules and small mineral crystals (asbestos fibres, for example) require no special treatment before being examined in the electron microscope. Samples of hydrated materials, including almost all biological specimens, have to be prepared in various ways to stabilize them, reduce their thickness (ultrathin sectioning) and increase their electron optical contrast (staining). These processes may result in "artifacts", but these can usually be identified by comparing the results obtained by using radically different specimen preparation methods. Since the 1980s, analysis of cryofixed, vitrified specimens has also become increasingly used by scientists, further confirming the validity of this technique.


List of extinct bird species since 1500

About 129 species of birds have become extinct since 1500, and the rate of extinction seems to be increasing. The situation is exemplified by Hawaii, where 30% of all known recently extinct bird taxa originally lived. Other areas, such as Guam, have also been hit hard; Guam has lost over 60% of its native bird taxa in the last 30 years, many of them due to the introduced brown tree snake ("Boiga irregularis").

Currently there are approximately 10,000 living species of birds, with over 1,480 at risk of extinction and 223 critically endangered.

Island species in general, and flightless island species in particular, are most at risk. The disproportionate number of rails in this list reflects the tendency of that family to lose the ability to fly when geographically isolated. Even more rails became extinct before they could be described by scientists; these taxa are listed in List of Late Quaternary prehistoric bird species.

The extinction dates given below are usually approximations of the actual date of extinction. In some cases, more exact dates are given as it is sometimes possible to pinpoint the date of extinction to a specific year or even day (the San Benedicto rock wren is possibly the most extreme exampleits extinction could be timed with an accuracy of maybe half an hour). Extinction dates in the literature are usually the dates of the last verified record (credible observation or specimen taken); for many Pacific birds that became extinct shortly after European contact, however, this leaves an uncertainty period of over 100 years, because the islands on which they lived were only rarely visited by scientists.




Ducks, geese and swans


Quails and relatives
See also Bokaak "bustard" under Gruiformes below

Megapodiidaemegapodes

Phasianidaepheasants and allies

Shorebirds, gulls and auks




Rails and allies - probably paraphyletic


Grebes

Petrels, storm petrels, shearwaters and albatrosses

Penguins

Boobies and related birds


Pelicans and related birds


Pigeons, doves and dodos
For the "Réunion solitaire", see Réunion ibis.

Cuckoos


True owls and barn-owls

Strigidae - true owls

Tytonidae - barn owls

Caprimulgidae - nightjars and nighthawks

Swifts and hummingbirds

Kingfishers and related birds

Woodpeckers and related birds

Birds of prey

Parrots


Perching birds

Tyrannidaetyrant flycatchers
Furnariidaeovenbirds
AcanthisittidaeNew Zealand "wrens"

MohoidaeHawaiian honeyeaters. Family established in 2008, previously in Meliphagidae.

Meliphagidaehoneyeaters and Australian chats

Acanthizidaescrubwrens, thornbills, and gerygones

Pachycephalidaewhistlers, shrike-thrushes, pitohuis and allies

Dicruridaemonarch flycatchers and allies

OriolidaeOld World orioles and allies

Corvidaecrows, ravens, jays and magpies

CallaeidaeNew Zealand wattlebirds


Hirundinidaeswallows and martins

Acrocephalidaeacrocephalid warblers or marsh warblers, tree warblers and reed warblers

MuscicapidaeOld World flycatchers and chats

Megaluridaemegalurid warblers or grass warblers

Cisticolidaecisticolas and allies

Zosteropidaewhite-eyes. Probably belong in Timaliidae.

Pycnonotidaebulbuls

Sylvioidea "incertae sedis"

Sturnidaestarlings


Turdidaethrushes and allies

Mimidaemockingbirds and thrashers

Estrildidaeestrildid finches (waxbills, munias, etc.)

IcteridaeNew World blackbirds and allies

ParulidaeNew World warblers

Ploceidaeweavers

Fringillidaetrue finches and Hawaiian honeycreepers

Emberizidaebuntings and New World sparrows

The extinction of subspecies is a subject very dependent on guesswork. National and international conservation projects and research publications such as red lists usually focus on species as a whole. Reliable information on the status of vulnerable, endangered or critically endangered subspecies usually has to be assembled piecemeal from published observations, such as regional checklists. Therefore, the following listing contains a high proportion of bird taxa that may still exist, but are listed here due to any one of, or any combination of, these three factors: absence of recent records, a known threat such as habitat destruction, or an observed decline.

Ratites and related birds




Tinamous

Ducks, geese and swans

Quails and relatives

Shorebirds, gulls and auks

Turnicidaebuttonquails

Rails and alliesprobably paraphyletic

Herons and related birdspossibly paraphyletic

Sandgrouse

Pigeons, doves and dodos

Cuckoos

True owls and barn owls

Strigidaetrue owls

Tytonidaebarn owls

Swifts and hummingbirds

Kingfishers and related birds

Woodpeckers and related birds

Birds of prey

Parrots

Perching birds

Pittidaepittas

Tyrannidaetyrant flycatchers

Furnariidaeovenbirds

Formicariidaeantpittas and antthrushes

MaluridaeAustralasian "wrens"

Pardalotidaepardalotes, scrubwrens, thornbills and gerygones

PetroicidaeAustralasian "robins"

Cinclosomatidaewhipbirds and allies

Artamidaewoodswallows, currawongs and allies

Monarchidaemonarch flycatchers

Rhipiduridaefantails

Campephagidaecuckooshrikes and trillers

OriolidaeOld World orioles and allies

Corvidaecrows, ravens, jays and magpies

Regulidaekinglets

Hirundinidaeswallows and martins

Phylloscopidaephylloscopid warblers or leaf warblers

Cettiidaecettiid warblers or typical bush warblers

Acrocephalidaeacrocephalid warblers or marsh warblers, tree warblers and reed warblers

Pycnonotidaebulbuls

Cisticolidaecisticolas and allies

Sylviidaesylviid ("true") warblers and parrotbills

Zosteropidaewhite-eyes. Probably belong in Timaliidae.

TimaliidaeOld World babblers

"African warblers"

Sylvioidea "incertae sedis"

Troglodytidaewrens

Paridaetits, chickadees and titmice

Cinclidaedippers

MuscicapidaeOld World flycatchers and chats

Turdidaethrushes and allies

Mimidaemockingbirds and thrashers

Estrildidaeestrildid finches (waxbills, munias, etc.)

Fringillidaetrue finches and Hawaiian honeycreepers

IcteridaeNew World blackbirds and allies

ParulidaeNew World warblers

Thraupidaetanagers
Emberizoideabuntings and New World sparrows




Eli Whitney

Eli Whitney Jr. (December 8, 1765January 8, 1825) was an American inventor, widely known for inventing the cotton gin in 1793, one of the key inventions of the Industrial Revolution that shaped the economy of the Antebellum South.

Whitney's invention made upland short cotton into a profitable crop, which strengthened the economic foundation of slavery in the United States and prolonged the institution. Despite the social and economic impact of his invention, Whitney lost much of his profits in legal battles over patent infringement for the cotton gin. Thereafter, he turned his attention to securing contracts with the government in the manufacture of muskets for the newly formed United States Army. He continued making arms and inventing until his death in 1825.

Whitney was born in Westborough, Massachusetts, on December 8, 1765, the eldest child of Eli Whitney Sr., a prosperous farmer, and his wife Elizabeth Fay, also of Westborough.

The younger Eli was famous during his lifetime and after his death by the name "Eli Whitney", though he was technically Eli Whitney Jr. His son, born in 1820, also named Eli, was known during his lifetime and afterward by the name "Eli Whitney Jr."

Whitney's mother, Elizabeth Fay, died in 1777, when he was 11. At age 14 he operated a profitable nail manufacturing operation in his father's workshop during the Revolutionary War.

Because his stepmother opposed his wish to attend college, Whitney worked as a farm laborer and school teacher to save money. He prepared for Yale at Leicester Academy (now Becker College) and under the tutelage of Rev. Elizur Goodrich of Durham, Connecticut, he entered in the fall of 1789 and graduated Phi Beta Kappa in 1792. Whitney expected to study law but, finding himself short of funds, accepted an offer to go to South Carolina as a private tutor.
Instead of reaching his destination, he was convinced to visit Georgia. In the closing years of the 18th century, Georgia was a magnet for New Englanders seeking their fortunes (its Revolutionary-era governor had been Lyman Hall, a migrant from Connecticut). When he initially sailed for South Carolina, among his shipmates were the widow (Catherine Littlefield Greene) and family of the Revolutionary hero Gen. Nathanael Greene of Rhode Island. Mrs. Greene invited Whitney to visit her Georgia plantation, Mulberry Grove. Her plantation manager and husband-to-be was Phineas Miller, another Connecticut migrant and Yale graduate (class of 1785), who would become Whitney's business partner.

Whitney is most famous for two innovations which came to have significant impacts on the United States in the mid-19th century: the cotton gin (1793) and his advocacy of interchangeable parts. In the South, the cotton gin revolutionized the way cotton was harvested and reinvigorated slavery. Conversely, in the North the adoption of interchangeable parts revolutionized the manufacturing industry, contributing greatly to the U.S. victory in the Civil War.

The cotton gin is a mechanical device that removes the seeds from cotton, a process that had previously been extremely labor-intensive. The word "gin" is short for "engine." While staying at Mulberry Grove, Whitney constructed several ingenious household devices which led Mrs Greene to introduce him to some businessmen who were discussing the desirability of a machine to
separate the short staple upland cotton from its seeds, work that was then done by hand at the rate of a pound of lint a day. In a few weeks Whitney produced a model. The cotton gin was a wooden drum stuck with hooks that pulled the cotton fibers through a mesh. The cotton seeds would not fit through the mesh and fell outside. Whitney occasionally told a story wherein he was pondering an improved method of seeding the cotton when he was inspired by observing a cat attempting to pull a chicken through a fence, and able to only pull through some of the feathers.

A single cotton gin could generate up to of cleaned cotton daily. This contributed to the economic development of the Southern United States, a prime cotton growing area; some historians believe that this invention allowed for the African slavery system in the Southern United States to become more sustainable at a critical point in its development.

Whitney applied for the patent for his cotton gin on October 28, 1793, and received the patent (later numbered as X72) on March 14, 1794, but it was not validated until 1807. Whitney and his partner, Miller, did not intend to sell the gins. Rather, like the proprietors of grist and sawmills, they expected to charge farmers for cleaning their cotton – two-fifths of the value, paid in cotton. Resentment at this scheme, the mechanical simplicity of the device and the primitive state of patent law, made infringement inevitable. Whitney and Miller could not build enough gins to meet demand, so gins from other makers found ready sale. Ultimately, patent infringement lawsuits consumed the profits (one patent, later annulled, was granted in 1796 to Hogden Holmes for a gin which substituted circular saws for the spikes) and their cotton gin company went out of business in 1797. One oft-overlooked point is that there were drawbacks to Whitney's first design. There is significant evidence that the design flaws were solved by his sponsor, Mrs. Greene, but Whitney gave her no public credit or recognition.

After validation of the patent, the legislature of South Carolina voted $50,000 for the rights for that state, while North Carolina levied a license tax for five years, from which about $30,000 was realized. There is a claim that Tennessee paid about $10,000.

While the cotton gin did not earn Whitney the fortune he had hoped for, it did give him fame. It has been argued by some historians that Whitney's cotton gin was an important if unintended cause of the American Civil War. After Whitney's invention, the plantation slavery industry was rejuvenated, eventually culminating in the Civil War.

The cotton gin transformed Southern agriculture and the national economy. Southern cotton found ready markets in Europe and in the burgeoning textile mills of New England. Cotton exports from the U.S. boomed after the cotton gin's appearance – from less than in 1793 to by 1810. Cotton was a staple that could be stored for long periods and shipped long distances, unlike most agricultural products. It became the U.S.'s chief export, representing over half the value of U.S. exports from 1820 to 1860.

Whitney believed that his cotton gin would reduce the demand for enslaved labor and would help hasten the end of southern slavery. Paradoxically, the cotton gin, a labor-saving device, helped preserve and prolong slavery in the United States for another 70 years. Before the 1790s, slave labor was primarily employed in growing rice, tobacco, and indigo, none of which were especially profitable anymore. Neither was cotton, due to the difficulty of seed removal. But with the invention of the gin, growing cotton with slave labor became highly profitable – the chief source of wealth in the American South, and the basis of frontier settlement from Georgia to Texas. "King Cotton" became a dominant economic force, and slavery was sustained as a key institution of Southern society.

Eli Whitney has often been incorrectly credited with inventing the idea of interchangeable parts, which he championed for years as a maker of muskets; however, the idea predated Whitney, and Whitney's role in it was one of promotion and popularizing, not invention. Successful implementation of the idea eluded Whitney until near the end of his life, occurring first in others' armories.

Attempts at interchangeability of parts can be traced back as far as the Punic Wars through both archaeological remains of boats now in Museo Archeologico Baglio Anselmi and contemporary written accounts. In modern times the idea developed over decades among many people. An early leader was Jean-Baptiste Vaquette de Gribeauval, an 18th-century French artillerist who created a fair amount of standardization of artillery pieces, although not true interchangeability of parts. He inspired others, including Honoré Blanc and Louis de Tousard, to work further on the idea, and on shoulder weapons as well as artillery. In the 19th century these efforts produced the "armory system," or American system of manufacturing. Certain other New Englanders, including Captain John H. Hall and Simeon North, arrived at successful interchangeability before Whitney's armory did. The Whitney armory finally succeeded not long after his death in 1825.

The motives behind Whitney's acceptance of a contract to manufacture muskets in 1798 were mostly monetary. By the late 1790s, Whitney was on the verge of bankruptcy and the cotton gin litigation had left him deeply in debt. His New Haven cotton gin factory had burned to the ground, and litigation sapped his remaining resources. The French Revolution had ignited new conflicts between Great Britain, France, and the United States. The new American government, realizing the need to prepare for war, began to rearm. The War Department issued contracts for the manufacture of 10,000 muskets. Whitney, who had never made a gun in his life, obtained a contract in January 1798 to deliver 10,000 to 15,000 muskets in 1800. He had not mentioned interchangeable parts at that time. Ten months later, the Treasury Secretary, Oliver Wolcott Jr., sent him a "foreign pamphlet on arms manufacturing techniques," possibly one of Honoré Blanc's reports, after which Whitney first began to talk about interchangeability.
In May 1798, Congress voted for legislation that would use 800,000 dollars in order to pay for small arms and cannons in case war with France erupted. It offered a 5,000 dollar incentive with an additional 5,000 dollars once that money was exhausted for the person that was able to accurately produce arms for the government. Because the cotton gin had not brought Whitney the rewards he believed it promised, he accepted the offer. Although the contract was for one year, Whitney did not deliver the arms until 1809, using multiple excuses for the delay. Recently, historians have found that during 1801–1806, Whitney took the money and headed into South Carolina in order to profit from the cotton gin.

Although Whitney's demonstration of 1801 appeared to show the feasibility of creating interchangeable parts, Merritt Roe Smith concludes that it was "staged" and "duped government authorities" into believing that he had been successful. The charade gained him time and resources toward achieving that goal.

When the government complained that Whitney's price per musket compared unfavorably with those produced in government armories, he was able to calculate an actual price per musket by including fixed costs such as insurance and machinery, which the government had not accounted for. He thus made early contributions to both the concepts of cost accounting, and economic efficiency in manufacturing.

Machine tool historian Joseph W. Roe credited Whitney with inventing the first milling machine circa 1818. Subsequent work by other historians (Woodbury; Smith; Muir; Battison [cited by Baida]) suggests that Whitney was among a group of contemporaries all developing milling machines at about the same time (1814 to 1818), and that the others were more important to the innovation than Whitney was. (The machine that excited Roe may not have been built until 1825, after Whitney's death.) Therefore, no one person can properly be described as the inventor of the milling machine.

Despite his humble origins, Whitney was keenly aware of the value of social and political connections. In building his arms business, he took full advantage of the access that his status as a Yale alumnus gave him to other well-placed graduates, such as Oliver Wolcott Jr., Secretary of the Treasury (class of 1778), and James Hillhouse, a New Haven developer and political leader.

His 1817 marriage to Henrietta Edwards, granddaughter of the famed evangelist Jonathan Edwards, daughter of Pierpont Edwards, head of the Democratic Party in Connecticut, and first cousin of Yale's president, Timothy Dwight, the state's leading Federalist, further tied him to Connecticut's ruling elite. In a business dependent on government contracts, such connections were essential to success.

Whitney died of prostate cancer on January 8, 1825, in New Haven, Connecticut, just a month after his 59th birthday. He left a widow and his four children behind. One of his offspring, Eli Whitney III (known as Eli Whitney Jr.), was instrumental in building New Haven, Connecticut's waterworks. During the course of his illness, he reportedly invented and constructed several devices to mechanically ease his pain.

The Eli Whitney Students Program, Yale University's admissions program for non-traditional students, is named in honor of Whitney, who not only began his studies there when he was 23, but also went on to graduate Phi Beta Kappa in just three years.




The American Prisoner

The American Prisoner is a British novel written by Eden Phillpotts and published in 1904 and adapted into a film by the same name in 1929. The story concerns an English woman who lives at Fox Tor farm, and an American captured during the American War of Independence and held at the prison at Princetown on Dartmoor.

In the novel "Malherb" is a miscreant who destroys Childe's tomb and beats his servant. He is depicted as a victim of his own bad temper rather than a sadist.

Malherb is introduced as the younger son of a noble family and he builds the Fox Tor house to be the impressive gentleman's residence suggested by William Crossing rather than the humble cottage which it actually is.

Electromagnetic field

An electromagnetic field (also EM field or EMF) is a mathematical representation of the influences on and due to electric charges. The field at any point in space and time can be regarded as a combination of an electric field and a magnetic field. The way in which charges and currents (i.e. streams of charges) interact with the electromagnetic field is described by Maxwell's equations and the Lorentz force law. Maxwell's equations detail how the electric field converges towards or diverges away from electric charges, how the magnetic field curls around electrical currents, and how changes in the electric and magnetic fields influence each other. The Lorentz force law states that a charge subject to an electric field feels a force along the direction of the field, and a charge moving through a magnetic field feels a force that is perpendicular both to the magnetic field and to its direction of motion. Because of the interrelationship between the fields, a disturbance in the electric field can create a disturbance in the magnetic field which in turn affects the electric field, leading to an oscillation that propagates through space, known as an electromagnetic wave.

The electromagnetic field is described by classical electrodynamics, an example of a classical field theory. This theory describes many macroscopic physical phenomena accurately. However, it was unable to explain the photoelectric effect and atomic absorption spectroscopy, experiments at the atomic scale. That required the use of quantum mechanics, specifically the quantization of the electromagnetic field and the development of quantum electrodynamics.

This article gives an overview of the classical electromagnetic field and introduces many related articles with more details.

The empirical investigation of electromagnetism is at least as old as the ancient Greek philosopher, mathematician and scientist Thales of Miletus, who around 600 BCE described his experiments rubbing fur of animals on various materials such as amber creating static electricity. By the 18th century, it was understood that objects can carry positive or negative electric charge, that two objects carrying charge of the same sign repel each other, that two objects carrying charges of opposite sign attract one another, and that the strength of this force falls off as the square of the distance between them. Michael Faraday visualized this in terms of the charges interacting via the electric field. An electric field is produced when the charge is stationary with respect to an observer measuring the properties of the charge, and a magnetic field as well as an electric field are produced when the charge moves, creating an electric current with respect to this observer. Over time, it was realized that the electric and magnetic fields are better thought of as two parts of a greater whole—the electromagnetic field. In 1820, Hans Christian Ørsted showed that an electric current can deflect a nearby compass needle, establishing that electricity and magnetism are closely related phenomena. Faraday then made the seminal observation that time-varying magnetic fields could induce electric currents in 1831. 

In 1861, James Clerk Maxwell synthesized all the work to date on electrical and magnetic phenomena into a single mathematical theory, from which he then deduced that light is an electromagnetic wave. Maxwell's continuous field theory was very successful until evidence supporting the atomic model of matter emerged. Beginning in 1877, Hendrik Lorentz developed an atomic model of electromagnetism and in 1897 J. J. Thomson completed experiments that defined the electron. The Lorentz theory works for free charges in electromagnetic fields, but fails to predict the energy spectrum for bound charges in atoms and molecules. For that problem, quantum mechanics is needed, ultimately leading to the theory of quantum electrodynamics.

Practical applications of the new understanding of electromagnetic fields emerged in the late 1800s. The electrical generator and motor were invented using only the empirical findings like Faraday's and Ampere's laws combined with practical experience.

There are different mathematical ways of representing the electromagnetic field. The first one views the electric and magnetic fields as three-dimensional vector fields. These vector fields each have a value defined at every point of space and time and are thus often regarded as functions of the space and time coordinates. As such, they are often written as (electric field) and (magnetic field).

If only the electric field () is non-zero, and is constant in time, the field is said to be an electrostatic field. Similarly, if only the magnetic field () is non-zero and is constant in time, the field is said to be a magnetostatic field. However, if either the electric or magnetic field has a time-dependence, then both fields must be considered together as a coupled electromagnetic field using Maxwell's equations.

With the advent of special relativity, physical laws became amenable to the formalism of tensors. Maxwell's equations can be written in tensor form, generally viewed by physicists as a more elegant means of expressing physical laws.

The behavior of electric and magnetic fields, whether in cases of electrostatics, magnetostatics, or electrodynamics (electromagnetic fields), is governed by Maxwell's equations. In the vector field formalism, these are:

where formula_5 is the charge density, which is a function of time and position, formula_6 is the vacuum permittivity, formula_7 is the vacuum permeability, and is the current density vector, also a function of time and position. Inside a linear material, Maxwell's equations change by switching the permeability and permittivity of free space with the permeability and permittivity of the linear material in question. Inside other materials which possess more complex responses to electromagnetic fields, these terms are often represented by complex numbers, or tensors.

The Lorentz force law governs the interaction of the electromagnetic field with charged matter.

When a field travels across to different media, the behavior of the field changes according to the properties of the media.

The Maxwell equations simplify when the charge density at each point in space does not change over time and all electric currents likewise remain constant. All of the time derivatives vanish from the equations, leaving two expressions that involve the electric field,
formula_8
and
formula_9
along with two formulae that involve the magnetic field:
formula_10
and
formula_11
These expressions are the basic equations of electrostatics, which focuses on situations where electrical charges do not move, and magnetostatics, the corresponding area of magnetic phenomena.

Whether a physical effect is attributable to an electric field or to a magnetic field is dependent upon the observer, in a way that special relativity makes mathematically precise. For example, suppose that a laboratory contains a long straight wire that carries an electrical current. In the frame of reference where the laboratory is at rest, the wire is motionless and electrically neutral: the current, composed of negatively charged electrons, moves against a background of positively charged ions, and the densities of positive and negative charges cancel each other out. A test charge near the wire would feel no electrical force from the wire. However, if the test charge is in motion parallel to the current, the situation changes. In the rest frame of the test charge, the positive and negative charges in the wire are moving at different speeds, and so the positive and negative charge distributions are Lorentz-contracted by different amounts. Consequently, the wire has a nonzero net charge density, and the test charge must experience a nonzero electric field and thus a nonzero force. In the rest frame of the laboratory, there is no electric field to explain the test charge being pulled towards or pushed away from the wire. So, an observer in the laboratory rest frame concludes that a field must be present.

In general, a situation that one observer describes using only an electric field will be described by an observer in a different inertial frame using a combination of electric and magnetic fields. Analogously, a phenomenon that one observer describes using only a magnetic field will be, in a relatively moving reference frame, described by a combination of fields. The rules for relating the fields required in different reference frames are the Lorentz transformations of the fields.

Thus, electrostatics and magnetostatics are now seen as studies of the static EM field when a particular frame has been selected to suppress the other type of field, and since an EM field with both electric and magnetic will appear in any other frame, these "simpler" effects are merely a consequence of different frames of measurement. The fact that the two field variations can be reproduced just by changing the motion of the observer is further evidence that there is only a single actual field involved which is simply being observed differently.

The two Maxwell equations, Faraday's Law and the Ampère–Maxwell Law, illustrate a very practical feature of the electromagnetic field. Faraday's Law may be stated roughly as "a changing magnetic field inside a loop creates an electric voltage around the loop". This is the principle behind the electric generator.

Ampere's Law roughly states that "an electrical current around a loop creates a magnetic field through the loop". Thus, this law can be applied to generate a magnetic field and run an electric motor.

Maxwell's equations can be combined to derive wave equations. The solutions of these equations take the form of an electromagnetic wave. In a volume of space not containing charges or currents (free space) – that is, where formula_5 and are zero, the electric and magnetic fields satisfy these electromagnetic wave equations:

James Clerk Maxwell was the first to obtain this relationship by his completion of Maxwell's equations with the addition of a displacement current term to Ampere's circuital law. This unified the physical understanding of electricity, magnetism, and light: visible light is but one portion of the full range of electromagnetic waves, the electromagnetic spectrum.

An electromagnetic field very far from currents and charges (sources) is called electromagnetic radiation (EMR) since it radiates from the charges and currents in the source. Such radiation can occur across a wide range of frequencies called the electromagnetic spectrum, including radio waves, microwave, infrared, visible light, ultraviolet light, X-rays, and gamma rays. The many commercial applications of these radiations are discussed in the named and linked articles.

A notable application of visible light is that this type of energy from the Sun powers all life on Earth that either makes or uses oxygen.

A changing electromagnetic field which is physically close to currents and charges (see near and far field for a definition of "close") will have a dipole characteristic that is dominated by either a changing electric dipole, or a changing magnetic dipole. This type of dipole field near sources is called an electromagnetic "near-field".

Changing dipole fields, as such, are used commercially as near-fields mainly as a source of dielectric heating. Otherwise, they appear parasitically around conductors which absorb EMR, and around antennas which have the purpose of generating EMR at greater distances.

Changing dipole fields (i.e., magnetic near-fields) are used commercially for many types of magnetic induction devices. These include motors and electrical transformers at low frequencies, and devices such as RFID tags, metal detectors, and MRI scanner coils at higher frequencies.

The potential effects of electromagnetic fields on human health vary widely depending on the frequency, intensity of the fields, and the length of the exposure. Low frequency, low intensity, and short duration exposure to electromagnetic radiation is generally considered safe. On the other hand, radiation from other parts of the electromagnetic spectrum, such as ultraviolet light and gamma rays, are known to cause significant harm in some circumstances.


Empire State Building

The Empire State Building is a 102-story Art Deco skyscraper in Midtown Manhattan, New York City. The building was designed by Shreve, Lamb & Harmon and built from 1930 to 1931. Its name is derived from "Empire State", the nickname of the state of New York. The building has a roof height of and stands a total of tall, including its antenna. The Empire State Building was the world's tallest building until the first tower of the World Trade Center was topped out in 1970; following the September 11 attacks in 2001, the Empire State Building was New York City's tallest building until it was surpassed in 2012 by One World Trade Center. , the building is the seventh-tallest building in New York City, the ninth-tallest completed skyscraper in the United States, and the 54th-tallest in the world.

The site of the Empire State Building, in Midtown South on the west side of Fifth Avenue between West 33rd and 34th Streets, was developed in 1893 as the Waldorf–Astoria Hotel. In 1929, Empire State Inc. acquired the site and devised plans for a skyscraper there. The design for the Empire State Building was changed fifteen times until it was ensured to be the world's tallest building. Construction started on March 17, 1930, and the building opened months afterward on May 1, 1931. Despite favorable publicity related to the building's construction, because of the Great Depression and World War II, its owners did not make a profit until the early 1950s.

The building's Art Deco architecture, height, and observation decks have made it a popular attraction. Around four million tourists from around the world annually visit the building's 86th- and 102nd-floor observatories; an additional indoor observatory on the 80th floor opened in 2019. The Empire State Building is an international cultural icon: it has been featured in more than 250 television series and films since the film "King Kong" was released in 1933. The building's size has become the global standard of reference to describe the height and length of other structures. A symbol of New York City, the building has been named as one of the Seven Wonders of the Modern World by the American Society of Civil Engineers. It was ranked first on the American Institute of Architects' List of America's Favorite Architecture in 2007. Additionally, the Empire State Building and its ground-floor interior were designated city landmarks by the New York City Landmarks Preservation Commission in 1980, and were added to the National Register of Historic Places as a National Historic Landmark in 1986.

The Empire State Building is located on the west side of Fifth Avenue in Midtown Manhattan, between 33rd Street to the south and 34th Street to the north. Tenants enter the building through the Art Deco lobby located at 350 Fifth Avenue. Visitors to the observatories use an entrance at 20 West 34th Street; prior to August 2018, visitors entered through the Fifth Avenue lobby. Although physically located in South Midtown, a mixed residential and commercial area, the building is so large that it was assigned its own ZIP Code, 10118; , it is one of 43 buildings in New York City that have their own ZIP codes.

The areas surrounding the Empire State Building are home to other major points of interest, including Macy's at Herald Square on Sixth Avenue and 34th Street, and Koreatown on 32nd Street between Madison and Sixth avenues. To the east of the Empire State Building is Murray Hill, a neighborhood with a mix of residential, commercial, and entertainment activity. The block directly to the northeast contains the B. Altman and Company Building, which houses the City University of New York's Graduate Center, while the Demarest Building is directly across Fifth Avenue to the east. The nearest New York City Subway stations are 34th Street–Herald Square, one block west, and 33rd Street at Park Avenue, two blocks east; there is also a PATH station at 33rd Street and Sixth Avenue.

The Empire State Building was designed by Shreve, Lamb and Harmon in the Art Deco style. The Empire State Building is tall to its 102nd floor, or including its pinnacle. It was the first building in the world to be more than 100 stories tall, though only the lowest 86 stories are usable. The first through 85th floors contain of commercial and office space, while the 86th floor contains an observatory. The remaining 16 stories are part of the spire, which is capped by an observatory on the 102nd floor; the spire does not contain any intermediate levels and is used mostly for mechanical purposes. Atop the 102nd story is the pinnacle, much of which is covered by broadcast antennas, and surmounted with a lightning rod.

The Empire State Building has a symmetrical massing because of its large lot and relatively short base. Its articulation consists of three horizontal sections similar to the components of a column, namely a base, shaft, and capital. The five-story base occupies the entire lot, while the 81-story shaft above it is set back sharply from the base. The setback above the 5th story is deep on all sides. There are smaller setbacks on the upper stories, allowing sunlight to illuminate the interiors of the top floors while also positioning these floors away from the noisy streets below. The setbacks are located at the 21st, 25th, 30th, 72nd, 81st, and 85th stories. The setbacks correspond to the tops of elevator shafts, allowing interior spaces to be at most deep (see ).

The setbacks were mandated by the 1916 Zoning Resolution, which was intended to allow sunlight to reach the streets as well. Normally, a building of the Empire State's dimensions would be permitted to build up to 12 stories on the Fifth Avenue side, and up to 17 stories on the 33rd Street and 34th Street sides, before it would have to utilize setbacks. However, with the largest setback being located above the base, the tower stories could contain a uniform shape. According to architectural writer Robert A. M. Stern, the building's form contrasted with the nearly contemporary, similarly designed 500 Fifth Avenue eight blocks north, which had an asymmetrical massing on a smaller lot.

The Empire State Building's Art Deco design is typical of pre–World War II architecture in New York City. The facade is clad in Indiana limestone panels made by the Indiana Limestone Company and sourced from a quarry in south-central Indiana; the panels give the building its signature blonde color. According to official fact sheets, the facade uses of limestone and granite, ten million bricks, and of aluminum and stainless steel. The building also contains 6,514 windows. The decorative features on the facade are largely geometric, in contrast with earlier buildings, whose decorations often were intended to represent a specific narrative.

The main entrance, composed of three sets of metal doors, is at the center of the facade's Fifth Avenue elevation, flanked by molded piers that are topped with eagles. Above the main entrance is a transom, a triple-height transom window with geometric patterns, and the golden letters "Empire State" above the fifth-floor windows. There are two entrances each on 33rd and 34th streets, with modernistic, stainless steel canopies projecting from the entrances on 33rd and 34th streets there. Above the secondary entrances are triple windows, less elaborate in design than those on Fifth Avenue.

The storefronts on the first floor contain aluminum-framed doors and windows within a black granite cladding. The second through fourth stories consist of windows alternating with wide stone piers and narrower stone mullions. The fifth story contains windows alternating with wide and narrow mullions, and is topped by a horizontal stone sill.

The facade of the tower stories is split into several vertical bays on each side, with windows projecting slightly from the limestone cladding. The bays are arranged into sets of one, two, or three windows on each floor. The bays are separated by alternating narrow and wide piers, the inclusion of which may have been influenced by the design of the contemporary Daily News Building. The windows in each bay are separated by vertical nickel-chrome steel mullions and connected by horizontal aluminum spandrels between each floor. The windows are placed within stainless-steel frames, which saved money by eliminating the need to apply a stone finish around the windows. In addition, the use of aluminum spandrels obviated the need for cross-bonding, which would have been required if stone had been used instead.

The building was originally equipped with white searchlights at the top. They were first used in November 1932 when they lit up to signal Roosevelt's victory over Hoover in the presidential election of that year. These were later swapped for four "Freedom Lights" in 1956. In February 1964, flood lights were added on the 72nd floor to illuminate the top of the building at night so that the building could be seen from the World Fair later that year. The lights were shut off from November 1973 to July 1974 because of the energy crisis at the time. In 1976, the businessman Douglas Leigh suggested that Wien and Helmsley install 204 metal-halide lights, which were four times as bright as the 1,000 incandescent lights they were to replace. New red, white, and blue metal-halide lights were installed in time for the country's bicentennial that July. After the bicentennial, Helmsley retained the new lights due to the reduced maintenance cost, about $116 a year.

Since October 12, 1977, the spire has been lit in colors chosen to match seasonal events and holidays. Organizations are allowed to make requests through the building's website. The building is also lit in the colors of New York-based sports teams on nights when they host games: for example, orange, blue, and white for the New York Knicks; red, white, and blue for the New York Rangers. The spire can also be lit to commemorate events including disasters, anniversaries, or deaths, as well as for celebrations such as Pride and Halloween. In 1998, the building was lit in blue after the death of singer Frank Sinatra, who was nicknamed "Ol' Blue Eyes".

The structure was lit in red, white, and blue for several months after the collapse of the World Trade Center on September 11, 2001. On January 13, 2012, the building was lit in red, orange, and yellow to honor the 60th anniversary of the NBC program "The Today Show". After retired basketball player Kobe Bryant's January 2020 death, the building was lit in purple and gold, signifying the colors of his former team, the Los Angeles Lakers.

In addition to lightings, the Empire State Building is able to do immersive visual projections on the building's exterior. Most recently partnering with Netflix in May 2022 to celebrate the return of Stranger Things fourth season by projecting the Upside Down onto the Empire State Building.

In 2012, the building's four hundred metal halide lamps and floodlights were replaced with 1,200 LED fixtures, increasing the available colors from nine to over 16 million. The computer-controlled system allows the building to be illuminated in ways that were unable to be done previously with plastic gels. For instance, CNN used the top of the Empire State Building as a scoreboard during the 2012 United States presidential election, using red and blue lights to represent Republican and Democratic electoral votes respectively. Also, on November 26, 2012, the building had its first synchronized light show, using music from recording artist Alicia Keys. Artists such as Eminem and OneRepublic have been featured in later shows, including the building's annual Holiday Music-to-Lights Show. The building's owners adhere to strict standards in using the lights; for instance, they do not use the lights to play advertisements.

According to official fact sheets, the Empire State Building weighs and has an internal volume of . The interior required of elevator cable and of electrical wires. It has a total floor area of , and each of the floors in the base cover . This gives the building capacity for 20,000 tenants and 15,000 visitors.

The riveted steel frame of the building was originally designed to handle all of the building's gravitational stresses and wind loads. The amount of material used in the building's construction resulted in a very stiff structure when compared to other skyscrapers, with a structural stiffness of versus the Willis Tower's and the John Hancock Center's . A December 1930 feature in "Popular Mechanics" estimated that a building with the Empire State's dimensions would still stand even if hit with an impact of .

Utilities are grouped in a central shaft. On the 6th through 86th stories, the central shaft is surrounded by a main corridor on all four sides. Per the final specifications of the building, the corridor is surrounded in turn by office space deep, maximizing office space at a time before air conditioning became commonplace. Each of the floors has 210 structural columns that pass through it, which provide structural stability but limits the amount of open space on these floors. The relative dearth of stone in the Empire State Building allows for more space overall, with a 1:200 stone-to-building ratio compared to a 1:50 ratio in similar buildings.

The original main lobby is accessed from Fifth Avenue, on the building's east side, and is the only place in the building where the design contains narrative motifs. It contains an entrance with one set of double doors between a pair of revolving doors. At the top of each doorway is a bronze motif depicting one of three "crafts or industries" used in the building's construction—Electricity, Masonry, and Heating. The three-story-high space runs parallel to 33rd and 34th Streets. The lobby contains two tiers of marble: a wainscoting of darker marble, topped by lighter marble. There is a pattern of zigzagging terrazzo tiles on the lobby floor, which leads from east to west. To the north and south are storefronts, which are flanked by tubes of dark rounded marble and topped by a vertical band of grooves set into the marble. Until the 1960s, there was a Longchamps restaurant next to the lobby, with six oval murals designed by Winold Reiss; these murals were placed in storage when the Longchamps closed.

The western ends of the north and south walls include escalators to a mezzanine level. At the west end of the lobby, behind the security desk, is an aluminum relief of the skyscraper as it was originally built (without the antenna). The relief, which was intended to provide a welcoming effect, contains an embossed outline of the building, with rays radiating from the spire and the sun behind it. In the background is a state map of New York with the building's location marked by a "medallion" in the very southeast portion of the outline. A compass is depicted in the bottom right and a plaque to the building's major developers is on the bottom left. A scale model of the building was also placed south of the security desk.
The plaque at the western end of the lobby is on the eastern interior wall of a one-story-tall rectangular-shaped corridor that surrounds the banks of escalators, with a similar design to the lobby. The rectangular-shaped corridor actually consists of two long hallways on the northern and southern sides of the rectangle, as well as a shorter hallway on the eastern side and another long hallway on the western side. At both ends of the northern and southern corridors, there is a bank of four low-rise elevators in between the corridors. The western side of the rectangular elevator-bank corridor extends north to the 34th Street entrance and south to the 33rd Street entrance. It borders three large storefronts and leads to escalators (originally stairs), which go both to the second floor and to the basement. Going from west to east, there are secondary entrances to 34th and 33rd Streets from the northern and southern corridors, respectively. The side entrances from 33rd and 34th Street lead to two-story-high corridors around the elevator core, crossed by stainless steel-and-glass-enclosed bridges at the mezzanine floor.

Until the 1960s, an Art Deco mural, inspired by both the sky and the Machine Age, was installed in the lobby ceilings. Subsequent damage to these murals, designed by artist Leif Neandross, resulted in reproductions being installed. Renovations to the lobby in 2009, such as replacing the clock over the information desk in the Fifth Avenue lobby with an anemometer and installing two chandeliers intended to be part of the building when it originally opened, revived much of its original grandeur. The north corridor contained eight illuminated panels created in 1963 by Roy Sparkia and Renée Nemorov, in time for the 1964 World's Fair, depicting the building as the Eighth Wonder of the World alongside the traditional seven. The building's owners installed a series of paintings by the New York artist Kysa Johnson in the concourse level. Johnson later filed a federal lawsuit, in January 2014, under the Visual Artists Rights Act alleging the negligent destruction of the paintings and damage to her reputation as an artist. As part of the building's 2010 renovation, Denise Amses commissioned a work consisting of 15,000 stars and 5,000 circles, superimposed on a etched-glass installation, in the lobby.

The Empire State Building has 73 elevators in all, including service elevators. Its original 64 elevators, built by the Otis Elevator Company, in a central core and are of varying heights, with the longest of these elevators reaching from the lobby to the 80th floor. As originally built, there were four "express" elevators that connected the lobby, 80th floor, and several landings in between; the other 60 "local" elevators connected the landings with the floors above these intermediate landings. Of the 64 total elevators, 58 were for passenger use (comprising the four express elevators and 54 local elevators), and eight were for freight deliveries. The elevators were designed to move at . At the time of the skyscraper's construction, their practical speed was limited to per city law, but this limit was removed shortly after the building opened.

Additional elevators connect the 80th floor to the six floors above it, as the six extra floors were built after the original 80 stories were approved. The elevators were mechanically operated until 2011, when they were replaced with automatic elevators during the $550 million renovation of the building. An additional elevator connects the 86th and 102nd floor observatories, which allows visitors access the 102nd floor observatory after having their tickets scanned. It also allows employees to access the mechanical floors located between the 87th and 101st floors.

The 80th, 86th, and 102nd floors contain observatories. The latter two observatories saw a combined average of four million visitors per year in 2010. Since opening, the observatories have been more popular than similar observatories at 30 Rockefeller Plaza, the Chrysler Building, the first One World Trade Center, or the Woolworth Building, despite being more expensive. There are variable charges to enter the observatories; one ticket allows visitors to go as high as the 86th floor, and there is an additional charge to visit the 102nd floor. Other ticket options for visitors include scheduled access to view the sunrise from the observatory, a "premium" guided tour with VIP access, and the "AM/PM" package which allows for two visits in the same day.

The 86th floor observatory contains both an enclosed viewing gallery and an open-air outdoor viewing area, allowing for it to remain open 365 days a year regardless of the weather. The 102nd floor observatory is completely enclosed and much smaller in size. The 102nd floor observatory was closed to the public from the late 1990s to 2005 due to limited viewing capacity and long lines. The observation decks were redesigned in mid-1979. The 102nd floor was again redesigned in a project that was completed in 2019, allowing the windows to be extended from floor to ceiling and widening the space in the observatory overall. An observatory on the 80th floor, opened in 2019, includes various exhibits as well as a mural of the skyline drawn by British artist Stephen Wiltshire. An interactive multimedia museum, with multiple hands-on exhibitions about the building's history, was added during this project. The design of the Observatory Experience was inspired by the plans and designs of the original Empire State Building.

According to a 2010 report by Concierge.com, the five lines to enter the observation decks are "as legendary as the building itself". Concierge.com stated that there were five lines: the sidewalk line, the lobby elevator line, the ticket purchase line, the second elevator line, and the line to get off the elevator and onto the observation deck. In 2016, New York City's official tourism website made note of only three lines: the security check line, the ticket purchase line, and the second elevator line. Following renovations completed in 2019, designed to streamline queuing and reduce wait times, guests enter from a single entrance on 34th Street, where they make their way through exhibits on their way up to the observatories. Guests were offered a variety of ticket packages, including a package that enables them to skip the lines throughout the duration of their stay. The Empire State Building garners significant revenue from ticket sales for its observation decks, making more money from ticket sales than it does from renting office space during some years.

In early 1994, a motion simulator attraction was built on the 2nd floor, as a complement to the observation deck. The original cinematic presentation lasted approximately 25 minutes, while the simulation was about eight minutes. The ride had two incarnations. The original version, which ran from 1994 until around 2002, featured James Doohan, "" Scotty, as the airplane's pilot who humorously tried to keep the flight under control during a storm. After the September 11 attacks in 2001, the ride was closed. An updated version debuted in mid-2002, featuring actor Kevin Bacon as the pilot, with the new flight also going haywire. This new version served a more informative goal, as opposed to the old version's main purpose of entertainment, and contained details about the 9/11 attacks. The simulator received mixed reviews, with assessments of the ride ranging from "great" to "satisfactory" to "corny".

The final stage of the building was the installation of a hollow mast, a steel shaft fitted with elevators and utilities, above the 86th floor. At the top would be a conical roof and the 102nd-floor docking station. Inside, the elevators would ascend from the 86th floor ticket offices to a 101st-floor waiting room. From there, stairs would lead to the 102nd floor, where passengers would enter the airships. The airships would have been moored to the spire at the equivalent of the building's 106th floor.

As constructed, the mast contains four rectangular tiers topped by a cylindrical shaft with a conical pinnacle. On the 102nd floor (formerly the 101st floor), there is a door with stairs ascending to the 103rd floor (formerly the 102nd). This was built as a disembarkation floor for airships tethered to the building's spire, and has a circular balcony outside. It is now an access point to reach the spire for maintenance. The room now contains electrical equipment, but celebrities and dignitaries may also be given permission to take pictures there. Above the 103rd floor, there is a set of stairs and a ladder to reach the spire for maintenance work. The mast's 480 windows were all replaced in 2015. The mast serves as the base of the building's broadcasting antenna.

Broadcasting began at the Empire State Building on December 22, 1931, when NBC and RCA began transmitting experimental television broadcasts from a small antenna erected atop the mast, with two separate transmitters for the visual and audio data. They leased the 85th floor and built a laboratory there. In 1934, RCA was joined by Edwin Howard Armstrong in a cooperative venture to test his FM system from the building's antenna. This setup, which entailed the installation of the world's first FM transmitter, continued only until October of the next year due to disputes between RCA and Armstrong. Specifically, NBC wanted to install more TV equipment in the room where Armstrong's transmitter was located.

After some time, the 85th floor became home to RCA's New York television operations initially as experimental station W2XBS channel 1 then, from 1941, as commercial station WNBT channel 1 (now WNBC channel 4). NBC's FM station, W2XDG, began transmitting from the antenna in 1940. NBC retained exclusive use of the top of the building until 1950 when the Federal Communications Commission (FCC) ordered the exclusive deal be terminated. The FCC directive was based on consumer complaints that a common location was necessary for the seven extant New York-area television stations to transmit from so that receiving antennas would not have to be constantly adjusted. Other television broadcasters would later join RCA at the building on the 81st through 83rd floors, often along with sister FM stations. Construction of a dedicated broadcast tower began on July 27, 1950, with TV, and FM, transmissions starting in 1951. The broadcast tower was completed in 1953. From 1951, six broadcasters agreed to pay a combined $600,000 per year for the use of the antenna. In 1965, a separate set of FM antennae was constructed ringing the 103rd floor observation area to act as a master antenna.

The placement of the stations in the Empire State Building became a major issue with the construction of the World Trade Center's Twin Towers in the late 1960s, and early 1970s. The greater height of the Twin Towers would reflect radio waves broadcast from the Empire State Building, eventually resulting in some broadcasters relocating to the newer towers instead of suing the developer, the Port Authority of New York and New Jersey. Even though the nine stations who were broadcasting from the Empire State Building were leasing their broadcast space until 1984, most of these stations moved to the World Trade Center as soon as it was completed in 1971. The broadcasters obtained a court order stipulating that the Port Authority had to build a mast and transmission equipment in the North Tower, as well as pay the broadcasters' leases in the Empire State Building until 1984. Only a few broadcasters renewed their leases in the Empire State Building.

The September 11 attacks destroyed the World Trade Center and the broadcast centers atop it, leaving most of the city's stations without a transmitter for ten days until the Armstrong Tower in Alpine, New Jersey, was re-activated temporarily. By October 2001, nearly all of the city's commercial broadcast stations (both television and FM radio) were again transmitting from the top of the Empire State Building. In a report that Congress commissioned about the transition from analog television to digital television, it was stated that the placement of broadcast stations in the Empire State Building was considered "problematic" due to interference from nearby buildings. In comparison, the congressional report stated that the former Twin Towers had very few buildings of comparable height nearby thus signals suffered little interference. In 2003, a few FM stations were relocated to the nearby Condé Nast Building to reduce the number of broadcast stations using the Empire State Building. Eleven television stations and twenty-two FM stations had signed 15-year leases in the building by May 2003. It was expected that a taller broadcast tower in Bayonne, New Jersey, or Governors Island, would be built in the meantime with the Empire State Building being used as a "backup" since signal transmissions from the building were generally of poorer quality. Following the construction of One World Trade Center in the late 2000s and early 2010s, some TV stations began moving their transmitting facilities there.

, the Empire State Building is home to the following stations:

The site was previously owned by John Jacob Astor of the prominent Astor family, who had owned the site since the mid-1820s. In 1893, John Jacob Astor Sr.'s grandson William Waldorf Astor opened the Waldorf Hotel on the site. Four years later, his cousin, John Jacob Astor IV, opened the 16-story Astoria Hotel on an adjacent site. The two portions of the Waldorf–Astoria hotel had 1,300 bedrooms, making it the largest hotel in the world at the time. After the death of its founding proprietor, George Boldt, in early 1918, the hotel lease was purchased by Thomas Coleman du Pont. By the 1920s, the old Waldorf–Astoria was becoming dated and the elegant social life of New York had moved much farther north. Additionally, many stores had opened on Fifth Avenue north of 34th Street. The Astor family decided to build a replacement hotel on Park Avenue and sold the hotel to Bethlehem Engineering Corporation in 1928 for $14–16 million. The hotel closed shortly thereafter on May 3, 1929.

Bethlehem Engineering Corporation originally intended to build a 25-story office building on the Waldorf–Astoria site. The company's president, Floyd De L. Brown, paid $100,000 of the $1 million down payment required to start construction on the building, with the promise that the difference would be paid later. Brown borrowed $900,000 from a bank but defaulted on the loan.

After Brown was unable to secure additional funding, the land was resold to Empire State Inc., a group of wealthy investors that included Louis G. Kaufman, Ellis P. Earle, John J. Raskob, Coleman du Pont, and Pierre S. du Pont. The name came from the state nickname for New York. Alfred E. Smith, a former Governor of New York and U.S. presidential candidate whose 1928 campaign had been managed by Raskob, was appointed head of the company. The group also purchased nearby land so they would have the needed for the base, with the combined plot measuring wide by long. The Empire State Inc. consortium was announced to the public in August 1929. Concurrently, Smith announced the construction of an 80-story building on the site, to be taller than any other buildings in existence.

Empire State Inc. contracted William F. Lamb, of architectural firm Shreve, Lamb and Harmon, to create the building design. Lamb produced the building drawings in just two weeks using the firm's earlier designs for the Reynolds Building in Winston-Salem, North Carolina, as the basis. He had also been inspired by Raymond Hood's design for the Daily News Building, which was being constructed at the same time. Concurrently, Lamb's partner Richmond Shreve created "bug diagrams" of the project requirements. The 1916 Zoning Act forced Lamb to design a structure that incorporated setbacks resulting in the lower floors being larger than the upper floors. Consequently, the building was designed from the top down, giving it a pencil-like shape. The plans were devised within a budget of $50 million and a stipulation that the building be ready for occupancy within 18 months of the start of construction.

The original plan of the building was 50 stories, but was later increased to 60 and then 80 stories. Height restrictions were placed on nearby buildings to ensure that the top fifty floors of the planned 80-story, building would have unobstructed views of the city. "The New York Times" lauded the site's proximity to mass transit, with the Brooklyn–Manhattan Transit's 34th Street station and the Hudson and Manhattan Railroad's 33rd Street terminal one block away, as well as Penn Station two blocks away and Grand Central Terminal nine blocks away at its closest. It also praised the of proposed floor space near "one of the busiest sections in the world". The Empire State Building was to be a typical office building, but Raskob intended to build it "better and in a bigger way", according to architectural writer Donald J. Reynolds.

While plans for the Empire State Building were being finalized, an intense competition in New York for the title of "world's tallest building" was underway. 40 Wall Street (then the Bank of Manhattan Building) and the Chrysler Building in Manhattan both vied for this distinction and were already under construction when work began on the Empire State Building. The "Race into the Sky", as popular media called it at the time, was representative of the country's optimism in the 1920s, fueled by the building boom in major cities. The race was defined by at least five other proposals, although only the Empire State Building would survive the Wall Street Crash of 1929. The 40 Wall Street tower was revised, in April 1929, from to making it the world's tallest. The Chrysler Building added its steel tip to its roof in October 1929, thus bringing it to a height of and greatly exceeding the height of 40 Wall Street. The Chrysler Building's developer, Walter Chrysler, realized that his tower's height would exceed the Empire State Building's as well, having instructed his architect, William Van Alen, to change the Chrysler's original roof from a stubby Romanesque dome to a narrow steel spire. Raskob, wishing to have the Empire State Building be the world's tallest, reviewed the plans and had five floors added as well as a spire; however, the new floors would need to be set back because of projected wind pressure on the extension. On November 18, 1929, Smith acquired a lot at 27–31 West 33rd Street, adding to the width of the proposed office building's site. Two days later, Smith announced the updated plans for the skyscraper. The plans included an observation deck on the 86th-floor roof at a height of , higher than the Chrysler's 71st-floor observation deck.

The 1,050-foot Empire State Building would only be taller than the Chrysler Building, and Raskob was afraid that Chrysler might try to "pull a trick like hiding a rod in the spire and then sticking it up at the last minute." The plans were revised one last time in December 1929, to include a 16-story, metal "crown" and an additional mooring mast intended for dirigibles. The roof height was now , making it the tallest building in the world by far, even without the antenna. The addition of the dirigible station meant that another floor, the now-enclosed 86th floor, would have to be built below the crown; however, unlike the Chrysler's spire, the Empire State's mast would serve a practical purpose. A revised plan was announced to the public in late December 1929, just before the start of construction. The final plan was sketched within two hours, the night before the plan was supposed to be presented to the site's owners in January 1930. "The New York Times" reported that the spire was facing some "technical problems", but they were "no greater than might be expected under such a novel plan." By this time the blueprints for the building had gone through up to fifteen versions before they were approved. Lamb described the other specifications he was given for the final, approved plan:

The contractors were Starrett Brothers and Eken, which were composed of Paul and William A. Starrett and Andrew J. Eken. The project was financed primarily by Raskob and Pierre du Pont, while James Farley's General Builders Supply Corporation supplied the building materials. John W. Bowser was the construction superintendent of the project, and the structural engineer of the building was Homer G. Balcom. The tight completion schedule necessitated the commencement of construction even though the design had yet to be finalized.

Demolition of the old Waldorf–Astoria began on October 1, 1929. Stripping the building down was an arduous process, as the hotel had been constructed using more rigid material than earlier buildings had been. Furthermore, the old hotel's granite, wood chips, and "'precious' metals such as lead, brass, and zinc" were not in high demand, resulting in issues with disposal. Most of the wood was deposited into a woodpile on nearby 30th Street or was burned in a swamp elsewhere. Much of the other materials that made up the old hotel, including the granite and bronze, were dumped into the Atlantic Ocean near Sandy Hook, New Jersey.

By the time the hotel's demolition started, Raskob had secured the required funding for the construction of the building. The plan was to start construction later that year but, on October 24, the New York Stock Exchange experienced the major and sudden Wall Street Crash, marking the beginning of the decade-long Great Depression. Despite the economic downturn, Raskob refused to cancel the project because of the progress that had been made up to that point. Neither Raskob, who had ceased speculation in the stock market the previous year, nor Smith, who had no stock investments, suffered financially in the crash. However, most of the investors were affected and as a result, in December 1929, Empire State Inc. obtained a $27.5 million loan from Metropolitan Life Insurance Company so construction could begin. The stock market crash resulted in no demand for new office space; Raskob and Smith nonetheless started construction, as canceling the project would have resulted in greater losses for the investors.

A structural steel contract was awarded on January 12, 1930, with excavation of the site beginning ten days later on January 22, before the old hotel had been completely demolished. Two twelve-hour shifts, consisting of 300 men each, worked continuously to dig the deep foundation. Small pier holes were sunk into the ground to house the concrete footings that would support the steelwork. Excavation was nearly complete by early March, and construction on the building itself started on March 17, with the builders placing the first steel columns on the completed footings before the rest of the footings had been finished. Around this time, Lamb held a press conference on the building plans. He described the reflective steel panels parallel to the windows, the large-block Indiana Limestone facade that was slightly more expensive than smaller bricks, and the building's vertical lines. Four colossal columns, intended for installation in the center of the building site, were delivered; they would support a combined when the building was finished.

The structural steel was pre-ordered and pre-fabricated in anticipation of a revision to the city's building code that would have allowed the Empire State Building's structural steel to carry , up from , thus reducing the amount of steel needed for the building. Although the 18,000-psi regulation had been safely enacted in other cities, Mayor Jimmy Walker did not sign the new codes into law until March 26, 1930, just before construction was due to commence. The first steel framework was installed on April 1, 1930. From there, construction proceeded at a rapid pace; during one stretch of 10 working days, the builders erected fourteen floors. This was made possible through precise coordination of the building's planning, as well as the mass production of common materials such as windows and spandrels. On one occasion, when a supplier could not provide timely delivery of dark Hauteville marble, Starrett switched to using Rose Famosa marble from a German quarry that was purchased specifically to provide the project with sufficient marble.

The scale of the project was massive, with trucks carrying "16,000 partition tiles, 5,000 bags of cement, of sand and 300 bags of lime" arriving at the construction site every day. There were also cafes and concession stands on five of the incomplete floors so workers did not have to descend to the ground level to eat lunch. Temporary water taps were also built so workers did not waste time buying water bottles from the ground level. Additionally, carts running on a small railway system transported materials from the basement storage to elevators that brought the carts to the desired floors where they would then be distributed throughout that level using another set of tracks. The of steel ordered for the project was the largest-ever single order of steel at the time, comprising more steel than was ordered for the Chrysler Building and 40 Wall Street combined. According to historian John Tauranac, building materials were sourced from numerous, and distant, sources with "limestone from Indiana, steel girders from Pittsburgh, cement and mortar from upper New York State, marble from Italy, France, and England, wood from northern and Pacific Coast forests, [and] hardware from New England." The facade, too, used a variety of material, most prominently Indiana limestone but also Swedish black granite, terracotta, and brick.

By June 20, the skyscraper's supporting steel structure had risen to the 26th floor, and by July 27, half of the steel structure had been completed. Starrett Bros. and Eken endeavored to build one floor a day in order to speed up construction, achieving a pace of stories per week; prior to this, the fastest pace of construction for a building of similar height had been stories per week. While construction progressed, the final designs for the floors were being designed from the ground up (as opposed to the general design, which had been from the roof down). Some of the levels were still undergoing final approval, with several orders placed within an hour of a plan being finalized. On September 10, as steelwork was nearing completion, Smith laid the building's cornerstone during a ceremony attended by thousands. The stone contained a box with contemporary artifacts including the previous day's "New York Times", a U.S. currency set containing all denominations of notes and coins minted in 1930, a history of the site and building, and photographs of the people involved in construction. The steel structure was topped out at on September 19, twelve days ahead of schedule and 23 weeks after the start of construction. Workers raised a flag atop the 86th floor to signify this milestone.

Work on the building's interior and crowning mast commenced after the topping out. The mooring mast topped out on November 21, two months after the steelwork had been completed. Meanwhile, work on the walls and interior was progressing at a quick pace, with exterior walls built up to the 75th floor by the time steelwork had been built to the 95th floor. The majority of the facade was already finished by the middle of November. Because of the building's height, it was deemed infeasible to have many elevators or large elevator cabins, so the builders contracted with the Otis Elevator Company to make 66 cars that could speed at , which represented the largest-ever elevator order at the time.

In addition to the time constraint builders had, there were also space limitations because construction materials had to be delivered quickly, and trucks needed to drop off these materials without congesting traffic. This was solved by creating a temporary driveway for the trucks between 33rd and 34th Streets, and then storing the materials in the building's first floor and basements. Concrete mixers, brick hoppers, and stone hoists inside the building ensured that materials would be able to ascend quickly and without endangering or inconveniencing the public. At one point, over 200 trucks made material deliveries at the building site every day. A series of relay and erection derricks, placed on platforms erected near the building, lifted the steel from the trucks below and installed the beams at the appropriate locations. The Empire State Building was structurally completed on April 11, 1931, twelve days ahead of schedule and 410 days after construction commenced. Al Smith shot the final rivet, which was made of solid gold.

The project involved more than 3,500 workers at its peak, including 3,439 on a single day, August 14, 1930. Many of the workers were Irish and Italian immigrants, with a sizable minority of Mohawk ironworkers from the Kahnawake reserve near Montreal. According to official accounts, five workers died during the construction, although the "New York Daily News" gave reports of 14 deaths and a headline in the socialist magazine "The New Masses" spread unfounded rumors of up to 42 deaths. The Empire State Building cost $40,948,900 to build (equivalent to $ in ), including demolition of the Waldorf–Astoria. This was lower than the $60 million budgeted for construction.

Lewis Hine captured many photographs of the construction, documenting not only the work itself but also providing insight into the daily life of workers in that era. Hine's images were used extensively by the media to publish daily press releases. According to the writer Jim Rasenberger, Hine "climbed out onto the steel with the ironworkers and dangled from a derrick cable hundreds of feet above the city to capture, as no one ever had before (or has since), the dizzy work of building skyscrapers". In Rasenberger's words, Hine turned what might have been an assignment of "corporate flak" into "exhilarating art". These images were later organized into their own collection. Onlookers were enraptured by the sheer height at which the steelworkers operated. "New York" magazine wrote of the steelworkers: "Like little spiders they toiled, spinning a fabric of steel against the sky".

The Empire State Building officially opened on May 1, 1931, forty-five days ahead of its projected opening date, and eighteen months from the start of construction. The opening was marked with an event featuring United States President Herbert Hoover, who turned on the building's lights with the ceremonial button push from Washington, D.C. Over 350 guests attended the opening ceremony, and following luncheon, at the 86th floor including Jimmy Walker, Governor Franklin D. Roosevelt, and Al Smith. An account from that day stated that the view from the luncheon was obscured by a fog, with other landmarks such as the Statue of Liberty being "lost in the mist" enveloping New York City. The Empire State Building officially opened the next day. Advertisements for the building's observatories were placed in local newspapers, while nearby hotels also capitalized on the events by releasing advertisements that lauded their proximity to the newly opened building.

According to "The New York Times", builders and real estate speculators predicted that the Empire State Building would be the world's tallest building "for many years", thus ending the great New York City skyscraper rivalry. At the time, most engineers agreed that it would be difficult to build a building taller than , even with the hardy Manhattan bedrock as a foundation. Technically, it was believed possible to build a tower of up to , but it was deemed uneconomical to do so, especially during the Great Depression. As the tallest building in the world, at that time, and the first one to exceed 100 floors, the Empire State Building became an icon of the city and, ultimately, of the nation.

In 1932, the Fifth Avenue Association gave the building its 1931 "gold medal" for architectural excellence, signifying that the Empire State had been the best-designed building on Fifth Avenue to open in 1931. A year later, on March 2, 1933, the movie "King Kong" was released. The movie, which depicted a large stop motion ape named Kong climbing the Empire State Building, made the still-new building into a cinematic icon.

At the beginning of 1931, Fifth Avenue was experiencing high demand for storefront space, with only 12 of 224 stores being unoccupied. The Empire State Building, along with 500 Fifth Avenue and 608 Fifth Avenue, were expected to add a combined 11 stores. The office space was less successful, as the Empire State Building's opening had coincided with the Great Depression in the United States. In the first year, only 23 percent of the available space was rented, as compared to the early 1920s, where the average building would be 52 percent occupied upon opening and 90 percent occupied within five years. The lack of renters led New Yorkers to deride the building as the "Empty State Building" or "Smith's Folly".

The earliest tenants in the Empire State Building were large companies, banks, and garment industries. Jack Brod, one of the building's longest resident tenants, co-established the Empire Diamond Corporation with his father in the building in mid-1931 and rented space in the building until he died in 2008. Brod recalled that there were only about 20 tenants at the time of opening, including him, and that Al Smith was the only real tenant in the space above his seventh-floor offices. Generally, during the early 1930s, it was rare for more than a single office space to be rented in the building, despite Smith's and Raskob's aggressive marketing efforts in the newspapers and to anyone they knew. The building's lights were continuously left on, even in the unrented spaces, to give the impression of occupancy. This was exacerbated by competition from Rockefeller Center as well as from buildings on 42nd Street, which, when combined with the Empire State Building, resulted in surplus of office space in a slow market during the 1930s.

Aggressive marketing efforts served to reinforce the Empire State Building's status as the world's tallest. The observatory was advertised in local newspapers as well as on railroad tickets. The building became a popular tourist attraction, with one million people each paying one dollar to ride elevators to the observation decks in 1931. In its first year of operation, the observation deck made approximately $2 million in revenue, as much as its owners made in rent that year. By 1936, the observation deck was crowded on a daily basis, with food and drink available for purchase at the top, and by 1944 the building had received its five-millionth visitor. In 1931, NBC took up tenancy, leasing space on the 85th floor for radio broadcasts. From the outset the building was in debt, losing $1 million per year by 1935. Real estate developer Seymour Durst recalled that the building was so underused in 1936 that there was no elevator service above the 45th floor, as the building above the 41st floor was empty except for the NBC offices and the Raskob/Du Pont offices on the 81st floor.

Per the original plans, the Empire State Building's spire was intended to be an airship docking station. Raskob and Smith had proposed dirigible ticketing offices and passenger waiting rooms on the 86th floor, while the airships themselves would be tied to the spire at the equivalent of the building's 106th floor. An elevator would ferry passengers from the 86th to the 101st floor after they had checked in on the 86th floor, after which passengers would have climbed steep ladders to board the airship. The idea, however, was impractical and dangerous due to powerful updrafts caused by the building itself, the wind currents across Manhattan, and the spires of nearby skyscrapers. Furthermore, even if the airship were to successfully navigate all these obstacles, its crew would have to jettison some ballast by releasing water onto the streets below in order to maintain stability, and then tie the craft's nose to the spire with no mooring lines securing the tail end of the craft. On September 15, 1931, a small commercial United States Navy airship circled 25 times in winds. The airship then attempted to dock at the mast, but its ballast spilled and the craft was rocked by unpredictable eddies. The near-disaster scuttled plans to turn the building's spire into an airship terminal, although one blimp did manage to make a single newspaper delivery afterward.

On July 28, 1945, a B-25 Mitchell bomber crashed into the north side of the Empire State Building, between the 79th and 80th floors. One engine completely penetrated the building and landed in a neighboring block, while the other engine and part of the landing gear plummeted down an elevator shaft. Fourteen people were killed in the incident, but the building escaped severe damage and was reopened two days later.

By the 1940s, the Empire State Building was 98 percent occupied. The structure broke even for the first time in the 1950s. At the time, mass transit options in the building's vicinity were limited compared to the present day. Despite this challenge, the Empire State Building began to attract renters due to its reputation. A radio antenna was erected on top of the towers starting in 1950, allowing the area's television stations to be broadcast from the building.

Despite the turnaround in the building's fortunes, Raskob listed it for sale in 1951, with a minimum asking price of $50 million. The property was purchased by business partners Roger L. Stevens, Henry Crown, Alfred R. Glancy and Ben Tobin. The sale was brokered by the Charles F. Noyes Company, a prominent real estate firm in upper Manhattan, for $51 million, the highest price paid for a single structure at the time. By this time, the Empire State had been fully leased for several years with a waiting list of parties looking to lease space in the building, according to the "Cortland Standard". That same year, six news companies formed a partnership to pay a combined annual fee of $600,000 to use the building's antenna, which was completed in 1953. Crown bought out his partners' ownership stakes in 1954, becoming the sole owner. The following year, the American Society of Civil Engineers named the building one of the "Seven Modern Civil Engineering Wonders".

In 1961, Lawrence A. Wien signed a contract to purchase the Empire State Building for $65 million, with Harry B. Helmsley acting as partners in the building's operating lease. This became the new highest price for a single structure. Over 3,000 people paid $10,000 for one share each in a company called Empire State Building Associates. The company in turn subleased the building to another company headed by Helmsley and Wien, raising $33 million of the funds needed to pay the purchase price. In a separate transaction, the land underneath the building was sold to Prudential Insurance for $29 million. Helmsley, Wien, and Peter Malkin quickly started a program of minor improvement projects, including the first-ever full-building facade refurbishment and window-washing in 1962, the installation of new flood lights on the 72nd floor in 1964, and replacement of the manually operated elevators with automatic units in 1966. The little-used western end of the second floor was used as a storage space until 1964, at which point it received escalators to the first floor as part of its conversion into a highly sought retail area.

In 1961, the same year that Helmsley, Wien, and Malkin had purchased the Empire State Building, the Port Authority of New York and New Jersey formally backed plans for a new World Trade Center in Lower Manhattan. The plan originally included 66-story twin towers with column-free open spaces. The Empire State's owners and real estate speculators were worried that the twin towers' of office space would create a glut of rentable space in Manhattan as well as take away the Empire State Building's profits from lessees. A revision in the World Trade Center's plan brought the twin towers to each or 110 stories, taller than the Empire State. Opponents of the new project included prominent real-estate developer Robert Tishman, as well as Wien's Committee for a Reasonable World Trade Center. In response to Wien's opposition, Port Authority executive director Austin J. Tobin said that Wien was only opposing the project because it would overshadow his Empire State Building as the world's tallest building.

The World Trade Center's twin towers started construction in 1966. The following year, the Ostankino Tower succeeded the Empire State Building as the tallest freestanding structure in the world. In 1970, the Empire State surrendered its position as the world's tallest building, when the World Trade Center's still-under-construction North Tower surpassed it, on October 19; the North Tower was topped out on December 23, 1970.

In December 1975, the observation deck was opened on the 110th floor of the Twin Towers, significantly higher than the 86th floor observatory on the Empire State Building. The latter was also losing revenue during this period, particularly as a number of broadcast stations had moved to the World Trade Center in 1971; although the Port Authority continued to pay the broadcasting leases for the Empire State until 1984. The Empire State Building was still seen as prestigious, having seen its forty-millionth visitor in March 1971.

By 1980, there were nearly two million annual visitors, although a building official had previously estimated between 1.5 million and 1.75 million annual visitors. The building received its own ZIP code in May 1980 in a roll out of 63 new postal codes in Manhattan. At the time, its tenants collectively received 35,000 pieces of mail daily. The Empire State Building celebrated its 50th anniversary on May 1, 1981, with a much-publicized, but poorly received, laser light show, as well as an "Empire State Building Week" that ran through to May 8. The New York City Landmarks Preservation Commission (LPC) voted to designate the building and its lobby as city landmarks on May 19, 1981,

Capital improvements were made to the Empire State Building during the early to mid-1990s at a cost of $55 million. Because all of the building's windows were being replaced at the same time, the LPC mandated a paint-color test for the windows; the test revealed that the Empire State Building's original windows were actually red. The improvements also entailed replacing alarm systems, elevators, windows, and air conditioning; making the observation deck compliant with the Americans with Disabilities Act of 1990 (ADA); and refurbishing the limestone facade. The observation deck renovation was added after disability rights groups and the United States Department of Justice filed a lawsuit against the building in 1992, in what was the first lawsuit filed by an organization under the new law. A settlement was reached in 1994, in which Empire State Building Associates agreed to add ADA-compliant elements, such as new elevators, ramps, and automatic doors, during the renovation.

Prudential sold the land under the building in 1991 for $42 million to a buyer representing hotelier , who was imprisoned at the time in connection with the deadly at the in Tokyo. In 1994, Donald Trump entered into a joint-venture agreement with Yokoi, with a shared goal of breaking the Empire State Building's lease on the land in an effort to gain total ownership of the building so that, if successful, the two could reap the potential profits of merging the ownership of the building with the land beneath it. Having secured a half-ownership of the land, Trump devised plans to take ownership of the building itself so he could renovate it, even though Helmsley and Malkin had already started their refurbishment project. He sued Empire State Building Associates in February 1995, claiming that the latter had caused the building to become a "high-rise slum" and a "second-rate, rodent-infested" office tower. Trump had intended to have Empire State Building Associates evicted for violating the terms of their lease, but was denied. This led to Helmsley's companies countersuing Trump in May. This sparked a series of lawsuits and countersuits that lasted several years, partly arising from Trump's desire to obtain the building's master lease by taking it from Empire State Building Associates. Upon Harry Helmsley's death in 1997, the Malkins sued Helmsley's widow, Leona Helmsley, for control of the building.

Following the destruction of the World Trade Center during the September 11 attacks in 2001, the Empire State Building again became the tallest building in New York City, but was only the second-tallest building in the Americas after the Sears (later Willis) Tower in Chicago. As a result of the attacks, transmissions from nearly all of the city's commercial television and FM radio stations were again broadcast from the Empire State Building. The attacks also led to an increase in security due to persistent terror threats against prominent sites in New York City.

In 2002, Trump and Yokoi sold their land claim to the Empire State Building Associates, now headed by Malkin, in a $57.5 million sale. This action merged the building's title and lease for the first time in half a century. Despite the lingering threat posed by the 9/11 attacks, the Empire State Building remained popular with 3.5 million visitors to the observatories in 2004, compared to about 2.8 million in 2003.

Even though she maintained her ownership stake in the building until the post-consolidation IPO in October 2013, Leona Helmsley handed over day-to-day operations of the building in 2006 to Peter Malkin's company. In 2008, the building was temporarily "stolen" by the "New York Daily News" to show how easy it was to transfer the deed on a property, since city clerks were not required to validate the submitted information, as well as to help demonstrate how fraudulent deeds could be used to obtain large mortgages and then have individuals disappear with the money. The paperwork submitted to the city included the names of Fay Wray, the famous star of "King Kong", and Willie Sutton, a notorious New York bank robber. The newspaper then transferred the deed back over to the legitimate owners, who at that time were Empire State Land Associates.

Starting in 2009, the building's public areas received a $550 million renovation, with improvements to the air conditioning and waterproofing, renovations to the observation deck and main lobby, and relocation of the gift shop to the 80th floor. About $120 million was spent on improving the energy efficiency of the building, with the goal of reducing energy emissions by 38% within five years. For example, all of the windows were refurbished onsite into film-coated "superwindows" which block heat but pass light. Air conditioning operating costs on hot days were reduced, saving $17 million of the project's capital cost immediately and partially funding some of the other retrofits. The Empire State Building won the Leadership in Energy and Environmental Design (LEED) Gold for Existing Buildings rating in September 2011, as well as the World Federation of Great Towers' Excellence in Environment Award for 2010. For the LEED Gold certification, the building's energy reduction was considered, as was a large purchase of carbon offsets. Other factors included low-flow bathroom fixtures, green cleaning supplies, and use of recycled paper products.

On April 30, 2012, One World Trade Center topped out, taking the Empire State Building's record of tallest in the city. By 2014, the building was owned by the Empire State Realty Trust (ESRT), with Anthony Malkin as chairman, CEO, and president. The ESRT was a public company, having begun trading publicly on the New York Stock Exchange the previous year. In August 2016, the Qatar Investment Authority (QIA) was issued new fully diluted shares equivalent to 9.9% of the trust; this investment gave them partial ownership of the entirety of the ESRT's portfolio, and as a result, partial ownership of the Empire State Building. The trust's president John Kessler called it an "endorsement of the company's irreplaceable assets". The investment has been described by the real-estate magazine "The Real Deal" as "an unusual move for a sovereign wealth fund", as these funds typically buy direct stakes in buildings rather than real estate companies. Other foreign entities that have a stake in the ESRT include investors from Norway, Japan, and Australia.

A renovation of the Empire State Building was commenced in the 2010s to further improve energy efficiency, public areas, and amenities. In August 2018, to improve the flow of visitor traffic, the main visitor's entrance was shifted to 20 West 34th Street as part of a major renovation of the observatory lobby. The new lobby includes several technological features, including large LED panels, digital ticket kiosks in nine languages, and a two-story architectural model of the building surrounded by two metal staircases. The first phase of the renovation, completed in 2019, features an updated exterior lighting system and digital hosts. The new lobby also features free Wi-Fi provided for those waiting. A exhibit with nine galleries opened in July 2019. The 102nd floor observatory, the third phase of the redesign, reopened to the public on October 12, 2019. That portion of the project included outfitting the space with floor-to-ceiling glass windows and a brand-new glass elevator. The final portion of the renovations to be completed was a new observatory on the 80th floor, which opened on December 2, 2019. In total, the renovation cost $160 million or $165 million and took four years to finish.

A comprehensive restoration of the building's mooring and antenna masts also began in June 2019. Antennas on the mooring mast were removed or relocated to the upper mast, while the aluminum panels were cleaned and coated with silver paint. To minimize disruption to the observation decks, the restoration work took place at night. The project was completed by late 2020.

The longest world record held by the Empire State Building was for the tallest skyscraper (to structural height), which it held for 42 years until it was surpassed by the North Tower of the World Trade Center in October 1970. The Empire State Building was also the tallest human-made structure in the world before it was surpassed by the Griffin Television Tower Oklahoma (KWTV Mast) in 1954, and the tallest freestanding structure in the world until the completion of the Ostankino Tower in 1967. An early-1970s proposal to dismantle the spire and replace it with an additional 11 floors, which would have brought the building's height to 1,494 feet (455 m) and made it once again the world's tallest at the time, was considered but ultimately rejected.

With the destruction of the World Trade Center in the September 11 attacks, the Empire State Building again became the tallest building in New York City, and the second-tallest building in the Americas, surpassed only by the Willis Tower in Chicago. The Empire State Building remained the tallest building in New York until the new One World Trade Center reached a greater height in April 2012. , it is the seventh-tallest building in New York City and the tenth-tallest in the United States. The Empire State Building is the 49th-tallest in the world . It is also the eleventh-tallest freestanding structure in the Americas behind the tallest U.S. buildings and the CN Tower.

, the building houses around 1,000 businesses. Current tenants include:
Former tenants include:

At 9:40 am on July 28, 1945, a B-25 Mitchell bomber, piloted in thick fog by Lieutenant Colonel William Franklin Smith Jr., crashed into the north side of the Empire State Building between the 79th and 80th floors (then the offices of the National Catholic Welfare Council). One engine completely penetrated the building, landing on the roof of a nearby building where it started a fire that destroyed a penthouse. The other engine and part of the landing gear plummeted down an elevator shaft, causing a fire that was extinguished in 40 minutes. Fourteen people were killed in the incident. Elevator operator Betty Lou Oliver fell 75 stories and survived, which still holds the Guinness World Record for the longest survived elevator fall recorded.

Despite the damage and loss of life, many floors were open two days later. The crash helped spur the passage of the long-pending Federal Tort Claims Act of 1946, as well as the insertion of retroactive provisions into the law, allowing people to sue the government for the incident. Also as a result of the crash, the Civil Aeronautics Administration enacted strict regulations regarding flying over New York City, setting a minimum flying altitude of above sea level regardless of the weather conditions.

A year later, on July 24, 1946, another airplane narrowly missed striking the building. The unidentified twin-engine plane scraped past the observation deck, frightening the tourists there.

On January 24, 2000, an elevator in the building suddenly descended 40 stories after a cable that controlled the cabin's maximum speed was severed. The elevator fell from the 44th floor to the fourth floor, where a narrowed elevator shaft provided a second safety system. Despite the 40-floor fall, both of the passengers in the cabin at the time were only slightly injured. After the fall, building inspectors reviewed all of the building's elevators.

Because of the building's iconic status, it and other Midtown landmarks are popular locations for suicide attempts. More than 30 people have attempted suicide over the years by jumping from the upper parts of the building, with most attempts being successful.

The first suicide from the building occurred on April 7, 1931, before it was even completed, when a carpenter who had been laid-off went to the 58th floor and jumped. The first suicide after the building's opening occurred from the 86th floor observatory in February 1935, when Irma P. Eberhardt fell onto a marquee sign. On December 16, 1943, William Lloyd Rambo jumped to his death from the 86th floor, landing amidst Christmas shoppers on the street below. In the early morning of September 27, 1946, shell-shocked Marine Douglas W. Brashear Jr. jumped from the 76th-floor window of the Grant Advertising Agency; police found his shoes from his body.

On May 1, 1947, Evelyn McHale leapt to her death from the 86th floor observation deck and landed on a limousine parked at the curb. Photography student Robert Wiles took a photo of McHale's oddly intact corpse a few minutes after her death. The police found a suicide note among possessions that she left on the observation deck: "He is much better off without me... I wouldn't make a good wife for anybody". The photo ran in the May 12, 1947, edition of "Life" magazine and is often referred to as "The Most Beautiful Suicide". It was later used by visual artist Andy Warhol in one of his prints entitled "Suicide (Fallen Body)". A mesh fence was put up around the 86th floor terrace in December 1947 after five people tried to jump during a three-week span in October and November of that year. By then, sixteen people had died from suicide jumps.

Only one person has jumped from the upper observatory. Frederick Eckert of Astoria ran past a guard in the enclosed 102nd-floor gallery on November 3, 1932, and jumped a gate leading to an outdoor catwalk intended for dirigible passengers. He landed and died on the roof of the 86th floor observation promenade.

Two people have survived falls by not falling more than a floor. On December 2, 1979, Elvita Adams jumped from the 86th floor, only to be blown back onto a ledge on the 85th floor by a gust of wind and left with a broken hip. On April 25, 2013, a man fell from the 86th floor observation deck, but he landed alive with minor injuries on an 85th-floor ledge where security guards brought him inside and paramedics transferred him to a hospital for a psychiatric evaluation.

Two fatal shootings have occurred in the direct vicinity of the Empire State Building. Abu Kamal, a 69-year-old Palestinian teacher, shot seven people on the 86th floor observation deck during the afternoon of February 23, 1997. He killed one person and wounded six others before committing suicide. Kamal reportedly committed the shooting in response to events happening in Palestine and Israel.

On the morning of August 24, 2012, 58-year-old Jeffrey T. Johnson shot and killed a former co-worker on the building's Fifth Avenue sidewalk. He had been laid off from his job in 2011. Two police officers confronted the gunman, and he aimed his firearm at them. They responded by firing 16 shots, killing him but also wounding nine bystanders. Most of the injured were hit by bullet fragments, although three took direct hits from bullets.

As the tallest building in the world and the first one to exceed 100 floors, the Empire State Building immediately became an icon of the city and of the nation. In 2013, "Time" magazine noted that the Empire State Building "seems to completely embody the city it has become synonymous with". The historian John Tauranac called it "'the' twentieth-century New York building", despite the existence of taller and more modernist buildings.

The New York City Landmarks Preservation Commission voted to designate the building and its lobby as city landmarks on May 19, 1981, citing the historic nature of the first and second floors, as well as "the fixtures and interior components" of the upper floors. The New York City Planning Commission endorsed the landmark status. The building became a National Historic Landmark in 1986 in close alignment with the New York City Landmarks report. The Empire State Building was added to the National Register of Historic Places the following year due to its architectural significance.

Early architectural critics also focused on the Empire State Building's exterior ornamentation. Architectural critic Talbot Hamlin wrote in 1931, "That it is the world's tallest building is purely incidental." George Shepard Chappell, writing in "The New Yorker" under the pseudonym "T-Square", wrote the same year that the Empire State Building had a "palpably enormous" appeal to the general public, and that "its difference and distinction [lay] in the extreme sensitiveness of its entire design". Edmund Wilson of "The New Republic" wrote that the building's neutral color palette made it "New York's handsomest skyscraper".

Architectural critics also wrote negatively of the mast, especially in light of its failure to become a real air terminal. Chappell called the mast "a silly gesture", and Lewis Mumford called it "a public comfort station for migratory birds". Nevertheless, architecture critic Douglas Haskell said the Empire State Building's appeal came from the fact that it was "caught at the exact moment of transition—caught between metal and stone, between the idea of 'monumental mass' and that of airy volume, between handicraft and machine design, and in the swing from what was essentially handicraft to what will be essentially industrial methods of fabrication."

Early in the building's history, travel companies such as Short Line Motor Coach Service and New York Central Railroad used the building as an icon to symbolize the city. In a 1932 survey of 50 American architects, fourteen ranked the Empire State Building as the United States' best building; the Empire State Building received more votes than any building except the Lincoln Memorial. After the construction of the first World Trade Center, architect Paul Goldberger noted that the Empire State Building "is famous for being tall, but it is good enough to be famous for being good."

As an icon of the United States, it is also very popular among Americans. In a 2007 survey, the American Institute of Architects found that the Empire State Building was "America's favorite building". The building was originally a symbol of hope in a country devastated by the Depression, as well as a work of accomplishment by newer immigrants. The writer Benjamin Flowers states that the Empire State was "a building intended to celebrate a new America, built by men (both clients and construction workers) who were themselves new Americans." The architectural critic Jonathan Glancey refers to the building as an "icon of American design". Additionally, in 2007, the Empire State Building was first on the AIA's List of America's Favorite Architecture.

The Empire State Building has been hailed as an example of a "wonder of the world" due to the massive effort expended during construction. "The Washington Star" listed it as part of one of the "seven wonders of the modern world" in 1931, while "Holiday" magazine wrote in 1958 that the Empire State's height would be taller than the combined heights of the Eiffel Tower and the Great Pyramid of Giza. The American Society of Civil Engineers also declared the building "A Modern Civil Engineering Wonder of the United States" in 1958 and one of the Seven Wonders of the Modern World in 1994. Ron Miller, in a 2010 book, also described the Empire State Building as one of the "seven wonders of engineering". It has often been called the Eighth Wonder of the World as well, an appellation that it has held since shortly after opening. The panels installed in the lobby in 1963 reflected this, showing the seven original wonders alongside the Empire State Building. The Empire State Building also became the standard of reference to describe the height and length of other structures globally, both natural and human-made.

The building has also inspired replicas. The New York-New York Hotel and Casino in Paradise, Nevada, contains the "Empire Tower", a 47-story replica of the Empire State Building.In addition, the New York-New York Hotel and Casino in Paradise, Nevada, contains the "Chrysler Tower", a replica of the Chrysler Building measuring 35 or 40 stories tall. A portion of the hotel's interior was also designed to resemble the Empire State Building's interior.

As an icon of New York City, the Empire State Building has been featured in various films, books, TV shows, and video games. According to the building's official website, more than 250 movies contain depictions of the Empire State Building. In his book about the building, John Tauranac writes that its first documented appearance in popular culture was "Swiss Family Manhattan", a 1932 children's story by Christopher Morley. A year later, the film "King Kong" depicted Kong, a giant stop motion ape that climbs the Empire State Building during the film's climax, bringing the building into the popular imagination. Later movies such as "An Affair to Remember" (1957), "Sleepless in Seattle" (1993), and "Independence Day" (1996) also prominently featured the building. The building has also been featured in other works, such as "Daleks in Manhattan", a 2007 episode of the TV series "Doctor Who"; and "Empire", an eight-hour black-and-white silent film by Andy Warhol, which was later added to the Library of Congress's National Film Registry.

Throughout its history, the Empire State Building has welcomed celebrities, royalty, and dignitaries to visit the observation deck. From celebrities like Taylor Swift and Zendaya to royalty such as Prince William, the Empire State Building hosts notable figures every year.

The Empire State Building Run-Up, a foot race from ground level to the 86th-floor observation deck, has been held annually since 1978. It is organized by NYCRUNS. Its participants are referred to both as runners and as climbers, and are often tower running enthusiasts. The race covers a vertical distance of and takes in 1,576 steps. The record time is 9 minutes and 33 seconds, achieved by Australian professional cyclist Paul Crake in 2003, at a climbing rate of per hour.





Eugenics

Eugenics ( ; ) is a set of beliefs and practices that aim to improve the genetic quality of a human population. Historically, eugenicists have attempted to alter human gene pools by excluding people and groups judged to be inferior or promoting those judged to be superior. In recent years, the term has seen a revival in bioethical discussions on the usage of new technologies such as CRISPR and genetic screening, with heated debate around whether these technologies should be considered eugenics or not.

The concept predates the term; Plato suggested applying the principles of selective breeding to humans around 400 BCE. Early advocates of eugenics in the 19th century regarded it as a way of improving groups of people. In contemporary usage, the term "eugenics" is closely associated with scientific racism. Modern bioethicists who advocate new eugenics characterize it as a way of enhancing individual traits, regardless of group membership.

While eugenic principles have been practiced as early as ancient Greece, the contemporary history of eugenics began in the late 19th century, when a popular eugenics movement emerged in the United Kingdom, and then spread to many countries, including the United States, Canada, Australia, and most European countries (e.g. , Sweden and Germany). In this period, people from across the political spectrum espoused eugenic ideas. Consequently, many countries adopted eugenic policies, intended to improve the quality of their populations' genetic stock. Such programs included both "positive" measures, such as encouraging individuals deemed particularly "fit" to reproduce, and "negative" measures, such as marriage prohibitions and forced sterilization of people deemed unfit for reproduction. Those deemed "unfit to reproduce" often included people with mental or physical disabilities, people who scored in the low ranges on different IQ tests, criminals and "deviants", and members of disfavored minority groups.

The eugenics movement became associated with Nazi Germany and the Holocaust when the defense of many of the defendants at the Nuremberg trials of 1945 to 1946 attempted to justify their human-rights abuses by claiming there was little difference between the Nazi eugenics programs and the US eugenics programs. In the decades following World War II, with more emphasis on human rights, many countries began to abandon eugenics policies, although some Western countries (the United States, Canada, and Sweden among them) continued to carry out forced sterilizations. Since the 1980s and 1990s, with new assisted reproductive technology procedures available, such as gestational surrogacy (available since 1985), preimplantation genetic diagnosis (available since 1989), and cytoplasmic transfer (first performed in 1996), concern has grown about the possible revival of a more potent form of eugenics after decades of promoting human rights.

A criticism of eugenics policies is that, regardless of whether "negative" or "positive" policies are used, they are susceptible to abuse because the genetic selection criteria are determined by whichever group has political power at the time. Furthermore, many criticize "negative eugenics" in particular as a violation of basic human rights, seen since 1968's Proclamation of Tehran, as including the right to reproduce. Another criticism is that eugenics policies eventually lead to a loss of genetic diversity, thereby resulting in inbreeding depression due to a loss of genetic variation. Yet another criticism of contemporary eugenics policies is that they propose to permanently and artificially disrupt millions of years of human evolution, and that attempting to create genetic lines "clean" of "disorders" can have far-reaching ancillary downstream effects in the genetic ecology, including negative effects on immunity and on species resilience. Eugenics is commonly seen in popular media, as highlighted by series like "Resident Evil".

Types of eugenic practices have existed for millennia. Some indigenous peoples of Brazil are known to have practiced infanticide against children born with physical abnormalities since precolonial times. In ancient Greece, the philosopher Plato suggested selective mating to produce a "guardian" class. In Sparta, every Spartan child was inspected by the council of elders, the Gerousia, who determined whether or not the child was fit to live.

The geographer Strabo ( 64 BCE - 24 CE) states that the Samnites would take ten virgin women and ten young men who were considered to be the best representation of their sex and mate them. Following this, the best women would be given to the best male, then the second-best women to the second-best male. It is possible that the "best" men and women were chosen based on athletic capabilities. This would continue until all 20 people had been assigned to one another. Any selected male dishonoring himself, would be separated from his partner.

In the early years of the Roman Republic, a Roman father was obliged by law to immediately kill any "dreadfully deformed" child. According to Tacitus ( - ), a Roman of the Imperial Period, the Germanic tribes of his day killed any member of their community they deemed cowardly, unwarlike or "stained with abominable vices", usually by drowning them in swamps. Modern historians, however, see Tacitus' ethnographic writing as unreliable in such details.

The idea of a modern project for improving the human population through selective breeding was originally developed by Francis Galton (1822-1911), and was initially inspired by Darwinism and its theory of natural selection. Galton had read his half-cousin Charles Darwin's theory of evolution, which sought to explain the development of plant and animal species, and desired to apply it to humans. Based on his biographical studies, Galton believed that desirable human qualities were hereditary traits, although Darwin strongly disagreed with this elaboration of his theory. In 1883, one year after Darwin's death, Galton gave his research a name: "eugenics". With the introduction of genetics, eugenics became associated with genetic determinism, the belief that human character is entirely or in the majority caused by genes, unaffected by education or living conditions. Many of the early geneticists were not Darwinians, and evolution theory was not needed for eugenics policies based on genetic determinism. Throughout its recent history, eugenics has remained controversial.

Eugenics became an academic discipline at many colleges and universities and received funding from many sources. Organizations were formed to win public support for and to sway opinion towards responsible eugenic values in parenthood, including the British Eugenics Education Society of 1907 and the American Eugenics Society of 1921. Both sought support from leading clergymen and modified their message to meet religious ideals. In 1909, the Anglican clergymen William Inge and James Peile both wrote for the Eugenics Education Society. Inge was an invited speaker at the 1921 International Eugenics Conference, which was also endorsed by the Roman Catholic Archbishop of New York Patrick Joseph Hayes. The book "The Passing of the Great Race" ("Or, The Racial Basis of European History") by American eugenicist, lawyer, and amateur anthropologist Madison Grant was published in 1916. Although subsequently influential, the book was largely ignored when it first appeared, and it went through several revisions and editions. Nevertheless, the book was used by people who advocated restricted immigration as justification for what became known as "scientific racism".

Three International Eugenics Conferences presented a global venue for eugenicists, with meetings in 1912 in London, and in 1921 and 1932 in New York City. Eugenic policies in the United States were first implemented by state-level legislators in the early 1900s. Eugenic policies also took root in France, Germany, and Great Britain. Later, in the 1920s and 1930s, the eugenic policy of sterilizing certain mental patients was implemented in other countries including Belgium, Brazil, Canada, Japan and Sweden. Frederick Osborn's 1937 journal article "Development of a Eugenic Philosophy" framed eugenics as a social philosophy—a philosophy with implications for social order. That definition is not universally accepted. Osborn advocated for higher rates of sexual reproduction among people with desired traits ("positive eugenics") or reduced rates of sexual reproduction or sterilization of people with less-desired or undesired traits ("negative eugenics").

In addition to being practiced in a number of countries, eugenics was internationally organized through the International Federation of Eugenics Organizations. Its scientific aspects were carried on through research bodies such as the Kaiser Wilhelm Institute of Anthropology, Human Heredity, and Eugenics, the Cold Spring Harbor Carnegie Institution for Experimental Evolution, and the Eugenics Record Office. Politically, the movement advocated measures such as sterilization laws. In its moral dimension, eugenics rejected the doctrine that all human beings are born equal and redefined moral worth purely in terms of genetic fitness. Its racist elements included pursuit of a pure "Nordic race" or "Aryan" genetic pool and the eventual elimination of "unfit" races. Many leading British politicians subscribed to the theories of eugenics. Winston Churchill supported the British Eugenics Society and was an honorary vice president for the organization. Churchill believed that eugenics could solve "race deterioration" and reduce crime and poverty.

Early critics of the philosophy of eugenics included the American sociologist Lester Frank Ward, the English writer G. K. Chesterton, the German-American anthropologist Franz Boas, who argued that advocates of eugenics greatly over-estimate the influence of biology, and Scottish tuberculosis pioneer and author Halliday Sutherland. Ward's 1913 article "Eugenics, Euthenics, and Eudemics", Chesterton's 1917 book , and Boas' 1916 article "" (published in "The Scientific Monthly") were all harshly critical of the rapidly growing movement. Sutherland identified eugenicists as a major obstacle to the eradication and cure of tuberculosis in his 1917 address "Consumption: Its Cause and Cure", and criticism of eugenicists and Neo-Malthusians in his 1921 book "Birth Control" led to a writ for libel from the eugenicist Marie Stopes. Several biologists were also antagonistic to the eugenics movement, including Lancelot Hogben. Other biologists such as J. B. S. Haldane and R. A. Fisher expressed skepticism in the belief that sterilization of "defectives" would lead to the disappearance of undesirable genetic traits.

Among institutions, the Catholic Church was an opponent of state-enforced sterilizations, but accepted isolating people with hereditary diseases so as not to let them reproduce. Attempts by the Eugenics Education Society to persuade the British government to legalize voluntary sterilization were opposed by Catholics and by the Labour Party. The American Eugenics Society initially gained some Catholic supporters, but Catholic support declined following the 1930 papal encyclical "Casti connubii". In this, Pope Pius XI explicitly condemned sterilization laws: "Public magistrates have no direct power over the bodies of their subjects; therefore, where no crime has taken place and there is no cause present for grave punishment, they can never directly harm, or tamper with the integrity of the body, either for the reasons of eugenics or for any other reason."

As a social movement, eugenics reached its greatest popularity in the early decades of the 20th century, when it was practiced around the world and promoted by governments, institutions, and influential individuals (such as the playwright G. B. Shaw). Many countries enacted various eugenics policies, including: genetic screenings, birth control, promoting differential birth rates, marriage restrictions, segregation (both racial segregation and sequestering the mentally ill), compulsory sterilization, forced abortions or forced pregnancies, ultimately culminating in genocide. By 2014, gene selection (rather than "people selection") was made possible through advances in genome editing, leading to what is sometimes called "new eugenics", also known as "neo-eugenics", "consumer eugenics", or "liberal eugenics"; which focuses on individual freedom and allegedly pull away from racism, sexism, heterosexism or a focus on intelligence.

Anti-miscegenation laws in the United States made it a crime for individuals to wed someone categorized as belonging to a different race. These laws were part of a broader policy of racial segregation in the United States to minimize contact between people of different ethnicities. Race laws and practices in the United States were explicitly used as models by the Nazi regime when it developed the Nuremberg Laws, stripping Jewish citizens of their citizenship.

The scientific reputation of eugenics started to decline in the 1930s, a time when Ernst Rüdin used eugenics as a justification for the racial policies of Nazi Germany. Adolf Hitler had praised and incorporated eugenic ideas in "Mein Kampf" in 1925 and emulated eugenic legislation for the sterilization of "defectives" that had been pioneered in the United States once he took power. Some common early 20th century eugenics methods involved identifying and classifying individuals and their families, including the poor, mentally ill, blind, deaf, developmentally disabled, promiscuous women, homosexuals, and racial groups (such as the Roma and Jews in Nazi Germany) as "degenerate" or "unfit", and therefore led to segregation, institutionalization, sterilization, and even mass murder. The Nazi policy of identifying German citizens deemed mentally or physically unfit and then systematically killing them with poison gas, referred to as the Aktion T4 campaign, is understood by historians to have paved the way for the Holocaust.

By the end of World War II, many eugenics laws were abandoned, having become associated with Nazi Germany. H. G. Wells, who had called for "the sterilization of failures" in 1904, stated in his 1940 book "The Rights of Man: Or What Are We Fighting For?" that among the human rights, which he believed should be available to all people, was "a prohibition on mutilation, sterilization, torture, and any bodily punishment". After World War II, the practice of "imposing measures intended to prevent births within [a national, ethnical, racial or religious] group" fell within the definition of the new international crime of genocide, set out in the Convention on the Prevention and Punishment of the Crime of Genocide. The Charter of Fundamental Rights of the European Union also proclaims "the prohibition of eugenic practices, in particular those aiming at selection of persons". In spite of the decline in discriminatory eugenics laws, some government mandated sterilizations continued into the 21st century. During the ten years President Alberto Fujimori led Peru from 1990 to 2000, 2,000 persons were allegedly involuntarily sterilized. China maintained its one-child policy until 2015 as well as a suite of other eugenics-based legislation to reduce population size and manage fertility rates of different populations.

While there is ostensibly less support for eugenics today, forced sterilization remains a problem around the world. It has been used against Indigenous women in Canada as recently as 2019. Until 2014, the Netherlands required sterilization of transgender people as a prerequisite for legal recognition of their genders. A similar law persists in Japan and was upheld in 2019 as constitutional. In the United States, most people affected by forced sterilization are under guardianship, though procedures were also performed on inmates in the California prison system. According to a report from The National Women's Law Center, 31 states and D.C. have laws allowing forced sterilization, and in most other states it is not clear whether it is legal or not. Seventeen states allow the sterilization of children under the age of 18, and some do not even require a legal guardian to make that decision.

Developments in genetic, genomic, and reproductive technologies at the beginning of the 21st century have raised numerous questions regarding the ethical status of eugenics, effectively creating a resurgence of interest in the subject. Some, such as UC Berkeley sociologist Troy Duster, have argued that modern genetics is a back door to eugenics. This view was shared by then-White House Assistant Director for Forensic Sciences, Tania Simoncelli, who stated in a 2003 publication by the Population and Development Program at Hampshire College that advances in pre-implantation genetic diagnosis (PGD) are moving society to a "new era of eugenics", and that, unlike the Nazi eugenics, modern eugenics is consumer driven and market based, "where children are increasingly regarded as made-to-order consumer products".

In a 2006 newspaper article, Richard Dawkins said that discussion regarding eugenics was inhibited by the shadow of Nazi misuse, to the extent that some scientists would not admit that breeding humans for certain abilities is at all possible. He believes that it is not physically different from breeding domestic animals for traits such as speed or herding skill. Dawkins felt that enough time had elapsed to at least ask just what the ethical differences were between breeding for ability versus training athletes or forcing children to take music lessons, though he could think of persuasive reasons to draw the distinction.

Lee Kuan Yew, the founding father of Singapore, promoted eugenics as late as 1983. A proponent of nature over nurture, he stated that "intelligence is 80% nature and 20% nurture", and attributed the successes of his children to genetics. In his speeches, Lee urged highly educated women to have more children, claiming that "social delinquents" would dominate unless their fertility rate increased. In 1984, Singapore began providing financial incentives to highly educated women to encourage them to have more children. In 1985, incentives were significantly reduced after public uproar.

In October 2015, the United Nations' International Bioethics Committee wrote that the ethical problems of human genetic engineering should not be confused with the ethical problems of the 20th century eugenics movements. However, it is still problematic because it challenges the idea of human equality and opens up new forms of discrimination and stigmatization for those who do not want, or cannot afford, the technology.

The National Human Genome Research Institute says that eugenics is "inaccurate", "scientifically erroneous and immoral".

Transhumanism is often associated with eugenics, although most transhumanists holding similar views nonetheless distance themselves from the term "eugenics" (preferring "germinal choice" or "reprogenetics") to avoid having their position confused with the discredited theories and practices of early-20th-century eugenic movements.

Prenatal screening has been called by some a contemporary form of eugenics because it may lead to abortions of fetuses with undesirable traits.

A system was proposed by California State Senator Nancy Skinner to compensate victims of the well-documented examples of prison sterilizations resulting from California's eugenics programs, but this did not pass by the bill's 2018 deadline in the Legislature.

The term "eugenics" and its modern field of study were first formulated by Francis Galton in 1883, drawing on the recent work of his half-cousin Charles Darwin. Galton published his observations and conclusions in his book "Inquiries into Human Faculty and Its Development".

The origins of the concept began with certain interpretations of Mendelian inheritance and the theories of August Weismann. The word "eugenics" is derived from the Greek word "eu" ("good" or "well") and the suffix "-genēs" ("born"); Galton intended it to replace the word "stirpiculture", which he had used previously but which had come to be mocked due to its perceived sexual overtones. Galton defined eugenics as "the study of all agencies under human control which can improve or impair the racial quality of future generations".

The most disputed aspect of eugenics has been the definition of "improvement" of the human gene pool, such as what is a beneficial characteristic and what is a defect. Historically, this aspect of eugenics was tainted with scientific racism and pseudoscience.

Historically, the idea of "eugenics" has been used to argue for a broad array of practices ranging from prenatal care for mothers deemed genetically desirable to the forced sterilization and murder of those deemed unfit. To population geneticists, the term has included the avoidance of inbreeding without altering allele frequencies; for example, J. B. S. Haldane wrote that "the motor bus, by breaking up inbred village communities, was a powerful eugenic agent." Debate as to what exactly counts as eugenics continues today.

Edwin Black, journalist, historian, and author of "War Against the Weak", argues that eugenics is often deemed a pseudoscience because what is defined as a genetic improvement of a desired trait is a cultural choice rather than a matter that can be determined through objective scientific inquiry. Black states the following about the pseudoscientific past of eugenics: "As American eugenic pseudoscience thoroughly infused the scientific journals of the first three decades of the twentieth century, Nazi-era eugenics placed its unmistakable stamp on the medical literature of the twenties, thirties and forties." Black says that eugenics was the pseudoscience aimed at "improving" the human race, used by Adolf Hitler to "try to legitimize his anti- Semitism by medicalizing it, and wrapping it in the more palatable pseudoscientific facade of eugenics."

Early eugenicists were mostly concerned with factors of perceived intelligence that often correlated strongly with social class. These included Karl Pearson and Walter Weldon, who worked on this at the University College London. In his lecture "Darwinism, Medical Progress and Eugenics", Pearson claimed that everything concerning eugenics fell into the field of medicine.

Eugenic policies have been conceptually divided into two categories. Positive eugenics is aimed at encouraging reproduction among the genetically advantaged; for example, the reproduction of the intelligent, the healthy, and the successful. Possible approaches include financial and political stimuli, targeted demographic analyses, "in vitro" fertilization, egg transplants, and cloning. Negative eugenics aimed to eliminate, through sterilization or segregation, those deemed physically, mentally, or morally "undesirable". This includes abortions, sterilization, and other methods of family planning. Both positive and negative eugenics can be coercive; in Nazi Germany, for example, abortion was illegal for women deemed by the state to be fit.

The heterozygote test is used for the early detection of recessive hereditary diseases, allowing for couples to determine if they are at risk of passing genetic defects to a future child. The goal of the test is to estimate the likelihood of passing the hereditary disease to future descendants.

There are examples of eugenic acts that managed to lower the prevalence of recessive diseases, although not influencing the prevalence of heterozygote carriers of those diseases. The elevated prevalence of certain genetically transmitted diseases among the Ashkenazi Jewish population (Tay–Sachs, cystic fibrosis, Canavan's disease, and Gaucher's disease), has been decreased in current populations by the application of genetic screening.

The first major challenge to conventional eugenics based on genetic inheritance was made in 1915 by Thomas Hunt Morgan. He demonstrated the event of genetic mutation occurring outside of inheritance involving the discovery of the hatching of a fruit fly ("Drosophila melanogaster") with white eyes from a family with red eyes, demonstrating that major genetic changes occurred outside of inheritance. Additionally, Morgan criticized the view that certain traits, such as intelligence and criminality, were hereditary because these traits were subjective. Despite Morgan's public rejection of eugenics, much of his genetic research was adopted by proponents of eugenics.

Pleiotropy occurs when one gene influences multiple, seemingly unrelated phenotypic traits, an example being phenylketonuria, which is a human disease that affects multiple systems but is caused by one gene defect. Andrzej Pękalski, from the University of Wroclaw, argues that eugenics can cause harmful loss of genetic diversity if a eugenics program selects a pleiotropic gene that could possibly be associated with a positive trait. Pekalski uses the example of a coercive government eugenics program that prohibits people with myopia from breeding but has the unintended consequence of also selecting against high intelligence since the two go together. Further, a culturally-accepted "improvement" of the gene pool may result in extinction, due to increased vulnerability to disease, reduced ability to adapt to environmental change, and other factors that may not be anticipated in advance. This has been evidenced in numerous instances, in isolated island populations. A long-term, species-wide eugenics plan might lead to such a scenario because the elimination of traits deemed undesirable would reduce genetic diversity by definition.

While the science of genetics has increasingly provided means by which certain characteristics and conditions can be identified and understood, given the complexity of human genetics, culture, and psychology, at this point there is no agreed objective means of determining which traits might be ultimately desirable or undesirable. Some conditions such as sickle-cell disease and cystic fibrosis respectively confer immunity to malaria and resistance to cholera when a single copy of the recessive allele is contained within the genotype of the individual, so eliminating these genes is undesirable in places where such diseases are common.

Societal and political consequences of eugenics call for a place in the discussion on the ethics behind the eugenics movement. Many of the ethical concerns regarding eugenics arise from its controversial past, prompting a discussion on what place, if any, it should have in the future. Advances in science have changed eugenics. In the past, eugenics had more to do with sterilization and enforced reproduction laws. Now, in the age of a progressively mapped genome, embryos can be tested for susceptibility to disease, gender, and genetic defects, and alternative methods of reproduction such as in vitro fertilization are becoming more common. Therefore, eugenics is no longer "ex post facto" regulation of the living but instead preemptive action on the unborn.

With this change, however, there are ethical concerns which some groups feel warrant more attention before this practice is commonly rolled out. Sterilized individuals, for example, could volunteer for the procedure, albeit under incentive or duress, or at least voice their opinion. The unborn fetus on which these new eugenic procedures are performed cannot speak out, as the fetus lacks the voice to consent or to express their opinion. Philosophers disagree about the proper framework for reasoning about such actions, which change the very identity and existence of future persons.

Edwin Black has described potential "eugenics wars" as the worst-case outcome of eugenics. In his view, this scenario would mean the return of coercive state-sponsored genetic discrimination and human rights violations such as the compulsory sterilization of persons with genetic defects, the killing of the institutionalized and, specifically, the segregation and genocide of races which are considered inferior. Law professors George Annas and Lori Andrews have argued that the use of these technologies could lead to such human-posthuman caste warfare.

Environmental ethicist Bill McKibben argued against germinal choice technology and other advanced biotechnological strategies for human enhancement. He writes that it would be morally wrong for humans to tamper with fundamental aspects of themselves (or their children) in an attempt to overcome universal human limitations, such as vulnerability to aging, maximum life span and biological constraints on physical and cognitive ability. Attempts to "improve" themselves through such manipulation would remove limitations that provide a necessary context for the experience of meaningful human choice. He claims that human lives would no longer seem meaningful in a world where such limitations could be overcome with technology. Even the goal of using germinal choice technology for clearly therapeutic purposes should be relinquished, he argues, since it would inevitably produce temptations to tamper with such things as cognitive capacities. He argues that it is possible for societies to benefit from renouncing particular technologies, using Ming China, Tokugawa Japan and the contemporary Amish as examples.

Amanda Caleb, Professor of Medical Humanities at Geisinger Commonwealth School of Medicine, says "Eugenic laws and policies are now understood as part of a specious devotion to a pseudoscience that actively dehumanizes to support political agendas and not true science or medicine."

Some, for example Nathaniel C. Comfort from Johns Hopkins University, claim that the change from state-led reproductive-genetic decision-making to individual choice has moderated the worst abuses of eugenics by transferring the decision-making process from the state to patients and their families. Comfort suggests that "the eugenic impulse drives us to eliminate disease, live longer and healthier, with greater intelligence, and a better adjustment to the conditions of society; and the health benefits, the intellectual thrill and the profits of genetic bio-medicine are too great for us to do otherwise." Others, such as bioethicist Stephen Wilkinson of Keele University and Honorary Research Fellow Eve Garrard at the University of Manchester, claim that some aspects of modern genetics can be classified as eugenics, but that this classification does not inherently make modern genetics immoral.

In their book published in 2000, "From Chance to Choice: Genetics and Justice", bioethicists Allen Buchanan, Dan Brock, Norman Daniels and Daniel Wikler argued that liberal societies have an obligation to encourage as wide an adoption of eugenic enhancement technologies as possible (so long as such policies do not infringe on individuals' reproductive rights or exert undue pressures on prospective parents to use these technologies) in order to maximize public health and minimize the inequalities that may result from both natural genetic endowments and unequal access to genetic enhancements.

In his book "A Theory of Justice" (1971), American philosopher John Rawls argued that "Over time a society is to take steps to preserve the general level of natural abilities and to prevent the diffusion of serious defects". The original position, a hypothetical situation developed by Rawls, has been used as an argument for "negative eugenics".

The novel "Brave New World" (1931) is a dystopian social science fiction novel by the English author Aldous Huxley, set in a futuristic World State, whose citizens are environmentally engineered into an intelligence-based social hierarchy.

The film "Gattaca" (1997) provides a fictional example of a dystopian society that uses eugenics to decide what people are capable of and their place in the world. Though "Gattaca" was not a box office success, it was critically acclaimed and is said to have crystallized the debate over the controversial topic of human genetic engineering. The film's dystopian depiction of "genoism" has been cited by many bioethicists and laypeople in support of their hesitancy about, or opposition to, eugenics and the societal acceptance of the genetic-determinist ideology that may frame it. In a 1997 review of the film for the journal "Nature Genetics", molecular biologist Lee M. Silver stated that ""Gattaca" is a film that all geneticists should see if for no other reason than to understand the perception of our trade held by so many of the public-at-large". In his 2018 book "Blueprint", behavioural geneticist Robert Plomin writes that while "Gattaca" warned of the dangers of genetic information being used by a totalitarian state, genetic testing could also favour better meritocracy in democratic societies which already administer psychological tests to select people for education and employment. Plomin suggests that polygenic scores might supplement testing in a manner that is free of biases.

Various works by author Robert A. Heinlein mention the Howard Foundation, a group aimed at improving human longevity through selective breeding.






