Digital Equipment Corporation

Digital Equipment Corporation (DEC ), using the trademark Digital, was a major American company in the computer industry from the 1960s to the 1990s. The company was co-founded by Ken Olsen and Harlan Anderson in 1957. Olsen was president until he was forced to resign in 1992, after the company had gone into precipitous decline.

The company produced many different product lines over its history. It is best known for the work in the minicomputer market starting in the mid-1960s. The company produced a series of machines known as the PDP line, with the PDP-8 and PDP-11 being among the most successful minis in history. Their success was only surpassed by another DEC product, the late-1970s VAX "supermini" systems that were designed to replace the PDP-11. Although a number of competitors had successfully competed with Digital through the 1970s, the VAX cemented the company's place as a leading vendor in the computer space.

As microcomputers improved in the late 1980s, especially with the introduction of RISC-based workstation machines, the performance niche of the minicomputer was rapidly eroded. By the early 1990s, the company was in turmoil as their mini sales collapsed and their attempts to address this by entering the high-end market with machines like the VAX 9000 were market failures. After several attempts to enter the workstation and file server market, the DEC Alpha product line began to make successful inroads in the mid-1990s, but was too late to save the company.

DEC was acquired in June 1998 by Compaq in what was at that time the largest merger in the history of the computer industry. During the purchase, some parts of DEC were sold to other companies; the compiler business and the Hudson Fab were sold to Intel. At the time, Compaq was focused on the enterprise market and had recently purchased several other large vendors. DEC was a major player overseas where Compaq had less presence. However, Compaq had little idea what to do with its acquisitions, and soon found itself in financial difficulty of its own. Compaq subsequently merged with Hewlett-Packard (HP) in May 2002.

Ken Olsen and Harlan Anderson were two engineers who had been working at MIT Lincoln Laboratory on the lab's various computer projects. The Lab is best known for their work on what would today be known as "interactivity", and their machines were among the first where operators had direct control over programs running in real-time. These had started in 1944 with the famed Whirlwind, which was originally developed to make a flight simulator for the US Navy, although this was never completed. Instead, this effort evolved into the SAGE system for the US Air Force, which used large screens and light guns to allow operators to interact with radar data stored in the computer.

When the Air Force project wound down, the Lab turned their attention to an effort to build a version of the Whirlwind using transistors in place of vacuum tubes. In order to test their new circuitry, they first built a small 18-bit machine known as TX-0, which first ran in 1956. When the TX-0 successfully proved the basic concepts, attention turned to a much larger system, the 36-bit TX-2 with a then-enormous 64 kWords of core memory. Core was so expensive that parts of TX-0's memory were stripped for the TX-2, and what remained of the TX-0 was then given to MIT on permanent loan.

At MIT, Ken Olsen and Harlan Anderson noticed something odd: students would line up for hours to get a turn to use the stripped-down TX-0, while largely ignoring a faster IBM machine that was also available. The two decided that the draw of interactive computing was so strong that they felt there was a market for a small machine dedicated to this role, essentially a commercialized TX-0. They could sell this to users where the graphical output or real-time operation would be more important than outright performance. Additionally, as the machine would cost much less than the larger systems then available, it would also be able to serve users that needed a lower-cost solution dedicated to a specific task, where a larger 36-bit machine would not be needed.

In 1957, when the pair and Ken's brother Stan sought capital, they found that the American business community was hostile to investing in computer companies. Many smaller computer companies had come and gone in the 1950s, wiped out when new technical developments rendered their platforms obsolete, and even large companies like RCA and General Electric were failing to make a profit in the market. The only serious expression of interest came from Georges Doriot and his American Research and Development Corporation (AR&D). Worried that a new computer company would find it difficult to arrange further financing, Doriot suggested the fledgling company change its business plan to focus less on computers, and even change their name from "Digital Computer Corporation".

The pair returned with an updated business plan that outlined two phases for the company's development. They would start by selling computer modules as stand-alone devices that could be purchased separately and wired together to produce a number of different digital systems for lab use. Then, if these "digital modules" were able to build a self-sustaining business, the company would be free to use them to develop a complete computer in their Phase II. The newly christened "Digital Equipment Corporation" received $70,000 from AR&D for a 70% share of the company, and began operations in a Civil War-era textile mill in Maynard, Massachusetts, where plenty of inexpensive manufacturing space was available.

In early 1958, DEC shipped its first products, the "Digital Laboratory Module" line. The Modules consisted of a number of individual electronic components and germanium transistors mounted to a circuit board, the actual circuits being based on those from the TX-2.

The Laboratory Modules were packaged in an extruded aluminum housing, intended to sit on an engineer's workbench, although a rack-mount bay was sold that held nine laboratory modules. They were then connected together using banana plug patch cords inserted at the front of the modules. Three versions were offered, running at 5 MHz (1957), 500 kHz (1959), or 10 MHz (1960). The Modules proved to be in high demand by other computer companies, who used them to build equipment to test their own systems. Despite the recession of the late 1950s, the company sold $94,000 worth of these modules during 1958 alone (), turning a profit at the end of its first year.

The original Laboratory Modules were soon supplemented with the "Digital System Module" line, which were identical internally but packaged differently. The Systems Modules were designed with all of the connections at the back of the module using 22-pin Amphenol connectors, and were attached to each other by plugging them into a backplane that could be mounted in a 19-inch rack. The backplanes allowed 25 modules in a single 5-1/4 inch section of rack, and allowed the high densities needed to build a computer.

The original laboratory and system module lines were offered in 500 kilocycle, 5 megacycle and 10 megacycle versions. In all cases, the supply voltages were -15 and +10 volts, with logic levels of -3 volts (passive pull-down) and 0 volts (active pull-up).

DEC used the System Modules to build their "Memory Test" machine for testing core memory systems, selling about 50 of these pre-packaged units over the next eight years. The PDP-1 and LINC computers were also built using System Modules (see below).

Modules were part of DEC's product line into the 1970s, although they went through several evolutions during this time as technology changed. The same circuits were then packaged as the first "R" (red) series "Flip-Chip" modules. Later, other Flip-Chip module series provided additional speed, much higher logic density, and industrial I/O capabilities. DEC published extensive data about the modules in free catalogs that became very popular.

With the company established and a successful product on the market, DEC turned its attention to the computer market once again as part of its planned "Phase II". In August 1959, Ben Gurley started design of the company's first computer, the PDP-1. In keeping with Doriot's instructions, the name was an initialism for "Programmable Data Processor", leaving off the term "computer". As Gurley put it, "We aren't building computers, we're building 'Programmable Data Processors'." The prototype was first shown publicly at the Joint Computer Conference in Boston in December 1959. The first PDP-1 was delivered to Bolt, Beranek and Newman in November 1960, and formally accepted the next April. The PDP-1 sold in basic form for $120,000 (). By the time production ended in 1969, 53 PDP-1s had been delivered.

The PDP-1 was supplied standard with 4096 words of core memory, 18-bits per word, and ran at a basic speed of 100,000 operations per second. It was constructed using many System Building Blocks that were packaged into several 19-inch racks. The racks were themselves packaged into a single large mainframe case, with a hexagonal control panel containing switches and lights mounted to lie at table-top height at one end of the mainframe. Above the control panel was the system's standard input/output solution, a punched tape reader and writer. Most systems were purchased with two peripherals, the Type 30 vector graphics display, and a Soroban Engineering modified IBM Model B Electric typewriter that was used as a printer. The Soroban system was notoriously unreliable, and often replaced with a modified Friden Flexowriter, which also contained its own punched tape system. A variety of more-expensive add-ons followed, including magnetic tape systems, punched card readers and punches, and faster punched tape and printer systems.

When DEC introduced the PDP-1, they also mentioned larger machines at 24, 30 and 36 bits, based on the same design. During construction of the prototype PDP-1, some design work was carried out on a 24-bit PDP-2, and the 36-bit PDP-3. Although the PDP-2 never proceeded beyond the initial design, the PDP-3 found some interest and was designed in full. Only one PDP-3 appears to have been built, in 1960, by the CIA's Scientific Engineering Institute (SEI) in Waltham, Massachusetts. According to the limited information available, they used it to process radar cross section data for the Lockheed A-12 reconnaissance aircraft. Gordon Bell remembered that it was being used in Oregon some time later, but could not recall who was using it.

In November 1962, DEC introduced the $65,000 PDP-4. The PDP-4 was similar to the PDP-1 and used a similar instruction set, but used slower memory and different packaging to lower the price. Like the PDP-1, about 54 PDP-4s were eventually sold, most to a customer base similar to the original PDP-1.

In 1964, DEC introduced its new Flip Chip module design, and used it to re-implement the PDP-4 as the PDP-7. The PDP-7 was introduced in December 1964, and about 120 were eventually produced. An upgrade to the Flip Chip led to the R series, which in turn led to the PDP-7A in 1965. The PDP-7 is most famous as the machine for which the Unix operating system was originally written. Unix ran only on DEC systems until the Interdata 8/32.

A more dramatic upgrade to the PDP-1 series was introduced in August 1966, the PDP-9. The PDP-9 was instruction-compatible with the PDP-4 and −7, but ran about twice as fast as the −7 and was intended to be used in larger deployments. At only $19,900 in 1968, the PDP-9 was a big seller, eventually selling 445 machines, more than all of the earlier models combined.

Even while the PDP-9 was being introduced, its replacement was being designed, and was introduced as 1969's PDP-15, which re-implemented the PDP-9 using integrated circuits in place of modules. Much faster than the PDP-9 even in basic form, the PDP-15 also included a floating point unit and a separate input/output processor for further performance gains. Over 400 PDP-15's were ordered in the first eight months of production, and production eventually amounted to 790 examples in 12 basic models. However, by this time other machines in DEC's lineup could fill the same niche at even lower price points, and the PDP-15 would be the last of the 18-bit series.

In 1962, Lincoln Laboratory used a selection of System Building Blocks to implement a small 12-bit machine, and attached it to a variety of analog-to-digital (A to D) input/output (I/O) devices that made it easy to interface with various analog lab equipment. The LINC proved to attract intense interest in the scientific community, and has since been referred to as the first real minicomputer, a machine that was small and inexpensive enough to be dedicated to a single task even in a small lab.

Seeing the success of the LINC, in 1963 DEC took the basic logic design but stripped away the extensive A to D systems to produce the PDP-5. The new machine, the first outside the PDP-1 mould, was introduced at WESTCON on August 11, 1963. A 1964 ad expressed the main advantage of the PDP-5, "Now you can own the PDP-5 computer for what a core memory alone used to cost: $27,000". 116 PDP-5s were produced until the lines were shut down in early 1967. Like the PDP-1 before it, the PDP-5 inspired a series of newer models based on the same basic design that would go on to be more famous than its parent.

On March 22, 1965, DEC introduced the PDP-8, which replaced the PDP-5's modules with the new R-series modules using Flip Chips. The machine was re-packaged into a small tabletop case, which remains distinctive for its use of smoked plastic over the CPU which allowed one to easily see the logic modules plugged into the wire-wrapped backplane of the CPU. Sold standard with 4 kWords of 12-bit core memory and a Teletype Model 33 ASR for basic input/output, the machine listed for only $18,000. The PDP-8 is referred to as the first "real" minicomputer because of its sub-$25,000 price. Sales were, unsurprisingly, very strong, and helped by the fact that several competitors had just entered the market with machines aimed directly at the PDP-5's market space, which the PDP-8 trounced. This gave the company two years of unrestricted leadership, and eventually 1450 "straight eight" machines were produced before it was replaced by newer implementations of the same basic design.

DEC hit an even lower price-point with the PDP-8/S, the S for "serial". As the name implies the /S used a serial arithmetic unit, which was much slower but reduced costs so much that the system sold for under $10,000. DEC then used the new PDP-8 design as the basis for a new LINC, the two-processor LINC-8. The LINC-8 used one PDP-8 CPU and a separate LINC CPU, and included instructions to switch from one to the other. This allowed customers to run their existing LINC programs, or "upgrade" to the PDP-8, all in software. Although not a huge seller, 142 LINC-8s were sold starting at $38,500. Like the original LINC to PDP-5 evolution, the LINC-8 was then modified into the single-processor PDP-12, adding another 1000 machines to the 12-bit family. Newer circuitry designs led to the PDP-8/I and PDP-8/L in 1968. In 1975, one year after an agreement between DEC and Intersil, the Intersil 6100 chip was launched, effectively a PDP-8 on a chip. This was a way to allow PDP-8 software to be run even after the official end-of-life announcement for the DEC PDP-8 product line.

While the PDP-5 introduced a lower-cost line, 1963's PDP-6 was intended to take DEC into the mainframe market with a 36-bit machine. However, the PDP-6 proved to be a "hard sell" with customers, as it offered few obvious advantages over similar machines from the better-established vendors like IBM or Honeywell, in spite of its low cost around $300,000. Only 23 were sold, or 26 depending on the source, and unlike other models the low sales meant the PDP-6 was not improved with successor versions. However, the PDP-6 is historically important as the platform that introduced "Monitor", an early time-sharing operating system that would evolve into the widely used TOPS-10.

When newer Flip Chip packaging allowed the PDP-6 to be re-implemented at a much lower cost, DEC took the opportunity to refine their 36-bit design, introducing the PDP-10 in 1968. The PDP-10 was as much a success as the PDP-6 was a commercial failure; about 700 mainframe PDP-10s were sold before production ended in 1984. The PDP-10 was widely used in university settings, and thus was the basis of many advances in computing and operating system design during the 1970s. DEC later re-branded all of the models in the 36-bit series as the "DECsystem-10", and PDP-10s are generally referred to by the model of their CPU, starting with the "KA10", soon upgraded to the "KI10" (I:Integrated circuit); then to "KL10" (L:Large-scale integration ECL logic); also the "KS10" (S: Small form factor). Unified product line upgrades produced the compatible DECSYSTEM-20, along with a TOPS-20 operating system that included virtual memory support.

The Jupiter Project was supposed to continue the mainframe product line into the future by using gate arrays with an innovative Air Mover Cooling System, coupled with a built-in floating point processing engine called "FBOX". The design was intended for a top tier scientific computing niche, yet the critical performance measurement was based upon COBOL compilation which did not fully utilize the primary design features of Jupiter technology. When the Jupiter Project was cancelled in 1983, some of the engineers adapted aspects of the 36-bit design into a forthcoming 32-bit design, releasing the high-end VAX8600 in 1985.

DEC's successful entry into the computer market took place during a fundamental shift in the underlying organization of the machines from word lengths based on 6-bit characters to those based on 8-bit words needed to support ASCII. DEC began studies of such a machine, the PDP-X, but Ken Olsen did not support it as he could not see how it offered anything their existing 12-bit or 18-bit machines didn't. This led the leaders of the PDP-X project to leave DEC and start Data General, whose 16-bit Data General Nova was released in 1969 and was a huge success.

The success of the Nova finally prompted DEC to take the switch seriously, and they began a crash program to introduce a 16-bit machine of their own. The new system was designed primarily by Harold McFarland, Gordon Bell, Roger Cady, and others. The project was able to leap forward in design with the arrival of Harold McFarland, who had been researching 16-bit designs at Carnegie Mellon University. One of his simpler designs became the basis for the new design, although when they first viewed the proposal, management was not impressed and almost cancelled it.

The result was the PDP-11, released in 1970. It differed from earlier designs considerably. In particular, the new design did not include many of the addressing modes that were intended to make programs smaller in memory, a technique that was widely used on other DEC machines and CISC designs in general. This would mean the machine would spend more time accessing memory, which would slow it down. However, the machine also extended the idea of multiple "General Purpose Registers" (GPRs), which gave the programmer flexibility to use these high-speed memory caches as they needed, potentially addressing the performance issues.
A major advance in the PDP-11 design was DEC's Unibus, which supported all peripherals through memory mapping. This allowed a new device to be added easily, generally only requiring plugging a hardware interface board into the backplane and possibly adding a jumper to the wire wrapped backplane, and then installing software that read and wrote to the mapped memory to control it. The relative ease of interfacing spawned a huge market of third party add-ons for the PDP-11, which made the machine even more useful.

The combination of architectural innovations proved superior to competitors and the "11" architecture was soon the industry leader, propelling DEC back to a strong market position. The design was later expanded to allow paged physical memory and memory protection features, useful for multitasking and time-sharing. Some models supported separate instruction and data spaces for an effective virtual address size of 128 kB within a physical address size of up to 4 MB. Smaller PDP-11s, implemented as single-chip CPUs, continued to be produced until 1996, by which time over 600,000 had been sold.

The PDP-11 supported several operating systems, including Bell Labs' new Unix operating system as well as DEC's DOS-11, RSX-11, IAS, RT-11, DSM-11, and RSTS/E. Many early PDP-11 applications were developed using standalone paper-tape utilities. DOS-11 was the PDP-11's first disk operating system, but was soon supplanted by more capable systems. RSX provided a general-purpose multitasking environment and supported a wide variety of programming languages. IAS was a time-sharing version of RSX-11D. Both RSTS and Unix were time-sharing systems available to educational institutions at little or no cost, and these PDP-11 systems were destined to be the "sandbox" for a rising generation of engineers and computer scientists. Large numbers of PDP-11/70s were deployed in telecommunications and industrial control applications. AT&T Corporation became DEC's largest customer.

RT-11 provided a practical real-time operating system in minimal memory, allowing the PDP-11 to continue DEC's critical role as a computer supplier for embedded systems. Historically, RT-11 also served as the inspiration for many microcomputer OS's, as these were generally being written by programmers who cut their teeth on one of the many PDP-11 models. For example, CP/M used a command syntax similar to RT-11's, and even retained the awkward PIP program used to copy data from one computer device to another. As another historical footnote, DEC's use of "/" for "switches" (command-line options) would lead to the adoption of "\" for pathnames in MS-DOS and Microsoft Windows as opposed to "/" in Unix.

The evolution of the PDP-11 followed earlier systems, eventually including a single-user deskside personal computer form, the MicroPDP-11. In total, around 600,000 PDP-11s of all models were sold, and a wide variety of third-party peripheral vendors had also entered the computer product ecosystem. It was even sold in kit form as the Heathkit H11, although it proved too expensive for Heathkit's traditional hobbyist market.

The introduction of semiconductor memory in the early 1970s, and especially dynamic RAM shortly thereafter, led to dramatic reductions in the price of memory as the effects of Moore's Law were felt. Within years, it was common to equip a machine with all the memory it could address, typically 64 kB on 16-bit machines. This led vendors to introduce new designs with the ability to address more memory, often by extending the address format to 18 or 24-bits in machines were otherwise similar to their earlier 16-bit designs.

In contrast, DEC decided to make a more radical departure. In 1976, they began the design of a machine whose entire architecture was expanded from the 16-bit PDP-11 to a new 32-bit basis. This would allow the addressing of very large memories, which were to be controlled by a new virtual memory system, and would also improve performance by processing twice as much data at a time. The system would, however, maintain compatibility with the PDP-11, by operating in a second mode that sent its 16-bit words into the 32-bit internals, while mapping the PDP-11's 16-bit memory space into the larger virtual 32-bit space.

The result was the VAX architecture, where VAX stands for Virtual Address eXtension (from 16 to 32 bits). The first computer to use a VAX CPU was the VAX-11/780, announced in October 1977, which DEC referred to as a "superminicomputer". Although it was not the first 32-bit minicomputer, the VAX-11/780's combination of features, price, and marketing almost immediately propelled it to a leadership position in the market after it was released in 1978. VAX systems were so successful that in 1983, DEC canceled its Jupiter project, which had been intended to build a successor to the PDP-10 mainframe, and instead focused on promoting the VAX as the single computer architecture for the company.

Supporting the VAX's success was the VT52, one of the most successful smart terminals. Building on earlier less successful models, the VT05 and VT50, the VT52 was the first terminal that did everything one might want in a single inexpensive chassis. The VT52 was followed by the even more successful VT100 and its follow-ons, making DEC one of the largest terminal vendors in the industry. This was supported by a line of inexpensive computer printers, the DECwriter line. With the VT and DECwriter series, DEC could now offer a complete top-to-bottom system from computer to all peripherals, which formerly required collecting the required devices from different suppliers.

The VAX processor architecture and family of systems evolved and expanded through several generations during the 1980s, culminating in the NVAX microprocessor implementation and VAX 7000/10000 series in the early 1990s.

When a DEC research group demonstrated two prototype microcomputers in 1974—before the debut of the MITS Altair—Olsen chose to not proceed with the project. The company similarly rejected another personal computer proposal in 1977. At the time these systems were of limited utility, and Olsen famously derided them in 1977, stating "There is no reason for any individual to have a computer in his home." Unsurprisingly, DEC did not put much effort into the microcomputer area in the early days of the market. In 1977, the Heathkit H11 was announced; a PDP-11 in kit form. At the beginning of the 1980s, DEC built the VT180 (codenamed "Robin"), which was a VT100 terminal with an added Z80-based microcomputer running CP/M, but this product was initially available only to DEC employees.

It was only after IBM had successfully launched the IBM PC in 1981 that DEC responded with their own systems. In 1982, DEC introduced not one, but three incompatible machines which were each tied to different proprietary architectures. The first, the DEC Professional, was based on the PDP-11/23 (and later, the 11/73) running the RSX-11M+ derived, but menu-driven, P/OS ("Professional Operating System"). This DEC machine easily outperformed the PC, but was more expensive than, and completely incompatible with IBM PC hardware and software, offering far fewer options for customizing a system.

Unlike CP/M and DOS microcomputers, every copy of every program for the Professional had to be provided with a unique key for the particular machine and CPU for which it was bought. At that time this was mainstream policy, because most computer software was either bought from the company that built the computer or custom-constructed for one client. However, the emerging third-party software industry disregarded the PDP-11/Professional line and concentrated on other microcomputers where distribution was easier. At DEC itself, creating better programs for the Professional was not a priority, perhaps from fear of cannibalizing the PDP-11 line. As a result, the Professional was a superior machine, running inferior software. In addition, a new user would have to learn an awkward, slow, and inflexible menu-based user interface which appeared to be radically different from PC DOS or CP/M, which were more commonly used on the 8080- and 8088-based microcomputers of the time. A second offering, the DECmate II was the latest version of the PDP-8-based word processors, but not really suited to general computing, nor competitive with Wang Laboratories' popular word processing equipment.
The most popular early DEC microcomputer was the dual-processor (Z80 and 8088) Rainbow 100, which ran the 8-bit CP/M operating system on the Z80 and the 16-bit CP/M-86 operating system on the Intel 8088 processor. It could also run a UNIX System III implementation called VENIX. Applications from standard CP/M could be re-compiled for the Rainbow, but by this time users were expecting custom-built (pre-compiled binary) applications such as Lotus 1-2-3, which was eventually ported along with MS-DOS 2.0 and introduced in late 1983. Although the Rainbow generated some press, it was unsuccessful due to its high price and lack of marketing and sales support. By late 1983 IBM was outselling DEC's personal computers by more than ten to one.

A further system was introduced in 1986 as the VAXmate, which included Microsoft Windows 1.0 and used VAX/VMS-based file and print servers along with integration into DEC's own DECnet-family, providing LAN/WAN connection from PC to mainframe or supermini. The VAXmate replaced the Rainbow, and in its standard form was the first widely marketed diskless workstation.

In 1984, DEC launched its first 10 Mbit/s Ethernet. Ethernet allowed scalable networking, and VAXcluster allowed scalable computing. Combined with DECnet and Ethernet-based terminal servers (LAT), DEC had produced a networked storage architecture which allowed them to compete directly with IBM. Ethernet replaced Token Ring, and went on to become the dominant networking model in use today.

In September 1985, DEC became the fifth company to register a .com domain name (dec.com).

Along with the hardware and protocols, DEC also introduced the VAXcluster concept, which allowed several VAX machines to be tied together into a single larger storage system. VAXclusters allowed a DEC-based company to scale their services by adding new machines to the cluster at any time, as opposed to buying a faster machine and using that to replace a slower one. The flexibility this offered was compelling, and allowed DEC to attack high-end markets formerly out of their reach.

The PDP-11 and VAX lines continued to sell in record numbers. Better yet, DEC was competing very well against the market leader, IBM, taking an estimated $2 billion away from them in the mid-1980s. In 1986, DEC's profits rose 38% when the rest of the computer industry experienced a downturn, and by 1987 the company was threatening IBM's number one position in the computer industry. Not long thereafter came IBM's VAX Killer offerings, at a time when DEC had twice the sales of IBM in the mid-range computer market.

At its peak, DEC was the second-largest computer company in the world, with over 100,000 employees. It was during this time that the company branched out development into a wide variety of projects that were far from its core business in computer equipment. The company invested heavily in custom software. In the 1970s and earlier most software was custom-written to serve a specific task, but by the 1980s the introduction of relational databases and similar systems allowed powerful software to be built in a modular fashion, potentially saving enormous amounts of development time. Software companies like Oracle became the new darlings of the industry, and DEC started their own efforts in every "hot" niche, in some cases several projects for the same niche. Some of these products competed with DEC's own partners, notably Rdb which competed with Oracle's products on the VAX, part of a major partnership only a few years earlier.

Although many of these products were well designed, most of them were DEC-only or DEC-centric, and customers frequently ignored them and used third-party products instead. This problem was further exacerbated by Olsen's aversion to traditional advertising and his belief that well-engineered products would sell themselves. Hundreds of millions of dollars were spent on these projects, at the same time that workstations using RISC microprocessors were starting to approach VAX CPUs in performance.

As microprocessors continued to improve in the 1980s, it soon became clear that the next generation would offer performance and features equal to the best of DECs low-end minicomputer lineup. Worse, the Berkeley RISC and Stanford MIPS designs were aiming to introduce 32-bit designs that would outperform the fastest members of the VAX family, DEC's cash cow.

Constrained by the huge success of their VAX and VMS products, which followed the proprietary model, the company was very late to respond to these threats. In the early 1990s, DEC found its sales faltering and its first layoffs followed. The company that created the minicomputer, a dominant networking technology, and arguably the first computers for personal use, had abandoned the "low end" market, whose dominance with the PDP-8 had built the company in a previous generation. Decisions about what to do about this threat led to infighting within the company that seriously delayed their responses.

One group suggested that every possible development in the industry be poured into the construction of a new VAX family that would leapfrog the performance of the existing machines. This would limit the market erosion in the top-end segment, where profit margins were maximized and DEC could continue to survive as a minicomputer vendor. This line of thought led, eventually, to the VAX 9000 series, which were plagued with problems when they were first introduced in October 1989, already two years late. The problems took so long to work out, and the prices of the systems were so high, that DEC was never able to make the line the success they hoped.

Others within the company felt that the proper response was to introduce their own RISC designs and use those to build new machines. However, there was little official support for these efforts, and no less than four separate small projects ran in parallel at various labs around the US. Eventually these were gathered into the PRISM project, which delivered a credible 32-bit design with some unique features allowing it to serve as the basis of a new VAX implementation. Infighting with teams dedicated to DEC's big iron made funding difficult, and the design was not finalized until April 1988, and then cancelled shortly thereafter. The PRISM project was accompanied by the MICA project, which intended to consolidate VMS and ULTRIX into a single operating system.

Another group concluded that new workstations like those from Sun Microsystems and Silicon Graphics would take away a large part of DEC's existing customer base before the new VAX systems could address the issues, and that the company needed its own Unix workstation as soon as possible. Fed up with slow progress on both the RISC and VAX fronts, a group in Palo Alto started a skunkworks project to introduce their own systems. Selecting the MIPS processor, which was widely available, introducing the new DECstation series with the model 3100 on January 11, 1989. These systems would see some success in the market, but were later displaced by similar models running the Alpha.

Eventually, in 1992, DEC launched the DECchip 21064 processor, the first implementation of their Alpha instruction set architecture, initially named Alpha AXP; the "AXP" was a "non-acronym" and was later dropped. This was a 64-bit RISC architecture as opposed to the 32-bit CISC architecture used in the VAX. It is one of the first "pure" 64-bit microprocessor architectures and implementations rather than an extension of an earlier 32-bit architecture. The Alpha offered class-leading performance at its launch and was used in the massively-parallel Cray T3D. Subsequent variants continued that performance trend into the 2000s, along with the Alpha-derived Pentium Pro, II, and III CPUs. An AlphaServer SC45 supercomputer was still ranked No. 6 in the world in November 2004. Alpha-based computers comprising the DEC AXP series, later the AlphaStation, and AlphaServer series respectively superseded both the VAX and MIPS architecture in DEC's product lines. They supported OpenVMS, DEC OSF/1 AXP (later known as Digital Unix or Tru64 UNIX) and Microsoft's then-new operating system, Windows NT, an operating system made possible by ex-Digital Equipment Corporation engineers.

In 1998, following the takeover by Compaq Computer Corporation, a decision was made that Microsoft would no longer support and develop Windows NT for the Alpha series computers, a decision that was seen as the beginning of the end for the Alpha series computers.

In the mid-1990s, Digital Semiconductor collaborated with ARM Limited to produce the StrongARM microprocessor. This was based in part on ARM7 and in part on DEC technologies like Alpha, and was targeted at embedded systems and portable devices. It was highly compatible with the ARMv4 architecture and was very successful, competing effectively against rivals such as the SuperH and MIPS architectures in the portable digital assistant market. Microsoft subsequently dropped support for these other architectures in their Pocket PC platform. In 1997, as part of a lawsuit settlement, the StrongARM intellectual property was sold to Intel. They continued to produce StrongARM, as well as developing it into the XScale architecture. Intel subsequently sold this business to Marvell Technology Group in 2006.

At its peak in the late 1980s, DEC had $14 billion in sales and ranked among the most profitable companies in the US. With its strong staff of engineers, DEC was expected to usher in the age of personal computers, but the commonly misunderstood belief then argued by the board to its shareholders was that Mr. Olsen was openly skeptical of the desktop machines, stating "the personal computer will fall flat on its face in business", and regarding them as "toys" used for playing video games. This was made in 1977 about what could be more characterised as home automation devices.

The board forced Olsen to resign as president in July 1992 after 2 years of losses in operating income. He was replaced by Robert Palmer as the company's president. DEC's board of directors also granted Palmer the title of chief executive officer ("CEO"), a title that had never been used during DEC's 35-year existence. Palmer had joined DEC in 1985 to run Semiconductor Engineering and Manufacturing. His relentless campaign to be CEO, and success with the Alpha microprocessor family, made him a candidate to succeed Olsen. At the same time a more modern logo was designed

Palmer restructured DEC into nine business units that reported directly to him. Nonetheless, DEC continued to suffer record losses, including a loss of $260.5 million for the quarter that ended on September 30, 1992. It reported $2.8 billion in losses for its fiscal year 1992. January 5, 1993, saw the retirement of John F. Smith as senior vice president of operations, the second in command at DEC, and his position was not filled. A 35-year company veteran, he had joined DEC in 1958 as the company's 12th employee, passing up a chance to work for Bell Laboratories in New Jersey to work for DEC. Smith rose to become one of the three senior vice presidents in 1987 and was widely considered among the potential successors to Ken Olsen, especially when Smith was appointed chief operating officer in 1991. Smith became a corporate spokesman on financial issues, and had filled in at trouble spots for which Olsen ordered more attention. Smith was passed over in favor of Palmer when Olsen was forced to resign in July 1992, though Smith stayed on for a time to help turn around the struggling company.

In June 1993, Palmer and several of his top lieutenants presented their reorganization plans to applause from the board of directors, and several weeks later DEC reported its first profitable quarter in several years. However, on April 15, 1994, DEC reported a loss of $183 million—three to four times higher than the loss many people on Wall Street had predicted (compared with a loss of $30 million in the comparable period a year earlier), causing the stock price on the NYSE to plunge $5.875 to $23, a 20% drop. The losses at that point totaled $339 million for the current fiscal year. Sales of the VAX, long the company's biggest moneymaker, continued to decline, which in turn also hurt DEC's lucrative service and maintenance business (this made up more than a third of DEC's revenue of $14 billion in the 1993 fiscal year), which declined 11% year over year to $1.5 billion in the most recent quarter.

Market acceptance of DEC Alpha computers and chips had been slower than the company had hoped, even though Alpha's sales for the quarter estimated at $275 million were up significantly from $165 million in the December quarter. DEC had also made a strong push into personal computers and workstations, which had even lower margins than Alpha computers and chips. Also, DEC was playing catchup with its own Unix offerings for client-server networks, as it long emphasized its own VMS software, while corporate computer users based their client-server networks on the industry-standard Unix software (of which Hewlett Packard was one of the market leaders). DEC's problems were similar to that of larger rival IBM, due to the fundamental shift in the computer industry that made it unlikely that DEC could ever again operate profitably at its former size of 120,000 employees, and while its workforce had been reduced to 92,000 people many analysts expected that they would have to cut another 20,000.

During the profitable years up until the early 1990s, DEC was a company that boasted that it never had a general layoff. Following the 1992 economic downturn, layoffs became regular events as the company continually downsized to try to stay afloat. Palmer was tasked with the goal of bringing DEC back to profitability, which he attempted to do by changing the established DEC business culture, hiring new executives from outside the company, and selling off various non-core business units:

Through 1997, DEC began discussions with Compaq on a possible merger. Several years earlier, Compaq had considered a bid for DEC but became seriously interested only after DEC's major divestments and refocusing on the Internet in 1997. At that time, Compaq was making strong moves into the enterprise market, and DEC's multivendor global services organization and customer support centers offered a real opportunity to expand their support and sales worldwide. Compaq was not interested in a number of DEC's product lines, which led to the series of sell-offs. Notable among these was DEC's Hudson Fab, which made most of their custom chips, a market that made little sense to Compaq's "industry standard" marketing. DEC had previously sold its semiconductor plant in South Queensferry to Motorola in 1995, with an understanding that Motorola would continue to produce Alpha processors at the facility, along with continuing a two-year foundry agreement with AMD to continue producing the Am486 processor.

This led to an interesting solution to the problem of selling off the division for a reasonable profit. In May 1997, DEC sued Intel for allegedly infringing on its Alpha patents in designing the original Pentium, Pentium Pro, and Pentium II chips. As part of a settlement, much of DEC's chip design and fabrication business was sold to Intel. This included DEC's StrongARM implementation of the ARM computer architecture, which Intel marketed as the XScale processors commonly used in Pocket PCs. The core of Digital Semiconductor, the Alpha microprocessor group, remained with DEC, while the associated office buildings went to Intel as part of the Hudson fab.

On January 26, 1998, what remained of the company was sold to Compaq in what was the largest merger up to that time in the computer industry. At the time of Compaq's acquisition announcement, DEC had a total of 53,500 employees, down from a peak of 130,000 in the 1980s, but it still employed about 65% more people than Compaq to produce about half the volume of sales revenues. After the merger closed, Compaq moved aggressively to reduce DEC's high selling, general, and administrative (SG&A) costs (equal to 24% of total 1997 revenues) and bring them more in line with Compaq's SG&A expense ratio of 12% of revenues.

Compaq used the acquisition to move into enterprise services and compete with IBM, and by 2001 services made up over 20% of Compaq's revenues, largely due to the DEC employees inherited from the merger. DEC's own PC manufacturing was discontinued after the merger closed. As Compaq did not wish to compete with one of its key partner suppliers, the remainder of Digital Semiconductor (the Alpha microprocessor group) was sold to Intel, which placed those employees back in their Hudson (Massachusetts) office, which they had vacated when the site was sold to Intel in 1997.

Compaq struggled as a result of the merger with DEC, and was acquired by Hewlett-Packard in 2002. Compaq, and later HP, continued to sell many of the former DEC products but re-branded with their own logos. For example, HP now sells what were formerly DEC's StorageWorks disk/tape products, as a result of the Compaq acquisition.

The Digital logo was used up until 2004, even after the company ceased to exist, as the logo of Digital GlobalSoft, an IT services company in India (which was a 51% subsidiary of Compaq). Digital GlobalSoft was later renamed "HP GlobalSoft" (also known as the "HP Global Delivery India Center" or HP GDIC), and no longer uses the Digital logo.

DEC's Research Laboratories (or Research Labs, as they were commonly known) conducted DEC's corporate research. Some of them were continued in operation by Compaq and are still operated by Hewlett-Packard. The laboratories were:


Some of the former employees of DEC's Research Labs or DEC's R&D in general include:

Some of the former employees of Digital Equipment Corp were responsible for developing DEC Alpha and StrongARM:

Grace Hopper worked for Digital Equipment Corporation as a consultant after her retirement from the United States Navy

Some of the work of the Research Labs was published in the "Digital Technical Journal", which was in published from 1985 until 1998. At least some of the research reports are available online.

, decades-old hardware (including PDP-11, VAX, and AlphaServer) is being emulated to allow legacy software to run on modern hardware; funding for this is planned to last at least until 2030.

DEC supported the ANSI standards, especially the ASCII character set, which survives in Unicode and the ISO 8859 character set family. DEC's own Multinational Character Set also had a large influence on ISO 8859-1 (Latin-1) and, by extension, Unicode.

Beyond DECsystem-10/20, PDP, VAX and Alpha, DEC was known for its work in communication subsystem designs, such as Ethernet, DNA (DIGITAL Network Architecture: predominantly DECnet products), DSA (Digital Storage Architecture: disks/tapes/controllers), and its "dumb terminal" subsystems including VT100 and DECserver products.


One of the most unusual peripherals produced for the PDP-10 was the DECtape. The DECtape was a length of special 3/4-inch wide magnetic tape wound on 5-inch reels. The recording format was a highly reliable redundant 10-track design using fixed-length numbered data "blocks" organized into a standard file structure, including a directory. Files could be written, read, changed, and deleted on a DECtape as though it were a disk drive. For greater efficiency, the DECtape drive could read and write to a DECtape in both directions.

In fact, some PDP-10 systems had no disks at all, using DECtapes alone for their primary data storage. The DECtape was also widely used on other PDP models, since it was much easier to use than hand-loading multiple paper tapes. Primitive early time-sharing systems could use DECtapes as system devices and swapping devices. Although superior to paper tape, DECtapes were relatively slow, and were supplanted once reliable disk drives became affordable.

DEC was both a manufacturer and a buyer of magnetic disk storage, offering more than 100 different models of hard disk drive (HDD) and floppy disk drive (FDD) during its existence. In the 1970s, it was the single largest OEM purchaser of HDDs, procuring from Diablo, Control Data Corporation, Information Storage Systems, and Memorex, among others.

DEC's first internally developed HDD was the RS08, a 256 kWord fixed-head contact-start-stop drive using plated media; it shipped in 1969.

Beginning in the 1970s, DEC moved first its HDD manufacturing and then its mass storage development labs to Colorado Springs.

DEC pioneered a number of HDD technologies, including sampled data servos (RL01, 1977) and serial HDD interfaces (Standard Disk Interconnect, 1983). The last internally developed disk drive family (RA9x series) used plated media, departing from the HDD industry trend to carbon overcoated sputtered media. DEC designated a $400 million investment to bring this product line into production. The RA92 (1.5 GB) was introduced in 1992, using a 14-inch platter.

DEC purchased its FDDs from OEMs such as Shugart Associates, Toshiba, and Sony.

The way the 400 KB DEC standard RX50 floppy disk drive supported DEC's initial offerings seemed to encapsulate their approach to the personal computer market. Although the mechanical drive hardware was nearly identical to other 5 " floppy disk drives available on competing systems, DEC sought to differentiate their product by using a proprietary disk format for the data written on the disk. The DEC format had a higher capacity for data, but the RX50 drives were incompatible with other PC floppy drives. This required DEC owners to buy higher-priced, specially formatted floppy media, which was harder to obtain through standard distribution channels. DEC attempted to enforce exclusive control over its floppy media sales by copyrighting its proprietary disk format, and requiring a negotiated license agreement and royalty payments from anybody selling compatible media. The proprietary data format meant that RX50 floppies were not interchangeable with other PC floppies, further isolating DEC products from the developing de facto standard PC market. Hardware hackers and DEC enthusiasts eventually reverse-engineered the RX50 format, but the damage had already been done, in terms of market confusion and isolation.

The Video-on-Demand project at DEC started in 1992, following Ken Olsen's retirement. At the time the company was rapidly downsizing under Robert Palmer, and it was difficult to gain funding for any new project. DEC's Interactive Video Information Server architecture gained traction and excelled over those of other companies, in that it was highly scalable, using a gateway to set up interactive video delivery sessions on large numbers of video and information servers. Initially high-end VAXes were used, then Alphas.
The scalability feature allowed it to win contracts for many of the video-on-demand trials in the 1993–95 timeframe, since the system could theoretically accommodate unlimited interactive video streams and other non-video content.

The design was proposed and incorporated into the MPEG-2 international standard. Its object-oriented interface became the mandatory user-to user core interface in DSM-CC, widely used in video stream and file delivery for MPEG-2 compliant systems.

Commercially, DEC's Digital and Interactive Information System was used by Adlink to distribute advertising to over two million subscribers.




Originally the users' group was called DECUS (Digital Equipment Computer User Society) during the 1960s to 1990s. When Compaq acquired DEC in 1998, the users group was renamed CUO, the Compaq Users' Organisation. When HP acquired Compaq in 2002, CUO became HP-Interex, although there are still DECUS groups in several countries. In the United States, the organization is represented by the Encompass organization; currently Connect.



Dead Kennedys

Dead Kennedys are an American punk rock band that formed in San Francisco, California, in 1978. The band was one of the defining punk bands during its initial eight-year run.

Dead Kennedys' lyrics were usually political in nature, satirizing political figures and authority in general, as well as popular culture and even the punk movement itself. During their initial incarnation between 1978 and 1986, they attracted considerable controversy for their provocative lyrics and artwork. Several stores refused to stock their recordings, provoking debate about censorship in rock music; in the mid-1980s, vocalist and primary lyricist Jello Biafra became an active campaigner against the Parents Music Resource Center. This culminated in an obscenity trial between 1985 and 1986, which resulted in a hung jury.

The group released a total of four studio albums and one EP before disbanding in 1986. Following the band's dissolution, Biafra continued to collaborate and record with other artists including D.O.A., NoMeansNo and his own bands Lard and the Guantanamo School of Medicine, as well as releasing several spoken word performances.

In 2000 (upheld on appeal in 2003), Biafra lost an acrimonious legal case initiated by his former Dead Kennedys bandmates over songwriting credits and unpaid royalties. In 2001, the band reformed without Biafra; various singers have since been recruited for vocal duties. Although Dead Kennedys have continued to perform over the years, they have not released any new material since their fourth studio album, "Bedtime for Democracy", in 1986.

Dead Kennedys formed in June 1978 in San Francisco, California, when East Bay Ray (Raymond Pepperell) advertised for bandmates in the newspaper "The Recycler", after seeing a ska-punk show at Mabuhay Gardens in San Francisco. The original band lineup consisted of East Bay Ray on lead guitar, Klaus Flouride (Geoffrey Lyall) on bass, Jello Biafra (Eric Reed Boucher) on vocals, Ted (Bruce Slesinger) on drums and 6025 (Carlos Cadona) on rhythm guitar. This lineup recorded their first demos. Their first live show was on July 19, 1978, at Mabuhay Gardens in San Francisco, California. They were the opening act on a bill that included DV8 and Negative Trend with The Offs headlining.

Dead Kennedys played numerous shows at local venues afterward. Due to the provocative name of the band, they sometimes played under pseudonyms, including "The DK's", "The Sharks", "The Creamsicles" and "The Pink Twinkies". "San Francisco Chronicle" columnist Herb Caen wrote in November 1978, "Just when you think tastelessness has reached its nadir, along comes a punk rock group called 'The Dead Kennedys', which will play at Mabuhay Gardens on Nov. 22, the 15th anniversary of John F. Kennedy's assassination." Despite mounting protests, the owner of Mabuhay declared, "I can't cancel them NOW—there's a contract. Not, apparently, the kind of contract some people have in mind." However, despite popular belief, the name was not meant to insult the Kennedy family, but according to Ray, "the assassinations were in much more poor taste than our band. We actually respect the Kennedy family. . . . When JFK was assassinated, when Martin Luther King was assassinated, when RFK was assassinated, the American Dream was assassinated. . . . Our name is actually homage to the American Dream."

6025 left the band in March 1979 under somewhat unclear circumstances, generally considered to be musical differences. In June, the band released their first single, "California Über Alles", on Biafra and East Bay Ray's independent label, Alternative Tentacles. The band followed with a poorly attended East Coast tour, being a new and fairly unknown band at the time, without a full album release.

In early 1980, they recorded and released the single "Holiday in Cambodia". In June, the band recorded their debut album, "Fresh Fruit for Rotting Vegetables", released in September of that year on the UK label Cherry Red. The album reached number 33 on the UK Albums Chart. Since its initial release, it has been re-released by several other labels, including IRS, Alternative Tentacles, and Cleopatra. The newest reissue—the special 25th-anniversary edition—features the original artwork and a bonus 55-minute DVD documenting the making of the album as well as the band's early years.

On March 25, 1980, Dead Kennedys were invited to perform at the Bay Area Music Awards in an effort to give the event some "new wave credibility", in the words of the organizers. The day of the performance was spent practicing the song they were asked to play, the underground hit "California über alles". The band became the talking point of the ceremony when after about 15 seconds into the song, Biafra stopped the band—in a manner reminiscent of Elvis Costello's "Saturday Night Live" appearance—and said, "Hold it! We've gotta prove that we're adults now. We're not a punk rock band, we're a new wave band." The band, all wearing white shirts with a big, black S painted on the front, pulled black ties from around the backs of their necks to form a dollar sign, then started playing a new song titled "Pull My Strings", a barbed, satirical attack on the ethics of the mainstream music industry, which contained the lyrics, "Is my cock big enough, is my brain small enough, for you to make me a star?". The song also referenced The Knack's song "My Sharona". "Pull My Strings" was never recorded for a studio release, though the performance at the Bay Area Music Awards, which was one of only two times that the song was ever performed, was released on the band's 1987 compilation album "Give Me Convenience or Give Me Death". In a 2017 interview about the show Klaus stated, "We did one other performance of it at The Mabuhay and that was the only other time we performed it... like within a week of the Bammies" This performance was not recorded.

In January 1981, Ted announced that he wanted to leave to pursue a career in architecture and would help look for a replacement. He played his last concert in February 1981. His replacement was D. H. Peligro (Darren Henley). Around the same time, East Bay Ray had tried to pressure the rest of the band to sign to the major record label Polydor Records; Biafra stated that he was prepared to leave the group if the rest of the band wanted to sign to the label, though East Bay Ray asserts that he recommended against signing with Polydor. Polydor decided not to sign the band after they learned that Dead Kennedys' next single was to be entitled "Too Drunk to Fuck".

When "Too Drunk to Fuck" came out in May 1981 it caused controversy in the UK, as the BBC feared the single would reach the Top 30, which would necessitate its title being mentioned on "Top of the Pops". It was never played, although it was called "'Too Drunk' by the Kennedys" by presenter Tony Blackburn.

After Peligro joined the band, the extended play "In God We Trust, Inc." (1981) saw them move toward a more aggressive hardcore/thrash sound. In addition to the EP's controversial artwork depicting a gold Christ figure on a cross of dollar bills, the lyrics contained Biafra's most biting social and political commentary yet, and songs such as "Moral Majority", "Nazi Punks Fuck Off!" and "We've Got a Bigger Problem Now" placed Dead Kennedys as the spokesmen of social protest, while "Dog Bite", a cover version of "Rawhide" and various joke introductions showed a much more whimsical side. In 1982, they released their second studio album, "Plastic Surgery Disasters". The album's cover features a withered starving African child's hand being held and dwarfed by a white man's hand, a picture that had won the World Press Photo award in 1980, taken in Karamoja district in Uganda by Mike Wells.

The band's music had evolved considerably in a short time, moving away from hardcore formulae toward a more innovative jazz-informed style, featuring musicianship and dynamics far beyond other bands in the genre (thus effectively removing the music from that genre). By now the group had become a de facto political force, pitting itself against rising elements of American social and political life such as the religious right, Ronald Reagan and the idle rich. The band continued touring all over the United States, as well as Europe and Australia, and gained a large underground following. While they continued to play live shows during 1983 and 1984, they took a break from releasing new records to concentrate on the Alternative Tentacles record label, which would become synonymous with DIY alternative culture. The band continued to write and perform new material during this time, which would appear on their next album (some of these early performances can be seen in the "DMPO's on Broadway" video, originally released by Dirk Dirksen and later reissued on Rhino).

The release of the album "Frankenchrist" in 1985 showed the band had grown in musical proficiency and lyrical maturity. While there were still a number of loud/fast songs, much of the music featured an eclectic mix of instruments including trumpets and synthesizers. Around this time Klaus Flouride released the similarly experimental solo EP "Cha Cha Cha With Mr. Flouride". Lyrically, the band continued their trademark social commentary, with songs such as "MTV Get Off The Air" and "Jock-O-Rama (Invasion of the Beef Patrol)" poking fun at mainstream America.

However, the controversy that erupted over H.R. Giger's "Penis Landscape", included as an insert with the album, dwarfed the notoriety of its music. The artwork caused a furor with the newly formed Parents Music Resource Center (PMRC). In December 1985 a teenage girl purchased the album at the Wherehouse Records store in Los Angeles County. The girl's mother wrote letters of complaint to the California Attorney General and to Los Angeles prosecutors. In June 1986, members of the band, along with other parties involved in the distribution of "Frankenchrist", were charged criminally with distribution of harmful matter to minors. The store where the teen actually purchased the album was never named in the lawsuit. The criminal charges focused on an illustration by H.R. Giger, titled "Work 219: Landscape XX" (also known as "Penis Landscape"). Included as a poster with the album, "Penis Landscape" depicts nine copulating penises and vaginas.

Members of the band and others in the chain of distribution were charged with violating the California Penal Code on a misdemeanor charge carrying a maximum penalty of up to a year in county jail and a base fine of up to $2,000. Biafra says that during this time government agents invaded and searched his home. The prosecution tried to present the poster to the jury in isolation for consideration as obscene material, but Judge Susan Isacoff ruled that the poster must be considered along with the music and lyrics. The charges against three of the original defendants, Ruth Schwartz (owner of Mordam Records), Steve Boudreau (a distributor involved in supplying "Frankenchrist" to the Los Angeles Wherehouse store), and Salvatore Alberti (owner of the factory where the record was pressed), were dismissed for lack of evidence.

In August 1987, the case went to the jury with two remaining defendants: Jello Biafra and Michael Bonanno (former Alternative Tentacles label manager). However, the criminal trial ended with a hung jury, split 7 to 5 in favor of acquittal. District Attorneys Michael Guarino and Ira Riener made a motion for a retrial which was denied by Judge Isacoff, Superior Court Judge for the County of Los Angeles. The album, however, was banned from many record stores nationwide.

After the break up of the band, Jello Biafra brought up the court case on "The Oprah Winfrey Show". Biafra was on the show with Tipper Gore as part of a panel discussion on the issues of "controversial music lyrics" and censorship.

In addition to the obscenity lawsuit, the band became increasingly disillusioned with the underground scene as well. The hardcore scene, which had been a haven for free-thinking intellectuals and downtrodden nonconformists, was attracting a more violent audience that imposed an increasing level of brutality on other concertgoers and began to alienate many of the bands and individuals who had helped pioneer the movement in the early 1980s. In earlier years the band had criticized neo-Nazi skinheads for trying to ruin the punk scene, but just as big a problem was the popularity of increasingly macho hardcore bands, which brought the group (and their genre) an audience that had little to do with the ideas/ideals they stood for. Biafra penned new songs such as "Chickenshit Conformist" and "Anarchy for Sale" that articulated the band's feelings about the "dumbing down" of punk rock. During the summer they recorded these for their final album, "Bedtime for Democracy", which was released in November. The artwork, depicting a defaced Statue of Liberty overrun with Nazis, media, opportunists, Klan members, corrupt government officials, and religious zombies, echoed the idea that neither America itself or the punk scene were safe havens any more for "your tired, your poor, your huddled masses yearning to breathe free". The album contains a number of fast/short songs interspersed with jazz ("D.M.S.O."), spoken word ("A Commercial") and psychedelia ("Cesspools In Eden").

The band decided to split up in January 1986, prior to the recording and release of "Bedtime for Democracy", and played their last live show with the original lineup on 21 February. Biafra went on to speak about his political beliefs on numerous television shows and he released a number of spoken-word albums. Ray, Flouride, and Peligro also went on to solo careers.

In 2001, Ray, Peligro, and Flouride reformed the Dead Kennedys, with former Dr. Know singer Brandon Cruz replacing Biafra on vocals. The band played under the name "DK Kennedys" for a few concerts, but later reverted to "Dead Kennedys" permanently. They played across the continental United States, Europe, Asia, South America, and Russia. Brandon Cruz left the band in May 2003 and was replaced by Jeff Penalty. The band has released two live albums of archival performances on Manifesto Records: "Mutiny on the Bay", compiled from various live shows including a recording from their last show with Biafra in 1986, and "Live at the Deaf Club", a recording of a 1979 performance at the Deaf Club in San Francisco which was greeted with more enthusiasm.

On October 9, 2007, a best of album titled "Milking the Sacred Cow" was released. It includes two previously unreleased live versions of "Soup Is Good Food" and "Jock-O-Rama", originally found on "Frankenchrist".

Jeff Penalty left the band in March 2008 in what he describes as a "not amicable split." In a statement released, Jeff said that, following a series of disputes, the band had secretly recruited a new singer and played a gig in his neighbourhood, although he also stated he was "really proud of what we were able to accomplish with Dead Kennedys". He was replaced by former Wynona Riders singer Ron "Skip" Greer. D. H. Peligro also left the band to "take some personal time off". He was replaced for a tour by Translator drummer Dave Scheff.

On August 21, 2008, the band announced an extended break from touring due to the health-related issues of Flouride and Peligro. They stated their plans to collaborate on new projects. The band performed a gig in Santa Rosa, California in June 2009, with Peligro returning to the drum kit.

In August 2010, Dead Kennedys announced plans for a short East Coast tour. The lineup assembled for this tour contained East Bay Ray, Peligro, Greer, and bassist Greg Reeves replacing Flouride, who was taking "personal time off" from the band. The tour dates included performances in Philadelphia, New York City, Boston, Washington, D.C., Portland, Maine and Hawaii. The band has played a reworked version of their song "MTV Get Off the Air", re-titled "MP3 Get Off the Web", with lyrics criticizing music piracy during their October 16, 2010, concert at the Rock and Roll Hotel in Washington, D.C.

Dead Kennedys had world tours in 2013 and in 2014, the latter mostly in North American cities. In 2015 and 2016 they toured again, including South America, where they had not played since 2001.

In 2017, East Bay Ray revealed that the band and Jello Biafra had been approached by the Punk-oriented music festival Riot Fest about a potential reunion. While Ray and the rest of the band expressed interest in the concept, Biafra refused.

On April 26, 2019, the group released "DK40", a live compilation album celebrating 40 years since the band formed.

On October 28, 2022, D.H. Peligro died from an overdose of heroin and fentanyl, although it was initially believed to have been from possible head trauma from a fall at his home that day. Since Peligro's death, the band has performed in the UK with Santi Guardiola and the United States with Steve Wilson filling in on drums.

In the late 1990s, former band members discovered they were being underpaid in terms of royalties from Alternative Tentacles. East Bay Ray, Klaus Flouride, and D. H. Peligro claimed that Jello Biafra had conspired to pay them lower royalty rates and then attempted to disguise the precise nature of the money owed. Biafra claimed that the failure to pay these royalties was an accounting mistake.

In 1998, the other three members of the band sued Biafra over these allegedly unpaid royalties. A jury ruled in their favor in May 2000, finding Biafra and Alternative Tentacles "guilty of malice, oppression and fraud". Malice was defined for the jury as "conduct which is intended to cause injury or despicable conduct which is carried with a willful and conscious disregard for the rights of others". Biafra's appeal was denied in June 2003; he had to pay the outstanding royalties as well as punitive damages, and was forced to hand over the rights to the majority of Dead Kennedys' back catalogue to the Decay Music partnership.

This dispute caused minor waves within punk circles. Biafra claims that East Bay Ray had long expressed displeasure with Alternative Tentacles and with the amount of money he received from them, thus the original incentive for the discovery of the back payments. It was found out that Alternative Tentacles was paying Dead Kennedys less per CD than all the other bands, including Biafra himself, and not informing his other bandmates, which was the fraud. Biafra accused the band of wanting to license the famous Dead Kennedys song "Holiday in Cambodia" for use in a Levi's jeans commercial, which the band denied. However, an instrumental loop from "Holiday in Cambodia" was part of the 1981 black comedy feature film "Neighbors", though it was not included on the soundtrack. The band maintains that the Levi's story was completely fictitious and invented by Biafra to discredit them.

Matters were stirred up even further when the three bandmates invited Jello Biafra to "bury the hatchet" in the form of a band reunion. Jello Biafra felt it was unprofessional because no one contacted him directly. In addition, Biafra was disdainful of the reunion, and having long expressed his disdain for nostalgia and rock reunion/oldies tours in particular, argued that the whole affair was motivated by greed.

Several DVDs, re-issues, and live albums have been released since the departure of Biafra most recently on Manifesto Records. According to Biafra, the live albums are "cash-ins" on Dead Kennedys' name and his music. Biafra also accused the releases of the new live material of having poor sound quality. Furthermore, he has stated he is not receiving any royalties from the sale of any Manifesto Records releases. Consequently, he has discouraged fans from buying any Dead Kennedy reissues. The other band members denied Biafra's accusations regarding the live releases, and have defended the mixes as an effort of hard work. Biafra dismissed the new group as "the world's greediest karaoke band." Nevertheless, in 2003, Klaus Flouride said of performances without the band's former frontman: "There hasn't been a show yet that people didn't really like."

Biafra further criticized them for advertising shows using his own image taken from the original 1980s incarnation of the band, which he labeled as false advertising. He attacked the reformed Dead Kennedys in a song called "Those Dumb Punk Kids (Will Buy Anything)", which appears on his second collaboration with sludge metal band the Melvins, "Sieg Howdy!"

Biafra told an audience at a speaking gig in Trenton, New Jersey, that the remaining Dead Kennedys have licensed their single "Too Drunk to Fuck" to be used in a rape scene in a Robert Rodriguez movie. The reference is to a lounge cover of the song, recorded by the band Nouvelle Vague, played during a scene in the "Planet Terror" segment of "Grindhouse", although no rape takes place, and in fact the would-be rapist is killed by the would-be victim. The scene in "Planet Terror" has would-be rapist, "Rapist No. 1" (Quentin Tarantino) order one-legged stripper "Cherry Darlin" (Rose McGowan) to get up off the floor and dance. At this point Tarantino hits play on a cassette recorder and Nouvelle Vague's cover of "Too Drunk To Fuck" plays. Biafra, disapproving of the situation, later wrote, "This is their lowest point since Levi's... This goes against everything the Dead Kennedys stands for in spades... The terrified woman later 'wins' by killing Tarantino, but that excuse does not rescue this at all. I wrote every note of that song and this is not what it was meant for... Some people will do anything for money. I can't help but think back to how prudish Klaus Flouride was when he objected to H. R. Giger's painting on the "Frankenchrist" (sic) poster, saying he couldn't bear to show it to his parents. I'd sure love to be a fly on the wall when he tries to explain putting a song in a rape scene for money to his teenage daughter... The deal was pushed through by a new business manager the other three hired."

The reformed Dead Kennedys followed their court victory by releasing reissues of all Dead Kennedys albums (except "Fresh Fruit for Rotting Vegetables", to which they did not have the rights until 2005), releasing several new archival concert DVDs, and licensing several songs to "The Manchurian Candidate" remake and the "Tony Hawk's Pro Skater" video game. East Bay Ray claims he received a fax from Alternative Tentacles purporting Biafra approved the licensing for the game.

The band claims on their website that they still pay close attention to an anti-corporate ideology, despite performing on September 5, 2003, at a festival in Turkey that was sponsored by Coca-Cola, noting that they have since pulled out of a show in Los Angeles when they found that it was being sponsored by Coors. However, Biafra claims the previous licensing deals prove otherwise.

The original logo was created by Winston Smith. He later contributed artwork for the covers of "In God We Trust, Inc.", "Plastic Surgery Disasters", "Frankenchrist", "Bedtime for Democracy", "Give Me Convenience or Give Me Death", the back cover of the "Kill the Poor" single and the Alternative Tentacles logo. When asked about the "DK" logo in an interview, Jello Biafra explained, "...I wanted to make sure it was something simple and easy to spray-paint so people would graffiti it all over the place, and then I showed it to Winston Smith. He played around with it, came back with a bunch of designs that had the circle and slightly 3-D looking letters and he had ones with different patterns behind it. I liked the one with bricks, but ultimately I thought simple red behind it was the boldest and the best."

Dead Kennedys have been described as one of the first hardcore punk bands. They were noted for the harshness of their lyrics, which generally combined biting social satire while expressing a staunchly left-wing view of contemporary America. Unlike other leftist punk bands who use more direct sloganeering, Dead Kennedys' lyrics were often snide. For example, "Holiday in Cambodia" is a multi-layered satire targeting both yuppies and Cambodia's recently deposed Khmer Rouge regime. Or, on "Jock-O-Rama", featured on Frankenchrist, they mock southern small towns whose residents’ lives revolve around high school football.

Dead Kennedys have influenced multiple acts such as System of a Down, Green Day, Faith No More, Rage Against the Machine, Sepultura, Descendents, Bad Religion, Slayer, X, Minutemen, The Hives, Saves the Day and Screeching Weasel among others.

Current members
Former members






DNA

Deoxyribonucleic acid (; DNA) is a polymer composed of two polynucleotide chains that coil around each other to form a double helix. The polymer carries genetic instructions for the development, functioning, growth and reproduction of all known organisms and many viruses. DNA and ribonucleic acid (RNA) are nucleic acids. Alongside proteins, lipids and complex carbohydrates (polysaccharides), nucleic acids are one of the four major types of macromolecules that are essential for all known forms of life.

The two DNA strands are known as polynucleotides as they are composed of simpler monomeric units called nucleotides. Each nucleotide is composed of one of four nitrogen-containing nucleobases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds (known as the phosphodiester linkage) between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. The nitrogenous bases of the two separate polynucleotide strands are bound together, according to base pairing rules (A with T and C with G), with hydrogen bonds to make double-stranded DNA. The complementary nitrogenous bases are divided into two groups, the single-ringed pyrimidines and the double-ringed purines. In DNA, the pyrimidines are thymine and cytosine; the purines are adenine and guanine.

Both strands of double-stranded DNA store the same biological information. This information is replicated when the two strands separate. A large part of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences. The two strands of DNA run in opposite directions to each other and are thus antiparallel. Attached to each sugar is one of four types of nucleobases (or "bases"). It is the sequence of these four nucleobases along the backbone that encodes genetic information. RNA strands are created using DNA strands as a template in a process called transcription, where DNA bases are exchanged for their corresponding bases except in the case of thymine (T), for which RNA substitutes uracil (U). Under the genetic code, these RNA strands specify the sequence of amino acids within proteins in a process called translation.

Within eukaryotic cells, DNA is organized into long structures called chromosomes. Before typical cell division, these chromosomes are duplicated in the process of DNA replication, providing a complete set of chromosomes for each daughter cell. Eukaryotic organisms (animals, plants, fungi and protists) store most of their DNA inside the cell nucleus as nuclear DNA, and some in the mitochondria as mitochondrial DNA or in chloroplasts as chloroplast DNA. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm, in circular chromosomes. Within eukaryotic chromosomes, chromatin proteins, such as histones, compact and organize DNA. These compacting structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.

DNA is a long polymer made from repeating units called nucleotides. The structure of DNA is dynamic along its length, being capable of coiling into tight loops and other shapes. In all species it is composed of two helical chains, bound to each other by hydrogen bonds. Both chains are coiled around the same axis, and have the same pitch of . The pair of chains have a radius of . According to another study, when measured in a different solution, the DNA chain measured wide, and one nucleotide unit measured long. The buoyant density of most DNA is 1.7g/cm.

DNA does not usually exist as a single strand, but instead as a pair of strands that are held tightly together. These two long strands coil around each other, in the shape of a double helix. The nucleotide contains both a segment of the backbone of the molecule (which holds the chain together) and a nucleobase (which interacts with the other DNA strand in the helix). A nucleobase linked to a sugar is called a nucleoside, and a base linked to a sugar and to one or more phosphate groups is called a nucleotide. A biopolymer comprising multiple linked nucleotides (as in DNA) is called a polynucleotide.

The backbone of the DNA strand is made from alternating phosphate and sugar groups. The sugar in DNA is 2-deoxyribose, which is a pentose (five-carbon) sugar. The sugars are joined by phosphate groups that form phosphodiester bonds between the third and fifth carbon atoms of adjacent sugar rings. These are known as the 3′-end (three prime end), and 5′-end (five prime end) carbons, the prime symbol being used to distinguish these carbon atoms from those of the base to which the deoxyribose forms a glycosidic bond.

Therefore, any DNA strand normally has one end at which there is a phosphate group attached to the 5′ carbon of a ribose (the 5′ phosphoryl) and another end at which there is a free hydroxyl group attached to the 3′ carbon of a ribose (the 3′ hydroxyl). The orientation of the 3′ and 5′ carbons along the sugar-phosphate backbone confers directionality (sometimes called polarity) to each DNA strand. In a nucleic acid double helix, the direction of the nucleotides in one strand is opposite to their direction in the other strand: the strands are antiparallel. The asymmetric ends of DNA strands are said to have a directionality of five prime end (5′ ), and three prime end (3′), with the 5′ end having a terminal phosphate group and the 3′ end a terminal hydroxyl group. One major difference between DNA and RNA is the sugar, with the 2-deoxyribose in DNA being replaced by the related pentose sugar ribose in RNA.

The DNA double helix is stabilized primarily by two forces: hydrogen bonds between nucleotides and base-stacking interactions among aromatic nucleobases. The four bases found in DNA are adenine (), cytosine (), guanine () and thymine (). These four bases are attached to the sugar-phosphate to form the complete nucleotide, as shown for adenosine monophosphate. Adenine pairs with thymine and guanine pairs with cytosine, forming and base pairs.

The nucleobases are classified into two types: the purines, and , which are fused five- and six-membered heterocyclic compounds, and the pyrimidines, the six-membered rings and . A fifth pyrimidine nucleobase, uracil (), usually takes the place of thymine in RNA and differs from thymine by lacking a methyl group on its ring. In addition to RNA and DNA, many artificial nucleic acid analogues have been created to study the properties of nucleic acids, or for use in biotechnology.

Modified bases occur in DNA. The first of these recognized was 5-methylcytosine, which was found in the genome of "Mycobacterium tuberculosis" in 1925. The reason for the presence of these noncanonical bases in bacterial viruses (bacteriophages) is to avoid the restriction enzymes present in bacteria. This enzyme system acts at least in part as a molecular immune system protecting bacteria from infection by viruses. Modifications of the bases cytosine and adenine, the more common and modified DNA bases, play vital roles in the epigenetic control of gene expression in plants and animals.

A number of noncanonical bases are known to occur in DNA. Most of these are modifications of the canonical bases plus uracil.


Twin helical strands form the DNA backbone. Another double helix may be found tracing the spaces, or grooves, between the strands. These voids are adjacent to the base pairs and may provide a binding site. As the strands are not symmetrically located with respect to each other, the grooves are unequally sized. The major groove is wide, while the minor groove is in width. Due to the larger width of the major groove, the edges of the bases are more accessible in the major groove than in the minor groove. As a result, proteins such as transcription factors that can bind to specific sequences in double-stranded DNA usually make contact with the sides of the bases exposed in the major groove. This situation varies in unusual conformations of DNA within the cell "(see below)", but the major and minor grooves are always named to reflect the differences in width that would be seen if the DNA was twisted back into the ordinary B form.

In a DNA double helix, each type of nucleobase on one strand bonds with just one type of nucleobase on the other strand. This is called complementary base pairing. Purines form hydrogen bonds to pyrimidines, with adenine bonding only to thymine in two hydrogen bonds, and cytosine bonding only to guanine in three hydrogen bonds. This arrangement of two nucleotides binding together across the double helix (from six-carbon ring to six-carbon ring) is called a Watson-Crick base pair. DNA with high GC-content is more stable than DNA with low -content. A Hoogsteen base pair (hydrogen bonding the 6-carbon ring to the 5-carbon ring) is a rare variation of base-pairing. As hydrogen bonds are not covalent, they can be broken and rejoined relatively easily. The two strands of DNA in a double helix can thus be pulled apart like a zipper, either by a mechanical force or high temperature. As a result of this base pair complementarity, all the information in the double-stranded sequence of a DNA helix is duplicated on each strand, which is vital in DNA replication. This reversible and specific interaction between complementary base pairs is critical for all the functions of DNA in organisms.

Most DNA molecules are actually two polymer strands, bound together in a helical fashion by noncovalent bonds; this double-stranded (dsDNA) structure is maintained largely by the intrastrand base stacking interactions, which are strongest for stacks. The two strands can come apart—a process known as melting—to form two single-stranded DNA (ssDNA) molecules. Melting occurs at high temperatures, low salt and high pH (low pH also melts DNA, but since DNA is unstable due to acid depurination, low pH is rarely used).

The stability of the dsDNA form depends not only on the -content (% basepairs) but also on sequence (since stacking is sequence specific) and also length (longer molecules are more stable). The stability can be measured in various ways; a common way is the melting temperature (also called "T" value), which is the temperature at which 50% of the double-strand molecules are converted to single-strand molecules; melting temperature is dependent on ionic strength and the concentration of DNA. As a result, it is both the percentage of base pairs and the overall length of a DNA double helix that determines the strength of the association between the two strands of DNA. Long DNA helices with a high -content have more strongly interacting strands, while short helices with high content have more weakly interacting strands. In biology, parts of the DNA double helix that need to separate easily, such as the Pribnow box in some promoters, tend to have a high content, making the strands easier to pull apart.

In the laboratory, the strength of this interaction can be measured by finding the melting temperature "T" necessary to break half of the hydrogen bonds. When all the base pairs in a DNA double helix melt, the strands separate and exist in solution as two entirely independent molecules. These single-stranded DNA molecules have no single common shape, but some conformations are more stable than others.

In humans, the total female diploid nuclear genome per cell extends for 6.37 Gigabase pairs (Gbp), is 208.23 cm long and weighs 6.51 picograms (pg). Male values are 6.27 Gbp, 205.00 cm, 6.41 pg. Each DNA polymer can contain hundreds of millions of nucleotides, such as in chromosome 1. Chromosome 1 is the largest human chromosome with approximately 220 million base pairs, and would be long if straightened.

In eukaryotes, in addition to nuclear DNA, there is also mitochondrial DNA (mtDNA) which encodes certain proteins used by the mitochondria. The mtDNA is usually relatively small in comparison to the nuclear DNA. For example, the human mitochondrial DNA forms closed circular molecules, each of which contains 16,569 DNA base pairs, with each such molecule normally containing a full set of the mitochondrial genes. Each human mitochondrion contains, on average, approximately 5 such mtDNA molecules. Each human cell contains approximately 100 mitochondria, giving a total number of mtDNA molecules per human cell of approximately 500. However, the amount of mitochondria per cell also varies by cell type, and an egg cell can contain 100,000 mitochondria, corresponding to up to 1,500,000 copies of the mitochondrial genome (constituting up to 90% of the DNA of the cell).

A DNA sequence is called a "sense" sequence if it is the same as that of a messenger RNA copy that is translated into protein. The sequence on the opposite strand is called the "antisense" sequence. Both sense and antisense sequences can exist on different parts of the same strand of DNA (i.e. both strands can contain both sense and antisense sequences). In both prokaryotes and eukaryotes, antisense RNA sequences are produced, but the functions of these RNAs are not entirely clear. One proposal is that antisense RNAs are involved in regulating gene expression through RNA-RNA base pairing.

A few DNA sequences in prokaryotes and eukaryotes, and more in plasmids and viruses, blur the distinction between sense and antisense strands by having overlapping genes. In these cases, some DNA sequences do double duty, encoding one protein when read along one strand, and a second protein when read in the opposite direction along the other strand. In bacteria, this overlap may be involved in the regulation of gene transcription, while in viruses, overlapping genes increase the amount of information that can be encoded within the small viral genome.

DNA can be twisted like a rope in a process called DNA supercoiling. With DNA in its "relaxed" state, a strand usually circles the axis of the double helix once every 10.4 base pairs, but if the DNA is twisted the strands become more tightly or more loosely wound. If the DNA is twisted in the direction of the helix, this is positive supercoiling, and the bases are held more tightly together. If they are twisted in the opposite direction, this is negative supercoiling, and the bases come apart more easily. In nature, most DNA has slight negative supercoiling that is introduced by enzymes called topoisomerases. These enzymes are also needed to relieve the twisting stresses introduced into DNA strands during processes such as transcription and DNA replication.

DNA exists in many possible conformations that include A-DNA, B-DNA, and Z-DNA forms, although only B-DNA and Z-DNA have been directly observed in functional organisms. The conformation that DNA adopts depends on the hydration level, DNA sequence, the amount and direction of supercoiling, chemical modifications of the bases, the type and concentration of metal ions, and the presence of polyamines in solution.

The first published reports of A-DNA X-ray diffraction patterns—and also B-DNA—used analyses based on Patterson functions that provided only a limited amount of structural information for oriented fibers of DNA. An alternative analysis was proposed by Wilkins "et al." in 1953 for the "in vivo" B-DNA X-ray diffraction-scattering patterns of highly hydrated DNA fibers in terms of squares of Bessel functions. In the same journal, James Watson and Francis Crick presented their molecular modeling analysis of the DNA X-ray diffraction patterns to suggest that the structure was a double helix.

Although the "B-DNA form" is most common under the conditions found in cells, it is not a well-defined conformation but a family of related DNA conformations that occur at the high hydration levels present in cells. Their corresponding X-ray diffraction and scattering patterns are characteristic of molecular paracrystals with a significant degree of disorder.

Compared to B-DNA, the A-DNA form is a wider right-handed spiral, with a shallow, wide minor groove and a narrower, deeper major groove. The A form occurs under non-physiological conditions in partly dehydrated samples of DNA, while in the cell it may be produced in hybrid pairings of DNA and RNA strands, and in enzyme-DNA complexes. Segments of DNA where the bases have been chemically modified by methylation may undergo a larger change in conformation and adopt the Z form. Here, the strands turn about the helical axis in a left-handed spiral, the opposite of the more common B form. These unusual structures can be recognized by specific Z-DNA binding proteins and may be involved in the regulation of transcription.

For many years, exobiologists have proposed the existence of a shadow biosphere, a postulated microbial biosphere of Earth that uses radically different biochemical and molecular processes than currently known life. One of the proposals was the existence of lifeforms that use arsenic instead of phosphorus in DNA. A report in 2010 of the possibility in the bacterium GFAJ-1 was announced, though the research was disputed, and evidence suggests the bacterium actively prevents the incorporation of arsenic into the DNA backbone and other biomolecules.

At the ends of the linear chromosomes are specialized regions of DNA called telomeres. The main function of these regions is to allow the cell to replicate chromosome ends using the enzyme telomerase, as the enzymes that normally replicate DNA cannot copy the extreme 3′ ends of chromosomes. These specialized chromosome caps also help protect the DNA ends, and stop the DNA repair systems in the cell from treating them as damage to be corrected. In human cells, telomeres are usually lengths of single-stranded DNA containing several thousand repeats of a simple TTAGGG sequence.

These guanine-rich sequences may stabilize chromosome ends by forming structures of stacked sets of four-base units, rather than the usual base pairs found in other DNA molecules. Here, four guanine bases, known as a guanine tetrad, form a flat plate. These flat four-base units then stack on top of each other to form a stable G-quadruplex structure. These structures are stabilized by hydrogen bonding between the edges of the bases and chelation of a metal ion in the centre of each four-base unit. Other structures can also be formed, with the central set of four bases coming from either a single strand folded around the bases, or several different parallel strands, each contributing one base to the central structure.

In addition to these stacked structures, telomeres also form large loop structures called telomere loops, or T-loops. Here, the single-stranded DNA curls around in a long circle stabilized by telomere-binding proteins. At the very end of the T-loop, the single-stranded telomere DNA is held onto a region of double-stranded DNA by the telomere strand disrupting the double-helical DNA and base pairing to one of the two strands. This triple-stranded structure is called a displacement loop or D-loop.

In DNA, fraying occurs when non-complementary regions exist at the end of an otherwise complementary double-strand of DNA. However, branched DNA can occur if a third strand of DNA is introduced and contains adjoining regions able to hybridize with the frayed regions of the pre-existing double-strand. Although the simplest example of branched DNA involves only three strands of DNA, complexes involving additional strands and multiple branches are also possible. Branched DNA can be used in nanotechnology to construct geometric shapes, see the section on uses in technology below.

Several artificial nucleobases have been synthesized, and successfully incorporated in the eight-base DNA analogue named Hachimoji DNA. Dubbed S, B, P, and Z, these artificial bases are capable of bonding with each other in a predictable way (S–B and P–Z), maintain the double helix structure of DNA, and be transcribed to RNA. Their existence could be seen as an indication that there is nothing special about the four natural nucleobases that evolved on Earth. On the other hand, DNA is tightly related to RNA which does not only act as a transcript of DNA but also performs as molecular machines many tasks in cells. For this purpose it has to fold into a structure. It has been shown that to allow to create all possible structures at least four bases are required for the corresponding RNA, while a higher number is also possible but this would be against the natural principle of least effort.

The phosphate groups of DNA give it similar acidic properties to phosphoric acid and it can be considered as a strong acid. It will be fully ionized at a normal cellular pH, releasing protons which leave behind negative charges on the phosphate groups. These negative charges protect DNA from breakdown by hydrolysis by repelling nucleophiles which could hydrolyze it.

Pure DNA extracted from cells forms white, stringy clumps.

The expression of genes is influenced by how the DNA is packaged in chromosomes, in a structure called chromatin. Base modifications can be involved in packaging, with regions that have low or no gene expression usually containing high levels of methylation of cytosine bases. DNA packaging and its influence on gene expression can also occur by covalent modifications of the histone protein core around which DNA is wrapped in the chromatin structure or else by remodeling carried out by chromatin remodeling complexes (see Chromatin remodeling). There is, further, crosstalk between DNA methylation and histone modification, so they can coordinately affect chromatin and gene expression.

For one example, cytosine methylation produces 5-methylcytosine, which is important for X-inactivation of chromosomes. The average level of methylation varies between organisms—the worm "Caenorhabditis elegans" lacks cytosine methylation, while vertebrates have higher levels, with up to 1% of their DNA containing 5-methylcytosine. Despite the importance of 5-methylcytosine, it can deaminate to leave a thymine base, so methylated cytosines are particularly prone to mutations. Other base modifications include adenine methylation in bacteria, the presence of 5-hydroxymethylcytosine in the brain, and the glycosylation of uracil to produce the "J-base" in kinetoplastids.

DNA can be damaged by many sorts of mutagens, which change the DNA sequence. Mutagens include oxidizing agents, alkylating agents and also high-energy electromagnetic radiation such as ultraviolet light and X-rays. The type of DNA damage produced depends on the type of mutagen. For example, UV light can damage DNA by producing thymine dimers, which are cross-links between pyrimidine bases. On the other hand, oxidants such as free radicals or hydrogen peroxide produce multiple forms of damage, including base modifications, particularly of guanosine, and double-strand breaks. A typical human cell contains about 150,000 bases that have suffered oxidative damage. Of these oxidative lesions, the most dangerous are double-strand breaks, as these are difficult to repair and can produce point mutations, insertions, deletions from the DNA sequence, and chromosomal translocations. These mutations can cause cancer. Because of inherent limits in the DNA repair mechanisms, if humans lived long enough, they would all eventually develop cancer. DNA damages that are naturally occurring, due to normal cellular processes that produce reactive oxygen species, the hydrolytic activities of cellular water, etc., also occur frequently. Although most of these damages are repaired, in any cell some DNA damage may remain despite the action of repair processes. These remaining DNA damages accumulate with age in mammalian postmitotic tissues. This accumulation appears to be an important underlying cause of aging.

Many mutagens fit into the space between two adjacent base pairs, this is called "intercalation". Most intercalators are aromatic and planar molecules; examples include ethidium bromide, acridines, daunomycin, and doxorubicin. For an intercalator to fit between base pairs, the bases must separate, distorting the DNA strands by unwinding of the double helix. This inhibits both transcription and DNA replication, causing toxicity and mutations. As a result, DNA intercalators may be carcinogens, and in the case of thalidomide, a teratogen. Others such as benzo["a"]pyrene diol epoxide and aflatoxin form DNA adducts that induce errors in replication. Nevertheless, due to their ability to inhibit DNA transcription and replication, other similar toxins are also used in chemotherapy to inhibit rapidly growing cancer cells.

DNA usually occurs as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. The set of chromosomes in a cell makes up its genome; the human genome has approximately 3 billion base pairs of DNA arranged into 46 chromosomes. The information carried by DNA is held in the sequence of pieces of DNA called genes. Transmission of genetic information in genes is achieved via complementary base pairing. For example, in transcription, when a cell uses the information in a gene, the DNA sequence is copied into a complementary RNA sequence through the attraction between the DNA and the correct RNA nucleotides. Usually, this RNA copy is then used to make a matching protein sequence in a process called translation, which depends on the same interaction between RNA nucleotides. In an alternative fashion, a cell may copy its genetic information in a process called DNA replication. The details of these functions are covered in other articles; here the focus is on the interactions between DNA and other molecules that mediate the function of the genome.

Genomic DNA is tightly and orderly packed in the process called DNA condensation, to fit the small available volumes of the cell. In eukaryotes, DNA is located in the cell nucleus, with small amounts in mitochondria and chloroplasts. In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid. The genetic information in a genome is held within genes, and the complete set of this information in an organism is called its genotype. A gene is a unit of heredity and is a region of DNA that influences a particular characteristic in an organism. Genes contain an open reading frame that can be transcribed, and regulatory sequences such as promoters and enhancers, which control transcription of the open reading frame.

In many species, only a small fraction of the total sequence of the genome encodes protein. For example, only about 1.5% of the human genome consists of protein-coding exons, with over 50% of human DNA consisting of non-coding repetitive sequences. The reasons for the presence of so much noncoding DNA in eukaryotic genomes and the extraordinary differences in genome size, or "C-value", among species, represent a long-standing puzzle known as the "C-value enigma". However, some DNA sequences that do not code protein may still encode functional non-coding RNA molecules, which are involved in the regulation of gene expression.
Some noncoding DNA sequences play structural roles in chromosomes. Telomeres and centromeres typically contain few genes but are important for the function and stability of chromosomes. An abundant form of noncoding DNA in humans are pseudogenes, which are copies of genes that have been disabled by mutation. These sequences are usually just molecular fossils, although they can occasionally serve as raw genetic material for the creation of new genes through the process of gene duplication and divergence.

A gene is a sequence of DNA that contains genetic information and can influence the phenotype of an organism. Within a gene, the sequence of bases along a DNA strand defines a messenger RNA sequence, which then defines one or more protein sequences. The relationship between the nucleotide sequences of genes and the amino-acid sequences of proteins is determined by the rules of translation, known collectively as the genetic code. The genetic code consists of three-letter 'words' called "codons" formed from a sequence of three nucleotides (e.g. ACT, CAG, TTT).

In transcription, the codons of a gene are copied into messenger RNA by RNA polymerase. This RNA copy is then decoded by a ribosome that reads the RNA sequence by base-pairing the messenger RNA to transfer RNA, which carries amino acids. Since there are 4 bases in 3-letter combinations, there are 64 possible codons (4 combinations). These encode the twenty standard amino acids, giving most amino acids more than one possible codon. There are also three 'stop' or 'nonsense' codons signifying the end of the coding region; these are the TAG, TAA, and TGA codons, (UAG, UAA, and UGA on the mRNA).

Cell division is essential for an organism to grow, but, when a cell divides, it must replicate the DNA in its genome so that the two daughter cells have the same genetic information as their parent. The double-stranded structure of DNA provides a simple mechanism for DNA replication. Here, the two strands are separated and then each strand's complementary DNA sequence is recreated by an enzyme called DNA polymerase. This enzyme makes the complementary strand by finding the correct base through complementary base pairing and bonding it onto the original strand. As DNA polymerases can only extend a DNA strand in a 5′ to 3′ direction, different mechanisms are used to copy the antiparallel strands of the double helix. In this way, the base on the old strand dictates which base appears on the new strand, and the cell ends up with a perfect copy of its DNA.

Naked extracellular DNA (eDNA), most of it released by cell death, is nearly ubiquitous in the environment. Its concentration in soil may be as high as 2 μg/L, and its concentration in natural aquatic environments may be as high at 88 μg/L. Various possible functions have been proposed for eDNA: it may be involved in horizontal gene transfer; it may provide nutrients; and it may act as a buffer to recruit or titrate ions or antibiotics. Extracellular DNA acts as a functional extracellular matrix component in the biofilms of several bacterial species. It may act as a recognition factor to regulate the attachment and dispersal of specific cell types in the biofilm; it may contribute to biofilm formation; and it may contribute to the biofilm's physical strength and resistance to biological stress.

Cell-free fetal DNA is found in the blood of the mother, and can be sequenced to determine a great deal of information about the developing fetus.

Under the name of environmental DNA eDNA has seen increased use in the natural sciences as a survey tool for ecology, monitoring the movements and presence of species in water, air, or on land, and assessing an area's biodiversity.

Neutrophil extracellular traps (NETs) are networks of extracellular fibers, primarily composed of DNA, which allow neutrophils, a type of white blood cell, to kill extracellular pathogens while minimizing damage to the host cells.

All the functions of DNA depend on interactions with proteins. These protein interactions can be non-specific, or the protein can bind specifically to a single DNA sequence. Enzymes can also bind to DNA and of these, the polymerases that copy the DNA base sequence in transcription and DNA replication are particularly important.

Structural proteins that bind DNA are well-understood examples of non-specific DNA-protein interactions. Within chromosomes, DNA is held in complexes with structural proteins. These proteins organize the DNA into a compact structure called chromatin. In eukaryotes, this structure involves DNA binding to a complex of small basic proteins called histones, while in prokaryotes multiple types of proteins are involved. The histones form a disk-shaped complex called a nucleosome, which contains two complete turns of double-stranded DNA wrapped around its surface. These non-specific interactions are formed through basic residues in the histones, making ionic bonds to the acidic sugar-phosphate backbone of the DNA, and are thus largely independent of the base sequence. Chemical modifications of these basic amino acid residues include methylation, phosphorylation, and acetylation. These chemical changes alter the strength of the interaction between the DNA and the histones, making the DNA more or less accessible to transcription factors and changing the rate of transcription. Other non-specific DNA-binding proteins in chromatin include the high-mobility group proteins, which bind to bent or distorted DNA. These proteins are important in bending arrays of nucleosomes and arranging them into the larger structures that make up chromosomes.

A distinct group of DNA-binding proteins is the DNA-binding proteins that specifically bind single-stranded DNA. In humans, replication protein A is the best-understood member of this family and is used in processes where the double helix is separated, including DNA replication, recombination, and DNA repair. These binding proteins seem to stabilize single-stranded DNA and protect it from forming stem-loops or being degraded by nucleases.
In contrast, other proteins have evolved to bind to particular DNA sequences. The most intensively studied of these are the various transcription factors, which are proteins that regulate transcription. Each transcription factor binds to one particular set of DNA sequences and activates or inhibits the transcription of genes that have these sequences close to their promoters. The transcription factors do this in two ways. Firstly, they can bind the RNA polymerase responsible for transcription, either directly or through other mediator proteins; this locates the polymerase at the promoter and allows it to begin transcription. Alternatively, transcription factors can bind enzymes that modify the histones at the promoter. This changes the accessibility of the DNA template to the polymerase.

As these DNA targets can occur throughout an organism's genome, changes in the activity of one type of transcription factor can affect thousands of genes. Consequently, these proteins are often the targets of the signal transduction processes that control responses to environmental changes or cellular differentiation and development. The specificity of these transcription factors' interactions with DNA come from the proteins making multiple contacts to the edges of the DNA bases, allowing them to "read" the DNA sequence. Most of these base-interactions are made in the major groove, where the bases are most accessible.

Nucleases are enzymes that cut DNA strands by catalyzing the hydrolysis of the phosphodiester bonds. Nucleases that hydrolyse nucleotides from the ends of DNA strands are called exonucleases, while endonucleases cut within strands. The most frequently used nucleases in molecular biology are the restriction endonucleases, which cut DNA at specific sequences. For instance, the EcoRV enzyme shown to the left recognizes the 6-base sequence 5′-GATATC-3′ and makes a cut at the horizontal line. In nature, these enzymes protect bacteria against phage infection by digesting the phage DNA when it enters the bacterial cell, acting as part of the restriction modification system. In technology, these sequence-specific nucleases are used in molecular cloning and DNA fingerprinting.

Enzymes called DNA ligases can rejoin cut or broken DNA strands. Ligases are particularly important in lagging strand DNA replication, as they join the short segments of DNA produced at the replication fork into a complete copy of the DNA template. They are also used in DNA repair and genetic recombination.

Topoisomerases are enzymes with both nuclease and ligase activity. These proteins change the amount of supercoiling in DNA. Some of these enzymes work by cutting the DNA helix and allowing one section to rotate, thereby reducing its level of supercoiling; the enzyme then seals the DNA break. Other types of these enzymes are capable of cutting one DNA helix and then passing a second strand of DNA through this break, before rejoining the helix. Topoisomerases are required for many processes involving DNA, such as DNA replication and transcription.

Helicases are proteins that are a type of molecular motor. They use the chemical energy in nucleoside triphosphates, predominantly adenosine triphosphate (ATP), to break hydrogen bonds between bases and unwind the DNA double helix into single strands. These enzymes are essential for most processes where enzymes need to access the DNA bases.

Polymerases are enzymes that synthesize polynucleotide chains from nucleoside triphosphates. The sequence of their products is created based on existing polynucleotide chains—which are called "templates". These enzymes function by repeatedly adding a nucleotide to the 3′ hydroxyl group at the end of the growing polynucleotide chain. As a consequence, all polymerases work in a 5′ to 3′ direction. In the active site of these enzymes, the incoming nucleoside triphosphate base-pairs to the template: this allows polymerases to accurately synthesize the complementary strand of their template. Polymerases are classified according to the type of template that they use.

In DNA replication, DNA-dependent DNA polymerases make copies of DNA polynucleotide chains. To preserve biological information, it is essential that the sequence of bases in each copy are precisely complementary to the sequence of bases in the template strand. Many DNA polymerases have a proofreading activity. Here, the polymerase recognizes the occasional mistakes in the synthesis reaction by the lack of base pairing between the mismatched nucleotides. If a mismatch is detected, a 3′ to 5′ exonuclease activity is activated and the incorrect base removed. In most organisms, DNA polymerases function in a large complex called the replisome that contains multiple accessory subunits, such as the DNA clamp or helicases.

RNA-dependent DNA polymerases are a specialized class of polymerases that copy the sequence of an RNA strand into DNA. They include reverse transcriptase, which is a viral enzyme involved in the infection of cells by retroviruses, and telomerase, which is required for the replication of telomeres. For example, HIV reverse transcriptase is an enzyme for AIDS virus replication. Telomerase is an unusual polymerase because it contains its own RNA template as part of its structure. It synthesizes telomeres at the ends of chromosomes. Telomeres prevent fusion of the ends of neighboring chromosomes and protect chromosome ends from damage.

Transcription is carried out by a DNA-dependent RNA polymerase that copies the sequence of a DNA strand into RNA. To begin transcribing a gene, the RNA polymerase binds to a sequence of DNA called a promoter and separates the DNA strands. It then copies the gene sequence into a messenger RNA transcript until it reaches a region of DNA called the terminator, where it halts and detaches from the DNA. As with human DNA-dependent DNA polymerases, RNA polymerase II, the enzyme that transcribes most of the genes in the human genome, operates as part of a large protein complex with multiple regulatory and accessory subunits.

A DNA helix usually does not interact with other segments of DNA, and in human cells, the different chromosomes even occupy separate areas in the nucleus called "chromosome territories". This physical separation of different chromosomes is important for the ability of DNA to function as a stable repository for information, as one of the few times chromosomes interact is in chromosomal crossover which occurs during sexual reproduction, when genetic recombination occurs. Chromosomal crossover is when two DNA helices break, swap a section and then rejoin.

Recombination allows chromosomes to exchange genetic information and produces new combinations of genes, which increases the efficiency of natural selection and can be important in the rapid evolution of new proteins. Genetic recombination can also be involved in DNA repair, particularly in the cell's response to double-strand breaks.

The most common form of chromosomal crossover is homologous recombination, where the two chromosomes involved share very similar sequences. Non-homologous recombination can be damaging to cells, as it can produce chromosomal translocations and genetic abnormalities. The recombination reaction is catalyzed by enzymes known as recombinases, such as RAD51. The first step in recombination is a double-stranded break caused by either an endonuclease or damage to the DNA. A series of steps catalyzed in part by the recombinase then leads to joining of the two helices by at least one Holliday junction, in which a segment of a single strand in each helix is annealed to the complementary strand in the other helix. The Holliday junction is a tetrahedral junction structure that can be moved along the pair of chromosomes, swapping one strand for another. The recombination reaction is then halted by cleavage of the junction and re-ligation of the released DNA. Only strands of like polarity exchange DNA during recombination. There are two types of cleavage: east-west cleavage and north–south cleavage. The north–south cleavage nicks both strands of DNA, while the east–west cleavage has one strand of DNA intact. The formation of a Holliday junction during recombination makes it possible for genetic diversity, genes to exchange on chromosomes, and expression of wild-type viral genomes.

DNA contains the genetic information that allows all forms of life to function, grow and reproduce. However, it is unclear how long in the 4-billion-year history of life DNA has performed this function, as it has been proposed that the earliest forms of life may have used RNA as their genetic material. RNA may have acted as the central part of early cell metabolism as it can both transmit genetic information and carry out catalysis as part of ribozymes. This ancient RNA world where nucleic acid would have been used for both catalysis and genetics may have influenced the evolution of the current genetic code based on four nucleotide bases. This would occur, since the number of different bases in such an organism is a trade-off between a small number of bases increasing replication accuracy and a large number of bases increasing the catalytic efficiency of ribozymes. However, there is no direct evidence of ancient genetic systems, as recovery of DNA from most fossils is impossible because DNA survives in the environment for less than one million years, and slowly degrades into short fragments in solution. Claims for older DNA have been made, most notably a report of the isolation of a viable bacterium from a salt crystal 250 million years old, but these claims are controversial.

Building blocks of DNA (adenine, guanine, and related organic molecules) may have been formed extraterrestrially in outer space. Complex DNA and RNA organic compounds of life, including uracil, cytosine, and thymine, have also been formed in the laboratory under conditions mimicking those found in outer space, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar cosmic dust and gas clouds.

In February 2021, scientists reported, for the first time, the sequencing of DNA from animal remains, a mammoth in this instance over a million years old, the oldest DNA sequenced to date.

Methods have been developed to purify DNA from organisms, such as phenol-chloroform extraction, and to manipulate it in the laboratory, such as restriction digests and the polymerase chain reaction. Modern biology and biochemistry make intensive use of these techniques in recombinant DNA technology. Recombinant DNA is a man-made DNA sequence that has been assembled from other DNA sequences. They can be transformed into organisms in the form of plasmids or in the appropriate format, by using a viral vector. The genetically modified organisms produced can be used to produce products such as recombinant proteins, used in medical research, or be grown in agriculture.

Forensic scientists can use DNA in blood, semen, skin, saliva or hair found at a crime scene to identify a matching DNA of an individual, such as a perpetrator. This process is formally termed DNA profiling, also called "DNA fingerprinting". In DNA profiling, the lengths of variable sections of repetitive DNA, such as short tandem repeats and minisatellites, are compared between people. This method is usually an extremely reliable technique for identifying a matching DNA. However, identification can be complicated if the scene is contaminated with DNA from several people. DNA profiling was developed in 1984 by British geneticist Sir Alec Jeffreys, and first used in forensic science to convict Colin Pitchfork in the 1988 Enderby murders case.

The development of forensic science and the ability to now obtain genetic matching on minute samples of blood, skin, saliva, or hair has led to re-examining many cases. Evidence can now be uncovered that was scientifically impossible at the time of the original examination. Combined with the removal of the double jeopardy law in some places, this can allow cases to be reopened where prior trials have failed to produce sufficient evidence to convince a jury. People charged with serious crimes may be required to provide a sample of DNA for matching purposes. The most obvious defense to DNA matches obtained forensically is to claim that cross-contamination of evidence has occurred. This has resulted in meticulous strict handling procedures with new cases of serious crime.

DNA profiling is also used successfully to positively identify victims of mass casualty incidents, bodies or body parts in serious accidents, and individual victims in mass war graves, via matching to family members.

DNA profiling is also used in DNA paternity testing to determine if someone is the biological parent or grandparent of a child with the probability of parentage is typically 99.99% when the alleged parent is biologically related to the child. Normal DNA sequencing methods happen after birth, but there are new methods to test paternity while a mother is still pregnant.

Deoxyribozymes, also called DNAzymes or catalytic DNA, were first discovered in 1994. They are mostly single stranded DNA sequences isolated from a large pool of random DNA sequences through a combinatorial approach called in vitro selection or systematic evolution of ligands by exponential enrichment (SELEX). DNAzymes catalyze variety of chemical reactions including RNA-DNA cleavage, RNA-DNA ligation, amino acids phosphorylation-dephosphorylation, carbon-carbon bond formation, etc. DNAzymes can enhance catalytic rate of chemical reactions up to 100,000,000,000-fold over the uncatalyzed reaction. The most extensively studied class of DNAzymes is RNA-cleaving types which have been used to detect different metal ions and designing therapeutic agents. Several metal-specific DNAzymes have been reported including the GR-5 DNAzyme (lead-specific), the CA1-3 DNAzymes (copper-specific), the 39E DNAzyme (uranyl-specific) and the NaA43 DNAzyme (sodium-specific). The NaA43 DNAzyme, which is reported to be more than 10,000-fold selective for sodium over other metal ions, was used to make a real-time sodium sensor in cells.

Bioinformatics involves the development of techniques to store, data mine, search and manipulate biological data, including DNA nucleic acid sequence data. These have led to widely applied advances in computer science, especially string searching algorithms, machine learning, and database theory. String searching or matching algorithms, which find an occurrence of a sequence of letters inside a larger sequence of letters, were developed to search for specific sequences of nucleotides. The DNA sequence may be aligned with other DNA sequences to identify homologous sequences and locate the specific mutations that make them distinct. These techniques, especially multiple sequence alignment, are used in studying phylogenetic relationships and protein function. Data sets representing entire genomes' worth of DNA sequences, such as those produced by the Human Genome Project, are difficult to use without the annotations that identify the locations of genes and regulatory elements on each chromosome. Regions of DNA sequence that have the characteristic patterns associated with protein- or RNA-coding genes can be identified by gene finding algorithms, which allow researchers to predict the presence of particular gene products and their possible functions in an organism even before they have been isolated experimentally. Entire genomes may also be compared, which can shed light on the evolutionary history of particular organism and permit the examination of complex evolutionary events.

DNA nanotechnology uses the unique molecular recognition properties of DNA and other nucleic acids to create self-assembling branched DNA complexes with useful properties. DNA is thus used as a structural material rather than as a carrier of biological information. This has led to the creation of two-dimensional periodic lattices (both tile-based and using the "DNA origami" method) and three-dimensional structures in the shapes of polyhedra. Nanomechanical devices and algorithmic self-assembly have also been demonstrated, and these DNA structures have been used to template the arrangement of other molecules such as gold nanoparticles and streptavidin proteins. DNA and other nucleic acids are the basis of aptamers, synthetic oligonucleotide ligands for specific target molecules used in a range of biotechnology and biomedical applications.

Because DNA collects mutations over time, which are then inherited, it contains historical information, and, by comparing DNA sequences, geneticists can infer the evolutionary history of organisms, their phylogeny. This field of phylogenetics is a powerful tool in evolutionary biology. If DNA sequences within a species are compared, population geneticists can learn the history of particular populations. This can be used in studies ranging from ecological genetics to anthropology.

DNA as a storage device for information has enormous potential since it has much higher storage density compared to electronic devices. However, high costs, slow read and write times (memory latency), and insufficient reliability has prevented its practical use.

DNA was first isolated by the Swiss physician Friedrich Miescher who, in 1869, discovered a microscopic substance in the pus of discarded surgical bandages. As it resided in the nuclei of cells, he called it "nuclein". In 1878, Albrecht Kossel isolated the non-protein component of "nuclein", nucleic acid, and later isolated its five primary nucleobases.

In 1909, Phoebus Levene identified the base, sugar, and phosphate nucleotide unit of RNA (then named "yeast nucleic acid"). In 1929, Levene identified deoxyribose sugar in "thymus nucleic acid" (DNA). Levene suggested that DNA consisted of a string of four nucleotide units linked together through the phosphate groups ("tetranucleotide hypothesis"). Levene thought the chain was short and the bases repeated in a fixed order. In 1927, Nikolai Koltsov proposed that inherited traits would be inherited via a "giant hereditary molecule" made up of "two mirror strands that would replicate in a semi-conservative fashion using each strand as a template". In 1928, Frederick Griffith in his experiment discovered that traits of the "smooth" form of "Pneumococcus" could be transferred to the "rough" form of the same bacteria by mixing killed "smooth" bacteria with the live "rough" form. This system provided the first clear suggestion that DNA carries genetic information.

In 1933, while studying virgin sea urchin eggs, Jean Brachet suggested that DNA is found in the cell nucleus and that RNA is present exclusively in the cytoplasm. At the time, "yeast nucleic acid" (RNA) was thought to occur only in plants, while "thymus nucleic acid" (DNA) only in animals. The latter was thought to be a tetramer, with the function of buffering cellular pH.

In 1937, William Astbury produced the first X-ray diffraction patterns that showed that DNA had a regular structure.

In 1943, Oswald Avery, along with co-workers Colin MacLeod and Maclyn McCarty, identified DNA as the transforming principle, supporting Griffith's suggestion (Avery–MacLeod–McCarty experiment). Erwin Chargaff developed and published observations now known as Chargaff's rules, stating that in DNA from any species of any organism, the amount of guanine should be equal to cytosine and the amount of adenine should be equal to thymine. 

Late in 1951, Francis Crick started working with James Watson at the Cavendish Laboratory within the University of Cambridge, UK. DNA's role in heredity was confirmed in 1952 when Alfred Hershey and Martha Chase in the Hershey–Chase experiment showed that DNA is the genetic material of the enterobacteria phage T2.

In May 1952, Raymond Gosling, a graduate student working under the supervision of Rosalind Franklin, took an X-ray diffraction image, labeled as "Photo 51", at high hydration levels of DNA. This photo was given to Watson and Crick by Maurice Wilkins and was critical to their obtaining the correct structure of DNA. Franklin told Crick and Watson that the backbones had to be on the outside. Before then, Linus Pauling, and Watson and Crick, had erroneous models with the chains inside and the bases pointing outwards. Franklin's identification of the space group for DNA crystals revealed to Crick that the two DNA strands were antiparallel. In February 1953, Linus Pauling and Robert Corey proposed a model for nucleic acids containing three intertwined chains, with the phosphates near the axis, and the bases on the outside. Watson and Crick completed their model, which is now accepted as the first correct model of the double helix of DNA. On 28 February 1953 Crick interrupted patrons' lunchtime at The Eagle pub in Cambridge, UK to announce that he and Watson had "discovered the secret of life".

The 25 April 1953 issue of the journal "Nature" published a series of five articles giving the Watson and Crick double-helix structure DNA and evidence supporting it. The structure was reported in a letter titled ""MOLECULAR STRUCTURE OF NUCLEIC ACIDS A Structure for Deoxyribose Nucleic Acid", in which they said, "It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material." This letter was followed by a letter from Franklin and Gosling, which was the first publication of their own X-ray diffraction data and of their original analysis method. Then followed a letter by Wilkins and two of his colleagues, which contained an analysis of "in vivo" B-DNA X-ray patterns, and which supported the presence "in vivo" of the Watson and Crick structure.

In April 2023, scientists, based on new evidence, concluded that Rosalind Franklin was a contributor and "equal player" in the discovery process of DNA, rather than otherwise, as may have been presented subsequently after the time of the discovery.

In 1962, after Franklin's death, Watson, Crick, and Wilkins jointly received the Nobel Prize in Physiology or Medicine. Nobel Prizes are awarded only to living recipients. A debate continues about who should receive credit for the discovery.

In an influential presentation in 1957, Crick laid out the central dogma of molecular biology, which foretold the relationship between DNA, RNA, and proteins, and articulated the "adaptor hypothesis". Final confirmation of the replication mechanism that was implied by the double-helical structure followed in 1958 through the Meselson–Stahl experiment. Further work by Crick and co-workers showed that the genetic code was based on non-overlapping triplets of bases, called codons, allowing Har Gobind Khorana, Robert W. Holley, and Marshall Warren Nirenberg to decipher the genetic code. These findings represent the birth of molecular biology.
In 1986 DNA analysis was first used for criminal investigative purposes when police in the UK requested Alec Jeffreys of the University of Leicester to verify or disprove a suspect's rape-murder "confession." In this particular case, the suspect had confessed to two rape-murders, but had later retracted his confession. DNA testing at the university labs soon disproved the veracity of the suspect's original "confession," and the suspect was exonerated from the murder-rape charges.




Kennedy family

The Kennedy family is an American political family that has long been prominent in American politics, public service, entertainment, and business. In 1884, 35 years after the family's arrival from County Wexford, Ireland, Patrick Joseph "P. J." Kennedy became the first Kennedy elected to public office, serving in the Massachusetts state legislature until 1895. At least one Kennedy family member served in federal elective office from 1947, when P. J. Kennedy's grandson John F. Kennedy became a member of Congress from Massachusetts, until 2011, when Patrick J. Kennedy II (John's nephew) retired as a member of the U.S. House of Representatives from Rhode Island.

P. J.'s son Joseph P. Kennedy Sr. and his wife, Rose Fitzgerald Kennedy, had nine children, including John F. Kennedy, who served in both houses of the United States Congress and as U.S. President; Robert F. Kennedy, who served as U.S. Attorney General and as a U.S. Senator; and Ted Kennedy, who served more than 46 years in the U.S. Senate. Other descendants include members of the U.S. House of Representatives, two U.S. ambassadors, one U.S. envoy, a lieutenant governor, three state legislators (one of whom also served in the U.S. House of Representatives), and one mayor.

Joseph and Rose's daughter Eunice played a vital role in establishing the National Institute of Child Health and Human Development (part of the National Institutes of Health) and the Special Olympics. Other descendants of Joseph and Rose Kennedy have been lawyers, authors, and activists on behalf of those with physical and intellectual disabilities.

According to genealogist Brian Kennedy in his work "JFK's Irish O'Kennedy Ancestors", the Kennedys—who would go on to play a significant role in the United States of America—originated from an Irish clan called Ó Cinnéide Fionn (which, along with the Ó Cinnéide Donn and Ó Cinnéide Ruadh, were the three Irish Gaelic Ó Cinnéide clans who ruled the kingdom of Ormond). In 1546, their progenitor Diarmaid Ó Cinnéide Fionn became the owner of Knigh Castle, located close to what is today Puckane, County Tipperary. In 1740, having lost out to the New English order in the Kingdom of Ireland, they moved to Dunganstown, New Ross, County Wexford. Patrick Kennedy was born there.

Patrick Kennedy (1823–1858) and Bridget Murphy (1824–1888) sailed from Ireland to East Boston in 1849. Patrick worked in East Boston as a barrel maker, or cooper, and had five children with Bridget. Their youngest, Patrick Joseph "P. J." Kennedy, went into business and served in the Massachusetts state legislature from 1884 to 1895.

P. J. and his wife, Mary Augusta Hickey, had four children. Their oldest was Joseph Patrick "Joe" Kennedy Sr., a businessman who amassed a private fortune in banking and securities trading, which he further expanded by investing in filmmaking and real estate. He also founded Somerset Importers and owned Chicago's Merchandise Mart.

In 1914, Joseph Sr. married Rose Fitzgerald, the eldest daughter of John F. "Honey Fitz" Fitzgerald, who served six years as mayor of Boston and six years as a member of the U.S. House of Representatives. The couple had nine children: Joseph Jr., John (called Jack), Rose Marie (called Rosemary), Kathleen, Eunice, Patricia, Robert (called Bobby), Jean, and Edward (called Ted).

Joseph Sr. was appointed by President Franklin D. Roosevelt as the first chairman of the Securities and Exchange Commission (SEC), chairman of the Maritime Commission, and U.S. ambassador to the United Kingdom from 1938 to 1940. He served from 1947 to 1949 on The Hoover Commission (the "Commission on Organization of the Executive Branch of the Government"), which was appointed by President Harry Truman to recommend administrative changes in the federal government. Rose Fitzgerald Kennedy was named Papal Countess of the Holy Roman Church by Pope Pius XII in 1951 in recognition of her "exemplary motherhood and many charitable works."

Every Kennedy elected to public office has served as a Democrat, while other members of the family have worked for the party or held Cabinet posts in Democratic administrations. Many have attended Harvard University, and the family has contributed greatly to that university's John F. Kennedy School of Government.

Joseph Sr. expected his eldest son, Joseph Jr., to go into politics and to ultimately be elected president. Joseph Jr. was elected as a Massachusetts delegate to the 1940 Democratic National Convention and enlisted in the U.S. Navy after the United States entered World War II. He was killed in 1944 when the bomber he was piloting exploded in flight. Joseph Sr.'s desire to see the family involved in politics and government then focused on John, who had considered a career as a journalist, having authored a book ("Why England Slept") and done some reporting for Hearst Newspapers. After returning from Navy service, John served in the U.S. House of Representatives representing Massachusetts's 11th congressional district from 1947 to 1953, and then as U.S. Senator from Massachusetts from 1953 to 1960. In the 1960 presidential election, John narrowly defeated Republican opponent Richard Nixon.

During John's administration, Robert served as attorney general; his brother-in-law Sargent Shriver served as director of the new Peace Corps, and Ted was elected to the U.S. Senate from Massachusetts, occupying his brother's former Senate seat until Ted's death in 2009. The Kennedy administration's accomplishments include the Alliance for Progress with Latin America, the establishment of the Peace Corps, a peaceful resolution to the Cuban Missile Crisis in October 1962, the Nuclear Test Ban Treaty of 1963, the 24th Amendment ending the poll tax, the continuation of the Apollo spaceflight program with the goal of landing a man on the Moon, and the introduction of the Civil Rights Act of 1964 to Congress (signed into law by Kennedy's successor Lyndon B. Johnson). The family was the subject of intense media coverage during and after Kennedy's presidency.

Ted served in the Senate with his brother Robert (1965–1968), and was serving in the Senate when his nephew, Joseph P. II, and his son, Patrick J., served in the U.S. House of Representatives representing Massachusetts's 8th congressional district (1987–1999) and Rhode Island's 1st congressional district (1995–2011), respectively. In November 2012, Joseph P. Kennedy III, son of former Rep. Joseph P. Kennedy II and grandson of the late Sen. Robert F. Kennedy, was elected to the U.S. House of Representatives from Massachusetts's 4th congressional district. In 2020, Joseph P. III lost the U.S. Senate primary election in Massachusetts to incumbent Ed Markey, the first Kennedy to ever lose an election in the state.

In the 2020s, three Kennedy family members were serving as U.S. ambassadors or envoys. Victoria Reggie Kennedy, second wife of Ted Kennedy, was named in 2021 by President Biden as U.S. ambassador to Austria. Caroline Kennedy, daughter of President Kennedy, was named in 2022 by President Biden as U.S. ambassador to Australia; she previously served as U.S. ambassador to Japan under President Barack Obama. In the same year, Joseph P. Kennedy III was named by President Biden as U.S. special envoy to Northern Ireland. In April 2023, Robert F. Kennedy Jr., an environmental lawyer and anti-vaccine activist, filed as a Democratic candidate for the 2024 nomination for President of the United States, and changed to an independent candidate in October 2023.




In addition, some Kennedy spouses have served in government:

There was a member of the Kennedy family in public office nearly continuously from 1946, when John F. Kennedy was elected to the U.S. House of Representatives, until early 2011, when Patrick J. Kennedy left the House. The only exception was the period between John F. Kennedy's resignation from the Senate on December 22, 1960, and his assumption of the office of President on January 20, 1961. In 2013, two years after Patrick Kennedy left the House, Joseph P. Kennedy III was elected U.S. Representative from Massachusetts and served until 2021. Below is a timeline of the Kennedys' tenure in the U.S. Congress.

In 1961, John F. Kennedy was presented with a grant of arms for all the descendants of Patrick Kennedy (1823–1858) from the Chief Herald of Ireland. The design of the arms (three gold closed helmets on a black field) strongly alludes to symbols in the coats of arms of the O'Kennedys of Ormonde and the FitzGeralds of Desmond, from whom the family is descended. The crest is an armored hand holding four arrows between two olive branches, elements taken from the coat of arms of the United States of America and also symbolic of Kennedy and his brothers.




Deflation (disambiguation)

Commonly, deflation refers to a decrease in the general price level, the opposite of inflation.

Deflation may also refer to:


Democracy

Democracy (from , "dēmos" 'people' and "kratos" 'rule') is a system of government in which state power is vested in the people or the general population of a state. Under a minimalist definition of democracy, rulers are elected through competitive elections while more expansive definitions link democracy to guarantees of civil liberties and human rights in addition to competitive elections.

In a direct democracy, the people have the direct authority to deliberate and decide legislation. In a representative democracy, the people choose governing officials through elections to do so. Who is considered part of "the people" and how authority is shared among or delegated by the people has changed over time and at different rates in different countries. Features of democracy oftentimes include freedom of assembly, association, personal property, freedom of religion and speech, citizenship, consent of the governed, voting rights, freedom from unwarranted governmental deprivation of the right to life and liberty, and minority rights.

The notion of democracy has evolved over time considerably. Throughout history, one can find evidence of direct democracy, in which communities make decisions through popular assembly. Today, the dominant form of democracy is representative democracy, where citizens elect government officials to govern on their behalf such as in a parliamentary or presidential democracy. Most democracies apply in most cases majority rule, but in some cases plurality rule, supermajority rule (e.g. constitution) or consensus rule (e.g. Switzerland) are applied. They serve the crucial purpose of inclusiveness and broader legitimacy on sensitive issues—counterbalancing majoritarianism—and therefore mostly take precedence on a constitutional level. In the common variant of liberal democracy, the powers of the majority are exercised within the framework of a representative democracy, but the constitution and a supreme court limit the majority and protect the minority—usually through securing the enjoyment by all of certain individual rights, e.g. freedom of speech or freedom of association.

The term appeared in the 5th century BC in Greek city-states, notably Classical Athens, to mean "rule of the people", in contrast to aristocracy (, ""), meaning "rule of an elite". Western democracy, as distinct from that which existed in antiquity, is generally considered to have originated in city-states such as those in Classical Athens and the Roman Republic, where various degrees of enfranchisement of the free male population were observed. In virtually all democratic governments throughout ancient and modern history, democratic citizenship was initially restricted to an elite class, which was later extended to all adult citizens. In most modern democracies, this was achieved through the suffrage movements of the 19th and 20th centuries.

Democracy contrasts with forms of government where power is not vested in the general population of a state, such as authoritarian systems. World public opinion strongly favors democratic systems of government. According to the V-Dem Democracy indices and The Economist Democracy Index, less than half the world's population lives in a democracy . 

Although democracy is generally understood to be defined by voting, no consensus exists on a precise definition of democracy. Karl Popper says that the "classical" view of democracy is, "in brief, the theory that democracy is the rule of the people, and that the people have a right to rule". One study identified 2,234 adjectives used to describe democracy in the English language.

Democratic principles are reflected in all eligible citizens being equal before the law and having equal access to legislative processes. For example, in a representative democracy, every vote has (in theory) equal weight, and the freedom of eligible citizens is secured by legitimised rights and liberties which are typically enshrined in a constitution. Other uses of "democracy" may encompass direct democracy, in which citizens vote on issues directly.

One theory holds that democracy requires three fundamental principles: upward control (sovereignty residing at the lowest levels of authority), political equality, and social norms by which individuals and institutions only consider acceptable acts that reflect the first two principles of upward control and political equality. Legal equality, political freedom and rule of law are often identified by commentators as foundational characteristics for a well-functioning democracy.

In some countries, notably in the United Kingdom (which originated the Westminster system), the dominant principle is that of parliamentary sovereignty, while maintaining judicial independence. In India, parliamentary sovereignty is subject to the Constitution of India which includes judicial review. Though the term "democracy" is typically used in the context of a political state, the principles also are potentially applicable to private organisations, such as clubs, societies and firms.

Democracies may use many different decision-making methods, but majority rule is the dominant form. Without compensation, like legal protections of individual or group rights, political minorities can be oppressed by the "tyranny of the majority". Majority rule involves a competitive approach, opposed to consensus democracy, creating the need that elections, and generally deliberation, be substantively and procedurally "fair"," i.e. just and equitable. In some countries, freedom of political expression, freedom of speech, and freedom of the press are considered important to ensure that voters are well informed, enabling them to vote according to their own interests and beliefs.

It has also been suggested that a basic feature of democracy is the capacity of all voters to participate freely and fully in the life of their society. With its emphasis on notions of social contract and the collective will of all the voters, democracy can also be characterised as a form of political collectivism because it is defined as a form of government in which all eligible citizens have an equal say in lawmaking.

Republics, though often popularly associated with democracy because of the shared principle of rule by consent of the governed, are not necessarily democracies, as republicanism does not specify "how" the people are to rule.
Classically the term "republic" encompassed both democracies and aristocracies. In a modern sense the republican form of government is a form of government without a monarch. Because of this, democracies can be republics or constitutional monarchies, such as the United Kingdom.

Democratic assemblies are as old as the human species and are found throughout human history, but up until the nineteenth century, major political figures have largely opposed democracy. Republican theorists linked democracy to small size: as political units grew in size, the likelihood increased that the government would turn despotic. At the same time, small political units were vulnerable to conquest. Montesquieu wrote, "If a republic be small, it is destroyed by a foreign force; if it be large, it is ruined by an internal imperfection." According to Johns Hopkins University political scientist Daniel Deudney, the creation of the United States, with its large size and its system of checks and balances, was a solution to the dual problems of size.

Retrospectively different polities, outside of declared democracies, have been described as proto-democratic.

The term "democracy" first appeared in ancient Greek political and philosophical thought in the city-state of Athens during classical antiquity. The word comes from "dêmos" '(common) people' and "krátos" 'force/might'. Under Cleisthenes, what is generally held as the first example of a type of democracy in 508–507 BC was established in Athens. Cleisthenes is referred to as "the father of Athenian democracy". The first attested use of the word democracy is found in prose works of the 430s BC, such as Herodotus' "Histories", but its usage was older by several decades, as two Athenians born in the 470s were named Democrates, a new political name—likely in support of democracy—given at a time of debates over constitutional issues in Athens. Aeschylus also strongly alludes to the word in his play "The Suppliants", staged in c.463 BC, where he mentions "the demos's ruling hand" ["demou kratousa cheir"]. Before that time, the word used to define the new political system of Cleisthenes was probably isonomia, meaning political equality.

Athenian democracy took the form of a direct democracy, and it had two distinguishing features: the random selection of ordinary citizens to fill the few existing government administrative and judicial offices, and a legislative assembly consisting of all Athenian citizens. All eligible citizens were allowed to speak and vote in the assembly, which set the laws of the city state. However, Athenian citizenship excluded women, slaves, foreigners (μέτοικοι / "métoikoi"), and youths below the age of military service. Effectively, only 1 in 4 residents in Athens qualified as citizens. Owning land was not a requirement for citizenship. The exclusion of large parts of the population from the citizen body is closely related to the ancient understanding of citizenship. In most of antiquity the benefit of citizenship was tied to the obligation to fight war campaigns.

Athenian democracy was not only "direct" in the sense that decisions were made by the assembled people, but also the "most direct" in the sense that the people through the assembly, boule and courts of law controlled the entire political process and a large proportion of citizens were involved constantly in the public business. Even though the rights of the individual were not secured by the Athenian constitution in the modern sense (the ancient Greeks had no word for "rights"), those who were citizens of Athens enjoyed their liberties not in opposition to the government but by living in a city that was not subject to another power and by not being subjects themselves to the rule of another person.

Range voting appeared in Sparta as early as 700 BC. The Spartan ecclesia was an assembly of the people, held once a month, in which every male citizen of at least 20 years of age could participate. In the assembly, Spartans elected leaders and cast votes by range voting and shouting (the vote is then decided on how loudly the crowd shouts). Aristotle called this "childish", as compared with the stone voting ballots used by the Athenian citizenry. Sparta adopted it because of its simplicity, and to prevent any biased voting, buying, or cheating that was predominant in the early democratic elections.

Even though the Roman Republic contributed significantly to many aspects of democracy, only a minority of Romans were citizens with votes in elections for representatives. The votes of the powerful were given more weight through a system of weighted voting, so most high officials, including members of the Senate, came from a few wealthy and noble families. In addition, the overthrow of the Roman Kingdom was the first case in the Western world of a polity being formed with the explicit purpose of being a republic, although it didn't have much of a democracy. The Roman model of governance inspired many political thinkers over the centuries.

Vaishali, capital city of the Vajjika League (Vrijji mahajanapada) of India, was also considered one of the first examples of a republic around the 6th century BC.

Other cultures, such as the Iroquois Nation in the Americas also developed a form of democratic society between 1450 and 1660 (and possibly in 1142), well before contact with the Europeans. This democracy continues to the present day and is the world's oldest standing representative democracy. This indicates that forms of democracy may have been invented in other societies around the world.

While most regions in Europe during the Middle Ages were ruled by clergy or feudal lords, there existed various systems involving elections or assemblies, although often only involving a small part of the population. In Scandinavia, bodies known as things consisted of freemen presided by a lawspeaker. These deliberative bodies were responsible for settling political questions, and variants included the Althing in Iceland and the Løgting in the Faeroe Islands. The veche, found in Eastern Europe, was a similar body to the Scandinavian thing. In the Roman Catholic Church, the pope has been elected by a papal conclave composed of cardinals since 1059. The first documented parliamentary body in Europe was the Cortes of León. Established by Alfonso IX in 1188, the Cortes had authority over setting taxation, foreign affairs and legislating, though the exact nature of its role remains disputed. The Republic of Ragusa, established in 1358 and centered around the city of Dubrovnik, provided representation and voting rights to its male aristocracy only. Various Italian city-states and polities had republic forms of government. For instance, the Republic of Florence, established in 1115, was led by the Signoria whose members were chosen by sortition. In 10th–15th century Frisia, a distinctly non-feudal society, the right to vote on local matters and on county officials was based on land size. The Kouroukan Fouga divided the Mali Empire into ruling clans (lineages) that were represented at a great assembly called the "Gbara". However, the charter made Mali more similar to a constitutional monarchy than a democratic republic.
The Parliament of England had its roots in the restrictions on the power of kings written into Magna Carta (1215), which explicitly protected certain rights of the King's subjects and implicitly supported what became the English writ of habeas corpus, safeguarding individual freedom against unlawful imprisonment with right to appeal. The first representative national assembly in England was Simon de Montfort's Parliament in 1265. The emergence of petitioning is some of the earliest evidence of parliament being used as a forum to address the general grievances of ordinary people. However, the power to call parliament remained at the pleasure of the monarch.

Studies have linked the emergence of parliamentary institutions in Europe during the medieval period to urban agglomeration and the creation of new classes, such as artisans, as well as the presence of nobility and religious elites. Scholars have also linked the emergence of representative government to Europe's relative political fragmentation. Political scientist David Stasavage links the fragmentation of Europe, and its subsequent democratization, to the manner in which the Roman Empire collapsed: Roman territory was conquered by small fragmented groups of Germanic tribes, thus leading to the creation of small political units where rulers were relatively weak and needed the consent of the governed to ward off foreign threats.

In Poland, noble democracy was characterized by an increase in the activity of the middle nobility, which wanted to increase their share in exercising power at the expense of the magnates. Magnates dominated the most important offices in the state (secular and ecclesiastical) and sat on the royal council, later the senate. The growing importance of the middle nobility had an impact on the establishment of the institution of the land "sejmik" (local assembly), which subsequently obtained more rights. During the fifteenth and first half of the sixteenth century, sejmiks received more and more powers and became the most important institutions of local power. In 1454, Casimir IV Jagiellon granted the sejmiks the right to decide on taxes and to convene a mass mobilization in the Nieszawa Statutes. He also pledged not to create new laws without their consent.

In 17th century England, there was renewed interest in Magna Carta. The Parliament of England passed the Petition of Right in 1628 which established certain liberties for subjects. The English Civil War (1642–1651) was fought between the King and an oligarchic but elected Parliament, during which the idea of a political party took form with groups debating rights to political representation during the Putney Debates of 1647. Subsequently, the Protectorate (1653–59) and the English Restoration (1660) restored more autocratic rule, although Parliament passed the Habeas Corpus Act in 1679 which strengthened the convention that forbade detention lacking sufficient cause or evidence. After the Glorious Revolution of 1688, the Bill of Rights was enacted in 1689 which codified certain rights and liberties and is still in effect. The Bill set out the requirement for regular elections, rules for freedom of speech in Parliament and limited the power of the monarch, ensuring that, unlike much of Europe at the time, royal absolutism would not prevail. Economic historians Douglass North and Barry Weingast have characterized the institutions implemented in the Glorious Revolution as a resounding success in terms of restraining the government and ensuring protection for property rights.

Renewed interest in the Magna Carta, the English Civil War, and the Glorious Revolution in the 17th century prompted the growth of political philosophy on the British Isles. Thomas Hobbes was the first philosopher to articulate a detailed social contract theory. Writing in the "Leviathan" (1651), Hobbes theorized that individuals living in the state of nature led lives that were "solitary, poor, nasty, brutish and short" and constantly waged a war of all against all. In order to prevent the occurrence of an anarchic state of nature, Hobbes reasoned that individuals ceded their rights to a strong, authoritarian power. In other words, Hobbes advocated for an absolute monarchy which, in his opinion, was the best form of government. Later, philosopher and physician John Locke would posit a different interpretation of social contract theory. Writing in his "Two Treatises of Government" (1689), Locke posited that all individuals possessed the inalienable rights to life, liberty and estate (property). According to Locke, individuals would voluntarily come together to form a state for the purposes of defending their rights. Particularly important for Locke were property rights, whose protection Locke deemed to be a government's primary purpose. Furthermore, Locke asserted that governments were legitimate only if they held the consent of the governed. For Locke, citizens had the right to revolt against a government that acted against their interest or became tyrannical. Although they were not widely read during his lifetime, Locke's works are considered the founding documents of liberal thought and profoundly influenced the leaders of the American Revolution and later the French Revolution. His liberal democratic framework of governance remains the preeminent form of democracy in the world.

In the Cossack republics of Ukraine in the 16th and 17th centuries, the Cossack Hetmanate and Zaporizhian Sich, the holder of the highest post of Hetman was elected by the representatives from the country's districts.

In North America, representative government began in Jamestown, Virginia, with the election of the House of Burgesses (forerunner of the Virginia General Assembly) in 1619. English Puritans who migrated from 1620 established colonies in New England whose local governance was democratic; although these local assemblies had some small amounts of devolved power, the ultimate authority was held by the Crown and the English Parliament. The Puritans (Pilgrim Fathers), Baptists, and Quakers who founded these colonies applied the democratic organisation of their congregations also to the administration of their communities in worldly matters.

The first Parliament of Great Britain was established in 1707, after the merger of the Kingdom of England and the Kingdom of Scotland under the Acts of Union. Two key documents of the UK's uncodified constitution, the English Declaration of Right, 1689 (restated in the Bill of Rights 1689) and the Scottish Claim of Right 1689, had both cemented Parliament's position as the supreme law-making body, and said that the "election of members of Parliament ought to be free". However, Parliament was only elected by male property owners, which amounted to 3% of the population in 1780. The first known British person of African heritage to vote in a general election, Ignatius Sancho, voted in 1774 and 1780.

During the Age of Liberty in Sweden (1718–1772), civil rights were expanded and power shifted from the monarch to parliament. The taxed peasantry was represented in parliament, although with little influence, but commoners without taxed property had no suffrage.

The creation of the short-lived Corsican Republic in 1755 was an early attempt to adopt a democratic constitution (all men and women above age of 25 could vote). This Corsican Constitution was the first based on Enlightenment principles and included female suffrage, something that was not included in most other democracies until the 20th century.

Colonial America had similar property qualifications as Britain, and in the period before 1776 the abundance and availability of land meant that large numbers of colonists met such requirements with at least 60 per cent of adult white males able to vote. The great majority of white men were farmers who met the property ownership or taxpaying requirements. With few exceptions no blacks or women could vote. Vermont, which, on declaring independence of Great Britain in 1777, adopted a constitution modelled on Pennsylvania's with citizenship and democratic suffrage for males with or without property. The United States Constitution of 1787 is the oldest surviving, still active, governmental codified constitution. The Constitution provided for an elected government and protected civil rights and liberties, but did not end slavery nor extend voting rights in the United States, instead leaving the issue of suffrage to the individual states. Generally, states limited suffrage to white male property owners and taxpayers. At the time of the first Presidential election in 1789, about 6% of the population was eligible to vote. The Naturalization Act of 1790 limited U.S. citizenship to whites only. The Bill of Rights in 1791 set limits on government power to protect personal freedoms but had little impact on judgements by the courts for the first 130 years after ratification.

In 1789, Revolutionary France adopted the Declaration of the Rights of Man and of the Citizen and, although short-lived, the National Convention was elected by all men in 1792. The Polish-Lithuanian Constitution of 3 May 1791 sought to implement a more effective constitutional monarchy, introduced political equality between townspeople and nobility, and placed the peasants under the protection of the government, mitigating the worst abuses of serfdom. In force for less than 19 months, it was declared null and void by the Grodno Sejm that met in 1793. Nonetheless, the 1791 Constitution helped keep alive Polish aspirations for the eventual restoration of the country's sovereignty over a century later.
In the United States, the 1828 presidential election was the first in which non-property-holding white males could vote in the vast majority of states. Voter turnout soared during the 1830s, reaching about 80% of the adult white male population in the 1840 presidential election. North Carolina was the last state to abolish property qualification in 1856 resulting in a close approximation to universal white male suffrage (however tax-paying requirements remained in five states in 1860 and survived in two states until the 20th century). In the 1860 United States Census, the slave population had grown to four million, and in Reconstruction after the Civil War, three constitutional amendments were passed: the 13th Amendment (1865) that ended slavery; the 14th Amendment (1869) that gave black people citizenship, and the 15th Amendment (1870) that gave black males a nominal right to vote. Full enfranchisement of citizens was not secured until after the civil rights movement gained passage by the US Congress of the Voting Rights Act of 1965.

The voting franchise in the United Kingdom was expanded and made more uniform in a series of reforms that began with the Reform Act 1832 and continued into the 20th century, notably with the Representation of the People Act 1918 and the Equal Franchise Act 1928. Universal male suffrage was established in France in March 1848 in the wake of the French Revolution of 1848. During that year, several revolutions broke out in Europe as rulers were confronted with popular demands for liberal constitutions and more democratic government.

In 1876 the Ottoman Empire transitioned from an absolute monarchy to a constitutional one, and held two elections the next year to elect members to her newly formed parliament. Provisional Electoral Regulations were issued, stating that the elected members of the Provincial Administrative Councils would elect members to the first Parliament. Later that year, a new constitution was promulgated, which provided for a bicameral Parliament with a Senate appointed by the Sultan and a popularly elected Chamber of Deputies. Only men above the age of 30 who were competent in Turkish and had full civil rights were allowed to stand for election. Reasons for disqualification included holding dual citizenship, being employed by a foreign government, being bankrupt, employed as a servant, or having "notoriety for ill deeds". Full universal suffrage was achieved in 1934.

In 1893 the self-governing colony New Zealand became the first country in the world (except for the short-lived 18th-century Corsican Republic) to establish active universal suffrage by recognizing women as having the right to vote.

20th-century transitions to liberal democracy have come in successive "waves of democracy", variously resulting from wars, revolutions, decolonisation, and religious and economic circumstances. Global waves of "democratic regression" reversing democratization, have also occurred in the 1920s and 30s, in the 1960s and 1970s, and in the 2010s.

World War I and the dissolution of the autocratic Ottoman and Austro-Hungarian empires resulted in the creation of new nation-states in Europe, most of them at least nominally democratic. In the 1920s democratic movements flourished and women's suffrage advanced, but the Great Depression brought disenchantment and most of the countries of Europe, Latin America, and Asia turned to strong-man rule or dictatorships. Fascism and dictatorships flourished in Nazi Germany, Italy, Spain and Portugal, as well as non-democratic governments in the Baltics, the Balkans, Brazil, Cuba, China, and Japan, among others.

World War II brought a definitive reversal of this trend in western Europe. The democratisation of the American, British, and French sectors of occupied Germany (disputed), Austria, Italy, and the occupied Japan served as a model for the later theory of government change. However, most of Eastern Europe, including the Soviet sector of Germany fell into the non-democratic Soviet-dominated bloc.

The war was followed by decolonisation, and again most of the new independent states had nominally democratic constitutions. India emerged as the world's largest democracy and continues to be so. Countries that were once part of the British Empire often adopted the British Westminster system. By 1960, the vast majority of country-states were nominally democracies, although most of the world's populations lived in nominal democracies that experienced sham elections, and other forms of subterfuge (particularly in "Communist" states and the former colonies.)

A subsequent wave of democratisation brought substantial gains toward true liberal democracy for many states, dubbed "third wave of democracy". Portugal, Spain, and several of the military dictatorships in South America returned to civilian rule in the 1970s and 1980s. This was followed by countries in East and South Asia by the mid-to-late 1980s. Economic malaise in the 1980s, along with resentment of Soviet oppression, contributed to the collapse of the Soviet Union, the associated end of the Cold War, and the democratisation and liberalisation of the former Eastern bloc countries. The most successful of the new democracies were those geographically and culturally closest to western Europe, and they are now either part of the European Union or candidate states. In 1986, after the toppling of the most prominent Asian dictatorship, the only democratic state of its kind at the time emerged in the Philippines with the rise of Corazon Aquino, who would later be known as the Mother of Asian Democracy.

The liberal trend spread to some states in Africa in the 1990s, most prominently in South Africa. Some recent examples of attempts of liberalisation include the Indonesian Revolution of 1998, the Bulldozer Revolution in Yugoslavia, the Rose Revolution in Georgia, the Orange Revolution in Ukraine, the Cedar Revolution in Lebanon, the Tulip Revolution in Kyrgyzstan, and the Jasmine Revolution in Tunisia.

According to Freedom House, in 2007 there were 123 electoral democracies (up from 40 in 1972). According to "World Forum on Democracy", electoral democracies now represent 120 of the 192 existing countries and constitute 58.2 per cent of the world's population. At the same time liberal democracies i.e. countries Freedom House regards as free and respectful of basic human rights and the rule of law are 85 in number and represent 38 per cent of the global population. Also in 2007 the United Nations declared 15 September the International Day of Democracy.
Many countries reduced their voting age to 18 years; the major democracies began to do so in the 1970s starting in Western Europe and North America. Most electoral democracies continue to exclude those younger than 18 from voting. The voting age has been lowered to 16 for national elections in a number of countries, including Brazil, Austria, Cuba, and Nicaragua. In California, a 2004 proposal to permit a quarter vote at 14 and a half vote at 16 was ultimately defeated. In 2008, the German parliament proposed but shelved a bill that would grant the vote to each citizen at birth, to be used by a parent until the child claims it for themselves.

According to Freedom House, starting in 2005, there have been 17 consecutive years in which declines in political rights and civil liberties throughout the world have outnumbered improvements, as populist and nationalist political forces have gained ground everywhere from Poland (under the Law and Justice Party) to the Philippines (under Rodrigo Duterte). In a Freedom House report released in 2018, Democracy Scores for most countries declined for the 12th consecutive year. "The Christian Science Monitor" reported that nationalist and populist political ideologies were gaining ground, at the expense of rule of law, in countries like Poland, Turkey and Hungary. For example, in Poland, the President appointed 27 new Supreme Court judges over legal objections from the European Commission. In Turkey, thousands of judges were removed from their positions following a failed coup attempt during a government crackdown .
"Democratic backsliding" in the 2010s were attributed to economic inequality and social discontent, personalism, poor government's management of the COVID-19 pandemic, as well as other factors such as manipulation of civil society, "toxic polarization", foreign disinformation campaigns, racism and nativism, excessive executive power, and decreased power of the opposition. Within English-speaking Western democracies, "protection-based" attitudes combining cultural conservatism and leftist economic attitudes were the strongest predictor of support for authoritarian modes of governance.

Aristotle contrasted rule by the many (democracy/timocracy), with rule by the few (oligarchy/aristocracy), and with rule by a single person (tyranny or today autocracy/absolute monarchy). He also thought that there was a good and a bad variant of each system (he considered democracy to be the degenerate counterpart to timocracy).

A common view among early and renaissance Republican theorists was that democracy could only survive in small political communities. Heeding the lessons of the Roman Republic's shift to monarchism as it grew larger or smaller, these Republican theorists held that the expansion of territory and population inevitably led to tyranny. Democracy was therefore highly fragile and rare historically, as it could only survive in small political units, which due to their size were vulnerable to conquest by larger political units. Montesquieu famously said, "if a republic is small, it is destroyed by an outside force; if it is large, it is destroyed by an internal vice." Rousseau asserted, "It is, therefore the natural property of small states to be governed as a republic, of middling ones to be subject to a monarch, and of large empires to be swayed by a despotic prince."

Among modern political theorists, there are three contending conceptions of democracy: "aggregative democracy", "deliberative democracy", and "radical democracy".

The theory of "aggregative democracy" claims that the aim of the democratic processes is to solicit citizens' preferences and aggregate them together to determine what social policies society should adopt. Therefore, proponents of this view hold that democratic participation should primarily focus on voting, where the policy with the most votes gets implemented.

Different variants of aggregative democracy exist. Under "minimalism", democracy is a system of government in which citizens have given teams of political leaders the right to rule in periodic elections. According to this minimalist conception, citizens cannot and should not "rule" because, for example, on most issues, most of the time, they have no clear views or their views are not well-founded. Joseph Schumpeter articulated this view most famously in his book "Capitalism, Socialism, and Democracy". Contemporary proponents of minimalism include William H. Riker, Adam Przeworski, Richard Posner.

According to the theory of direct democracy, on the other hand, citizens should vote directly, not through their representatives, on legislative proposals. Proponents of direct democracy offer varied reasons to support this view. Political activity can be valuable in itself, it socialises and educates citizens, and popular participation can check powerful elites. Most importantly, citizens do not rule themselves unless they directly decide laws and policies.

Governments will tend to produce laws and policies that are close to the views of the median voter—with half to their left and the other half to their right. This is not a desirable outcome as it represents the action of self-interested and somewhat unaccountable political elites competing for votes. Anthony Downs suggests that ideological political parties are necessary to act as a mediating broker between individual and governments. Downs laid out this view in his 1957 book "An Economic Theory of Democracy".

Robert A. Dahl argues that the fundamental democratic principle is that, when it comes to binding collective decisions, each person in a political community is entitled to have his/her interests be given equal consideration (not necessarily that all people are equally satisfied by the collective decision). He uses the term polyarchy to refer to societies in which there exists a certain set of institutions and procedures which are perceived as leading to such democracy. First and foremost among these institutions is the regular occurrence of free and open elections which are used to select representatives who then manage all or most of the public policy of the society. However, these polyarchic procedures may not create a full democracy if, for example, poverty prevents political participation. Similarly, Ronald Dworkin argues that "democracy is a substantive, not a merely procedural, ideal."

"Deliberative democracy" is based on the notion that democracy is government by deliberation. Unlike aggregative democracy, deliberative democracy holds that, for a democratic decision to be legitimate, it must be preceded by authentic deliberation, not merely the aggregation of preferences that occurs in voting. "Authentic deliberation" is deliberation among decision-makers that is free from distortions of unequal political power, such as power a decision-maker obtained through economic wealth or the support of interest groups. If the decision-makers cannot reach consensus after authentically deliberating on a proposal, then they vote on the proposal using a form of majority rule. Citizens assemblies are considered by many scholars as practical examples of deliberative democracy, with a recent OECD report identifying citizens assemblies as an increasingly popular mechanism to involve citizens in governmental decision-making.

"Radical democracy" is based on the idea that there are hierarchical and oppressive power relations that exist in society. Democracy's role is to make visible and challenge those relations by allowing for difference, dissent and antagonisms in decision-making processes.

Democracy has taken a number of forms, both in theory and practice. Some varieties of democracy provide better representation and more freedom for their citizens than others. However, if any democracy is not structured to prohibit the government from excluding the people from the legislative process, or any branch of government from altering the separation of powers in its favour, then a branch of the system can accumulate too much power and destroy the democracy.

The following kinds of democracy are not exclusive of one another: many specify details of aspects that are independent of one another and can co-exist in a single system.

Several variants of democracy exist, but there are two basic forms, both of which concern how the whole body of all eligible citizens executes its will. One form of democracy is direct democracy, in which all eligible citizens have active participation in the political decision making, for example voting on policy initiatives directly. In most modern democracies, the whole body of eligible citizens remain the sovereign power but political power is exercised indirectly through elected representatives; this is called a representative democracy.

Direct democracy is a political system where the citizens participate in the decision-making personally, contrary to relying on intermediaries or representatives. A direct democracy gives the voting population the power to:

Within modern-day representative governments, certain electoral tools like referendums, citizens' initiatives and recall elections are referred to as forms of direct democracy. However, some advocates of direct democracy argue for local assemblies of face-to-face discussion. Direct democracy as a government system currently exists in the Swiss cantons of Appenzell Innerrhoden and Glarus, the Rebel Zapatista Autonomous Municipalities, communities affiliated with the CIPO-RFM, the Bolivian city councils of FEJUVE, and Kurdish cantons of Rojava.

Some modern democracies that are predominantly representative in nature also heavily rely upon forms of political action that are directly democratic. These democracies, which combine elements of representative democracy and direct democracy, are termed "semi-direct democracies" or "participatory democracies". Examples include Switzerland and some U.S. states, where frequent use is made of referendums and initiatives.

The Swiss confederation is a semi-direct democracy. At the federal level, citizens can propose changes to the constitution (federal popular initiative) or ask for a referendum to be held on any law voted by the parliament. Between January 1995 and June 2005, Swiss citizens voted 31 times, to answer 103 questions (during the same period, French citizens participated in only two referendums). Although in the past 120 years less than 250 initiatives have been put to referendum.

Examples include the extensive use of referendums in the US state of California, which is a state that has more than 20 million voters.

In New England, town meetings are often used, especially in rural areas, to manage local government. This creates a hybrid form of government, with a local direct democracy and a representative state government. For example, most Vermont towns hold annual town meetings in March in which town officers are elected, budgets for the town and schools are voted on, and citizens have the opportunity to speak and be heard on political matters.

The use of a lot system, a characteristic of Athenian democracy, is a feature of some versions of direct democracies. In this system, important governmental and administrative tasks are performed by citizens picked from a lottery.

Representative democracy involves the election of government officials by the people being represented. If the head of state is also democratically elected then it is called a democratic republic. The most common mechanisms involve election of the candidate with a majority or a plurality of the votes. Most western countries have representative systems.

Representatives may be elected or become diplomatic representatives by a particular district (or constituency), or represent the entire electorate through proportional systems, with some using a combination of the two. Some representative democracies also incorporate elements of direct democracy, such as referendums. A characteristic of representative democracy is that while the representatives are elected by the people to act in the people's interest, they retain the freedom to exercise their own judgement as how best to do so. Such reasons have driven criticism upon representative democracy, pointing out the contradictions of representation mechanisms with democracy

Parliamentary democracy is a representative democracy where government is appointed by or can be dismissed by, representatives as opposed to a "presidential rule" wherein the president is both head of state and the head of government and is elected by the voters. Under a parliamentary democracy, government is exercised by delegation to an executive ministry and subject to ongoing review, checks and balances by the legislative parliament elected by the people.

In a parliamentary system, the Prime Minister may be dismissed by the legislature at any point in time for not meeting the expectations of the legislature. This is done through a Vote of No Confidence where the legislature decides whether or not to remove the Prime Minister from office with majority support for dismissal. In some countries, the Prime Minister can also call an election at any point in time, typically when the Prime Minister believes that they are in good favour with the public as to get re-elected. In other parliamentary democracies, extra elections are virtually never held, a minority government being preferred until the next ordinary elections. An important feature of the parliamentary democracy is the concept of the "loyal opposition". The essence of the concept is that the second largest political party (or opposition) opposes the governing party (or coalition), while still remaining loyal to the state and its democratic principles.

Presidential Democracy is a system where the public elects the president through an election. The president serves as both the head of state and head of government controlling most of the executive powers. The president serves for a specific term and cannot exceed that amount of time. The legislature often has limited ability to remove a president from office. Elections typically have a fixed date and aren't easily changed. The president has direct control over the cabinet, specifically appointing the cabinet members.

The executive usually has the responsibility to execute or implement legislation and may have the limited legislative powers, such as a veto. However, a legislative branch passes legislation and budgets. This provides some measure of separation of powers. In consequence, however, the president and the legislature may end up in the control of separate parties, allowing one to block the other and thereby interfere with the orderly operation of the state. This may be the reason why presidential democracy is not very common outside the Americas, Africa, and Central and Southeast Asia.

A semi-presidential system is a system of democracy in which the government includes both a prime minister and a president. The particular powers held by the prime minister and president vary by country.

Many countries such as the United Kingdom, Spain, the Netherlands, Belgium, Scandinavian countries, Thailand, Japan and Bhutan turned powerful monarchs into constitutional monarchs (often gradually) with limited or symbolic roles. For example, in the predecessor states to the United Kingdom, constitutional monarchy began to emerge and has continued uninterrupted since the Glorious Revolution of 1688 and passage of the Bill of Rights 1689. Strongly limited constitutional monarchies, such as the United Kingdom, have been referred to as crowned republics by writers such as H. G. Wells.

In other countries, the monarchy was abolished along with the aristocratic system (as in France, China, Russia, Germany, Austria, Hungary, Italy, Greece and Egypt). An elected person, with or without significant powers, became the head of state in these countries.

Elite upper houses of legislatures, which often had lifetime or hereditary tenure, were common in many states. Over time, these either had their powers limited (as with the British House of Lords) or else became elective and remained powerful (as with the Australian Senate).

The term "republic" has many different meanings, but today often refers to a representative democracy with an elected head of state, such as a president, serving for a limited term, in contrast to states with a hereditary monarch as a head of state, even if these states also are representative democracies with an elected or appointed head of government such as a prime minister.

The Founding Fathers of the United States often criticised direct democracy, which in their view often came without the protection of a constitution enshrining inalienable rights; James Madison argued, especially in "The Federalist" No. 10, that what distinguished a direct "democracy" from a "republic" was that the former became weaker as it got larger and suffered more violently from the effects of faction, whereas a republic could get stronger as it got larger and combats faction by its very structure.

Professors Richard Ellis of Willamette University and Michael Nelson of Rhodes College argue that much constitutional thought, from Madison to Lincoln and beyond, has focused on "the problem of majority tyranny". They conclude, "The principles of republican government embedded in the Constitution represent an effort by the framers to ensure that the inalienable rights of life, liberty, and the pursuit of happiness would not be trampled by majorities." What was critical to American values, John Adams insisted, was that the government be "bound by fixed laws, which the people have a voice in making, and a right to defend." As Benjamin Franklin was exiting after writing the U.S. constitution, Elizabeth Willing Powel asked him "Well, Doctor, what have we got—a republic or a monarchy?". He replied "A republic—if you can keep it."

A liberal democracy is a representative democracy in which the ability of the elected representatives to exercise decision-making power is subject to the rule of law, and moderated by a constitution or laws that emphasise the protection of the rights and freedoms of individuals, and which places constraints on the leaders and on the extent to which the will of the majority can be exercised against the rights of minorities (see civil liberties).

In a liberal democracy, it is possible for some large-scale decisions to emerge from the many individual decisions that citizens are free to make. In other words, citizens can "vote with their feet" or "vote with their dollars", resulting in significant informal government-by-the-masses that exercises many "powers" associated with formal government elsewhere.

Socialist thought has several different views on democracy. Social democracy, democratic socialism, and the dictatorship of the proletariat are some examples. Many democratic socialists and social democrats believe in a form of participatory, industrial, economic and/or workplace democracy combined with a representative democracy.

Within Marxist orthodoxy there is a hostility to what is commonly called "liberal democracy", which is referred to as parliamentary democracy because of its centralised nature. Because of orthodox Marxists' desire to eliminate the political elitism they see in capitalism, Marxists, Leninists and Trotskyists believe in direct democracy implemented through a system of communes (which are sometimes called soviets). This system can begin with workplace democracy and ultimately manifests itself as council democracy.

Anarchists are split in this domain, depending on whether they believe that a majority-rule is tyrannic or not. To many anarchists, the only form of democracy considered acceptable is direct democracy. Pierre-Joseph Proudhon argued that the only acceptable form of direct democracy is one in which it is recognised that majority decisions are not binding on the minority, even when unanimous. However, anarcho-communist Murray Bookchin criticised individualist anarchists for opposing democracy, and says "majority rule" is consistent with anarchism.

Some anarcho-communists oppose the majoritarian nature of direct democracy, feeling that it can impede individual liberty and opt-in favour of a non-majoritarian form of consensus democracy, similar to Proudhon's position on direct democracy.

Sortition is the process of choosing decision-making bodies via a random selection. These bodies can be more representative of the opinions and interests of the people at large than an elected legislature or other decision-maker. The technique was in widespread use in Athenian Democracy and Renaissance Florence and is still used in modern jury selection and citizens' assemblies.

Consociational democracy, also called consociationalism, is a form of democracy based on power-sharing formula between elites representing the social groups within the society. In 1969, Arendt Lijphart argued this would stabilize democracies with factions. A consociational democracy allows for simultaneous majority votes in two or more ethno-religious constituencies, and policies are enacted only if they gain majority support from both or all of them. The Qualified majority voting rule in European Council of Ministers is a consociational democracy approach for supranational democracies. This system in Treaty of Rome allocates votes to member states in part according to their population, but heavily weighted in favour of the smaller states. A consociational democracy requires consensus of representatives, while consensus democracy requires consensus of electorate.

Consensus democracy requires consensus decision-making and supermajority to obtain a larger support than majority. In contrast, in majoritarian democracy minority opinions can potentially be ignored by vote-winning majorities. Constitutions typically require consensus or supermajorities.

Inclusive democracy is a political theory and political project that aims for direct democracy in all fields of social life: political democracy in the form of face-to-face assemblies which are confederated, economic democracy in a stateless, moneyless and marketless economy, democracy in the social realm, i.e. self-management in places of work and education, and ecological democracy which aims to reintegrate society and nature. The theoretical project of inclusive democracy emerged from the work of political philosopher Takis Fotopoulos in "Towards An Inclusive Democracy" and was further developed in the journal "Democracy & Nature" and its successor "The International Journal of Inclusive Democracy".

A Parpolity or Participatory Polity is a theoretical form of democracy that is ruled by a Nested Council structure. The guiding philosophy is that people should have decision-making power in proportion to how much they are affected by the decision. Local councils of 25–50 people are completely autonomous on issues that affect only them, and these councils send delegates to higher level councils who are again autonomous regarding issues that affect only the population affected by that council.

A council court of randomly chosen citizens serves as a check on the tyranny of the majority, and rules on which body gets to vote on which issue. Delegates may vote differently from how their sending council might wish but are mandated to communicate the wishes of their sending council. Delegates are recallable at any time. Referendums are possible at any time via votes of lower-level councils, however, not everything is a referendum as this is most likely a waste of time. A parpolity is meant to work in tandem with a participatory economy.

Cosmopolitan democracy, also known as "Global democracy" or "World Federalism", is a political system in which democracy is implemented on a global scale, either directly or through representatives. An important justification for this kind of system is that the decisions made in national or regional democracies often affect people outside the constituency who, by definition, cannot vote. By contrast, in a cosmopolitan democracy, the people who are affected by decisions also have a say in them.

According to its supporters, any attempt to solve global problems is undemocratic without some form of cosmopolitan democracy. The general principle of cosmopolitan democracy is to expand some or all of the values and norms of democracy, including the rule of law; the non-violent resolution of conflicts; and equality among citizens, beyond the limits of the state. To be fully implemented, this would require reforming existing international organisations, e.g., the United Nations, as well as the creation of new institutions such as a World Parliament, which ideally would enhance public control over, and accountability in, international politics.

Cosmopolitan Democracy has been promoted, among others, by physicist Albert Einstein, writer Kurt Vonnegut, columnist George Monbiot, and professors David Held and Daniele Archibugi. The creation of the International Criminal Court in 2003 was seen as a major step forward by many supporters of this type of cosmopolitan democracy.

Creative Democracy is advocated by American philosopher John Dewey. The main idea about Creative Democracy is that democracy encourages individual capacity building and the interaction among the society. Dewey argues that democracy is a way of life in his work of "Creative Democracy: The Task Before Us" and an experience built on faith in human nature, faith in human beings, and faith in working with others. Democracy, in Dewey's view, is a moral ideal requiring actual effort and work by people; it is not an institutional concept that exists outside of ourselves. "The task of democracy", Dewey concludes, "is forever that of creation of a freer and more humane experience in which all share and to which all contribute".

Guided democracy is a form of democracy that incorporates regular popular elections, but which often carefully "guides" the choices offered to the electorate in a manner that may reduce the ability of the electorate to truly determine the type of government exercised over them. Such democracies typically have only one central authority which is often not subject to meaningful public review by any other governmental authority. Russian-style democracy has often been referred to as a "Guided democracy". Russian politicians have referred to their government as having only one center of power/ authority, as opposed to most other forms of democracy which usually attempt to incorporate two or more naturally competing sources of authority within the same government.

Aside from the public sphere, similar democratic principles and mechanisms of voting and representation have been used to govern other kinds of groups. Many non-governmental organisations decide policy and leadership by voting. Most trade unions and cooperatives are governed by democratic elections. Corporations are ultimately governed by their shareholders through shareholder democracy. Corporations may also employ systems such as workplace democracy to handle internal governance. Amitai Etzioni has postulated a system that fuses elements of democracy with sharia law, termed "Islamocracy". There is also a growing number of Democratic educational institutions such as Sudbury schools that are co-governed by students and staff.

Shareholder democracy is a concept relating to the governance of corporations by their shareholders. In the United States, shareholders are typically granted voting rights according to the one share, one vote principle. Shareholders may vote annually to elect the company's board of directors, who themselves may choose the company's executives. The shareholder democracy framework may be inaccurate for companies which have different classes of stock that further alter the distribution of voting rights.

Several justifications for democracy have been postulated.

Social contract theory argues that the legitimacy of government is based on consent of the governed, i.e. an election, and that political decisions must reflect the general will. Some proponents of the theory like Jean-Jacques Rousseau advocate for a direct democracy on this basis.

Condorcet's jury theorem is logical proof that if each decision-maker has a better than chance probability of making the right decision, then having the largest number of decision-makers, i.e. a democracy, will result in the best decisions. This has also been argued by theories of the wisdom of the crowd.

In "Why Nations Fail", economists Daron Acemoglu and James A. Robinson argue that democracies are more economically successful because undemocratic political systems tend to limit markets and favor monopolies at the expense of the creative destruction which is necessary for sustained economic growth.

A 2019 study by Acemoglu and others estimated that countries switching to democratic from authoritarian rule had on average a 20% higher GDP after 25 years than if they had remained authoritarian. The study examined 122 transitions to democracy and 71 transitions to authoritarian rule, occurring from 1960 to 2010. Acemoglu said this was because democracies tended to invest more in health care and human capital, and reduce special treatment of regime allies.

Democracy promotion can increase the quality of already existing democracies, reduce political apathy, and the chance of democratic backsliding. Democracy promotion measures include voting advice applications, participatory democracy, increasing youth suffrage, increasing civic education, reducing barriers to entry for new political parties, increasing proportionality and reducing presidentialism.

A democratic transition describes a phase in a countries political system, often created as a result of an incomplete change from an authoritarian regime to a democratic one (or vice versa).

Several philosophers and researchers have outlined historical and social factors seen as supporting the evolution of democracy.
Other commentators have mentioned the influence of economic development. In a related theory, Ronald Inglehart suggests that improved living-standards in modern developed countries can convince people that they can take their basic survival for granted, leading to increased emphasis on self-expression values, which correlates closely with democracy.

Douglas M. Gibler and Andrew Owsiak in their study argued about the importance of peace and stable borders for the development of democracy. It has often been assumed that democracy causes peace, but this study shows that, historically, peace has almost always predated the establishment of democracy.

Carroll Quigley concludes that the characteristics of weapons are the main predictor of democracy: Democracy—this scenario—tends to emerge only when the best weapons available are easy for individuals to obtain and use. By the 1800s, guns were the best personal weapons available, and in the United States of America (already nominally democratic), almost everyone could afford to buy a gun, and could learn how to use it fairly easily. Governments could not do any better: it became the age of mass armies of citizen soldiers with guns. Similarly, Periclean Greece was an age of the citizen soldier and democracy.

Other theories stressed the relevance of education and of human capital—and within them of cognitive ability to increasing tolerance, rationality, political literacy and participation. Two effects of education and cognitive ability are distinguished:

Evidence consistent with conventional theories of why democracy emerges and is sustained has been hard to come by. Statistical analyses have challenged modernisation theory by demonstrating that there is no reliable evidence for the claim that democracy is more likely to emerge when countries become wealthier, more educated, or less unequal. In fact, empirical evidence shows that economic growth and education may not lead to increased demand for democratization as modernization theory suggests: historically, most countries attained high levels of access to primary education well before transitioning to democracy. Rather than acting as a catalyst for democratization, in some situations education provision may instead be used by non-democratic regimes to indoctrinate their subjects and strengthen their power.

The assumed link between education and economic growth is called into question when analyzing empirical evidence. Across different countries, the correlation between education attainment and math test scores is very weak (.07). A similarly weak relationship exists between per-pupil expenditures and math competency (.26). Additionally, historical evidence suggests that average human capital (measured using literacy rates) of the masses does not explain the onset of industrialization in France from 1750 to 1850 despite arguments to the contrary. Together, these findings show that education does not always promote human capital and economic growth as is generally argued to be the case. Instead, the evidence implies that education provision often falls short of its expressed goals, or, alternatively, that political actors use education to promote goals other than economic growth and development.

Some scholars have searched for the "deep" determinants of contemporary political institutions, be they geographical or demographic.

An example of this is the disease environment. Places with different mortality rates had different populations and productivity levels around the world. For example, in Africa, the tsetse fly—which afflicts humans and livestock—reduced the ability of Africans to plough the land. This made Africa less settled. As a consequence, political power was less concentrated. This also affected the colonial institutions European countries established in Africa. Whether colonial settlers could live or not in a place made them develop different institutions which led to different economic and social paths. This also affected the distribution of power and the collective actions people could take. As a result, some African countries ended up having democracies and others autocracies.

An example of geographical determinants for democracy is having access to coastal areas and rivers. This natural endowment has a positive relation with economic development thanks to the benefits of trade. Trade brought economic development, which in turn, broadened power. Rulers wanting to increase revenues had to protect property-rights to create incentives for people to invest. As more people had more power, more concessions had to be made by the ruler and in many places this process lead to democracy. These determinants defined the structure of the society moving the balance of political power.

Robert Michels asserts that although democracy can never be fully realised, democracy may be developed automatically in the act of striving for democracy:

The peasant in the fable, when on his deathbed, tells his sons that a treasure is buried in the field. After the old man's death the sons dig everywhere in order to discover the treasure. They do not find it. But their indefatigable labor improves the soil and secures for them a comparative well-being. The treasure in the fable may well symbolise democracy.

Democracy in modern times has almost always faced opposition from the previously existing government, and many times it has faced opposition from social elites. The implementation of a democratic government from a non-democratic state is typically brought by peaceful or violent democratic revolution.

Some democratic governments have experienced sudden state collapse and regime change to an undemocratic form of government. Domestic military coups or rebellions are the most common means by which democratic governments have been overthrown. (See List of coups and coup attempts by country and List of civil wars.) Examples include the Spanish Civil War, the Coup of 18 Brumaire that ended the First French Republic, and the 28 May 1926 coup d'état which ended the First Portuguese Republic. Some military coups are supported by foreign governments, such as the 1954 Guatemalan coup d'état and the 1953 Iranian coup d'état. Other types of a sudden end to democracy include:

Democratic backsliding can end democracy in a gradual manner, by increasing emphasis on national security and eroding free and fair elections, freedom of expression, independence of the judiciary, rule of law. A famous example is the Enabling Act of 1933, which lawfully ended democracy in Weimar Germany and marked the transition to Nazi Germany.

Temporary or long-term political violence and government interference can prevent free and fair elections, which erode the democratic nature of governments. This has happened on a local level even in well-established democracies like the United States; for example, the Wilmington insurrection of 1898 and African-American disfranchisement after the Reconstruction era.

The theory of democracy relies on the implicit assumption that voters are well informed about social issues, policies, and candidates so that they can make a truly informed decision. Since the late 20'th century there has been a growing concern that voters may be poorly informed because the news media are focusing more on entertainment and gossip and less on serious journalistic research on political issues.

The media professors Michael Gurevitch and Jay Blumler have proposed a number of functions that the mass media are expected to fulfill in a democracy:

This proposal has inspired a lot of discussions over whether the news media are actually fulfilling the requirements that a well functioning democracy requires.
Commercial mass media are generally not accountable to anybody but their owners, and they have no obligation to serve a democratic function.
They are controlled mainly by economic market forces. Fierce economic competition may force the mass media to divert themselves from any democratic ideals and focus entirely on how to survive the competition.

The tabloidization and popularization of the news media is seen in an increasing focus on human examples rather than statistics and principles. There is more focus on politicians as personalities and less focus on political issues in the popular media. Election campaigns are covered more as horse races and less as debates about ideologies and issues. The dominating media focus on spin, conflict, and competitive strategies has made voters perceive the politicians as egoists rather than idealists. This fosters mistrust and a cynical attitude to politics, less civic engagement, and less interest in voting.
The ability to find effective political solutions to social problems is hampered when problems tend to be blamed on individuals rather than on structural causes.
This person-centered focus may have far-reaching consequences not only for domestic problems but also for foreign policy when international conflicts are blamed on foreign heads of state rather than on political and economic structures.
A strong media focus on fear and terrorism has allowed military logic to penetrate public institutions, leading to increased surveillance and the erosion of civil rights.

The responsiveness and accountability of the democratic system is compromised when lack of access to substantive, diverse, and undistorted information is handicapping the citizens' capability of evaluating the political process.
The fast pace and trivialization in the competitive news media is dumbing down the political debate. Thorough and balanced investigation of complex political issues does not fit into this format. The political communication is characterized by short time horizons, short slogans, simple explanations, and simple solutions. This is conducive to political populism rather than serious deliberation.

Commercial mass media are often differentiated along the political spectrum so that people can hear mainly opinions that they already agree with. Too much controversy and diverse opinions are not always profitable for the commercial news media.
Political polarization is emerging when different people read different news and watch different TV channels. This polarization has been worsened by the emergence of the social media that allow people to communicate mainly with groups of like-minded people, the so-called echo chambers.
Extreme political polarization may undermine the trust in democratic institutions, leading to erosion of civil rights and free speech and in some cases even reversion to autocracy.

Many media scholars have discussed non-commercial news media with public service obligations as a means to improve the democratic process by providing the kind of political contents that a free market does not provide.
The World Bank has recommended public service broadcasting in order to strengthen democracy in developing countries. These broadcasting services should be accountable to an independent regulatory body that is adequately protected from interference from political and economic interests.
Public service media have an obligation to provide reliable information to voters. Many countries have publicly funded radio and television stations with public service obligations, especially in Europe and Japan, while such media are weak or non-existent in other countries including the US.
Several studies have shown that the stronger the dominance of commercial broadcast media over public service media, the less the amount of policy-relevant information in the media and the more focus on horse race journalism, personalities, and the pecadillos of politicians. Public service broadcasters are characterized by more policy-relevant information and more respect for journalistic norms and impartiality than the commercial media. However, the trend of deregulation has put the public service model under increased pressure from competition with commercial media.

The emergence of the internet and the social media has profoundly altered the conditions for political communication. The social media have given ordinary citizens easy access to voice their opinion and share information while bypassing the filters of the large news media. This is often seen as an advantage for democracy.
The new possibilities for communication have fundamentally changed the way social movements and protest movements operate and organize. The internet and social media have provided powerful new tools for democracy movements in developing countries and emerging democracies, enabling them to bypass censorship, voice their opinions, and organize protests.

A serious problem with the social media is that they have no truth filters. The established news media have to guard their reputation as trustworthy, while ordinary citizens may post unreliable information. In fact, studies show that false stories are going more viral than true stories.
The proliferation of false stories and conspiracy theories may undermine public trust in the political system and public officials.

Reliable information sources are essential for the democratic process. Less democratic governments rely heavily on censorship, propaganda, and misinformation in order to stay in power, while independent sources of information are able to undermine their legitimacy.



Deduction and induction

Deduction and induction may refer to:

Logical disjunction

In logic, disjunction, also known as logical disjunction or logical or or logical addition or inclusive disjunction , is a logical connective typically notated as formula_1 and read aloud as "or". For instance, the English language sentence "it is sunny or it is warm" can be represented in logic using the disjunctive formula formula_2, assuming that formula_3 abbreviates "it is sunny" and formula_4 abbreviates "it is warm".

In classical logic, disjunction is given a truth functional semantics according to which a formula formula_5 is true unless both formula_6 and formula_7 are false. Because this semantics allows a disjunctive formula to be true when both of its disjuncts are true, it is an "inclusive" interpretation of disjunction, in contrast with exclusive disjunction. Classical proof theoretical treatments are often given in terms of rules such as disjunction introduction and disjunction elimination. Disjunction has also been given numerous non-classical treatments, motivated by problems including Aristotle's sea battle argument, Heisenberg's uncertainty principle, as well as the numerous mismatches between classical disjunction and its nearest equivalents in natural languages.

Because the logical "or" means a disjunction formula is true when either one or both of its parts are true, it is referred to as an "inclusive" disjunction. This is in contrast with an exclusive disjunction, which is true when one or the other of the arguments are true, but not both (referred to as ""exclusive or"", or "XOR").

When it is necessary to clarify whether inclusive or exclusive "or" is intended, English speakers sometimes uses the phrase "and/or". In terms of logic, this phrase is identical to "or", but makes the inclusion of both being true explicit.

In logic and related fields, disjunction is customarily notated with an infix operator formula_8 (Unicode ). Alternative notations include formula_9, used mainly in electronics, as well as formula_10 and formula_11 in many programming languages. The English word "or" is sometimes used as well, often in capital letters. In Jan Łukasiewicz's prefix notation for logic, the operator is formula_12, short for Polish "alternatywa" (English: alternative).

In the semantics of logic, classical disjunction is a truth functional operation which returns the truth value "true" unless both of its arguments are "false". Its semantic entry is standardly given as follows:

This semantics corresponds to the following truth table:

In classical logic systems where logical disjunction is not a primitive, it can be defined in terms of the primitive "and" (formula_16) and "not" (formula_17) as:

Alternatively, it may be defined in terms of "implies" (formula_19) and "not" as:
The latter can be checked by the following truth table:

It may also be defined solely in terms of formula_19:
It can be checked by the following truth table:

The following properties apply to disjunction:




Operators corresponding to logical disjunction exist in most programming languages.

Disjunction is often used for bitwise operations. Examples:

The codice_1 operator can be used to set bits in a bit field to 1, by codice_1-ing the field with a constant field with the relevant bits set to 1. For example, codice_3 will force the final bit to 1, while leaving other bits unchanged.

Many languages distinguish between bitwise and logical disjunction by providing two distinct operators; in languages following C, bitwise disjunction is performed with the single pipe operator (codice_4), and logical disjunction with the double pipe (codice_5) operator.

Logical disjunction is usually short-circuited; that is, if the first (left) operand evaluates to codice_6, then the second (right) operand is not evaluated. The logical disjunction operator thus usually constitutes a sequence point.

In a parallel (concurrent) language, it is possible to short-circuit both sides: they are evaluated in parallel, and if one terminates with value true, the other is interrupted. This operator is thus called the "parallel or".

Although the type of a logical disjunction expression is boolean in most languages (and thus can only have the value codice_6 or codice_8), in some languages (such as Python and JavaScript), the logical disjunction operator returns one of its operands: the first operand if it evaluates to a true value, and the second operand otherwise.

The Curry–Howard correspondence relates a constructivist form of disjunction to tagged union types.

The membership of an element of a union set in set theory is defined in terms of a logical disjunction: formula_32. Because of this, logical disjunction satisfies many of the same identities as set-theoretic union, such as associativity, commutativity, distributivity, and de Morgan's laws, identifying logical conjunction with set intersection, logical negation with set complement.

Disjunction in natural languages does not precisely match the interpretation of formula_8 in classical logic. Notably, classical disjunction is inclusive while natural language disjunction is often understood exclusively, as the following English typically would be.

This inference has sometimes been understood as an entailment, for instance by Alfred Tarski, who suggested that natural language disjunction is ambiguous between a classical and a nonclassical interpretation. More recent work in pragmatics has shown that this inference can be derived as a conversational implicature on the basis of a semantic denotation which behaves classically. However, disjunctive constructions including Hungarian "vagy... vagy" and French "soit... soit" have been argued to be inherently exclusive, rendering ungrammaticality in contexts where an inclusive reading would otherwise be forced.

Similar deviations from classical logic have been noted in cases such as free choice disjunction and simplification of disjunctive antecedents, where certain modal operators trigger a conjunction-like interpretation of disjunction. As with exclusivity, these inferences have been analyzed both as implicatures and as entailments arising from a nonclassical interpretation of disjunction.

In many languages, disjunctive expressions play a role in question formation. For instance, while the following English example can be interpreted as a polar question asking whether it's true that Mary is either a philosopher or a linguist, it can also be interpreted as an alternative question asking which of the two professions is hers. The role of disjunction in these cases has been analyzed using nonclassical logics such as alternative semantics and inquisitive semantics, which have also been adopted to explain the free choice and simplification inferences.

In English, as in many other languages, disjunction is expressed by a coordinating conjunction. Other languages express disjunctive meanings in a variety of ways, though it is unknown whether disjunction itself is a linguistic universal. In many languages such as Dyirbal and Maricopa, disjunction is marked using a verb suffix. For instance, in the Maricopa example below, disjunction is marked by the suffix "šaa".



Disjunctive syllogism

In classical logic, disjunctive syllogism (historically known as modus tollendo ponens (MTP), Latin for "mode that affirms by denying") is a valid argument form which is a syllogism having a disjunctive statement for one of its premises.

An example in English:

In propositional logic, disjunctive syllogism (also known as disjunction elimination and or elimination, or abbreviated ∨E), is a valid rule of inference. If it is known that at least one of two statements is true, and that it is not the former that is true; we can infer that it has to be the latter that is true. Equivalently, if "P" is true or "Q" is true and "P" is false, then "Q" is true. The name "disjunctive syllogism" derives from its being a syllogism, a three-step argument, and the use of a logical disjunction (any "or" statement.) For example, "P or Q" is a disjunction, where P and Q are called the statement's "disjuncts". The rule makes it possible to eliminate a disjunction from a logical proof. It is the rule that

where the rule is that whenever instances of "formula_2", and "formula_3" appear on lines of a proof, "formula_4" can be placed on a subsequent line.

Disjunctive syllogism is closely related and similar to hypothetical syllogism, which is another rule of inference involving a syllogism. It is also related to the law of noncontradiction, one of the .

For a logical system that validates it, the "disjunctive syllogism" may be written in sequent notation as

where formula_6 is a metalogical symbol meaning that formula_4 is a syntactic consequence of formula_2, and formula_9.

It may be expressed as a truth-functional tautology or theorem in the object language of propositional logic as

where formula_11, and formula_4 are propositions expressed in some formal system.

Here is an example:

Here is another example:

It may be observed that the disjunctive syllogism works whether 'or' is considered 'exclusive' or 'inclusive' disjunction. See below for the definitions of these terms.

There are two kinds of logical disjunction:


The concept of "or" as it exists in the English language is often ambiguous between these two meanings, but the difference is pivotal in evaluating disjunctive arguments.

The argument

is valid and indifferent between both meanings. However, only in the "exclusive" meaning is the following form valid:


With the "inclusive" meaning, one could draw no conclusion from the first two premises of that argument. See affirming a disjunct.

Unlike "modus ponens" and "modus ponendo tollens", with which it should not be confused, disjunctive syllogism is often not made an explicit rule or axiom of logical systems, as the above arguments can be proven with a combination of reductio ad absurdum and disjunction elimination.

Other forms of syllogism include:

Disjunctive syllogism holds in classical propositional logic and intuitionistic logic, but not in some paraconsistent logics.


Definition

A definition is a statement of the meaning of a term (a word, phrase, or other set of symbols). Definitions can be classified into two large categories: intensional definitions (which try to give the sense of a term), and extensional definitions (which try to list the objects that a term describes). Another important category of definitions is the class of ostensive definitions, which convey the meaning of a term by pointing out examples. A term may have many different senses and multiple meanings, and thus require multiple definitions.

In mathematics, a definition is used to give a precise meaning to a new term, by describing a condition which unambiguously qualifies what a mathematical term is and is not. Definitions and axioms form the basis on which all of modern mathematics is to be constructed. In computing, definitions can be used as logic programs 

In modern usage, a definition is something, typically expressed in words, that attaches a meaning to a word or group of words. The word or group of words that is to be defined is called the "definiendum", and the word, group of words, or action that defines it is called the "definiens". For example, in the definition ""An elephant is a large gray animal native to Asia and Africa"", the word "elephant" is the "definiendum", and everything after the word "is" is the "definiens".

The "definiens" is not "the meaning" of the word defined, but is instead something that "conveys the same meaning" as that word.

There are many sub-types of definitions, often specific to a given field of knowledge or study. These include, "lexical definitions", or the common dictionary definitions of words already in a language; "demonstrative definitions", which define something by pointing to an example of it (""This," [said while pointing to a large grey animal], "is an Asian elephant.""); and "precising definitions", which reduce the vagueness of a word, typically in some special sense (""'Large', among female Asian elephants, is any individual weighing over 5,500 pounds."").

An "intensional definition", also called a "connotative" definition, specifies the necessary and sufficient conditions for a thing to be a member of a specific set. Any definition that attempts to set out the essence of something, such as that by genus and differentia, is an intensional definition.

An "extensional definition", also called a "denotative" definition, of a concept or term specifies its "extension". It is a list naming every object that is a member of a specific set.

Thus, the "seven deadly sins" can be defined "intensionally" as those singled out by Pope Gregory I as particularly destructive of the life of grace and charity within a person, thus creating the threat of eternal damnation. An "extensional" definition, on the other hand, would be the list of wrath, greed, sloth, pride, lust, envy, and gluttony. In contrast, while an intensional definition of "prime minister" might be "the most senior minister of a cabinet in the executive branch of parliamentary government", an extensional definition is not possible since it is not known who the future prime ministers will be (even though all prime ministers from the past and present can be listed).

A "genus–differentia definition" is a type of intensional definition that takes a large category (the "genus") and narrows it down to a smaller category by a distinguishing characteristic (i.e. the "differentia").

More formally, a genus–differentia definition consists of:

For example, consider the following genus–differentia definitions:

Those definitions can be expressed as a genus ("a plane figure") and two "differentiae" ("that has three straight bounding sides" and "that has four straight bounding sides", respectively).

It is also possible to have two different genus–differentia definitions that describe the same term, especially when the term describes the overlap of two large categories. For instance, both of these genus–differentia definitions of "square" are equally acceptable:

Thus, a "square" is a member of both genera (the plural of "genus"): the genus "rectangle" and the genus "rhombus".

One important form of the extensional definition is "ostensive definition". This gives the meaning of a term by pointing, in the case of an individual, to the thing itself, or in the case of a class, to examples of the right kind. For example, one can explain who "Alice" (an individual) is, by pointing her out to another; or what a "rabbit" (a class) is, by pointing at several and expecting another to understand. The process of ostensive definition itself was critically appraised by Ludwig Wittgenstein.

An "enumerative definition" of a concept or a term is an "extensional definition" that gives an explicit and exhaustive listing of all the objects that fall under the concept or term in question. Enumerative definitions are only possible for finite sets (and in fact only practical for relatively small sets).

"Divisio" and "partitio" are classical terms for definitions. A "partitio" is simply an intensional definition. A "divisio" is not an extensional definition, but an exhaustive list of subsets of a set, in the sense that every member of the "divided" set is a member of one of the subsets. An extreme form of "divisio" lists all sets whose only member is a member of the "divided" set. The difference between this and an extensional definition is that extensional definitions list "members", and not "subsets".

In classical thought, a definition was taken to be a statement of the essence of a thing. Aristotle had it that an object's essential attributes form its "essential nature", and that a definition of the object must include these essential attributes.

The idea that a definition should state the essence of a thing led to the distinction between "nominal" and "real" essence—a distinction originating with Aristotle. In the Posterior Analytics, he says that the meaning of a made-up name can be known (he gives the example "goat stag") without knowing what he calls the "essential nature" of the thing that the name would denote (if there were such a thing). This led medieval logicians to distinguish between what they called the "quid nominis", or the "whatness of the name", and the underlying nature common to all the things it names, which they called the "quid rei", or the "whatness of the thing". The name "hobbit", for example, is perfectly meaningful. It has a "quid nominis", but one could not know the real nature of hobbits, and so the "quid rei" of hobbits cannot be known. By contrast, the name "man" denotes real things (men) that have a certain "quid rei". The meaning of a name is distinct from the nature that a thing must have in order that the name apply to it.

This leads to a corresponding distinction between "nominal" and "real" definitions. A nominal definition is the definition explaining what a word means (i.e., which says what the "nominal essence" is), and is definition in the classical sense as given above. A real definition, by contrast, is one expressing the real nature or "quid rei" of the thing.

This preoccupation with essence dissipated in much of modern philosophy. Analytic philosophy, in particular, is critical of attempts to elucidate the essence of a thing. Russell described essence as "a hopelessly muddle-headed notion".

More recently Kripke's formalisation of possible world semantics in modal logic led to a new approach to essentialism. Insofar as the essential properties of a thing are "necessary" to it, they are those things that it possesses in all possible worlds. Kripke refers to names used in this way as rigid designators.

A definition may also be classified as an operational definition or theoretical definition.

A homonym is, in the strict sense, one of a group of words that share the same spelling and pronunciation but have different meanings. Thus homonyms are simultaneously homographs (words that share the same spelling, regardless of their pronunciation) "and" homophones (words that share the same pronunciation, regardless of their spelling). The state of being a homonym is called "homonymy". Examples of homonyms are the pair "stalk" (part of a plant) and "stalk" (follow/harass a person) and the pair "left" (past tense of leave) and "left" (opposite of right). A distinction is sometimes made between "true" homonyms, which are unrelated in origin, such as "skate" (glide on ice) and "skate" (the fish), and polysemous homonyms, or polysemes, which have a shared origin, such as "mouth" (of a river) and "mouth" (of an animal).

Polysemy is the capacity for a sign (such as a word, phrase, or symbol) to have multiple meanings (that is, multiple semes or sememes and thus multiple senses), usually related by contiguity of meaning within a semantic field. It is thus usually regarded as distinct from homonymy, in which the multiple meanings of a word may be unconnected or unrelated.

In mathematics, definitions are generally not used to describe existing terms, but to describe or characterize a concept. For naming the object of a definition mathematicians can use either a neologism (this was mainly the case in the past) or words or phrases of the common language (this is generally the case in modern mathematics). The precise meaning of a term given by a mathematical definition is often different from the English definition of the word used, which can lead to confusion, particularly when the meanings are close. For example a set is not exactly the same thing in mathematics and in common language. In some case, the word used can be misleading; for example, a real number has nothing more (or less) real than an imaginary number. Frequently, a definition uses a phrase built with common English words, which has no meaning outside mathematics, such as primitive group or irreducible variety.

In first-order logic definitions are usually introduced using extension by definition (so using a metalogic). On the other hand, lambda-calculi are a kind of logic where the definitions are included as the feature of the formal system itself.

Authors have used different terms to classify definitions used in formal languages like mathematics. Norman Swartz classifies a definition as "stipulative" if it is intended to guide a specific discussion. A stipulative definition might be considered a temporary, working definition, and can only be disproved by showing a logical contradiction. In contrast, a "descriptive" definition can be shown to be "right" or "wrong" with reference to general usage.

Swartz defines a "precising definition" as one that extends the descriptive dictionary definition (lexical definition) for a specific purpose by including additional criteria. A precising definition narrows the set of things that meet the definition.

C.L. Stevenson has identified "persuasive definition" as a form of stipulative definition which purports to state the "true" or "commonly accepted" meaning of a term, while in reality stipulating an altered use (perhaps as an argument for some specific belief). Stevenson has also noted that some definitions are "legal" or "coercive" – their object is to create or alter rights, duties, or crimes.

A recursive definition, sometimes also called an "inductive" definition, is one that defines a word in terms of itself, so to speak, albeit in a useful way. Normally this consists of three steps:

For instance, we could define a natural number as follows (after Peano): 

So "0" will have exactly one successor, which for convenience can be called "1". In turn, "1" will have exactly one successor, which could be called "2", and so on. The second condition in the definition itself refers to natural numbers, and hence involves self-reference. Although this sort of definition involves a form of circularity, it is not vicious, and the definition has been quite successful.

In the same way, we can define ancestor as follows:
Or simply: an ancestor is a parent or a parent of an ancestor.

Logic programs can be understood as sets of recursive (and non-recursive) definitions. For example, the following Prolog and Datalog program (and database) provides intensional definitions of the parent_child , grandparent_child and ancestor_descendant relations, as well as partial, extensional definitions of the mother_child and father_child relations. The definition of the ancestor_descendant relation is recursive:

mother_child(elizabeth, charles).
father_child(charles, william).
father_child(charles, harry).
parent_child(X, Y) :- 
parent_child(X, Y) :- 
grandparent_child(X, Y) :- 
ancestor_descendant(X, Y) :- 
ancestor_descendant(X, Y) :- 
Here codice_1 represents "if" and codice_2 represents "and".

In Prolog, definitions, which have the form conclusion :- conditions, are treated as goal-reduction procedures, using backward reasoning to reduce goals that unify with the conclusion to subgoals that correspond to the associated, instantiated conditions. In Datalog, the same definitions are typically used to reason forwards to derive instances of the conclusion from facts that unify with the conditions.

Definitions in Prolog have the expressive power of Turing machines. For example, here is a Prolog program that implements the Euclidean algorithm, using gcd(A, B, C) to "define" C as the greatest common divisor of A and B:
gcd(A, A, A).
gcd(A, B, C) :- A > B, gcd(A-B, B, C).
gcd(A, B, C) :- B > A, gcd(A, B-A, C).
Backward reasoning using SLD resolution turns the definition into the Euclidean algorithm:

To find the gcd C of two given numbers A and B:
If A = B, then C = A.
If A > B, then find the gcd of A-B and B, which is C.
If B > A, then find the gcd of A and B-A, which is C.
The standard definition of greatest common divisor can also be written and executed (inefficiently) in Prolog:
gcd(A, B, C) :- divides(C, A), divides(C, B),
See also Algorithm = Logic + Control.

In medical dictionaries, guidelines and other consensus statements and classifications, definitions should as far as possible be:

Certain rules have traditionally been given for definitions (in particular, genus-differentia definitions).

Given that a natural language such as English contains, at any given time, a finite number of words, any comprehensive list of definitions must either be circular or rely upon primitive notions. If every term of every "definiens" must itself be defined, "where at last should we stop?" A dictionary, for instance, insofar as it is a comprehensive list of lexical definitions, must resort to circularity.

Many philosophers have chosen instead to leave some terms undefined. The scholastic philosophers claimed that the highest genera (called the ten "generalissima") cannot be defined, since a higher genus cannot be assigned under which they may fall. Thus being, unity and similar concepts cannot be defined. Locke supposes in "An Essay Concerning Human Understanding" that the names of simple concepts do not admit of any definition. More recently Bertrand Russell sought to develop a formal language based on logical atoms. Other philosophers, notably Wittgenstein, rejected the need for any undefined simples. Wittgenstein pointed out in his "Philosophical Investigations" that what counts as a "simple" in one circumstance might not do so in another. He rejected the very idea that every explanation of the meaning of a term needed itself to be explained: "As though an explanation hung in the air unless supported by another one", claiming instead that explanation of a term is only needed to avoid misunderstanding.

Locke and Mill also argued that individuals cannot be defined. Names are learned by connecting an idea with a sound, so that speaker and hearer have the same idea when the same word is used. This is not possible when no one else is acquainted with the particular thing that has "fallen under our notice". Russell offered his theory of descriptions in part as a way of defining a proper name, the definition being given by a definite description that "picks out" exactly one individual. Saul Kripke pointed to difficulties with this approach, especially in relation to modality, in his book "Naming and Necessity".

There is a presumption in the classic example of a definition that the "definiens" can be stated. Wittgenstein argued that for some terms this is not the case. The examples he used include "game", "number" and "family". In such cases, he argued, there is no fixed boundary that can be used to provide a definition. Rather, the items are grouped together because of a family resemblance. For terms such as these it is not possible and indeed not necessary to state a definition; rather, one simply comes to understand the "use" of the term.



Disruption

Disruption, disruptive, or disrupted may refer to:






Disco

Disco is a genre of dance music and a subculture that emerged in the 1970s from the United States' urban nightlife scene. Its sound is typified by four-on-the-floor beats, syncopated basslines, string sections, brass and horns, electric piano, synthesizers, and electric rhythm guitars.

Disco started as a mixture of music from venues popular among African-Americans, Hispanic/Latino Americans, gay Americans, and Italian Americans in Philadelphia and New York City during the late 1960s to early 1970s. Disco can be seen as a reaction by the 1960s counterculture to both the dominance of rock music and the stigmatization of dance music at the time. Several dance styles were developed during the period of 70s disco's popularity in the United States, including "the Bump", "the Hustle", "the Watergate", and "the Busstop".

In the course of the 1970s, disco music was developed further, mainly by artists from the United States and Europe. Well-known artists included the Bee Gees, ABBA, Donna Summer, Gloria Gaynor, Giorgio Moroder, Baccara, Boney M., Earth Wind & Fire, Chaka Khan, Chic, KC and the Sunshine Band, Thelma Houston, Sister Sledge, Sylvester, The Trammps, Diana Ross, Kool & the Gang, and the Village People. While performers garnered public attention, record producers working behind the scenes played an important role in developing the genre. By the late 1970s, most major U.S. cities had thriving disco club scenes, and DJs would mix dance records at clubs such as Studio 54 in Manhattan, a venue popular among celebrities. Nightclub-goers often wore expensive, extravagant outfits, consisting predominantly of loose, flowing pants or dresses for ease of movement while dancing. There was also a thriving drug subculture in the disco scene, particularly for drugs that would enhance the experience of dancing to the loud music and the flashing lights, such as cocaine and quaaludes, the latter being so common in disco subculture that they were nicknamed "disco biscuits". Disco clubs were also associated with promiscuity as a reflection of the sexual revolution of this era in popular history. Films such as "Saturday Night Fever" (1977) and "Thank God It's Friday" (1978) contributed to disco's mainstream popularity.

Disco declined as a major trend in popular music in the United States following the infamous Disco Demolition Night on July 12, 1979, and it continued to sharply decline in popularity in the U.S. during the early 1980s; however, it remained popular in Italy and some European countries throughout the 1980s, and during this time also started becoming trendy in places elsewhere including India and the Middle East, where aspects of disco were blended with regional folk styles such as "ghazals" and belly dancing. Disco would eventually become a key influence in the development of electronic dance music, house music, hip hop, new wave, dance-punk, and post-disco. The style has had several revivals since the 1990s, and the influence of disco remains strong across American and European pop music. A revival has been underway since the early 2010s, coming to great popularity in the early 2020s. Albums that have contributed to this revival include "Confessions on a Dance Floor", "Random Access Memories", "Future Nostalgia", and Kylie Minogue's album itself titled "Disco".

The term "disco" is shorthand for the word "discothèque", a French word for "library of phonograph records" derived from "bibliothèque". The word "discothèque" had the same meaning in English in the 1950s.

"Discothèque" became used in French for a type of nightclub in Paris, after they had resorted to playing records during the Nazi occupation in the early 1940s. Some clubs used it as their proper name. In 1960, it was also used to describe a Parisian nightclub in an English magazine.

In the summer of 1964, a short sleeveless dress called the "discotheque dress" was briefly very popular in the United States. The earliest known use for the abbreviated form "disco" described this dress and has been found in "The Salt Lake Tribune" on July 12, 1964; "Playboy" magazine used it in September of the same year to describe Los Angeles nightclubs.

Vince Aletti was one of the first to describe disco as a sound or a music genre. He wrote the feature article "Discotheque Rock Paaaaarty" that appeared in "Rolling Stone" magazine in September 1973.

The music typically layered soaring, often-reverberated vocals, often doubled by horns, over a background "pad" of electric pianos and "chicken-scratch" rhythm guitars played on an electric guitar. Lead guitar features less frequently in disco than in rock. "The "rooster scratch" sound is achieved by lightly pressing the guitar strings against the fretboard and then quickly releasing them just enough to get a slightly muted poker [sound] while constantly strumming very close to the bridge." Other backing keyboard instruments include the piano, electric organ (during early years), string synthesizers, and electromechanical keyboards such as the Fender Rhodes electric piano, Wurlitzer electric piano, and Hohner Clavinet. Donna Summer's 1977 song "I Feel Love", produced by Giorgio Moroder with a prominent Moog synthesizer on the beat, was one of the first disco tracks to use the synthesizer.

The rhythm is laid down by prominent, syncopated basslines (with heavy use of broken octaves, that is, octaves with the notes sounded one after the other) played on the bass guitar and by drummers using a drum kit, African/Latin percussion, and electronic drums such as Simmons and Roland drum modules. Philly dance and Salsoul disco the sound was enriched with solo lines and harmony parts played by a variety of orchestral instruments, such as violin, viola, cello, trumpet, saxophone, trombone, flugelhorn, French horn, English horn, oboe, flute, timpani and synth strings, string section or a full string orchestra.

Most disco songs have a steady four-on-the-floor beat set by a bass drum, a quaver or semi-quaver hi-hat pattern with an open hissing hi-hat on the off-beat, and a heavy, syncopated bass line. A recording error in the 1975 song "Bad Luck" by Harold Melvin & the Blue Notes where Earl Young's hi-hat was too loud in the recording is said to have established loud hi-hats in disco. Other Latin rhythms such as the rhumba, the samba, and the cha-cha-cha are also found in disco recordings, and Latin polyrhythms, such as a rhumba beat layered over a merengue, are commonplace. The quaver pattern is often supported by other instruments such as the rhythm guitar and may be implied rather than explicitly present.

Songs often use syncopation, which is the accenting of unexpected beats. In general, the difference between disco, or any dance song, and a rock or popular song is that in dance music the bass drum hits "four to the floor", at least once a beat (which in 4/4 time is 4 beats per measure). Disco is further characterized by a 16th note division of the quarter notes as shown in the second drum pattern below, after a typical rock drum pattern.

The orchestral sound usually known as "disco sound" relies heavily on string sections and horns playing linear phrases, in unison with the soaring, often reverberated vocals or playing instrumental fills, while electric pianos and chicken-scratch guitars create the background "pad" sound defining the harmony progression. Typically, all of the doubling of parts and use of additional instruments creates a rich "wall of sound". There are, however, more minimalist flavors of disco with reduced, transparent instrumentation.

Harmonically, disco music typically contains major and minor seven chords, which are found more often in jazz than pop music.

The "disco sound" was much more costly to produce than many of the other popular music genres from the 1970s. Unlike the simpler, four-piece-band sound of funk, soul music of the late 1960s or the small jazz organ trios, disco music often included a large band, with several chordal instruments (guitar, keyboards, synthesizer), several drum or percussion instruments (drumkit, Latin percussion, electronic drums), a horn section, a string orchestra, and a variety of "classical" solo instruments (for example, flute, piccolo, and so on).

Disco songs were arranged and composed by experienced arrangers and orchestrators, and record producers added their creative touches to the overall sound using multitrack recording techniques and effects units. Recording complex arrangements with such a large number of instruments and sections required a team that included a conductor, copyists, record producers, and mixing engineers. Mixing engineers had an important role in the disco production process because disco songs used as many as 64 tracks of vocals and instruments. Mixing engineers and record producers, under the direction of arrangers, compiled these tracks into a fluid composition of verses, bridges, and refrains, complete with builds and breaks. Mixing engineers and record producers helped to develop the "disco sound" by creating a distinctive-sounding, sophisticated disco mix.

Early records were the "standard" three-minute version until Tom Moulton came up with a way to make songs longer so that he could take a crowd of dancers at a club to another level and keep them dancing longer. He found that it was impossible to make the 45-RPM vinyl singles of the time longer, as they could usually hold no more than five minutes of good-quality music. With the help of José Rodriguez, his remaster/mastering engineer, he pressed a single on a 10" disc instead of 7". They cut the next single on a 12" disc, the same format as a standard album. Moulton and Rodriguez discovered that these larger records could have much longer songs and remixes. 12" single records, also known as "Maxi singles", quickly became the standard format for all DJs of the disco genre.

By the late 1970s, most major US cities had thriving disco club scenes. The largest scenes were most notably in New York City but also in Philadelphia, San Francisco, Miami, and Washington, D.C. The scene was centered on discotheques, nightclubs and private loft parties.

In the 1970s, notable discos included "Crisco Disco", "The Sanctuary", "Leviticus", "Studio 54", and "Paradise Garage" in New York, "Artemis" in Philadelphia, "Studio One" in Los Angeles, "Dugan's Bistro" in Chicago, and "The Library" in Atlanta.

In the late '70s, Studio 54 in Midtown Manhattan was arguably the best-known nightclub in the world. This club played a major formative role in the growth of disco music and nightclub culture in general. It was operated by Steve Rubell and Ian Schrager and was notorious for the hedonism that went on within: the balconies were known for sexual encounters and drug use was rampant. Its dance floor was decorated with an image of the "Man in the Moon" that included an animated cocaine spoon.

The "Copacabana", another New York nightclub dating to the 1940s, had a revival in the late 1970s when it embraced disco; it would become the setting of a Barry Manilow song of the same name.

In Washington, D.C., large disco clubs such as "The Pier" ("Pier 9") and "The Other Side", originally regarded exclusively as "gay bars", became particularly popular among the capital area's gay and straight college students in the late '70s.

By 1979 there were 15,000-20,000 disco nightclubs in the US, many of them opening in suburban shopping centers, hotels, and restaurants. The 2001 Club franchises were the most prolific chain of disco clubs in the country. Although many other attempts were made to franchise disco clubs, 2001 was the only one to successfully do so in this time frame.

Powerful, bass-heavy, hi-fi sound systems were viewed as a key part of the disco club experience. "[Loft-party host David] Mancuso introduced the technologies of tweeter arrays (clusters of small loudspeakers, which emit high-end frequencies, positioned above the floor) and bass reinforcements (additional sets of subwoofers positioned at ground level) at the start of the 1970s to boost the treble and bass at opportune moments, and by the end of the decade sound engineers such as Richard Long had multiplied the effects of these innovations in venues such as the Garage."

Typical lighting designs for disco dance floors include multi-colored lights that swirl around or flash to the beat, strobe lights, an illuminated dance floor, and a mirror ball.

Disco-era disc jockeys (DJs) would often remix existing songs using reel-to-reel tape machines, and add in percussion breaks, new sections, and new sounds. DJs would select songs and grooves according to what the dancers wanted, transitioning from one song to another with a DJ mixer and using a microphone to introduce songs and speak to the audiences. Other equipment was added to the basic DJ setup, providing unique sound manipulations, such as reverb, equalization, and echo effects unit. Using this equipment, a DJ could do effects such as cutting out all but the bassline of a song and then slowly mixing in the beginning of another song using the DJ mixer's crossfader. Notable U.S. disco DJs include Francis Grasso of The Sanctuary, David Mancuso of The Loft, Frankie Knuckles of the Chicago Warehouse, Larry Levan of the Paradise Garage, Nicky Siano, Walter Gibbons, Karen Mixon Cook, Jim Burgess, John "Jellybean" Benitez, Richie Kulala of Studio 54, and Rick Salsalini.

Some DJs were also record producers who created and produced disco songs in the recording studio. Larry Levan, for example, was a prolific record producer as well as a DJ. Because record sales were often dependent on dance floor play by DJs in the nightclubs, DJs were also influential in the development and popularization of certain types of disco music being produced for record labels.

In the early years, dancers in discos danced in a "hang loose" or "freestyle" approach. At first, many dancers improvised their own dance styles and dance steps. Later in the disco era, popular dance styles were developed, including the "Bump", "Penguin", "Boogaloo", "Watergate", and "Robot". By October 1975 the Hustle reigned. It was highly stylized, sophisticated, and overtly sexual. Variations included the Brooklyn Hustle, New York Hustle, and Latin Hustle.

During the disco era, many nightclubs would commonly host disco dance competitions or offer free dance lessons. Some cities had disco dance instructors or dance schools, which taught people how to do popular disco dances such as "touch dancing", "the hustle", and "the cha cha". The pioneer of disco dance instruction was Karen Lustgarten in San Francisco in 1973. Her book "The Complete Guide to Disco Dancing" (Warner Books 1978) was the first to name, break down and codify popular disco dances as dance forms and distinguish between disco freestyle, partner, and line dances. The book topped the "New York Times" bestseller list for 13 weeks and was translated into Chinese, German, and French.

In Chicago, the "Step By Step" disco dance TV show was launched with the sponsorship support of the Coca-Cola company. Produced in the same studio that Don Cornelius used for the nationally syndicated dance/music television show, "Soul Train", "Step by Step"'s audience grew and the show became a success. The dynamic dance duo of Robin and Reggie led the show. The pair spent the week teaching disco dancing to dancers in the disco clubs. The instructional show aired on Saturday mornings and had a strong following. Its viewers would stay up all night on Fridays so they could be on the set the next morning, ready to return to the disco on Saturday night knowing with the latest personalized steps. The producers of the show, John Reid and Greg Roselli, routinely made appearances at disco functions with Robin and Reggie to scout out new dancing talent and promote upcoming events such as "Disco Night at White Sox Park".

In Sacramento, California, Disco King Paul Dale Roberts danced for the Guinness Book of World Records. He danced for 205 hours, the equivalent of 8½ days. Other dance marathons took place afterward and Roberts held the world record for disco dancing for a short period of time.

Some notable professional dance troupes of the 1970s included Pan's People and Hot Gossip. For many dancers, a key source of inspiration for 1970s disco dancing was the film "Saturday Night Fever" (1977). Further influence came from the music and dance style of such films as "Fame" (1980), "Disco Dancer" (1982), "Flashdance" (1983), and "The Last Days of Disco" (1998). Interest in disco dancing also helped spawn dance competition TV shows such as "Dance Fever" (1979).

Disco fashions were very trendy in the late 1970s. Discothèque-goers often wore glamorous, expensive, and extravagant fashions for nights out at their local disco club. Some women would wear sheer, flowing dresses, such as Halston dresses, or loose, flared pants. Other women wore tight, revealing, sexy clothes, such as backless halter tops, disco pants, "hot pants", or body-hugging spandex bodywear or "catsuits". Men would wear shiny polyester Qiana shirts with colorful patterns and pointy, extra wide collars, preferably open at the chest. Men often wore Pierre Cardin suits, three piece suits with a vest, and double-knit polyester shirt jackets with matching trousers known as the leisure suit. Men's leisure suits were typically form-fitted to some parts of the body, such as the waist and bottom while the lower part of the pants were flared in a bell bottom style, to permit freedom of movement.

During the disco era, men engaged in elaborate grooming rituals and spent time choosing fashion clothing, activities that would have been considered "feminine" according to the gender stereotypes of the era. Women dancers wore glitter makeup, sequins, or gold lamé clothing that would shimmer under the lights. Bold colors were popular for both genders. Platform shoes and boots for both genders and high heels for women were popular footwear. Necklaces and medallions were a common fashion accessory. Less commonly, some disco dancers wore outlandish costumes, dressed in drag, covered their bodies with gold or silver paint, or wore very skimpy outfits leaving them nearly nude; these uncommon get-ups were more likely to be seen at invitation-only New York City loft parties and disco clubs.

In addition to the dance and fashion aspects of the disco club scene, there was also a thriving club drug subculture, particularly for drugs that would enhance the experience of dancing to the loud, bass-heavy music and the flashing colored lights, such as cocaine (nicknamed "blow"), amyl nitrite ("poppers"), and the "... other quintessential 1970s club drug Quaalude, which suspended motor coordination and gave the sensation that one's arms and legs had turned to 'Jell-O. Quaaludes were so popular at disco clubs that the drug was nicknamed "disco biscuits".

Paul Gootenberg states that "[t]he relationship of cocaine to 1970s disco culture cannot be stressed enough..." During the 1970s, the use of cocaine by well-to-do celebrities led to its "glamorization" and to the widely held view that it was a "soft drug". LSD, marijuana, and "speed" (amphetamines) were also popular in disco clubs, and the use of these drugs "...contributed to the hedonistic quality of the dance floor experience." Since disco dances were typically held in liquor licensed-nightclubs and dance clubs, alcoholic drinks were also consumed by dancers; some users intentionally combined alcohol with the consumption of other drugs, such as Quaaludes, for a stronger effect.

According to Peter Braunstein, the "massive quantities of drugs ingested in discothèques produced the next cultural phenomenon of the disco era: rampant promiscuity and public sex. While the dance floor was the central arena of seduction, actual sex usually took place in the nether regions of the disco: bathroom stalls, exit stairwells, and so on. In other cases the disco became a kind of 'main course' in a hedonist's menu for a night out." At The Saint nightclub, a high percentage of the gay male dancers and patrons would have sex in the club; they typically had unprotected sex, because in 1980, HIV-AIDS had not yet been identified. At The Saint, "dancers would elope to an unpoliced upstairs balcony to engage in sex." The promiscuity and public sex at discos was part of a broader trend towards exploring a freer sexual expression in the 1970s, an era that is also associated with "swingers clubs, hot tubs, [and] key parties."

In his paper, "In Defense of Disco" (1979), Richard Dyer claims eroticism as one of the three main characteristics of disco. As opposed to rock music which has a very phallic centered eroticism focusing on the sexual pleasure of men over other persons, Dyer describes disco as featuring a non-phallic full body eroticism. Through a range of percussion instruments, a willingness to play with rhythm, and the endless repeating of phrases without cutting the listener off, disco achieved this full-body eroticism by restoring eroticism to the whole body for both sexes. This allowed for the potential expression of sexualities not defined by the cock/penis, and the erotic pleasure of bodies that are not defined by a relationship to a penis. The sexual liberation expressed through the rhythm of disco is further represented in the club spaces that disco grew within.

In Peter Shapiro's ": Throbbing Words on Sound", he discusses eroticism through the technology disco utilizes to create its audacious sound. The music, Shapiro states, is adjunct to "the pleasure-is-politics ethos of post-Stonewall culture." He explains how "mechano-eroticism", which links the technology used to create the unique mechanical sound of disco to eroticism, set the genre in a new dimension of reality living outside of naturalism and heterosexuality. Randy Jones and Mark Jacobsen echo this sentiment in BBC Radio's "The Politics of Dancing: How Disco Changed the World," describing the loose, hip-focused dance style as "a new kind of communion" that celebrates the sparks of liberation brought on the Stonewall riots. As New York state had laws against homosexual behavior in public, including dancing with a member of the same sex, the eroticism of disco served as resistance and an expression of sexual freedom.

He uses Donna Summer's singles "Love to Love You Baby" (1975) and "I Feel Love" (1977) as examples of the ever-present relationship between the synthesized bass lines and backgrounds to the simulated sounds of orgasms. Summer's voice echoes in the tracks, and likens them to the drug-fervent, sexually liberated fans of disco who sought to free themselves through disco's "aesthetic of machine sex." Shapiro sees this as an influence that creates sub-genres like hi-NRG and dub-disco, which allowed for eroticism and technology to be further explored through intense synth bass lines and alternative rhythmic techniques that tap into the entire body rather than the obvious erotic parts of the body.

The New York nightclub The Sanctuary under resident DJ Francis Grasso is a prime example of this sexual liberty. In their history of the disc jockey and club culture, Bill Brewster and Frank Broughton describe the Sanctuary as "poured full of newly liberated gay men, then shaken (and stirred) by a weighty concoction of dance music and pharmacoia of pills and potions, the result is a festivaly of carnality." The Sanctuary was the "first totally uninhibited gay discotheque in America" and while sex was not allowed on the dancefloor, the dark corners, bathrooms. and hallways of the adjacent buildings were all utilized for orgy-like sexual engagements.

By describing the music, drugs, and liberated mentality as a trifecta coming together to create the festival of carnality, Brewster and Broughton are inciting all three as stimuli for the dancing, sex, and other embodied movements that contributed to the corporeal vibrations within the Sanctuary. It supports the argument that disco music took a role in facilitating this sexual liberation that was experienced in the discotheques. The recent legalization of abortion and the introduction of antibiotics and the pill facilitated a culture shift around sex from one of procreation to pleasure and enjoyment. Thus was fostered a very sex-positive framework around discotheques.

Further, in addition to gay sex being illegal in New York state, until 1973 the American Psychiatric Association classified homosexuality as an illness. This law and classification coupled together can be understood to have heavily dissuaded the expression of queerness in public, as such the liberatory dynamics of discotheques can be seen as having provided space for self-realization for queer persons. David Mancuso's club/house party, The Loft, was described as having a "pansexual attitude [that] was revolutionary in a country where up until recently it had been illegal for two men to dance together unless there was a woman present; where women were legally obliged to wear at least one recognizable item of female clothing in public; and where men visiting gay bars usually carried bail money with them."

Disco was mostly developed from music that was popular on the dance floor in clubs that started playing records instead of having a live band. The first discotheques mostly played swing music. Later on, uptempo rhythm and blues became popular in American clubs and northern soul and glam rock records in the UK. In the early 1940s, nightclubs in Paris resorted to playing jazz records during the Nazi occupation.

Régine Zylberberg claimed to have started the first discotheque and to have been the first club DJ in 1953 in the "Whisky à Go-Go" in Paris. She installed a dance floor with colored lights and two turntables so she could play records without having a gap in the music. In October 1959, the owner of the Scotch Club in Aachen, West Germany chose to install a record player for the opening night instead of hiring a live band. The patrons were unimpressed until a young reporter, who happened to be covering the opening of the club, impulsively took control of the record player and introduced the records that he chose to play. Klaus Quirini later claimed to thus have been the world's first nightclub DJ.

During the 1960s, discotheque dancing became a European trend that was enthusiastically picked up by the American press. At this time, when the discotheque culture from Europe became popular in the United States, several music genres with danceable rhythms rose to popularity and evolved into different sub-genres: rhythm and blues (originated in the 1940s), soul (late 1950s and 1960s), funk (mid-1960s) and go-go (mid-1960s and 1970s; more than "disco", the word "go-go" originally indicated a music club). Musical genres that were primarily performed by African-American musicians would influence much of early disco.

Also during the 1960s, the Motown record label developed its own approach, described as having "1) simply structured songs with sophisticated melodies and chord changes, 2) a relentless four-beat drum pattern, 3) a gospel use of background voices, vaguely derived from the style of the Impressions, 4) a regular and sophisticated use of both horns and strings, 5) lead singers who were half way between pop and gospel music, 6) a group of accompanying musicians who were among the most dextrous, knowledgeable, and brilliant in all of popular music (Motown bassists have long been the envy of white rock bassists) and 7) a trebly style of mixing that relied heavily on electronic limiting and equalizing (boosting the high range frequencies) to give the overall product a distinctive sound, particularly effective for broadcast over AM radio." Motown had many hits with disco elements by acts like Eddie Kendricks ("Keep on Truckin'" in 1973, "Boogie Down" in 1974).

At the end of the 1960s, musicians, and audiences from the Black, Italian, and Latino communities adopted several traits from the hippie and psychedelia subcultures. They included using music venues with a loud, overwhelming sound, free-form dancing, trippy lighting, colorful costumes, and the use of hallucinogenic drugs. In addition, the perceived positivity, lack of irony, and earnestness of the hippies informed proto-disco music like MFSB's album "Love Is the Message".
Partly through the success of Jimi Hendrix, psychedelic elements that were popular in rock music of the late 1960s found their way into soul and early funk music and formed the subgenre psychedelic soul. Examples can be found in the music of the Chambers Brothers, George Clinton with his Parliament-Funkadelic collective, Sly and the Family Stone, and the productions of Norman Whitfield with The Temptations.

The long instrumental introductions and detailed orchestration found in psychedelic soul tracks by the Temptations are also considered as cinematic soul. In the early 1970s, Curtis Mayfield and Isaac Hayes scored hits with cinematic soul songs that were actually composed for movie soundtracks: "Superfly" (1972) and "Theme from Shaft" (1971). The latter is sometimes regarded as an early disco song. From the mid-1960s to early 1970s, Philadelphia soul and New York soul developed as sub-genres that also had lavish percussion, lush string orchestra arrangements, and expensive record production processes. In the early 1970s, the Philly soul productions by Gamble and Huff evolved from the simpler arrangements of the late-1960s into a style featuring lush strings, thumping basslines, and sliding hi-hat rhythms. These elements would become typical for disco music and are found in several of the hits they produced in the early 1970s:

Other early disco tracks that helped shape disco and became popular on the dance floors of (underground) discotheque clubs and parties include: 

Early disco was dominated by record producers and labels such as Salsoul Records (Ken, Stanley, and Joseph Cayre), West End Records (Mel Cheren), Casablanca (Neil Bogart), and Prelude (Marvin Schlachter). The genre was also shaped by Tom Moulton, who wanted to extend the enjoyment of dance songs — thus creating the extended mix or "remix", going from a three-minute 45 rpm single to the much longer 12" record. Other influential DJs and remixers who helped to establish what became known as the "disco sound" included David Mancuso, Nicky Siano, Shep Pettibone, Larry Levan, Walter Gibbons, and Chicago-based Frankie Knuckles. Frankie Knuckles was not only an important disco DJ; he also helped to develop house music in the 1980s.

Disco hit the television airwaves as part of the music/dance variety show "Soul Train" in 1971 hosted by Don Cornelius, then Marty Angelo's "Disco Step-by-Step Television Show" in 1975, Steve Marcus's "Disco Magic/Disco 77", Eddie Rivera's "Soap Factory", and Merv Griffin's "Dance Fever", hosted by Deney Terrio, who is credited with teaching actor John Travolta to dance for his role in the film "Saturday Night Fever" (1977), as well as DANCE, based out of Columbia, South Carolina.

In 1974, New York City's WPIX-FM premiered the first disco radio show.

In the 1970s, the key counterculture of the 1960s, the hippie movement, was fading away. The economic prosperity of the previous decade had declined, and unemployment, inflation, and crime rates had soared. Political issues like the backlash from the Civil Rights Movement culminating in the form of , the Vietnam War, the assassinations of Dr. Martin Luther King Jr. and John F. Kennedy, and the Watergate scandal, left many feeling disillusioned and hopeless . The start of the '70s was marked by a shift in the consciousness of the American people: the rise of the feminist movement, identity politics, gangs, etc. very much shaped this era. Disco music and disco dancing provided an escape from negative social and economic issues. The non-partnered dance style of disco music allowed people of all races and sexual orientations to enjoy the dancefloor atmosphere.

In "Beautiful Things in Popular Culture", Simon Frith highlights the sociability of disco and its roots in 1960s counterculture. "The driving force of the New York underground dance scene in which disco was forged was not simply that city's complex ethnic and sexual culture but also a 1960s notion of community, pleasure and generosity that can only be described as hippie", he says. "The best disco music contained within it a remarkably powerful sense of collective euphoria."

The birth of disco is often claimed to be found in the private dance parties held by New York City DJ David Mancuso's home that became known as The Loft, an invitation-only non-commercial underground club that inspired many others. He organized the first major party in his Manhattan home on Valentine's Day 1970 with the name "Love Saves The Day". After some months the parties became weekly events and Mancuso continued to give regular parties into the 1990s. Mancuso required that the music played had to be soulful, rhythmic, and impart words of hope, redemption, or pride.

When Mancuso threw his first informal house parties, the gay community (which made up much of The Loft's attendee roster) was often harassed in the gay bars and dance clubs, with many gay men carrying bail money with them to gay bars. But at The Loft and many other early, private discotheques, they could dance together without fear of police action thanks to Mancuso's underground, yet legal, policies. Vince Aletti described it "like going to party, completely mixed, racially and sexually, where there wasn't any sense of someone being more important than anyone else," and Alex Rosner reiterated this saying "It was probably about sixty percent black and seventy percent gay...There was a mix of sexual orientation, there was a mix of races, mix of economic groups. A real mix, where the common denominator was music."

Film critic Roger Ebert called the popular embrace of disco's exuberant dance moves an escape from "the general depression and drabness of the political and musical atmosphere of the late seventies." Pauline Kael, writing about the disco-themed film "Saturday Night Fever", said the film and disco itself touched on "something deeply romantic, the need to move, to dance, and the need to be who you'd like to be. Nirvana is the dance; when the music stops, you return to being ordinary."

In the late 1960s, uptempo soul with heavy beats and some associated dance styles and fashion were picked up in the British mod scene and formed the northern soul movement. Originating at venues such as the Twisted Wheel in Manchester, it quickly spread to other UK dancehalls and nightclubs like the Chateau Impney (Droitwich), Catacombs (Wolverhampton), the Highland Rooms at Blackpool Mecca, Golden Torch (Stoke-on-Trent), and Wigan Casino. As the favoured beat became more uptempo and frantic in the early 1970s, northern soul dancing became more athletic, somewhat resembling the later dance styles of disco and break dancing. Featuring spins, flips, karate kicks, and backdrops, club dancing styles were often inspired by the stage performances of touring American soul acts such as Little Anthony & the Imperials and Jackie Wilson.

In 1974, there were an estimated 25,000 mobile discos and 40,000 professional disc jockeys in the United Kingdom. Mobile discos were hired deejays that brought their own equipment to provide music for special events. Glam rock tracks were popular, with, for example, Gary Glitter's 1972 single "Rock and Roll Part 2" becoming popular on UK dance floors while it did not get much radio airplay.

From 1974 to 1977, disco music increased in popularity as many disco songs topped the charts. The Hues Corporation's "Rock the Boat" (1974), a US number-one single and million-seller, was one of the early disco songs to reach number one. The same year saw the release of "Kung Fu Fighting", performed by Carl Douglas and produced by Biddu, which reached number one in both the UK and US, and became the best-selling single of the year and one of the best-selling singles of all time with 11 million records sold worldwide, helping to popularize disco to a great extent. Another notable disco success that year was George McCrae's "Rock Your Baby": it became the United Kingdom's first number one disco single.

In the northwestern sections of the United Kingdom, the northern soul explosion, which started in the late 1960s and peaked in 1974, made the region receptive to disco, which the region's disc jockeys were bringing back from New York City. The shift by some DJs to the newer sounds coming from the U.S. resulted in a split in the scene, whereby some abandoned the 1960s soul and pushed a modern soul sound which tended to be more closely aligned with disco than soul.
In 1975, Gloria Gaynor released her first side-long vinyl album, which included a remake of the Jackson 5's "Never Can Say Goodbye" (which, in fact, is also the album title) and two other songs, "Honey Bee" and her disco version of "Reach Out (I'll Be There)". The album first topped the Billboard disco/dance charts in November 1974. Later in 1978, Gaynor's number-one disco song was "I Will Survive", which was seen as a symbol of female strength and a gay anthem, like her further disco hit, a 1983 remake of "I Am What I Am". In 1979 she released "Let Me Know (I Have a Right)", a single which gained popularity in the civil rights movements. Also in 1975, Vincent Montana Jr.'s Salsoul Orchestra contributed with their Latin-flavored orchestral dance song "Salsoul Hustle", reaching number four on the Billboard Dance Chart; their 1976 hits were "Tangerine" and "Nice 'n' Naasty", the first being a cover of a 1941 song.
Songs such as Van McCoy's 1975 "The Hustle" and the humorous Joe Tex 1977 "Ain't Gonna Bump No More (With No Big Fat Woman)" gave names to the popular disco dances "the Bump" and "the Hustle". Other notable early successful disco songs include Barry White's "You're the First, the Last, My Everything" (1974); Labelle's "Lady Marmalade" (1974)'; Disco-Tex and the Sex-O-Lettes' "Get Dancin'" (1974); Earth, Wind & Fire's "Shining Star" (1975); Silver Convention's "Fly, Robin, Fly" (1975) and "Get Up and Boogie" (1976); Vicki Sue Robinson's "Turn the Beat Around" (1976); and "More, More, More" (1976) by Andrea True (a former pornographic actress during the Golden Age of Porn, an era largely contemporaneous with the height of disco).

Formed by Harry Wayne Casey (a.k.a. "KC") and Richard Finch, Miami's KC and the Sunshine Band had a string of disco-definitive top-five singles between 1975 and 1977, including "Get Down Tonight", "That's the Way (I Like It)", "(Shake, Shake, Shake) Shake Your Booty", "I'm Your Boogie Man", "Boogie Shoes", and "Keep It Comin' Love". In this period, rock bands like the English Electric Light Orchestra featured in their songs a violin sound that became a staple of disco music, as in the 1975 hit "Evil Woman", although the genre was correctly described as orchestral rock.

Other disco producers such as Tom Moulton took ideas and techniques from dub music (which came with the increased Jamaican migration to New York City in the 1970s) to provide alternatives to the "four on the floor" style that dominated. DJ Larry Levan utilized styles from dub and jazz and remixing techniques to create early versions of house music that sparked the genre.

Norman Whitfield was an influential producer and songwriter at Motown records, renowned for creating innovative "psychedelic soul" songs with many hits for Marvin Gaye, the Velvelettes, the Temptations, and Gladys Knight & the Pips. From around the production of the Temptations album "Cloud Nine" in 1968, he incorporated some psychedelic influences and started to produce longer, dance-friendly tracks, with more room for elaborate rhythmic instrumental parts. An example of such a long psychedelic soul track is "Papa Was a Rollin' Stone", which appeared as a single edit of almost seven minutes and an approximately 12-minute-long 12" version in 1972. By the early 70s, many of Whitfield's productions evolved more and more towards funk and disco, as heard on albums by the Undisputed Truth and the 1973 album "" by The Jackson 5. The Undisputed Truth, a Motown recording act assembled by Whitfield to experiment with his psychedelic soul production techniques, found success with their 1971 song "Smiling Faces Sometimes". Their disco single "You + Me = Love" (number 43) was produced by Whitfield and made number 2 on the US dance chart in 1976.

In 1975, Whitfield left Motown and founded his own label Whitfield records, on which also "You + Me = Love" was released. Whitfield produced some more disco hits, including "Car Wash" (1976) by Rose Royce from the to the 1976 film "Car Wash". In 1977, singer, songwriter, and producer Willie Hutch, who had been signed to Motown since 1970, now signed with Whitfield's new label, and scored a successful disco single with his song "In and Out" in 1982.

Other Motown artists turned to disco as well. Diana Ross embraced the disco sound with her successful 1976 outing "Love Hangover" from her self-titled album. Her 1980 dance classics "Upside Down" and "I'm Coming Out" were written and produced by Nile Rodgers and Bernard Edwards of the group Chic. The Supremes, the group that made Ross famous, scored a handful of hits in the disco clubs without her, most notably 1976's "I'm Gonna Let My Heart Do the Walking" and, their last charted single before disbanding, 1977's "You're My Driving Wheel".

At the request of Motown that he produce songs in the disco genre, Marvin Gaye released "Got to Give It Up" in 1978, despite his dislike of disco. He vowed not to record any songs in the genre and actually wrote the song as a parody. However, several of Gaye's songs have disco elements, including "I Want You" (1975). Stevie Wonder released the disco single "Sir Duke" in 1977 as a tribute to Duke Ellington, the influential jazz legend who had died in 1974. Smokey Robinson left the Motown group the Miracles for a solo career in 1972 and released his third solo album "A Quiet Storm" in 1975, which spawned and lent its name to the "Quiet Storm" musical programming format and subgenre of R&B. It contained the disco single "Baby That's Backatcha". Other Motown artists who scored disco hits were Robinson's former group, the Miracles, with "Love Machine" (1975), Eddie Kendricks with "Keep On Truckin'" (1973), the Originals with "Down to Love Town" (1976), and Thelma Houston with her cover of the Harold Melvin and the Blue Notes song "Don't Leave Me This Way" (1976). The label continued to release successful songs into the 1980s with Rick James's "Super Freak" (1981), and the Commodores' "Lady (You Bring Me Up)" (1981).

Several of Motown's solo artists who left the label went on to have successful disco songs. Mary Wells, Motown's first female superstar with her signature song "My Guy" (written by Smokey Robinson), abruptly left the label in 1964. She briefly reappeared on the charts with the disco song "Gigolo" in 1980. Jimmy Ruffin, the elder brother of the Temptations lead singer David Ruffin, was also signed to Motown and released his most successful and well-known song "What Becomes of the Brokenhearted" as a single in 1966. Ruffin eventually left the record label in the mid-1970s, but saw success with the 1980 disco song "Hold On (To My Love)", which was written and produced by Robin Gibb of the Bee Gees, for his album "Sunrise". Edwin Starr, known for his Motown protest song "War" (1970), reentered the charts in 1979 with a pair of disco songs, "Contact" and "H.A.P.P.Y. Radio". Kiki Dee became the first white British singer to sign with Motown in the US, and released one album, "Great Expectations" (1970), and two singles "The Day Will Come Between Sunday and Monday" (1970) and "Love Makes the World Go Round" (1971), the latter giving her first-ever chart entry (number 87 on the US Chart). She soon left the company and signed with Elton John's The Rocket Record Company, and in 1976 had her biggest and best-known single, "Don't Go Breaking My Heart", a disco duet with John. The song was intended as an affectionate disco-style pastiche of the Motown sound, in particular the various duets recorded by Marvin Gaye with Tammi Terrell and Kim Weston.

Many Motown groups who had left the record label charted with disco songs. The Jackson 5, one of Motown's premier acts in the early 1970s, left the record company in 1975 (Jermaine Jackson, however, remained with the label) after successful songs like "I Want You Back" (1969) and "ABC" (1970), and even the disco song "Dancing Machine" (1974). Renamed as 'the Jacksons' (as Motown owned the name 'the Jackson 5'), they went on to find success with disco songs like "Blame It on the Boogie" (1978), "Shake Your Body (Down to the Ground)" (1979), and "Can You Feel It?" (1981) on the Epic label.

The Isley Brothers, whose short tenure at the company had produced the song "This Old Heart of Mine (Is Weak for You)" in 1966, went on release successful disco songs like "It's a Disco Night (Rock Don't Stop)" (1979). Gladys Knight & the Pips, who recorded the most successful version of "I Heard It Through the Grapevine" (1967) before Marvin Gaye, scored commercially successful singles such as "Baby, Don't Change Your Mind" (1977) and "Bourgie, Bourgie" (1980) in the disco era. The Detroit Spinners were also signed to the Motown label and saw success with the Stevie Wonder-produced song "It's a Shame" in 1970. They left soon after, on the advice of fellow Detroit native Aretha Franklin, to Atlantic Records, and there had disco songs like "The Rubberband Man" (1976). In 1979, they released a successful cover of Elton John's "Are You Ready for Love", as well as a medley of the Four Seasons' song "Working My Way Back to You" and Michael Zager's "Forgive Me, Girl". The Four Seasons themselves were briefly signed to Motown's MoWest label, a short-lived subsidiary for R&B and soul artists based on the West Coast, and there the group produced one album, "Chameleon" (1972) – to little commercial success in the US. However, one single, "The Night", was released in Britain in 1975, and thanks to popularity from the Northern Soul circuit, reached number seven on the UK Singles Chart. The Four Seasons left Motown in 1974 and went on to have a disco hit with their song "December, 1963 (Oh, What a Night)" (1975) for Warner Curb Records.

By far the most successful Euro disco act was ABBA (1972–1982). This Swedish quartet, which sang primarily in English, found success with singles such as "Waterloo" (1974), "Take a Chance on Me" (1978), "Gimme! Gimme! Gimme! (A Man After Midnight)" (1979), "Super Trouper" (1980), and their signature smash hit "Dancing Queen" (1976).

In the 1970s Munich, West Germany, music producers Giorgio Moroder and Pete Bellotte made a decisive contribution to disco music with a string of hits for Donna Summer, which became known as the "Munich Sound". In 1975, Summer suggested the lyric "Love to Love You Baby" to Moroder and Bellotte, who turned the lyric into a full disco song. The final product, which contained the vocalizations of a series of simulated orgasms, initially was not intended for release, but when Moroder played it in the clubs it caused a sensation and he released it. The song became an international hit, reaching the charts in many European countries and the US (No. 2). It has been described as the arrival of the expression of raw female sexual desire in pop music. A nearly 17-minute 12-inch single was released. The 12" single became and remains a standard in discos today. In 1976 Donna Summer's version of "Could It Be Magic" brought disco further into the mainstream. In 1977 Summer, Moroder and Bellotte further released "I Feel Love", as the B-side of "Can't We Just Sit Down (And Talk It Over)", which revolutionized dance music with its mostly electronic production and was a massive worldwide success, spawning the Hi-NRG subgenre. Giorgio Moroder was described by AllMusic as "one of the principal architects of the disco sound". Another successful disco music project by Moroder at that time was Munich Machine (1976–1980).

Boney M. (1974–1986) was a West German Euro disco group of four West Indian singers and dancers masterminded by record producer Frank Farian. Boney M. charted worldwide with such songs as "Daddy Cool" (1976) "Ma Baker" (1977) and "Rivers Of Babylon" (1978). Another successful West German Euro disco recording act was Silver Convention (1974–1979). The German group Kraftwerk also had an influence on Euro disco.
In France, Dalida released "J'attendrai" ("I Will Wait") in 1975, which also became successful in Canada, Europe, and Japan. Dalida successfully adjusted herself to disco and released at least a dozen of songs that charted in the top 10 in Europe. Claude François, who re-invented himself as the "king of French disco", released "La plus belle chose du monde", a French version of the Bee Gees song "Massachusetts", which became successful in Canada and Europe and "Alexandrie Alexandra" was posthumously released on the day of his burial and became a worldwide success. Cerrone's early songs, "Love in C Minor" (1976), "Supernature" (1977), and "Give Me Love" (1978) were successful in the US and Europe. Another Euro disco act was the French diva Amanda Lear, where Euro disco sound is most heard in "Enigma (Give a Bit of Mmh to Me)" (1978). French producer Alec Costandinos assembled the Euro disco group Love and Kisses (1977–1982).

In Italy Raffaella Carrà was the most successful Euro disco act, alongside La Bionda, Hermanas Goggi and Oliver Onions. Her greatest international single was "Tanti Auguri" ("Best Wishes"), which has become a popular song with gay audiences. The song is also known under its Spanish title "Para hacer bien el amor hay que venir al sur" (which refers to Southern Europe, since the song was recorded and taped in Spain). The Estonian version of the song "Jätke võtmed väljapoole" was performed by Anne Veski. "A far l'amore comincia tu" ("To make love, your move first") was another success for her internationally, known in Spanish as "En el amor todo es empezar", in German as "Liebelei", in French as "Puisque tu l'aimes dis le lui", and in English as "Do It, Do It Again". It was her only entry to the UK Singles Chart, reaching number 9, where she remains a one-hit wonder. In 1977, she recorded another successful single, "Fiesta" ("The Party" in English) originally in Spanish, but then recorded it in French and Italian after the song hit the charts. "A far l'amore comincia tu" has also been covered in Turkish by a Turkish popstar Ajda Pekkan as "Sakın Ha" in 1977.

Recently, Carrà has gained new attention for her appearance as the female dancing soloist in a 1974 TV performance of the experimental gibberish song "Prisencolinensinainciusol" (1973) by Adriano Celentano. A remixed video featuring her dancing went viral on the internet in 2008. In 2008 a video of a performance of her only successful UK single, "Do It, Do It Again", was featured in the "Doctor Who" episode "Midnight". Rafaella Carrà worked with Bob Sinclar on the new single "Far l'Amore" which was released on YouTube on March 17, 2011. The song charted in different European countries. Another prominent European disco act was the pop group Luv' from the Netherlands.

Euro disco continued evolving within the broad mainstream pop music scene, even when disco's popularity sharply declined in the United States, abandoned by major U.S. record labels and producers. Through the influence of Italo disco, it also played a role in the evolution of early house music in the early 1980s and later forms of electronic dance music, including early '90s Eurodance.

In December 1977, the film "Saturday Night Fever" was released. It was a huge success and its soundtrack became one of the best-selling albums of all time. The idea for the film was sparked by a 1976 "New York" magazine article titled "Tribal Rites of the New Saturday Night" which supposedly chronicled the disco culture in mid-1970s New York City, but was later revealed to have been fabricated. Some critics said the film "mainstreamed" disco, making it more acceptable to heterosexual white males. Many music historians believe the success of the movie and soundtrack extended the life of the disco era by several years.

Organized around the culture of suburban discotheques and the character of Tony Manero, portrayed by John Travolta, "Saturday Night Fever" became a cultural phenomenon that recast the dance floor as a site for patriarchal masculinity and heterosexual courtship. This transformation aligned disco with the interests of the perceived mass market, specifically targeting suburban and Middle American audiences.

The portrayal of the dance floor in "Saturday Night Fever" marked a reappropriation by straight male culture, turning it into a space for men to showcase their prowess and pursue partners of the opposite sex. The film popularized the hustle, a Latin social dance, reinforcing the centrality of the straight-dancing couple in the disco exchange. Notably, the soundtrack, dominated by the Bee Gees, risked presenting disco as a new incarnation of shrill white pop, deviating from its diverse and inclusive origins. The success of "Saturday Night Fever" was unprecedented, breaking box office and album sale records. Unfortunately, its impact went beyond mere popularity. The film established a template for disco that was easily reproducible, yet thoroughly de-queered in its outlook. By narrowing the narrative to fit into the conventional ideals of suburban heterosexual culture, the film contributed to a distorted and commodified version of disco.

The Bee Gees used Barry Gibb's falsetto to garner hits such as "You Should Be Dancing", "Stayin' Alive", "Night Fever", "More Than A Woman", "Love You Inside Out", and "Tragedy". Andy Gibb, a younger brother to the Bee Gees, followed with similarly styled solo singles such as "I Just Want to Be Your Everything", "(Love Is) Thicker Than Water", and "Shadow Dancing".

In 1978, Donna Summer's multi-million-selling vinyl single disco version of "MacArthur Park" was number one on the "Billboard" Hot 100 chart for three weeks and was nominated for the Grammy Award for Best Female Pop Vocal Performance. The recording, which was included as part of the "MacArthur Park Suite" on her double live album "Live and More", was eight minutes and 40 seconds long on the album. The shorter seven-inch vinyl single version of MacArthur Park was Summer's first single to reach number one on the Hot 100; it does not include the balladic second movement of the song, however. A 2013 remix of "MacArthur Park" by Summer topped the Billboard Dance Charts marking five consecutive decades with a number-one song on the charts. From mid-1978 to late 1979, Summer continued to release singles such as "Last Dance", "Heaven Knows" (with Brooklyn Dreams), "Hot Stuff", "Bad Girls", "Dim All the Lights" and "On the Radio", all very successful songs, landing in the top five or better, on the Billboard pop charts.

The band Chic was formed mainly by guitarist Nile Rodgers—a self-described "street hippie" from late 1960s New York—and bassist Bernard Edwards. Their popular 1978 single, "Le Freak", is regarded as an iconic song of the genre. Other successful songs by Chic include the often-sampled "Good Times" (1979), "I Want Your Love" (1979), and "Everybody Dance" (1979). The group regarded themselves as the disco movement's rock band that made good on the hippie movement's ideals of peace, love, and freedom. Every song they wrote was written with an eye toward giving it "deep hidden meaning" or D.H.M.

Sylvester, a flamboyant and openly gay singer famous for his soaring falsetto voice, scored his biggest disco hit in late 1978 with "You Make Me Feel (Mighty Real)". His singing style was said to have influenced the singer Prince. At that time, disco was one of the forms of music most open to gay performers.

The Village People were a singing/dancing group created by Jacques Morali and Henri Belolo to target disco's gay audience. They were known for their onstage costumes of typically male-associated jobs and ethnic minorities and achieved mainstream success with their 1978 hit song "Macho Man". Other songs include "Y.M.C.A." (1979) and "In the Navy" (1979).

Also noteworthy are The Trammps' "Disco Inferno" (1976), (1978, reissue due to the popularity gained from the "Saturday Night Fever" soundtrack), Heatwave's "Boogie Nights" (1977), Evelyn "Champagne" King's "Shame" (1977), A Taste of Honey's "Boogie Oogie Oogie" (1978), Cheryl Lynn's "Got to Be Real" (1978), Alicia Bridges's "I Love the Nightlife" (1978), Patrick Hernandez's "Born to Be Alive" (1978), Earth, Wind & Fire's "September" (1978) and "Boogie Wonderland" (1979), Peaches & Herb's "Shake Your Groove Thing" (1978), Sister Sledge's "We Are Family" and "He's the Greatest Dancer" (both 1979), McFadden and Whitehead's "Ain't No Stoppin' Us Now" (1979), Anita Ward's "Ring My Bell" (1979), Kool & the Gang's "Ladies' Night" (1979) and "Celebration" (1980), The Whispers's "And the Beat Goes On" (1979), Stephanie Mills's "What Cha Gonna Do with My Lovin'" (1979), Lipps Inc.'s "Funkytown" (1980), The Brothers Johnson's "Stomp!" (1980), George Benson's "Give Me the Night" (1980), Donna Summer's "Sunset People" (1980), and Walter Murphy's various attempts to bring classical music to the mainstream, most notably the disco song "A Fifth of Beethoven" (1976), which was inspired by Beethoven's fifth symphony.

At the height of its popularity, many non-disco artists recorded songs with disco elements, such as Rod Stewart with his "Da Ya Think I'm Sexy?" in 1979. Even mainstream rock artists adopted elements of disco. Progressive rock group Pink Floyd used disco-like drums and guitar in their song "Another Brick in the Wall, Part 2" (1979), which became their only number-one single in both the US and UK. The Eagles referenced disco with "One of These Nights" (1975) and "Disco Strangler" (1979), Paul McCartney & Wings with "Silly Love Songs" (1976) and "Goodnight Tonight" (1979), Queen with "Another One Bites the Dust" (1980), the Rolling Stones with "Miss You" (1978) and "Emotional Rescue" (1980), Stephen Stills with his album "Thoroughfare Gap" (1978), Electric Light Orchestra with "Shine a Little Love" and "Last Train to London" (both 1979), Chicago with "Street Player" (1979), the Kinks with "(Wish I Could Fly Like) Superman" (1979), the Grateful Dead with "Shakedown Street", The Who with "Eminence Front" (1982), and the J. Geils Band with "Come Back" (1980). Even hard rock group KISS jumped in with "I Was Made for Lovin' You" (1979), and Ringo Starr's album "Ringo the 4th" (1978) features a strong disco influence.

The disco sound was also adopted by artists from other genres, including the 1979 U.S. number one hit "No More Tears (Enough Is Enough)" by easy listening singer Barbra Streisand in a duet with Donna Summer. In country music, in an attempt to appeal to the more mainstream market, artists began to add pop/disco influences to their music. Dolly Parton launched a successful crossover onto the pop/dance charts, with her albums "Heartbreaker" and "Great Balls of Fire" containing songs with a disco flair. In particular, a disco remix of the track "Baby I'm Burnin'" peaked at number 15 on the Billboard Dance Club Songs chart; ultimately becoming one of the years biggest club hits.
Additionally, Connie Smith covered Andy Gibb's "I Just Want to Be Your Everything" in 1977, Bill Anderson recorded "Double S" in 1978, and Ronnie Milsap released "Get It Up" and covered blues singer Tommy Tucker's song "Hi-Heel Sneakers" in 1979.

Pre-existing non-disco songs, standards, and TV themes were frequently "disco-ized" in the 1970s, such as the "I Love Lucy" theme (recorded as "Disco Lucy" by the Wilton Place Street Band), "Aquarela do Brasil" (recorded as "Brazil" by The Ritchie Family), and "Baby Face" (recorded by the Wing and a Prayer Fife and Drum Corps). The rich orchestral accompaniment that became identified with the disco era conjured up the memories of the big band era—which brought out several artists that recorded and disco-ized some big band arrangements, including Perry Como, who re-recorded his 1945 song "Temptation", in 1975, as well as Ethel Merman, who released an album of disco songs entitled "The Ethel Merman Disco Album" in 1979.

Myron Floren, second-in-command on "The Lawrence Welk Show", released a recording of the "Clarinet Polka" entitled "Disco Accordion." Similarly, Bobby Vinton adapted "The Pennsylvania Polka" into a song named "Disco Polka". Easy listening icon Percy Faith, in one of his last recordings, released an album entitled "Disco Party" (1975) and recorded a disco version of his "Theme from "A Summer Place"" in 1976. Even classical music was adapted for disco, notably Walter Murphy's "A Fifth of Beethoven" (1976, based on the first movement of Beethoven's 5th Symphony) and "Flight 76" (1976, based on Rimsky-Korsakov's "Flight of the Bumblebee"), and Louis Clark's "Hooked On Classics" series of albums and singles.
Many original television theme songs of the era also showed a strong disco influence, such as "S.W.A.T." (1975), "Wonder Woman" (1975), "Charlie's Angels" (1976), "NBC Saturday Night At The Movies" (1976), "The Love Boat" (1977), "The Donahue Show" (1977), "CHiPs" (1977), "The Professionals" (1977), "Dallas" (1978), NBC Sports broadcasts (1978), "Kojak" (1977), and "The Hollywood Squares" (1979).

Disco jingles also made their way into many TV commercials, including Purina's 1979 "Good Mews" cat food commercial and an "IC Light" commercial by Pittsburgh's Iron City Brewing Company.

Several parodies of the disco style were created. Rick Dees, at the time a radio DJ in Memphis, Tennessee, recorded "Disco Duck" (1976) and "Dis-Gorilla" (1977); Frank Zappa parodied the lifestyles of disco dancers in "Disco Boy" on his 1976 "Zoot Allures" album and in "Dancin' Fool" on his 1979 "Sheik Yerbouti" album. "Weird Al" Yankovic's eponymous 1983 debut album includes a disco song called "Gotta Boogie", an extended pun on the similarity of the disco move to the American slang word "booger". Comedian Bill Cosby devoted his entire 1977 album "Disco Bill" to disco parodies. In 1980, "Mad Magazine" released a flexi-disc titled "Mad Disco" featuring six full-length parodies of the genre. Rock and roll songs critical of disco included Bob Seger's "Old Time Rock and Roll" and, especially, the Who's "Sister Disco" (both 1978)—although the Who's "Eminence Front" (four years later) had a disco feel.

By the end of the 1970s, anti-disco sentiment developed among rock music fans and musicians, particularly in the United States. Disco was criticized as mindless, consumerist, overproduced and escapist. The slogans "Disco sucks" and "Death to disco" became common. Rock artists such as Rod Stewart and David Bowie who added disco elements to their music were accused of selling out.

The punk subculture in the United States and the United Kingdom was often hostile to disco, although, in the UK, many early Sex Pistols fans such as the Bromley Contingent and Jordan liked disco, often congregating at nightclubs such as Louise's in Soho and the Sombrero in Kensington. The track "Love Hangover" by Diana Ross, the house anthem at the former, was cited as a particular favourite by many early UK punks.
The film "The Great Rock 'n' Roll Swindle" and its soundtrack album contained a disco medley of Sex Pistols songs, entitled "Black Arabs" and credited to a group of the same name.

However, Jello Biafra of the Dead Kennedys, in the song "Saturday Night Holocaust", likened disco to the cabaret culture of Weimar-era Germany for its apathy towards government policies and its escapism. Mark Mothersbaugh of Devo said that disco was "like a beautiful woman with a great body and no brains", and a product of political apathy of that era. New Jersey rock critic Jim Testa wrote "Put a Bullet Through the Jukebox", a vitriolic screed attacking disco that was considered a punk call to arms. Steve Hillage, shortly prior to his transformation from a progressive rock musician into an electronic artist at the end of the 1970s with the inspiration of disco, disappointed his rockist fans by admitting his love for disco, with Hillage recalling "it's like I'd killed their pet cat."

Anti-disco sentiment was expressed in some television shows and films. A recurring theme on the show "WKRP in Cincinnati" was a hostile attitude towards disco music. In one scene of the 1980 comedy film "Airplane!", a wayward airplane slices a radio tower with its wing, knocking out an all-disco radio station. July 12, 1979, became known as "the day disco died" because of the Disco Demolition Night, an anti-disco demonstration in a baseball double-header at Comiskey Park in Chicago. Rock station DJs Steve Dahl and Garry Meier, along with Michael Veeck, son of Chicago White Sox owner Bill Veeck, staged the promotional event for disgruntled rock fans between the games of a White Sox doubleheader which involved exploding disco records in centerfield. As the second game was about to begin, the raucous crowd stormed onto the field and proceeded to set fires and tear out seats and pieces of turf. The Chicago Police Department made numerous arrests, and the extensive damage to the field forced the White Sox to forfeit the second game to the Detroit Tigers, who had won the first game.

Disco's decline in popularity after Disco Demolition Night was rapid. On July 12, 1979, the top six records on the U.S. music charts were disco songs. By September 22, there were no disco songs in the US Top 10 chart, with the exception of Herb Alpert's instrumental "Rise", a smooth jazz composition with some disco overtones. Some in the media, in celebratory tones, declared disco "dead" and rock revived. Karen Mixon Cook, the first female disco DJ, stated that people still pause every July 12 for a moment of silence in honor of disco. Dahl stated in a 2004 interview that disco was "probably on its way out [at the time]. But I think it [Disco Demolition Night] hastened its demise".

The anti-disco movement, combined with other societal and radio industry factors, changed the face of pop radio in the years following Disco Demolition Night. Starting in the 1980s, country music began a slow rise on the pop chart. Emblematic of country music's rise to mainstream popularity was the commercially successful 1980 movie "Urban Cowboy". The continued popularity of power pop and the revival of oldies in the late 1970s was also related to disco's decline; the 1978 film "Grease" was emblematic of this trend. Coincidentally, the star of both films was John Travolta, who in 1977 had starred in "Saturday Night Fever", which remains one of the most iconic disco films of the era.

During this period of decline in disco's popularity, several record companies folded, were reorganized, or were sold. In 1979, MCA Records purchased ABC Records, absorbed some of its artists and then shut the label down. Midsong International Records ceased operations in 1980. RSO Records founder Robert Stigwood left the label in 1981 and TK Records closed in the same year. Salsoul Records continues to exist in the 2000s, but primarily is used as a reissue brand. Casablanca Records had been releasing fewer records in the 1980s, and was shut down in 1986 by parent company PolyGram.

Many groups that were popular during the disco period subsequently struggled to maintain their success—even ones who tried to adapt to evolving musical tastes. The Bee Gees, for instance, had only one top-10 entry (1989's "One") and three more top-40 songs (despite completely abandoning disco in their 1980s and 1990s songs), even though numerous songs they wrote and had other artists perform were successful. Of the handful of groups not taken down by disco's fall from favor, Kool and the Gang, Donna Summer, the Jacksons, and Gloria Gaynor in particular—stand out. In spite of having helped define the disco sound early on, they continued to make popular and danceable, if more refined, songs for yet another generation of music fans in the 1980s and beyond. Earth, Wind & Fire also survived the anti-disco trend and continued to produce successful singles at roughly the same pace for several more years, in addition to an even longer string of R&B chart hits that lasted into the 1990s.

Six months prior to Disco Demolition Night (in December 1978), popular progressive rock radio station WDAI (WLS-FM) had suddenly switched to an all-disco format, disenfranchising thousands of Chicago rock fans and leaving Dahl unemployed. WDAI, who survived the change of public sentiment and still had good ratings at this point, continued to play disco until it flipped to a short-lived hybrid Top 40/rock format in May 1980. Another disco outlet that competed against WDAI at the time, WGCI-FM, would later incorporate R&B and pop songs into the format, eventually evolving into an urban contemporary outlet that it continues with today. The latter also helped bring the Chicago house genre to the airwaves.

Factors that have been cited as leading to the decline of disco in the United States include economic and political changes at the end of the 1970s, as well as burnout from the hedonistic lifestyles led by participants. In the years since Disco Demolition Night, some social critics have described the "Disco sucks" movement as implicitly macho and bigoted, and an attack on non-white and non-heterosexual cultures. It was also interpreted being part of a wider cultural "backlash", the move towards conservatism, that also made its way into US politics with the election of conservative president Ronald Reagan in 1980, which also led to Republican control of the United States Senate for the first time since 1954, plus the subsequent rise of the Religious Right around the same time.

In January 1979, rock critic Robert Christgau argued that homophobia, and most likely racism, were reasons behind the movement, a conclusion seconded by John Rockwell. Craig Werner wrote: "The Anti-disco movement represented an unholy alliance of funkateers and feminists, progressives, and puritans, rockers and reactionaries. Nonetheless, the attacks on disco gave respectable voice to the ugliest kinds of unacknowledged racism, sexism and homophobia." Legs McNeil, founder of the fanzine "Punk", was quoted in an interview as saying, "the hippies always wanted to be black. We were going, 'fuck the blues, fuck the black experience.'" He also said that disco was the result of an "unholy" union between homosexuals and blacks.

Steve Dahl, who had spearheaded Disco Demolition Night, denied any racist or homophobic undertones to the promotion, saying, "It's really easy to look at it historically, from this perspective, and attach all those things to it. But we weren't thinking like that," it was "just kids pissing on a musical genre". It has been noted that British punk rock critics of disco were very supportive of the pro-black/anti-racist reggae genre as well as the more pro-gay new romantics movement. Christgau and Jim Testa have said that there were legitimate artistic reasons for being critical of disco.

In 1979, the music industry in the United States underwent its worst slump in decades, and disco, despite its mass popularity, was blamed. The producer-oriented sound was having difficulty mixing well with the industry's artist-oriented marketing system. Harold Childs, senior vice president at A&M Records, reportedly told the "Los Angeles Times" that "radio is really desperate for rock product" and "they're all looking for some white rock-n-roll". Gloria Gaynor argued that the music industry supported the destruction of disco because rock music producers were losing money and rock musicians were losing the spotlight.

Disco was instrumental in the development of electronic dance music genres like house, techno, and eurodance. The Eurodisco song "I Feel Love", produced by Giorgio Moroder for Donna Summer in 1976, has been described as a milestone and blueprint for electronic dance music because it was the first to combine repetitive synthesizer loops with a continuous four-on-the-floor bass drum and an off-beat hi-hat, which would become a main feature of techno and house ten years later.

During the first years of the 1980s, the traditional disco sound characterized by complex arrangements performed by large ensembles of studio session musicians (including a horn section and an orchestral string section) began to be phased out, and faster tempos and synthesized effects, accompanied by guitar and simplified backgrounds, moved dance music toward electronic and pop genres, starting with hi-NRG. Despite its decline in popularity, so-called club music and European-style disco remained relatively successful in the early-to-mid 1980s with songs like Aneka's "Japanese Boy", The Weather Girls's "It's Raining Men", Stacey Q's "Two of Hearts", Dead or Alive's "You Spin Me Round (Like a Record)", Laura Branigan's "Self Control", and Baltimora's "Tarzan Boy". However, a revival of the traditional-style disco called nu-disco has been popular since the 1990s.

House music displayed a strong disco influence, which is why house music, regarding its enormous success in shaping electronic dance music and contemporary club culture, is often described being "disco's revenge." Early house music was generally dance-based music characterized by repetitive four-on-the-floor beats, rhythms mainly provided by drum machines, off-beat hi-hat cymbals, and synthesized basslines. While house displayed several characteristics similar to disco music, it was more electronic and minimalist, and the repetitive rhythm of house was more important than the song itself. As well, house did not use the lush string sections that were a key part of the disco sound.

The rising popularity of disco came in tandem with developments in the role of the DJ. DJing developed from the use of multiple record turntables and DJ mixers to create a continuous, seamless mix of songs, with one song transitioning to another with no break in the music to interrupt the dancing. The resulting DJ mix differed from previous forms of dance music in the 1960s, which were oriented towards live performances by musicians. It, in turn, affected the arrangement of dance music, since songs in the disco era typically contained beginnings and endings marked by a simple beat or riff that could be easily used to transition to a new song. The development of DJing was also influenced by new turntablism techniques, such as beatmatching and scratching, a process facilitated by the introduction of new turntable technologies such as the Technics SL-1200 MK 2, first sold in 1978, which had a precise variable pitch control and a direct drive motor. DJs were often avid record collectors, who would hunt through used record stores for obscure soul records and vintage funk recordings. DJs helped to introduce rare records and new artists to club audiences.
In the 1970s, individual DJs became more prominent, and some DJs, such as Larry Levan, the resident at Paradise Garage, Jim Burgess, Tee Scott, and Francis Grasso became famous in the disco scene. Levan, for example, developed a cult following among clubgoers, who referred to his DJ sets as "Saturday Mass". Some DJs would use reel-to-reel tape recorders to make remixes and tape edits of songs. Some DJs who were making remixes made the transition from the DJ booth to becoming a record producer, notably Burgess. Scott developed several innovations. He was the first disco DJ to use three turntables as sound sources, the first to simultaneously play two beat-matched records, the first to use electronic effects units in his mixes, and he was an innovator in mixing dialogue in from well-known movies, typically over a percussion break. These mixing techniques were also applied to radio DJs, such as Ted Currier of WKTU and WBLS. Grasso is particularly notable for taking the DJ "profession out of servitude and [making] the DJ the musical head chef." Once he entered the scene, the DJ was no longer responsible for waiting on the crowd hand and foot, meeting their every song request. Instead, with increased agency and visibility, the DJ was now able to use their own technical and creative skills to whip up a nightly special of innovative mixes, refining their personal sound and aesthetic, and building their own reputation.

The post-disco sound and genres associated with it originated in the 1970s and early 1980s with R&B and post-punk musicians focusing on a more electronic and experimental side of disco, spawning boogie, Italo disco, and alternative dance. Drawing from a diverse range of non-disco influences and techniques, such as the "one-man band" style of Kashif and Stevie Wonder and alternative approaches of Parliament-Funkadelic, it was driven by synthesizers, keyboards, and drum machines. Post-disco acts include D. Train, Patrice Rushen, ESG, Bill Laswell, Arthur Russell. Post-disco had an important influence on dance-pop and was bridging classical disco and later forms of electronic dance music.

The disco sound had a strong influence on early hip hop. Most of the early hip-hop songs were created by isolating existing disco bass guitar lines and dubbing over them with MC rhymes. The Sugarhill Gang used Chic's "Good Times" as the foundation for their 1979 song "Rapper's Delight", generally considered to be the song that first popularized rap music in the United States and around the world.

With synthesizers and Krautrock influences that replaced the previous disco foundation, a new genre was born when Afrika Bambaataa released the single "Planet Rock", spawning a hip hop electronic dance trend that includes songs such as Planet Patrol's "Play at Your Own Risk" (1982), C-Bank's "One More Shot" (1982), Cerrone's "Club Underworld" (1984), Shannon's "Let the Music Play" (1983), Freeez's "I.O.U." (1983), Midnight Star's "Freak-a-Zoid" (1983), and Chaka Khan's "I Feel For You" (1984).

House music is a genre of electronic dance music that originated in Chicago in the early 1980s (also see: Chicago house). It quickly spread to other American cities such as Detroit, where it developed into the harder and more industrial techno, New York City (also see: garage house), and Newark – all of which developed their own regional scenes.

In the mid-to-late 1980s, house music became popular in Europe as well as major cities in South America and Australia. Early house music commercial success in Europe saw songs such as "Pump Up The Volume" by MARRS (1987), "House Nation" by House Master Boyz and the Rude Boy of House (1987), "Theme from S'Express" by S'Express (1988) and "Doctorin' the House" by Coldcut (1988) in the pop charts. Since the early to mid-1990s, house music has been infused in mainstream pop and dance music worldwide.

House music in the 2010s, while keeping several of these core elements, notably the prominent kick drum on every beat, varies widely in style and influence, ranging from the soulful and atmospheric deep house to the more aggressive acid house or the minimalist microhouse. House music has also fused with several other genres creating fusion subgenres, such as euro house, tech house, electro house, and jump house.

In the late 1980s and early 1990s, rave culture began to emerge from the house and acid house scene. Like house, it incorporated disco culture's same love of dance music played by DJs over powerful sound systems, recreational drug and club drug exploration, sexual promiscuity, and hedonism. Although disco culture started out underground, it eventually thrived in the mainstream by the late 1970s, and major labels commodified and packaged the music for mass consumption. In contrast, the rave culture started out underground and stayed (mostly) underground. In part, this was to avoid the animosity that was still surrounding disco and dance music. The rave scene also stayed underground to avoid law enforcement attention that was directed at the rave culture due to its use of secret, unauthorized warehouses for some dance events and its association with illegal club drugs like ecstasy.

The post-punk movement that originated in the late 1970s both supported punk rock's rule-breaking while rejecting its move back to raw rock music. Post-punk's mantra of constantly moving forward lent itself to both openness to and experimentation with elements of disco and other styles. Public Image Limited is considered the first post-punk group. The group's second album "Metal Box" fully embraced the "studio as instrument" methodology of disco. The group's founder John Lydon, the former lead singer for the Sex Pistols, told the press that disco was the only music he cared for at the time.

No wave was a subgenre of post-punk centered in New York City. For shock value, James Chance, a notable member of the no wave scene, penned an article in the "East Village Eye" urging his readers to move uptown and get "trancin' with some superradioactive disco voodoo funk". His band James White and the Blacks wrote a disco album titled "Off White". Their performances resembled those of disco performers (horn section, dancers and so on). In 1981 ZE Records led the transition from no wave into the more subtle mutant disco (post-disco/punk) genre. Mutant disco acts such as Kid Creole and the Coconuts, Was Not Was, ESG and Liquid Liquid influenced several British post-punk acts such as New Order, Orange Juice and A Certain Ratio.

Nu-disco is a 21st-century dance music genre associated with the renewed interest in 1970s and early 1980s disco, mid-1980s Italo disco, and the synthesizer-heavy Euro disco aesthetics. The moniker appeared in print as early as 2002, and by mid-2008 was used by record shops such as the online retailers Juno and Beatport. These vendors often associate it with re-edits of original-era disco music, as well as with music from European producers who make dance music inspired by original-era American disco, electro, and other genres popular in the late 1970s and early 1980s. It is also used to describe the music on several American labels who were previously associated with the genres electroclash and French house.

In the 1990s, after a decade of backlash, disco and its legacy became more accepted by pop music artists and listeners alike, as more songs, films, and compilations were released that referenced disco. This was part of a wave of 1970s nostalgia that was taking place in popular culture at the time. Some commentators attributed the revival of the genre to frequent use of disco music in fashion shows.

Examples of songs during this time that were influenced by disco included Deee-Lite's "Groove Is in the Heart" (1990), U2's "Lemon" (1993), Blur's "Girls & Boys" (1994) and "Entertain Me" (1995), Pulp's "Disco 2000" (1995), and Jamiroquai's "Canned Heat" (1999), while films such as "Boogie Nights" (1997) and "The Last Days of Disco" (1998) featured primarily disco soundtracks.

In the early 2000s, an updated genre of disco called "nu-disco" began breaking into the mainstream. A few examples like Daft Punk's "One More Time" and Kylie Minogue's "Love at First Sight" and "Can't Get You Out of My Head" became club favorites and commercial successes. Several nu-disco songs were crossovers with funky house, such as Spiller's "Groovejet (If This Ain't Love)" and Modjo's "Lady (Hear Me Tonight)", both songs sampling older disco songs and both reaching number one on the UK Singles Chart in 2000. Robbie Williams's disco single "Rock DJ" was the UK's fourth best-selling single the same year. Jamiroquai's song "Little L" and "Murder on the Dancefloor" by Sophie Ellis-Bextor were hits in 2001. Rock band Manic Street Preachers released a disco song, "Miss Europa Disco Dancer", in the same year. The song's disco influence, which appears on "Know Your Enemy", was described as being "much-discussed". In 2005, Madonna immersed herself in the disco music of the 1970s and released her album "Confessions on a Dance Floor" to rave reviews. One of the singles from the album, "Hung Up", which samples ABBA's 1979 song "Gimme! Gimme! Gimme! (A Man After Midnight)", became a major club staple. In addition to Madonna's disco-influenced attire to award shows and interviews, her Confessions Tour incorporated various elements of the 1970s, such as disco balls, a mirrored stage design, and the roller derby. In 2006, Jessica Simpson released her album "A Public Affair" inspired by disco and the 1980s music. The first single of the album, """A Public Affair", was reviewed as a disco-dancing competition influenced by Madonna's early works. The video of the song was filmed on a skating rink and features a line dance of hands.

The success of the "nu-disco" revival of the early 2000s was described by music critic Tom Ewing as more interpersonal than the pop music of the 1990s: "The revival of disco within pop put a spotlight on something that had gone missing over the 90s: a sense of music not just for dancing, but for dancing with someone. Disco was a music of mutual attraction: cruising, flirtation, negotiation. Its dancefloor is a space for immediate pleasure, but also for promises kept and otherwise. It's a place where things start, but their resolution, let alone their meaning, is never clear. All of 2000s great disco number ones explore how to play this hand. Madison Avenue look to impose their will upon it, to set terms and roles. Spiller is less rigid. 'Groovejet' accepts the night's changeability, happily sells out certainty for an amused smile and a few great one-liners."

In 2011, K-pop girl group T-ara released Roly-Poly as a part of their EP John Travolta Wannabe. The song accumulated over 4,000,000 units in digital downloads, which became the highest number of downloads for a K-pop girl group single on the Gaon Digital Chart in the 2010s. In 2013, with several 1970s-style disco and funk being released, the pop charts had more dance songs than at any other point since the late 1970s. The biggest disco song of the year was "Get Lucky" by Daft Punk, featuring Nile Rodgers on guitar. Its parent album, "Random Access Memories", ended up winning Album of the Year at the 2014 Grammys. Other disco-styled songs that made it into the top 40 that year were Robin Thicke's "Blurred Lines" (number one), Justin Timberlake's "Take Back the Night" (number 29), Bruno Mars' "Treasure" (number five) Arcade Fire's "Reflektor" featured strong disco elements. In 2014, disco music could be found in Lady Gaga's "Artpop" and Katy Perry's "Birthday". Other disco songs from 2014 include "I Want It All" By Karmin, 'Wrong Club" by the Ting Tings, "Blow" by Beyoncé and the William Orbit mix of "Let Me in Your Heart Again" by Queen.

In 2014 Brazilian Globo TV, the second biggest television network in the world, aired Boogie Oogie, a telenovela about the Disco Era that takes place between 1978 and 1979, from the hit fever to the decadence. The show's success was responsible for a Disco revival across the country, bringing back to the stage and to Brazilian record charts local disco divas like Lady Zu and As Frenéticas.

Top-10 entries from 2015 such as Mark Ronson's disco groove-infused "Uptown Funk", Maroon 5's "Sugar", the Weeknd's "Can't Feel My Face" and Jason Derulo's "Want To Want Me" also have a strong disco influence. Disco mogul and producer Giorgio Moroder also re-appeared in 2015 with his new album "Déjà Vu", which proved to be a modest success. Other songs from 2015 like "I Don't Like It, I Love It" by Flo Rida, "Adventure of a Lifetime" by Coldplay, "Back Together" by Robin Thicke and "Levels" by Nick Jonas feature disco elements as well. In 2016, disco songs or disco-styled pop songs continued showing a strong presence on the music charts as a possible backlash to the 1980s-styled synthpop, electro house, and dubstep that had been dominating the charts up until then. Justin Timberlake's 2016 song "Can't Stop the Feeling!", which shows strong elements of disco, became the 26th song to debut at number-one on the "Billboard" Hot 100 in the history of the chart. "The Martian", a 2015 film, extensively uses disco music as a soundtrack, although for the main character, astronaut Mark Watney, there's only one thing worse than being stranded on Mars: it's being stranded on Mars with nothing but disco music. "Kill the Lights", featured on an episode of the HBO television series "Vinyl" (2016) and with Nile Rodgers' guitar licks, hit number one on the US Dance chart in July 2016.

In 2020, disco continued its mainstream popularity and became a prominent trend in popular music. In early 2020, disco-influenced hits such as Doja Cat's "Say So", Lady Gaga's "Stupid Love", and Dua Lipa's "Don't Start Now" experienced widespread success on global music charts, charting at numbers 1, 5 and 2, respectively, on the US Billboard Hot 100 chart. At the time, "Billboard", declared that Lipa was "leading the charge toward disco-influenced production" a day after her retro and disco-influenced album "Future Nostalgia" was released on March 27, 2020. By the end of 2020, multiple disco albums had been released, including Adam Lambert's "Velvet", Jessie Ware's "What's Your Pleasure?", and Róisín Murphy's discothèque mixtape, "Róisín Machine". In early September 2020, South Korean group BTS debuted at number 1 in the US with their English–language disco single "Dynamite" having sold 265,000 downloads in its first week in the US, marking the biggest pure sales week since Taylor Swift's "Look What You Made Me Do" (2017).

In July 2020, Australian singer Kylie Minogue announced she would be releasing her fifteenth studio album, "Disco", on November 6, 2020. The album was preceded by two singles. The lead single, "Say Something", was released on July 23 and premiered on BBC Radio 2; the second single, "Magic", was released on September 24. Both singles received critical acclaim, with critics praising Minogue for returning to disco roots, which were prominent in her albums "Light Years" (2000), "Fever" (2001), and "Aphrodite" (2010).





Darwin

Darwin most often refers to:

Darwin may also refer to:















Donegal fiddle tradition

The Donegal fiddle tradition is the way of playing the fiddle that is traditional in County Donegal, Ireland. It is one of the distinct fiddle traditions within Irish traditional music.

The distinctness of the Donegal tradition developed due to the close relations between Donegal and Scotland, and the Donegal repertoire and style has influences from Scottish fiddle music. For example, in addition to the ”universally known” standard Irish dance tunes, there is an added volume of Scottish and Nova Scotia tunes played, with even some tunes from Shetland and Orkney. This includes standard tune types such as double jigs (), slip jigs (), reels (), and hornpipes (swung ). It has been claimed that Donegal musicians play more slip jigs than any other region of Ireland. This is potentially due to the geographical borders/mountains (as well as national borders with Northern Ireland) keeping Donegal's repertoire more locally-known for decades. There is also a prevalence of mazurka playing. Mazurkas are historically mainland-European tunes very similar to a waltz, in its meter, though generally livelier and with more emphasis being placed on the second beat of each measure. Another uniquely Donegal tune is called the barndance, stemming from the Germanic schottische (essentially meaning ‘Scottish’), also similar to the Norwegian reinlander. The barndance is very similar to a hornpipe, but slower than a reel; typically they are played with less of a hornpipe's “swing” and more of the “drive” of a reel.

In stark contrast to other Irish musical styles, the Donegal tradition also has the Scottish strathspey, a traditional dance from Scotland, played a bit like a hornpipe but with emphasis on the semi-quaver; this dotted rhythm gives the strathspey its distinct “Scotch Snap” sound. While strathspeys are definitely known in Donegal (albeit played slightly slower and with less ”snap” than Scottish fiddlers), more common is the highland. Very rarely referred to as a “highland fling”, these quintessentially Donegal tunes are influenced by the Scottish strathspey, but played a bit smoother, as a sort of “strathspey-reel”. Some Scotch Snaps will be played, but highlands tend to be more akin to a slower reel, overall. Reels, themselves, are said to have originated in Scottish music. The distinctiveness of the Donegal tradition led to some conflict, between Donegal players and representatives of the mainstream tradition, when Irish traditional music was organised in the 1960s.

The tradition has several distinguishing traits compared to other fiddle traditions such as the Sliabh Luachra style of southern Ireland, most of which involves styles of bowing and the ornamentation of the music, and rhythm. Due to the frequency of double stops and the strong bowing it is often compared to the Cape Breton tradition. Another characteristic of the style is the rapid pace at which it tends to proceed. Modern players, such as the fiddle group Altan, continue to be popular due to a variety of reasons.

Among the most famous Donegal style players are John Doherty from the early twentieth century and James Byrne, Paddy Glackin, Tommy Peoples and Mairéad Ní Mhaonaigh in recent decades.

The fiddle has ancient roots in Ireland, the first report of bowed instruments similar to the violin being in the Book of Leinster (ca. 1160). The modern violin was ubiquitous in Ireland by the early 1700s. However the first mention of the fiddle being in use in Donegal is from the blind harper Arthur O'Neill who in his 1760 memoirs described a wedding in Ardara as having "plenty of pipers and fiddlers". Donegal fiddlers participated in the development of the Irish music tradition in the 18th century during which jigs and slipjigs and later reels and hornpipes became the dominant musical forms. However, Donegal musicians, many of them being fishermen, also frequently travelled to Scotland, where they acquired tune types from the Scottish repertoire such as the Strathspey which was integrated into the Donegal tradition as "Highland" tunes. The Donegal tradition derives much of its unique character from the synthesis of Irish and Scottish stylistic features and repertoires. Aoidh notes however that while different types of art music were commonly played among the upper classes of Scottish society in the 18th century, the Donegal tradition drew exclusively from the popular types of Scottish music. Like some Scottish fiddlers (who, like Donegal fiddlers, tend to use a short bow and play in a straight-ahead fashion), some Donegal fiddlers worked at imitating the sound of the bagpipes. Workers from Donegal would bring their music to Scotland and also bring back Scottish tunes with them such music of J. Scott Skinner and Mackenzie Murdoch. Lilting, unaccompanied singing of wordless tunes, was also an important part of the Donegal musical tradition often performed by women in social settings. Describing the musical life of Arranmore Island in the late 19th century singer Róise Rua Nic Gríanna describes the most popular dances: "The Sets, the Lancers, the Maggie Pickie [i.e., Maggie Pickins] the Donkey, the Mazurka and the Barn dances". Among the travelling fiddlers of the late 19th century players such as John Mhosaí McGinley, Anthony Hilferty, the McConnells and the Dohertys are best known. As skill levels increased through apprenticeships several fiddle masters appeared such as the Cassidy's, Connie Haughey, Jimmy Lyons and Miock McShane of Teelin and Francie Dearg and Mickey Bán Byrne of Kilcar. These virtuosos played unaccompanied listening pieces in addition to the more common dance music.

The influences between Scotland and Donegal went both ways and were furthered by a wave of immigration from Donegal to Scotland in the 19th century (the regions share common names of dances), as can be heard in the volume of strathspeys, schottisches, marches, and Donegal's own strong piping tradition, has influenced and been influenced by music, and by the sounds, ornaments, and repertoire of the Píob Mhór, the traditional bagpipes of Ireland and Scotland. There are other differences between the Donegal style and the rest of Ireland. Instruments such as the tin whistle, flute, concertina and accordion were very rare in Donegal until modern times. Traditionally the píob mór and the fiddle were the only instruments used and the use of pipe or fiddle music was common in old wedding customs. Migrant workers carried their music to Scotland and also brought back a number of tunes of Scottish origin. The Donegal fiddlers may well have been the route by which Scottish tunes such as Lucy Campbell, Tarbolton Lodge (Tarbolton) and The Flagon (The Flogging Reel), that entered the Irish repertoire. These players prided themselves on their technical abilities, which included playing in higher positions (fairly uncommon among traditional Irish fiddlers), and sought out material which would demonstrate their skills.

As Irish music was consolidated and organised under the Comhaltas Ceoltóirí Éireann movement in the 1960s, both strengthened the interest in traditional music but sometimes conflicted with the Donegal tradition and its social conventions. The rigidly organised sessions of the Comhaltas reflected the traditions of Southern Ireland and Donegal fiddlers like John Doherty considered the National repertoire with its strong focus on reels to be less diverse than that of Donegal with its varied rhythms. Other old fiddlers dislike the ways comhaltas sessions were organised with a committee player, often not himself a musician, in charge. Sometimes Comhaltas representatives would even disparage the Donegal tradition, with its Scottish flavour, as being un-Irish, and prohibit them from playing local tunes with Scottish genealogies such as the "Highlands" at Comhaltas sessions. This sometimes cause antagonism between Donegal players and the main organisation of traditional music in Ireland.

Outside of the Comhaltas movement however, Donegal fiddling stood strong with Paddy Glackin of Ceoltorí Laighean and the Bothy Band and later Tommy Peoples also with the Bothy Band and Mairead Ni Mhaonaigh with Altan, who all drew attention and prestige to the Donegal tradition within folk music circles throughout Ireland.

The Donegal style of fiddling is a label often applied to music from this area, though one also might plausibly identify several different, but related, styles within the county. To the extent to which there is one common style in the county, it is characterised by a rapid pace; a tendency to be more un-swung in the playing of the fast dance tune types (reel and jigs); short (non-slurred), aggressive bowing, sparse ornamentation, the use of bowed triplets more often than trills as ornaments, the use of double stops and droning; and the occurrence of "playing the octave", with one player playing the melody and the other playing the melody an octave lower. None of these characteristics are universal, and there is some disagreement as to the extent to which there is a common style at all. In general, however, the style is rather aggressive.

Another feature of Donegal fiddling that makes it distinctive among Irish musical traditions is the variety of rare tune types that are played. Highlands, a type of tune in time with some similarities to Scottish strathspeys, which are also played in Donegal, are one of the most commonly played types of tune in the county. Other tune types common solely in the county include barndances, also called "Germans," and mazurkas.

There are a number of different strands to the history of fiddle playing in County Donegal. Perhaps the best-known and, in the last half of the twentieth century, the most influential has been that of the Doherty family. Hugh Doherty is the first known musician of this family. Born in 1790, he headed an unbroken tradition of fiddlers and pipers in the Doherty family until the death, in 1980, of perhaps the best-known Donegal fiddler, John Doherty. John, a travelling tinsmith, was known for his extremely precise and fast finger- and bow-work and vast repertoire, and is considered to be one of the greatest Irish fiddlers ever recorded. John's older brother, Mickey, was also recorded and, though Mickey was another of the great Irish fiddlers, his reputation has been overshadowed by John's.

There is no single Donegal style but several distinctive styles. These styles traditionally come from the geographical isolated regions of Donegal including Inishowen, eastern Donegal, The Rosses and Gweedore, Croaghs, Teelin, Kilcar, Glencolmcille, Ballyshannon and Bundoran. Even with improved communications and transport, these regions still have recognisably different ways of fiddle playing. Notable deceased players of the older Donegal styles include Neillidh ("Neilly") Boyle, Francie Byrne, Con Cassidy, Frank Cassidy, James Byrne (1946–2008), P.V. O'Donnell (2011), and Tommy Peoples (1948–2018). Currently living Donegal fiddlers, include, Vincent Campbell, John Gallagher, Paddy Glackin, and Danny O'Donnell.

Fiddle playing continues to be popular in Donegal. The three fiddlers of the Donegal "supergroup" Altan, Mairéad Ní Mhaonaigh, Paul O'Shaughnessy, and Ciarán Tourish, are generally admired within Donegal. An example of another fiddler-player from Donegal is Liz Doherty.
Another well regarded fiddle player hailing from Donegal is Aidan O'Donnell. TG4 Young Musician of the Year 2010 Aidan O'Donnell has been described as one of the finest young Irish musicians at present. He began his music making at the age of 12, and since then has performed with some of traditional music's finest artists, including Donal Lunny, Micheal Ó'Suilleabháin and the Chieftains. In 2007, he won the prestigious ‘Oireachtas na Geailge' fiddle title, and has been a regular tutor at the Irish World Academy of Music and Dance, at the University of Limerick for the past number of years.

The fiddle, and traditional music in general, remained popular in Donegal not only because of the international coverage of certain artists but because of local pride in the music. Traditional music "Seisiúns" are still common place both in pubs and in houses. The Donegal fiddle music has been influenced by recorded music, but this is claimed to have had a positive impact on the tradition. Modern Donegal fiddle music is often played in concerts and recorded on albums.


Double-barreled shotgun

A double-barreled shotgun, also known as a double shotgun, is a break-action shotgun with two parallel barrels, allowing two single shots that can be fired simultaneously or sequentially in quick succession.

Modern double-barreled shotguns, often known as "doubles", are almost universally break action, with the barrels hinge down at the rear to expose the breech ends for unloading and reloading. Since there is no reciprocating action needed to eject and reload the shells, doubles are more compact than repeating designs such as pump action, lever action, bolt action, or self-loading shotguns.

Double-barreled shotguns (specifically break-action), come in two basic configurations:

The original double-barreled guns were nearly all side-by-side designs, which was a more practical design for muzzleloaders. Early cartridge-firing shotguns also used the side-by-side action, because they kept the exposed hammers of the earlier muzzleloading shotguns from which they evolved. When hammerless designs started to become common, the over-and-under design was introduced, and most modern sporting doubles are over-and-under designs.

One significant advantage that doubles have over single-barrel repeating shotguns is the ability to have more than one choke at a time. Some shotgun shooting sports, such as skeet shooting, use crossing targets presented in a narrow range of distance, and only require one level of choke. Other sports, like sporting clays, give the shooter targets at differing ranges, and targets that might approach or recede from the shooter, and so must be engaged at differing ranges. Having two barrels lets the shooter use a more open choke for near targets, and a tighter choke for distant targets, providing the optimal shot pattern for each distance.

The disadvantage lies in the fact that the barrels of a double-barreled shotgun, whether over-and-under or side-by-side, are not parallel, but slightly angled, so that shots from the barrels converge, usually at "40 yards out". For the side-by-side configuration, the shotstring continues on its path to the opposite side of the rib after the converging point; for example, the left barrel's discharge travels on the left of the rib till it hits dead center at 40 yards (36.58 m) out, after that, the discharge continues on to the right. In the over-and-under configuration with a parallel rib, both barrels' discharges will keep to the dead center, but the discharge from the "under" barrel will shoot higher than the discharge from the "over" barrel after 40 yards (36.58 m). Thus, double-barreled shotguns are accurate only at practical shotgun ranges, though the range of their ammunition easily exceeds four to six times that distance.

Side-by-side shotguns are often more expensive, and may take more practice to aim effectively than an over-and-under. The off-center nature of the recoil in a side-by-side gun may make shooting the body-side barrel slightly more painful by comparison to an over-and-under, single-shot, or pump-action, lever-action shotgun. Gas-operated and Recoil-operated, designs will recoil less than either. More side-by-side than over-and-under guns have traditional "cast-off" stocks, where the end of the buttstock veers slightly to the right, allowing a right-handed user to point the gun more easily.

Double-barreled shotguns are also inherently more safe, as whether the shotgun is loaded or can be fired can be ascertained by anyone present if the action is broken open, for instance on a skeet, trap or hunting clays course when another shooter is firing; if the action is open, the gun cannot fire. Similarly, doubles are more easily examined to see if loaded than pump-action or semi-automatic shotguns, whose bolt must be opened and chamber closely examined or felt to make sure it is unloaded; with a double gun (or a break-action single gun), whether the gun is loaded, i.e., has cartridges in any chamber, is easily and immediately seen with a glance (and just as easily unloaded).

The early doubles used two triggers, one for each barrel, located front to back inside the trigger guard. The index finger was used to pull either trigger, as having two fingers inside the trigger guard can cause a very undesirable recoil-induced double-discharge. Double-trigger designs are typically set up for right-handed users. In double-trigger designs, it is often possible to pull both triggers at once, firing both barrels simultaneously, though this is generally not recommended as it doubles the recoil, battering both shotgun and shooter, particularly if it was unanticipated or unintended. Discharging both barrels at the same time has long been a hunting trick employed by hunters using 8 gauge "elephant" shotguns, firing the two slugs for sheer stopping power at close range.

Later models use a single trigger that alternately fires both barrels, called a "single selective trigger" or "SST". The single selective trigger does not allow firing both barrels at once, since the single trigger must be pulled twice in order to fire both barrels. The change from one barrel to the other may be done by a clockwork type system, where a cam alternates between barrels, or by an inertial system where the recoil of firing the first barrel toggles the trigger to the next barrel. A double-barreled shotgun with an inertial trigger works best with full power shotshells; shooting low recoil shotshells often will not reliably toggle the inertial trigger, causing an apparent failure to fire occasionally when attempting to depress the trigger a second time to fire the second barrel (this also can happen if the first shell fails to fire). Generally there is a method of selecting the order in which the barrels of a single selective trigger shotgun fire; commonly this is done through manipulation of the safety, pushing to one side to select top barrel first and the other side to select bottom barrel first. In the event that an inertial trigger does not toggle to the second barrel when firing low recoil shotshells, manually selecting the order to the second barrel will enable the second barrel to fire when the trigger is depressed again.

One of the advantages of double-barreled shotgun with double triggers or single selective trigger, is that the second shot can be taken almost immediately after the first with merely a second trigger pull, without needing to manually operate the action (which will inevitably destabilize the gun from the shoulder position and affect aim), and can utilize different chokes for the two shots (assuming, of course, that full power shotshells are fired, at least for a double-barreled shotgun with an inertial type single selective trigger, as needed to toggle the inertial trigger). This can be noticeably faster than a pump-action shotgun, which requires manually pumping the fore-end to eject and reload for the second shot, and may be faster, or not slower, than a semi-automatic shotgun (as there are no bolt movements to delay the rechambering of a second shell). Note, however, in neither the pump-action or semi-automatic will the second shot be a different choke pattern from the first shot, whereas for a double, the two shots are usually with different chokes. Thus, depending on the nature of the hunt, the appropriate choke for the shot is always at hand. For example, while field hunting flushing birds, the first shot is usually closer than the second because the bird flies away from the shooter; so, the more open choke (and barrel) would be better for the first shot, and if a second shot is needed, as the bird is flying away, the more closed (and thus longer distance of an effective shot pattern) choke (and barrel) is then appropriate. Conversely, on a driven hunt, where the birds are driven towards the shooter, the closed (longer effective distance) choke (and barrel) should be fired first, saving the open (closer effective distance) choke (and barrel) for the now-closer incoming bird. None of this is possible with single-barrel shotguns, only with a double, either a side-by-side (S×S) or over-and-under (O/U).

"Regulation" is a term used for multi-barreled firearms (most commonly found in rifles and shotguns) that indicates how close to the same point of aim the barrels will shoot. A poorly regulated gun may hit consistently with one barrel, but miss consistently with the other, making the gun nearly useless for anything requiring two shots. However, the short ranges and spread of shot provide a significant overlap, so a small error in regulation in a double is often too small to be noticed. Generally the shotguns are regulated to hit the point of aim at a given distance, usually the maximum expected range since that is the range at which a full choke is used, and where precise regulation matters most. The regulation is usually more important in side-by-side, rather than in over-and-under shotguns, as felt recoil differs.


Dessert

Dessert is a course that concludes a meal. The course consists of sweet foods, such as cake, and possibly a beverage such as dessert wine and liqueur. Some cultures sweeten foods that are more commonly savory to create desserts. In some parts of the world there is no tradition of a dessert course to conclude a meal.

The term "dessert" can apply to many sweets, such as biscuits, cakes, cookies, custards, gelatins, ice creams, pastries, pies, puddings, macaroons, sweet soups, tarts, and fruit salad (fruit is commonly found in dessert courses because of its naturally occurring sweetness).

The word "dessert" originated from the French word "desservir," meaning "to clear the table". Its first known use in English was in 1600, in a health education manual entitled "Naturall and artificial Directions for Health", written by William Vaughan. In his book "Sweet Invention: A History of Dessert" (2011), Michael Krondl explains that it refers to the fact that dessert was served after the table had been cleared of other dishes.

The term dates from the 14th century but attained its current meaning around the beginning of the 20th century, when "service à la française" (setting a variety of dishes on the table at the same time) was replaced with "service à la russe" (presenting a meal in multiple courses).

The word "dessert" is most commonly used for this course in Australia, Canada, Ireland, New Zealand, and the United States, while it is one of several synonyms, including ""pudding"", ""sweet"" and ""afters"", in the United Kingdom and some other Commonwealth countries.

Sweets were fed to the gods in ancient Mesopotamia and ancient India and other ancient civilizations. Herodotus mentions that Persian meals featured many desserts, and were more varied in their sweet offerings than the main dishes. German army officer Helmuth von Moltke whilst serving in the Ottoman Empire noted the unusual presentation of courses with the sweet courses served between roasts and other savory dishes.

Dried fruit and honey were probably the first sweeteners used in most of the world, but the spread of sugarcane around the world was essential to the development of dessert. Sugarcane was grown and refined in India before 500 BC and was crystallized, making it easy to transport, by AD 500. Sugar and sugarcane were traded, making sugar available to Macedonia by 303 BC and China by AD 600. In the Indian subcontinent, the Middle East, and China, sugar has been a staple of cooking and desserts for over a thousand years.

Sugarcane and sugar were little known and rare in Europe until the twelfth century or later when the Crusades and then colonization spread its use. Europeans began to manufacture sugar in the Middle Ages, and more sweet desserts became available. Even then sugar was so expensive usually only the wealthy could indulge on special occasions. The first apple pie recipe was published in 1381; The earliest documentation of the term "cupcake" was in "Seventy-five Receipts for Pastry, Cakes, and Sweetmeats" in 1828 in Eliza Leslie's "Receipts" cookbook.

The Industrial Revolution in Europe and later America led to the mass-production of foodstuffs, including desserts, that could be processed, preserved, canned, and packaged. Frozen foods, including desserts, became very popular starting in the 1920s.

Sweet desserts usually contain cane sugar, palm sugar, brown sugar, honey, or some types of syrup such as molasses, maple syrup, treacle, or corn syrup. Other common ingredients in Western-style desserts are flour or other starches, cooking fats such as butter or lard, dairy, eggs, salt, acidic ingredients such as lemon juice, and spices and other flavoring agents such as chocolate, coffee, peanut butter, fruits, and nuts. The proportions of these ingredients, along with the preparation methods, play a major part in the consistency, texture, and flavor of the end product.

Sugars contribute moisture and tenderness to baked goods. Flour or starch components serves as a protein and gives the dessert structure. Fats contribute moisture and can enable the development of flaky layers in pastries and pie crusts. The dairy products in baked goods keep the desserts moist. Many desserts also contain eggs, in order to form custard or to aid in the rising and thickening of a cake-like substance. Egg yolks specifically contribute to the richness of desserts. Egg whites can act as a leavening agent or provide structure. Further innovation in the healthy eating movement has led to more information being available about vegan and gluten-free substitutes for the standard ingredients, as well as replacements for refined sugar.

Desserts can contain many spices and extracts to add a variety of flavors. Salt and acids are added to desserts to balance sweet flavors and create a contrast in flavors. Some desserts are coffee-flavored, for example an iced coffee soufflé or coffee biscuits. Alcohols and liqueurs can also be used as an ingredient, to make alcoholic desserts.

Dessert consist of variations of tastes, textures, and appearances. Desserts can be defined as a usually sweeter course that concludes a meal. This definition includes a range of courses ranging from fruits or dried nuts to multi-ingredient cakes and pies. Many cultures have different variations of dessert. In modern times the variations of desserts have usually been passed down or come from geographical regions. This is one cause for the variation of desserts. These are some major categories in which desserts can be placed.

Cakes are sweet tender breads made with sugar and delicate flour. Cakes can vary from light, airy sponge cakes to dense cakes with less flour. Common flavorings include dried, candied or fresh fruit, nuts, cocoa or extracts. They may be filled with fruit preserves or dessert sauces (like pastry cream), iced with buttercream or other icings, and decorated with marzipan, piped borders, or candied fruit. Cake is often served as a celebratory dish on ceremonial occasions, for example weddings, anniversaries, and birthdays. Small-sized cakes have become popular, in the form of cupcakes and petits fours, an example of which can be the Portuguese "bolo de arroz".

Puddings are similar to custards in that their base is cream or milk. However, their primary difference is that puddings are thickened with starches such as corn starch or tapioca. On the other hand, custards are thickened using only eggs and are usually more firm.

A batched dough between a cake and pastry by the mix of ingredients. An Old French "bescuit", commonly spelt in English as biscuit, is a derivation of Latin for "twice-baked". A Dutch "koekje", commonly spelt in English as cookie, is a derivation of "cake-ie ", meaning little cake.

This form of dough can have a texture that is crisp, hard, chewy, or soft – in the UK a biscuit is the former two and a cookie is typically the latter. Examples include a ginger nut, shortbread biscuit and chocolate chip cookie.

Other small cakes and pastries can also be counted as under these terms, due to their size and relative similarity to cookies and biscuits, such as jaffa cakes and Eccles cakes.

Confection, also called candy, sweets or lollies, features sugar or honey as a principal ingredient.

Many involve sugar heated into crystals with subtle differences. Dairy and sugar based include caramel, fudge and toffee or taffy. They are multiple forms of egg and sugar meringues. and similar confections. Unheated sugar co-adulate into icings, preservatives and sauces with other ingredients.

"Theobroma cacao beans" can be a substitute or more commonly mixed with sugar to form chocolate. Pure, unsweetened dark chocolate contains primarily cocoa solids. Cocoa butter is also added in varying proportions. Much of the chocolate currently consumed is in the form of sweet chocolate, combining chocolate with sugar. Milk chocolate is sweet chocolate that additionally contains milk powder or condensed milk. White chocolate contains cocoa butter, sugar, and milk, but no cocoa solids. Dark chocolate is produced by adding fat and sugar to the cacao mixture, with no milk or much less than milk chocolate.
Mithai, derived from the Sanskrit word "'sharkara'," represents the range of Indian desserts.

These kinds of desserts usually include a thickened dairy base. Custards are cooked and thickened with eggs. Baked custards include crème brûlée and flan. They are often used as ingredients in other desserts, for instance as a filling for pastries or pies.
Many cuisines include a dessert made of deep-fried starch-based batter or dough. In many countries, a doughnut is a flour-based batter that has been deep-fried. It is sometimes filled with custard or jelly. Fritters are fruit pieces in a thick batter that have been deep fried. Gulab jamun is an Indian dessert made of milk solids kneaded into a dough, deep-fried, and soaked in honey. Churros are a deep-fried and sugared dough that is eaten as dessert or a snack in many countries.

Ice cream, gelato, sorbet and shaved-ice desserts fit into this category. Ice cream is a cream base that is churned as it is frozen to create a creamy consistency. Gelato uses a milk base and has less air whipped in than ice cream, making it denser. Sorbet is made from churned fruit and is not dairy based. Shaved-ice desserts are made by shaving a block of ice and adding flavored syrup or juice to the ice shavings.

Jellied desserts are made with a sweetened liquid thickened with gelatin or another gelling agent. They are traditional in many cultures. Grass jelly and annin tofu are Chinese jellied desserts. Yōkan is a Japanese jellied dessert. In English-speaking countries, many dessert recipes are based on gelatin with fruit or whipped cream added. The vegetarian substitute for gelatin is agar agar. Marshmallow is also most commonly made with gelatin.

 Pastries are sweet baked pastry products. Pastries can either take the form of light and flaky bread with an airy texture, such as a croissant or unleavened dough with a high fat content and crispy texture, such as shortbread. Pastries are often flavored or filled with fruits, chocolate, nuts, and spices. Pastries are sometimes eaten with tea or coffee as a breakfast food.

Pies and cobblers consist of a filling enclosed by a crust, which can be made from either pastry or crumbs. The fillings of pies can vary from fruits to puddings, whereas cobbler fillings are mostly fruit-based. On the other hand, clafoutis is a dessert in which batter is poured over a fruit-based filling before being baked.

Tong sui, literally translated as "sugar water" and also known as tim tong, is a collective term for any sweet, warm soup or custard served as a dessert at the end of a meal in Cantonese cuisine. "Tong sui" are a Cantonese specialty and are rarely found in other regional cuisines of China. Outside of Cantonese-speaking communities, soupy desserts generally are not recognized as a distinct category, and the term "tong sui" is not used.

Dessert wines are sweet wines typically served with dessert. There is no simple definition of a dessert wine. In the UK, a dessert wine is considered to be any sweet wine drunk with a meal, as opposed to the white fortified wines (fino and amontillado sherry) drunk before the meal, and the red fortified wines (port and madeira) drunk after it. Thus, most fortified wines are regarded as distinct from dessert wines, but some of the less strong fortified white wines, such as Pedro Ximénez sherry and Muscat de Beaumes-de-Venise, are regarded as honorary dessert wines. In the United States, by contrast, a dessert wine is legally defined as any wine over 14% alcohol by volume, which includes all fortified wines - and is taxed at higher rates as a result. Examples include Sauternes and Tokaji Aszú.

Throughout much of central and western Africa, there is no tradition of a dessert course following a meal. Fruit or fruit salad would be eaten instead, which may be spiced, or sweetened with a sauce. In some former colonies in the region, the colonial power has influenced desserts – for example, the Angolan "cocada amarela" (yellow coconut) resembles baked desserts in Portugal.

In Asia, desserts are often eaten between meals as snacks rather than as a concluding course. There is widespread use of rice flour in East Asian desserts, which often include local ingredients such as coconut milk, palm sugar, and tropical fruit. In India, where sugarcane has been grown and refined since before 500 BC, desserts have been an important part of the diet for thousands of years; types of desserts include burfis, halvahs, jalebis, and laddus.

Bubble tea, which originated in Taiwan, is a kind of dessert made with flavored tea or milk and tapioca. It is well known across the world.

In Ukraine and Russia, breakfast foods such as nalysnyky or blintz or oladi (pancake), and syrniki are served with honey and jam as desserts.

In the Netherlands vla is a popular dessert. It is a custard-like dessert that is served cold. Popular flavours are: vanilla, chocolate, caramel, and several fruit flavours. There is also hopjesvla which is flavoured like a Hopje, a Dutch coffee and caramel sweet.

The traditional dessert for informal meals in France consists of cheese or fresh fruit with coffee. However, the French tradition of pastry is highly developed, and desserts in haute cuisine may be very elaborate, with generous use of cream and butter.

Because of their long Christian history, all countries of Europe have developed traditional desserts and sweet snacks for the Christmas season.

European colonization of the Americas yielded the introduction of a number of ingredients and cooking styles. The various styles continued expanding well into the 19th and 20th centuries, proportional to the influx of immigrants.

Dulce de leche is a very common confection in Argentina. In Bolivia, sugarcane, honey and coconut are traditionally used in desserts. "Tawa tawa" is a Bolivian sweet fritter prepared using sugar cane, and "helado de canela" is a dessert that is similar to sherbet which is prepared with cane sugar and cinnamon. Coconut tarts, puddings cookies and candies are also consumed in Bolivia. Brazil has a variety of candies such as brigadeiros (chocolate fudge balls), cocada (a coconut sweet), beijinhos (coconut truffles and clove) and Romeu e Julieta (cheese with a guava jam known as goiabada). Peanuts are used to make paçoca, rapadura and pé-de-moleque. Local common fruits are turned in juices and used to make chocolates, ice pops and ice cream. In Chile, "kuchen" has been described as a "trademark dessert". Several desserts in Chile are prepared with "manjar", (caramelized milk), including "alfajor", "flan", "cuchufli" and "arroz con leche". Desserts consumed in Colombia include dulce de leche, waffle cookies, puddings, nougat, coconut with syrup and thickened milk with sugarcane syrup. Desserts in Ecuador tend to be simple, and desserts are a moderate part of the cuisine. Desserts consumed in Ecuador include tres leches cake, flan, candies and various sweets.

In Australia, meals are often finished with dessert. This includes various fruits. More complex desserts include cakes, pies and cookies, which are sometimes served during special occasions.

New Zealand and Australia have a long-standing debate over which country invented the Pavlova. The pavlova is named after Anna Pavlova, who visited both countries in the 1920s.

The market for desserts has grown over the last few decades, being greatly increased by the commercialisation of baking desserts and the rise of food productions. Desserts are served in most restaurants as their popularity has increased. Many commercial stores have been established as solely dessert stores. Ice cream parlors have been around since before 1800. Many businesses have started advertising campaigns focusing solely on desserts. The tactics used to market desserts are very different depending on the audience; for example, desserts can be advertised with popular movie characters to target children. The rise of companies such as Food Network has produced many shows which feature desserts and their creation. Shows like these have displayed extreme desserts and made a game show atmosphere to make desserts a more competitive field.

Desserts are a standard staple in restaurant menus, with different degrees of variety. Pie and cheesecake were among the most popular dessert courses ordered in U.S. restaurants in 2012.

Dessert foods often contain relatively high amounts of sugar and fats and, as a result, higher calorie counts per gram than other foods. Fresh or cooked fruit with minimal added sugar or fat is an exception.



Data Encryption Standard

The Data Encryption Standard (DES ) is a symmetric-key algorithm for the encryption of digital data. Although its short key length of 56 bits makes it too insecure for modern applications, it has been highly influential in the advancement of cryptography.

Developed in the early 1970s at IBM and based on an earlier design by Horst Feistel, the algorithm was submitted to the National Bureau of Standards (NBS) following the agency's invitation to propose a candidate for the protection of sensitive, unclassified electronic government data. In 1976, after consultation with the National Security Agency (NSA), the NBS selected a slightly modified version (strengthened against differential cryptanalysis, but weakened against brute-force attacks), which was published as an official Federal Information Processing Standard (FIPS) for the United States in 1977.

The publication of an NSA-approved encryption standard led to its quick international adoption and widespread academic scrutiny. Controversies arose from classified design elements, a relatively short key length of the symmetric-key block cipher design, and the involvement of the NSA, raising suspicions about a backdoor. The S-boxes that had prompted those suspicions were designed by the NSA to remove a backdoor they secretly knew (differential cryptanalysis). However, the NSA also ensured that the key size was drastically reduced so that they could break the cipher by brute force attack. The intense academic scrutiny the algorithm received over time led to the modern understanding of block ciphers and their cryptanalysis.

DES is insecure due to the relatively short 56-bit key size. In January 1999, distributed.net and the Electronic Frontier Foundation collaborated to publicly break a DES key in 22 hours and 15 minutes (see ). However, internal keys are much larger than 56 bits. The DES uses the 56-bit key to generate the 16 * 48-bit subkeys, or 768 bits. The 56-bit limitation of the key is artificial, so it can be enlarged up to 768 bits. In 2014 the DES-768 was released, it uses the same principle as the DES but the 16 subkeys are generated by a one-way hash function. The result is an algorithm that works at the same speed as the DES, but with a 768-bit key. The same is true for the Triple DES with independent subkeys, which allows you to obtain a key of 2304 bits.

There are also some analytical results which demonstrate theoretical weaknesses in the cipher, although they are infeasible in practice. The algorithm is believed to be practically secure in the form of Triple DES, although there are theoretical attacks. This cipher has been superseded by the Advanced Encryption Standard (AES). DES has been withdrawn as a standard by the National Institute of Standards and Technology.

Some documents distinguish between the DES standard and its algorithm, referring to the algorithm as the DEA (Data Encryption Algorithm).

The origins of DES date to 1972, when a National Bureau of Standards study of US government computer security identified a need for a government-wide standard for encrypting unclassified, sensitive information.

Around the same time, engineer Mohamed Atalla in 1972 founded Atalla Corporation and developed the first hardware security module (HSM), the so-called "Atalla Box" which was commercialized in 1973. It protected offline devices with a secure PIN generating key, and was a commercial success. Banks and credit card companies were fearful that Atalla would dominate the market, which spurred the development of an international encryption standard. Atalla was an early competitor to IBM in the banking market, and was cited as an influence by IBM employees who worked on the DES standard. The IBM 3624 later adopted a similar PIN verification system to the earlier Atalla system.

On 15 May 1973, after consulting with the NSA, NBS solicited proposals for a cipher that would meet rigorous design criteria. None of the submissions was suitable. A second request was issued on 27 August 1974. This time, IBM submitted a candidate which was deemed acceptable—a cipher developed during the period 1973–1974 based on an earlier algorithm, Horst Feistel's Lucifer cipher. The team at IBM involved in cipher design and analysis included Feistel, Walter Tuchman, Don Coppersmith, Alan Konheim, Carl Meyer, Mike Matyas, Roy Adler, Edna Grossman, Bill Notz, Lynn Smith, and Bryant Tuckerman.

On 17 March 1975, the proposed DES was published in the "Federal Register". Public comments were requested, and in the following year two open workshops were held to discuss the proposed standard. There was criticism received from public-key cryptography pioneers Martin Hellman and Whitfield Diffie, citing a shortened key length and the mysterious "S-boxes" as evidence of improper interference from the NSA. The suspicion was that the algorithm had been covertly weakened by the intelligence agency so that they—but no one else—could easily read encrypted messages. Alan Konheim (one of the designers of DES) commented, "We sent the S-boxes off to Washington. They came back and were all different." The United States Senate Select Committee on Intelligence reviewed the NSA's actions to determine whether there had been any improper involvement. In the unclassified summary of their findings, published in 1978, the Committee wrote:

However, it also found that

Another member of the DES team, Walter Tuchman, stated "We developed the DES algorithm entirely within IBM using IBMers. The NSA did not dictate a single wire!"
In contrast, a declassified NSA book on cryptologic history states:

and
Some of the suspicions about hidden weaknesses in the S-boxes were allayed in 1990, with the independent discovery and open publication by Eli Biham and Adi Shamir of differential cryptanalysis, a general method for breaking block ciphers. The S-boxes of DES were much more resistant to the attack than if they had been chosen at random, strongly suggesting that IBM knew about the technique in the 1970s. This was indeed the case; in 1994, Don Coppersmith published some of the original design criteria for the S-boxes. According to Steven Levy, IBM Watson researchers discovered differential cryptanalytic attacks in 1974 and were asked by the NSA to keep the technique secret. Coppersmith explains IBM's secrecy decision by saying, "that was because [differential cryptanalysis] can be a very powerful tool, used against many schemes, and there was concern that such information in the public domain could adversely affect national security." Levy quotes Walter Tuchman: "[t]hey asked us to stamp all our documents confidential... We actually put a number on each one and locked them up in safes, because they were considered U.S. government classified. They said do it. So I did it". Bruce Schneier observed that "It took the academic community two decades to figure out that the NSA 'tweaks' actually improved the security of DES."

Despite the criticisms, DES was approved as a federal standard in November 1976, and published on 15 January 1977 as FIPS PUB 46, authorized for use on all unclassified data. It was subsequently reaffirmed as the standard in 1983, 1988 (revised as FIPS-46-1), 1993 (FIPS-46-2), and again in 1999 (FIPS-46-3), the latter prescribing "Triple DES" (see below). On 26 May 2002, DES was finally superseded by the Advanced Encryption Standard (AES), following a public competition. On 19 May 2005, FIPS 46-3 was officially withdrawn, but NIST has approved Triple DES through the year 2030 for sensitive government information.

The algorithm is also specified in ANSI X3.92 (Today X3 is known as INCITS and ANSI X3.92 as ANSI INCITS 92), NIST SP 800-67 and ISO/IEC 18033-3 (as a component of TDEA).

Another theoretical attack, linear cryptanalysis, was published in 1994, but it was the Electronic Frontier Foundation's DES cracker in 1998 that demonstrated that DES could be attacked very practically, and highlighted the need for a replacement algorithm. These and other methods of cryptanalysis are discussed in more detail later in this article.

The introduction of DES is considered to have been a catalyst for the academic study of cryptography, particularly of methods to crack block ciphers. According to a NIST retrospective about DES,

DES is the archetypal block cipher—an algorithm that takes a fixed-length string of plaintext bits and transforms it through a series of complicated operations into another ciphertext bitstring of the same length. In the case of DES, the block size is 64 bits. DES also uses a key to customize the transformation, so that decryption can supposedly only be performed by those who know the particular key used to encrypt. The key ostensibly consists of 64 bits; however, only 56 of these are actually used by the algorithm. Eight bits are used solely for checking parity, and are thereafter discarded. Hence the effective key length is 56 bits.

The key is nominally stored or transmitted as 8 bytes, each with odd parity. According to ANSI X3.92-1981 (Now, known as ANSI INCITS 92–1981), section 3.5:

Like other block ciphers, DES by itself is not a secure means of encryption, but must instead be used in a mode of operation. FIPS-81 specifies several modes for use with DES. Further comments on the usage of DES are contained in FIPS-74.

Decryption uses the same structure as encryption, but with the keys used in reverse order. (This has the advantage that the same hardware or software can be used in both directions.)

The algorithm's overall structure is shown in Figure 1: there are 16 identical stages of processing, termed "rounds". There is also an initial and final permutation, termed "IP" and "FP", which are inverses (IP "undoes" the action of FP, and vice versa). IP and FP have no cryptographic significance, but were included in order to facilitate loading blocks in and out of mid-1970s 8-bit based hardware.

Before the main rounds, the block is divided into two 32-bit halves and processed alternately; this criss-crossing is known as the Feistel scheme. The Feistel structure ensures that decryption and encryption are very similar processes—the only difference is that the subkeys are applied in the reverse order when decrypting. The rest of the algorithm is identical. This greatly simplifies implementation, particularly in hardware, as there is no need for separate encryption and decryption algorithms.

The ⊕ symbol denotes the exclusive-OR (XOR) operation. The "F-function" scrambles half a block together with some of the key. The output from the F-function is then combined with the other half of the block, and the halves are swapped before the next round. After the final round, the halves are swapped; this is a feature of the Feistel structure which makes encryption and decryption similar processes.

The F-function, depicted in Figure 2, operates on half a block (32 bits) at a time and consists of four stages:


The alternation of substitution from the S-boxes, and permutation of bits from the P-box and E-expansion provides so-called "confusion and diffusion" respectively, a concept identified by Claude Shannon in the 1940s as a necessary condition for a secure yet practical cipher.

Figure 3 illustrates the "key schedule" for encryption—the algorithm which generates the subkeys. Initially, 56 bits of the key are selected from the initial 64 by "Permuted Choice 1" ("PC-1")—the remaining eight bits are either discarded or used as parity check bits. The 56 bits are then divided into two 28-bit halves; each half is thereafter treated separately. In successive rounds, both halves are rotated left by one or two bits (specified for each round), and then 48 subkey bits are selected by "Permuted Choice 2" ("PC-2")—24 bits from the left half, and 24 from the right. The rotations (denoted by "«<" in the diagram) mean that a different set of bits is used in each subkey; each bit is used in approximately 14 out of the 16 subkeys.

The key schedule for decryption is similar—the subkeys are in reverse order compared to encryption. Apart from that change, the process is the same as for encryption. The same 28 bits are passed to all rotation boxes.

Pseudocode for the DES algorithm follows.

Although more information has been published on the cryptanalysis of DES than any other block cipher, the most practical attack to date is still a brute-force approach. Various minor cryptanalytic properties are known, and three theoretical attacks are possible which, while having a theoretical complexity less than a brute-force attack, require an unrealistic number of known or chosen plaintexts to carry out, and are not a concern in practice.

For any cipher, the most basic method of attack is brute force—trying every possible key in turn. The length of the key determines the number of possible keys, and hence the feasibility of this approach. For DES, questions were raised about the adequacy of its key size early on, even before it was adopted as a standard, and it was the small key size, rather than theoretical cryptanalysis, which dictated a need for a replacement algorithm. As a result of discussions involving external consultants including the NSA, the key size was reduced from 256 bits to 56 bits to fit on a single chip.

In academia, various proposals for a DES-cracking machine were advanced. In 1977, Diffie and Hellman proposed a machine costing an estimated US$20 million which could find a DES key in a single day. By 1993, Wiener had proposed a key-search machine costing US$1 million which would find a key within 7 hours. However, none of these early proposals were ever implemented—or, at least, no implementations were publicly acknowledged. The vulnerability of DES was practically demonstrated in the late 1990s. In 1997, RSA Security sponsored a series of contests, offering a $10,000 prize to the first team that broke a message encrypted with DES for the contest. That contest was won by the DESCHALL Project, led by Rocke Verser, Matt Curtin, and Justin Dolske, using idle cycles of thousands of computers across the Internet. The feasibility of cracking DES quickly was demonstrated in 1998 when a custom DES-cracker was built by the Electronic Frontier Foundation (EFF), a cyberspace civil rights group, at the cost of approximately US$250,000 (see EFF DES cracker). Their motivation was to show that DES was breakable in practice as well as in theory: ""There are many people who will not believe a truth until they can see it with their own eyes. Showing them a physical machine that can crack DES in a few days is the only way to convince some people that they really cannot trust their security to DES."" The machine brute-forced a key in a little more than 2 days' worth of searching.

The next confirmed DES cracker was the COPACOBANA machine built in 2006 by teams of the Universities of Bochum and Kiel, both in Germany. Unlike the EFF machine, COPACOBANA consists of commercially available, reconfigurable integrated circuits. 120 of these field-programmable gate arrays (FPGAs) of type XILINX Spartan-3 1000 run in parallel. They are grouped in 20 DIMM modules, each containing 6 FPGAs. The use of reconfigurable hardware makes the machine applicable to other code breaking tasks as well. One of the more interesting aspects of COPACOBANA is its cost factor. One machine can be built for approximately $10,000. The cost decrease by roughly a factor of 25 over the EFF machine is an example of the continuous improvement of digital hardware—see Moore's law. Adjusting for inflation over 8 years yields an even higher improvement of about 30x. Since 2007, SciEngines GmbH, a spin-off company of the two project partners of COPACOBANA has enhanced and developed successors of COPACOBANA. In 2008 their COPACOBANA RIVYERA reduced the time to break DES to less than one day, using 128 Spartan-3 5000's. SciEngines RIVYERA held the record in brute-force breaking DES, having utilized 128 Spartan-3 5000 FPGAs. Their 256 Spartan-6 LX150 model has further lowered this time.

In 2012, David Hulton and Moxie Marlinspike announced a system with 48 Xilinx Virtex-6 LX240T FPGAs, each FPGA containing 40 fully pipelined DES cores running at 400 MHz, for a total capacity of 768 gigakeys/sec. The system can exhaustively search the entire 56-bit DES key space in about 26 hours and this service is offered for a fee online.

There are three attacks known that can break the full 16 rounds of DES with less complexity than a brute-force search: differential cryptanalysis (DC), linear cryptanalysis (LC), and Davies' attack. However, the attacks are theoretical and are generally considered infeasible to mount in practice; these types of attack are sometimes termed certificational weaknesses.


There have also been attacks proposed against reduced-round versions of the cipher, that is, versions of DES with fewer than 16 rounds. Such analysis gives an insight into how many rounds are needed for safety, and how much of a "security margin" the full version retains.

Differential-linear cryptanalysis was proposed by Langford and Hellman in 1994, and combines differential and linear cryptanalysis into a single attack. An enhanced version of the attack can break 9-round DES with 2 chosen plaintexts and has a 2 time complexity (Biham and others, 2002).

DES exhibits the complementation property, namely that
where formula_2 is the bitwise complement of formula_3 formula_4 denotes encryption with key formula_5 formula_6 and formula_7 denote plaintext and ciphertext blocks respectively. The complementation property means that the work for a brute-force attack could be reduced by a factor of 2 (or a single bit) under a chosen-plaintext assumption. By definition, this property also applies to TDES cipher.

DES also has four so-called "weak keys". Encryption ("E") and decryption ("D") under a weak key have the same effect (see involution):
There are also six pairs of "semi-weak keys". Encryption with one of the pair of semiweak keys, formula_10, operates identically to decryption with the other, formula_11:
It is easy enough to avoid the weak and semiweak keys in an implementation, either by testing for them explicitly, or simply by choosing keys randomly; the odds of picking a weak or semiweak key by chance are negligible. The keys are not really any weaker than any other keys anyway, as they do not give an attack any advantage.

DES has also been proved not to be a group, or more precisely, the set formula_14 (for all possible keys formula_15) under functional composition is not a group, nor "close" to being a group. This was an open question for some time, and if it had been the case, it would have been possible to break DES, and multiple encryption modes such as Triple DES would not increase the security, because repeated encryption (and decryptions) under different keys would be equivalent to encryption under another, single key.

Simplified DES (SDES) was designed for educational purposes only, to help students learn about modern cryptanalytic techniques.
SDES has similar structure and properties to DES, but has been simplified to make it much easier to perform encryption and decryption by hand with pencil and paper.
Some people feel that learning SDES gives insight into DES and other block ciphers, and insight into various cryptanalytic attacks against them.

DES uses 56-bit keys. However, the internal keys are much larger. The DES uses the 56-bit key to generate the 16 * 48-bit subkeys, or 768 bits. The 56-bit limitation of the key is artificial, so it can be enlarged up to 768 bits. In 2014 the DES-768 was released, it uses the same principle as the DES but the 16 subkeys are generated by a one-way hash function. The result is an algorithm that works at the same speed as the DES but with a 768-bit key. The same is true for Triple DES with independent subkeys, which results in a 2304-bit key.

Concerns about security and the relatively slow operation of DES in software motivated researchers to propose a variety of alternative block cipher designs, which started to appear in the late 1980s and early 1990s: examples include RC5, Blowfish, IDEA, NewDES, SAFER, CAST5 and FEAL. Most of these designs kept the 64-bit block size of DES, and could act as a "drop-in" replacement, although they typically used a 64-bit or 128-bit key. In the Soviet Union the GOST 28147-89 algorithm was introduced, with a 64-bit block size and a 256-bit key, which was also used in Russia later.

DES itself can be adapted and reused in a more secure scheme. Many former DES users now use Triple DES (TDES) which was described and analysed by one of DES's patentees (see FIPS Pub 46–3); it involves applying DES three times with two (2TDES) or three (3TDES) different keys. TDES is regarded as adequately secure, although it is quite slow. A less computationally expensive alternative is DES-X, which increases the key size by XORing extra key material before and after DES. GDES was a DES variant proposed as a way to speed up encryption, but it was shown to be susceptible to differential cryptanalysis.

On January 2, 1997, NIST announced that they wished to choose a successor to DES. In 2001, after an international competition, NIST selected a new cipher, the Advanced Encryption Standard (AES), as a replacement. The algorithm which was selected as the AES was submitted by its designers under the name Rijndael. Other finalists in the NIST AES competition included RC6, Serpent, MARS, and Twofish.



Double-hulled tanker

A double-hulled tanker refers to an oil tanker which has a double hull. They reduce the likelihood of leaks occurring compared to single-hulled tankers, and their ability to prevent or reduce oil spills led to double hulls being standardized for oil tankers and other types of ships including by the International Convention for the Prevention of Pollution from Ships or MARPOL Convention. After the "Exxon Valdez" oil spill disaster in Alaska in 1989, the US government required all new oil tankers built for use between US ports to be equipped with a full double hull.

A number of manufacturers have embraced oil tankers with a double hull because it strengthens the hull of ships, reducing the likelihood of oil disasters in low-impact collisions and groundings over single-hull ships. They reduce the likelihood of leaks occurring at low speed impacts in port areas when the ship is under pilotage. Research of impact damage of ships has revealed that double-hulled tankers are unlikely to perforate both hulls in a collision, preventing oil from seeping out. However, for smaller tankers, U-shaped tanks might be susceptible to "free flooding" across the double bottom and up to the outside water level each side of the cargo tank. Salvors prefer to salvage doubled-hulled tankers because they permit the use of air pressure to vacuum out the flood water. In the 1960s, collision proof double hulls for nuclear ships were extensively investigated, due to escalating concerns over nuclear accidents.

The ability of double-hulled tankers to prevent or reduce oil spills led to double hulls being standardized for other types of ships including oil tankers by the International Convention for the Prevention of Pollution from Ships or MARPOL Convention. In 1992, MARPOL was amended, making it "mandatory for tankers of 5,000 dwt and more ordered after 6 July 1993 to be fitted with double hulls, or an alternative design approved by IMO". However, in the aftermath of the Erika incident of the coast off France in December 1999, members of IMO adopted a revised schedule for the phase-out of single-hull tankers, which came into effect on 1 September 2003, with further amendments validated on 5 April 2005.

After the "Exxon Valdez" oil spill disaster, when that ship grounded on Bligh Reef outside the port of Valdez, Alaska in 1989, the US government required all new oil tankers built for use between US ports to be equipped with a full double hull. However, the damage to the Exxon Valdez penetrated sections of the hull (the slops oil tanks, or slop tanks) that were protected by a double bottom, or partial double hull.

Although double-hulled tankers reduce the likelihood of ships grazing rocks and creating holes in the hull, a double hull does not protect against major, high-energy collisions or groundings which cause the majority of oil pollution, despite this being the reason that the double hull was mandated by United States legislation. Double-hulled tankers, if poorly designed, constructed, maintained and operated can be as problematic, if not more problematic than their single-hulled counterparts. Double-hulled tankers have a more complex design and structure than their single-hulled counterparts, which means that they require more maintenance and care in operating, which if not subject to responsible monitoring and policing, may cause problems. Double hulls often result in the weight of the hull increasing by at least 20%, and because the steel weight of doubled-hulled tanks should not be greater than that of single-hulled ships, the individual hull walls are typically thinner and theoretically less resistant to wear. Double hulls by no means eliminate the possibility of the hulls breaking apart. Due to the air space between the hulls, there is also a potential problem with volatile gases seeping out through worn areas of the internal hull, increasing the risk of an explosion.

Although several international conventions against pollution are in place, as of 2003 there was still no formal body setting international mandatory standards, although the International Safety Guide for Oil Tankers and Terminals (ISGOTT) does provide guidelines giving advice on optimum use and safety, such as recommending that ballast tanks are not entered while loaded with cargo, and that weekly samples are made of the atmosphere inside for hydrocarbon gas. Due to the difficulties of maintenance, ship builders have been competitive in producing double-hulled ships which are easier to inspect, such as ballast and cargo tanks which are easily accessible and easier to spot corrosion in the hull. The Tanker Structure Cooperative Forum (TSCF) published the "Guide to Inspection and Maintenance of Double-Hull Tanker Structures" in 1995 giving advice based on experience of operating double-hulled tankers.


Drink

A drink or beverage is a liquid intended for human consumption. In addition to their basic function of satisfying thirst, drinks play important roles in human culture. Common types of drinks include plain drinking water, milk, juice, smoothies and soft drinks but it has a sugar, sweetened and carbonation acid on soft drinks. Traditionally warm beverages include coffee, tea, and hot chocolate. Caffeinated drinks that contain the stimulant caffeine have a long history.

In addition, alcoholic drinks such as wine, beer, and liquor, which contain the drug ethanol, have been part of human culture for more than 8,000 years. Non-alcoholic drinks often signify drinks that would normally contain alcohol, such as beer, wine and cocktails, but are made with a sufficiently low concentration of alcohol by volume. The category includes drinks that have undergone an alcohol removal process such as non-alcoholic beers and de-alcoholized wines.

When the human body becomes dehydrated, a person experiences thirst. This craving of fluids results in an instinctive "need to drink". Thirst is regulated by the hypothalamus in response to subtle changes in the body's electrolyte levels, and also as a result of changes in the volume of blood circulating. The complete deprivation of drinks (that is, water) will result in death faster than the removal of any other substance besides oxygen. Water and milk have been basic drinks throughout history. As water is essential for life, it has also been the carrier of many diseases.

As society developed, techniques were discovered to create alcoholic drinks from the plants that were available in different areas. The earliest archaeological evidence of wine production yet found has been at sites in Georgia ( BCE) and Iran ( BCE). Beer may have been known in Neolithic Europe as far back as 3000 BCE, and was mainly brewed on a domestic scale. The invention of beer (and bread) has been argued to be responsible for humanity's ability to develop technology and build civilization. Tea likely originated in Yunnan, China, during the Shang Dynasty (1500 BCE–1046 BCE) as a medicinal drink.

Drinking has been a large part of socialising throughout the centuries. In Ancient Greece, a social gathering for the purpose of drinking was known as a symposium, where watered down wine would be drunk. The purpose of these gatherings could be anything from serious discussions to direct indulgence. In Ancient Rome, a similar concept of a "convivium" took place regularly.

Many early societies considered alcohol a gift from the gods, leading to the creation of gods such as Dionysus. Other religions forbid, discourage, or restrict the drinking of alcoholic drinks for various reasons. In some regions with a dominant religion the production, sale, and consumption of alcoholic drinks is forbidden to everybody, regardless of religion.

Toasting is a method of honouring a person or wishing good will by taking a drink. Another tradition is that of the loving cup, at weddings or other celebrations such as sports victories a group will share a drink in a large receptacle, shared by everyone until empty.

In East Africa and Yemen, coffee was used in native religious ceremonies. As these ceremonies conflicted with the beliefs of the Christian church, the Ethiopian Church banned the secular consumption of coffee until the reign of Emperor Menelik II. The drink was also banned in Ottoman Turkey during the 17th century for political reasons and was associated with rebellious political activities in Europe.

A drink is a form of liquid which has been prepared for human consumption. The preparation can include a number of different steps, some prior to transport, others immediately prior to consumption.

Water is the chief constituent in all drinks, and the primary ingredient in most. Water is purified prior to drinking. Methods for purification include filtration and the addition of chemicals, such as chlorination. The importance of purified water is highlighted by the World Health Organization, who point out 94% of deaths from diarrhea – the third biggest cause of infectious death worldwide at 1.8 million annually – could be prevented by improving the quality of the victim's environment, particularly safe water.

Pasteurisation is the process of heating a liquid for a period of time at a specified temperature, then immediately cooling. The process reduces the growth of microorganisms within the liquid, thereby increasing the time before spoilage. It is primarily used on milk, which prior to pasteurisation is commonly infected with pathogenic bacteria and therefore is more likely than any other part of the common diet in the developed world to cause illness.

The process of extracting juice from fruits and vegetables can take a number of forms. Simple crushing of most fruits will provide a significant amount of liquid, though a more intense pressure can be applied to get the maximum amount of juice from the fruit. Both crushing and pressing are processes used in the production of wine.

Infusion is the process of extracting flavours from plant material by allowing the material to remain suspended within water. This process is used in the production of teas, herbal teas and can be used to prepare coffee (when using a coffee press).

The name is derived from the word "percolate" which means "to cause (a solvent) to pass through a permeable substance especially for extracting a soluble constituent".
In the case of coffee-brewing the solvent is water, the permeable substance is the coffee grounds, and the soluble constituents are the chemical compounds that give coffee its color, taste, aroma, and stimulating properties.

Carbonation is the process of dissolving carbon dioxide into a liquid, such as water.

Fermentation is a metabolic process that converts sugar to ethanol. Fermentation has been used by humans for the production of drinks since the Neolithic age. In winemaking, grape juice is combined with yeast in an anaerobic environment to allow the fermentation. The amount of sugar in the wine and the length of time given for fermentation determine the alcohol level and the sweetness of the wine.

When brewing beer, there are four primary ingredients – water, grain, yeast and hops. The grain is encouraged to germinate by soaking and drying in heat, a process known as malting. It is then milled before soaking again to create the sugars needed for fermentation. This process is known as mashing. Hops are added for flavouring, then the yeast is added to the mixture (now called wort) to start the fermentation process.

Distillation is a method of separating mixtures based on differences in volatility of components in a boiling liquid mixture. It is one of the methods used in the purification of water. It is also a method of producing spirits from milder alcoholic drinks.

An alcoholic mixed drink that contains two or more ingredients is referred to as a cocktail. Cocktails were originally a mixture of spirits, sugar, water, and bitters. The term is now often used for almost any mixed drink that contains alcohol, including mixers, mixed shots, etc. A cocktail today usually contains one or more kinds of spirit and one or more mixers, such as soda or fruit juice. Additional ingredients may be sugar, honey, milk, cream, and various herbs.

A non-alcoholic drink is one that contains little or no alcohol. This category includes low-alcohol beer, non-alcoholic wine, and apple cider if they contain a sufficiently low concentration of alcohol by volume (ABV). The exact definition of what is "non-alcoholic" and what is not depends on local laws: in the United Kingdom, "alcohol-free beer" is under 0.05% ABV, "de-alcoholised beer" is under 0.5%, while "low-alcohol beer" can contain no more than 1.2% ABV. The term "soft drink" specifies the absence of alcohol in contrast to "hard drink" and "drink". The term "drink" is theoretically neutral, but often is used in a way that suggests alcoholic content. Drinks such as soda pop, sparkling water, iced tea, lemonade, root beer, fruit punch, milk, hot chocolate, tea, coffee, milkshakes, tap water, bottled water, juice and energy drinks are all soft drinks.

Water is the world's most consumed drink, however, 97% of water on Earth is non-drinkable salt water. Fresh water is found in rivers, lakes, wetlands, groundwater, and frozen glaciers. Less than 1% of the Earth's fresh water supplies are accessible through surface water and underground sources which are cost effective to retrieve.

In western cultures, water is often drunk cold. In the Chinese culture, it is typically drunk hot.

Milk is regarded as one of the "original" drinks; milk is the primary source of nutrition for babies. In many cultures of the world, especially the Western world, humans continue to consume dairy milk beyond infancy, using the milk of other animals (especially cattle, goats and sheep) as a drink.

Carbonated drinks refer to drinks which have carbon dioxide dissolved into them. This can happen naturally through fermenting and in natural water spas or artificially by the dissolution of carbon dioxide under pressure. The first commercially available artificially carbonated drink is believed to have been produced by Thomas Henry in the late 1770s.
Cola, orange, various roots, ginger, and lemon/lime are commonly used to create non-alcoholic carbonated drinks; sugars and preservatives may be added later.

The most consumed carbonated soft drinks are produced by three major global brands: Coca-Cola, PepsiCo and the Dr Pepper Snapple Group.

Fruit juice is a natural product that contains few or no additives. Citrus products such as orange juice and tangerine juice are familiar breakfast drinks, while grapefruit juice, pineapple, apple, grape, lime, and lemon juice are also common. Coconut water is a highly nutritious and refreshing juice. Many kinds of berries are crushed; their juices are mixed with water and sometimes sweetened. Raspberry, blackberry and currants are popular juices drinks but the percentage of water also determines their nutritive value. Grape juice allowed to ferment produces wine.

Fruits are highly perishable so the ability to extract juices and store them was of significant value. Some fruits are highly acidic and mixing them with water and sugars or honey was often necessary to make them palatable. Fruits can also be blended with ice and other ingredients to make a smoothie. Early storage of fruit juices was labor-intensive, requiring the crushing of the fruits and the mixing of the resulting pure juices with sugars before bottling.

Vegetable juices are usually served warm or cold. Different types of vegetables can be used to make vegetable juice such as carrots, tomatoes, cucumbers, celery and many more. Some vegetable juices are mixed with some fruit juice to make the vegetable juice taste better. Many popular vegetable juices, particularly ones with high tomato content, are high in sodium, and therefore consumption of them for health must be carefully considered. Some vegetable juices provide the same health benefits as whole vegetables in terms of reducing risks of cardiovascular disease and cancer.

Plant milk is a general term for any milk-like product that is derived from a plant source. The most common varieties internationally are soy milk, almond milk, rice milk and coconut milk.

A nightcap is a drink taken shortly before bedtime to induce sleep. For example, a small alcoholic drink or a cup of warm milk can supposedly promote a good night's sleep. Today, most nightcaps and relaxation drinks are generally non-alcoholic beverages containing calming ingredients. They are considered beverages which serve to relax a person. Unlike other calming beverages, such as tea, warm milk or milk with honey; relaxation drinks almost universally contain more than one active ingredient. Relaxation drinks have been known to contain other natural ingredients and are usually free of caffeine and alcohol but some have claimed to contain marijuana.

A drink is considered "alcoholic" if it contains ethanol, commonly known as alcohol (although in chemistry the definition of "alcohol" includes many other compounds). Beer has been a part of human civilisation for around 8,000 years.

Beer is an alcoholic drink produced by the saccharification of starch and fermentation of the resulting sugar. The starch and saccharification enzymes are often derived from malted cereal grains, most commonly malted barley and malted wheat. Most beer is also flavoured with hops, which add bitterness and act as a natural preservative, though other flavourings such as herbs or fruit may occasionally be included. The preparation of beer is called brewing. Beer is the world's most widely consumed alcoholic drink, and is the third-most consumed drink overall, after water and tea. It is said to have been discovered by goddess Ninkasi around 5300 BCE, when she accidentally discovered yeast after leaving grain in jars that were later rained upon and left for several days. Women have been the chief creators of beer throughout history due to its association with domesticity and it, throughout much of history, being brewed in the home for family consumption. Only in recent history have men begun to dabble in the field. It is thought by some to be the oldest fermented drink.

Some of humanity's earliest known writings refer to the production and distribution of beer: the Code of Hammurabi included laws regulating beer and beer parlours, and "The Hymn to Ninkasi", a prayer to the Mesopotamian goddess of beer, served as both a prayer and as a method of remembering the recipe for beer in a culture with few literate people. Today, the brewing industry is a global business, consisting of several dominant multinational companies and many thousands of smaller producers ranging from brewpubs to regional breweries.

Cider is a fermented alcoholic drink made from fruit juice, most commonly and traditionally apple juice, but also the juice of peaches, pears ("Perry" cider) or other fruit. Cider may be made from any variety of apple, but certain cultivars grown solely for use in cider are known as cider apples. The United Kingdom has the highest per capita consumption of cider, as well as the largest cider-producing companies in the world, , the U.K. produces 600 million litres of cider each year (130 million imperial gallons).

Wine is an alcoholic drink made from fermented grapes or other fruits. The natural chemical balance of grapes lets them ferment without the addition of sugars, acids, enzymes, water, or other nutrients. Yeast consumes the sugars in the grapes and converts them into alcohol and carbon dioxide. Different varieties of grapes and strains of yeasts produce different styles of wine. The well-known variations result from the very complex interactions between the biochemical development of the fruit, reactions involved in fermentation, terroir and subsequent appellation, along with human intervention in the overall process. The final product may contain tens of thousands of chemical compounds in amounts varying from a few percent to a few parts per billion.

Wines made from produce besides grapes are usually named after the product from which they are produced (for example, rice wine, pomegranate wine, apple wine and elderberry wine) and are generically called fruit wine. The term "wine" can also refer to starch-fermented or fortified drinks having higher alcohol content, such as barley wine, huangjiu, or sake.

Wine has a rich history dating back thousands of years, with the earliest production so far discovered having occurred  BC in Georgia. It had reached the Balkans by  BC and was consumed and celebrated in ancient Greece and Rome.

From its earliest appearance in written records, wine has also played an important role in religion. Red wine was closely associated with blood by the ancient Egyptians, who, according to Plutarch, avoided its free consumption as late as the 7th-century BC Saite dynasty, "thinking it to be the blood of those who had once battled against the gods". The Greek cult and mysteries of Dionysus, carried on by the Romans in their Bacchanalia, were the origins of western theater. Judaism incorporates it in the Kiddush and Christianity in its Eucharist, while alcohol consumption was forbidden in Islam.

Spirits are distilled beverages that contain no added sugar and have at least 20% alcohol by volume (ABV). Popular spirits include borovička, brandy, gin, rum, slivovitz, tequila, vodka, and whisky. Brandy is a spirit created by distilling wine, whilst vodka may be distilled from any starch- or sugar-rich plant matter; most vodka today is produced from grains such as sorghum, corn, rye or wheat.

These drinks are often served warm or hot.

Coffee is a brewed drink prepared from the roasted seeds of several species of an evergreen shrub of the genus "Coffea". The two most common sources of coffee beans are the highly regarded "Coffea arabica", and the "robusta" form of the hardier "Coffea canephora". Coffee plants are cultivated in more than 70 countries. Once ripe, coffee "berries" are picked, processed, and dried to yield the seeds inside. The seeds are then roasted to varying degrees, depending on the desired flavor, before being ground and brewed to create coffee.

Coffee is slightly acidic (pH 5.0–5.1) and can have a stimulating effect on humans because of its caffeine content. It is one of the most popular drinks in the world. It can be prepared and presented in a variety of ways. The effect of coffee on human health has been a subject of many studies; however, results have varied in terms of coffee's relative benefit.

Coffee cultivation first took place in southern Arabia; the earliest credible evidence of coffee-drinking appears in the middle of the 15th century in the Sufi shrines of Yemen.

Coffee may have been used socially in the renaissance period of the 17th century. The increasing trades between Europe and North Africa regions made coffee more widely available to Europeans gathering at social locations that served coffee, possibly contributing to the growth of coffeehouses.

Hot chocolate, also known as drinking chocolate or cocoa, is a heated drink consisting of shaved chocolate, melted chocolate or cocoa powder, heated milk or water, and usually a sweetener. Hot chocolate may be topped with whipped cream. Hot chocolate made with melted chocolate is sometimes called drinking chocolate, characterized by less sweetness and a thicker consistency.

The first chocolate drink is believed to have been created by the Mayans around 2,500-3,000 years ago, and a cocoa drink was an essential part of Aztec culture by 1400 AD, by which they referred to as xocōlātl. The drink became popular in Europe after being introduced from Mexico in the New World and has undergone multiple changes since then. Until the 19th century, hot chocolate was even used medicinally to treat ailments such as liver and stomach diseases.

Hot chocolate is consumed throughout the world and comes in multiple variations, including the spiced "chocolate para mesa" of Latin America, the very thick "cioccolata calda" served in Italy and "chocolate a la taza" served in Spain, and the thinner hot cocoa consumed in the United States. Prepared hot chocolate can be purchased from a range of establishments, including cafeterias, fast food restaurants, coffeehouses and teahouses. Powdered hot chocolate mixes, which can be added to boiling water or hot milk to make the drink at home, are sold at grocery stores and online.

Tea, the second most consumed drink in the world, is produced from infusing dried leaves of the "Camellia sinensis" shrub, in boiling water. There are many ways in which tea is prepared for consumption: lemon or milk and sugar are among the most common additives worldwide. Other additions include butter and salt in Bhutan, Nepal, and Tibet; bubble tea in Taiwan; fresh ginger in Indonesia, Malaysia and Singapore; mint in North Africa and Senegal; cardamom in Central Asia; rum to make Jagertee in Central Europe; and coffee to make yuanyang in Hong Kong. Tea is also served differently from country to country: in China, Japan and South Korea tiny cups are used to serve tea; in Thailand and the United States tea is often served cold (as "iced tea") or with a lot of sweetener; Indians boil tea with milk and a blend of spices as masala chai; tea is brewed with a samovar in Iran, Kashmir, Russia and Turkey; and in the Australian Outback it is traditionally brewed in a billycan.
Tea leaves can be processed in different ways resulting in a drink which appears and tastes different. Chinese yellow and green tea are steamed, roasted and dried; Oolong tea is semi-oxidised and appears green-black and black teas are fully oxidised.

Around the world, people refer to other herbal infusions as "teas"; it is also argued that these were popular long before the "Camellia sinensis" shrub was used for tea making. Leaves, flowers, roots or bark can be used to make a herbal infusion and can be bought fresh, dried or powdered.

Throughout history, people have come together in establishments to socialise whilst drinking. This includes cafés and coffeehouses, focus on providing hot drinks as well as light snacks. Many coffee houses in the Middle East, and in West Asian immigrant districts in the Western world, offer "shisha" ("nargile" in Turkish and Greek), flavored tobacco smoked through a hookah. Espresso bars are a type of coffeehouse that specialize in serving espresso and espresso-based drinks.

In China and Japan, the establishment would be a tea house, where people would socialise while drinking tea. Chinese scholars have used the teahouse as a place to share ideas.

Alcoholic drinks are served in drinking establishments, which have different cultural connotations. For example, pubs are fundamental to the culture of Britain, Ireland, Australia, Canada, New England, Metro Detroit, South Africa and New Zealand. In many places, especially in villages, a pub can be the focal point of the community. The writings of Samuel Pepys describe the pub as the heart of England. Many pubs are controlled by breweries, so cask ale or keg beer may be a better value than wines and spirits.

In contrast, types of bars range from seedy bars or nightclubs, sometimes termed "dive bars", to elegant places of entertainment for the elite. Bars provide stools or chairs that are placed at tables or counters for their patrons. The term "bar" is derived from the specialized counter on which drinks are served. Some bars have entertainment on a stage, such as a live band, comedians, go-go dancers, or strippers. Patrons may sit or stand at the bar and be served by the bartender, or they may sit at tables and be served by cocktail servers.

Food and drink are often paired together to enhance the taste experience. This primarily happens with wine and a culture has grown up around the process. Weight, flavors and textures can either be contrasted or complemented. In recent years, food magazines began to suggest particular wines with recipes and restaurants would offer multi-course dinners matched with a specific wine for each course.

Different drinks have unique receptacles for their consumption. This is sometimes purely for presentations purposes, such as for cocktails. In other situations, the drinkware has practical application, such as coffee cups which are designed for insulation or brandy snifters which are designed to encourage evaporation but trap the aroma within the glass.

Many glasses include a stem, which allows the drinker to hold the glass without affecting the temperature of the drink. In champagne glasses, the bowl is designed to retain champagne's signature carbonation, by reducing the surface area at the opening of the bowl. Historically, champagne has been served in a champagne coupe, the shape of which allowed carbonation to dissipate even more rapidly than from a standard wine glass.

An important export commodity, coffee was the top agricultural export for twelve countries in 2004,
and it was the world's seventh-largest legal agricultural export by value in 2005. Green (unroasted) coffee is one of the most traded agricultural commodities in the world.

Some drinks, such as wine, can be used as an alternative investment. This can be achieved by either purchasing and reselling individual bottles or cases of particular wines, or purchasing shares in an investment wine fund that pools investors' capital.



Dill

Dill (Anethum graveolens) is an annual herb in the celery family Apiaceae. It is native to North Africa, Iran, and the Arabian Peninsula; it is grown widely in Eurasia, where its leaves and seeds are used as a herb or spice for flavouring food.

The word "dill" and its close relatives are found in most of the Germanic languages; its ultimate origin is unknown.

The genus name "Anethum" is the Latin form of Greek ἄνῑσον / ἄνησον / ἄνηθον / ἄνητον, which meant both "dill" and "anise". The form 'anīsum' came to be used for anise, and 'anēthum' for dill. The Latin word is the origin of dill's names in the Western Romance languages ('anet', 'aneldo' etc.), and also of the obsolete English 'anet'.

Dill grows up to from a taproot like a carrot. Its stems are slender and hollow with finely divided, softly delicate leaves; the leaves are alternately arranged, long with ultimate leaf divisions are broad, slightly broader than the similar leaves of fennel, which are threadlike, less than broad, but harder in texture.

In hot or dry weather, small white to yellow scented flowers form in small umbels diameter from one long stalk. The seeds come from dried up fruit long and thick, and straight to slightly curved with a longitudinally ridged surface.

Successful cultivation requires warm to hot summers with high sunshine levels; even partial shade will reduce the yield substantially. It also prefers rich, well-drained soil. 
The seed is harvested by cutting the flower heads off the stalks when the seed is beginning to ripen. The seed heads are placed upside down in a paper bag and left in a warm, dry place for a week. The seeds then separate from the stems easily for storage in an airtight container.

These plants, like their fennel and parsley relatives, often are eaten by black swallowtail caterpillars in areas where that species occurs. For this reason, they may be included in some butterfly gardens.

Dill has been found in the tomb of Egyptian Pharaoh Amenhotep II, dating to around 1400 BC. It was also later found in the Greek city of Samos, around the 7th century BC, and mentioned in the writings of Theophrastus (371–287 BC). In Greek mythology, the dill was originally a young man named Anethus who was transformed into the plant.

Fresh and dried dill leaves (sometimes called "dill weed" or "dillweed" to distinguish it from dill seed) are widely used as herbs in Europe and in central and south-eastern Asia.

Like caraway, the fern-like leaves of dill are aromatic and are used to flavour many foods such as gravlax (cured salmon) and other fish dishes, borscht, and other soups, as well as pickles (where the dill flower is sometimes used). Dill is best when used fresh, as it loses its flavor rapidly if dried. However, freeze-dried dill leaves retain their flavour relatively well for a few months.

Dill oil is extracted from the leaves, stems, and seeds of the plant. The oil from the seeds is distilled and used in the manufacturing of soaps.

Dill is the eponymous ingredient in dill pickles.

In central and eastern Europe, the Nordic countries, the Baltic states, Ukraine, and Russia, dill is a staple culinary herb along with chives and parsley. Fresh, finely cut dill leaves are used as a topping in soups, especially the hot red borsht and the cold borsht mixed with curds, kefir, yogurt, or sour cream, which is served during hot summer weather and is called 'okroshka'. It also is popular in summer to drink fermented milk (curds, kefir, yogurt, or buttermilk) mixed with dill (and sometimes other herbs).

In the same way, dill is used as a topping for boiled potatoes covered with fresh butter – especially in summer when there are so-called "new", or young, potatoes. The dill leaves may be mixed with butter, making a dill butter, to serve the same purpose. Dill leaves mixed with tvorog form one of the traditional cheese spreads used for sandwiches. Fresh dill leaves are used throughout the year as an ingredient in salads, "e.g.", one made of lettuce, fresh cucumbers, and tomatoes, as basil leaves are used in Italy and Greece.

Russian cuisine is noted for liberal use of dill, where it is known as . It is supposed to have antiflatulent properties; some Russian cosmonauts recommended its use in human spaceflight due to such properties being beneficial in confined quarters with a closed air supply.

In Polish cuisine, fresh dill leaves mixed with sour cream are the basis for dressings. It is especially popular to use this kind of sauce with freshly cut cucumbers, which are almost wholly immersed in the sauce, making a salad called 'mizeria'. Dill sauce is used hot for baked freshwater fish and for chicken or turkey breast, or used hot or cold for hard-boiled eggs. A dill-based soup, (zupa koperkowa), served with potatoes and hard-boiled eggs, is popular in Poland. Whole stems including roots and flower buds are used traditionally to prepare Polish-style pickled cucumbers (ogórki kiszone), especially the so-called low-salt cucumbers (ogórki małosolne). Whole stems of dill (often including the roots) also are cooked with potatoes, especially the potatoes of autumn and winter, so they resemble the flavour of the newer potatoes found in summer. Some kinds of fish, especially trout and salmon, traditionally are baked with the stems and leaves of dill.

In the Czech Republic, white dill sauce made of cream (or milk), butter, flour, vinegar, and dill is called 'koprová omáčka' (also 'koprovka' or 'kopračka') and is served either with boiled eggs and potatoes, or with dumplings and boiled beef. Another Czech dish with dill is a soup called 'kulajda' that contains mushrooms (traditionally wild ones).

In Germany, dill is popular as a seasoning for fish and many other dishes, chopped as a garnish on potatoes, and as a flavouring in pickles.

In the UK, dill may be used in fish pie.

In Bulgaria dill is widely used in traditional vegetable salads, and most notably the yogurt-based cold soup Tarator. It is also used in the preparation of sour pickles, cabbage, and other dishes.

In Romania dill (mărar) is widely used as an ingredient for soups such as 'borş' (pronounced "borsh"), pickles, and other dishes, especially those based on peas, beans, and cabbage. It is popular for dishes based on potatoes and mushrooms and may be found in many summer salads (especially cucumber salad, cabbage salad and lettuce salad). During springtime, it is used in omelets with spring onions. It often complements sauces based on sour cream or yogurt and is mixed with salted cheese and used as a filling. Another popular dish with dill as a main ingredient is dill sauce, which is served with eggs and fried sausages.

In Hungary, dill is very widely used. It is popular as a sauce or filling, and mixed with a type of cottage cheese. Dill is also used for pickling and in salads. The Hungarian name for dill is 'kapor'.

In Serbia, dill is known as 'mirodjija' and is used as an addition to soups, potato and cucumber salads, and French fries. It features in the Serbian proverb, "бити мирођија у свакој чорби" /biti mirodjija u svakoj čorbi/ (to be a dill in every soup), which corresponds to the English proverb "to have a finger in every pie".

In Greece, dill is known as 'άνηθος' (anithos). In antiquity it was used as an ingredient in wines that were called "anithites oinos" (wine with anithos-dill). In modern days, dill is used in salads, soups, sauces, and fish and vegetable dishes.

In Santa Maria, Azores, dill (endro) is the most important ingredient of the traditional Holy Ghost soup (sopa do Espírito Santo). Dill is found ubiquitously in Santa Maria, yet, is rare in the other Azorean Islands.

In Sweden, dill is a common spice or herb. The flowers of fully grown dill are called 'krondill' (crown dill) and used when cooking crayfish. The krondill is put into the water after the crayfish is boiled, but still in hot and salt water. Then the entire dish is refrigerated for at least 24 hours before being served (with toasted bread and butter). Krondill is also used to flavor pickles and vodka. After a month or two of fermentation, the cucumber pickles are ready to eat, for instance, with pork, brown sauce, and potatoes, as a sweetener. The thinner part of dill and young plants may be used with boiled fresh potatoes (especially the first potatoes of the year, new potatoes, which usually are small and have a very thin skin). In salads it is used together with, or instead, of other green herbs, such as parsley, chives, and basil. It is often paired up with chives when used in food. Dill is often used to flavour fish and seafood in Sweden, for example, gravlax and various herring pickles, among them the traditional, 'sill i dill' (literally 'herring in dill'). In contrast to the various fish dishes flavoured with dill, there is also a traditional Swedish dish called, 'dillkött', which is a meaty stew flavoured with dill. The dish commonly contains pieces of veal or lamb that are boiled until tender and then served together with a vinegary dill sauce. Dill seeds may be used in breads or 'akvavit'. A newer, non-traditional use of dill is to pair it with chives as a flavouring for potato chips. These are called 'dillchips' and are quite popular in Sweden.

In Finland, the uses of dill are very similar to those in Sweden, including flavouring potato chips and, comparably less popularly, in a dish comparable to 'dillkött' ('tilliliha'). Generally, the use of dill in Finland, however, is not as extensive as in large parts of central and eastern Europe, particularly Russia but including even the ethnolinguistically close Estonia.

In Iran, dill is known as 'shevid' and sometimes, is used with rice and called 'shevid-polo'. It also is used in Iranian 'aash' recipes, and similarly, is called in Persian.

In India, dill is known as 'Sholpa' in Bengali, (शेपू) in Marathi and Konkani, in Hindi, or in Punjabi. In Telugu, it is called 'Soa-kura' (herb greens). It also is called (ಸಬ್ಬಸಿಗೆ ಸೊಪ್ಪು) in Kannada. In Tamil it is known as (சதகுப்பி). In Malayalam, it is ചതകുപ്പ () or (). In Sanskrit, this herb is called . In Gujarati, it is known as (સૂવા). In India, dill is prepared in the manner of yellow 'moong dal', as a main-course dish. It is considered to have very good antiflatulent properties, so it is used as 'mukhwas', or an after-meal digestive. Traditionally, it is given to mothers immediately after childbirth. In the state of Uttar Pradesh in India, a small amount of fresh dill is cooked along with cut potatoes and fresh fenugreek leaves (Hindi आलू-मेथी-सोया).

In Manipur, dill, locally known as , is an essential ingredient of – a traditional Manipuri dish made with fermented soybean and rice.

In Laos and parts of northern Thailand, dill is known in English as Lao coriander ( or ), and served as a side with salad yum or papaya salad. In the Lao language, it is called 'phak see', and in Thai, it is known as 'phak chee Lao'. In Lao cuisine, Lao coriander is used extensively in traditional Lao dishes such as 'mok pa' (steamed fish in banana leaf) and several coconut milk curries that contain fish or prawns.

In China dill is called colloquially, 'huíxiāng' (, perfume of Hui people), or more properly 'shíluó' (). It is a common filling in 'baozi', 'jiaozi' and 'xianbing' and may be used as vegetarian with rice vermicelli, or combined with either meat or eggs. Vegetarian dill baozi are a common part of a Beijing breakfast. In baozi and xianbing, it often is interchangeable with non-bulbing fennel and the term also may refer to fennel, similarly to caraway and coriander leaf, sharing a name in Chinese as well. Dill also may be stir fried as a potherb, often with egg, in the same manner as Chinese chives. In Northern China, Beijing, Inner-Mongolia, Ningxia, Gansu, and Xinjiang, dill seeds commonly are called 'zīrán' (), but also 'kūmíng' (), 'kūmíngzi' (), 'shíluózi' (), 'xiǎohuíxiāngzi' () and are used with pepper for lamb meat. In the whole of China, 'yángchuàn' () or 'yángròu chuàn' (), lamb brochette, a speciality from Uyghurs, uses cumin and pepper. 

In Taiwan, it is also commonly used as a filling in steamed buns (baozi) and dumplings (jiaozi).

In Vietnam, the use of dill in cooking is regional. It is used mainly in northern Vietnamese cuisine.

In Arab countries, dill seed, called (grasshopper's eye), is used as a spice in cold dishes such as 'fattoush' and pickles. In Arab countries of the Persian Gulf, dill is called 'shibint' and is used mostly in fish dishes. In Egypt, dillweed is commonly used to flavour cabbage dishes, including 'mahshi koronb' (stuffed cabbage leaves).
In Israel, dill weed is used in salads and also to flavour omelettes, often alongside parsley.

When used as a companion plant, dill attracts many beneficial insects as the umbrella flower heads go to seed. It makes a good companion plant for cucumbers and broccoli.

Tomatoes will benefit from dill when it is young since it will repel harmful pests while attracting pollinators, but must be pruned as it matures to prevent the dill from flowering, as this will slow or stop the growth of tomatoes.



Dual space

In mathematics, any vector space "formula_1" has a corresponding dual vector space (or just dual space for short) consisting of all linear forms on "formula_2" together with the vector space structure of pointwise addition and scalar multiplication by constants.

The dual space as defined above is defined for all vector spaces, and to avoid ambiguity may also be called the .
When defined for a topological vector space, there is a subspace of the dual space, corresponding to continuous linear functionals, called the continuous dual space.

Dual vector spaces find application in many branches of mathematics that use vector spaces, such as in tensor analysis with finite-dimensional vector spaces.
When applied to vector spaces of functions (which are typically infinite-dimensional), dual spaces are used to describe measures, distributions, and Hilbert spaces. Consequently, the dual space is an important concept in functional analysis.

Early terms for "dual" include "polarer Raum" [Hahn 1927], "espace conjugué", "adjoint space" [Alaoglu 1940], and "transponierter Raum" [Schauder 1930] and [Banach 1932]. The term "dual" is due to Bourbaki 1938.

Given any vector space formula_1 over a field formula_4, the (algebraic) dual space formula_5 (alternatively denoted by formula_6 or formula_7) is defined as the set of all linear maps "formula_8" (linear functionals). Since linear maps are vector space homomorphisms, the dual space may be denoted formula_9.
The dual space formula_10 itself becomes a vector space over "formula_4" when equipped with an addition and scalar multiplication satisfying:
for all formula_13, "formula_14", and formula_15.

Elements of the algebraic dual space formula_10 are sometimes called covectors, one-forms, or linear forms.

The pairing of a functional "formula_17" in the dual space formula_10 and an element "formula_19" of "formula_1" is sometimes denoted by a bracket: "formula_21"
or "formula_22". This pairing defines a nondegenerate bilinear mapping formula_23 called the natural pairing.

If formula_1 is finite-dimensional, then formula_10 has the same dimension as formula_1. Given a basis formula_27 in formula_1, it is possible to construct a specific basis in formula_10, called the dual basis. This dual basis is a set formula_30 of linear functionals on formula_1, defined by the relation
for any choice of coefficients formula_33. In particular, letting in turn each one of those coefficients be equal to one and the other coefficients zero, gives the system of equations
where formula_35 is the Kronecker delta symbol. This property is referred to as the "bi-orthogonality property".
Consider formula_27 the basis of V. Let formula_30 be defined as the following:

formula_32.

We have:

and formula_30 generates formula_10. Hence, it is a basis of formula_60. 
For example, if formula_1 is formula_62, let its basis be chosen as formula_63. The basis vectors are not orthogonal to each other. Then, formula_64 and formula_65 are one-forms (functions that map a vector to a scalar) such that formula_66, formula_67, formula_68, and formula_69. (Note: The superscript here is the index, not an exponent.) This system of equations can be expressed using matrix notation as
Solving for the unknown values in the first matrix shows the dual basis to be formula_71. Because formula_64 and formula_65 are functionals, they can be rewritten as formula_74 and formula_75.

In general, when formula_1 is formula_77, if formula_78 is a matrix whose columns are the basis vectors and formula_79 is a matrix whose columns are the dual basis vectors, then
where formula_81 is the identity matrix of order formula_82. The biorthogonality property of these two basis sets allows any point formula_83 to be represented as
even when the basis vectors are not orthogonal to each other. Strictly speaking, the above statement only makes sense once the inner product formula_85 and the corresponding duality pairing are introduced, as described below in "".

In particular, formula_77 can be interpreted as the space of columns of formula_82 real numbers, its dual space is typically written as the space of "rows" of formula_82 real numbers. Such a row acts on formula_77 as a linear functional by ordinary matrix multiplication. This is because a functional maps every formula_82-vector formula_19 into a real number formula_92. Then, seeing this functional as a matrix formula_93, and formula_19 as an formula_95 matrix, and formula_92 a formula_97 matrix (trivially, a real number) respectively, if formula_98 then, by dimension reasons, formula_93 must be a formula_100 matrix; that is, formula_93 must be a row vector.

If formula_1 consists of the space of geometrical vectors in the plane, then the level curves of an element of formula_10 form a family of parallel lines in formula_1, because the range is 1-dimensional, so that every point in the range is a multiple of any one nonzero element.
So an element of formula_10 can be intuitively thought of as a particular family of parallel lines covering the plane. To compute the value of a functional on a given vector, it suffices to determine which of the lines the vector lies on. Informally, this "counts" how many lines the vector crosses.
More generally, if formula_1 is a vector space of any dimension, then the level sets of a linear functional in formula_10 are parallel hyperplanes in formula_1, and the action of a linear functional on a vector can be visualized in terms of these hyperplanes.

If formula_1 is not finite-dimensional but has a basis formula_110 indexed by an infinite set formula_111, then the same construction as in the finite-dimensional case yields linearly independent elements formula_112 (formula_113) of the dual space, but they will not form a basis.

For instance, consider the space formula_114, whose elements are those sequences of real numbers that contain only finitely many non-zero entries, which has a basis indexed by the natural numbers formula_115. For formula_116, formula_117 is the sequence consisting of all zeroes except in the formula_118-th position, which is 1.
The dual space of formula_114 is (isomorphic to) formula_120, the space of "all" sequences of real numbers: each real sequence formula_121 defines a function where the element formula_122 of formula_114 is sent to the number

which is a finite sum because there are only finitely many nonzero formula_125. The dimension of formula_114 is countably infinite, whereas formula_120 does not have a countable basis.

This observation generalizes to any infinite-dimensional vector space formula_1 over any field formula_4: a choice of basis formula_130 identifies formula_1 with the space formula_132 of functions formula_133 such that formula_134 is nonzero for only finitely many formula_113, where such a function formula_136 is identified with the vector

in formula_1 (the sum is finite by the assumption on formula_136, and any formula_140 may be written uniquely in this way by the definition of the basis).

The dual space of formula_1 may then be identified with the space formula_142 of "all" functions from formula_111 to formula_4: a linear functional formula_145 on formula_1 is uniquely determined by the values formula_147 it takes on the basis of formula_1, and any function formula_149 (with formula_150) defines a linear functional formula_145 on formula_1 by

Again, the sum is finite because formula_154 is nonzero for only finitely many formula_155.

The set formula_132 may be identified (essentially by definition) with the direct sum of infinitely many copies of formula_4 (viewed as a 1-dimensional vector space over itself) indexed by formula_111, i.e. there are linear isomorphisms

On the other hand, formula_142 is (again by definition), the direct product of infinitely many copies of formula_4 indexed by formula_111, and so the identification
is a special case of a general result relating direct sums (of modules) to direct products.

If a vector space is not finite-dimensional, then its (algebraic) dual space is "always" of larger dimension (as a cardinal number) than the original vector space. This is in contrast to the case of the continuous dual space, discussed below, which may be isomorphic to the original vector space even if the latter is infinite-dimensional.

The proof of this inequality between dimensions results from the following.

If formula_1 is an infinite-dimensional formula_4-vector space, the arithmetical properties of cardinal numbers implies that 
where cardinalities are denoted as absolute values. For proving that formula_167 it suffices to prove that formula_168 which can be done with an argument similar to Cantor's diagonal argument. The exact dimension of the dual is given by the Erdős–Kaplansky theorem.

If "V" is finite-dimensional, then "V" is isomorphic to "V". But there is in general no natural isomorphism between these two spaces. Any bilinear form on "V" gives a mapping of "V" into its dual space via

where the right hand side is defined as the functional on "V" taking each to . In other words, the bilinear form determines a linear mapping

defined by

If the bilinear form is nondegenerate, then this is an isomorphism onto a subspace of "V".
If "V" is finite-dimensional, then this is an isomorphism onto all of "V". Conversely, any isomorphism formula_172 from "V" to a subspace of "V" (resp., all of "V" if "V" is finite dimensional) defines a unique nondegenerate bilinear form on "V" by

Thus there is a one-to-one correspondence between isomorphisms of "V" to a subspace of (resp., all of) "V" and nondegenerate bilinear forms on "V".

If the vector space "V" is over the complex field, then sometimes it is more natural to consider sesquilinear forms instead of bilinear forms.
In that case, a given sesquilinear form determines an isomorphism of "V" with the complex conjugate of the dual space

The conjugate of the dual space formula_175 can be identified with the set of all additive complex-valued functionals such that

There is a natural homomorphism formula_177 from formula_1 into the double dual formula_179, defined by formula_180 for all formula_181. In other words, if formula_182 is the evaluation map defined by formula_183, then formula_184 is defined as the map formula_185. This map formula_177 is always injective; and it is always an isomorphism if formula_1 is finite-dimensional.
Indeed, the isomorphism of a finite-dimensional vector space with its double dual is an archetypal example of a natural isomorphism.
Infinite-dimensional Hilbert spaces are not isomorphic to their algebraic double duals, but instead to their continuous double duals.

If is a linear map, then the "transpose" (or "dual") is defined by
for every "formula_189". The resulting functional "formula_190" in "formula_10" is called the "pullback" of "formula_17" along "formula_136".

The following identity holds for all "formula_189" and "formula_195":
where the bracket [·,·] on the left is the natural pairing of "V" with its dual space, and that on the right is the natural pairing of "W" with its dual. This identity characterizes the transpose, and is formally similar to the definition of the adjoint.

The assignment produces an injective linear map between the space of linear operators from "V" to "W" and the space of linear operators from "W" to "V"; this homomorphism is an isomorphism if and only if "W" is finite-dimensional.
If then the space of linear maps is actually an algebra under composition of maps, and the assignment is then an antihomomorphism of algebras, meaning that .
In the language of category theory, taking the dual of vector spaces and the transpose of linear maps is therefore a contravariant functor from the category of vector spaces over "F" to itself.
It is possible to identify ("f") with "f" using the natural injection into the double dual.

If the linear map "f" is represented by the matrix "A" with respect to two bases of "V" and "W", then "f" is represented by the transpose matrix "A" with respect to the dual bases of "W" and "V", hence the name.
Alternatively, as "f" is represented by "A" acting on the left on column vectors, "f" is represented by the same matrix acting on the right on row vectors.
These points of view are related by the canonical inner product on R, which identifies the space of column vectors with the dual space of row vectors.

Let formula_197 be a subset of formula_1.
The annihilator of formula_197 in formula_10, denoted here formula_201, is the collection of linear functionals formula_202 such that formula_203 for all formula_204.
That is, formula_201 consists of all linear functionals formula_206 such that the restriction to formula_197 vanishes: formula_208.
Within finite dimensional vector spaces, the annihilator is dual to (isomorphic to) the orthogonal complement.

The annihilator of a subset is itself a vector space.
The annihilator of the zero vector is the whole dual space: formula_209, and the annihilator of the whole space is just the zero covector: formula_210.
Furthermore, the assignment of an annihilator to a subset of formula_1 reverses inclusions, so that if formula_212, then

If formula_111 and formula_215 are two subsets of formula_1 then
and equality holds provided formula_1 is finite-dimensional. If formula_219 is any family of subsets of formula_1 indexed by formula_118 belonging to some index set formula_222, then
In particular if formula_111 and formula_215 are subspaces of formula_1 then

If formula_1 is finite-dimensional and formula_229 is a vector subspace, then
after identifying formula_229 with its image in the second dual space under the double duality isomorphism formula_232. In particular, forming the annihilator is a Galois connection on the lattice of subsets of a finite-dimensional vector space.

If formula_229 is a subspace of formula_1 then the quotient space formula_235 is a vector space in its own right, and so has a dual. By the first isomorphism theorem, a functional formula_206 factors through formula_235 if and only if formula_229 is in the kernel of formula_136. There is thus an isomorphism
As a particular consequence, if formula_1 is a direct sum of two subspaces formula_111 and formula_215, then formula_10 is a direct sum of formula_245 and formula_246.

The dual space is analogous to a "negative"-dimensional space. Most simply, since a vector formula_195 can be paired with a covector formula_248 by the natural pairing
formula_249 to obtain a scalar, a covector can "cancel" the dimension of a vector, similar to reducing a fraction. Thus while the direct sum formula_250 is a -dimensional space (if is -dimensional), behaves as an -dimensional space, in the sense that its dimensions can be canceled against the dimensions of . This is formalized by tensor contraction.

This arises in physics via dimensional analysis, where the dual space has inverse units. Under the natural pairing, these units cancel, and the resulting scalar value is dimensionless, as expected. For example, in (continuous) Fourier analysis, or more broadly time–frequency analysis: given a one-dimensional vector space with a unit of time , the dual space has units of frequency: occurrences "per" unit of time (units of ). For example, if time is measured in seconds, the corresponding dual unit is the inverse second: over the course of 3 seconds, an event that occurs 2 times per second occurs a total of 6 times, corresponding to formula_251. Similarly, if the primal space measures length, the dual space measures inverse length.

When dealing with topological vector spaces, the continuous linear functionals from the space into the base field formula_252 (or formula_253) are particularly important.
This gives rise to the notion of the "continuous dual space" or "topological dual" which is a linear subspace of the algebraic dual space formula_10, denoted by formula_7.
For any "finite-dimensional" normed vector space or topological vector space, such as Euclidean "n-"space, the continuous dual and the algebraic dual coincide.
This is however false for any infinite-dimensional normed space, as shown by the example of discontinuous linear maps.
Nevertheless, in the theory of topological vector spaces the terms "continuous dual space" and "topological dual space" are often replaced by "dual space".

For a topological vector space formula_1 its "continuous dual space", or "topological dual space", or just "dual space" (in the sense of the theory of topological vector spaces) formula_7 is defined as the space of all continuous linear functionals formula_258.

Important examples for continuous dual spaces are the space of compactly supported test functions formula_259 and its dual formula_260 the space of arbitrary distributions (generalized functions); the space of arbitrary test functions formula_261 and its dual formula_262 the space of compactly supported distributions; and the space of rapidly decreasing test functions formula_263 the Schwartz space, and its dual formula_264 the space of tempered distributions (slowly growing distributions) in the theory of generalized functions.

If is a Hausdorff topological vector space (TVS), then the continuous dual space of is identical to the continuous dual space of the completion of .

There is a standard construction for introducing a topology on the continuous dual formula_7 of a topological vector space formula_1. Fix a collection formula_267 of bounded subsets of formula_1.
This gives the topology on formula_1 of uniform convergence on sets from formula_270 or what is the same thing, the topology generated by seminorms of the form

where formula_17 is a continuous linear functional on formula_1, and formula_111 runs over the class formula_275

This means that a net of functionals formula_276 tends to a functional formula_17 in formula_7 if and only if

Usually (but not necessarily) the class formula_267 is supposed to satisfy the following conditions:

If these requirements are fulfilled then the corresponding topology on formula_7 is Hausdorff and the sets

form its local base.

Here are the three most important special cases.
If formula_1 is a normed vector space (for example, a Banach space or a Hilbert space) then the strong topology on formula_7 is normed (in fact a Banach space if the field of scalars is complete), with the norm

Each of these three choices of topology on formula_7 leads to a variant of reflexivity property for topological vector spaces:

Let 1 < "p" < ∞ be a real number and consider the Banach space "ℓ" of all sequences for which

Define the number "q" by . Then the continuous dual of "ℓ" is naturally identified with "ℓ": given an element formula_313, the corresponding element of is the sequence formula_314 where formula_315 denotes the sequence whose -th term is 1 and all others are zero. Conversely, given an element , the corresponding continuous linear functional "formula_17" on is defined by

for all (see Hölder's inequality).

In a similar manner, the continuous dual of is naturally identified with (the space of bounded sequences).
Furthermore, the continuous duals of the Banach spaces "c" (consisting of all convergent sequences, with the supremum norm) and "c" (the sequences converging to zero) are both naturally identified with .

By the Riesz representation theorem, the continuous dual of a Hilbert space is again a Hilbert space which is anti-isomorphic to the original space.
This gives rise to the bra–ket notation used by physicists in the mathematical formulation of quantum mechanics.

By the Riesz–Markov–Kakutani representation theorem, the continuous dual of certain spaces of continuous functions can be described using measures.

If is a continuous linear map between two topological vector spaces, then the (continuous) transpose is defined by the same formula as before:

The resulting functional is in . The assignment produces a linear map between the space of continuous linear maps from "V" to "W" and the space of linear maps from to .
When "T" and "U" are composable continuous linear maps, then

When "V" and "W" are normed spaces, the norm of the transpose in is equal to that of "T" in .
Several properties of transposition depend upon the Hahn–Banach theorem.
For example, the bounded linear map "T" has dense range if and only if the transpose is injective.

When "T" is a compact linear map between two Banach spaces "V" and "W", then the transpose is compact.
This can be proved using the Arzelà–Ascoli theorem.

When "V" is a Hilbert space, there is an antilinear isomorphism "i" from "V" onto its continuous dual .
For every bounded linear map "T" on "V", the transpose and the adjoint operators are linked by

When "T" is a continuous linear map between two topological vector spaces "V" and "W", then the transpose is continuous when and are equipped with "compatible" topologies: for example, when for and , both duals have the strong topology of uniform convergence on bounded sets of "X", or both have the weak-∗ topology of pointwise convergence on "X".
The transpose is continuous from to , or from to .

Assume that "W" is a closed linear subspace of a normed space "V", and consider the annihilator of "W" in ,

Then, the dual of the quotient can be identified with "W", and the dual of "W" can be identified with the quotient .
Indeed, let "P" denote the canonical surjection from "V" onto the quotient ; then, the transpose is an isometric isomorphism from into , with range equal to "W".
If "j" denotes the injection map from "W" into "V", then the kernel of the transpose is the annihilator of "W":
and it follows from the Hahn–Banach theorem that induces an isometric isomorphism

If the dual of a normed space is separable, then so is the space itself.
The converse is not true: for example, the space is separable, but its dual is not.

In analogy with the case of the algebraic double dual, there is always a naturally defined continuous linear operator from a normed space "V" into its continuous double dual , defined by

As a consequence of the Hahn–Banach theorem, this map is in fact an isometry, meaning for all .
Normed spaces for which the map Ψ is a bijection are called reflexive.

When "V" is a topological vector space then Ψ("x") can still be defined by the same formula, for every , however several difficulties arise.
First, when "V" is not locally convex, the continuous dual may be equal to { 0 } and the map Ψ trivial.
However, if "V" is Hausdorff and locally convex, the map Ψ is injective from "V" to the algebraic dual of the continuous dual, again as a consequence of the Hahn–Banach theorem.

Second, even in the locally convex setting, several natural vector space topologies can be defined on the continuous dual , so that the continuous double dual is not uniquely defined as a set. Saying that Ψ maps from "V" to , or in other words, that Ψ("x") is continuous on for every , is a reasonable minimal requirement on the topology of , namely that the evaluation mappings

be continuous for the chosen topology on . Further, there is still a choice of a topology on , and continuity of Ψ depends upon this choice.
As a consequence, defining reflexivity in this framework is more involved than in the normed case.



Dianetics

Dianetics is a set of pseudoscientific ideas and practices regarding the relationship between the human mind and body created by science fiction writer and Scientology founder L. Ron Hubbard. Dianetics is practiced by followers of Scientology and the Nation of Islam (as of 2010).

Dianetics was originally conceived as a branch of psychiatry, which Hubbard would come to despise when various psychoanalysts dismissed it as unscientific. Though it is presented as a form of psychological treatment, Dianetics and its core concepts have been rejected by psychologists and other scientists from the outset and are not supported by credible evidence.

The word "Dianetics" is coined from Greek "dia" meaning "through" and "nous" meaning "mind".

Dianetics theory describes the human mind as two parts: the conscious "analytical mind" and the subconscious "reactive mind". The purpose of Dianetics technique, called "auditing", is to erase the contents of the reactive mind, which practitioners believe interferes with a person's ethics, awareness, happiness, and sanity. In auditing, the person is asked questions intended to help them locate and deal with painful past experiences.

Dianetics theory posits that "the basic principle of existence is to survive" and that the basic personality of humans is sincere, intelligent, and good. The drive for goodness and survival is distorted and inhibited by aberrations (deviations from rational thinking). Hubbard claimed that Dianetics could increase intelligence, eliminate unwanted emotions and alleviate a wide range of illnesses he believed to be psychosomatic. Conditions purportedly treatable with Dianetics included arthritis, allergies, asthma, some coronary difficulties, eye trouble, ulcers, migraine headaches, and sexual deviation.

According to Hubbard, when he was sedated for a dental operation in 1938, he had a near-death experience which inspired him to write the manuscript "Excalibur". Though it was never published, this work would allegedly become the basis for Dianetics. The first publication on Dianetics was "", an article by Hubbard in "Astounding Science Fiction" (cover date May 1950). This was followed by the book "" (DMSMH) published May 9, 1950. In these works Hubbard claimed that the source of all psychological pain, and therefore the cause of mental and physical health problems, was a form of memory known as "engrams". According to Hubbard, individuals could reach a state he named "Clear" when all of their engrams had been removed through talking with an "auditor".

While the technique was not accepted by the medical and scientific establishment, in the first two years of its publication DMSMH sold over 100,000 copies. "Publishers Weekly" posthumously awarded Hubbard a plaque to acknowledge DMSMH appearing on its bestseller list for one hundred consecutive weeks. Publication of DMSMH brought in a flood of revenue, which Hubbard used to establish Dianetics foundations in six major American cities. Two of the strongest initial supporters of Dianetics in the 1950s were John W. Campbell, editor of "Astounding Science Fiction", and Joseph Augustus Winter, a writer and medical physician. Campbell published some of Hubbard's short stories and Winter hoped that his colleagues would likewise be attracted to Hubbard's Dianetics system.

Readers formed groups to study and practice Dianetics technique. According to sociologist Roy Wallis, this period was one of "excited experimentation" and Hubbard's work was regarded as "an initial exploration to be developed further by others". Per Wallis, it was Dianetics' popularity as a lay psychotherapy that contributed to the Dianetics Foundation's downfall. Most people read the book, tried it out, then put it down. The remaining practitioners had no ties to the Foundation. Factions formed and followers challenged Hubbard's movement and his authority. The craze of 1950–51 was dead by 1952.

In 1951, with debts piled up and facing bankruptcy, Don Purcell, a wealthy Dianetics follower from Wichita, bailed out the foundation. It was short-lived, however, and the foundation fell to bankruptcy in 1952. Hubbard fled to Phoenix, Arizona, having lost the foundation, the rights to Dianetics, and the copyrights to DMSMH, though in 1954 Purcell gave the copyrights back to Hubbard.

In Phoenix, Hubbard created "Scientology"; it's techniques were intended to rehabilitate a person so that they might reach their full potential as a spiritual being. Dianetics was incorporated into Scientology. In 1963 and in 1969, Hubbard modified Dianetics into "Standard Dianetics". In 1978, Hubbard introduced "New Era Dianetics" (NED), said to permanently free someone from his "reactive mind". Hubbard later introduced New Era Dianetics for OTs. These steps are on The Bridge to Total Freedom.

In the book, "", Hubbard describes techniques that he suggests can rid individuals of fears and psychosomatic illnesses. A basic idea in Dianetics is that the mind consists of two parts: the "analytical mind" and the "reactive mind". The "reactive mind", the mind which operates when a person is physically unconscious, acts as a record of shock, trauma, pain, and otherwise harmful memories. Experiences such as these, stored in the "reactive mind" are dubbed "engrams". Dianetics is proposed as a method to erase these engrams in the reactive mind to achieve a state of clear.

In Dianetics, the unconscious or reactive mind is described as a collection of "mental image pictures", which contain the recorded experience of past moments of unconsciousness, including all sensory perceptions and feelings involved, ranging from pre-natal experiences, infancy and childhood, to even the traumatic feelings associated with events from past lives and extraterrestrial cultures. The type of mental image picture created during a period of unconsciousness involves the exact recording of a painful experience. Hubbard called this phenomenon an engram, and defined it as "a complete recording of a moment of unconsciousness containing physical pain or painful emotion and all perceptions."

Hubbard proposed that these engrams caused "aberrations" (deviations from rational thinking) in the mind, which produced lasting adverse physical and emotional effects (cf. conversion disorder). When the analytical (conscious) mind shut down during these moments, events and perceptions of this period were stored as engrams in the unconscious or reactive mind. In Hubbard's earliest publications on the subject, engrams were variously referred to as "Norns", "Impediments", and "comanomes" before "engram" was adapted from its existing usage at the suggestion of Joseph Augustus Winter, MD. Some commentators noted Dianetics's blend of science fiction and occult orientations at the time.

Hubbard claimed that these engrams are the cause of almost all psychological and physical problems. In addition to physical pain, engrams could include words or phrases spoken in the vicinity while the patient was unconscious. For instance, Winter cites the example of a patient with a persistent headache supposedly tracing the problem to a doctor saying, "Take him now", during the patient's birth. Hubbard similarly claimed that leukemia is traceable to "an engram containing the phrase 'It turns my blood to water. While it is sometimes claimed that the Church of Scientology no longer stands by Hubbard's claims that Dianetics can treat physical conditions, it still publishes them: "when the knee injuries of the past are located and discharged, the arthritis ceases, no other injury takes its place and the person is finished with arthritis of the knee." "[The reactive mind] can give a man arthritis, bursitis, asthma, allergies, sinusitis, coronary trouble, high blood pressure ... And it is the only thing in the human being which can produce these effects ... Discharge the content of [the reactive mind] and the arthritis vanishes, myopia gets better, heart illness decreases, asthma disappears, stomachs function properly and the whole catalog of ills goes away and stays away."

According to scholar Regis Dericqeobourg, Dianetics was first presented as a psychotherapy that focused on recalling an individual's past experiences as a source of origination for someone's physical and mental impairments, as well as "inappropriate behavior." In the form of counseling that Hubbard called "auditing," "auditors attempt to wash away associated emotional burdens and therein are supposed to cure people from their troubles". Eventually, psychologists and psychiatrists began to doubt the validity of Dianetics, leading Hubbard to the formation of Scientology as spirituality.

Some of the psychometric ideas in Dianetics, in particular the E-meter, can be traced to Carl Jung. Basic concepts, including conversion disorder, are derived from Sigmund Freud, whom Hubbard credited as an inspiration and source. Freud had speculated 40 years previously that traumas with similar content would join together as "chains" of incidents, embedded in the unconscious mind, to cause irrational responses in the individual. Such a chain would be relieved by inducing the patient to remember the earliest trauma, "with an accompanying expression of emotion."

According to Bent Corydon, Hubbard created the illusion that Dianetics was the first psychotherapy to address traumatic experiences in their own time, but others had done so before as standard procedure. One treatment method Hubbard drew from in developing Dianetics was abreaction therapy. Abreaction is a psychoanalytical term that means bringing to consciousness, and thus adequate expression, material that has been unconscious. "It includes not only the recollection of forgotten memories and experience, but also their reliving with appropriate emotional display and discharge of effect. This process is usually facilitated by the patient's gaining awareness of the causal relationship between the previously undischarged emotion and his symptoms."

According to Hubbard, before Dianetics psychotherapists had dealt with very light and superficial incidents (e.g., an incident that reminds the patient of a moment of loss), but with Dianetic therapy, the patient could actually erase moments of pain and unconsciousness. He emphasized: "The discovery of the engram is entirely the property of Dianetics. Methods of its erasure are also owned entirely by Dianetics".

While 1950 style Dianetics was in some respects similar to older therapies, with the development of New Era Dianetics in 1978, the similarity vanished. New Era Dianetics uses an E-Meter and a rote procedure for running "chains" of related traumatic incidents.

Dianetics clarifies the understanding of psychosomatic illness in terms of "predisposition", "precipitation", and "prolongation".

With the use of Dianetics techniques, Hubbard claimed, the reactive mind could be processed and all stored engrams could be refiled as experience. The central technique was "auditing", a two-person question-and-answer method designed to isolate and dissipate engrams (or "mental masses"). An auditor addresses questions to a subject, observes and records the subject's responses, and returns repeatedly to experiences or areas under discussion that appear painful until the troubling experience has been identified and confronted. Through repeated applications of this method, the reactive mind could be "cleared" of its content having outlived its usefulness in the process of evolution; a person who has completed this process would be "Clear".

The benefits of going Clear, according to Hubbard, were dramatic. A Clear would have no compulsions, repressions, psychoses or neuroses, and would enjoy a near-perfect memory as well as a rise in IQ of as much as 50 points. He also claimed that "the atheist is activated by engrams as thoroughly as the zealot". He further claimed that widespread application of Dianetics would result in "A world without insanity, without criminals and without war."

One of the key ideas of Dianetics, according to Hubbard, is the fundamental existential command to survive. According to Hugh B. Urban, this would serve as the foundation of a big part of later Scientology.

The procedure of Dianetics therapy (known as "auditing") is a two-person activity. One person, the "auditor", guides the other person, the "preclear". The preclear's job is to look at the mind and talk to the auditor. The auditor acknowledges what the preclear says and controls the process so the preclear may put his full attention on his work.

The auditor and preclear sit down in chairs facing each other. The process then follows in eleven distinct steps:


A few transcripts of auditing sessions with confidential information redacted have been published as demonstration examples. Some extracts can be found in Winter's book "A Doctor's Report on Dianetics". Other, more comprehensive, transcripts of auditing sessions carried out by Hubbard himself can be found in volume 1 of the "Research & Discovery Series" (Bridge Publications, 1980). Examples of public group processing sessions can be found throughout Hubbard's many recorded lectures.

In August 1950, amidst the success of "", Hubbard held a demonstration in Los Angeles' Shrine Auditorium where he presented a young woman called Sonya Bianca (a pseudonym) to a large audience including many reporters and photographers as "the world's first Clear". Despite Hubbard's claim that she had "full and perfect recall of every moment of her life", Bianca proved unable to answer questions from the audience testing her memory and analytical abilities, including the question of the color of Hubbard's tie. Hubbard explained Bianca's failure to display her promised powers of recall to the audience by saying that he had used the word "now" in calling her to the stage, and thus inadvertently froze her in "present time", which blocked her abilities. Later, in the late 1950s, Hubbard would claim that several people had reached the state of Clear by the time he presented Bianca as the world's first; these others, Hubbard said, he had successfully cleared in the late 1940s while working "incognito" in Hollywood posing as a swami. In 1966, Hubbard declared South African Scientologist John McMaster to be the first true Clear.

Hubbard claimed, in an interview with "The New York Times" in November 1950, that "he had already submitted proof of claims made in the book to a number of scientists and associations." He added that the public as well as proper organizations were entitled to such proof and that he was ready and willing to give such proof in detail. In January 1951, the Hubbard Dianetic Research Foundation of Elizabeth, New Jersey, published "Dianetic Processing: A Brief Survey of Research Projects and Preliminary Results", a booklet providing the results of psychometric tests conducted on 88 people undergoing Dianetics therapy. It presents case histories and a number of X-ray plates to support claims that Dianetics had cured "aberrations" including manic depression, asthma, arthritis, colitis and "overt homosexuality", and that after Dianetic processing, test subjects experienced significantly increased scores on a standardized IQ test. The report's subjects are not identified by name, but one of them is clearly Hubbard himself ("Case 1080A, R. L.").

The authors provide no qualifications, although they are described in Hubbard's book "Science of Survival" (where some results of the same study were reprinted) as psychotherapists. Critics of Dianetics are skeptical of this study, both because of the bias of the source and because the researchers appear to ascribe all physical benefits to Dianetics without considering possible outside factors; in other words, the report lacks any scientific controls. Winter was originally an associate of Hubbard and an early adopter of Dianetics, but by the end of 1950 had cut ties with Hubbard and written an account of his personal experiences with Dianetics. He described Hubbard as "absolutistic and authoritarian", and criticized the Hubbard Dianetic Research Foundation for failing to undertake "precise scientific research into the functioning of the mind". He also recommended that auditing be done by experts only and that it was dangerous for laymen to audit each other. Hubbard writes: "Again, Dianetics is not being released to a profession, for no profession could encompass it."

Hubbard's original book on Dianetics attracted highly critical reviews from science and medical writers and organizations. The American Psychological Association passed a resolution in 1950 calling "attention to the fact that these claims are not supported by empirical evidence of the sort required for the establishment of scientific generalizations." Subsequently, Dianetics has achieved no acceptance as a scientific theory, and scientists cite Dianetics as an example of a pseudoscience.

Few scientific investigations into the effectiveness of Dianetics have been published. Professor John A. Lee states in his 1970 evaluation of Dianetics:

The MEDLINE database records two independent scientific studies on Dianetics, both conducted in the 1950s under the auspices of New York University. Harvey Jay Fischer tested Dianetic therapy against three claims made by proponents and found it does not effect any significant changes in intellectual functioning, mathematical ability, or the degree of personality conflicts; Jack Fox tested Hubbard's thesis regarding recall of engrams, with the assistance of the Dianetic Research Foundation, and could not substantiate it.

Commentators from a variety of backgrounds have described Dianetics as an example of pseudoscience. For example, philosophy professor Robert Carroll points to Dianetics' lack of empirical evidence:

The validity and practice of auditing have been questioned by a variety of non-Scientologist commentators. Commenting on the example cited by Winter, the science writer Martin Gardner asserts that "nothing could be clearer from the above dialogue than the fact that the dianetic explanation for the headache existed only in the mind of the therapist, and that it was with considerable difficulty that the patient was maneuvered into accepting it."

Other critics and medical experts have suggested that Dianetic auditing is a form of hypnosis. Hubbard, who had previously used hypnosis for entertainment purposes, strongly denied this connection and cautioned against hypnosis in Dianetics auditing. Professor Richard J. Ofshe, a leading expert on false memories, suggests that the feeling of well-being reported by preclear at the end of an auditing session may be induced by post-hypnotic suggestion. Other researchers have identified quotations in Hubbard's work suggesting evidence that false memories were created in "Dianetics", specifically in the form of birth and pre-birth memories.

According to an article by physician Martin Gumpert, "Hubbard's concept of psychosomatic disease is definitely wrong. Psychosomatic ailments are not simply caused by emotional disturbances: they are diseases in which the emotional and the organic factor are closely involved and interdependent."



Data warehouse

In computing, a data warehouse (DW or DWH), also known as an enterprise data warehouse (EDW), is a system used for reporting and data analysis and is considered a core component of business intelligence. Data warehouses are central repositories of integrated data from one or more disparate sources. They store current and historical data in one single place that are used for creating analytical reports for workers throughout the enterprise. This is beneficial for companies as it enables them to interrogate and draw insights from their data and make decisions.
The data stored in the warehouse is uploaded from the operational systems (such as marketing or sales). The data may pass through an operational data store and may require data cleansing for additional operations to ensure data quality before it is used in the data warehouse for reporting. 

Extract, transform, load (ETL) and extract, load, transform (ELT) are the two main approaches used to build a data warehouse system.

The typical extract, transform, load (ETL)-based data warehouse uses staging, data integration, and access layers to house its key functions. The staging layer or staging database stores raw data extracted from each of the disparate source data systems. The integration layer integrates disparate data sets by transforming the data from the staging layer, often storing this transformed data in an operational data store (ODS) database. The integrated data are then moved to yet another database, often called the data warehouse database, where the data is arranged into hierarchical groups, often called dimensions, and into facts and aggregate facts. The combination of facts and dimensions is sometimes called a star schema. The access layer helps users retrieve data.

The main source of the data is cleansed, transformed, catalogued, and made available for use by managers and other business professionals for data mining, online analytical processing, market research and decision support. However, the means to retrieve and analyze data, to extract, transform, and load data, and to manage the data dictionary are also considered essential components of a data warehousing system. Many references to data warehousing use this broader context. Thus, an expanded definition of data warehousing includes business intelligence tools, tools to extract, transform, and load data into the repository, and tools to manage and retrieve metadata.

ELT-based data warehousing gets rid of a separate ETL tool for data transformation. Instead, it maintains a staging area inside the data warehouse itself. In this approach, data gets extracted from heterogeneous source systems and are then directly loaded into the data warehouse, before any transformation occurs. All necessary transformations are then handled inside the data warehouse itself. Finally, the manipulated data gets loaded into target tables in the same data warehouse.

A data warehouse maintains a copy of information from the source transaction systems. This architectural complexity provides the opportunity to:

The environment for data warehouses and marts includes the following:


In regards to source systems listed above, R. Kelly Rainer states, "A common source for the data in data warehouses is the company's operational databases, which can be relational databases".

Regarding data integration, Rainer states, "It is necessary to extract data from source systems, transform them, and load them into a data mart or warehouse".

Rainer discusses storing data in an organization's data warehouse or data marts.

Metadata is data about data. "IT personnel need information about data sources; database, table, and column names; refresh schedules; and data usage measures".

Today, the most successful companies are those that can respond quickly and flexibly to market changes and opportunities. A key to this response is the effective and efficient use of data and information by analysts and managers. A "data warehouse" is a repository of historical data that is organized by the subject to support decision-makers in the organization. Once data is stored in a data mart or warehouse, it can be accessed.

A data mart is a simple form of a data warehouse that is focused on a single subject (or functional area), hence they draw data from a limited number of sources such as sales, finance or marketing. Data marts are often built and controlled by a single department within an organization. The sources could be internal operational systems, a central data warehouse, or external data. Denormalization is the norm for data modeling techniques in this system. Given that data marts generally cover only a subset of the data contained in a data warehouse, they are often easier and faster to implement.

Types of data marts include dependent, independent, and hybrid data marts.

Online analytical processing (OLAP) is characterized by a relatively low volume of transactions. Queries are often very complex and involve aggregations. For OLAP systems, response time is an effective measure. OLAP applications are widely used by Data Mining techniques. OLAP databases store aggregated, historical data in multi-dimensional schemas (usually star schemas). OLAP systems typically have a data latency of a few hours, as opposed to data marts, where latency is expected to be closer to one day. The OLAP approach is used to analyze multidimensional data from multiple sources and perspectives. The three basic operations in OLAP are Roll-up (Consolidation), Drill-down, and Slicing & Dicing.

Online transaction processing (OLTP) is characterized by a large number of short on-line transactions (INSERT, UPDATE, DELETE). OLTP systems emphasize very fast query processing and maintaining data integrity in multi-access environments. For OLTP systems, effectiveness is measured by the number of transactions per second. OLTP databases contain detailed and current data. The schema used to store transactional databases is the entity model (usually 3NF). Normalization is the norm for data modeling techniques in this system.

Predictive analytics is about finding and quantifying hidden patterns in the data using complex mathematical models that can be used to predict future outcomes. Predictive analysis is different from OLAP in that OLAP focuses on historical data analysis and is reactive in nature, while predictive analysis focuses on the future. These systems are also used for customer relationship management (CRM).

The concept of data warehousing dates back to the late 1980s when IBM researchers Barry Devlin and Paul Murphy developed the "business data warehouse". In essence, the data warehousing concept was intended to provide an architectural model for the flow of data from operational systems to decision support environments. The concept attempted to address the various problems associated with this flow, mainly the high costs associated with it. In the absence of a data warehousing architecture, an enormous amount of redundancy was required to support multiple decision support environments. In larger corporations, it was typical for multiple decision support environments to operate independently. Though each environment served different users, they often required much of the same stored data. The process of gathering, cleaning and integrating data from various sources, usually from long-term existing operational systems (usually referred to as legacy systems), was typically in part replicated for each environment. Moreover, the operational systems were frequently reexamined as new decision support requirements emerged. Often new requirements necessitated gathering, cleaning and integrating new data from "data marts" that was tailored for ready access by users.

Additionally, with the publication of The IRM Imperative (Wiley & Sons, 1991) by James M. Kerr, the idea of managing and putting a dollar value on an organization's data resources and then reporting that value as an asset on a balance sheet became popular. In the book, Kerr described a way to populate subject-area databases from data derived from transaction-driven systems to create a storage area where summary data could be further leveraged to inform executive decision-making. This concept served to promote further thinking of how a data warehouse could be developed and managed in a practical way within any enterprise.

Key developments in early years of data warehousing:


A fact is a value, or measurement, which represents a fact about the managed entity or system.

Facts, as reported by the reporting entity, are said to be at raw level; e.g., in a mobile telephone system, if a BTS (base transceiver station) receives 1,000 requests for traffic channel allocation, allocates for 820, and rejects the remaining, it would report three facts or measurements to a management system:

Facts at the raw level are further aggregated to higher levels in various dimensions to extract more service or business-relevant information from it. These are called aggregates or summaries or aggregated facts.

For instance, if there are three BTS in a city, then the facts above can be aggregated from the BTS to the city level in the network dimension. For example:

There are three or more leading approaches to storing data in a data warehouse – the most important approaches are the dimensional approach and the normalized approach.

The dimensional approach refers to Ralph Kimball's approach in which it is stated that the data warehouse should be modeled using a Dimensional Model/star schema. The normalized approach, also called the 3NF model (Third Normal Form), refers to Bill Inmon's approach in which it is stated that the data warehouse should be modeled using an E-R model/normalized model.

In a dimensional approach, transaction data is partitioned into "facts", which are generally numeric transaction data, and "dimensions", which are the reference information that gives context to the facts. For example, a sales transaction can be broken up into facts such as the number of products ordered and the total price paid for the products, and into dimensions such as order date, customer name, product number, order ship-to and bill-to locations, and salesperson responsible for receiving the order.

A key advantage of a dimensional approach is that the data warehouse is easier for the user to understand and to use. Also, the retrieval of data from the data warehouse tends to operate very quickly. Dimensional structures are easy to understand for business users, because the structure is divided into measurements/facts and context/dimensions. Facts are related to the organization's business processes and operational system whereas the dimensions surrounding them contain context about the measurement (Kimball, Ralph 2008). Another advantage offered by dimensional model is that it does not involve a relational database every time. Thus, this type of modeling technique is very useful for end-user queries in data warehouse.

The model of facts and dimensions can also be understood as a data cube. Where the dimensions are the categorical coordinates in a multi-dimensional cube, the fact is a value corresponding to the coordinates.

The main disadvantages of the dimensional approach are the following:

In the normalized approach, the data in the data warehouse are stored following, to a degree, database normalization rules. Tables are grouped together by "subject areas" that reflect general data categories (e.g., data on customers, products, finance, etc.). The normalized structure divides data into entities, which creates several tables in a relational database. When applied in large enterprises the result is dozens of tables that are linked together by a web of joins. Furthermore, each of the created entities is converted into separate physical tables when the database is implemented (Kimball, Ralph 2008).
The main advantage of this approach is that it is straightforward to add information into the database. Some disadvantages of this approach are that, because of the number of tables involved, it can be difficult for users to join data from different sources into meaningful information and to access the information without a precise understanding of the sources of data and of the data structure of the data warehouse.

Both normalized and dimensional models can be represented in entity–relationship diagrams as both contain joined relational tables. The difference between the two models is the degree of normalization (also known as Normal Forms). These approaches are not mutually exclusive, and there are other approaches. Dimensional approaches can involve normalizing data to a degree (Kimball, Ralph 2008).

In "Information-Driven Business", Robert Hillard proposes an approach to comparing the two approaches based on the information needs of the business problem. The technique shows that normalized models hold far more information than their dimensional equivalents (even when the same fields are used in both models) but this extra information comes at the cost of usability. The technique measures information quantity in terms of information entropy and usability in terms of the Small Worlds data transformation measure.

In the "bottom-up" approach, data marts are first created to provide reporting and analytical capabilities for specific business processes. These data marts can then be integrated to create a comprehensive data warehouse. The data warehouse bus architecture is primarily an implementation of "the bus", a collection of conformed dimensions and conformed facts, which are dimensions that are shared (in a specific way) between facts in two or more data marts.

The "top-down" approach is designed using a normalized enterprise data model. "Atomic" data, that is, data at the greatest level of detail, are stored in the data warehouse. Dimensional data marts containing data needed for specific business processes or specific departments are created from the data warehouse.

Data warehouses often resemble the hub and spokes architecture. Legacy systems feeding the warehouse often include customer relationship management and enterprise resource planning, generating large amounts of data. To consolidate these various data models, and facilitate the extract transform load process, data warehouses often make use of an operational data store, the information from which is parsed into the actual data warehouse. To reduce data redundancy, larger systems often store the data in a normalized way. Data marts for specific reports can then be built on top of the data warehouse.

A hybrid (also called ensemble) data warehouse database is kept on third normal form to eliminate data redundancy. A normal relational database, however, is not efficient for business intelligence reports where dimensional modelling is prevalent. Small data marts can shop for data from the consolidated warehouse and use the filtered, specific data for the fact tables and dimensions required. The data warehouse provides a single source of information from which the data marts can read, providing a wide range of business information. The hybrid architecture allows a data warehouse to be replaced with a master data management repository where operational (not static) information could reside.

The data vault modeling components follow hub and spokes architecture. This modeling style is a hybrid design, consisting of the best practices from both third normal form and star schema. The data vault model is not a true third normal form, and breaks some of its rules, but it is a top-down architecture with a bottom up design. The data vault model is geared to be strictly a data warehouse. It is not geared to be end-user accessible, which, when built, still requires the use of a data mart or star schema-based release area for business purposes.

There are basic features that define the data in the data warehouse that include subject orientation, data integration, time-variant, nonvolatile data, and data granularity.

Unlike the operational systems, the data in the data warehouse revolves around the subjects of the enterprise. Subject orientation is not database normalization. Subject orientation can be really useful for decision-making.
Gathering the required objects is called subject-oriented.

The data found within the data warehouse is integrated. Since it comes from several operational systems, all inconsistencies must be removed. Consistencies include naming conventions, measurement of variables, encoding structures, physical attributes of data, and so forth.

While operational systems reflect current values as they support day-to-day operations, data warehouse data represents a long time horizon (up to 10 years) which means it stores mostly historical data. It is mainly meant for data mining and forecasting. (E.g. if a user is searching for a buying pattern of a specific customer, the user needs to look at data on the current and past purchases.)

The data in the data warehouse is read-only, which means it cannot be updated, created, or deleted (unless there is a regulatory or statutory obligation to do so).

In the data warehouse process, data can be aggregated in data marts at different levels of abstraction. The user may start looking at the total sale units of a product in an entire region. Then the user looks at the states in that region. Finally, they may examine the individual stores in a certain state. Therefore, typically, the analysis starts at a higher level and drills down to lower levels of details.
With data virtualization, the data used remains in its original locations and real-time access is established to allow analytics across multiple sources creating a virtual data warehouse. This can aid in resolving some technical difficulties such as compatibility problems when combining data from various platforms, lowering the risk of error caused by faulty data, and guaranteeing that the newest data is used. Furthermore, avoiding the creation of a new database containing personal information can make it easier to comply with privacy regulations. However, with data virtualization, the connection to all necessary data sources must be operational as there is no local copy of the data, which is one of the main drawbacks of the approach.

The different methods used to construct/organize a data warehouse specified by an organization are numerous. The hardware utilized, software created and data resources specifically required for the correct functionality of a data warehouse are the main components of the data warehouse architecture. All data warehouses have multiple phases in which the requirements of the organization are modified and fine-tuned.

Operational systems are optimized for the preservation of data integrity and speed of recording of business transactions through use of database normalization and an entity–relationship model. Operational system designers generally follow Codd's 12 rules of database normalization to ensure data integrity. Fully normalized database designs (that is, those satisfying all Codd rules) often result in information from a business transaction being stored in dozens to hundreds of tables. Relational databases are efficient at managing the relationships between these tables. The databases have very fast insert/update performance because only a small amount of data in those tables is affected each time a transaction is processed. To improve performance, older data are usually periodically purged from operational systems.

Data warehouses are optimized for analytic access patterns. Analytic access patterns generally involve selecting specific fields and rarely if ever , which selects all fields/columns, as is more common in operational databases. Because of these differences in access patterns, operational databases (loosely, OLTP) benefit from the use of a row-oriented DBMS whereas analytics databases (loosely, OLAP) benefit from the use of a column-oriented DBMS. Unlike operational systems which maintain a snapshot of the business, data warehouses generally maintain an infinite history which is implemented through ETL processes that periodically migrate data from the operational systems over to the data warehouse.

These terms refer to the level of sophistication of a data warehouse:




Disperser

A disperser is a one-sided extractor. Where an extractor requires that every event gets the same probability under the uniform distribution and the extracted distribution, only the latter is required for a disperser. So for a disperser, an event formula_1 we have:
formula_2

Definition (Disperser): "A" formula_3"-disperser is a function"

formula_4

"such that for every distribution" formula_5 "on" formula_6 "with" formula_7 "the support of the distribution" formula_8 "is of size at least" formula_9.

An ("N", "M", "D", "K", "e")-disperser is a bipartite graph with "N" vertices on the left side, each with degree "D", and "M" vertices on the right side, such that every subset of "K" vertices on the left side is connected to more than (1 − "e")"M" vertices on the right.

An extractor is a related type of graph that guarantees an even stronger property; every ("N", "M", "D", "K", "e")-extractor is also an ("N", "M", "D", "K", "e")-disperser.

A disperser is a high-speed mixing device used to disperse or dissolve pigments and other solids into a liquid.


Devonian

The Devonian ( ) is a geologic period and system of the Paleozoic era during the Phanerozoic eon, spanning 60.3 million years from the end of the preceding Silurian period at million years ago (Ma), to the beginning of the succeeding Carboniferous period at Ma. It is named after Devon, South West England, where rocks from this period were first studied.

The first significant evolutionary radiation of life on land occurred during the Devonian, as free-sporing land plants (pteridophytes) began to spread across dry land, forming extensive coal forests which covered the continents. By the middle of the Devonian, several groups of vascular plants had evolved leaves and true roots, and by the end of the period the first seed-bearing plants (pteridospermatophytes) appeared. This rapid evolution and colonization process, which had begun during the Silurian, is known as the Silurian-Devonian Terrestrial Revolution. The earliest land animals, predominantly arthropods such as myriapods, arachnids and hexapods, also became well-established early in this period, after beginning their colonization of land at least from the Ordovician period.

Fishes, especially jawed fish, reached substantial diversity during this time, leading the Devonian to often be dubbed the Age of Fishes. The armored placoderms began dominating almost every known aquatic environment. In the oceans, cartilaginous fishes such as primitive sharks became more numerous than in the Silurian and Late Ordovician. Tetrapodomorphs, which include the ancestors of all four-limbed vertebrates (i.e. tetrapods), began diverging from freshwater lobe-finned fish as their more robust and muscled pectoral and pelvic fins gradually evolved into forelimbs and hindlimbs, though they were not fully established for life on land until the Late Carboniferous.

The first ammonites, a subclass of cephalopod molluscs, appeared. Trilobites, brachiopods and the great coral reefs were still common during the Devonian. The Late Devonian extinction, which started about 375 Ma, severely affected marine life, killing off most of the reef systems, most of the jawless fish, half of all placoderms, and nearly all trilobites save for a few species of the order Proetida. The subsequent end-Devonian extinction, which occurred at around 359 Ma, further impacted the ecosystems and completed the extinction of all calcite sponge reefs and placoderms.

Devonian palaeogeography was dominated by the supercontinent Gondwana to the south, the small continent of Siberia to the north, and the medium-sized continent of Laurussia to the east. Major tectonic events include the closure of the Rheic Ocean, the separation of South China from Gondwana, and the resulting expansion of the Paleo-Tethys Ocean. The Devonian experienced several major mountain-building events as Laurussia and Gondwana approached; these include the Acadian Orogeny in North America and the beginning of the Variscan Orogeny in Europe. These early collisions preceded the formation of the single supercontinent Pangaea in the Late Paleozoic.

The period is named after Devon, a county in southwestern England, where a controversial argument in the 1830s over the age and structure of the rocks found distributed throughout the county was eventually resolved by the definition of the Devonian Period in the geological timescale. The Great Devonian Controversy was a long period of vigorous argument and counter-argument between the main protagonists of Roderick Murchison with Adam Sedgwick against Henry De la Beche supported by George Bellas Greenough. Murchison and Sedgwick won the debate and named the period they proposed as the Devonian System.

While the rock beds that define the start and end of the Devonian Period are well identified, the exact dates are uncertain. According to the International Commission on Stratigraphy, the Devonian extends from the end of the Silurian Ma, to the beginning of the Carboniferous Ma – in North America, at the beginning of the Mississippian subperiod of the Carboniferous.

In 19th-century texts the Devonian has been called the "Old Red Age", after the red and brown terrestrial deposits known in the United Kingdom as the Old Red Sandstone in which early fossil discoveries were found. Another common term is "Age of the Fishes", referring to the evolution of several major groups of fish that took place during the period. Older literature on the Anglo-Welsh basin divides it into the Downtonian, Dittonian, Breconian, and Farlovian stages, the latter three of which are placed in the Devonian.

The Devonian has also erroneously been characterised as a "greenhouse age", due to sampling bias: most of the early Devonian-age discoveries came from the strata of western Europe and eastern North America, which at the time straddled the Equator as part of the supercontinent of Euramerica where fossil signatures of widespread reefs indicate tropical climates that were warm and moderately humid. In fact the climate in the Devonian differed greatly during its epochs and between geographic regions. For example, during the Early Devonian, arid conditions were prevalent through much of the world including Siberia, Australia, North America, and China, but Africa and South America had a warm temperate climate. In the Late Devonian, by contrast, arid conditions were less prevalent across the world and temperate climates were more common.

The Devonian Period is formally broken into Early, Middle and Late subdivisions. The rocks corresponding to those epochs are referred to as belonging to the Lower, Middle and Upper parts of the Devonian System.

The Early Devonian lasted from to Ma. It began with the Lochkovian Stage to Ma, which was followed by the Pragian from to Ma and then by the Emsian, which lasted until the Middle Devonian began, Ma.
During this time, the first ammonoids appeared, descending from bactritoid nautiloids. Ammonoids during this time period were simple and differed little from their nautiloid counterparts. These ammonoids belong to the order Agoniatitida, which in later epochs evolved to new ammonoid orders, for example Goniatitida and Clymeniida. This class of cephalopod molluscs would dominate the marine fauna until the beginning of the Mesozoic Era.

The Middle Devonian comprised two subdivisions: first the Eifelian, which then gave way to the Givetian Ma. During this time the jawless agnathan fishes began to decline in diversity in freshwater and marine environments partly due to drastic environmental changes and partly due to the increasing competition, predation, and diversity of jawed fishes. The shallow, warm, oxygen-depleted waters of Devonian inland lakes, surrounded by primitive plants, provided the environment necessary for certain early fish to develop such essential characteristics as well developed lungs, and the ability to crawl out of the water and onto the land for short periods of time.

Finally, the Late Devonian started with the Frasnian, to Ma, during which the first forests took shape on land. The first tetrapods appeared in the fossil record in the ensuing Famennian subdivision, the beginning and end of which are marked with extinction events. This lasted until the end of the Devonian, Ma.

The Devonian was a relatively warm period, although significant glaciers may have existed during the Early and Middle Devonian. The temperature gradient from the equator to the poles was not as large as it is today. The weather was also very arid, mostly along the equator where it was the driest. Reconstruction of tropical sea surface temperature from conodont apatite implies an average value of in the Early Devonian. Early Devonian mean annual surface temperatures were approximately 16 °C. levels dropped steeply throughout the Devonian Period. The newly evolved forests drew carbon out of the atmosphere, which were then buried into sediments. This may be reflected by a Mid-Devonian cooling of around . The Late Devonian warmed to levels equivalent to the Early Devonian; while there is no corresponding increase in concentrations, continental weathering increases (as predicted by warmer temperatures); further, a range of evidence, such as plant distribution, points to a Late Devonian warming. The climate would have affected the dominant organisms in reefs; microbes would have been the main reef-forming organisms in warm periods, with corals and stromatoporoid sponges taking the dominant role in cooler times. The warming at the end of the Devonian may even have contributed to the extinction of the stromatoporoids. At the terminus of the Devonian, Earth rapidly cooled into an icehouse, marking the beginning of the Late Paleozoic icehouse.

The Devonian world involved many continents and ocean basins of various sizes. The largest continent, Gondwana, was located entirely within the Southern Hemisphere. It corresponds to modern day South America, Africa, Australia, Antarctica, and India, as well as minor components of North America and Asia. The second-largest continent, Laurussia, was northwest of Gondwana, and corresponds to much of modern-day North America and Europe. Various smaller continents, microcontinents, and terranes were present east of Laurussia and north of Gondwana, corresponding to parts of Europe and Asia. The Devonian Period was a time of great tectonic activity, as the major continents of Laurussia and Gondwana drew closer together.

Sea levels were high worldwide, and much of the land lay under shallow seas, where tropical reef organisms lived. The enormous "world ocean", Panthalassa, occupied much of the Northern Hemisphere as well as wide swathes east of Gondwana and west of Laurussia. Other minor oceans were the Paleo-Tethys Ocean and Rheic Ocean.

By the early Devonian, the continent Laurussia (also known as Euramerica) was fully formed through the collision of the continents Laurentia (modern day North America) and Baltica (modern day northern and eastern Europe). The tectonic effects of this collision continued into the Devonian, producing a string of mountain ranges along the southeastern coast of the continent. In present-day eastern North America, the Acadian Orogeny continued to raise the Appalachian Mountains. Further east, the collision also extended the rise of the Caledonian Mountains of Great Britain and Scandinavia. As the Caledonian Orogeny wound down in the later part of the period, orogenic collapse facilitated a cluster of granite intrusions in Scotland.

Most of Laurussia was located south of the equator, but in the Devonian it moved northwards and began to rotate counterclockwise towards its modern position. While the most northern parts of the continent (such as Greenland and Ellesmere Island) established tropical conditions, most of the continent was located within the natural dry zone along the Tropic of Capricorn, which (as nowadays) is a result of the convergence of two great air-masses, the Hadley cell and the Ferrel cell. In these near-deserts, the Old Red Sandstone sedimentary beds formed, made red by the oxidised iron (hematite) characteristic of drought conditions. The abundance of red sandstone on continental land also lends Laurussia the name "the Old Red Continent". For much of the Devonian, the majority of western Laurussia (North America) was covered by subtropical inland seas which hosted a diverse ecosystem of reefs and marine life. Devonian marine deposits are particularly prevalent in the midwestern and northeastern United States. Devonian reefs also extended along the southeast edge of Laurussia, a coastline now corresponding to southern England, Belgium, and other mid-latitude areas of Europe.

In the Early and Middle Devonian, the west coast of Laurussia was a passive margin with broad coastal waters, deep silty embayments, river deltas and estuaries, found today in Idaho and Nevada. In the Late Devonian, an approaching volcanic island arc reached the steep slope of the continental shelf and began to uplift deep water deposits. This minor collision sparked the start of a mountain-building episode called the Antler orogeny, which extended into the Carboniferous. Mountain building could also be found in the far northeastern extent of the continent, as minor tropical island arcs and detached Baltic terranes re-join the continent. Deformed remnants of these mountains can still be found on Ellesmere Island and Svalbard. Many of the Devonian collisions in Laurussia produce both mountain chains and foreland basins, which are frequently fossiliferous.

Gondwana was by far the largest continent on the planet. It was completely south of the equator, although the northeastern sector (now Australia) did reach tropical latitudes. The southwestern sector (now South America) was located to the far south, with Brazil situated near the South Pole. The northwestern edge of Gondwana was an active margin for much of the Devonian, and saw the accretion of many smaller land masses and island arcs. These include Chilenia, Cuyania, and Chaitenia, which now form much of Chile and Patagonia. These collisions were associated with volcanic activity and plutons, but by the Late Devonian the tectonic situation had relaxed and much of South America was covered by shallow seas. These south polar seas hosted a distinctive brachiopod fauna, the Malvinokaffric Realm, which extended eastward to marginal areas now equivalent to South Africa and Antarctica. Malvinokaffric faunas even managed to approach the South Pole via a tongue of Panthalassa which extended into the Paraná Basin.

The northern rim of Gondwana was mostly a passive margin, hosting extensive marine deposits in areas such as northwest Africa and Tibet. The eastern margin, though warmer than the west, was equally active. Numerous mountain building events and granite and kimberlite intrusions affected areas equivalent to modern day eastern Australia, Tasmania, and Antarctica.

Several island microcontinents (which would later coalesce into modern day Asia) stretched over a low-latitude archipelago to the north of Gondwana. They were separated from the southern continent by an oceanic basin: the Paleo-Tethys. Although the western Paleo-Tethys Ocean had existed since the Cambrian, the eastern part only began to rift apart as late as the Silurian. This process accelerated in the Devonian. The eastern branch of the Paleo-Tethys was fully opened when South China and Annamia (a terrane equivalent to most of Indochina), together as a unified continent, detached from the northeastern sector of Gondwana. Nevertheless, they remained close enough to Gondwana that their Devonian fossils were more closely related to Australian species than to north Asian species. Other Asian terranes remained attached to Gondwana, including Sibumasu (western Indochina), Tibet, and the rest of the Cimmerian blocks.

While the South China-Annamia continent was the newest addition to the Asian microcontinents, it was not the first. North China and the Tarim Block (now northwesternmost China) were located westward and continued to drift northwards, powering over older oceanic crust in the process. Further west was a small ocean (the Turkestan Ocean), followed by the larger microcontinents of Kazakhstania, Siberia, and Amuria. Kazakhstania was a volcanically active region during the Devonian, as it continued to assimilate smaller island arcs. The island arcs of the region, such as the Balkhash-West Junggar Arc, exhibited biological endemism as a consequence of their location.

Siberia was located just north of the equator as the largest landmass in the Northern Hemisphere. At the beginning of the Devonian, Siberia was inverted (upside down) relative to its modern orientation. Later in the period it moved northwards and began to twist clockwise, though it was not near its modern location. Siberia approached the eastern edge of Laurussia as the Devonian progressed, but it was still separated by a seaway, the Ural Ocean. Although Siberia's margins were generally tectonically stable and ecologically productive, rifting and deep mantle plumes impacted the continent with flood basalts during the Late Devonian. The Altai-Sayan region was shaken by volcanism in the Early and Middle Devonian, while Late Devonian magmatism was magnified further to produce the Vilyuy Traps, flood basalts which may have contributed to the Late Devonian Mass Extinction. The last major round of volcanism, the Yakutsk Large Igneous Province, continued into the Carboniferous to produce extensive kimberlite deposits.

Similar volcanic activity also affected the nearby microcontinent of Amuria (now Manchuria, Mongolia and their vicinities). Though certainly close to Siberia in the Devonian, the precise location of Amuria is uncertain due to contradictory paleomagnetic data.

The Rheic Ocean, which separated Laurussia from Gondwana, was wide at the start of the Devonian, having formed after the drift of Avalonia away from Gondwana. It steadily shrunk as the period continued, as the two major continents approached near the equator in the early stages of the assembly of Pangaea. The closure of the Rheic Ocean began in the Devonian and continued into the Carboniferous. As the ocean narrowed, endemic marine faunas of Gondwana and Laurussia combined into a single tropical fauna. The history of the western Rheic Ocean is a subject of debate, but there is good evidence that Rheic oceanic crust experienced intense subduction and metamorphism under Mexico and Central America.

The closure of the eastern part of the Rheic Ocean is associated with the assemblage of central and southern Europe. In the early Paleozoic, much of Europe was still attached to Gondwana, including the terranes of Iberia, Armorica (France), Palaeo-Adria (the western Mediterranean area), Bohemia, Franconia, and Saxothuringia. These continental blocks, collectively known as the Armorican Terrane Assemblage, split away from Gondwana in the Silurian and drifted towards Laurussia through the Devonian. Their collision with Laurussia leads to the beginning of the Variscan Orogeny, a major mountain-building event which would escalate further in the Late Paleozoic. Franconia and Saxothuringia collided with Laurussia near the end of the Early Devonian, pinching out the easternmost Rheic Ocean. The rest of the Armorican terranes followed, and by the end of the Devonian they were fully connected with Laurussia. This sequence of rifting and collision events led to the successive creation and destruction of several small seaways, including the Rheno-Hercynian, Saxo-Thuringian, and Galicia-Moldanubian oceans. Their sediments were eventually compressed and completely buried as Gondwana fully collided with Laurussia in the Carboniferous.

Sea levels in the Devonian were generally high. Marine faunas continued to be dominated by conodonts, bryozoans, diverse and abundant brachiopods, the enigmatic hederellids, microconchids, and corals. Lily-like crinoids (animals, their resemblance to flowers notwithstanding) were abundant, and trilobites were still fairly common. Bivalves became commonplace in deep water and outer shelf environments. The first ammonites also appeared during or slightly before the early Devonian Period around 400  Ma. Bactritoids make their first appearance in the Early Devonian as well; their radiation, along with that of ammonoids, has been attributed by some authors to increased environmental stress resulting from decreasing oxygen levels in the deeper parts of the water column. Among vertebrates, jawless armored fish (ostracoderms) declined in diversity, while the jawed fish (gnathostomes) simultaneously increased in both the sea and fresh water. Armored placoderms were numerous during the early ages of the Devonian Period and became extinct in the Late Devonian, perhaps because of competition for food against the other fish species. Early cartilaginous (Chondrichthyes) and bony fishes (Osteichthyes) also become diverse and played a large role within the Devonian seas. The first abundant genus of cartilaginous fish, "Cladoselache", appeared in the oceans during the Devonian Period. The great diversity of fish around at the time has led to the Devonian being given the name "The Age of Fishes" in popular culture.

The Devonian saw significant expansion in the diversity of nektonic marine life driven by the abundance of planktonic microorganisms in the free water column as well as high ecological competition in benthic habitats, which were extremely saturated; this diversification has been labeled the "Devonian Nekton Revolution" by many researchers. However, other researchers have questioned whether this revolution existed at all; a 2018 study found that although the proportion of biodiversity constituted by nekton increased across the boundary between the Silurian and Devonian, it decreased across the span of the Devonian, particularly during the Pragian, and that the overall diversity of nektonic taxa did not increase significantly during the Devonian compared to during other geologic periods, and was in fact higher during the intervals spanning from the Wenlock to the Lochkovian and from the Carboniferous to the Permian. The study's authors instead attribute the increased overall diversity of nekton in the Devonian to a broader, gradual trend of nektonic diversification across the entire Palaeozoic.

A now-dry barrier reef, located in present-day Kimberley Basin of northwest Australia, once extended , fringing a Devonian continent. Reefs are generally built by various carbonate-secreting organisms that can erect wave-resistant structures near sea level. Although modern reefs are constructed mainly by corals and calcareous algae, Devonian reefs were either microbial reefs built up mostly by autotrophic cyanobacteria or coral-stromatoporoid reefs built up by coral-like stromatoporoids and tabulate and rugose corals. Microbial reefs dominated under the warmer conditions of the early and late Devonian, while coral-stromatoporoid reefs dominated during the cooler middle Devonian.

By the Devonian Period, life was well underway in its colonization of the land. The moss forests and bacterial and algal mats of the Silurian were joined early in the period by primitive rooted plants that created the first stable soils and harbored arthropods like mites, scorpions, trigonotarbids and myriapods (although arthropods appeared on land much earlier than in the Early Devonian and the existence of fossils such as "Protichnites" suggest that amphibious arthropods may have appeared as early as the Cambrian). By far the largest land organism at the beginning of this period was the enigmatic "Prototaxites", which was possibly the fruiting body of an enormous fungus, rolled liverwort mat, or another organism of uncertain affinities that stood more than tall, and towered over the low, carpet-like vegetation during the early part of the Devonian. Also, the first possible fossils of insects appeared around 416  Ma, in the Early Devonian. Evidence for the earliest tetrapods takes the form of trace fossils in shallow lagoon environments within a marine carbonate platform/shelf during the Middle Devonian, although these traces have been questioned and an interpretation as fish feeding traces ("Piscichnus") has been advanced.

Many Early Devonian plants did not have true roots or leaves like extant plants, although vascular tissue is observed in many of those plants. Some of the early land plants such as "Drepanophycus" likely spread by vegetative growth and spores. The earliest land plants such as "Cooksonia" consisted of leafless, dichotomous axes with terminal sporangia and were generally very short-statured, and grew hardly more than a few centimetres tall. Fossils of "Armoricaphyton chateaupannense", about 400 million years old, represent the oldest known plants with woody tissue. By the Middle Devonian, shrub-like forests of primitive plants existed: lycophytes, horsetails, ferns, and progymnosperms evolved. Most of these plants had true roots and leaves, and many were quite tall. The earliest-known trees appeared in the Middle Devonian. These included a lineage of lycopods and another arborescent, woody vascular plant, the cladoxylopsids and progymnosperm "Archaeopteris". These tracheophytes were able to grow to large size on dry land because they had evolved the ability to biosynthesize lignin, which gave them physical rigidity and improved the effectiveness of their vascular system while giving them resistance to pathogens and herbivores. These are the oldest-known trees of the world's first forests. By the end of the Devonian, the first seed-forming plants had appeared. This rapid appearance of many plant groups and growth forms has been referred to as the Devonian Explosion or the Silurian-Devonian Terrestrial Revolution.

The 'greening' of the continents acted as a carbon sink, and atmospheric concentrations of carbon dioxide may have dropped. This may have cooled the climate and led to a massive extinction event. ("See" Late Devonian extinction).

Primitive arthropods co-evolved with this diversified terrestrial vegetation structure. The evolving co-dependence of insects and seed plants that characterized a recognizably modern world had its genesis in the Late Devonian Epoch. The development of soils and plant root systems probably led to changes in the speed and pattern of erosion and sediment deposition. The rapid evolution of a terrestrial ecosystem that contained copious animals opened the way for the first vertebrates to seek terrestrial living. By the end of the Devonian, arthropods were solidly established on the land.

The Late Devonian extinction is not a single event, but rather is a series of pulsed extinctions at the Givetian-Frasnian boundary, the Frasnian-Famennian boundary, and the Devonian-Carboniferous boundary. Together, these are considered one of the "Big Five" mass extinctions in Earth's history. The Devonian extinction crisis primarily affected the marine community, and selectively affected shallow warm-water organisms rather than cool-water organisms. The most important group to be affected by this extinction event were the reef-builders of the great Devonian reef systems.

Amongst the severely affected marine groups were the brachiopods, trilobites, ammonites, and acritarchs, and the world saw the disappearance of an estimated 96% of vertebrates like conodonts and bony fishes, and all of the ostracoderms and placoderms. Land plants as well as freshwater species, such as our tetrapod ancestors, were relatively unaffected by the Late Devonian extinction event (there is a counterargument that the Devonian extinctions nearly wiped out the tetrapods).

The reasons for the Late Devonian extinctions are still unknown, and all explanations remain speculative. Canadian paleontologist Digby McLaren suggested in 1969 that the Devonian extinction events were caused by an asteroid impact. However, while there were Late Devonian collision events (see the Alamo bolide impact), little evidence supports the existence of a large enough Devonian crater.



Dungeon Master (disambiguation)

A Dungeon Master is the organizer of a "Dungeons & Dragons" role-playing game.

Dungeon Master may also refer to:




David Thompson (explorer)

David Thompson (30 April 1770 – 10 February 1857) was an Anglo-Canadian fur trader, surveyor, and cartographer, known to some native people as "Koo-Koo-Sint" or "the Stargazer". Over Thompson's career, he travelled across North America, mapping of the continent along the way. For this historic feat, Thompson has been described as the "greatest practical land geographer that the world has produced".

David Thompson was born in Westminster, Middlesex, to recent Welsh migrants David and Ann Thompson. When Thompson was two, his father died. Due to his widowed mother not having financial resources, she placed Thompson, 29 April 1777, the day before his seventh birthday, and his older brother in the Grey Coat Hospital, a school for the disadvantaged of Westminster. Thompson graduated to the Grey Coat mathematical school, well known for teaching navigation and surveying. 

He received an education for the Royal Navy: including mathematics of trigonometry and geometry, practical navigation including using of nautical instruments, finding latitudes and longitudes and making navigational calculations from observing the sun, moon and tide, and drawing maps and charts, taking land measurements, and sketching landscapes. He later built on these skills to make his career. In 1784, when Thompson was 14, the Grey Coat treasurer paid the Hudson's Bay Company the sum of five pounds, upon which the youth became an apprentice employee of the company, contracted for a period of seven years to be trained as a clerk.<ref name="Thompson/Moreau p.xxiii">Thompson/Moreau p. xxiii</ref> 

He set sail on a ship to North America on 28 May of that year, leaving England.

On 2 September 1784, Thompson arrived in Churchill (now in Manitoba) and was put to work as a clerk/secretary, copying the personal papers of the governor of Fort Churchill, Samuel Hearne. The next year he was transferred to nearby York Factory, and over the next few years spent time as a secretary at Cumberland House, Saskatchewan, and South Branch House of the Hudson Bay Company before being transferred to Manchester House in 1787. During those years he learned to keep accounts and other records, calculate values of furs (It was noted that he also had several expensive beaver pelts at that time even when a secretary's job would not pay terribly well), track supplies and other duties.

On 23 December 1788, Thompson seriously fractured his tibia, forcing him to spend the next two winters at Cumberland House convalescing. It was during this time that he greatly refined and expanded his mathematical, astronomical, and surveying skills under the tutelage of Hudson's Bay Company surveyor Philip Turnor. It was also during this time that he lost sight in his right eye.

In 1790, with his apprenticeship nearing its end, Thompson requested a set of surveying tools in place of the typical parting gift of fine clothes offered by the company to those completing their indenture. He received both. He entered the employ of the Hudson's Bay Company as a fur trader. In 1792 he completed his first significant survey, mapping a route to Lake Athabasca (where today's Alberta/Saskatchewan border is located). 

Between February and May 1793, Thompson made 34 observations of the longitude of Cumberland House using lunar distances. The mean of these observations was 102°12′ W, about 2' east of the modern value. The mean error of the 34 observations was about 15' of longitude. Broughton (2009) notes that the precision of the type of sextant used by Thompson was 15" of arc, corresponding to 7.5' of longitude giving an absolute limit to the precision of an individual observation. The error in Thompson's mean was several times less than this. The time he took on these observations, about 3 hours of calculation each, indicates that he understood the power of averages.

In recognition of his map-making and surveying skills, the company promoted Thompson to the surveyor in 1794. He continued working for the Hudson's Bay Company until 23 May 1797 when, frustrated by an order to cease surveying and focus on the fur trade, he left. He walked in the snow in order to enter the employ of the competition, the North West Company. There he continued to work as a fur trader and surveyor.

Thompson's decision to defect to the North West Company (NWC) in 1797 without providing the customary one-year notice was not well received by his former employers. But the North West Company was more supportive of Thompson pursuing his work on surveying and mapping the interior of what was to become Canada, as they judged it in the company's interest to know the exact locations of their settlements and the distances between them. In 1797, Thompson was sent south by his employers to survey part of the Canada-US boundary along the water routes from Lake Superior to Lake of the Woods to satisfy unresolved questions of territory arising from the Jay Treaty between Great Britain and the United States after the American Revolutionary War.

By 1798 Thompson had completed a survey of from Grand Portage, through Lake Winnipeg, to the headwaters of the Assiniboine and Mississippi rivers, as well as two sides of Lake Superior. In 1798, the company sent him to Red Deer Lake (Lac La Biche in present-day Alberta) to establish a trading post. (The English translation of Lac la Biche: Red Deer Lake, was first recorded on the Mackenzie map of 1793.) Thompson spent the next few seasons trading based in Fort George (now in Alberta), and during this time led several expeditions into the Rocky Mountains.

On 10 July 1804, at the annual meeting of the North West Company in Kaministiquia, Thompson was made a full partner of the company. He became a 'wintering partner', who was based in the field rather than Montreal, and was granted two of the 92 NWC's shares worth more than £4,000. He spent the next few seasons based there managing the fur trading operations, but still finding time to expand his surveys of the waterways around Lake Superior. At the 1806 company meeting, officers decided to send Thompson back into the interior. Concern over the United States-backed expedition of Lewis and Clark prompted the North West Company to charge Thompson with the task of finding a route to the Pacific to open up the lucrative trading territories of the Pacific Northwest.

After the general meeting in 1806, Thompson travelled to Rocky Mountain House and prepared for an expedition to follow the Columbia River to the Pacific Ocean. In June 1807 Thompson crossed the Rocky Mountains and spent the summer surveying the Columbia basin; he continued to survey the area over the next few seasons. Thompson mapped and established trading posts in Northwestern Montana, Idaho, Washington, and Western Canada. Trading posts he founded included Kootenae House, Kullyspell House and Saleesh House; the latter two were the first trading posts west of the Rockies in Idaho and Montana, respectively. These posts established by Thompson extended North West Company fur trading territory into the Columbia Basin drainage area. The maps he made of the Columbia River basin east of the Cascade Mountains were of such high quality and detail that they continued to be useful into the 20th-century.

In early 1810, Thompson was returning eastward toward Montreal but, while en route at Rainy Lake, received orders to return to the Rocky Mountains and establish a route to the mouth of the Columbia. The North West Company was responding to the plans of American entrepreneur John Jacob Astor to send a ship around the Americas to establish a fur trading post of the Pacific Fur Company on the Pacific Coast. During his return, Thompson was delayed by an angry group of Peigan natives at Howse Pass. He was ultimately forced to seek a new route across the Rocky Mountains and found one through the Athabasca Pass.

David Thompson was the first European to navigate the full length of the Columbia River. Between Kettle Falls (3 July 1811) and the Junction of the Columbia and Snake Rivers (9 July), he was travelling through country that had never been visited by Europeans, and took time to visit the villages along the way to establish good relations, helped by copious quantities of tobacco. In 1805 Lewis and Clark had descended the Snake River, and continued down the Columbia. On reaching the junction Thompson erected a pole and a notice claiming the country for Great Britain and stating the intention of the North West Company to build a trading post at the site. This notice was found later that year by Astor company workers looking to establish an inland fur post, contributing to their selection of a more northerly site at Fort Okanogan. The North West Company established its post of Fort Nez Percés near the Snake River confluence several years later. Continuing down the Columbia, Thompson passed over the Celilo Falls, almost losing the canoe on the rocks, and portaged around the rapids of The Dalles and the Cascades Rapids. On 14 July 1811, Thompson reached the partially constructed Fort Astoria at the mouth of the Columbia, arriving two months after the Pacific Fur Company's ship, the "Tonquin".

Before returning upriver and across the mountains, Thompson hired Naukane, a Native Hawaiian Takane labourer brought to Fort Astoria by the Pacific Fur Company's ship "Tonquin". Naukane, known as Coxe to Thompson, accompanied Thompson across the continent to Lake Superior before journeying on to England.

Thompson wintered at Saleesh House before beginning his final journey in 1812 back to Montreal, where the North West Company was based.

In his published journals, Thompson recorded seeing large footprints (“which measured fourteen inches in length by eight inches in breadth”) near what is now Jasper, Alberta, in 1811. It has been suggested that these prints were similar to what has since been called the sasquatch. However, Thompson noted that these tracks showed "a small Nail at the end of each [toe]", which led him to surmise it was a bear, but he had doubts, saying, "I held it to be the track of a large old grizzled bear; yet the shortness of the nails, the ball of the foot, and its great size was not that of a Bear".

The years 1807-1812 are the most carefully scrutinized in his career and comprise his most enduring historical legacy, due to his development of the commercial routes across the Rockies, and his mapping of the lands they traverse.

In 1820, the English geologist, John Jeremiah Bigsby, attended a dinner party given by The Hon. William McGillivray at his home, Chateau St. Antoine, one of the early estates in Montreal's Golden Square Mile. He describes the party and some of the guests in his entertaining book "The Shoe and Canoe", giving an excellent description of David Thompson:

On 10 June 1799 at Île-à-la-Crosse, Thompson married Charlotte Small, a thirteen-year-old Métis daughter of Scottish fur trader Patrick Small and a Cree mother. Their marriage was formalised thirteen years later at the Scotch Presbyterian Church in Montreal on 30 October 1812. He and Charlotte had 13 children together; five of them were born before he left the fur trade. The family did not adjust easily to life in Eastern Canada; they lived in Montreal while he was travelling. Two of the children, John (aged 5) and Emma (aged 7), died of round worms, a common parasite. By the time of Thompson's death, the couple had been married 57 years, the longest marriage known in Canada pre-Confederation.

Upon his arrival back in Montreal, Thompson retired with a generous pension from the North West Company. He settled in nearby Terrebonne and worked on completing his great map, a summary of his lifetime of exploring and surveying the interior of North America. The map covered the wide area stretching from Lake Superior to the Pacific, and was given by Thompson to the North West Company. Thompson's 1814 map, his greatest achievement, was so accurate that 100 years later it was still the basis for many of the maps issued by the Canadian government. It now resides in the Archives of Ontario.

In 1815, Thompson moved his family to Williamstown, Upper Canada, and a few years later was employed to survey the newly established borders with the United States from Lake of the Woods to the Eastern Townships of Quebec, established by Treaty of Ghent after the War of 1812. In 1843 Thompson completed his atlas of the region from Hudson Bay to the Pacific Ocean.

Afterwards, Thompson returned to a life as a land owner, but soon financial misfortune would ruin him. By 1831 he was so deeply in debt he was forced to take up a position as a surveyor for the British American Land Company to provide for his family. His luck continued to worsen and he was forced to move in with his daughter and son-in-law in 1845. He began work on a manuscript chronicling his life exploring the continent, but this project was left unfinished when his sight failed him completely in 1851.

The land mass mapped by Thompson amounted to of wilderness (one-fifth of the continent). His contemporary, the great explorer Alexander Mackenzie, remarked that Thompson did more in ten months than he would have thought possible in two years.

Despite these significant achievements, Thompson died in Montreal in near obscurity on 10 February 1857, his accomplishments almost unrecognised. He never finished the book of his 28 years in the fur trade, based on his 77 field notebooks, before he died. In the 1890s geologist J.B. Tyrrell resurrected Thompson's notes and in 1916 published them as "David Thompson's Narrative", as part of the General Series of the Champlain Society. Further editions and re-examinations of Thompson's life and works were published in 1962 by Richard Glover, in 1971 by Victor Hopwood, and in 2015 by William Moreau.
Thompson's body was interred in Montreal's Mount Royal Cemetery in an unmarked grave. It was not until 1926 that efforts by J.B. Tyrrell and the Canadian Historical Society resulted in the placing of a tombstone to mark his grave. The next year, Thompson was named a National Historic Person by the federal government, one of the earliest such designations. A federal plaque reflecting that status is located at Jasper National Park, Alberta. Meantime, Thompson's achievements are central reasons for other national historic designations:

In 1957, one hundred years after his death, Canada's post office department honoured him with his image on a postage stamp. The David Thompson Highway in Alberta was named in his honour, along with David Thompson High School situated on the side of the highway near Leslieville, Alberta. There are also two David Thompson Secondary Schools, one in Vancouver, BC, and one in Invermere, BC.

His prowess as a geographer is now well-recognized. He has been called "the greatest land geographer that the world has produced."

There is a monument dedicated to David Thompson (maintained by the state of North Dakota) near the former town site of the ghost town Verendrye, North Dakota, located approximately north and west of Karlsruhe, North Dakota. Thompson Falls, Montana, and British Columbia's Thompson River and Thompson Falls on the Blaeberry River are also named after the explorer.
The year 2007 marked the 150th year of Thompson's death and the 200th anniversary of his first crossing of the Rocky Mountains. Commemorative events and exhibits were planned across Canada and the United States from 2007 to 2011 as a celebration of his accomplishments.

In 2007, a commemorative plaque was placed on a wall at the Grey Coat Hospital, the school for the disadvantaged of Westminster David Thompson attended as a boy, by English author and TV presenter Ray Mears.

Thompson was the subject of a 1964 National Film Board of Canada short film "David Thompson: The Great Mapmaker ", as well as the BBC2 programme "Ray Mears' Northern Wilderness" (Episode 5), broadcast in November 2009. He's also the subject of 2010 KSPS-TV film Uncharted Territory: David Thompson on the Columbia Plateau.

He is referenced in the 1981 folk song "Northwest Passage" by Stan Rogers.

The national park service, Parks Canada, announced in 2018 that it had named its new research vessel , to be used for underwater archaeology, including sea floor mapping, and for marine science in the Pacific, Atlantic, Arctic Oceans, and the Great Lakes. It will be the main platform for research on the Wrecks of HMS "Erebus" and HMS "Terror" National Historic Site.

The David Thompson Astronomical Observatory at Fort William Historical Park was named to commemorate David Thompson and his discoveries.






Dioscoreales

The Dioscoreales are an order of monocotyledonous flowering plants, organized under modern classification systems, such as the Angiosperm Phylogeny Group or the Angiosperm Phylogeny Web. Among monocot plants, Dioscoreales are grouped with the lilioid monocots, wherein they are a sister group to the Pandanales. In total, the order Dioscoreales comprises three families, 22 genera and about 850 species.

Dioscoreales contains the family Dioscoreaceae, which notably includes the yams ("Dioscorea") and several other bulbous and tuberous plants, some of which are heavily cultivated as staple food sources in certain countries. 

Certain species are found solely in arid climates (incl. parts of Southern Africa), and have adapted to this harsh environment as caudex-forming, perennial caudiciformes, including "Dioscorea elephantipes", the "elephant's foot" or "elephant-foot yam".

Older systems tended to place all lilioid monocots with reticulate veined leaves (such as Smilacaceae and Stemonaceae together with Dioscoraceae) in Dioscoreales; as currently circumscribed by phylogenetic analysis, using combined morphology and molecular methods, Dioscreales now contains many reticulate-veined vines within the Dioscoraceae, as well as the myco-heterotrophic Burmanniaceae and the autotrophic Nartheciaceae.

Dioscoreales are vines or herbaceous forest floor plants. They may be achlorophyllous or saprophytic. Synapomorphies include tuberous roots, glandular hairs, seed coat characteristics and the presence of calcium oxalate crystals. Other characteristics of the order include the presence of saponin steroids, annular vascular bundles that are found in both the stem and leaf. The leaves are often unsheathed at the base, have a distinctive petiole and reticulate veined lamina. Alternatively they may be small and scale-like with a sheathed base. The flowers are actinomorphic, and may be bisexual or dioecious, while the flowers or inflorescence bear glandular hairs. The perianth may be conspicuous or reduced and the style is short with well developed style branches. The tepals persist in the development of the fruit, which is a dry capsule or berry. In the seed, the endotegmen is tanniferous and the embryo short.

All of the species except the genera placed in Nartheciaceae express simultaneous microsporogenesis. Plants in Nartheciaceae show successive microsporogenesis which is one of the traits indicating that the family is sister to all the other members included in the order.

For the early history from Lindley (1853) onwards, see Caddick "et al." (2000) Table 1, Caddick et al. (2002a) Table 1 and Table 2 in Bouman (1995). The taxonomic classification of Dioscoreales has been complicated by the presence of a number of morphological features reminiscent of the dicotyledons, leading some authors to place the order as intermediate between the monocotyledons and the dicotyledons.
While Lindley did not use the term "Dioscoreales", he placed the family Dioscoraceae together with four other families in what he referred to as an Alliance (the equivalent of the modern Order) called Dictyogens. He reflected the uncertainty as to the place of this Alliance by placing it as a class of its own between Endogens (monocots) and Exogens (dicots) The botanical authority is given to von Martius (1835) by APG for his description of the family Dioscoreae or "Ordo", while other sources cite Hooker (Dioscoreales Hook.f.) for his use of the term "Dioscorales" in 1873 with a single family, Dioscoreae. However, in his more definitive work, the "Genera plantara" (1883), he simply placed Dioscoraceae in the Epigynae "Series".

Although Charles Darwin's Origin of Species (1859) preceded Bentham and Hooker's publication, the latter project was commenced much earlier and George Bentham was initially sceptical of Darwinism. The new phyletic approach changed the way that taxonomists considered plant classification, incorporating evolutionary information into their schemata, but this did little to further define the circumscription of Dioscoreaceae. The major works in the late nineteenth and early twentieth century employing this approach were in the German literature. Authors such as Eichler, Engler and Wettstein placed this family in the Liliiflorae, a major subdivision of monocotyledons. it remained to Hutchinson (1926) to resurrect the Dioscoreales to group Dioscoreaceae and related families together. Hutchinson's circumscription of Dioscoreales included three other families in addition to Dioscoreaceae, Stenomeridaceae, Trichopodaceae and Roxburghiaceae. Of these only Trichopodaceae was included in the Angiosperm Phylogeny Group (APG) classification (see below), but was subsumed into Dioscoraceae. Stenomeridaceae, as "Stenomeris" was also included in Dioscoreaceae as subfamily Stenomeridoideae, the remaining genera being grouped in subfamily Dioscoreoideae. Roxburghiaceae on the other hand was segregated in the sister order Pandanales as Stemonaceae. Most taxonomists in the twentieth century (the exception was the 1981 Cronquist system which placed most such plants in order Liliales, subclass Liliidae, class Liliopsida=monocotyledons, division Magnoliophyta=angiosperms) recognised Dioscoreales as a distinct order, but demonstrated wide variations in its composition.

Dahlgren, in the second version of his taxonomic classification (1982) raised the Liliiflorae to a superorder and placed Dioscoreales as an order within it. In his system, Dioscoreales contained only three families, Dioscoreaceae, Stemonaceae ("i.e." Hutchinson's Roxburghiaceae) and Trilliaceae. The latter two families had been treated as a separate order (Stemonales, or Roxburghiales) by other authors, such as Huber (1969). The APG would later assign these to Pandanales and Liliales respectively. Dahlgren's construction of Dioscoreaceae included the Stenomeridaceae and Trichopodaceae, doubting these were distinct, and Croomiaceae in Stemonaceae. Furthermore, he expressed doubts about the order's homogeneity, especially Trilliaceae. The Dioscoreales at that time were marginally distinguishable from the Asparagales. In his examination of Huber's Stemonales, he found that the two constituent families had as close an affinity to Dioscoreaceae as to each other, and hence included them. He also considered closely related families and their relationship to Dioscoreales, such as the monogeneric Taccaceae, then in its own order, Taccales. Similar considerations were discussed with respect to two Asparagales families, Smilacaceae and Petermanniaceae.

In Dahlgren's third and final version (1985) that broader circumscription of Dioscoreales was created within the superorder Lilianae, subclass Liliidae (monocotyledons), class Magnoliopsida (angiosperms) and comprised the seven families Dioscoreaceae, Petermanniaceae, Smilacaceae, Stemonaceae, Taccaceae, Trichopodaceae and Trilliaceae. Thismiaceae has either been treated as a separate family closely related to Burmanniaceae or as a tribe (Thismieae) within a more broadly defined Burmanniaceae, forming a separate order, Burmanniales, in the Dahlgren system. The related Nartheciaceae were treated as tribe Narthecieae within the Melanthiaceae in a third order, the Melanthiales, by Dahlgren. Dahlgren considered the Dioscoreales to most strongly resemble the ancestral monocotyledons, and hence sharing "dicotyledonous" characteristics, making it the most central monocotyledon order. Of these seven families, Bouman considered Dioscoreaceae, Trichopodaceae, Stemonaceae and Taccaceae to represent the "core" families of the order. However, that study also indicated both a clear delineation of the order from other orders particularly Asparagales, and a lack of homogeneity within the order.

The increasing availability of molecular phylogenetics methods in addition to morphological characteristics in the 1990s led to major reconsiderations of the relationships within the monocotyledons. In that large multi-institutional examination of the seed plants using the plastid gene "rbc"L the authors used Dahlgren's system as their basis, but followed Thorne (1992) in altering the suffixes of the superorders from ""-iflorae"" to ""-anae"". This demonstrated that the Lilianae comprised three lineages corresponding to Dahlgren's orders Dioscoreales, Liliales, and Asparagaless.

Under the Angiosperm Phylogeny Group system of 1998, which took Dahlgren's system as a basis, the order was placed in the monocot clade and comprised the five families Burmanniaceae, Dioscoreaceae, Taccaceae, Thismiaceae and Trichopodaceae.

In APG II (2003), a number of changes were made to Dioscoreales, as a result of an extensive study by Caddick and colleagues (2002), using an analysis of three genes, "rbc"L, "atp"B and 18S rDNA, in addition to morphology. These studies resulted in a re-examination of the relationships between most of the genera within the order. Thismiaceae was shown to be a sister group to Burmanniaceae, and so was included in it. The monotypic families Taccaceae and Trichopodaceae were included in Dioscoreaceae, while Nartheciaceae could also be grouped within Dioscoreales. APG III (2009) did not change this, so the order now comprises three families Burmanniaceae, Dioscoreaceae and Nartheciaceae.

Although further research on the deeper relationships within Dioscoreales continues, the APG IV (2016) authors felt it was still premature to propose a restructuring of the order. Specifically these issues involve conflicting information as to the relationship between "Thismia" and Burmanniaceae, and hence whether Thismiaceae should be subsumed in the latter, or reinstated.

Molecular phylogenetics in Dioscoreales poses special problems due to the absence of plastid genes in mycoheterotrophs. Dioscoreales is monophyletic and is placed as a sister order to Pandanales, as shown in Cladogram I.

The data for the evolution of the order is collected from molecular analyses since there are no such fossils found. It is estimated that Dioscoreales and its sister clade Pandanales split up around 121 million years ago during Early Cretaceous when the stem group was formed. Then it took 3 to 6 million years for the crown group to differentiate in Mid Cretaceous.

The three families of Dioscreales constitutes about 22 genera and about 849 species making it one of the smaller monocot orders. Of these, the largest group is "Dioscorea" (yams) with about 450 species. By contrast the second largest genus is "Burmannia" with about 60 species, and most have only one or two.

Some authors, preferring the original APG (1998)families, continue to treat Thismiaceae separately from Burmanniaceae and Taccaceae from Dioscoreaceae. But in the 2015 study of Hertwerk and colleagues, seven genera representing all three families were examined with an eight gene dataset. Dioscoreales was monophyletic and three subclades were represented corresponding to the APG families. Dioscoreaceae and Burmanniaceae were in a sister group relationship.

Named after the type genus "Dioscorea", which in turn was named by Linnaeus in 1753 to honour the Greek physician and botanist Dioscorides.

Species from this order are distributed across all of the continents except Antarctica. They are mainly tropical or subtropical representatives, but some members of families Dioscoreaceae and Nartheciaceae are found in cooler regions of Europe and North America. Order Dioscoreales contains plants that are able to form an underground organ for reservation of nutritions as many other monocots. An exception is the family Burmanniaceae which is entirely myco-heterotrophic and contains species that lack photosynthetic abilities.

The three families included in order Dioscoreales also represent three different ecological groups of plants. Dioscoreaceae contains mainly vines ("Dioscorea") and other crawling species ("Epipetrum"). Nartheciaceae on the other hand is a family composed of herbaceous plants with a rather lily-like appearance ("Aletris") while Burmanniaceae is entirely myco-heterotrophic group.

Many members of Dioscoreaceae produce tuberous starchy roots (yams) which form staple foods in tropical regions. They have also been the source of steroids for the pharmaceutical industry, including the production of oral contraceptives.





Default

Default may refer to:






Deposition

Deposition may refer to:






Dentistry

Dentistry, also known as dental medicine and oral medicine, is the branch of medicine focused on the teeth, gums, and mouth. It consists of the study, diagnosis, prevention, management, and treatment of diseases, disorders, and conditions of the mouth, most commonly focused on dentition (the development and arrangement of teeth) as well as the oral mucosa. Dentistry may also encompass other aspects of the craniofacial complex including the temporomandibular joint. The practitioner is called a dentist.

The history of dentistry is almost as ancient as the history of humanity and civilization, with the earliest evidence dating from 7000 BC to 5500 BC. Dentistry is thought to have been the first specialization in medicine which has gone on to develop its own accredited degree with its own specializations. Dentistry is often also understood to subsume the now largely defunct medical specialty of stomatology (the study of the mouth and its disorders and diseases) for which reason the two terms are used interchangeably in certain regions. However, some specialties such as oral and maxillofacial surgery (facial reconstruction) may require both medical and dental degrees to accomplish. In European history, dentistry is considered to have stemmed from the trade of barber surgeons.

Dental treatments are carried out by a dental team, which often consists of a dentist and dental auxiliaries (dental assistants, dental hygienists, dental technicians, as well as dental therapists). Most dentists either work in private practices (primary care), dental hospitals, or (secondary care) institutions (prisons, armed forces bases, etc.).

The modern movement of evidence-based dentistry calls for the use of high-quality scientific research and evidence to guide decision-making such as in manual tooth conservation, use of fluoride water treatment and fluoride toothpaste, dealing with oral diseases such as tooth decay and periodontitis, as well as systematic diseases such as osteoporosis, diabetes, celiac disease, cancer, and HIV/AIDS which could also affect the oral cavity. Other practices relevant to evidence-based dentistry include radiology of the mouth to inspect teeth deformity or oral malaises, haematology (study of blood) to avoid bleeding complications during dental surgery, cardiology (due to various severe complications arising from dental surgery with patients with heart disease), etc.

The term dentistry comes from "dentist", which comes from French "dentiste", which comes from the French and Latin words for tooth. The term for the associated scientific study of teeth is odontology (from ) – the study of the structure, development, and abnormalities of the teeth.

Dentistry usually encompasses practices related to the oral cavity. According to the World Health Organization, oral diseases are major public health problems due to their high incidence and prevalence across the globe, with the disadvantaged affected more than other socio-economic groups.

The majority of dental treatments are carried out to prevent or treat the two most common oral diseases which are dental caries (tooth decay) and periodontal disease (gum disease or pyorrhea). Common treatments involve the restoration of teeth, extraction or surgical removal of teeth, scaling and root planing, endodontic root canal treatment, and cosmetic dentistry

By nature of their general training, dentists, without specialization can carry out the majority of dental treatments such as restorative (fillings, crowns, bridges), prosthetic (dentures), endodontic (root canal) therapy, periodontal (gum) therapy, and extraction of teeth, as well as performing examinations, radiographs (x-rays), and diagnosis. Dentists can also prescribe medications used in the field such as antibiotics, sedatives, and any other drugs used in patient management. Depending on their licensing boards, general dentists may be required to complete additional training to perform sedation, dental implants, etc.

Dentists also encourage the prevention of oral diseases through proper hygiene and regular, twice or more yearly, checkups for professional cleaning and evaluation. Oral infections and inflammations may affect overall health and conditions in the oral cavity may be indicative of systemic diseases, such as osteoporosis, diabetes, celiac disease or cancer. Many studies have also shown that gum disease is associated with an increased risk of diabetes, heart disease, and preterm birth. The concept that oral health can affect systemic health and disease is referred to as "oral-systemic health".

John M. Harris started the world's first dental school in Bainbridge, Ohio, and helped to establish dentistry as a health profession. It opened on 21 February 1828, and today is a dental museum. The first dental college, Baltimore College of Dental Surgery, opened in Baltimore, Maryland, US in 1840. The second in the United States was the Ohio College of Dental Surgery, established in Cincinnati, Ohio, in 1845. The Philadelphia College of Dental Surgery followed in 1852. In 1907, Temple University accepted a bid to incorporate the school.

Studies show that dentists that graduated from different countries, or even from different dental schools in one country, may make different clinical decisions for the same clinical condition. For example, dentists that graduated from Israeli dental schools may recommend the removal of asymptomatic impacted third molar (wisdom teeth) more often than dentists that graduated from Latin American or Eastern European dental schools.

In the United Kingdom, the first dental schools, the London School of Dental Surgery and the Metropolitan School of Dental Science, both in London, opened in 1859. The British Dentists Act of 1878 and the 1879 Dentists Register limited the title of "dentist" and "dental surgeon" to qualified and registered practitioners. However, others could legally describe themselves as "dental experts" or "dental consultants". The practice of dentistry in the United Kingdom became fully regulated with the 1921 Dentists Act, which required the registration of anyone practising dentistry. The British Dental Association, formed in 1880 with Sir John Tomes as president, played a major role in prosecuting dentists practising illegally. Dentists in the United Kingdom are now regulated by the General Dental Council.

In many countries, dentists usually complete between five and eight years of post-secondary education before practising. Though not mandatory, many dentists choose to complete an internship or residency focusing on specific aspects of dental care after they have received their dental degree. In a few countries, to become a qualified dentist one must usually complete at least four years of postgraduate study; Dental degrees awarded around the world include the Doctor of Dental Surgery (DDS) and Doctor of Dental Medicine (DMD) in North America (US and Canada), and the Bachelor of Dental Surgery/Baccalaureus Dentalis Chirurgiae (BDS, BDent, BChD, BDSc) in the UK and current and former British Commonwealth countries.

All dentists in the United States undergo at least three years of undergraduate studies, but nearly all complete a bachelor's degree. This schooling is followed by four years of dental school to qualify as a "Doctor of Dental Surgery" (DDS) or "Doctor of Dental Medicine" (DMD). Specialization in dentistry is available in the fields of Anesthesiology, Dental Public Health, Endodontics, Oral Radiology, Oral and Maxillofacial Surgery, Oral Medicine, Orofacial Pain, Pathology, Orthodontics, Pediatric Dentistry (Pedodontics), Periodontics, and Prosthodontics.

Some dentists undertake further training after their initial degree in order to specialize. Exactly which subjects are recognized by dental registration bodies varies according to location. Examples include:

Tooth decay was low in pre-agricultural societies, but the advent of farming society about 10,000 years ago correlated with an increase in tooth decay (cavities). An infected tooth from Italy partially cleaned with flint tools, between 13,820 and 14,160 years old, represents the oldest known dentistry, although a 2017 study suggests that 130,000 years ago the Neanderthals already used rudimentary dentistry tools. The Indus valley has yielded evidence of dentistry being practised as far back as 7000 BC, during the Stone Age. The Neolithic site of Mehrgarh (now in Pakistan's south western province of Balochistan) indicates that this form of dentistry involved curing tooth related disorders with bow drills operated, perhaps, by skilled bead-crafters. The reconstruction of this ancient form of dentistry showed that the methods used were reliable and effective. The earliest dental filling, made of beeswax, was discovered in Slovenia and dates from 6500 years ago. Dentistry was practised in prehistoric Malta, as evidenced by a skull which had a dental abscess lanced from the root of a tooth dating back to around 2500 BC.

An ancient Sumerian text describes a "tooth worm" as the cause of dental caries. Evidence of this belief has also been found in ancient India, Egypt, Japan, and China. The legend of the worm is also found in the "Homeric Hymns", and as late as the 14th century AD the surgeon Guy de Chauliac still promoted the belief that worms cause tooth decay.

Recipes for the treatment of toothache, infections and loose teeth are spread throughout the Ebers Papyrus, Kahun Papyri, Brugsch Papyrus, and Hearst papyrus of Ancient Egypt. The Edwin Smith Papyrus, written in the 17th century BC but which may reflect previous manuscripts from as early as 3000 BC, discusses the treatment of dislocated or fractured jaws. In the 18th century BC, the Code of Hammurabi referenced dental extraction twice as it related to punishment. Examination of the remains of some ancient Egyptians and Greco-Romans reveals early attempts at dental prosthetics. However, it is possible the prosthetics were prepared after death for aesthetic reasons.

Ancient Greek scholars Hippocrates and Aristotle wrote about dentistry, including the eruption pattern of teeth, treating decayed teeth and gum disease, extracting teeth with forceps, and using wires to stabilize loose teeth and fractured jaws. Some say the first use of dental appliances or bridges comes from the Etruscans from as early as 700 BC. The Phoenicians crafted the oldest documented dentures during the 6th–4th century BC, fashioning them from gold wire and incorporating two ivory teeth. In ancient Egypt, Hesy-Ra is the first named "dentist" (greatest of the teeth). The Egyptians bound replacement teeth together with gold wire. Roman medical writer Cornelius Celsus wrote extensively of oral diseases as well as dental treatments such as narcotic-containing emollients and astringents. The earliest dental amalgams were first documented in a Tang dynasty medical text written by the Chinese physician Su Kung in 659, and appeared in Germany in 1528.

During the Islamic Golden Age Dentistry was discussed in several famous books of medicine such as The Canon in medicine written by Avicenna and Al-Tasreef by Al-Zahrawi who is considered the greatest surgeon of the Middle ages, Avicenna said that jaw fracture should be reduced according to the occlusal guidance of the teeth; this principle is still valid in modern times. Al-Zahrawi invented over 200 surgical tools that resemble the modern kind.

Historically, dental extractions have been used to treat a variety of illnesses. During the Middle Ages and throughout the 19th century, dentistry was not a profession in itself, and often dental procedures were performed by barbers or general physicians. Barbers usually limited their practice to extracting teeth which alleviated pain and associated chronic tooth infection. Instruments used for dental extractions date back several centuries. In the 14th century, Guy de Chauliac most probably invented the dental pelican (resembling a pelican's beak) which was used to perform dental extractions up until the late 18th century. The pelican was replaced by the dental key which, in turn, was replaced by modern forceps in the 19th century.

The first book focused solely on dentistry was the "Artzney Buchlein" in 1530, and the first dental textbook written in English was called "Operator for the Teeth" by Charles Allen in 1685.

In the United Kingdom, there was no formal qualification for the providers of dental treatment until 1859 and it was only in 1921 that the practice of dentistry was limited to those who were professionally qualified. The Royal Commission on the National Health Service in 1979 reported that there were then more than twice as many registered dentists per 10,000 population in the UK than there were in 1921.

It was between 1650 and 1800 that the science of modern dentistry developed. The English physician Thomas Browne in his "A Letter to a Friend" ( pub. 1690) made an early dental observation with characteristic humour:

The French surgeon Pierre Fauchard became known as the "father of modern dentistry". Despite the limitations of the primitive surgical instruments during the late 17th and early 18th century, Fauchard was a highly skilled surgeon who made remarkable improvisations of dental instruments, often adapting tools from watchmakers, jewelers and even barbers, that he thought could be used in dentistry. He introduced dental fillings as treatment for dental cavities. He asserted that sugar-derived acids like tartaric acid were responsible for dental decay, and also suggested that tumors surrounding the teeth and in the gums could appear in the later stages of tooth decay.

Fauchard was the pioneer of dental prosthesis, and he invented many methods to replace lost teeth. He suggested that substitutes could be made from carved blocks of ivory or bone. He also introduced dental braces, although they were initially made of gold, he discovered that the teeth position could be corrected as the teeth would follow the pattern of the wires. Waxed linen or silk threads were usually employed to fasten the braces. His contributions to the world of dental science consist primarily of his 1728 publication Le chirurgien dentiste or The Surgeon Dentist. The French text included "basic oral anatomy and function, dental construction, and various operative and restorative techniques, and effectively separated dentistry from the wider category of surgery".

After Fauchard, the study of dentistry rapidly expanded. Two important books, "Natural History of Human Teeth" (1771) and "Practical Treatise on the Diseases of the Teeth" (1778), were published by British surgeon John Hunter. In 1763, he entered into a period of collaboration with the London-based dentist James Spence. He began to theorise about the possibility of tooth transplants from one person to another. He realised that the chances of a successful tooth transplant (initially, at least) would be improved if the donor tooth was as fresh as possible and was matched for size with the recipient. These principles are still used in the transplantation of internal organs. Hunter conducted a series of pioneering operations, in which he attempted a tooth transplant. Although the donated teeth never properly bonded with the recipients' gums, one of Hunter's patients stated that he had three which lasted for six years, a remarkable achievement for the period.

Major advances in science were made in the 19th century, and dentistry evolved from a trade to a profession. The profession came under government regulation by the end of the 19th century. In the UK, the Dentist Act was passed in 1878 and the British Dental Association formed in 1879. In the same year, Francis Brodie Imlach was the first ever dentist to be elected President of the Royal College of Surgeons (Edinburgh), raising dentistry onto a par with clinical surgery for the first time.

Long term occupational noise exposure can contribute to permanent hearing loss, which is referred to as noise-induced hearing loss (NIHL) and tinnitus. Noise exposure can cause excessive stimulation of the hearing mechanism, which damages the delicate structures of the inner ear. NIHL can occur when an individual is exposed to sound levels above 90 dBA according to the Occupational Safety and Health Administration (OSHA). Regulations state that the permissible noise exposure levels for individuals is 90 dBA. For the National Institute for Occupational Safety and Health (NIOSH), exposure limits are set to 85 dBA. Exposures below 85 dBA are not considered to be hazardous. Time limits are placed on how long an individual can stay in an environment above 85 dBA before it causes hearing loss. OSHA places that limitation at 8 hours for 85 dBA. The exposure time becomes shorter as the dBA level increases.

Within the field of dentistry, a variety of cleaning tools are used including piezoelectric and sonic scalers, and ultrasonic scalers and cleaners. While a majority of the tools do not exceed 75 dBA, prolonged exposure over many years can lead to hearing loss or complaints of tinnitus. Few dentists have reported using personal hearing protective devices, which could offset any potential hearing loss or tinnitus.

There is a movement in modern dentistry to place a greater emphasis on high-quality scientific evidence in decision-making. Evidence-based dentistry (EBD) uses current scientific evidence to guide decisions. It is an approach to oral health that requires the application and examination of relevant scientific data related to the patient's oral and medical health. Along with the dentist's professional skill and expertise, EBD allows dentists to stay up to date on the latest procedures and patients to receive improved treatment. A new paradigm for medical education designed to incorporate current research into education and practice was developed to help practitioners provide the best care for their patients. It was first introduced by Gordon Guyatt and the Evidence-Based Medicine Working Group at McMaster University in Ontario, Canada in the 1990s. It is part of the larger movement toward evidence-based medicine and other evidence-based practices, especially since a major part of dentistry involves dealing with oral and systemic diseases. Other issues relevant to the dental field in terms of evidence-based research and evidence-based practice include population oral health, dental clinical practice, tooth morphology etc. 
Dentistry is unique in that it requires dental students to have competence-based clinical skills that can only be acquired through supervised specialized laboratory training and direct patient care. This necessitates the need for a scientific and professional basis of care with a foundation of extensive research-based education. According to some experts, the accreditation of dental schools can enhance the quality and professionalism of dental education.


Diameter

In geometry, a diameter of a circle is any straight line segment that passes through the centre of the circle and whose endpoints lie on the circle. It can also be defined as the longest chord of the circle. Both definitions are also valid for the diameter of a sphere.

In more modern usage, the length formula_1 of a diameter is also called the diameter. In this sense one speaks of diameter rather than diameter (which refers to the line segment itself), because all diameters of a circle or sphere have the same length, this being twice the radius formula_2

For a convex shape in the plane, the diameter is defined to be the largest distance that can be formed between two opposite parallel lines tangent to its boundary, and the is often defined to be the smallest such distance. Both quantities can be calculated efficiently using rotating calipers. For a curve of constant width such as the Reuleaux triangle, the width and diameter are the same because all such pairs of parallel tangent lines have the same distance.

For an ellipse, the standard terminology is different. A diameter of an ellipse is any chord passing through the centre of the ellipse. For example, conjugate diameters have the property that a tangent line to the ellipse at the endpoint of one diameter is parallel to the conjugate diameter. The longest diameter is called the major axis.

The word "diameter" is derived from (), "diameter of a circle", from (), "across, through" and (), "measure". It is often abbreviated formula_4 or formula_5

The definitions given above are only valid for circles, spheres and convex shapes. However, they are special cases of a more general definition that is valid for any kind of formula_6-dimensional (convex or non-convex) object, such as a hypercube or a set of scattered points. The or of a subset of a metric space is the least upper bound of the set of all distances between pairs of points in the subset. Explicitly, if formula_7 is the subset and if formula_8 is the metric, the diameter is
formula_9

If the metric formula_8 is viewed here as having codomain formula_11 (the set of all real numbers), this implies that the diameter of the empty set (the case formula_12) equals formula_13 (negative infinity). Some authors prefer to treat the empty set as a special case, assigning it a diameter of formula_14 which corresponds to taking the codomain of formula_1 to be the set of nonnegative reals.

For any solid object or set of scattered points in formula_6-dimensional Euclidean space, the diameter of the object or set is the same as the diameter of its convex hull. In medical parlance concerning a lesion or in geology concerning a rock, the diameter of an object is the least upper bound of the set of all distances between pairs of points in the object.

In differential geometry, the diameter is an important global Riemannian invariant.

In planar geometry, a diameter of a conic section is typically defined as any chord which passes through the conic's centre; such diameters are not necessarily of uniform length, except in the case of the circle, which has eccentricity formula_17

The symbol or variable for diameter, , is sometimes used in technical drawings or specifications as a prefix or suffix for a number (e.g. "⌀ 55 mm"), indicating that it represents diameter. For example, photographic filter thread sizes are often denoted in this way.

In German, the diameter symbol (German "") is also used as an average symbol ("Durchschnittszeichen").

The symbol has a Unicode code point at , in the Miscellaneous Technical set. On an Apple Macintosh, the diameter symbol can be entered via the character palette (this is opened by pressing in most applications), where it can be found in the Technical Symbols category. In Unix/Linux/ChromeOS systems, it is generated using  . It can be obtained in Unix-like operating systems using a Compose key by pressing, in sequence, . In Windows, it can be entered in most programs with Alt code 8960.

The character will sometimes not display correctly, however, since many fonts do not include it. In many situations, the Nordic letter ø at Unicode is an acceptable substitute. It can be entered on a Macintosh by pressing (the letter o, not the number 0). In Unix/Linux/ChromeOS systems, it is generated using   or . AutoCAD uses available as a shortcut string .

In Microsoft Word, the diameter symbol can be acquired by typing and then pressing .

In LaTeX, the diameter symbol can be obtained with the command codice_1 from the "wasysym" package.

The diameter of a circle is exactly twice its radius. However, this is true only for a circle, and only in the Euclidean metric. Jung's theorem provides more general inequalities relating the diameter to the radius.

Direct examination

The direct examination or examination-in-chief is one stage in the process of adducing evidence from witnesses in a court of law. Direct examination is the questioning of a witness by the lawyer/side/party that called such witness in a trial. Direct examination is usually performed to elicit evidence in support of facts which will satisfy a required element of a party's claim or defense.

In direct examination, one is generally prohibited from asking leading questions. This prevents a lawyer from feeding answers to a favorable witness. An exception to this rule occurs if one side has called a witness, but it is either understood or becomes clear, that the witness is hostile to the calling lawyer's side of the controversy, the lawyer who called the witness may then ask the court to declare the person on the stand a hostile witness. If the court does so, the lawyer may thereafter ask witness leading questions during direct examination.

The techniques of direct examination are taught in courses on trial advocacy. Each direct examination is integrated with the overall case strategy through either a theme and theory or, with more advanced strategies, a line of effort.


Alcohol intoxication

Alcohol intoxication, also known in overdose as alcohol poisoning, commonly described as drunkenness or inebriation, is the behavior and physical effects caused by a recent consumption of alcohol. In addition to the toxicity of ethanol, the main psychoactive component of alcoholic beverages, other physiological symptoms may arise from the activity of acetaldehyde, a metabolite of alcohol. These effects may not arise until hours after ingestion and may contribute to the condition colloquially known as a hangover.

Symptoms of intoxication at lower doses may include mild sedation and poor coordination. At higher doses, there may be slurred speech, trouble walking, and vomiting. Extreme doses may result in a respiratory depression, coma, or death. Complications may include seizures, aspiration pneumonia, low blood sugar, and injuries or self-harm such as suicide. Alcohol intoxication can lead to alcohol-related crime with perpetrators more likely to be intoxicated than victims.
Alcohol intoxication typically begins after two or more alcoholic drinks. Alcohol has the potential for abuse. Risk factors include a social situation where heavy drinking is common and a person having an impulsive personality. Diagnosis is usually based on the history of events and physical examination. Verification of events by witnesses may be useful. Legally, alcohol intoxication is often defined as a blood alcohol concentration (BAC) of greater than 5.4–17.4 mmol/L (25–80 mg/dL or 0.025–0.080%). This can be measured by blood or breath testing. Alcohol is broken down in the human body at a rate of about 3.3 mmol/L (15 mg/dL) per hour, depending on an individual's metabolic rate (metabolism).
Management of alcohol intoxication involves supportive care. Typically this includes putting the person in the recovery position, keeping the person warm, and making sure breathing is sufficient. Gastric lavage and activated charcoal have not been found to be useful. Repeated assessments may be required to rule out other potential causes of a person's symptoms.
Acute intoxication has been documented throughout history, and alcohol remains one of the world's most widespread recreational drugs. Some religions consider alcohol intoxication to be a sin.

Alcohol intoxication leads to negative health effects due to the recent drinking of ethanol (alcohol). When severe it may become a medical emergency. Some effects of alcohol intoxication, such as euphoria and lowered social inhibition, are central to alcohol's desirability.

Alcohol is metabolized by a normal liver at the rate of about 8 grams of pure ethanol per hour. 8 grams or is one British standard unit. An "abnormal" liver with conditions such as hepatitis, cirrhosis, gall bladder disease, and cancer is likely to result in a slower rate of metabolism.

Ethanol is metabolised to acetaldehyde by alcohol dehydrogenase (ADH), which is found in many tissues, including the gastric mucosa. Acetaldehyde is metabolised to acetate by acetaldehyde dehydrogenase (ALDH), which is found predominantly in liver mitochondria. Acetate is used by the muscle cells to produce acetyl-CoA using the enzyme acetyl-CoA synthetase, and the acetyl-CoA is then used in the citric acid cycle.

As drinking increases, people become sleepy or fall into a stupor. After a very high level of consumption, the respiratory system becomes depressed and the person will stop breathing. Comatose patients may aspirate their vomit (resulting in vomitus in the lungs, which may cause "drowning" and later pneumonia if survived). CNS depression and impaired motor coordination along with poor judgment increase the likelihood of accidental injury occurring. It is estimated that about one-third of alcohol-related deaths are due to accidents and another 14% are from intentional injury.

In addition to respiratory failure and accidents caused by its effects on the central nervous system, alcohol causes significant metabolic derangements. Hypoglycaemia occurs due to ethanol's inhibition of gluconeogenesis, especially in children, and may cause lactic acidosis, ketoacidosis, and acute kidney injury. Metabolic acidosis is compounded by respiratory failure. Patients may also present with hypothermia.

In the past, alcohol was believed to be a non-specific pharmacological agent affecting many neurotransmitter systems in the brain. However, molecular pharmacology studies have shown that alcohol has only a few primary targets. In some systems, these effects are facilitatory, and in others inhibitory.

Among the neurotransmitter systems with enhanced functions are: GABA, 5-HT receptor agonism (responsible for GABAergic (GABA receptor PAM), glycinergic, and cholinergic effects), nicotinic acetylcholine receptors.

Among those that are inhibited are: NMDA, dihydropyridine-sensitive L-type Ca2+ channels and G-protein-activated inwardly rectifying K+ channels.

Alcohol is also converted into phosphatidylethanol (a lipid metabolite) by phospholipase D2, and this metabolite has been shown to directly bind to and regulate ion channels. The result of these direct effects is a wave of further indirect effects involving a variety of other neurotransmitter and neuropeptide systems, leading finally to the behavioural or symptomatic effects of alcohol intoxication.

The order in which different types of alcoholic beverages are consumed ("Grape or grain but never the twain" and "Beer before wine and you'll feel fine; wine before beer and you'll feel queer") does not have any effect.

Many of the effects of activating GABA receptors have the same effects as that of ethanol consumption. Some of these effects include anxiolytic, anticonvulsant, sedative, and hypnotic effects, cognitive impairment, and motor incoordination. This correlation between activating GABA receptors and the effects of ethanol consumption have led to the study of ethanol and its effects on GABA receptors. It has been shown that ethanol does in fact exhibit positive allosteric binding properties to GABA receptors. However, its effects are limited to pentamers containing the δ-subunit rather than the γ-subunit. 

GABA receptors containing the δ-subunit have been shown to be located exterior to the synapse and are involved with tonic inhibition rather than its γ-subunit counterpart, which is involved in phasic inhibition. The δ-subunit has been shown to be able to form the allosteric binding site which makes GABA receptors containing the δ-subunit more sensitive to ethanol concentrations, even to moderate social ethanol consumption levels (30mM). While it has been shown by Santhakumar et al. that GABA receptors containing the δ-subunit are sensitive to ethanol modulation, depending on subunit combinations receptors could be more or less sensitive to ethanol. It has been shown that GABA receptors that contain both δ and β3-subunits display increased sensitivity to ethanol. One such receptor that exhibits ethanol insensitivity is α3-β6-δ GABA. It has also been shown that subunit combination is not the only thing that contributes to ethanol sensitivity. Location of GABA receptors within the synapse may also contribute to ethanol sensitivity.

Alcohol intoxication is described as a mental and behavioural disorder by the International Classification of Diseases. (ICD-10). Definitive diagnosis relies on a blood test for alcohol, usually performed as part of a toxicology screen. Law enforcement officers in the United States and other countries often use breathalyzer units and field sobriety tests as more convenient and rapid alternatives to blood tests. There are also various models of breathalyzer units that are available for consumer use. Because these may have varying reliability and may produce different results than the tests used for law-enforcement purposes, the results from such devices should be conservatively interpreted.

Many informal intoxication tests exist, which, in general, are unreliable and not recommended as deterrents to excessive intoxication or as indicators of the safety of activities such as motor vehicle driving, heavy equipment operation, machine tool use, etc.

For determining whether someone is intoxicated by alcohol by some means other than a blood-alcohol test, it is necessary to rule out other conditions such as hypoglycemia, stroke, usage of other intoxicants, mental health issues, and so on. It is best if their behavior has been observed while the subject is sober to establish a baseline. Several well-known criteria can be used to establish a probable diagnosis. For a physician in the acute-treatment setting, acute alcohol intoxication can mimic other acute neurological disorders or is frequently combined with other recreational drugs that complicate diagnosis and treatment.

Acute alcohol poisoning is a medical emergency due to the risk of death from respiratory depression or aspiration of vomit if vomiting occurs while the person is unresponsive. Emergency treatment strives to stabilize and maintain an open airway and sufficient breathing while waiting for the alcohol to metabolize. This can be done by removal of any vomit or, if the person is unconscious or has impaired gag reflex, intubation of the trachea.

Other measures may include
Additional medication may be indicated for treatment of nausea, tremor, and anxiety.

Alcohol intoxication was found to be prevalent in clinical populations within the United States involving people treated for trauma and in the age group of people aged within their 18th - 24th years (in a study of a group for the years 1999 - 2004). In the United States during the years 2010 - 2012, acute intoxication was found to be the direct cause of an average of 2,221 deaths, in the sample group of those aged within their 15th year or older. The same mortality route is thought to cause indirectly more than 30,000 deaths per year.

A normal liver detoxifies the blood of alcohol over a period of time that depends on the initial level and the patient's overall physical condition. An abnormal liver will take longer but still succeeds, provided the alcohol does not cause liver failure.

People having drunk heavily for several days or weeks may have withdrawal symptoms after the acute intoxication has subsided.

A person consuming a dangerous amount of alcohol persistently can develop memory blackouts and idiosyncratic intoxication or pathological drunkenness symptoms. Long-term persistent consumption of excessive amounts of alcohol can cause liver damage and have other deleterious health effects.

Alcohol intoxication is a risk factor in some cases of catastrophic injury, in particular for unsupervised recreational activity. A study in the province of Ontario based on epidemiological data from 1986, 1989, 1992, and 1995 states that 79.2% of the 2,154 catastrophic injuries recorded for the study were preventable, of which 346 (17%) involved alcohol consumption. The activities most commonly associated with alcohol-related catastrophic injury were snowmobiling (124), fishing (41), diving (40), boating (31) and canoeing (7), swimming (31), riding an all-terrain vehicle (24), and cycling (23). These events are often associated with unsupervised young males, often inexperienced in the activity, and may result in drowning. Alcohol use is also associated with unsafe sex.

Laws on drunkenness vary. In the United States, it is a criminal offense for a person to be drunk while driving a motorized vehicle, except in Wisconsin, where it is only a fine for the first offense. It is also a criminal offense to fly an aircraft or (in some American states) to assemble or operate an amusement park ride while drunk. Similar laws also exist in the United Kingdom and most other countries.

In some countries, it is also an offense to serve alcohol to an already-intoxicated person, and, often, alcohol can only be sold by persons qualified to serve responsibly through alcohol server training.

The (BAC) for legal operation of a vehicle is typically measured as a percentage of a unit volume of blood. This percentage ranges from 0.00% in Romania and the United Arab Emirates; to 0.05% in Australia, South Africa, Germany, Scotland, and New Zealand (0.00% for underage individuals); to 0.08% in England and Wales, the United States and Canada.

The United States Federal Aviation Administration prohibits crew members from performing their duties within eight hours of consuming an alcoholic beverage, while under the influence of alcohol, or with a BAC greater than 0.04%.

In the United States, the United Kingdom, and Australia, public intoxication is a crime (also known as "being drunk and disorderly" or "being drunk and incapable").

In some countries, there are special facilities, sometimes known as "drunk tanks", for the temporary detention of persons found to be drunk.

Some religious groups permit the consumption of alcohol; some permit consumption but prohibit intoxication; others prohibit any amount of alcohol consumption altogether. Many denominations of Christianity, such as Catholicism, Orthodoxy and Lutheranism, use wine as a part of the Eucharist and permit its consumption, but consider it sinful to become intoxicated.

In the Bible, the Book of Proverbs contains several chapters related to the negative effects of drunkenness and warns to stay away from intoxicating beverages. The Book of Genesis refers to the use of wine by Lot's daughters to rape him. The Book of Leviticus tells the story of Nadab and Abihu, the eldest sons of Aaron, who were killed for serving in the Temple in Jerusalem after drinking wine, presumably while intoxicated. It continues to discuss monasticism, in which drinking wine is prohibited. The story of Samson in the Book of Judges tells of a monk from the Israelite tribe of Dan who is prohibited from cutting his hair and drinking wine. Romans 13:13–14, 1 Corinthians 6:9–11, Galatians 5:19–21 and Ephesians 5:18 are among a number of other Bible passages that speak against intoxication. While warns against kings and other rulers drinking wine and similar alcoholic beverages, Proverbs 31:6–7 promotes giving such beverages to the perishing and wine to those whose lives are bitter as a coping mechanism against the likes of poverty and other troubles.

Some Protestant Christian denominations prohibit the consumption of alcohol based upon biblical passages that condemn drunkenness, but others allow a moderate rate of consumption.

In the Church of Jesus Christ of Latter-day Saints, alcohol consumption is forbidden, and teetotalism has become a distinguishing feature of its members. Jehovah's Witnesses allow moderate alcohol consumption among its members.

In the Quran, there is a prohibition on the consumption of grape-based alcoholic beverages, and intoxication is considered an abomination in the hadith of Muhammad. The schools of thought of Islamic jurisprudence have interpreted this as a strict prohibition of the consumption of all types of alcohol and declared it to be "haram" (), although other uses may be permitted.

In Buddhism, in general, the consumption of intoxicants is discouraged for both monastics and lay followers. Many Buddhists observe a basic code of ethics known as the five precepts, of which the fifth precept is an undertaking to refrain from the consumption of intoxicating substances (except for medical reasons). In the "bodhisattva" vows of the "Brahmajala Sutra", observed by Mahayana Buddhist communities, distribution of intoxicants is likewise discouraged, as well as consumption.

In the Gaudiya Vaishnavism branch of Hinduism, one of the four regulative principles forbids the taking of intoxicants, including alcohol.

In Judaism, in accordance with the biblical stance against drinking, wine drinking is not permitted for priests and monks. The biblical command to sanctify the Sabbath and other holidays has been interpreted as having three ceremonial meals with wine or grape juice, known as "Kiddush". A number of Jewish marriage ceremonies end with the bride and groom drinking a shared cup of wine after reciting seven blessings; this occurs after a fasting day in some Ashkenazi traditions. It has been customary and in many cases even mandated to drink moderately so as to stay sober, and only after the prayers are over.

During the Seder on Passover, there is an obligation to drink four ceremonial cups of wine while reciting the Haggadah. It has been assumed as the source of the wine-drinking ritual at communion in some Christian groups. During Purim, there is an obligation to become intoxicated; however, as with many other decrees, this has been avoided in many communities by allowing sleep during the day as a replacement.

During the U.S. Prohibition era in the 1920s, a rabbi from the Reform Judaism movement proposed using grape juice for the ritual instead of wine. Although refuted at first, the practice became widely accepted by orthodox Jews as well.

In the film "Animals Are Beautiful People", an entire section was dedicated to showing many different animals including monkeys, elephants, hogs, giraffes, and ostriches, eating over-ripe marula tree fruit causing them to sway and lose their footing in a manner similar to human drunkenness. Birds may become intoxicated with fermented berries and some die colliding with hard objects when flying under the influence.

In elephant warfare, practiced by the Greeks during the Maccabean revolt and by Hannibal during the Punic wars, it has been recorded that the elephants would be given wine before the attack, and only then would they charge forward after being agitated by their driver.

It is a regular practice to give small amounts of beer to race horses in Ireland. Ruminant farm animals have natural fermentation occurring in their stomach, and adding alcoholic beverages in small amounts to their drink will generally do them no harm, and will not cause them to become drunk.

Alcoholic beverages are extremely harmful to dogs, and often for reasons of additives such as xylitol, an artificial sweetener in some mixers. Dogs can absorb ethyl alcohol in dangerous amounts through their skin as well as through drinking the liquid or consuming it in foods. Even fermenting bread dough can be dangerous to dogs. In 1999, one of the royal footmen for Britain's Queen Elizabeth II was demoted from Buckingham Palace due to his "party trick" of spiking the meals and drinks of the Queen's pet corgi dogs with alcohol which in turn would lead the dogs to run around drunk.



Data compression

In information theory, data compression, source coding, or bit-rate reduction is the process of encoding information using fewer bits than the original representation. Any particular compression is either lossy or lossless. Lossless compression reduces bits by identifying and eliminating statistical redundancy. No information is lost in lossless compression. Lossy compression reduces bits by removing unnecessary or less important information. Typically, a device that performs data compression is referred to as an encoder, and one that performs the reversal of the process (decompression) as a decoder.

The process of reducing the size of a data file is often referred to as data compression. In the context of data transmission, it is called source coding: encoding is done at the source of the data before it is stored or transmitted. Source coding should not be confused with channel coding, for error detection and correction or line coding, the means for mapping data onto a signal.

Compression is useful because it reduces the resources required to store and transmit data. Computational resources are consumed in the compression and decompression processes. Data compression is subject to a space-time complexity trade-off. For instance, a compression scheme for video may require expensive hardware for the video to be decompressed fast enough to be viewed as it is being decompressed, and the option to decompress the video in full before watching it may be inconvenient or require additional storage. The design of data compression schemes involves trade-offs among various factors, including the degree of compression, the amount of distortion introduced (when using lossy data compression), and the computational resources required to compress and decompress the data.

Lossless data compression algorithms usually exploit statistical redundancy to represent data without losing any information, so that the process is reversible. Lossless compression is possible because most real-world data exhibits statistical redundancy. For example, an image may have areas of color that do not change over several pixels; instead of coding "red pixel, red pixel, ..." the data may be encoded as "279 red pixels". This is a basic example of run-length encoding; there are many schemes to reduce file size by eliminating redundancy.

The Lempel–Ziv (LZ) compression methods are among the most popular algorithms for lossless storage. DEFLATE is a variation on LZ optimized for decompression speed and compression ratio, but compression can be slow. In the mid-1980s, following work by Terry Welch, the Lempel–Ziv–Welch (LZW) algorithm rapidly became the method of choice for most general-purpose compression systems. LZW is used in GIF images, programs such as PKZIP, and hardware devices such as modems. LZ methods use a table-based compression model where table entries are substituted for repeated strings of data. For most LZ methods, this table is generated dynamically from earlier data in the input. The table itself is often Huffman encoded. Grammar-based codes like this can compress highly repetitive input extremely effectively, for instance, a biological data collection of the same or closely related species, a huge versioned document collection, internet archival, etc. The basic task of grammar-based codes is constructing a context-free grammar deriving a single string. Other practical grammar compression algorithms include Sequitur and Re-Pair.

The strongest modern lossless compressors use probabilistic models, such as prediction by partial matching. The Burrows–Wheeler transform can also be viewed as an indirect form of statistical modelling. In a further refinement of the direct use of probabilistic modelling, statistical estimates can be coupled to an algorithm called arithmetic coding. Arithmetic coding is a more modern coding technique that uses the mathematical calculations of a finite-state machine to produce a string of encoded bits from a series of input data symbols. It can achieve superior compression compared to other techniques such as the better-known Huffman algorithm. It uses an internal memory state to avoid the need to perform a one-to-one mapping of individual input symbols to distinct representations that use an integer number of bits, and it clears out the internal memory only after encoding the entire string of data symbols. Arithmetic coding applies especially well to adaptive data compression tasks where the statistics vary and are context-dependent, as it can be easily coupled with an adaptive model of the probability distribution of the input data. An early example of the use of arithmetic coding was in an optional (but not widely used) feature of the JPEG image coding standard. It has since been applied in various other designs including H.263, H.264/MPEG-4 AVC and HEVC for video coding.

Archive software typically has the ability to adjust the "dictionary size", where a larger size demands more random-access memory during compression and decompression, but compresses stronger, especially on repeating patterns in files' content.

In the late 1980s, digital images became more common, and standards for lossless image compression emerged. In the early 1990s, lossy compression methods began to be widely used. In these schemes, some loss of information is accepted as dropping nonessential detail can save storage space. There is a corresponding trade-off between preserving information and reducing size. Lossy data compression schemes are designed by research on how people perceive the data in question. For example, the human eye is more sensitive to subtle variations in luminance than it is to the variations in color. JPEG image compression works in part by rounding off nonessential bits of information. A number of popular compression formats exploit these perceptual differences, including psychoacoustics for sound, and psychovisuals for images and video.

Most forms of lossy compression are based on transform coding, especially the discrete cosine transform (DCT). It was first proposed in 1972 by Nasir Ahmed, who then developed a working algorithm with T. Natarajan and K. R. Rao in 1973, before introducing it in January 1974. DCT is the most widely used lossy compression method, and is used in multimedia formats for images (such as JPEG and HEIF), video (such as MPEG, AVC and HEVC) and audio (such as MP3, AAC and Vorbis).

Lossy image compression is used in digital cameras, to increase storage capacities. Similarly, DVDs, Blu-ray and streaming video use lossy video coding formats. Lossy compression is extensively used in video.

In lossy audio compression, methods of psychoacoustics are used to remove non-audible (or less audible) components of the audio signal. Compression of human speech is often performed with even more specialized techniques; speech coding is distinguished as a separate discipline from general-purpose audio compression. Speech coding is used in internet telephony, for example, audio compression is used for CD ripping and is decoded by the audio players.

Lossy compression can cause generation loss.

The theoretical basis for compression is provided by information theory and, more specifically, Shannon's source coding theorem; domain-specific theories include algorithmic information theory for lossless compression and rate–distortion theory for lossy compression. These areas of study were essentially created by Claude Shannon, who published fundamental papers on the topic in the late 1940s and early 1950s. Other topics associated with compression include coding theory and statistical inference.

There is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for "general intelligence".

An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.

According to AIXI theory, a connection more directly explained in Hutter Prize, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.

Examples of AI-powered audio/video compression software include VP9, NVIDIA Maxine, AIVC, AccMPEG. Examples of software that can perform AI-powered image compression include OpenCV, TensorFlow, MATLAB's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.

In unsupervised machine learning, k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression.

Data compression can be viewed as a special case of data differencing. Data differencing consists of producing a "difference" given a "source" and a "target," with patching reproducing the "target" given a "source" and a "difference." Since there is no separate source and target in data compression, one can consider data compression as data differencing with empty source data, the compressed file corresponding to a difference from nothing. This is the same as considering absolute entropy (corresponding to data compression) as a special case of relative entropy (corresponding to data differencing) with no initial data.

The term "differential compression" is used to emphasize the data differencing connection.

Entropy coding originated in the 1940s with the introduction of Shannon–Fano coding, the basis for Huffman coding which was developed in 1950. Transform coding dates back to the late 1960s, with the introduction of fast Fourier transform (FFT) coding in 1968 and the Hadamard transform in 1969.

An important image compression technique is the discrete cosine transform (DCT), a technique developed in the early 1970s. DCT is the basis for JPEG, a lossy compression format which was introduced by the Joint Photographic Experts Group (JPEG) in 1992. JPEG greatly reduces the amount of data required to represent an image at the cost of a relatively small reduction in image quality and has become the most widely used image file format. Its highly efficient DCT-based compression algorithm was largely responsible for the wide proliferation of digital images and digital photos.

Lempel–Ziv–Welch (LZW) is a lossless compression algorithm developed in 1984. It is used in the GIF format, introduced in 1987. DEFLATE, a lossless compression algorithm specified in 1996, is used in the Portable Network Graphics (PNG) format.

Wavelet compression, the use of wavelets in image compression, began after the development of DCT coding. The JPEG 2000 standard was introduced in 2000. In contrast to the DCT algorithm used by the original JPEG format, JPEG 2000 instead uses discrete wavelet transform (DWT) algorithms. JPEG 2000 technology, which includes the Motion JPEG 2000 extension, was selected as the video coding standard for digital cinema in 2004.

Audio data compression, not to be confused with dynamic range compression, has the potential to reduce the transmission bandwidth and storage requirements of audio data. Audio compression formats compression algorithms are implemented in software as audio codecs. In both lossy and lossless compression, information redundancy is reduced, using methods such as coding, quantization, DCT and linear prediction to reduce the amount of information used to represent the uncompressed data.

Lossy audio compression algorithms provide higher compression and are used in numerous audio applications including Vorbis and MP3. These algorithms almost all rely on psychoacoustics to eliminate or reduce fidelity of less audible sounds, thereby reducing the space required to store or transmit them.

The acceptable trade-off between loss of audio quality and transmission or storage size depends upon the application. For example, one 640 MB compact disc (CD) holds approximately one hour of uncompressed high fidelity music, less than 2 hours of music compressed losslessly, or 7 hours of music compressed in the MP3 format at a medium bit rate. A digital sound recorder can typically store around 200 hours of clearly intelligible speech in 640 MB.

Lossless audio compression produces a representation of digital data that can be decoded to an exact digital duplicate of the original. Compression ratios are around 50–60% of the original size, which is similar to those for generic lossless data compression. Lossless codecs use curve fitting or linear prediction as a basis for estimating the signal. Parameters describing the estimation and the difference between the estimation and the actual signal are coded separately.

A number of lossless audio compression formats exist. See list of lossless codecs for a listing. Some formats are associated with a distinct system, such as Direct Stream Transfer, used in Super Audio CD and Meridian Lossless Packing, used in DVD-Audio, Dolby TrueHD, Blu-ray and HD DVD.

Some audio file formats feature a combination of a lossy format and a lossless correction; this allows stripping the correction to easily obtain a lossy file. Such formats include MPEG-4 SLS (Scalable to Lossless), WavPack, and OptimFROG DualStream.

When audio files are to be processed, either by further compression or for editing, it is desirable to work from an unchanged original (uncompressed or losslessly compressed). Processing of a lossily compressed file for some purpose usually produces a final result inferior to the creation of the same compressed file from an uncompressed original. In addition to sound editing or mixing, lossless audio compression is often used for archival storage, or as master copies.

Lossy audio compression is used in a wide range of applications. In addition to standalone audio-only applications of file playback in MP3 players or computers, digitally compressed audio streams are used in most video DVDs, digital television, streaming media on the Internet, satellite and cable radio, and increasingly in terrestrial radio broadcasts. Lossy compression typically achieves far greater compression than lossless compression, by discarding less-critical data based on psychoacoustic optimizations.

Psychoacoustics recognizes that not all data in an audio stream can be perceived by the human auditory system. Most lossy compression reduces redundancy by first identifying perceptually irrelevant sounds, that is, sounds that are very hard to hear. Typical examples include high frequencies or sounds that occur at the same time as louder sounds. Those irrelevant sounds are coded with decreased accuracy or not at all.

Due to the nature of lossy algorithms, audio quality suffers a digital generation loss when a file is decompressed and recompressed. This makes lossy compression unsuitable for storing the intermediate results in professional audio engineering applications, such as sound editing and multitrack recording. However, lossy formats such as MP3 are very popular with end-users as the file size is reduced to 5-20% of the original size and a megabyte can store about a minute's worth of music at adequate quality.

Several proprietary lossy compression algorithms have been developed that provide higher quality audio performance by using a combination of lossless and lossy algorithms with adaptive bit rates and lower compression ratios. Examples include aptX, LDAC, LHDC, MQA and SCL6.

To determine what information in an audio signal is perceptually irrelevant, most lossy compression algorithms use transforms such as the modified discrete cosine transform (MDCT) to convert time domain sampled waveforms into a transform domain, typically the frequency domain. Once transformed, component frequencies can be prioritized according to how audible they are. Audibility of spectral components is assessed using the absolute threshold of hearing and the principles of simultaneous masking—the phenomenon wherein a signal is masked by another signal separated by frequency—and, in some cases, temporal masking—where a signal is masked by another signal separated by time. Equal-loudness contours may also be used to weigh the perceptual importance of components. Models of the human ear-brain combination incorporating such effects are often called psychoacoustic models.

Other types of lossy compressors, such as the linear predictive coding (LPC) used with speech, are source-based coders. LPC uses a model of the human vocal tract to analyze speech sounds and infer the parameters used by the model to produce them moment to moment. These changing parameters are transmitted or stored and used to drive another model in the decoder which reproduces the sound.

Lossy formats are often used for the distribution of streaming audio or interactive communication (such as in cell phone networks). In such applications, the data must be decompressed as the data flows, rather than after the entire data stream has been transmitted. Not all audio codecs can be used for streaming applications.

Latency is introduced by the methods used to encode and decode the data. Some codecs will analyze a longer segment, called a "frame", of the data to optimize efficiency, and then code it in a manner that requires a larger segment of data at one time to decode. The inherent latency of the coding algorithm can be critical; for example, when there is a two-way transmission of data, such as with a telephone conversation, significant delays may seriously degrade the perceived quality.

In contrast to the speed of compression, which is proportional to the number of operations required by the algorithm, here latency refers to the number of samples that must be analyzed before a block of audio is processed. In the minimum case, latency is zero samples (e.g., if the coder/decoder simply reduces the number of bits used to quantize the signal). Time domain algorithms such as LPC also often have low latencies, hence their popularity in speech coding for telephony. In algorithms such as MP3, however, a large number of samples have to be analyzed to implement a psychoacoustic model in the frequency domain, and latency is on the order of 23 ms.

Speech encoding is an important category of audio data compression. The perceptual models used to estimate what aspects of speech a human ear can hear are generally somewhat different from those used for music. The range of frequencies needed to convey the sounds of a human voice is normally far narrower than that needed for music, and the sound is normally less complex. As a result, speech can be encoded at high quality using a relatively low bit rate.

This is accomplished, in general, by some combination of two approaches:

The earliest algorithms used in speech encoding (and audio data compression in general) were the A-law algorithm and the μ-law algorithm.

Early audio research was conducted at Bell Labs. There, in 1950, C. Chapin Cutler filed the patent on differential pulse-code modulation (DPCM). In 1973, Adaptive DPCM (ADPCM) was introduced by P. Cummiskey, Nikil S. Jayant and James L. Flanagan.

Perceptual coding was first used for speech coding compression, with linear predictive coding (LPC). Initial concepts for LPC date back to the work of Fumitada Itakura (Nagoya University) and Shuzo Saito (Nippon Telegraph and Telephone) in 1966. During the 1970s, Bishnu S. Atal and Manfred R. Schroeder at Bell Labs developed a form of LPC called adaptive predictive coding (APC), a perceptual coding algorithm that exploited the masking properties of the human ear, followed in the early 1980s with the code-excited linear prediction (CELP) algorithm which achieved a significant compression ratio for its time. Perceptual coding is used by modern audio compression formats such as MP3 and AAC.

Discrete cosine transform (DCT), developed by Nasir Ahmed, T. Natarajan and K. R. Rao in 1974, provided the basis for the modified discrete cosine transform (MDCT) used by modern audio compression formats such as MP3, Dolby Digital, and AAC. MDCT was proposed by J. P. Princen, A. W. Johnson and A. B. Bradley in 1987, following earlier work by Princen and Bradley in 1986.

The world's first commercial broadcast automation audio compression system was developed by Oscar Bonello, an engineering professor at the University of Buenos Aires.

In 1983, using the psychoacoustic principle of the masking of critical bands first published in 1967, he started developing a practical application based on the recently developed IBM PC computer, and the broadcast automation system was launched in 1987 under the name Audicom.

35 years later, almost all the radio stations in the world were using this technology manufactured by a number of companies because the inventor refuses to get invention patents for his work. He prefers declaring it of Public Domain publishing it
A literature compendium for a large variety of audio coding systems was published in the IEEE's "Journal on Selected Areas in Communications" ("JSAC"), in February 1988. While there were some papers from before that time, this collection documented an entire variety of finished, working audio coders, nearly all of them using perceptual techniques and some kind of frequency analysis and back-end noiseless coding.

Uncompressed video requires a very high data rate. Although lossless video compression codecs perform at a compression factor of 5 to 12, a typical H.264 lossy compression video has a compression factor between 20 and 200.

The two key video compression techniques used in video coding standards are the DCT and motion compensation (MC). Most video coding standards, such as the H.26x and MPEG formats, typically use motion-compensated DCT video coding (block motion compensation).

Most video codecs are used alongside audio compression techniques to store the separate but complementary data streams as one combined package using so-called "container formats".

Video data may be represented as a series of still image frames. Such data usually contains abundant amounts of spatial and temporal redundancy. Video compression algorithms attempt to reduce redundancy and store information more compactly.

Most video compression formats and codecs exploit both spatial and temporal redundancy (e.g. through difference coding with motion compensation). Similarities can be encoded by only storing differences between e.g. temporally adjacent frames (inter-frame coding) or spatially adjacent pixels (intra-frame coding). Inter-frame compression (a temporal delta encoding) (re)uses data from one or more earlier or later frames in a sequence to describe the current frame. Intra-frame coding, on the other hand, uses only data from within the current frame, effectively being still-image compression.

The intra-frame video coding formats used in camcorders and video editing employ simpler compression that uses only intra-frame prediction. This simplifies video editing software, as it prevents a situation in which a compressed frame refers to data that the editor has deleted.

Usually, video compression additionally employs lossy compression techniques like quantization that reduce aspects of the source data that are (more or less) irrelevant to the human visual perception by exploiting perceptual features of human vision. For example, small differences in color are more difficult to perceive than are changes in brightness. Compression algorithms can average a color across these similar areas in a manner similar to those used in JPEG image compression. As in all lossy compression, there is a trade-off between video quality and bit rate, cost of processing the compression and decompression, and system requirements. Highly compressed video may present visible or distracting artifacts.

Other methods other than the prevalent DCT-based transform formats, such as fractal compression, matching pursuit and the use of a discrete wavelet transform (DWT), have been the subject of some research, but are typically not used in practical products. Wavelet compression is used in still-image coders and video coders without motion compensation. Interest in fractal compression seems to be waning, due to recent theoretical analysis showing a comparative lack of effectiveness of such methods.

In inter-frame coding, individual frames of a video sequence are compared from one frame to the next, and the video compression codec records the differences to the reference frame. If the frame contains areas where nothing has moved, the system can simply issue a short command that copies that part of the previous frame into the next one. If sections of the frame move in a simple manner, the compressor can emit a (slightly longer) command that tells the decompressor to shift, rotate, lighten, or darken the copy. This longer command still remains much shorter than data generated by intra-frame compression. Usually, the encoder will also transmit a residue signal which describes the remaining more subtle differences to the reference imagery. Using entropy coding, these residue signals have a more compact representation than the full signal. In areas of video with more motion, the compression must encode more data to keep up with the larger number of pixels that are changing. Commonly during explosions, flames, flocks of animals, and in some panning shots, the high-frequency detail leads to quality decreases or to increases in the variable bitrate.

Today, nearly all commonly used video compression methods (e.g., those in standards approved by the ITU-T or ISO) share the same basic architecture that dates back to H.261 which was standardized in 1988 by the ITU-T. They mostly rely on the DCT, applied to rectangular blocks of neighboring pixels, and temporal prediction using motion vectors, as well as nowadays also an in-loop filtering step.

In the prediction stage, various deduplication and difference-coding techniques are applied that help decorrelate data and describe new data based on already transmitted data.

Then rectangular blocks of remaining pixel data are transformed to the frequency domain. In the main lossy processing stage, frequency domain data gets quantized in order to reduce information that is irrelevant to human visual perception.

In the last stage statistical redundancy gets largely eliminated by an entropy coder which often applies some form of arithmetic coding.

In an additional in-loop filtering stage various filters can be applied to the reconstructed image signal. By computing these filters also inside the encoding loop they can help compression because they can be applied to reference material before it gets used in the prediction process and they can be guided using the original signal. The most popular example are deblocking filters that blur out blocking artifacts from quantization discontinuities at transform block boundaries.

In 1967, A.H. Robinson and C. Cherry proposed a run-length encoding bandwidth compression scheme for the transmission of analog television signals. The DCT, which is fundamental to modern video compression, was introduced by Nasir Ahmed, T. Natarajan and K. R. Rao in 1974.

H.261, which debuted in 1988, commercially introduced the prevalent basic architecture of video compression technology. It was the first video coding format based on DCT compression. H.261 was developed by a number of companies, including Hitachi, PictureTel, NTT, BT and Toshiba.

The most popular video coding standards used for codecs have been the MPEG standards. MPEG-1 was developed by the Motion Picture Experts Group (MPEG) in 1991, and it was designed to compress VHS-quality video. It was succeeded in 1994 by MPEG-2/H.262, which was developed by a number of companies, primarily Sony, Thomson and Mitsubishi Electric. MPEG-2 became the standard video format for DVD and SD digital television. In 1999, it was followed by MPEG-4/H.263. It was also developed by a number of companies, primarily Mitsubishi Electric, Hitachi and Panasonic.

H.264/MPEG-4 AVC was developed in 2003 by a number of organizations, primarily Panasonic, Godo Kaisha IP Bridge and LG Electronics. AVC commercially introduced the modern context-adaptive binary arithmetic coding (CABAC) and context-adaptive variable-length coding (CAVLC) algorithms. AVC is the main video encoding standard for Blu-ray Discs, and is widely used by video sharing websites and streaming internet services such as YouTube, Netflix, Vimeo, and iTunes Store, web software such as Adobe Flash Player and Microsoft Silverlight, and various HDTV broadcasts over terrestrial and satellite television.

Genetics compression algorithms are the latest generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and genetic algorithms adapted to the specific datatype. In 2012, a team of scientists from Johns Hopkins University published a genetic compression algorithm that does not use a reference genome for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression and is less computationally intensive than the leading general-purpose compression utilities. For this, Chanda, Elhaik, and Bader introduced MAF-based encoding (MAFE), which reduces the heterogeneity of the dataset by sorting SNPs by their minor allele frequency, thus homogenizing the dataset. Other algorithms developed in 2009 and 2013 (DNAZip and GenomeZip) have compression ratios of up to 1200-fold—allowing 6 billion basepair diploid human genomes to be stored in 2.5 megabytes (relative to a reference genome or averaged over many genomes). For a benchmark in genetics/genomics data compressors, see 

It is estimated that the total amount of data that is stored on the world's storage devices could be further compressed with existing compression algorithms by a remaining average factor of 4.5:1. It is estimated that the combined technological capacity of the world to store information provides 1,300 exabytes of hardware digits in 2007, but when the corresponding content is optimally compressed, this only represents 295 exabytes of Shannon information.


History of the Democratic Republic of the Congo

The earliest known human settlements in what is now the Democratic Republic of the Congo have been dated back to the Middle Stone Age, approximately 90,000 years ago. The first real states, such as the Kongo, the Lunda, the Luba and Kuba, appeared south of the equatorial forest on the savannah from the 14th century onwards.

The Kingdom of Kongo controlled much of western and central Africa including what is now the western portion of the DR Congo between the 14th and the early 19th centuries. At its peak it had many as 500,000 people, and its capital was known as Mbanza-Kongo (south of Matadi, in modern-day Angola). In the late 15th century, Portuguese sailors arrived in the Kingdom of Kongo, and this led to a period of great prosperity and consolidation, with the king's power being founded on Portuguese trade. King Afonso I (1506–1543) had raids carried out on neighboring districts in response to Portuguese requests for slaves. After his death, the kingdom underwent a deep crisis.

The Atlantic slave trade occurred from approximately 1500 to 1850, with the entire west coast of Africa targeted, but the region around the mouth of the Congo suffered the most intensive enslavement. Over a strip of coastline about long, about 4 million people were enslaved and sent across the Atlantic to sugar plantations in Brazil, the US and the Caribbean. From 1780 onwards, there was a higher demand for slaves in the US which led to more people being enslaved. By 1780, more than 15,000 people were shipped annually from the Loango Coast, north of the Congo.

In 1870, explorer Henry Morton Stanley arrived in and explored what is now the DR Congo. Belgian colonization of DR Congo began in 1885 when King Leopold II founded and ruled the Congo Free State. However, de facto control of such a huge area took decades to achieve. Many outposts were built to extend the power of the state over such a vast territory. In 1885, the Force Publique was set up, a colonial army with white officers and black soldiers. In 1886, Leopold made Camille Jansen the first Belgian governor-general of Congo. Over the late 19th century, various Christian (including Catholic and Protestant) missionaries arrived intending to convert the local population. A railway between Matadi and Stanley Pool was built in the 1890s. Reports of widespread murder, torture, and other abuses in the rubber plantations led to international and Belgian outrage and the Belgian government transferred control of the region from Leopold II and established the Belgian Congo in 1908.

Following unrest, Belgium granted Congo independence in 1960. However, the Congo remained unstable, leading to the Congo Crisis, where the regional governments of Katanga and South Kasai attempted to gain independence with Belgian support. Prime Minister Patrice Lumumba tried to suppress secession with the aid of the Soviet Union as part of the Cold War, causing the United States to support a coup led by Colonel Joseph Mobutu. Lumumba was handed over to the Katangan government and executed in 1961. The secessionist movements were later defeated by the Congolese government as were the Soviet-backed Simba rebels. Following the end of the Congo Crisis in 1965, Joseph Kasa-Vubu was deposed and Mobutu seized complete power of the country and then renamed it Zaire. He sought to Africanize the country, changing his own name to Mobutu Sese Seko Kuku Ngbendu Wa Za Banga, and demanded that African citizens change their Western names to traditional African names. Mobutu sought to repress any opposition to his rule, which he successfully did throughout the 1980s. However, with his regime weakened in the 1990s, Mobutu was forced to agree to a power-sharing government with the opposition party. Mobutu remained the head of state and promised elections within the next two years that never took place.

During the First Congo War, Rwanda invaded Zaire, in which Mobutu lost his power during this process. In 1997, Laurent-Désiré Kabila took power and renamed the country the Democratic Republic of the Congo. Afterwards, the Second Congo War broke out, resulting in a regional war in which many different African nations took part and in which millions of people were killed or displaced. Laurent-Désiré Kabila was assassinated by his own bodyguard in 2001, and his son, Joseph, succeeded him and was later elected president by the Congolese government in 2006. Joseph Kabila quickly sought peace. Foreign soldiers remained in the Congo for a few years and a power-sharing government between Joseph Kabila and the opposition party was set up. Joseph Kabila later resumed complete control over the Congo and was re-elected in a disputed election in 2011. In 2018, Félix Tshisekedi was elected president; in the first peaceful transfer of power since independence.

The area now known as the Democratic Republic of the Congo was populated as early as 90,000 years ago, as shown by the 1988 discovery of the Semliki harpoon at Katanda, one of the oldest barbed harpoons ever found, which is believed to have been used to catch giant river catfish.

The Kingdom of Kongo existed from the 14th to the early 19th century. Until the arrival of the Portuguese it was the dominant force in the region along with the Kingdom of Luba, the Kingdom of Lunda, the Mongo people and the Anziku Kingdom.

The Congo Free State was a privately controlled by Leopold II of Belgium through the "Association Internationale africaine", a non-governmental organization. Leopold was the sole shareholder and chairman. The state included the entire area of the present the Democratic Republic of the Congo. Under Leopold II, the Congo Free State became one of the most infamous international scandals of the turn of the twentieth century. The report of the British Consul Roger Casement led to the arrest and punishment of white officials who had been responsible for cold-blooded killings during a rubber-collecting expedition in 1900, including a Belgian national who caused the shooting of at least 122 Congolese natives. Estimates of the total death toll vary considerably. The first census was only done in 1924, so it is even more difficult to quantify the population loss of the period. Roger Casement's famous 1904 report estimated ten million people. According to Casement's report, indiscriminate "war", starvation, reduction of births and Tropical diseases caused the country's depopulation. European and U.S. press agencies exposed the conditions in the Congo Free State to the public in 1900. By 1908 public and diplomatic pressure had led Leopold II to annex the Congo as the Belgian Congo colony.

On 15 November 1908 King Leopold II of Belgium formally relinquished personal control of the Congo Free State. The renamed Belgian Congo was put under the direct administration of the Belgian government and its Ministry of Colonies.

Belgian rule in the Congo was based around the "colonial trinity" ("trinité colonial") of state, missionary and private company interests. The privileging of Belgian commercial interests meant that large amounts of capital flowed into the Congo and that individual regions became specialized. The interests of the government and private enterprise became closely tied; the state helped companies break strikes and remove other barriers imposed by the indigenous population. The country was split into nesting, hierarchically organized administrative subdivisions, and run uniformly according to a set "native policy" ("politique indigène")—in contrast to the British and the French, who generally favored the system of indirect rule whereby traditional leaders were retained in positions of authority under colonial oversight. There was also a high degree of racial segregation. Large numbers of white immigrants who moved to the Congo after the end of World War II came from across the social spectrum, but were nonetheless always treated as superior to blacks.

During the 1940s and 1950s, the Congo experienced an unprecedented level of urbanization and the colonial administration began various development programs aimed at making the territory into a "model colony". Notable advances were made in treating diseases such as African trypanosomiasis. One of the results of these measures was the development of a new middle class of Europeanised African "évolués" in the cities. By the 1950s the Congo had a wage labor force twice as large as that in any other African colony. The Congo's rich natural resources, including uranium—much of the uranium used by the U.S. nuclear programme during World War II was Congolese—led to substantial interest in the region from both the Soviet Union and the United States as the Cold War developed.

During the latter stages of World War II a new social stratum emerged in the Congo, known as the "évolué"s. Forming an African middle class in the colony, they held skilled positions (such as clerks and nurses) made available by the economic boom. While there were no universal criteria for determining "évolué status", it was generally accepted that one would have "a good knowledge of French, adhere to Christianity, and have some form of post-primary education." Early on in their history, "évolué"s sought to use their unique status to earn special privileges in the Congo. Since opportunities for upward mobility through the colonial structure were limited, the "évolué" class institutionally manifested itself in elite clubs through which they could enjoy trivial privileges that made them feel distinct from the Congolese "masses". Additional groups, such as labor unions, alumni associations, and ethnic syndicates, provided other Congolese the means of organization. Among the most important of these was the Alliance des Bakongo (ABAKO), representing the Kongo people of the Lower Congo. However, they were restricted in their actions by the administration. While white settlers were consulted in the appointment of certain officials, the Congolese had no means of expressing their beliefs through the governing structures. Though native chiefs held legal authority in some jurisdictions, in practice they were used by the administration to further its own policies.

Up into the 1950s, most "évolué"s were concerned only with social inequalities and their treatment by the Belgians. Questions of self-government were not considered until 1954 when ABAKO requested that the administration consider a list of suggested candidates for a Léopoldville municipal post. That year the association was taken over by Joseph Kasa-Vubu, and under his leadership, it became increasingly hostile to the colonial authority and sought autonomy for the Kongo regions in the Lower Congo. In 1956 a group of Congolese intellectuals under the tutelage of several European academics issued a manifesto calling for a transition to independence over the course of 30 years. The ABAKO quickly responded with a demand for "immediate independence". The Belgian government was not prepared to grant the Congo independence and even when it started realizing the necessity of a plan for decolonization in 1957, it was assumed that such a process would be solidly controlled by Belgium. In December 1957 the colonial administration instituted reforms that permitted municipal elections and the formation of political parties. Some Belgian parties attempted to establish branches in the colony, but these were largely ignored by the population in favour of Congolese-initiated groups. Nationalism fermented in 1958 as more "évolué"s began interacting with others outside of their own locales and started discussing the future structures of a post-colonial Congolese state. Nevertheless, most political mobilisation occurred along tribal and regional divisions. In Katanga, various tribal groups came together to form the Confédération des associations tribales du Katanga (CONAKAT) under the leadership of Godefroid Munongo and Moïse Tshombe. Hostile to immigrant peoples, it advocated provincial autonomy and close ties with Belgium. Most of its support was rooted in individual chiefs, businessmen, and European settlers of southern Katanga. It was opposed by Jason Sendwe's Association Générale des Baluba du Katanga (BALUBAKAT).
In October 1958 a group of Léopoldville "évolués" including Patrice Lumumba, Cyrille Adoula and Joseph Iléo established the Mouvement National Congolais (MNC). Diverse in membership, the party sought to peacefully achieve Congolese independence, promote the political education of the populace, and eliminate regionalism. The MNC drew most of its membership from the residents of the eastern city of Stanleyville, where Lumumba was well known, and from the population of the Kasai Province, where efforts were directed by a Muluba businessman, Albert Kalonji. Belgian officials appreciated its moderate and anti-separatist stance and allowed Lumumba to attend the All-African Peoples' Conference in Accra, Ghana, in December 1958 (Kasa-Vubu was informed that the documents necessary for his travel to the event were not in order and was not permitted to go). Lumumba was deeply impressed by the Pan-Africanist ideals of Ghanaian President Kwame Nkrumah and returned to the Congo with a more radical party programme. He reported on his trip during a widely attended rally in Léopoldville and demanded the country's "genuine" independence.

Fearing that they were being overshadowed by Lumumba and the MNC, Kasa-Vubu and the ABAKO leadership announced that they would be hosting their own rally in the capital on 4 January 1959. The municipal government (under Belgian domination) was given short notice, and communicated that only a "private meeting" would be authorised. On the scheduled day of the rally the ABAKO leadership told the crowd that had gathered that the event was postponed and that they should disperse. The mass was infuriated and instead began hurling stones at the police and pillaging European property, initiating three days of violent and destructive riots. The Force Publique, the colonial army, was called into service and suppressed the revolt with considerable brutality. In wake of the riots Kasa-Vubu and his lieutenants were arrested. Unlike earlier expressions of discontent, the grievances were conveyed primarily by uneducated urban residents, not "évolué"s. Popular opinion in Belgium was one of extreme shock and surprise. An investigative commission found the riots to be the culmination of racial discrimination, overcrowding, unemployment, and wishes for more political self-determination. On 13 January the administration announced several reforms, and the Belgian King, Baudouin, declared that independence would be granted to the Congo in the future.

Meanwhile, discontent surfaced among the MNC leadership, who were bothered by Lumumba's domination over the party's politics. Relations between Lumumba and Kalonji also grew tense, as the former was upset with how the latter was transforming the Kasai branch into an exclusively Luba group and antagonising other tribes. This culminated into the split of the party into the MNC-Lumumba/MNC-L under Lumumba and the MNC-Kalonji/MNC-K under Kalonji and Iléo. The latter began advocating federalism. Adoula left the organisation. Alone to lead his own faction and facing competition from ABAKO, Lumumba became increasingly insistent in his demands for independence. Following an October riot in Stanleyville he was arrested. Nevertheless, the influence of himself and the MNC-L continued to grow rapidly. The party advocated for a strong unitary state, nationalism, and the termination of Belgian rule and began forming alliances with regional groups, such as the Kivu-based Centre du Regroupement Africain (CEREA). Though the Belgians supported a unitary system over the federal models suggested by ABAKO and CONAKAT, they and more moderate Congolese were unnerved by Lumumba's increasingly extremist attitudes. With the implicit support of the colonial administration, the moderates formed the Parti National du Progrès (PNP) under the leadership of Paul Bolya and Albert Delvaux. It advocated centralisation, respect for traditional elements, and close ties with Belgium. In southern Léopoldville Province, a socialist-federalist party, the Parti Solidaire Africain (PSA) was founded. Antoine Gizenga served as its president, and Cléophas Kamitatu was in charge of the Léopoldville Province chapter.

Following the riots in Leopoldville (4–7 January 1959) and in Stanleyville (31 October 1959), the Belgians realised they could not maintain control of such a vast country in the face of rising demands for independence. Belgian and Congolese political leaders held a Round Table Conference in Brussels beginning on 18 January 1960.

At the end of the conference, on 27 January 1960, it was announced that elections would be held in the Congo on 22 May 1960, and full independence granted on 30 June 1960. The elections produced the nationalist Patrice Lumumba as prime minister, and Joseph Kasavubu as president.
On independence the country adopted the name "Republic of the Congo" (République du Congo). The French colony of Middle Congo (Moyen Congo) also chose the name Republic of the Congo upon its independence, so the two countries were more commonly known as Congo-Léopoldville and Congo-Brazzaville, after their capital cities.

In 1960, the country was very unstable—regional tribal leaders held far more power than the central government—and with the departure of the Belgian administrators, almost no skilled bureaucrats remained in the country. The first Congolese graduated from university only in 1956, and very few in the new nation had any idea how to manage a country of such size.

On 5 July 1960, a military mutiny by Congolese soldiers against their European officers broke out in the capital and rampant looting began. On 11 July 1960 the richest province of the country, Katanga, seceded under Moise Tshombe. The United Nations sent 20,000 peacekeepers to protect Europeans in the country and try to restore order. Western paramilitaries and mercenaries, often hired by mining companies to protect their interests, also began to pour into the country. In this period Congo's second richest province, Kasai, also announced its independence on 8 August 1960.

After trying to get help from the United States and the United Nations, Prime Minister Lumumba turned to the USSR for assistance. Nikita Khrushchev agreed to help, offering advanced weaponry and technical advisors. The United States viewed the Soviet presence as an attempt to take advantage of the situation and gain a proxy state in sub-Saharan Africa. UN forces were ordered to block any shipments of arms into the country. The United States also looked for a way to replace Lumumba as leader. President Kasavubu had clashed with Prime Minister Lumumba and advocated an alliance with the West rather than the Soviets. The U.S. sent weapons and CIA personnel to aid forces allied with Kasavubu and combat the Soviet presence.

On 23 August, the Congolese armed forces invaded South Kasai and perpetrated massacres against the Luba people. Lumumba was dismissed from office on 5 September 1960 by Kasavubu who publicly blamed him for the massacres in South Kasai and for involving Soviets in the country. On 14 September 1960, with CIA support, Colonel Joseph Mobutu overthrew the government and arrested Lumumba. A technocratic government, the College of Commissioners-General, was established.

On 17 January 1961 Mobutu sent Lumumba to Élisabethville (now Lubumbashi), capital of Katanga. In full view of the press he was beaten and forced to eat copies of his own speeches. For three weeks afterward, he was not seen or heard from. Then Katangan radio announced implausibly that he had escaped and been killed by villagers. It was soon clear that in fact he had been tortured and killed along with two others shortly after his arrival. In 2001, a Belgian inquiry established that he had been shot by Katangan gendarmes in the presence of Belgian officers, under Katangan command. Lumumba was beaten, placed in front of a firing squad with two allies, cut up, buried, dug up and what remained was dissolved in acid.

In Stanleyville, those loyal to the deposed Lumumba set up a rival government under Antoine Gizenga which lasted from 31 March 1961 until it was reintegrated on 5 August 1961. After some reverses, UN and Congolese government forces succeeded in recapturing the breakaway provinces of South Kasai on 30 December 1961, and Katanga on 15 January 1963.

Beginning in 1964, in the east of the country, Soviet and Cuban backed rebels called the Simbas rose up, taking a significant amount of territory and proclaiming a communist "People's Republic of the Congo" in Stanleyville. As the Congolese government was reclaiming territory from the Simbas, the rebels resorted to taking the local white population hostage. Belgian and American forces pushed the Simbas out of Stanleyville in November 1964 during a hostage rescue operation. Congolese government forces, supported by European mercenaries, fully defeated the Simba rebels by November 1965. The Simba rebels executed 20,000 Congolese and 392 Western hostages, including 268 Belgians, during the rebellion. Tens of thousands of people were killed in total during the suppression of the Simbas.

Unrest and rebellion plagued the government until November 1965, when Lieutenant General Joseph-Désiré Mobutu, by then commander in chief of the national army, seized control of the country and declared himself president for the next five years. Mobutu quickly consolidated his power, despite the Stanleyville mutinies of 1966 and 1967, and was elected unopposed as president in a sham election in 1970 for a seven-year term.

Embarking on a campaign of cultural awareness, President Mobutu renamed the country the "Republic of Zaire" in 1971 and required citizens to adopt African names and drop their French-language ones. The name comes from Portuguese, adapted from the Kongo word "nzere" or "nzadi" ("river that swallows all rivers"). Among other changes, Leopoldville became Kinshasa and Katanga Shaba.
Relative peace and stability prevailed until 1977 and 1978 when Katangan Front for Congolese National Liberation rebels, based in the Angolan People's Republic, launched the Shaba I and II invasions into the southeast Shaba region. These rebels were driven out with the aid of French and Belgian paratroopers plus Moroccan troops. An Inter-African Force remained in the region for some time afterwards.

Zaire remained a one-party state in the 1980s. Although Mobutu successfully maintained control during this period, opposition parties, most notably the Union pour la Démocratie et le Progrès Social (UDPS), were active. Mobutu's attempts to quell these groups drew significant international criticism.

As the Cold War came to a close, internal and external pressures on Mobutu increased. In late 1989 and early 1990, Mobutu was weakened by a series of domestic protests, by heightened international criticism of his regime's human rights practices, by a faltering economy, and by government corruption, most notably his own massive embezzlement of government funds for personal use.

In April 1990, Mobutu declared the Third Republic, agreeing to a limited multi-party system with free elections and a constitution. As details of the reforms were delayed, soldiers in September 1991 began looting Kinshasa to protest their unpaid wages. Two thousand French and Belgian troops, some of whom were flown in on U.S. Air Force planes, arrived to evacuate the 20,000 endangered foreign nationals in Kinshasa.

In 1992, after previous similar attempts, the long-promised Sovereign National Conference was staged, encompassing over 2,000 representatives from various political parties. The conference gave itself a legislative mandate and elected Archbishop Laurent Monsengwo Pasinya as its chairman, along with Étienne Tshisekedi, leader of the UDPS, as prime minister. By the end of the year Mobutu had created a rival government with its own prime minister. The ensuing stalemate produced a compromise merger of the two governments into the High Council of Republic-Parliament of Transition (HCR-PT) in 1994, with Mobutu as head of state and Kengo Wa Dondo as prime minister. Although presidential and legislative elections were scheduled repeatedly over the next two years, they never took place.

By 1996, tensions from the war and genocide in neighboring Rwanda had spilled over into Zaire. Rwandan Hutu militia forces (Interahamwe) who had fled Rwanda following the ascension of a Tutsi-led government had been using Hutu refugee camps in eastern Zaire as bases for incursions into Rwanda. In October 1996
Rwandan forces attacked refugee camps in the Ruzizi Plain near the intersection of the Congolese, Rwandan and Burundi borders meet, scattering refugees. They took Uvira, then Bukavu, Goma and Mugunga.

Hutu militia forces soon allied with the Zairian armed forces (FAZ) to launch a campaign against Congolese ethnic Tutsis in eastern Zaire. In turn, these Tutsis formed a militia to defend themselves against attacks. When the Zairian government began to escalate the massacres in November 1996, Tutsi militias erupted in rebellion against Mobutu.

The Tutsi militia was soon joined by various opposition groups and supported by several countries, including Rwanda and Uganda. This coalition, led by Laurent-Desire Kabila, became known as the Alliance des Forces Démocratiques pour la Libération du Congo-Zaïre (AFDL). The AFDL, now seeking the broader goal of ousting Mobutu, made significant military gains in early 1997. Various Zairean politicians who had unsuccessfully opposed the dictatorship of Mobutu for many years now saw an opportunity for them in the invasion of Zaire by two of the region's strongest military forces. Following failed peace talks between Mobutu and Kabila in May 1997, Mobutu left the country on 16 May. The AFDL entered Kinshasa unopposed a day later, and Kabila named himself president, reverting the name of the country to the Democratic Republic of the Congo. He marched into Kinshasa on 20 May and consolidated power around himself and the AFDL.

In September 1997, Mobutu died in exile in Morocco.

Kabila demonstrated little ability to manage the problems of his country, and lost his allies. To counterbalance the power and influence of Rwanda in DRC, Ugandan troops created another rebel movement called the Movement for the Liberation of Congo (MLC), led by the Congolese warlord Jean-Pierre Bemba. They attacked in August 1998, backed by Rwandan and Ugandan troops. Soon afterwards, Angola, Namibia, and Zimbabwe became involved militarily in the Congo, with Angola and Zimbabwe supporting the government. While the six African governments involved in the war signed a ceasefire accord in Lusaka in July 1999, the Congolese rebels did not and the ceasefire broke down within months.

Kabila was assassinated in 2001 by a bodyguard called Rashidi Kasereka, 18, who was then shot dead, according to Justice Minister Mwenze Kongolo. Another account of the assassination says that the real killer escaped.

Kabila was succeeded by his son, Joseph. Upon taking office, Kabila called for multilateral peace talks to end the war. Kabila partly succeeded when a further peace deal was brokered between him, Uganda, and Rwanda leading to the apparent withdrawal of foreign troops.

Currently, the Ugandans and the MLC still hold a wide section of the north of the country; Rwandan forces and its front, the Rassemblement Congolais pour la Démocratie (RCD) control a large section of the east; and government forces or their allies hold the west and south of the country. There were reports that the conflict is being prolonged as a cover for extensive looting of the substantial natural resources in the country, including diamonds, copper, zinc, and coltan. The conflict was reignited in January 2002 by ethnic clashes in the northeast and both Uganda and Rwanda then halted their withdrawal and sent in more troops. Talks between Kabila and the rebel leaders, held in Sun City, lasted a full six weeks, beginning in April 2002. In June, they signed a peace accord under which Kabila would share power with former rebels. By June 2003, all foreign armies except those of Rwanda had pulled out of Congo.

Few people in the Congo have been unaffected by the conflict. A survey conducted in 2009 by the ICRC and Ipsos shows that three-quarters (76%) of the people interviewed have been affected in some way–either personally or due to the wider consequences of armed conflict.

The response of the international community has been incommensurate with the scale of the disaster resulting from the war in the Congo. Its support for political and diplomatic efforts to end the war has been relatively consistent, but it has taken no effective steps to abide by repeated pledges to demand accountability for the war crimes and crimes against humanity that were routinely committed in Congo. 
The United Nations Security Council and the U.N. Secretary-General have frequently denounced human rights abuses and the humanitarian disaster that the war unleashed on the local population, but have shown little will to tackle the responsibility of occupying powers for the atrocities taking place in areas under their control, areas where the worst violence in the country took place. In particular Rwanda and Uganda have escaped any significant sanction for their role.

DR Congo had a transitional government in July 2003 until the election was over. A constitution was approved by voters and on 30 July 2006 the Congo held its first multi-party elections since independence in 1960. Joseph Kabila took 45% of the votes and his opponent Jean-Pierre Bemba 20%. That was the origin of a fight between the two parties from 20 to 22 August 2006 in the streets of the capital, Kinshasa. Sixteen people died before policemen and MONUC took control of the city. A new election was held on 29 October 2006, which Kabila won with 70% of the vote. Bemba has decried election "irregularities". On 6 December 2006 Joseph Kabila was sworn in as president.

In December 2011, Joseph Kabila was re-elected for a second term as president. After the results were announced on 9 December, there was violent unrest in Kinshasa and Mbuji-Mayi, where official tallies showed that a strong majority had voted for the opposition candidate Étienne Tshisekedi. Official observers from the Carter Center reported that returns from almost 2,000 polling stations in areas where support for Tshisekedi was strong had been lost and not included in the official results. They described the election as lacking credibility. On 20 December, Kabila was sworn in for a second term, promising to invest in infrastructure and public services. However, Tshisekedi maintained that the result of the election was illegitimate and said that he intended also to "swear himself in" as president.

On 19 January 2015 protests led by students at the University of Kinshasa broke out. The protests began following the announcement of a proposed law that would allow Kabila to remain in power until a national census can be conducted (elections had been planned for 2016). By Wednesday 21 January clashes between police and protesters had claimed at least 42 lives (although the government claimed only 15 people had been killed).

Similarly, in September 2016, violent protests were met with brutal force by the police and Republican Guard soldiers. Opposition groups claim 80 dead, including the Students' Union leader. From Monday 19 September Kinshasa residents, as well as residents elsewhere in Congo, were mostly confined to their homes. Police arrested anyone remotely connected to the opposition as well as innocent onlookers. Government propaganda, on television, and actions of covert government groups in the streets, acted against opposition as well as foreigners. The president's mandate was due to end on 19 December 2016, but no plans were made to elect a replacement at that time and this caused further protests.

On 30 December 2018 the presidential election to determine the successor to Kabila was held. On 10 January 2019, the electoral commission announced opposition candidate Félix Tshisekedi as the winner of the vote. He was officially sworn in as president on 24 January 2019. in the ceremony of taking of the office Félix Tshisekedi appointed Vital Kamerhe as his chief of staff. In June 2020, chief of staff Vital Kamerhe was found guilty of embezzling public funds and he was sentenced to 20 years in prison. However, Kamerhe was released in December 2021.

The political allies of former president Joseph Kabila, who stepped down in January 2019, maintained control of key ministries, the legislature, judiciary and security services. However, President Felix Tshisekedi succeeded to strengthen his hold on power. In a series of moves, he won over more legislators, gaining the support of almost 400 out of 500 members of the National Assembly. The pro-Kabila speakers of both houses of parliament were forced out. In April 2021, the new government was formed without the supporters of Kabila. President Felix Tshisekedi succeeded to oust the last remaining elements of his government who were loyal to former leader Joseph Kabila. In January 2021, DRC's President Félix Tshisekedi pardoned all those convicted in the murder of Laurent-Désiré Kabila in 2001. Colonel Eddy Kapend and his co-defendants, who have been incarcerated for 15 years, were released.

After the 2023 presidential election, Tshisekedi had a clear lead in his run for a second term. On 31 December 2023, officials said that President Felix Tshisekedi had been re-elected with 73% of the vote. Nine opposition candidates signed a declaration rejecting the election and called for a rerun.

The inability of the state and the world's largest United Nations peacekeeping force to provide security throughout the vast country has led to the emergence of up to 120 armed groups by 2018, perhaps the largest number in the world. Armed groups are often accused of being proxies or being supported by regional governments interested in Eastern Congo's vast mineral wealth. Some argue that much of the lack of security by the national army is strategic on the part of the government, who let the army profit from illegal logging and mining operations in return for loyalty. Different rebel groups often target civilians by ethnicity and militias often become oriented around ethnic local militias known as "Mai-Mai".

Laurent Nkunda with other soldiers from RCD-Goma who were integrated into the army defected and called themselves the National Congress for the Defence of the People (CNDP). Starting in 2004, CNDP, believed to be backed by Rwanda as a way to tackle the Hutu group Democratic Forces for the Liberation of Rwanda (FDLR), rebelled against the government, claiming to protect the Banyamulenge (Congolese Tutsis). In 2009, after a deal between the DRC and Rwanda, Rwandan troops entered the DRC and arrested Nkunda and were allowed to pursue FDLR militants. The CNDP signed a peace treaty with the government where its soldiers would be integrated into the national army.

In April 2012, the leader of the CNDP, Bosco Ntaganda and troops loyal to him mutinied, claiming a violation of the peace treaty and formed a rebel group, the March 23 Movement (M23), which was believed to be backed by Rwanda. On 20 November 2012, M23 took control of Goma, a provincial capital with a population of one million people. The UN authorized the Force Intervention Brigade (FIB), which was the first UN peacekeeping force with a mandate to neutralize opposition rather than a defensive mandate, and the FIB quickly defeated M23. The FIB was then to fight the FDLR but were hampered by the efforts of the Congolese government, who some believe tolerate the FDLR as a counterweight to Rwandan interests. Since 2017, fighters from M23, most of whom had fled into Uganda and Rwanda (both were believed to have supported them), started crossing back into DRC with the rising crisis over Kabila's extension of his term limit.

After rising insecurity, President Tshisekedi declared a "state of siege" or state of emergency in North Kivu, as well as Ituri province, in the first such declaration since the country's independence. The military and police took over positions from civilian authorities and some saw it as a powerplay since the civilian officials were part of the opposition to the President. A similar declaration was avoided for South Kivu, in a move believed to avoid antagonizing armed groups with ties to regional powers such as Rwanda.

Ethnic conflict in Kivu has often involved the Congolese Tutsis known as Banyamulenge, a cattle herding group of Rwandan origin derided as outsiders, and other ethnic groups who consider themselves indigenous. Additionally, neighboring Burundi and Rwanda, who have a thorny relationship, are accused of being involved, with Rwanda accused of training Burundi rebels who have joined with Mai Mai against the Banyamulenge and the Banyamulenge is accused of harboring the RNC, a Rwandan opposition group supported by Burundi. In June 2017, the group was formed called the National Coalition of the People for the Sovereignty of Congo (CNPSC) or Alliance of Article 64, a reference to Article 64 of the constitution, which says the people have an obligation to fight the efforts of those who seek to take power by force, in reference to President Kabila. It is one of three alliances of various Mai-Mai militias and is led by Bembe warlord William Yakutumba whose Mai-Mai Yakutumba is the largest component of the CNPSC and has had friction with the Congolese Tutsis. was formed and even briefly capturing a few strategic towns. In May 2019, Banyamulenge fighters killed a Banyindu traditional chief, Kawaza Nyakwana. Later in 2019, a coalition of militias from the Bembe, Bafuliru and Banyindu are estimated to have burnt more than 100, mostly Banyamulenge, villages and stole tens of thousands of cattle from the largely cattle-herding Banyamulenge. About 200,000 people fled their homes.

Clashes between Hutu militias and militias of other ethnic groups has also been prominent. In 2012, the Congolese army in its attempt to crush the Rwandan backed and Tutsi-dominated CNDP and M23 rebels, empowered and used Hutu groups such as the FDLR and a Hutu dominated Maï Maï Nyatura as proxies in its fight. The Nyatura and FDLR even arbitrarily executed up to 264 mostly Tembo civilians in 2012. In 2015, the army then launched an offensive against the FDLR militia. The FDLR and Nyatura were accused of killing Nande people and of burning their houses. The Nande-dominate UPDI militia, a Nande militia called Mai-Mai Mazembe and a militia dominated by Nyanga people, the "Nduma Defense of Congo" (NDC), also called Maï-Maï Sheka and led by Gédéon Kyungu Mutanga, are accused of attacking Hutus. In North Kivu, in 2017, an alliance of Mai-Mai groups called the National Movement of Revolutionaries (MNR) began attacks in June 2017 includes Nande Mai-Mai leaders from groups such as Corps du Christ and Mai-Mai Mazembe. Another alliance of Mai-Mai groups is CMC which brings together Hutu militia Nyatura and are active along the border between North Kivu and South Kivu. In September 2019, the army declared it had killed Sylvestre Mudacumura, head of the FDLR, and in November that year the army declared it had killed Juvenal Musabimana, who had led a splinter group of the FDLR.

The Allied Democratic Forces (ADF) has been waging an insurgency in the Democratic Republic of the Congo and is blamed for the Beni massacre in 2016. While the Congolese army maintains that the ADF is an Islamist insurgency, most observers feel that they are only a criminal group interested in gold mining and logging. In March 2021, the United States claimed that the ADF was linked to the Islamic State of Iraq and the Levant as part of the Islamic State's Central Africa Province. By 2021, the ADF was considered the deadliest of the many armed groups in the east of the country.

In Northern Katanga Province starting in 2013, the Pygmy Batwa people, whom the Luba people often exploit and allegedly enslave, rose up into militias, such as the "Perci" militia, and attacked Luba villages. A Luba militia known as "Elements" or "Elema" attacked back, notably killing at least 30 people in the "Vumilia 1" displaced people camp in April 2015. Since the start of the conflict, hundreds have been killed and tens of thousands have been displaced from their homes. The weapons used in the conflict are often arrows and axes, rather than guns.

Elema also began fighting the government mainly with machetes, bows and arrows in Congo's Haut Katanga and Tanganyika provinces. The government forces fought alongside a tribe known as the Abatembo and targeting civilians of the Luba and the Tabwa tribes who were believed to be sympathetic to the Elema.

In the Kasaï-Central province, starting in 2016, the largely Luba Kamwina Nsapu militia led by Kamwina Nsapu attacked state institutions. The leader was killed by authorities in August 2016 and the militia reportedly took revenge by attacking civilians. By June 2017, more than 3,300 people had been killed and 20 villages have been completely destroyed, half of them by government troops. The militia has expanded to the neighboring Kasai-Oriental area, Kasaï and Lomami.

The UN discovered dozens of mass graves. There was an ethnic nature to the conflict with the rebels being mostly Luba and Lulua and have selectively killed non-Luba people while the government allied militia, the Bana Mura, constituting people from the Chokwe, Pende, and Tetela, have committed ethnically motivated attacks against the Luba and Lulua.

The Ituri conflict in the Ituri region of the north-eastern DRC involved fighting between the agriculturalist Lendu and pastoralist Hema ethnic groups, who together made up around 40% of Ituri's population, with other groups including the Ndo-Okebo and the Nyali. During Belgian rule, the Hema were given privileged positions over the Lendu while long time leader Mobutu Sese Seko also favored the Hema. While "Ituri conflict" often refers to the major fighting from 1999 to 2003, fighting has existed before and continues since that time. During the Second Congolese Civil War, Ituri was considered the most violent region. An agricultural and religious group from the Lendu people known as the "Cooperative for the Development of Congo" or CODECO allegedly reemerged as a militia in 2017 and began attacking the Hema as well as the Alur people to control the resources in the region, with the Ndo-Okebo and the Nyali also involved in the violence. After disagreements over negotiating with the government and the killing of CODECO's leader, Ngudjolo Duduko Justin, in March 2020, the group splintered and violence spread into new areas. In late 2020, CODECO briefly held the capital of the province, Bunia, but retreated. In June 2019, attacks by CODECO led to 240 people being killed and more than 300,000 people fleeing.

The Allied Democratic Forces (ADF), mostly active in North and South Kivu has also been involved in Ituri province. President Tshisekedi declared a "state of siege" or state of emergency in the province in May 2021 to tackle ADF. However, ADF killed 57 civilians in one attack in the same month in one of its deadliest single attacks. 30 people were massacred in September 2021 by the ADF. The President is accused of promoting former rebel leaders and generals accused of war crimes to be in charge of the province.

In October 2009 a conflict started in Dongo, Sud-Ubangi District where clashes had broken out over access to fishing ponds.

Nearly 900 people were killed between 16 and 17 December 2018 around Yumbi, a few weeks before the Presidential election, when mostly those of the Batende tribe massacred mostly those of the Banunu tribe. About 16,000 fled to neighboring Republic of the Congo. It was alleged that it was a carefully planned massacre, involving elements of the national military.



Geography of the Democratic Republic of the Congo

The Democratic Republic of the Congo (DRC) is the largest country of sub-Saharan Africa, occupying some . Most of the country lies within the vast hollow of the Congo River basin. The vast, low-lying central area is a plateau-shaped basin sloping toward the west, covered by tropical rainforest and criss-crossed by rivers. The forest center is surrounded by mountainous terraces in the west, plateaus merging into savannas in the south and southwest. Dense grasslands extend beyond the Congo River in the north. High mountains of the Ruwenzori Range (some above ) are found on the eastern borders with Rwanda and Uganda (see Albertine Rift montane forests for a description of this area).

Several major geographic regions may be defined in terms of terrain and patterns of natural vegetation, namely the central Congo Basin, the uplands north and south of the basin, and the eastern highlands.

The country's core region is the central Congo Basin. Having an average elevation of about , it measures roughly , constituting about a third of the DRC's territory. Much of the forest within the basin is swamp, and still more of it consists of a mixture of marshes and firm land.

North and south of the basin lie higher plains and, occasionally, hills covered with varying mixtures of savanna grasses and woodlands. The southern uplands region, like the basin, constitutes about a third of the DRC's territory. The area slopes from south to north, starting at about near the Angolan border and falling to about near the basin. Vegetation cover in the southern uplands territory is more varied than that of the northern uplands. In some areas, woodland is dominant; in others, savanna grasses predominate. South of the basin, along the streams flowing into the Kasai River are extensive gallery forests. In the far southeast, most of the former Katanga Province is characterized by somewhat higher plateaus and low mountains. The westernmost section of the DRC, a partly forested panhandle reaching the Atlantic Ocean, is an extension of the southern uplands that drops sharply to a very narrow shore about long.

In the much narrower northern uplands, the cover is largely savanna, and woodlands are rarer. The average elevation of this region is about , but it rises as high as where it meets the western edge of the eastern highlands.

The eastern highlands region is the highest and most rugged portion of the country. It extends for more than from above Lake Albert to the country's southern tip and varies in width from . Its hills and mountains range in altitude from about to more than . The western arm of the Great Rift Valley forms a natural eastern boundary to this region. The eastern border of the DRC extends through the valley and its system of lakes, which are separated from each other by plains situated between high mountain ranges.

In this region, changes in elevation bring marked changes in vegetation, which ranges from montane savanna to heavy montane forest. The Rwenzori Mountains between lakes Albert and Edward constitutes the highest range in Africa. The height and location of these mountains on the equator make for a varied and spectacular flora.

The Congo River and its tributaries drain this basin and provide the country with the most extensive network of navigable waterways in Africa. wide at the mid-point of its length, the river carries a volume of water that is second only to the Amazon's. Its flow is unusually regular because it is fed by rivers and streams from both sides of the equator; the complementary alternation of rainy and dry seasons on each side of the equator guarantees a regular supply of water for the main channel. At points where navigation is blocked by rapids and waterfalls, the sudden descent of the river creates a hydroelectric potential greater than that found in any other river system on earth.

Most of the DRC is served by the Congo River system, a fact that has facilitated both trade and outside penetration. Its network of waterways is dense and evenly distributed through the country, with three exceptions: northeastern Mayombe in Kongo Central in the west, which is drained by a small coastal river called the Shilango; a strip of land on the eastern border adjoining lakes Edward and Albert, which is part of the Nile River basin; and a small part of the extreme southeastern DRC, which lies in the Zambezi River basin and drains into the Indian Ocean.

Most of the DRC's lakes are also part of the Congo River basin. In the west are Lac Mai-Ndombe and Lac Tumba, which are remnants of a huge interior lake that once occupied the entire basin prior to the breach of the basin's edge by the Congo River and the subsequent drainage of the interior. In the southeast, Lake Mweru straddles the border with Zambia. On the eastern frontier, Lac Kivu, Central Africa's highest lake and a key tourist center, and Lake Tanganyika, just south of Lac Kivu, both feed into the Lualaba River, the name often given to the upper extension of the Congo River. Only the waters of the eastern frontier's northernmost great lakes, Edward and Albert, drain north, into the Nile Basin.

Climate ranges from tropical rain forest in the Congo River basin to tropical wet-and-dry in the southern uplands to tropical highland in eastern areas above in elevation. In general, temperatures and humidity are quite high. The highest and least variable temperatures are to be found in the equatorial forest, where daytime highs range between , and nighttime lows rarely go below . The average annual temperature is about . In the southern uplands, particularly in the far southeast Katanga region, winters are cool and dry, whereas summers are warm and damp. The area embracing the chain of lakes from Lake Albert to Lake Tanganyika in the eastern highlands has a moist climate and a narrow but not excessively warm temperature range. The mountain sections are cooler, but humidity increases with altitude until the saturation point is reached; a nearly constant falling mist prevails on some slopes, particularly in the Rwenzori Mountains.

The seasonal pattern of rainfall is affected by the DRC's straddling of the equator. In the third of the country that lies north of the equator, the dry season (roughly early November to late March) corresponds to the rainy season in the southern two-thirds. There is a great deal of variation, however, and a number of places on either side of the equator have two wet and two dry seasons. Rainfall averages range from about . Annual rainfall is highest in the heart of the Congo River basin and in the highlands west of Bukavu and with some variation tends to diminish in direct relation to distance from these areas. The only areas marked by long four-month to five-month dry seasons and occasional droughts are parts of the Southeast.

Area:
"total:"
2,344,858 km
"land:"
2,267,048 km
"water:"
77,810 km

Area - comparative:
The 11th-largest country in the world (and 2nd in Africa); it is smaller than Algeria but larger than Greenland and Saudi Arabia. It is about a quarter the size of the United States as a whole.
Land boundaries:
"total:"
10,481 km
"border countries:"
"Angola 2,646 km, Burundi 236 km, Central African Republic 1,747 km, Republic of the Congo 1,229 km, Rwanda 221 km, South Sudan 714 km, Tanzania 479 km, Uganda 877 km, Zambia 2,332 km"

Coastline:

Maritime claims:
"territorial sea:"

"exclusive economic zone:"
boundaries with neighbors

Climate:
tropical; hot and humid in equatorial river basin; cooler and drier in southern highlands; cooler-cold and wetter in eastern highlands and the Ruwenzori Range; north of Equator - wet season April to October, dry season December to February; south of Equator - wet season November to March, dry season April to October

Terrain:
vast central plateau covered by tropical rainforest, surrounded by mountains in the west, plains and savanna in the south/southwest, and grasslands in the north. The high mountains of the Ruwenzori Range on the eastern borders.

Elevation extremes:
"lowest point:"
Atlantic Ocean 0 m
"highest point:"
Pic Marguerite on Mont Ngaliema (Mount Stanley) 5,110 m

Natural resources:
cobalt, copper, niobium, petroleum, industrial and gem diamonds, gold, silver, zinc, manganese, tin, uranium, coal, hydropower, timber

Land use:
"arable land:"
3.09% 
"permanent crops:"
0.36%
96.55 (2012 est.)

Irrigated land:
105 km (2003)

Total renewable water resources:
1,283 km (2011)

"total:"
0.68 km/yr (68%/21%/11%)

"per capita:"
11.25 m/yr (2005)

Natural hazards:

periodic droughts in south; Congo River floods (seasonal); in the east, in the Albertine Rift, there are active volcanoes

Poaching threatens wildlife populations (for example, the painted hunting dog, "Lycaon pictus", is now considered extirpated from the Congo due to human overpopulation and poaching); water pollution; deforestation (chiefly due to land conversion to agriculture by indigenous farmers); refugees responsible for significant deforestation, soil erosion, and wildlife poaching; mining of minerals (coltan — a mineral used in creating capacitors, diamonds, and gold) causing environmental damage

"party to:"
Biodiversity, Desertification, Endangered Species, Hazardous Wastes, Law of the Sea, Marine Dumping, Nuclear Test Ban, Ozone Layer Protection, Tropical Timber 83, Tropical Timber 94, Wetlands
"signed, but not ratified:"
Environmental Modification

Geography:

D.R. Congo is one of six African states that straddles the equator; it's the largest African state that has the equator passing through it. Very narrow strip of land that controls the lower Congo River and is the only outlet to South Atlantic Ocean; dense tropical rainforest in the central river basin and eastern highlands.

This is a list of the extreme points of the Democratic Republic of the Congo, the points that are farther north, south, east or west than any other location.



Demographics of the Democratic Republic of the Congo

Demographic features of the population of the Democratic Republic of the Congo include ethnicity, education level, health, economic status, religious affiliations and other aspects of the population.

As many as 250 ethnic groups have been distinguished and named. The most numerous people are the Luba, Mongo, and Kongo.

Although 700 local languages and dialects are spoken, the linguistic variety is bridged both by the use of French, and the intermediary languages Kikongo ya leta, Tshiluba, Swahili, and Lingala.

The CIA World Factbook estimated the population to be over 105 million as of 2022 (the exact number being 108,407,721), now exceeding that of Vietnam (with 98,721,275 inhabitants as of 2020) and ascending the country to the rank of 14th most populous in the world. The proportion of children below the age of 14 in 2020 was 46.38%, 51.15% of the population was between 15 and 65 years of age, while 2.47% was 65 years or older.
Population Estimates by Sex and Age Group (01.VII.2020) (Post-censal estimates.) (Provisional.):

The first and so far only census conducted in DR Congo dates from 1984.

Registration of vital events in the Democratic Republic of the Congo is incomplete. The Population Department of the United Nations prepared the following estimates.

Total Fertility Rate (TFR) (Wanted Fertility Rate) and Crude Birth Rate (CBR) for urban and rural areas:

The Wanted Fertility Rate is an estimate of what the fertility rate would be if all unwanted births were avoided.

Fertility data per province, as of 2014:

Over 250 ethnic groups and 450 tribes (ethnic subgroups) populate the Democratic Republic of Congo. These ethnic groups are from the Bantu, Sudanic, Nilotic, Ubangian and Pygmy linguistic groups. Because of this diversity, there is no dominant ethnic group in Congo, however the following ethnic groups account for 51.5% of the population:

- Luba-Kasaï

- Kongo

- Mongo

- Lubakat

- Lulua

- Tetela

- Nande

- Ngbandi

- Ngombe

- Yaka

- Ngbaka
See below for a more detailed list of Congolese ethnic groups.

Bantu peoples:

Central Sudanic:

Nilotic peoples :
Ubangian:

Azande, Banda, Ngbandi, Ngbaka 

Pygmy peoples :
More than 600,000 pygmies (around 1% of the total population) are believed to live in DR Congo, mainly in forests, where they survive by hunting wild animals and gathering fruits.

The four major languages in the DRC are French (official), Lingala (a lingua franca, or trade language), Kingwana (a dialect of Swahili), Kikongo ya leta, and Tshiluba. In total, there are over 200 ethnic languages.

French is generally the language of instruction in schools. English is taught as a compulsory foreign language in Secondary and High Schools around the country. It is a required subject in the Faculty of Economics at major universities around the country and there are numerous language schools in the country that teach it. Former President Kabila himself is fluent in both English and French, as was his father.

A survey conducted by the Demographic and Health Surveys program in 2013–2014 indicated that Christians constituted 93.7% of the population (Catholics 29.7%, Protestants 26.8%, and other Christians 37.2%). An indigenous religion, Kimbanguism, was practiced by 2.8% of the population, while Muslims make up 1.2%.

Another estimate (by the Pew Research Center in 2010) found Christianity was followed by 95.8% of the population.

The CIA The World Factbook gives the following percentages: Roman Catholic 29.9%, Protestant 26.7%, Kimbanguist 2.8%, Other Christian 36.5%, Islam 1.3%, Other (includes Syncretic Sects and Indigenous beliefs) 2.7%.

The Joshua Project, a Christian missionary organisation, gives the following percentages: Roman Catholic 43.9%, Protestant 24.8%, Other Christian 23.7%, Muslim 1.6%, Non-religious 0.6%, Hindu 0.1% other syncretic sects and indigenous beliefs 5.3%.

These are some other demographic statistics according to the World Population Review in 2022.


The following demographic statistics are from the CIA World Factbook.

Roman Catholic 29.9%, Protestant 26.7%, other Christian 36.5%, Kimbanguist 2.8%, Muslim 1.3%, other (includes syncretic sects and indigenous beliefs) 1.2%, none 1.3%, unspecified 0.2% (2014 est.)

"note": fighting between the Congolese Government and Uganda- and Rwanda-backed Congolese rebels spawned a regional war in DRC in August 1998, which left 2.33 million Congolese internally displaced and caused 412,000 Congolese refugees to flee to surrounding countries (2011 est.)

Given the situation in the country and the condition of state structures, it is extremely difficult to obtain reliable data however evidence suggests that DRC continues to be a destination country for immigrants in spite of recent declines. Immigration is seen to be very diverse in nature, with refugees and asylum-seekers - products of the numerous and violent conflicts in the Great Lakes Region - constituting an important subset of the population in the country.

Additionally, the country's large mine operations attract migrant workers from Africa and beyond and there is considerable migration for commercial activities from other African countries and the rest of the world, but these movements are not well studied. Transit migration towards South Africa and Europe also plays a role. Immigration in the DRC has decreased steadily over the past two decades, most likely as a result of the armed violence that the country has experienced.

According to the International Organization for Migration, the number of immigrants in the DRC has declined from just over 1 million in 1960, to 754,000 in 1990, to 480,000 in 2005, to an estimated 445,000 in 2010. Valid figures are not available on migrant workers in particular, partly due to the predominance of the informal economy in the DRC. Data are also lacking on irregular immigrants, however given neighbouring country ethnic links to nationals of the DRC, irregular migration is assumed to be a significant phenomenon in the country.

Figures on the number of Congolese nationals abroad vary greatly depending on the source, from 3 to 6 million. This discrepancy is due to a lack of official, reliable data. Emigrants from the DRC are above all long-term emigrants, the majority of which live within Africa and to a lesser extent in Europe; 79.7% and 15.3% respectively, according to estimates on 2000 data. Most Congolese emigrants however, remain in Africa, with new destination countries including South Africa and various points en route to Europe.

In addition to being a host country, the DRC has also produced a considerable number of refugees and asylum-seekers located in the region and beyond. These numbers peaked in 2004 when, according to UNHCR, there were more than 460,000 refugees from the DRC; in 2008, Congolese refugees numbered 367,995 in total, 68% of which were living in other African countries.

The table below shows DRC born people who have emigrated abroad in selected Western countries (although it excludes their descendants).
These are only estimates and do not account for Congolese migrants residing illegally in these and other countries. 

Congolese ethnic groups:
Other articles


Economy of the Democratic Republic of the Congo

The economy of the Democratic Republic of the Congo has declined drastically around the 1980s, despite being home to vast potential in natural resources and mineral wealth; their gross domestic product is $69.474 billion as of 2023.

At the time of its independence in 1960, the Democratic Republic of the Congo was the second most industrialized country in Africa after South Africa. It boasted a thriving mining sector and its agriculture sector was relatively productive. Since then, decades of corruption, war, and political instability have been a severe detriment to further growth, today leaving DRC with a GDP per capita and a HDI rating that rank among the world's lowest and make the DRC one of the most fragile and according to United Nations, least developed countries in the world.

Despite this the DRC is quickly modernizing; it tied with Malaysia for the largest positive change in HDI development in 2016. Government projects include strengthening the health system for maternal and child health, expansion of electricity access, water supply reconstructions, and urban and social rehabilitation programs.

The two recent conflicts (the First and Second Congo Wars), which began in 1996, have dramatically reduced national output and government revenue, have increased external debt, and have resulted in deaths of more than five million people from war, and associated famine and disease. Malnutrition affects approximately two-thirds of the country's population.

Agriculture is the mainstay of the economy, accounting for 57.9% of GDP in 1997. In 1996, agriculture employed 66% of the work force.

Rich in minerals, the Democratic Republic of the Congo has a difficult history of predatory mineral extraction, which has been at the heart of many struggles within the country for many decades, but particularly in the 1990s. The economy of the second largest country in Africa relies heavily on mining. However, much economic activity occurs in the informal sector and is not reflected in GDP data.

In 2006 Transparency International ranked the Democratic Republic of the Congo 156 out of 163 countries in the Corruption Perception Index, tying Bangladesh, Chad, and Sudan with a 2.0 rating. President Joseph Kabila established the Commission of Repression of Economic Crimes upon his ascension to power in 2001.

The conflicts in the Democratic Republic of Congo were over water, minerals, and other resources. Political agendas have worsened the economy, as in times of crisis, the elite benefit while the general populace suffers. This is worsened as a result of corrupt national and international corporations. The corporations instigate and allow the fighting for resources because they benefit from it. A large proportion of fatalities in the country are attributed to a lack of basic services. The influx of refugees since the war in 1998 only serves to worsen the issue of poverty. Money of the taxpayers in the DRC is often misappropriated by the corrupt leaders of the country, who use the money to benefit themselves instead of the citizens of the DRC. The DRC is consistently rated the lowest on the UN Human Development Index.

Forced labor (slavery) was important for the rural sector. The corporations that dominated the economy were mostly owned by Belgium, but British capital also played an important role. The 1950s were a period of rising income and expectations. Congo was said to have the best public health system in Africa, but there was also a huge wealth disparity. Belgian companies favored workers in certain areas more and exported them to work in different areas, restricting opportunities for others. Favored groups also received better education and were able to secure jobs for people in the same ethnic group which increased tensions. In 1960 there were only 16 university graduates out of a population of 20 million. Belgium still had economic power and independence gave little opportunity for improvement. Common refrains included "no elite, no trouble" and "before independence = after independence". When the Belgians left, most of the government officials and educated residents left with them. Before independence, there were just 3 out of 5000 government jobs held by Congolese people. The resulting loss of institutional knowledge and human capital crippled the government.

After the Congo Crisis, Mobutu arose as the country's sole ruler and stabilized the country politically. Economically, however, the situation continued to decline, and by 1979, the purchasing power was only 4% of that from 1960. Starting in 1976 the IMF provided stabilizing loans to the dictatorship. Much of the money was embezzled by Mobutu and his circle. This was not a secret as the 1982 report by IMF's envoy Erwin Blumenthal documented. He stated, it is "alarmingly clear that the corruptive system in Zaire with all its wicked and ugly manifestations, its mismanagement and fraud will destroy all endeavors of international institutions, of friendly governments, and of the commercial banks towards recovery and rehabilitation of Zaire’s economy". Blumenthal indicated that there was "no chance" that creditors would ever recover their loans. Yet the IMF and the World Bank continued to lend money that was either embezzled, stolen, or "wasted on elephant projects". "Structural adjustment programmes" implemented as a condition of IMF loans cut support for health care, education, and infrastructure.

Poor infrastructure, an uncertain legal framework, corruption, and lack of openness in government economic policy and financial operations remain a brake on investment and growth. A number of International Monetary Fund (IMF) and World Bank missions have met with the new government to help it develop a coherent economic plan but associated reforms are on hold.

Faced with continued currency depreciation, the government resorted to more drastic measures and in January 1999 banned the widespread use of American dollars for all domestic commercial transactions, a position it later adjusted. The government has been unable to provide foreign exchange for economic transactions, while it has resorted to printing money to finance its expenditure. Growth was negative in 2000 because of the difficulty of meeting the conditions of international donors, continued low prices of key exports, and post-coup instability.
Although depreciated, congolese francs have been stable for few years (Ndonda, 2014)

Conditions improved in late 2002 with the withdrawal of a large portion of the invading foreign troops. A number of IMF and World Bank missions have met with the government to help it develop a coherent economic plan, and President Kabila has begun implementing reforms.

DRC's economic growth decelerated from its pre-COVID level of 4.4% in 2019, to an estimated 0.8% in 2020. Growth was driven by the extractives sector which, helped by robust demand from China, expanded by 6.9% in 2020 (compared to 1% in 2019). Meanwhile, non-mining sectors contracted by 1.6% (vs. growth of 5.7% in 2019) due to pandemic-related mobility restrictions, weaker trading activities and constrained government spending. Private consumption and government investment fell in 2020 by an estimated 1.0 and 10.2%, respectively.

The DRC is embarking on the establishment of special economic zones (SEZ) to encourage the revival of its industry. The first SEZ was planned to come into being in 2012 in N'Sele, a commune of Kinshasa, and will focus on agro-industries. The Congolese authorities also planned to open another zone dedicated to mining (Katanga) and a third dedicated to cement (in the Bas-Congo). There are three phases to the program that each have their own objectives. Phase I was the precursor to the actual investment in the Special Economic Zone where policymakers agreed to the framework, the framework was studied for its establishment, and to predict the potential market demand for the land. Stage one of Phase II involved submitting laws for the Special Economic Zone, finding good sites for businesses, and currently there is an effort to help the government attract foreign investment. Stage two of Phase II hasn't been started yet and it involves assisting the government in creating framework for the country, creating an overall plan for the site, figuring out what the environmental impact of the project will be, and guessing how much it will cost and what the return can be made on the investment. Phase III involves the World Bank creating a transaction phase that will keep everything competitive. The program is looking for options to hand over the program to the World Bank which could be very beneficial for the western part of the country.

The following table shows the main economic indicators in 1980–2023. Inflation below 5% is in green.
Ongoing conflicts dramatically reduced government revenue and increased external debt. As Reyntjens wrote, "Entrepreneurs of insecurity are engaged in extractive activities that would be impossible in a stable state environment. The criminalization context in which these activities occur offers avenues for considerable factional and personal enrichment through the trafficking of arms, illegal drugs, toxic products, mineral resources and dirty money." Ethnic rivalries were made worse because of economic interests and looting and coltan smuggling took place. Illegal monopolies formed in the country where they used forced labor for children to mine or work as soldiers. National parks were overrun with people looking to exploit minerals and resources. Increased poverty and hunger from the war and that increased the hunting of rare wildlife. Education was denied when the country was under foreign control and very few people make money off the minerals in the country. The national resources are not the root cause for the continued fighting in the region, however, the competition has become an incentive to keep fighting.[1] The DRC's level of economic freedom is one of the lowest in the world, putting it in the repressed category. The armed militias fight with the government in the eastern section of the country over the mining sector or the corruption of the government, and weak policies lead to the instability of the economy. Human rights abuses also ruin economic activity; the DRC has a 7% unemployment rate, but still has one of the lowest GDP's per capita in the world. A major problem for people trying to start their own companies is that the minimum amount of capital needed to launch the company is five times the average annual income, and prices are regulated by the government, which almost forces people to have to work for the larger, more corrupt businesses; otherwise, they won't have work. It is hard for the DRC to encourage foreign trade because of the regulatory barriers.

Poor infrastructure, an uncertain legal framework, corruption, and lack of openness in government economic policy and financial operations remain a brake on investment and growth. A number of International Monetary Fund (IMF) and World Bank missions have met with the new government to help it develop a coherent economic plan but associated reforms are on hold.

Faced with continued currency depreciation, the government resorted to more drastic measures and in January 1999 banned the widespread use of U.S. dollars for all domestic commercial transactions, a position it later adjusted. The government has been unable to provide foreign exchange for economic transactions, while it has resorted to printing money to finance its expenditure. Growth was negative in 2000 because of the difficulty of meeting the conditions of international donors, continued low prices of key exports, and post-coup instability. 125 companies in 2003 contributed to the conflict in DRC showing the corruption.

With the help of the International Development Association the DRC has worked toward the reestablishment of social services. This is done by giving 15 million people access to basic health services and giving bed nets to prevent malaria from spreading to people. With the Emergency Demobilization and Reintegration Program more than 107,000 adults and 34,000 child soldiers stood down their militarized posture. The travel time from Lubumbashi to Kasomeno in Katanga went down from seven days to two hours because of the improved roads which led to the decrease of prices of main goods by 60%. With the help of the IFC, KfW, and the EU the DRC improved its businesses by reducing the time it took to create a business by 51%, reducing the time it took to get construction permits by 54%, and reducing the number of taxes from 118 to 30. Improvements in health have been noticeable specifically that deliveries attended by trained staff jumped from 47 to 80%. In education 14 million textbooks were provided to children, completion rates of school have increased, and higher education was made available to students that chose to pursue it.

The IMF plans on giving the DRC a $1 billion loan after its two-year suspension after it failed to give details about a mining deal from one of its state owned mines and an Israeli billionaire, Dan Gertler. The loan may be necessary for the country because there will be elections in December 2016 for the next president and the cost of funding this would range around $1.1 billion. The biggest problem with the vote is getting a country of 68 million people the size of Western Europe to polling stations with less than 1,860 miles of paved roads.

Agriculture is the mainstay of the economy, accounting for 57.9% of the GDP in 1997. Main cash crops include coffee, palm oil, rubber, cotton, sugar, tea, and cocoa. Food crops include cassava, plantains, maize, groundnuts, and rice. In 1996, agriculture employed 66% of the work force.

The Democratic Republic of Congo produced, in 2018:


In addition to smaller productions of other agricultural products, such as coffee (29 thousand tons), cocoa (3.6 thousand tons), natural rubber (14 thousand tons) and tea (3.6 thousand tons).

The Democratic Republic of Congo also possesses 50 percent of Africa's forests and a river system that could provide hydro-electric power to the entire continent, according to a United Nations report on the country's strategic significance and its potential role as an economic power in central Africa. Fish are the single most important source of animal protein in the DRC. Total production of marine, river, and lake fisheries in 2003 was estimated at 222,965 tons, all but 5,000 tons from inland waters. PEMARZA, a state agency, carries on marine fishing.

Forests cover 60 percent of the total land area. There are vast timber resources, and commercial development of the country's 61 million hectares (150 million acres) of exploitable wooded area is only beginning. The Mayumbe area of Bas-Congo was once the major center of timber exploitation, but forests in this area were nearly
depleted. The more extensive forest regions of the central cuvette and of the Ubangi River valley have increasingly been tapped.

Roundwood removals were estimated at 72,170,000 m in 2003, about 95 percent for fuel. Some 14 species are presently being harvested. Exports of forest products in 2003 totalled $25.7 million. Foreign capital is necessary in order for forestry to expand, and the government recognizes that changes in tax structure and export procedures will be needed to facilitate economic growth.

Rich in minerals, the DRC has a difficult history of predatory mineral extraction, which has been at the heart of many struggles within the country for many decades, but particularly in the 1990s. Although the economy of the Democratic Republic of the Congo, the second largest country in Africa who has historically relied heavily on mining, is no longer reflected in the GDP data as the mining industry has suffered from long-term "uncertain legal framework, corruption, and a lack of transparency in government policy." The informal sector .

In her book entitled "The Real Economy of Zaire", MacGaffey described a second, often illegal economy, "system D", which is outside the official economy (MacGaffey 1991:27). and therefore is not reflected in the GDP.

The economy of the second largest country in Africa relies heavily on mining. The Congo is the world's largest producer of cobalt ore, and a major producer of copper and industrial diamonds. The Congo has 70% of the world's coltan, and more than 30% of the world's diamond reserves., mostly in the form of small, industrial diamonds. The coltan is a major source of tantalum, which is used in the fabrication of electronic components in computers and mobile phones. In 2002, tin was discovered in the east of the country, but, to date, mining has been done on a small scale. Manono in Central DRC has a significant deposit of lithium and tin with tantalum and niobium and is being developed by an Australian company. Production is expected in 2023.

Smuggling of the conflict minerals, coltan and cassiterite (ores of tantalum and tin, respectively), has helped fuel the war in the Eastern Congo.

Today's larger mining companies are making changes and adhering to global demand for ESG ( Environmental, Social and Governance) and IRMA (Initiative for Responsible Mining Assurance). One such globally recognised certification is the 3T iTSCi, the only widely implemented and accepted mineral traceability and due diligence system in the region for the 3T minerals – Tin, Tantalum and Tungsten, an internationally recognised certification for responsible mining and traceability under the 2010 Dodd-Frank Act. Today four central African countries including the Democratic Republic of Congo (DRC) provides legitimate and ethical 3T minerals. ITSCI is the only industry initiative with standards 100% aligned with the OECD Guidance. Much has been done in the last 15 years, providing artisanal and small-scale miners a support network through iTSCi, to build the foundations and regulate the industry. At the end of 2019 ITSCI has seen to 2000 mines, employment of around 80,000 miners, and the supply of over 2000 tonnes of tin, tantalum and tungsten minerals per month; the initiative has come a long way in the last decade. A report had been done by Pact in 2015, detailing iTSCi's progress over the previous five years, it discusses the successes, the challenges ahead and the work yet to be done. Entitled "Unconflicted: Making Conflict-Free Mining a Reality in the DRC, Rwanda and Burundi."

Katanga Mining Limited, a London-based company, owns the Luilu Metallurgical Plant, which has a capacity of 175,000 tonnes of copper and 8,000 tonnes of cobalt per year, making it the largest cobalt refinery in the world. After a major rehabilitation program, the company restarted copper production in December 2007 and cobalt production in May 2008.

Much economic activity occurs in the informal sector and is not reflected in GDP data.

Ground transport in the Democratic Republic of Congo has always been difficult. The terrain and climate of the Congo Basin present serious barriers to road and rail construction, and the distances are enormous across this vast country. Furthermore, chronic economic mismanagement and internal conflict has led to serious under-investment over many years.

On the other hand, the Democratic Republic of Congo has thousands of kilometres of navigable waterways, and traditionally water transport has been the dominant means of moving around approximately two-thirds of the country.



Politics of the Democratic Republic of the Congo

Politics of the Democratic Republic of Congo take place in a framework of a republic in transition from a civil war to a semi-presidential republic.

On 18 and 19 December 2005, a successful nationwide referendum was carried out on a draft constitution, which set the stage for elections in 2006. The voting process, though technically difficult due to the lack of infrastructure, was facilitated and organized by the Congolese Independent Electoral Commission with support from the UN mission to the Congo (MONUC). Early UN reports indicate that the voting was for the most part peaceful, but spurred violence in many parts of the war-torn east and the Kasais.

In 2006, many Congolese complained that the constitution was a rather ambiguous document and were unaware of its contents. This is due in part to the high rates of illiteracy in the country. However, interim President Kabila urged Congolese to vote 'Yes', saying the constitution is the country's best hope for peace in the future. 25 million Congolese turned out for the two-day balloting. According to results released in January 2006, the constitution was approved by 84% of voters. The new constitution also aims to decentralize authority, dividing the vast nation into 25 semi-autonomous provinces, drawn along ethnic and cultural lines.

The country's first democratic elections in four decades were held on 30 July 2006.

From the day of the arguably ill-prepared independence of the Democratic Republic of the Congo, the tensions between the powerful leaders of the political elite, such as Joseph Kasa Vubu, Patrice Lumumba, Moise Tshombe, Joseph Mobutu and others, jeopardize the political stability of the new state. From Tshombe's secession of the Katanga, to the assassination of Lumumba, to the two coups d'état of Mobutu, the country has known periods of true nationwide peace, but virtually no period of genuine democratic rule.

The regime of President Mobutu Sese Seko lasted 32 years (1965–1997), during which all but the first seven years the country was named Zaire. His dictatorship operated as a one-party state, which saw most of the powers concentrated between President Mobutu, who was simultaneously the head of both the party and the state through the Popular Movement of the Revolution (MPR), and a series of essentially rubber-stamping institutions.

One particularity of the Regime was the claim to be thriving for an "authentic" system, different from Western or Soviet influences. This lasted roughly between the establishment of Zaire in 1971, and the official beginning of the transition towards democracy, on 24 April 1990. This was true at the regular people's level as everywhere else. People were ordered by law to drop their Western Christian names; the titles Mr. and Mrs. were abandoned for the male and female versions of the French word for "citizen"; Men were forbidden to wear suits, and women to wear pants. At the institutional level, many of the institutions also changed denominations, but the end result was a system that borrowed from both systems:


Every corporation, whether financial or union, as well as every division of the administration, was set up as branches of the party. CEOs, union leaders, and division directors were each sworn-in as section presidents of the party. Every aspect of life was regulated to some degree by the party, and the will of its founding-president, Mobutu Sese Seko.

Most of the petty aspects of the regime disappeared after 1990 with the beginning of the democratic transition. Democratization would prove to be fairly short-lived, as Mobutu's power plays dragged it in length until ultimately 1997, when forces led by Laurent Kabila eventually successfully toppled the regime, after a 9-month-long military campaign.

The government of former president Mobutu Sese Seko was toppled by a rebellion led by Laurent Kabila in May 1997, with the support of Rwanda and Uganda. They were later to turn against Kabila and backed a rebellion against him in August 1998. Troops from Zimbabwe, Angola, Namibia, Chad, and Sudan intervened to support the Kinshasa regime. A cease-fire was signed on 10 July 1999 by the DROC, Zimbabwe, Angola, Uganda, Namibia, Rwanda, and Congolese armed rebel groups, but fighting continued.

Under Laurent Kabila's regime, all executive, legislative, and military powers were first vested in the President, Laurent-Désiré Kabila. The judiciary was independent, with the president having the power to dismiss or appoint. The president was first head of a 26-member cabinet dominated by the Alliance of Democratic Forces for the Liberation of Congo (ADFL). Towards the end of the 90s, Laurent Kabila created and appointed a Transitional Parliament, with a seat in the buildings of the former Katanga Parliament, in the southern town of Lubumbashi, in a move to unite the country, and to legitimate his regime. Kabila was assassinated on 16 January 2001 and his son Joseph Kabila was named head of state ten days later.

The younger Kabila continued with his father's Transitional Parliament, but overhauled his entire cabinet, replacing it with a group of technocrats, with the stated aim of putting the country back on the track of development, and coming to a decisive end of the Second Congo War. In October 2002, the new president was successful in getting occupying Rwandan forces to withdraw from eastern Congo; two months later, an agreement was signed by all remaining warring parties to end the fighting and set up a Transition Government, the make-up of which would allow representation for all negotiating parties. Two founding documents emerged from this: The , and the Global and Inclusive Agreement, both of which describe and determine the make-up and organization of the Congolese institutions, until planned elections in July 2006, at which time the provisions of the new constitution, democratically approved by referendum in December 2005, will take full effect and that is how it happened.

Under the Global and All-Inclusive Agreement, signed on 17 December 2002, in Pretoria, there was to be one President and four Vice-Presidents, one from the government, one from the Rally for Congolese Democracy, one from the MLC, and one from civil society. The position of Vice-President expired after the 2006 elections.

After being for three years (2003–06) in the interregnum between two constitutions, the Democratic Republic of the Congo is now under the regime of the Constitution of the Third Republic. The constitution, adopted by referendum in 2005, and promulgated by President Joseph Kabila in February 2006, establishes a decentralized semi-presidential republic, with a separation of powers between the three branches of government - executive, legislative and judiciary, and a distribution of prerogatives between the central government and the provinces.

In September 2016, violent protests were met with brutal force by the police and Republican Guard soldiers. Opposition groups claim 80 dead, including the Students' Union leader. From Monday 19 September Kinshasa residents, as well as residents elsewhere in Congo, where mostly confined to their homes. Police arrested anyone remotely connected to the opposition as well as innocent onlookers. Government propaganda, on television, and actions of covert government groups in the streets, acted against opposition as well as foreigners. The president's mandate was due to end on 19 December 2016, but no plans were made to elect a replacement at that time and this caused further protests.

As of 8 August 2017 there are 54 political parties legally operating in the Congo.

On 15 December 2018 US State Department announced it had decided to evacuate its employees’ family members from Democratic Republic of Congo just before the Congolese elections to choose a successor to President Joseph Kabila.

On 30 December 2018 the presidential election to determine the successor to Kabila was held. On 10 January 2019, the electoral commission announced opposition candidate Félix Tshisekedi as the winner of the vote. He was officially sworn in as President on 24 January 2019. In the ceremony of taking of the office Félix Tshisekedi appointed Vital Kamerhe as his chief of staff. In June 2020, chief of staff Vital Kamerhe was found guilty of embezzling public funds and he was sentenced to 20 years in prison.

The political allies of former president Joseph Kabila, who stepped down in January 2019, maintained control of key ministries, the legislature, judiciary and security services. However, President Felix Tshisekedi succeeded to strengthen his hold on power. In a series of moves, he won over more legislators, gaining the support of almost 400 out of 500 members of the National Assembly. The pro-Kabila speakers of both houses of parliament were forced out. In April 2021, the new government was formed without the supporters of Kabila. President Felix Tshisekedi succeeded to oust the last remaining elements of his government who were loyal to former leader Joseph Kabila.

After the 2023 presidential election, Tshisekedi had a clear lead in his run for a second term. On 20 December 2023, official said that President Felix Tshisekedi had been re-elected with 73% of the vote. Nine opposition candidates signed a declaration rejecting the election and called for a rerun. In January, following the election, the major opposition candidate, Moise Katumbi was momentarily placed under house arrest but this was quickly rectified by the governor of Haut-Katanga province.

Since the July 2006 elections, the country is led by a semi-presidential, strongly-decentralized state. The executive at the central level, is divided between the President, and a Prime Minister appointed by him/her from the party having the majority of seats in Parlement. Should there be no clear majority, the President can appoint a "government former" that will then have the task to win the confidence of the National Assembly. The President appoints the government members (ministers) at the proposal of the Prime Minister. In coordination, the President and the government have the charge of the executive. The Prime minister and the government are responsible to the lower-house of Parliament, the National Assembly.

At the province level, the Provincial legislature (Provincial Assembly) elects a governor, and the governor, with his government of up to 10 ministers, is in charge of the provincial executive. Some domains of government power are of the exclusive provision of the Province, and some are held concurrently with the Central government. This is not a Federal state however, simply a decentralized one, as the majority of the domains of power are still vested in the Central government. The governor is responsible to the Provincial Assembly.

The semi-presidential system has been described by some as "conflictogenic" and "dictatogenic", as it ensures frictions, and a reduction of pace in government life, should the President and the Prime Minister be from different sides of the political arena. This was seen several times in France, a country that shares the semi-presidential model. It was also, arguably, in the first steps of the Congo into independence, the underlying cause of the crisis between Prime Minister Patrice Lumumba and President Joseph Kasa Vubu, who ultimately dismissed each other, in 1960.

In January 2015 the 2015 Congolese protests broke out in the country's capital following the release of a draft law that would extend the presidential term limits and allow Joseph Kabila to run again for office.

The Inter-Congolese dialogue, that set-up the transitional institutions, created a bicameral parliament, with a National Assembly and Senate, made up of appointed representatives of the parties to the dialogue. These parties included the preceding government, the rebel groups that were fighting against the government, with heavy Rwandan and Ugandan support, the internal opposition parties, and the Civil Society. At the beginning of the transition, and up until recently, the National Assembly is headed by the MLC with Speaker Hon. Olivier Kamitatu, while the Senate is headed by a representative of the Civil Society, namely the head of the Church of Christ in Congo, Mgr. Pierre Marini Bodho. Hon. Kamitatu has since left both the MLC and the Parliament to create his own party, and ally with current President Joseph Kabila. Since then, the position of Speaker is held by Hon. Thomas Luhaka, of the MLC.

Aside from the regular legislative duties, the Senate had the charge to draft a new constitution for the country. That constitution was adopted by referendum in December 2005, and decreed into law on 18 February 2006.

The Parliament of the third republic is also bicameral, with a National Assembly and a Senate. Members of the National Assembly, the lower - but the most powerful - house, are elected by direct suffrage. Senators are elected by the legislatures of the 26 provinces.

The Congolese Judicial Branch Consists of a Supreme Court, which handles federal crimes.

10 provinces (provinces, singular - province) and one city* (ville): Bandundu, Bas-Congo, Équateur, Kasai-Occidental, Kasai-Oriental, Katanga, Kinshasa*, Maniema, North Kivu, Orientale.

Each province is divided into districts and cities.

25 provinces (provinces, singular - province) and city* (ville): Bas-Uele | Équateur | Haut-Lomami | Haut-Katanga | Haut-Uele | Ituri | Kasaï | Kasaï oriental | Kongo central | Kwango | Kwilu | Lomami | Lualaba | Lulua | Mai-Ndombe | Maniema | Mongala | North Kivu | Nord-Ubangi | Sankuru | South Kivu | Sud-Ubangi | Tanganyika | Tshopo | Tshuapa | Kinshasa*

Each province is divided into territories and cities.

ACCT, ACP, AfDB, AU, CEEAC, CEPGL, East African Community, ECA, FAO, G-19, G-24, G-77, IAEA, IBRD, ICAO, ICC, ICRM, IDA, IFAD, IFC, IFRCS, IHO, ILO, IMF, UN, UNCTAD, UNESCO, UNHCR, UNIDO, UPU, WCO WFTU, WHO, WIPO, WMO, WToO, WTrO

Telecommunications in the Democratic Republic of the Congo

Telecommunications in the Democratic Republic of the Congo include radio, television, fixed and mobile telephones, and the Internet.


Radio is the dominant medium; a handful of stations, including state-run Radio-Télévision Nationale Congolaise (RTNC), broadcast across the country. The United Nations Mission (MONUSCO) and a Swiss-based NGO, Fondation Hirondelle, operate one of country's leading stations, Radio Okapi. The network employs mostly-Congolese staff and aims to bridge political divisions. Radio France Internationale (RFI), which is widely available on FM, is the most popular news station. The BBC broadcasts on FM in Kinshasa (92.7), Lubumbashi (92.0), Kisangani (92.0), Goma (93.3) and Bukavu (102.2).

Radio Okapi was first established in February 2002 by the United Nations Mission in the Democratic of Republic of Congo (MONUC). Radio Okapi provides news, music, and political information to all corners of the Democratic Republic of Congo. The major purpose behind Radio Okapi is to provide all DRC citizens with radio services regardless of political affiliation. The FM waves Radio Okapi provided were aimed to be free of hate speech. Most importantly, Radio Okapi caters to the various different ethnicities within the DRC. This is done through the broadcasting of content in 5 of major languages spoken in the DRC. These five languages are French, Lingala, Swahili, Tshiluba, and Kikongo.

Specific media platforms in the Democratic Republic of Congo have used its platforms for the dissemination of hate speech. Media in the DRC has propagated hatred and ethnic divisions by reinforcing nationalistic sentiments. Numerous media outlets are owned by presidential candidates and their supporters. This increases the probability that news will tend to favor the political base of these presidential candidates. These presidential candidates use their media platforms to attack political opponents which include ethnically charged hate speech. The result of such propaganda is evident in recent conflicts between ethnic groups, Hema and Lendu. The conflict was fueled by hate speech on media platforms. As a result, the conflict between these ethnic groups has transformed to one of the bloodiest conflicts in the Democratic Republic of Congo.

Peacekeeping agencies in the Democratic Republic of Congo observed the dangerous risk hate speech posed to communal welfare in the region. In order to combat such harmful speech, Non-governmental agencies (NGO's) began promoting large scale media campaigns. Campaigns consisted of several different radio programs aimed at reconciliation and peacekeeping. Research concluded that such programs showed measurable positive effects.




After the First Congo War (1996-1997) and Second Congo War (1998-2003), the nation transitioned to a renewed national unity under the rule of President Joseph Kabila and 4 vice presidents, all from former rebel and political opposition groups. The establishment of a democratic model required checks on corruption in public finance and natural resources, executive political parties, and hyperlocal militias and bandits. Peace agreements, in turn, did not end state violence, hence the need for absolute clarity to the public. The right to report on hostile resolutions was adopted in a 2002 resolution as a part of the eventual Inter-Congolese Dialogue. This accord declared that “independent, free, responsible and efficient media are a guarantee for public freedoms, the smooth running of democracy and social cohesion”, giving the voters direct insight into public figures, programs, and overall transparency. Article 27, 28, and Clause 29 established individual freedom of expression, moral press freedom, and the public right to information, respectively. During the time of continuing 2002 conflict, radios served as stages for peace songs and “come-home” messaging. Hosts had conversations with military and government officials, army members, and rebels to discuss the challenges of peace talks and demobilization. Censorship was lenient as long as radio personnel covered both sides.

Major exceptions to the right of free press imminently ensued. In 1996, censorship had begun to target Congo's artistic freedoms. Beyond broadcasts and news, the nation began to censor those who expressed political sentiments through music. The National Censorship Commission banned six songs that mentioned common opposition outcries relating to employment opportunities, civilian killings, corruption, and faltering human rights. If these songs are played on the radio, the artists may be fined up to $500 per song in accordance with a 1996 censorship decree. Freedom of the press was restricted for artists offending political elites or speaking against Congolese leaders and parties. For those using telecommunications as an outlet, interference was backed by such legislation. Open discussion about political corruption or unmentioned events, such as riots or uprisings against the ruling party, are avoided in news media but continuously active on pavement radio.

The Congolese government performed a series of intentional internet shutdowns. The first was conducted in December 2011 and lasted approximately 25 days. During the 25 days, Short Message Service otherwise known as SMS was the only one affected by the shutdown. According to an article by CIPESA, "One of the reasons cited by the government for blocking communication was to prevent the spread of fake results over the internet before the electoral commission announced official results"

Unlike the first shutdown the second intentional shutdown had a broader range of impact.The second intentional shutdown occurred in January 2015. The Congolese government directed telecommunication companies within the country to halt all its services. Not only was SMS affected, but the entire internet itself. This action by the government came on the eve of political protest on a proposed electoral bill.

The most recent government shutdown occurred on December 19, 2016. This was an important date as President Joseph Kabila was supposed to step down as head of state. In order to quell, political upheaval the Congolese government ordered telecom operators to block social media in the country.

In September 2016, the government cut the signals of the Radio France Internationale (RFI) and United Nations Radio Okapi (UNRO). Later, the general and program director of the Radio-Télévision Manika de Kolwezi was arrested after intentionally broadcasting a phone interview with Katumbi, the opposition leader. The censorship of human freedoms of expression to information was condemned by the Congo's United Nations on Human Rights. Kabila was given until December 19, 2016, to step down. If he decided not to, precautionary measures were set to counter organization and public protests. The government ordered a temporary blocking of images, videos, and voiceovers on social networking sites such as Facebook, Twitter, Skype, and WhatsApp right after Kabila was to step down. Digital media was the central counter to government oversight and regulation seen in other telecommunication outlets. Media was used in lieu of radio broadcasting to avoid self-censorship, financial restraints that may affect networks, or news station shutdowns. Removing the intermediary for independent journalism and coverage prevented communication among those who wanted to organize and speak out against Kabila. Black-outs were utilized to prevent anticipated politically motivated violence. Additionally, the then Telecommunications Minister Thomas Luhaka was “not informed” of such interference by the government.



Transport in the Democratic Republic of the Congo

Ground transport in the Democratic Republic of the Congo (DRC) has always been difficult. The terrain and climate of the Congo Basin present serious barriers to road and rail construction, and the distances are enormous across this vast country. Furthermore, chronic economic mismanagement and internal conflict has led to serious under-investment over many years.

On the other hand, the DRC has thousands of kilometres of navigable waterways, and traditionally water transport has been the dominant means of moving around approximately two-thirds of the country.

As an illustration of transport difficulties in the DRC, even before wars damaged the infrastructure, the so-called "national" route, used to get supplies to Bukavu from the seaport of Matadi, consisted of the following:
In other words, goods had to be loaded and unloaded eight times and the total journey would take many months.

Many of the routes listed below are in poor condition and may be operating at only a fraction of their original capacity (if at all), despite recent attempts to make improvements. Up to 2006 the United Nations Joint Logistics Centre (UNJLC) had an operation in Congo to support humanitarian relief agencies working there, and its bulletins and maps about the transport situation are archived on ReliefWeb.

The First and Second Congo Wars saw great destruction of transport infrastructure from which the country has not yet recovered. Many vehicles were destroyed or commandeered by militias, especially in the north and east of the country, and the fuel supply system was also badly affected. Consequently, outside of Kinshasa, Matadi and Lubumbashi, private and commercial road transport is almost non-existent and traffic is scarce even where roads are in good condition. The few vehicles in use outside these cities are run by the United Nations, aid agencies, the DRC government, and a few larger companies such as those in the mining and energy sectors. High-resolution satellite photos on the Internet show large cities such as Bukavu, Butembo and Kikwit virtually devoid of traffic, compared to similar photos of towns in neighbouring countries.

Air transport is the only effective means of moving between many places within the country. The Congolese government, the United Nations, aid organisations and large companies use air rather than ground transport to move personnel and freight. The UN operates a large fleet of aircraft and helicopters, and compared to other African countries the DRC has a large number of small domestic airlines and air charter companies. The transport (and smuggling) of minerals with a high value for weight is also carried out by air, and in the east, some stretches of paved road isolated by destroyed bridges or impassable sections have been turned into airstrips.

For the ordinary citizen though, especially in rural areas, often the only options are to cycle, walk or go by dugout canoe.

Some parts of the DRC are more accessible from neighbouring countries than from Kinshasa. For example, Bukavu itself and Goma and other north-eastern towns are linked by paved road from the DRC border to the Kenyan port of Mombasa, and most goods for these cities have been brought via this route in recent years. Similarly, Lubumbashi and the rest of Katanga Province is linked to Zambia, through which the paved highway and rail networks of Southern Africa can be accessed. Such links through neighbouring countries are generally more important for the east and south-east of the country, and are more heavily used, than surface links to the capital.

In 2007 China agreed to lend the DRC US$5bn for two major transport infrastructure projects to link mineral-rich Katanga, specifically Lubumbashi, by rail to an ocean port (Matadi) and by road to the Kisangani river port, and to improve its links to the transport network of Southern Africa in Zambia. The two projects would also link the major parts of the country not served by water transport, and the main centres of the economy. Loan repayments will be from concessions for raw materials which China desperately needs: copper, cobalt, gold and nickel, as well as by toll revenues from the road and railway. In the face of reluctance by the international business community to invest in DRC, this represents a revitalisation of DRC's infrastructure much needed by its government.

The China Railway Seventh Group Co. Ltd will be in charge of the contract, under signed by the China Railway Engineering Corporation, with construction to be started from June 2008.

The Democratic Republic of the Congo has fewer all-weather paved highways than any country of its population and size in Africa — a total of 2250 km, of which only 1226 km is in good condition (see below). To put this in perspective, the road distance across the country in any direction is more than 2500 km (e.g. Matadi to Lubumbashi, 2700 km by road). The figure of 2250 km converts to 35 km of paved road per 1,000,000 of population. Comparative figures for Zambia and Botswana are 721 km and 3427 km respectively.

The road network is theoretically divided into four categories (national roads, priority regional roads, secondary regional roads and local roads), however, the United Nations Joint Logistics Centre (UNJLC) reports that this classification is of little practical use because some roads simply do not exist. For example, National Road 9 is not operational and cannot be detected by remote sensing methods.

The two principal highways are:

The total road network in 2005, according to the UNJLC, consisted of:


The UNJLC also points out that the pre-Second Congo War network no longer exists, and is dependent upon 20,000 bridges and 325 ferries, most of which are in need of repair or replacement. In contrast, a Democratic Republic of the Congo government document shows that, also in 2005, the network of main highways in good condition was as follows:

The 2000 Michelin "Motoring and Tourist Map 955 of Southern and Central Africa", which categorizes roads as "surfaced", "improved" (generally unsurfaced but with gravel added and graded), "partially improved" and "earth roads" and "tracks" shows that there were 2694 km of paved highway in 2000. These figures indicate that, compared to the more recent figures above, there has been a deterioration this decade, rather than improvement.

Three routes in the Trans-African Highway network pass through DR Congo:

The DRC has more navigable rivers and moves more passengers and goods by boat and ferry than any other country in Africa. Kinshasa, with 7 km of river frontage occupied by wharfs and jetties, is the largest inland waterways port on the continent. However, much of the infrastructure — vessels and port handling facilities — has, like the railways, suffered from poor maintenance and internal conflict.

The total length of waterways is estimated at 16,238 km including the Congo River, its tributaries, and unconnected lakes.

The 1000-kilometre Kinshasa-Kisangani route on the Congo River is the longest and best-known. It is operated by river tugs pushing several barges lashed together, and for the hundreds of passengers and traders these function like small floating towns. Rather than mooring at riverside communities along the route, traders come out by canoe and small boat alongside the river barges and transfer goods on the move.

Most waterway routes do not operate to regular schedules. It is common for an operator to moor a barge at a riverside town and collect freight and passengers over a period of weeks before hiring a river tug to tow or push the barge to its destination.


The middle Congo River and its tributaries from the east are the principal domestic waterways in the DRC. The two principal river routes are:
See the diagrammatic transport map above for other river waterways.

The most-used domestic lake waterways are:

Most large Congo river ferry boats were destroyed during the civil war. Only smaller boats are running and they are irregular.





petroleum products 390 km

1 petroleum tanker

Due to the lack of roads, operating railroads and ferry transportation many people traveling around the country fly on aircraft. As of 2016 the country does not have an international passenger airline and relies on foreign-based airlines for international connections. Congo Airways provides domestic flights and are based at Kinshasa's N'djili Airport which serves as the country's main international airport. Lubumbashi International Airport in the country's south-east is also serviced by several international airlines.

"total:"
24
"over 3,047 m:"
4
"2,438 to 3,047 m:"
2
"1,524 to 2,437 m:"
16
"914 to 1,523 m:"
2 (2002 est.)

"total:"
205
"1,524 to 2,437 m:"
19
"914 to 1,523 m:"
95
"under 914 m:"
91 (2002 est.)

All air carriers certified by the Democratic Republic of the Congo have been banned from operating at airports in the European Community by the European Commission because of inadequate safety standards.





The Democratic Republic of the Congo has a rocketry program called Troposphere.



Armed Forces of the Democratic Republic of the Congo

The Armed Forces of the Democratic Republic of the Congo ( [FARDC]) is the state organisation responsible for defending the Democratic Republic of the Congo. The FARDC was rebuilt patchily as part of the peace process which followed the end of the Second Congo War in July 2003.

The majority of FARDC members are land forces, but it also has a small air force and an even smaller navy. In 2010–2011 the three services may have numbered between 144,000 and 159,000 personnel. In addition, there is a presidential force called the Republican Guard, but it and the Congolese National Police (PNC) are not part of the Armed Forces.

The government in the capital city Kinshasa, the United Nations, the European Union, and bilateral partners which include Angola, South Africa, and Belgium are attempting to create a viable force with the ability to provide the Democratic Republic of Congo with stability and security. However, this process is being hampered by corruption, inadequate donor coordination, and competition between donors. The various military units now grouped under the FARDC banner are some of the most unstable in Africa after years of war and underfunding.

To assist the new government, since February 2000 the United Nations has had the United Nations Mission in the Democratic Republic of Congo (now called MONUSCO), which currently has a strength of over 16,000 peacekeepers in the country. Its principal tasks are to provide security in key areas, such as the South Kivu and North Kivu in the east, and to assist the government in reconstruction. Foreign rebel groups are also in the Congo, as they have been for most of the last half-century. The most important is the Democratic Forces for the Liberation of Rwanda (FDLR), against which Laurent Nkunda's troops were fighting, but other smaller groups such as the anti-Ugandan Lord's Resistance Army are also present.

The legal standing of the FARDC was laid down in the Transitional Constitution, articles 118 and 188. This was then superseded by provisions in the 2006 Constitution, articles 187 to 192. Law 04/023 of 12 November 2004 establishes the General Organisation of Defence and the Armed Forces. In mid-2010, the Congolese Parliament was debating a new defence law, provisionally designated Organic Law 130.

The first organised Congolese troops, known as the , were created in 1888 when King Leopold II of Belgium, who held the Congo Free State as his private property, ordered his Secretary of the Interior to create military and police forces for the state. In 1908, under international pressure, Leopold ceded administration of the colony to the government of Belgium as the Belgian Congo. It remained under the command of a Belgian officer corps through to the independence of the colony in 1960. Throughout 1916 and 1917, the "Force Publique" saw combat in Cameroun, and successfully invaded and conquered areas of German East Africa, notably present day Rwanda, during World War I. Elements of the "Force Publique" were also used to form Belgian colonial units that fought in the East African Campaign during World War II.

At independence on 30 June 1960, the army suffered from a dramatic deficit of trained leaders, particularly in the officer corps. This was because the "Force Publique" had always only been officered by Belgian or other expatriate whites. The Belgian Government made no effort to train Congolese commissioned officers until the very end of the colonial period, and in 1958, only 23 African cadets had been admitted even to the military secondary school. The highest rank available to Congolese was adjutant, which only four soldiers achieved before independence. Though 14 Congolese cadets were enrolled in the Royal Military Academy in Brussels in May, they were not scheduled to graduate as second lieutenants until 1963. Ill-advised actions by Belgian officers led to an enlisted ranks' rebellion on 5 July 1960, which helped spark the Congo Crisis. Lieutenant General Émile Janssens, the "Force Publique" commander, wrote during a meeting of soldiers that 'Before independence=After Independence', pouring cold water on the soldiers' desires for an immediate raise in their status.

Historian Louis-François Vanderstraeten says that on the morning of 8 July 1960, following a night during which all control had been lost over the soldiers, numerous ministers arrived at Camp Leopold with the aim of calming the situation. Both Prime Minister Patrice Lumumba and President Joseph Kasa-Vubu eventually arrived, and the soldiers listened to Kasa-Vubu "religiously." After his speech, Kasa-Vubu and the ministers present retired into the camp canteen to hear a delegation from the soldiers. Vanderstraeten says that, according to Joseph Ileo, their demands ("revendications") included the following:
The "laborious" discussions which then followed were later retrospectively given the label of an "extraordinary ministerial council." Gérard-Libois writes that "...the special meeting of the council of ministers took steps for the immediate Africanisation of the officer corps and named Victor Lundula, who was born in Kasai and was burgomaster of Jadotville, as Commander-in-Chief of the ANC; Colonel Joseph-Désiré Mobutu as chief of staff; and the Belgian, Colonel Henniquiau, as chief advisor to the ANC". Thus General Janssens was dismissed. Both Lundula and Mobutu were former sergeants of the "Force Publique".

On 8–9 July 1960, the soldiers were invited to appoint black officers, and "command of the army passed securely into the hands of former sergeants," as the soldiers in general chose the most-educated and highest-ranked Congolese army soldiers as their new officers. Most of the Belgian officers were retained as advisors to the new Congolese hierarchy, and calm returned to the two main garrisons at Leopoldville and Thysville. The "Force Publique" was renamed the "Armée nationale congolaise" (ANC), or Congolese National Armed Forces. However, in Katanga Belgian officers resisted the Africanisation of the army.

There was a "Force Publique" mutiny at Camp Massart, in Elizabethville, on 9 July 1960; five or seven Europeans were killed. The army revolt and resulting rumours caused severe panic across the country, and Belgium despatched troops and the naval Task Group 218.2 to protect its citizens. Belgian troops intervened in Elisabethville and Luluabourg (10 July), Matadi (11 July), Leopoldville (13 July) and elsewhere. There were immediate suspicions that Belgium planned to re-seize their former colony whilst doing so. Large numbers of Belgian colonists fled the country. At the same time, on 11 July, Moise Tshombe declared the independence of Katanga Province in the south-east, closely backed by remaining Belgian administrators and soldiers.
On 14 July 1960, in response to requests by Prime Minister Lumumba, the UN Security Council adopted United Nations Security Council Resolution 143. This called upon Belgium to remove its troops and for the UN to provide military assistance to the Congolese forces to allow them "to meet fully their tasks". Lumumba demanded that Belgium remove its troops immediately, threatening to seek help from the Soviet Union if they did not leave within two days. The UN reacted quickly and established the United Nations Operation in the Congo (ONUC). The first UN troops arrived the next day but there was instant disagreement between Lumumba and the UN over the new force's mandate. Because the Congolese army had been in disarray since the mutiny, Lumumba wanted to use the UN troops to subdue Katanga by force. Lumumba became extremely frustrated with the UN's unwillingness to use force against Tshombe and his secession. He cancelled a scheduled meeting with Secretary General Dag Hammarskjöld on 14 August and wrote a series of angry letters instead. To Hammarskjöld, the secession of Katanga was an internal Congolese matter and the UN was forbidden to intervene by Article 2 of the United Nations Charter. Disagreements over what the UN force could and could not do continued throughout its deployment.

A total of 3,500 troops for ONUC had arrived in the Congo by 20 July 1960. The first contingent of Belgian forces had left Leopoldville on 16 July upon the arrival of the United Nations troops. Following assurances that contingents of the Force would arrive in sufficient numbers, the Belgian authorities agreed to withdraw all their forces from the Leopoldville area by 23 July. The last Belgian troops left the country by 23 July, as United Nations forces continued to deploy throughout the Congo. The build of ONUC continued, its strength increasing to over 8,000 by 25 July and to over 11,000 by 31 July 1960. A basic agreement between the United Nations and the Congolese Government on the operation of the Force was agreed by 27 July. On 9 August, Albert Kalonji proclaimed the independence of South Kasai.
During the crucial period of July–August 1960, Mobutu built up "his" national army by channeling foreign aid to units loyal to him, by exiling unreliable units to remote areas, and by absorbing or dispersing rival armies. He tied individual officers to him by controlling their promotion and the flow of money for payrolls. Researchers working from the 1990s have concluded that money was directly funnelled to the army by the U.S. Central Intelligence Agency, the UN, and Belgium. Despite this, by September 1960, following the four-way division of the country, there were four separate armed forces: Mobotu's ANC itself, numbering about 12,000, the South Kasai Constabulary loyal to Albert Kalonji (3,000 or less), the Katanga Gendarmerie which were part of Moise Tshombe's regime (totalling about 10,000), and the Stanleyville dissident ANC loyal to Antoine Gizenga (numbering about 8,000).

In August 1960, due to the rejection of requests for UN assistance to suppress the South Kasai and Katanga revolts, Lumumba's government decided to request Soviet help. De Witte writes that "Leopoldville asked the Soviet Union for planes, lorries, arms, and equipment...Shortly afterwards, on 22 or 23 August, about 1,000 soldiers left for Kasai." On 26–27 August, the ANC seized Bakwanga, Albert Kalonji's capital in South Kasai, without serious resistance and, according to de Witte, "in the next two days it temporarily put an end to the secession of Kasai."

At this point, the Library of Congress Country Study for the Congo says, that on 5 September 1960:
"Kasavubu also appointed Mobutu as head of the ANC. Joseph Ileo was chosen as the new prime minister and began trying to form a new government. Lumumba and his cabinet responded by accusing Kasa-Vubu of high treason and voted to dismiss him. Parliament refused to confirm the dismissal of either Lumumba or Kasavubu and sought to bring about a reconciliation between them. After a week's deadlock, Mobutu announced on 14 September that he was assuming power until 31 December 1960, in order to "neutralize" both Kasavubu and Lumumba." Mobutu formed the College of Commissioners-General, a technocratic government of university graduates.

In early January 1961, ANC units loyal to Lumumba invaded northern Katanga to support a revolt of Baluba tribesmen against Tshombe's secessionist regime. On 23 January 1961, Kasa-Vubu promoted Mobutu to major-general; De Witte argues that this was a political move, "aimed to strengthen the army, the president's sole support, and Mobutu's position within the army."

United Nations Security Council Resolution 161 of 21 February 1961, called for the withdrawal of Belgian officers from command positions in the ANC, and the training of new Congolese officers with UN help. ONUC made a number of attempts to retrain the ANC from August 1960 to June 1963, often been set back by political changes. By March 1963 however, after the visit of Colonel Michael Greene of the United States Army, and the resulting "Greene Plan", the pattern of bilaterally agreed military assistance to various Congolese military components, instead of a single unified effort, was already taking shape.
In early 1964, a new crisis broke out as Congolese rebels calling themselves "Simba" (Swahili for "Lion") rebelled against the government. They were led by Pierre Mulele, Gaston Soumialot and Christophe Gbenye who were former members of Gizenga's Parti Solidaire Africain (PSA). The rebellion affected Kivu and Eastern (Orientale) provinces. By August they had captured Stanleyville and set up a rebel government there. As the rebel movement spread, discipline became more difficult to maintain, and acts of violence and terror increased. Thousands of Congolese were executed, including government officials, political leaders of opposition parties, provincial and local police, school teachers, and others believed to have been Westernised. Many of the executions were carried out with extreme cruelty, in front of a monument to Lumumba in Stanleyville. Tshombe decided to use foreign mercenaries as well as the ANC to suppress the rebellion. Mike Hoare was employed to create the English-speaking 5 Commando at Kamina, with the assistance of a Belgian officer, Colonel Frederic Vanderwalle, while 6 Commando (Congo) was French-speaking and originally under the command of a Belgian Army colonel, Lamouline. By August 1964, the mercenaries, with the assistance of other ANC troops, were making headway against the Simba rebellion. Fearing defeat, the rebels started taking hostages of the local white population in areas under their control. These hostages were rescued in Belgian airdrops (Operations Dragon Rouge and Dragon Noir) over Stanleyville and Paulis airlifted by U.S. aircraft. The operation coincided with the arrival of mercenary units (seemingly including the hurriedly formed 5th Mechanised Brigade) at Stanleyville which was quickly captured. It took until the end of the year to completely put down the remaining areas of rebellion during "Operation South".

After five years of turbulence, in 1965 Mobutu used his position as ANC Chief of Staff to seize power in the 1965 Democratic Republic of the Congo coup d'état. Although Mobutu succeeded in taking power, his position was soon threatened by the Stanleyville mutinies, also known as the Mercenaries' Mutinies, which were eventually suppressed.

As a general rule, since that time, the armed forces have not intervened in politics as a body, rather being tossed and turned as ambitious men have shaken the country. In reality, the larger problem has been the misuse and sometimes abuse of the military and police by political and ethnic leaders.

On 16 May 1968 a parachute brigade of two regiments (each of three battalions) was formed which eventually was to grow in size to a full division.

The country was renamed Zaire in 1971 and the army was consequently designated the (FAZ). In 1971 the army's force consisted of the 1st Groupement at Kananga, with one guard battalion, two infantry battalions, and a gendarmerie battalion attached, and the 2nd Groupement (Kinshasa), the 3rd Groupement (Kisangani), the 4th Groupement (Lubumbashi), the 5th Groupement (Bukavu), the 6th Groupement (Mbandaka), and the 7th Groupement (Boma). Each was about the size of a brigade, and commanded by aging generals who have had no military training, and often not much positive experience, since they were NCOs in the Belgian Force Publique.' By the late 1970s the number of groupements reached nine, one per administrative region. The parachute division (Division des Troupes Aéroportées Renforcées de Choc, DITRAC) operated semi-independently from the rest of the army.

In July 1972 a number of the aging generals commanding the "groupements" were retired. Général d'armée Louis Bobozo, and Generaux de Corps d'Armée Nyamaseko Mata Bokongo, Nzoigba Yeu Ngoli, Muke Massaku, Ingila Grima, Itambo Kambala Wa Mukina, Tshinyama Mpemba, and General de Division Yossa Yi Ayira, the last having been commander of the Kamina base, were all retired on 25 July 1972. Taking over as military commander-in-chief, now titled Captain General, was newly promoted General de Division Bumba Moaso, former commander of the parachute division.

A large number of countries supported the FAZ in the early 1970s. Three hundred Belgian personnel were serving as staff officers and advisors throughout the Ministry of Defence, Italians were supporting the Air Force, Americans were assisting with transport and communications, Israelis with airborne forces training, and there were British advisors with the engineers. In 1972 the state-sponsored political organisation, the Mouvement Populaire de la Révolution (MPR), resolved at a party congress to form activist cells in each military unit. The decision caused consternation among the officer corps, as the army had been apolitical (and even anti-political) since before independence.

On 11 June 1975 several military officers were arrested in what became known as the "coup monté et manqué." Amongst those arrested were Générals Daniel Katsuva wa Katsuvira, Land Forces Chief of Staff, Utshudi Wembolenga, Commandant of the 2nd Military Region at Kalemie; Fallu Sumbu, Military Attaché of Zaïre in Washington, Colonel Mudiayi wa Mudiayi, the military attaché of Zaïre in Paris, the military attache in Brussels, a paracommando battalion commander, and several others. The regime alleged these officers and others (including Mobutu's "secrétaire particulier") had plotted the assassination of Mobutu, high treason, and disclosure of military secrets, among other offences. The alleged coup was investigated by a revolutionary commission headed by Boyenge Mosambay Singa, at that time head of the Gendarmerie. Writing in 1988, Michael Schatzberg said the full details of the coup had yet to emerge. Meitho, writing many years later, says the officers were accused of trying to raise Mobutu's "secrétaire particulier", Colonel Omba Pene Djunga, from Kasai, to power.
In late 1975, Mobutu, in a bid to install a pro-Kinshasa government in Angola and thwart the Marxist Popular Movement for the Liberation of Angola (MPLA)'s drive for power, deployed FAZ armoured cars, paratroopers, and three infantry battalions to Angola in support of the National Liberation Front of Angola (FNLA).
On 10 November 1975, an anti-Communist force made up of 1,500 FNLA fighters, 100 Portuguese Angolan soldiers, and two FAZ battalions passed near the city of Quifangondo, only north of Luanda, at dawn on 10 November. The force, supported by South African aircraft and three 140 mm artillery pieces, marched in a single line along the Bengo River to face an 800-strong Cuban force across the river. Thus the Battle of Quifangondo began. The Cubans and MPLA fighters bombarded the FNLA with mortar and 122 mm rockets, destroying most of the FNLA's armoured cars and six Jeeps carrying antitank rockets in the first hour of fighting.

Mobutu's support for the FNLA policy backfired when the MPLA won in Angola. The MPLA, then, acting ostensibly at least as the Front for Congolese National Liberation, occupied Zaire's southeastern Katanga Province, then known as Shaba, in March 1977, facing little resistance from the FAZ. This invasion is sometimes known as Shaba I. Mobutu had to request assistance, which was provided by Morocco in the form of regular troops who routed the MPLA and their Cuban advisors out of Katanga. Also important were Egyptian pilots who flew Zaire's Mirage 5 combat aircraft. The humiliation of this episode led to civil unrest in Zaire in early 1978, which the FAZ had to put down.
The poor performance of Zaire's military during Shaba I gave evidence of chronic weaknesses. One problem was that some of the Zairian soldiers in the area had not received pay for extended periods. Senior officers often kept the money intended for the soldiers, typifying a generally disreputable and inept senior leadership in the FAZ. As a result, many soldiers simply deserted rather than fight. Others stayed with their units but were ineffective. During the months following the Shaba invasion, Mobutu sought solutions to the military problems that had contributed to the army's dismal performance. He implemented sweeping reforms of the command structure, including wholesale firings of high-ranking officers. He merged the military general staff with his own presidential staff and appointed himself chief of staff again, in addition to the positions of minister of defence and supreme commander that he already held. He also redeployed his forces throughout the country instead of keeping them close to Kinshasa, as had previously been the case. The Kamanyola Division, at the time considered the army's best formation, and considered the president's own, was assigned permanently to Shaba. In addition to these changes, the army's strength was reduced by 25 percent. Also, Zaire's allies provided a large influx of military equipment, and Belgian, French, and American advisers assisted in rebuilding and retraining the force.

Despite these improvements, a second invasion by the former Katangan gendarmerie, known as Shaba II in May–June 1978, was only dispersed with the despatch of the French 2nd Foreign Parachute Regiment and a battalion of the Belgian Paracommando Regiment. Kamanyola Division units collapsed almost immediately. French units fought the Battle of Kolwezi to recapture the town from the FLNC. The U.S. provided logistical assistance.

In July 1975, according to the IISS Military Balance, the FAZ included 14 infantry battalions, seven "Guard" battalions, and seven other infantry battalions variously designated as "parachute" (or possibly "commando"; probably the units of the parachute brigade originally formed in 1968). There were also an armoured car regiment and a mechanised infantry battalion. Organisationally, the army was made up of the parachute division and the seven "groupements." In addition to these units, a tank battalion was reported to have formed by 1979.

In January 1979 "General de Division" Mosambaye Singa Boyenge was named as both military region commander and Region Commissioner for Shaba.

In 1984, a militarised police force, the Civil Guard, was formed. It was eventually commanded by Général d'armée Kpama Baramoto Kata.

Thomas Turner wrote in the mid-1990s that "[m]ajor acts of violence, such as the killings that followed the "Kasongo uprising" in Bandundu Region in 1978, the killings of diamond miners in Kasai-Oriental Region in 1979, and, more recently, the massacre of students in Lubumbashi in 1990, continued to intimidate the population."

The authors of the Library of Congress Country Study on Zaire commented in 1992–93 that: 
"The maintenance status of equipment in the inventory has traditionally varied, depending on a unit's priority and the presence or absence of foreign advisers and technicians. A considerable portion of military equipment is not operational, primarily as a result of shortages of spare parts, poor maintenance, and theft. For example, the tanks of the 1st Armoured Brigade often have a nonoperational rate approaching 70 to 80 percent. After a visit by a Chinese technical team in 1985, most of the tanks operated, but such an improved status generally has not lasted long beyond the departure of the visiting team. Several factors complicate maintenance in Zairian units. Maintenance personnel often lack the training necessary to maintain modern military equipment. Moreover, the wide variety of military equipment and the staggering array of spare parts necessary to maintain it not only clog the logistic network but also are expensive.

The most important factor that negatively affects maintenance is the low and irregular pay that soldiers receive, resulting in the theft and sale of spare parts and even basic equipment to supplement their meager salaries. When not stealing spare parts and equipment, maintenance personnel often spend the better part of their duty day looking for other ways to profit. American maintenance teams working in Zaire found that providing a free lunch to the work force was a good, sometimes the only, technique to motivate personnel to work at least half of the duty day.

The army's logistics corps [was tasked].. to provide logistic support and conduct direct, indirect, and depot-level maintenance for the FAZ. But because of Zaire's lack of emphasis on maintenance and logistics, a lack of funding, and inadequate training, the corps is understaffed, underequipped, and generally unable to accomplish its mission. It is organised into three battalions assigned to Mbandaka, Kisangani, and Kamina, but only the battalion at Kamina is adequately staffed; the others are little more than skeleton" units.

The poor state of discipline of the Congolese forces became apparent again in 1990. Foreign military assistance to Zaire ceased following the end of the Cold War and Mobutu deliberately allowed the military's condition to deteriorate so that it did not threaten his hold on power. Protesting low wages and lack of pay, paratroopers began looting Kinshasa in September 1991 and were only stopped after intervention by French ('Operation Baumier') and Belgian ('Operation Blue Beam') forces.

In 1993, according to the Library of Congress Country Studies, the 25,000-member FAZ ground forces consisted of one infantry division (with three infantry brigades); one airborne brigade (with three parachute battalions and one support battalion); one special forces (commando/counterinsurgency) brigade; the Special Presidential Division; one independent armoured brigade; and two independent infantry brigades (each with three infantry battalions, one support battalion). These units were deployed throughout the country, with the main concentrations in Shaba Region (approximately half the force). The Kamanyola Division, consisting of three infantry brigades operated generally in western Shaba Region; the 21st Infantry Brigade was located in Lubumbashi; the 13th Infantry Brigade was deployed throughout eastern Shaba; and at least one battalion of the 31st Airborne Brigade stayed at Kamina. The other main concentration of forces was in and around Kinshasa: the 31st Airborne Brigade was deployed at N'djili Airport on the outskirts of the capital; the Special Presidential Division (DSP) resided adjacent to the presidential compound; and the 1st Armoured Brigade was at Mbanza-Ngungu (in Bas-Congo, approximately southwest of Kinshasa). Finally the 41st Commando Brigade was at Kisangani.

This superficially impressive list of units overstates the actual capability of the armed forces at the time. Apart from privileged formations such as the Presidential Division and the 31st Airborne Brigade, most units were poorly trained, divided and so badly paid that they regularly resorted to looting. What operational abilities the armed forces had were gradually destroyed by politicisation of the forces, tribalisation, and division of the forces, included purges of suspectedly disloyal groups, intended to allow Mobutu to divide and rule. All this occurred against the background of increasing deterioration of state structures under the kleptocratic Mobutu regime.

Much of the origins of the recent conflict in what is now the Democratic Republic of the Congo stems from the turmoil following the Rwandan genocide of 1994, which then led to the Great Lakes refugee crisis. Within the largest refugee camps, beginning in Goma in Nord-Kivu, were Rwandan Hutu fighters, who were eventually organised into the Rassemblement Démocratique pour le Rwanda, who launched repeated attacks into Rwanda. Rwanda eventually backed Laurent-Désiré Kabila and his quickly-organised Alliance of Democratic Forces for the Liberation of Congo (AFDL) in invading Zaire, aiming to stop the attacks on Rwanda in the process of toppling Mobutu's government. When the militias rebelled, backed by Rwanda, the FAZ, weakened as is noted above, proved incapable of mastering the situation and preventing the overthrow of Mobutu in 1997.

The Battle of Kinsangani took place in March 1997 during this war. The AFDL rebels, created by the Rwandan Patriotic Front, took the city defended by the Zairian Armed Forces (FAZ), loyal to President Mobutu. Before the battle itself, the air force, Serbian mercenaries and Rwandan Hutu militiamen were not enough to make up for the FAZ's lack of fighting spirit. After the war, elements of the Mobutu-loyal FAZ managed to retreat into northern Congo, and from there into Sudan while attempting to escape the AFDL. Allying themselves with the Sudanese government which was fighting its own civil war at the time, these FAZ troops were destroyed by the Sudan People's Liberation Army during Operation Thunderbolt near Yei in March 1997.

When Kabila took power in 1997, the country was renamed the Democratic Republic of the Congo and so the name of the national army changed once again, to the "Forces armées congolaises" (FAC). Tanzania sent six hundred military advisors to train Kabila's new army in May 1997. (Prunier says that the instructors were still at the Kitona base when the Second Congo War broke out, and had to be quickly returned to Tanzania. Prunier said "South African aircraft carried out the evacuation after a personal conversation between President Mkapa and not-yet-president Thabo Mbeki. Command over the armed forces in the first few months of Kabila's rule was vague. Gérard Prunier writes that "there was no minister of defence, no known chief of staff, and no ranks; all officers were Cuban-style 'commanders' called 'Ignace', 'Bosco', Jonathan', or 'James', who occupied connecting suites at the Intercontinental Hotel and had presidential list cell-phone numbers. None spoke French or Lingala, but all spoke Kinyarwanda, Swahili, and, quite often, English." On being asked by Belgian journalist Colette Braeckman what was the actual army command structure apart from himself, Kabila answered 'We are not going to expose ourselves and risk being destroyed by showing ourselves openly... . We are careful so that the true masters of the army are not known. It is strategic. Please, let us drop the matter.' Kabila's new "Forces armées congolaises" were riven with internal tensions. The new FAC had Banyamulenge fighters from South Kivu, "kadogo" child soldiers from various eastern tribes, such as Thierry Nindaga, Safari Rwekoze, etc... [the mostly] Lunda Katangese Tigers of the former FNLC, and former FAZ personnel. Mixing these disparate and formerly warring elements together led to mutiny. On 23 February 1998, a mostly Banyamulenge unit mutiniued at Bukavu after its officers tried to disperse the soldiers into different units spread all around the Congo. By mid-1998, formations on the outbreak of the Second Congo War included the Tanzanian-supported 50th Brigade, headquartered at Camp Kokolo in Kinshasa, and the 10th Brigade – one of the best and largest units in the army – stationed in Goma, as well as the 12th Brigade in Bukavu. The declaration of the 10th Brigade's commander, former DSP officer Jean-Pierre Ondekane, on 2 August 1998 that he no longer recognised Kabila as the state's president was one of the factors in the beginning of the Second Congo War.

According to "Jane's", the FAC performed poorly throughout the Second Congo War and "demonstrated little skill or recognisable military doctrine". At the outbreak of the war in 1998 the Army was ineffective and the DRC Government was forced to rely on assistance from Angola, Chad, Namibia and Zimbabwe. As well as providing expeditionary forces, these countries unsuccessfully attempted to retrain the DRC Army. North Korea and Tanzania also provided assistance with training. During the first year of the war the Allied forces defeated the Rwandan force which had landed in Bas-Congo and the rebel forces south-west of Kinshasa and eventually halted the rebel and Rwandan offensive in the east of the DRC. These successes contributed to the Lusaka Ceasefire Agreement which was signed in July 1999. Following the Lusaka Agreement, in mid-August 1999 President Kabila issued a decree dividing the country into eight military regions. The first military region, Congolese state television reported, would consist of the two Kivu provinces, Orientale Province would form the second region, and Maniema and Kasai-Oriental provinces the third. Katanga and Équateur would fall under the fourth and fifth regions, respectively, while Kasai-Occidental and Bandundu would form the sixth region. Kinshasa and Bas-Congo would form the seventh and eighth regions, respectively. In November 1999 the Government attempted to form a 20,000-strong paramilitary force designated the People's Defence Forces. This force was intended to support the FAC and national police but never became effective.

The Lusaka Ceasefire Agreement was not successful in ending the war, and fighting resumed in September 1999. The FAC's performance continued to be poor and both the major offensives the Government launched in 2000 ended in costly defeats. President Kabila's mismanagement was an important factor behind the FAC's poor performance, with soldiers frequently going unpaid and unfed while the Government purchased advanced weaponry which could not be operated or maintained. The defeats in 2000 are believed to have been the cause of President Kabila's assassination in January 2001. Following the assassination, Joseph Kabila assumed the presidency and was eventually successful in negotiating an end to the war in 2002–2003.

The December 2002 Global and All-Inclusive Agreement devoted Chapter VII to the armed forces. It stipulated that the armed forces chief of staff, and the chiefs of the army, air force, and navy were not to come from the same warring faction. The new "national, restructured and integrated" army would be made up from Kabila's government forces (the FAC), the RCD, and the MLC. Also stipulated in VII(b) was that the RCD-N, RCD-ML, and the Mai-Mai would become part of the new armed forces. An intermediate mechanism for physical identification of the soldiers, and their origin, date of enrolment, and unit was also called for (VII(c)). It also provided for the creation of a "Conseil Superieur de la Defense" (Superior Defence Council) which would declare states of siege or war and give advice on security sector reform, disarmament/demobilization, and national defence policy.

A decision on which factions were to name chiefs of staff and military regional commanders was announced on 19 August 2003 as the first move in military reform, superimposed on top of the various groups of fighters, government and former rebels. Negotiations had been ongoing since June 2003. Kabila was able to name the armed forces chief of staff, Lieutenant General Liwanga Mata, who previously served as navy chief of staff under Laurent Kabila. Kabila was able to name the air force commander (John Numbi), the RCD-Goma received the Land Force commander's position (Sylvain Buki) and the MLC the navy (Dieudonne Amuli Bahigwa). Three military regional commanders were nominated by the former Kinshasa government, two commanders each by the RCD-Goma and the MLC, and one region commander each by the RCD-K/ML and RCD-N. However these appointments were announced for Kabila's "Forces armées congolaises" (FAC), not the later FARDC. However, troop deployment on the ground did not change substantially until the year afterward.
On 24 January 2004, a decree created the "Structure Militaire d'Intégration" (SMI, Military Integration Structure). Together with the SMI, CONADER also was designated to manage the combined "tronc commun" DDR element and military reform programme. The first post-Sun City military law appears to have been passed on 12 November 2004, which formally created the new national Forces Armées de la République Démocratique du Congo (FARDC). Included in this law was article 45, which recognised the incorporation of a number of armed groups into the FARDC, including the former government army Forces Armées Congolaises (FAC), ex-FAZ personnel also known as former President Mobutu's 'les tigres', the RCD-Goma, RCD-ML, RCD-N, MLC, the Mai-Mai, as well as other government-determined military and paramilitary groups.

Turner writes that the two most prominent opponents of military integration ("brassage") were Colonel Jules Mutebusi, a Munyamulenge from South Kivu, and Laurent Nkunda, a Rwandaphone Tutsi who Turner says was allegedly from Rutshuru in North Kivu. In May–June 2004 Mutebusi led a revolt against his superiors from Kinshasa in South Kivu. Nkunda began his long series of revolts against central authority by helping Mutebusi in May–June 2004. In November 2004 a Rwandan government force entered North Kivu to attack the FDLR, and, it seems, reinforced and resupplied RCD-Goma (ANC) at the same time. Mutebutsi and Nkunda were seemingly supported by both the Rwandan government, the FARDC regional commander, General Obed Rwisbasira, and the RCD-Goma governor of North Kivu, Eugene Serufuli. Neither government figure did anything to prevent Nkunda's march south to Bukavu with his military force. In mid-December, civilians at Kanyabayonga, Buramba, and Nyabiondo in North Kivu were killed, tortured, and raped, seemingly deliberately targeted on ethic grounds (the victims came almost exclusively from the Hunde and Nande ethnic groups). Kabila despatched 10,000 government troops to the east in response, launching an operation 11 December that was called "Operation Bima". Its only major success was the capture of Walikale from RCD-Goma (ANC) troops.

There was another major personnel reshuffle on 12 June 2007. FARDC chief General Kisempia Sungilanga Lombe was replaced with General Dieudonne Kayembe Mbandankulu. General Gabriel Amisi Kumba retained his post as Land Forces commander. John Numbi, a trusted member of Kabila's inner circle, was shifted from air force commander to Police Inspector General. U.S. diplomats reported that the former Naval Forces Commander Maj. General Amuli Bahigua (ex-MLC) became the FARDC's Chief of Operations; former FARDC Intelligence Chief General Didier Etumba (ex-FAC) was promoted to vice admiral and appointed Commander of Naval Forces; Maj. General Rigobert Massamba (ex-FAC), a former commander of the Kitona air base, was appointed as Air Forces Commander; and Brig. General Jean-Claude Kifwa, commander of the Republican Guard, was appointed as a regional military commander.

Due to significant delays in the DDR and integration process, of the eighteen brigades, only seventeen have been declared operational, over two and a half years after the initial target date. Responding to the situation, the Congolese Minister of Defence presented a new defence reform master plan to the international community in February 2008. Essentially the three force tiers all had their readiness dates pushed back: the first, territorial forces, to 2008–12, the mobile force to 2008–10, and the main defence force to 2015.

Much of the east of the country remains insecure, however. In the far northeast this is due primarily to the Ituri conflict. In the area around Lake Kivu, primarily in North Kivu, fighting continues among the Democratic Forces for the Liberation of Rwanda and between the government FARDC and Laurent Nkunda's troops, with all groups greatly exacerbating the issues of internal refugees in the area of Goma, the consequent food shortages, and loss of infrastructure from the years of conflict. In 2009, several United Nations officials stated that the army is a major problem, largely due to corruption that results in food and pay meant for soldiers being diverted and a military structure top-heavy with colonels, many of whom are former warlords. In a 2009 report itemizing FARDC abuses, Human Rights Watch urged the UN to stop supporting government offensives against eastern rebels until the abuses ceased.

Caty Clement wrote in 2009:
"One of the most notable [FARDC corruption] schemes was known as 'Opération Retour' (Operation Return). Senior officers ordered the soldiers' pay to be sent from Kinshasa to the commanders in the field, who took their cut and returned the remainder to their commander in Kinshasa instead of paying the soldiers. To ensure that foot soldiers would be paid their due, in late 2005, EUSEC suggested separating the chain of command from the chain of payment. The former remained within Congolese hands, while the EU mission delivered salaries directly to the newly 'integrated' brigades. Although efficient in the short term, this solution raises the question of sustainability and ownership in the long term. Once soldiers' pay could no longer be siphoned off via 'Opération Retour', however, two other budgetary lines, the 'fonds de ménage' and logistical support to the brigades, were soon diverted."

In 2010, thirty FARDC officers were given scholarships to study in Russian military academies. This is part of a greater effort by Russia to help improve the FARDC. A new military attaché and other advisers from Russia visited the DRC.

On 22 November 2012, Gabriel Amisi Kumba was suspended from his position in the Forces Terrestres by president Joseph Kabila due to an inquiry into his alleged role in the sale of arms to various rebel groups in the eastern part of the country, which may have implicated the rebel group M23. In December 2012 it was reported that members of Army units in the north east of the country are often not paid due to corruption, and these units rarely made against villages by the Lord's Resistance Army.

The FARDC deployed 850 soldiers and 150 PNC police officers as part of an international force in the Central African Republic, which the DRC borders to the north. The country had been in a state of civil war since 2012, when the president was ousted by rebel groups. The DRC was urged by French president François Hollande to keep its troops in CAR.

In July 2014, the Congolese army carried out a joint operation with UN troops in the Masisi and Walikale territories of the North Kivu province. In the process, they liberated over 20 villages and a mine from the control of two rebel groups, the Mai Mai Cheka and the Alliance for the Sovereign and Patriotic Congo.

The UN published a report in October 2017 announcing that the FARDC no longer employed child soldiers but was still listed under militaries that committed sexual violations against children.

Troops operating with MONUSCO in North Kivu were attacked by likely rebels from the Allied Democratic Forces on 8 December 2017. After a protracted firefight the troops suffered 5 dead along with 14 dead among the UN force.

The President Félix Tshisekedi is the Commander-in-Chief of the Armed Forces. The Minister of Defence, formally Ministers of Defence and Veterans (Ancien Combattants) is Crispin Atama Tabe, who succeeded former minister Aimé Ngoy Mukena.

The Colonel Tshatshi Military Camp in the Kinshasa suburb of Ngaliema hosts the defence department and the Chiefs of Staff central command headquarters of the FARDC. Jane's data from 2002 appears inaccurate; there is at least one ammunition plant in Katanga.

Below the Chief of Staff, the current organisation of the FARDC is not fully clear. There is known to be a Military Intelligence branch – Service du Renseignement militaire (SRM), the former DEMIAP. The FARDC is known to be broken up into the Land Forces ("Forces Terrestres"), Navy and Air Force. The Land Forces are distributed around ten military regions, up from the previous eight, following the ten provinces of the country. There is also a training command, the Groupement des Écoles Supérieurs Militaires (GESM) or Group of Higher Military Schools, which, in January 2010, was under the command of Major General Marcellin Lukama. The Navy and Air Forces are composed of various "groupments" (see below). There is also a central logistics base. The United Nations Mine Action Service supervised the construction of a new ammunition depot on the outskirts of Kisangani and handed it over to the MOD in October 2013.

It should be made clear also that Joseph Kabila does not trust the military; the Republican Guard is the only component he trusts. Major General John Numbi, former Air Force chief, now inspector general of police, ran a parallel chain of command in the east to direct the 2009 Eastern Congo offensive, Operation Umoja Wetu; the regular chain of command was by-passed. Previously Numbi negotiated the agreement to carry out the "mixage" process with Laurent Nkunda. Commenting on a proposed vote of no confidence in the Minister of Defence in September 2012, Baoudin Amba Wetshi of "lecongolais.cd" described Ntolo as a "scapegoat". Wetshi said that all key military and security questions were handled in total secrecy by the President and other civil and military personalities trusted by him, such as John Numbi, Gabriel Amisi Kumba ('Tango Four'), Delphin Kahimbi, and others such as Kalev Mutond and Pierre Lumbi Okongo.


The General Secretariat for Defence: is headed by a General Officer (Secretary General for Defence). He oversees the following departments:

Military Justice is an independent institution under the judiciary, responsible for upholding the law and strengthening order and discipline within the Armed Forces.

The General Inspectorate includes the following people:


The available information on armed forces' Chiefs of Staff is incomplete and sometimes contradictory. In addition to armed forces chiefs of staff, in 1966 Lieutenant Colonel Ferdinand Malila was listed as Army Chief of Staff.

Virtually all officers have now changed positions, but this list gives an outline of the structure in January 2005. Despite the planned subdivision of the country into more numerous provinces, the actual splitting of the former provinces has not taken place.

In September 2014, President Kabila reshuffled the command structure and in addition to military regions created three new 'defence zones' which would be subordinated directly to the general staff. The defence zones essentially created a new layer between the general staff and the provincial commanders. The military regions themselves were reorganised and do not correspond with the ones that existed prior to the reshuffle. New commanders of branches were also appointed: A Congolese military analyst based in Brussels, Jean-Jacques Wondo, provided an outline of the updated command structure of the FARDC following the shake up of the high command:


Regional commanders:

The following changes were announced in July 2018.


Circa 2008–09, the land forces were made up of about 14 integrated brigades of fighters from all the former warring factions who went through a "brassage" integration process (see next paragraph) and a limited number of non-integrated brigades that remain solely made up of single factions (the Congolese Rally for Democracy (RCD)'s "Armée national congolaise", the ex-government former Congolese Armed Forces (FAC), the ex-RCD KML, the ex-Movement for the Liberation of Congo, the armed groups of the Ituri conflict (the Mouvement des Révolutionnaires Congolais (MRC), Forces de Résistance Patriotique d'Ituri (FRPI), and the Front Nationaliste Intégrationniste (FNI)), and the Mai-Mai).

It appears that about the same time that Presidential Decree 03/042 of 18 December 2003 established the National Commission for Demobilisation and Reinsertion (CONADER), "..all ex-combatants were officially declared as FARDC soldiers and the then FARDC brigades [were to] rest deployed until the order to leave for "brassage"" [the military integration process].
The reform plan adopted in 2005 envisaged the formation of eighteen integrated brigades through the military integration process as its first of three stages. The process consisted firstly of regroupment, where fighters are disarmed. Then they were sent to orientation centres, run by CONADER, where fighters took the choice of either returning to civilian society or remaining in the armed forces. Combatants who chose demobilisation received an initial cash payment of US$110. Those who chose to stay within the FARDC were then transferred to one of six integration centres for a 45-day training course, which aimed to build integrated formations out of factional fighters previously heavily divided along ethnic, political and regional lines. The centres were spread out around the country at Kitona, Kamina, Kisangani, Rumangabo and Nyaleke (within the Virunga National Park) in Nord-Kivu, and Luberizi (on the border with Burundi) in South Kivu. The process suffered severe difficulties due to construction delays, administration errors, and the amount of travel former combatants have to do, as the three stages' centres are widely separated. There were three sequential buildup stages in the 2005 plan. Following the first 18 integrated brigades, the second goal was the formation of a ready reaction force of two to three brigades, and finally, by 2010, when MONUC was hoped to have withdrawn, the creation of a Main Defence Force of three divisions.

In February 2008, then Defence Minister Chikez Diemu described the reform plan at the time as:
"The short term, 2008–2010, will see the setting in place of a Rapid Reaction Force; the medium term, 2008–2015, with a Covering Force; and finally the long term, 2015–2020, with a Principal Defence Force." Diemu added that the reform plan rests on a programme of synergy based on the four pillars of dissuasion, production, reconstruction and excellence. "The Rapid Reaction Force is expected to focus on dissuasion, through a Rapid Reaction Force of 12 battalions, capable of aiding MONUC to secure the east of the country and to realise constitutional missions."
Amid the other difficulties in building new armed forces for the DRC, in early 2007 the integration and training process was distorted as the DRC government under Kabila attempted to use it to gain more control over the dissident general Laurent Nkunda. A hastily negotiated verbal agreement in Rwanda saw three government FAC brigades integrated with Nkunda's former ANC 81st and 83rd Brigades in what was called "mixage". "Mixage" brought multiple factions into composite brigades, but without the 45-day retraining provided by "brassage", and it seems that actually, the process was limited to exchanging battalions between the FAC and Nkunda brigades in North Kivu, without further integration. Due to Nkunda's troops having greater cohesion, Nkunda effectively gained control of all five brigades, which was not the intention of the DRC central government. However, after Nkunda used the "mixage" brigades to fight the FDLR, strains arose between the FARDC and Nkunda-loyalist troops within the brigades and they fell apart in the last days of August 2007. The International Crisis Group says that "by 30 August [2007] Nkunda's troops had left the mixed brigades and controlled a large part of the Masisi and Rutshuru territories" (of North Kivu).

Both formally integrated brigades and the non-integrated units continue to conduct arbitrary arrests, rapes, robbery, and other crimes and these human rights violations are "regularly" committed by both officers and members of the rank and file. Members of the Army also often strike deals to gain access to resources with the militias they are meant to be fighting.

The various brigades and other formations and units number at least 100,000 troops. The status of these brigades has been described as "pretty chaotic." A 2007 disarmament and repatriation study said "army units that have not yet gone through the process of brassage are usually much smaller than what they ought to be. Some non-integrated brigades have only 500 men (and are thus nothing more than a small battalion) whereas some battalions may not even have the size of a normal company (over a 100 men)."

A number of outside donor countries are also carrying out separate training programmes for various parts of the Forces Terrestres (Land Forces). The People's Republic of China has trained Congolese troops at Kamina in Katanga from at least 2004 to 2009, and the Belgian government is training at least one "rapid reaction" battalion. When Kabila visited U.S. President George W. Bush in Washington D.C., he also asked the U.S. Government to train a battalion, and as a result, a private contractor, Protection Strategies Incorporated, started training a FARDC battalion at Camp Base, Kisangani, in February 2010. The company was supervised by United States Special Operations Command Africa. Three years later, the battalion broke and ran in the face of M23, raping women and young girls, looting, and carrying out arbitrary executions. The various international training programmes are not well integrated.

Attempting to list the equipment available to the DRC's land forces is difficult; most figures are unreliable estimates based on known items delivered in the past. The figures below are from the IISS Military Balance 2014. Much of the Army's equipment is non-operational due to insufficient maintenance—in 2002 only 20 percent of the Army's armoured vehicles were estimated as being serviceable.

In addition to these 2014 figures, in March 2010, it was reported that the DRC's land forces had ordered US$80 million worth of military equipment from Ukraine which included 20 T-72 main battle tanks, 100 trucks and various small arms. Tanks have been used in the Kivus in the 2005–09 period.

In February 2014, Ukraine revealed that it had achieved the first export order for the T-64 tank to the DRC Land Forces for 50 T-64BV-1s.

In June 2015 it was reported that Georgia had sold 12 of its Didgori-2 to the DRC for $4 million. The vehicles were specifically designed for reconnaissance and special operations. Two of the vehicles are a recently developed conversion to serve for medical field evacuation.

The United Nations confirmed in 2011, both from sources in the Congolese military and from officials of the Commission nationale de contrôle des armes légères et de petit calibre et de réduction de la violence armée, that the ammunition plant called Afridex in Likasi, Katanga Province, manufactures ammunition for small arms and light weapons.

In addition to the other land forces, President Joseph Kabila also has a Republican Guard presidential force ("Garde Républicaine" or GR), formerly known as the Special Presidential Security Group (GSSP). FARDC military officials state that the Garde Républicaine is not the responsibility of FARDC, but of the Head of State. Apart from Article 140 of the Law on the Army and Defence, no legal stipulation on the DRC's Armed Forces makes provision for the GR as a distinct unit within the national army. In February 2005 President Joseph Kabila passed a decree which appointed the GR's commanding officer and "repealed any previous provisions contrary" to that decree. The GR, more than 10,000 strong (the ICG said 10,000 to 15,000 in January 2007), has better working conditions and is paid regularly, but still commits rapes and robberies in the vicinity of its bases.

In an effort to extend his personal control across the country, Joseph Kabila has deployed the GR at key airports, ostensibly in preparation for an impending presidential visit. there were Guards deployed in the central prison of Kinshasa, N'djili Airport, Bukavu, Kisangani, Kindu, Lubumbashi, Matadi, and Moanda, where they appear to answer to no local commander and have caused trouble with MONUC troops there.

The GR is also supposed to undergo the integration process, but in January 2007, only one battalion had been announced as having been integrated. Formed at a brassage centre in the Kinshasa suburb of Kibomango, the battalion included 800 men, half from the former GSSP and half from the MLC and RCD Goma.

Up until June 2016, the GR comprised three brigades, the 10th Brigade at Camp Tshatshi and the 11th at Camp Kimbembe, both in Kinshasa, and the 13th Brigade at Camp Simi Simi in Kisangani. It was reorganised on the basis of eight fighting regiments, the 14th Security and Honor Regiment, an artillery regiment, and a command brigade/regiment from that time.

There are currently large numbers of United Nations troops stationed in the DRC. The United Nations Organization Stabilization Mission in the Democratic Republic of the Congo (MONUSCO) on 31 March 2017 had a strength of over 18,316 peacekeepers (including 16,215 military personnel) and is tasked with assisting Congolese authorities to maintain security. The UN and foreign military aid missions, the most prominent being EUSEC RD Congo, are attempting to assist the Congolese in rebuilding the armed forces, with major efforts being made in trying to assure regular payment of salaries to armed forces personnel and also in military justice. Retired Canadian Lieutenant General Marc Caron also served for a time as Security Sector Reform advisor to the head of MONUC.

Groups of anti-Rwandan government rebels like the FDLR, and other foreign fighters remain inside the DRC. The FDLR which is the greatest concern, was some 6,000 strong, in July 2007. By late 2010 the FDLR's strength however was estimated at 2,500. The other groups are smaller: the Ugandan Lord's Resistance Army, the Ugandan rebel group the Allied Democratic Forces in the remote area of Mt Rwenzori, and the Burundian Parti pour la Libération du Peuple Hutu—Forces Nationales de Liberation (PALIPEHUTU-FNL).

Finally there is a government paramilitary force, created in 1997 under President Laurent Kabila. The National Service is tasked with providing the army with food and with training the youth in a range of reconstruction and developmental activities. There is not much further information available, and no internet-accessible source details the relationship of the National Service to other armed forces bodies; it is not listed in the constitution. President Kabila, in one of the few comments available, says National Service will provide a gainful activity for street children. Obligatory civil service administered through the armed forces was also proposed under the Mobutu regime during the "radicalisation" programme of December 1974 – January 1975; the FAZ was opposed to the measure and the plan "took several months to die."

All military aircraft in the DRC are operated by the Air Force. In 2007, Jane's World Air Forces stated that the Air Force had an estimated strength of 1,800 personnel and is organised into two Air Groups. These Groups command five wings and nine squadrons, of which not all are operational. 1 Air Group is located at Kinshasa and consists of Liaison Wing, Training Wing and Logistical Wing and has a strength of five squadrons. 2 Tactical Air Group is located at Kaminia and consists of Pursuit and Attack Wing and Tactical Transport Wing and has a strength of four squadrons. Foreign private military companies have reportedly been contracted to provide the DRC's aerial reconnaissance capability using small propeller aircraft fitted with sophisticated equipment. Jane's states that National Air Force of Angola fighter aircraft would be made available to defend Kinshasa if it came under attack.

Like the other services, the Congolese Air Force is not capable of carrying out its responsibilities. Few of the Air Force's aircraft are currently flyable or capable of being restored to service and it is unclear whether the Air Force is capable of maintaining even unsophisticated aircraft. Moreover, Jane's stated that the Air Force's Ecole de Pilotage is 'in near total disarray' though Belgium has offered to restart the Air Force's pilot training program.

In 2018 the IISS estimated that the Air Force numbered 2250 (p457); the 2020 edition carried the same number, unchanged.

The IISS Military Balance 2021 said the Air Force had four Su-25s; four transport aircraft, including 2 B727s; 7 Mil Mi-24s; and three transport helicopters, with a strength of 2,550 (p.461).

Before the downfall of Mobutu, a small navy operated on the Congo River. One of its installations was at the village of N'dangi near the presidential residence in Gbadolite. The port at N'dangi was the base for several patrol boats, helicopters and the presidential yacht. The 2002 edition of "Jane's Sentinel" described the Navy as being "in a state of near total disarray" and stated that it did not conduct any training or have operating procedures. The Navy shares the same discipline problems as the other services. It was initially placed under command of the MLC when the transition began, so the current situation is uncertain.

The 2007 edition of "Jane's Fighting Ships" states that the Navy is organised into four commands, based at Matadi, near the coast; the capital Kinshasa, further up the Congo river; Kalemie, on Lake Tanganyika; and Goma, on Lake Kivu. The International Institute for Strategic Studies, in its 2007 edition of the "Military Balance", confirms the bases listed in "Jane's" and adds a fifth base at Boma, a coastal city near Matadi. Various sources also refer to numbered Naval Regions. Operations of the 1st Naval Region have been reported in Kalemie, the 4th near the northern city of Mbandaka, and the 5th at Goma.

As of 2012, the Navy on paper consisted of about 6,700 personnel and up to 23 patrol craft. The IISS repeated the same 6,700 figure in 2018 (p457) and the 2020 edition carried the same number, unchanged. In reality, The IISS lists the Navy only consists of around 1,000 personnel and a total of eight patrol craft, of which only one is operational, a Shanghai II Type 062 class gunboat designated "102". There are five other 062s as well as two Swiftships which are not currently operational, though some may be restored to service in the future. According to "Jane's", the Navy also operates barges and small craft armed with machine guns.



Geography of Denmark

Denmark is a Nordic country located in Northern Europe. It consists of the Jutland Peninsula and several islands in the Baltic Sea, referred to as the Danish Archipelago. Denmark is located southwest of Sweden and due south of Norway and is bordered by the German state (and former possession) Schleswig-Holstein to the south, on Denmark's only land border, 68 kilometres (42 miles) long.

Denmark borders both the Baltic and North seas along its tidal shoreline. Denmark's general coastline is much shorter, at , as it would not include most of the 1,419 offshore islands (each defined as exceeding 100 square metres in area) and the 180-kilometre long Limfjorden, which separates Denmark's second largest island, North Jutlandic Island, 4,686 km in size, from the rest of Jutland. No location in Denmark is further from the coast than . The land area of Denmark is estimated to be . However, it cannot be stated exactly since the ocean constantly erodes and adds material to the coastline, and there are human land reclamation projects. On the southwest coast of Jutland, the tide is between , and the tideline moves outward and inward on a stretch. A recent global remote sensing analysis suggested that there were 607 km² of tidal flats in Denmark, making it the 42nd ranked country in terms of tidal flat extent. Denmark has an Exclusive Economic Zone of . When including the Faroe Islands and Greenland, the EEZ is the 15th largest in the world with .

A circle enclosing the same total area as Denmark would have a diameter of 234 km (146 miles). Denmark has 443 named islands (1,419 islands above 100 m), of which 72 are inhabited (, Statistics Denmark). The largest islands are Zealand "(Sjælland)" and Funen "(Fyn)". The island of Bornholm is located east of the rest of the country, in the Baltic Sea. Many of the larger islands are connected by bridges; the Øresund Bridge connects Zealand with Sweden; the Great Belt Bridge connects Funen with Zealand; and the Little Belt Bridge connects Jutland with Funen. Ferries or small aircraft connect to the smaller islands. Main cities are the capital Copenhagen on Zealand; Århus, Aalborg and Esbjerg in Jutland; and Odense on Funen.

Denmark experiences a temperate climate. This means that the winters are mild and windy and the summers are cool. The local terrain is generally flat with a few gently rolling plains. The territory of Denmark includes the island of Bornholm in the Baltic Sea and the rest of metropolitan Denmark, but excludes the Faroe Islands and Greenland. Its position gives Denmark complete control of the Danish Straits (Skagerrak and Kattegat) linking the Baltic and North Seas. The country's natural resources include petroleum, natural gas, fish, salt, limestone, chalk, stone, gravel, and sand.

Irrigated land: 4,354 km (2007)

Total renewable water resources: 6 km (2011)

Freshwater withdrawal (domestic/industrial/agricultural):
<br>"total:" 0.66 km/yr (58%/5%/36%)
<br> "per capita:" 118.4 m/yr (2009)

In 2019, the government proposed building 9 new artificial islands, named project Holmene, which would create 3 sq km of reclaimed land, to be built from 2022-2040.

In June 2021, lawmakers approved the construction of a 3 sq km island, named , in the Copenhagen Harbor. A spokesperson for the Climate Movement in Denmark (Klimabevægelsen i Danmark) said the organization would sue the government over environmental concerns.

Denmark has plenty of rain, flat landscape, and moderate climate. With 55.99% of its land considered as arable, Denmark has model characteristics for agriculture. 61% of the country's total area is cultivated Farms in Denmark are remarkably large, averaging 172.9 acres per farm. Additionally, homesteads exceeding 247 acres make up more than 20% in Denmark. Many of these large farms harvest fruits and vegetables, the leading exports from Denmark are meat, fur, and dairy products. The animal's diets in Denmark consist of mainly cereals since they are the dominant field crop. 75% of all cereal produced in Denmark is feed to the four most produced animals which are pigs, cattle, chicken and mink. Denmark overproduces about 66% of food production compared to their own population size (5.7 million) being that they are able to feed 15 million people. This is a byproduct of being highly productive within the Danish agricultural production.

In 1961, Denmark's Agricultural land represented 74.5% of land area. Fifty-six years later to 2015, Denmark has decreased its amount of Agricultural land down to 62.1% then to 61% one year later in reference to "Facts and Figures - Danish Agriculture and Food" The decrease in agricultural land comes as farmers are being well educated and the intensive amount of research and development is being implemented. It begins with advancements in agro-technology. The results have improved fertilization and nutrient use on arable land. Digestibility and nutrient uptake are developing from the improvements of new methods that are being implemented. Examples of these new methods are the addition of enzymes and microbial cultures.




Demographics of Denmark

Demographic features of the population of Denmark include ethnicity, education level, health of the populace, economic status, religious affiliations, and other aspects.

Since 1980, the number of people of Danish descent, defined as having at least one parent who was born in Denmark and has Danish citizenship, has remained constant at around 5 million in Denmark, and nearly all the population growth from 5.1 up to the 2018 total of 5.8 million was due to immigration.

Demographic statistics according to the World Population Review in 2019. Population numbers until 2100 will be increasing.

The natural growth of the population (births minus deaths) was negative in 2022, that is, minus 1005 people. The last time there was a negative natural increase in the population was in 1988. During 2022, 58,430 children were born, 5,043 fewer than in 2021. In 2022, 59,435 people died, there were 2,283, or 4.0% more than in 2021. The total population in the age group 80 and over grew by 12,844 people, or 4.4%., from 2022 to 2023.

During 2022, the Danish population grew by 59,234 people, so the population on January 1, 2023, consisted of 5,932,654 people. It was a population increase of 1.0 percent, which is higher than in 2021, when the population increase was 0.6 percent.

In 2022, it is the first time in history that immigrant women from non-Western countries now have fewer children on average than women of Danish roots in Denmark. On average, immigrant women have 1.76 children, the descendants have an average of 1.75 children, while women of Danish roots have 1.78 children. This is because Ukrainians, who are categorized as non-Western, have come to Denmark in large numbers.

In the same year, immigrant women from Syria had the highest TFR in Denmark, they give birth to an average of 3.7 children. They are followed by women from Somalia and Pakistan, 2020 figures show.

Denmark had a total fertility rate of 1.55 children per woman in 2022.

In 2021 the number of childless women in their 50s is the highest in seven years; 12.3 percent of women at that age have never had a child, while the 19.5 percent of 50-year-old men do not have children.

The total fertility rate is the number of children born per woman. It is based on fairly good data for the entire period. Sources: Our World In Data and Gapminder Foundation.

Total fertility rate

1.78 children born/woman (2018 est.) Country comparison to the world: 152nd

In 2021 the average age of the mother at her first birth in Denmark was of 29.8 years, and the father is of 31.5 years.

Sources: Our World In Data and the United Nations.

1775–1950

1950–2015


Non-indigenous ethnic minorities include:

Ethnic minorities in Denmark include a handful of groups:


In the modern minorities, Statistics Denmark counts first-generation immigrants, second-generation (Descendants in Danish statistics classification) and third-generation (Children of descendants in Danish classification). Children of descendants can be either of "Danish origin" (if both of their parents were born in Denmark with Danish citizenship) and of "foreign origin" (if one of their parents is a second-generation immigrant and another first-generation). Therefore, this table included all people of the respective background, people who are classified as of "foreign background" and third-generation immigrants, who classified as of "Danish origin". Statistics Denmark denotes an immigrant's group based on their country of birth, it does this usually off of the immigrant or descendents parents, if only one such parent is known, then the group is determined by that or if no parents are known then it is assumed if the person is an immigrant that their country of origin is their country of birth.

Statistics Denmark also has specific classification bands which it uses to separate different immigrant groups. As an example, for 'Western' immigrants and 'Non-western', the classification band is as follows:

According to 2021 figures from Statistics Denmark, 86% of Denmark's population of over 5,840,045 was of Danish descent. The remaining 14% were of a foreign background, defined as immigrants or descendants of recent immigrants. With the same definition, the most common countries of origin were Turkey, Poland, Germany, Iraq, Romania, Syria, Somalia, Iran, Afghanistan, and Yugoslavia and its successor states.
More than 817,438 individuals (14%) are migrants and their descendants (199,668 second generation migrants born in Denmark).

Of these 817,438 immigrants and their descendants:

There were 121,183 immigrants in 2022, of these 31,381 were Ukrainian citizens, people with Ukrainian citizenship accounted for 26 percent of all immigration. The total population of Denmark increased in 2022 by 59,234 people, and the net immigration of Ukrainian people amounted to 45 percent of this population growth.

Data according to Statistics Denmark, which collects the official statistics for Denmark.

In 2022, 45,922 (78.6%) babies were born to mothers of Danish origin, 10,039 (17.2%) to immigrant mothers and 2,469 (4.2%) to mothers who are descendants of immigrants.

The urban area of Copenhagen consists of the contiguously built-up area of the capital of Denmark. The Copenhagen metropolitan area consists of 34 municipalities. The East Jutland metropolitan area includes 19 municipalities.

The Church of Denmark () is state-supported and, according to statistics from January 2022, accounts for the religious affiliation of 73.2% of the population. Denmark has had religious freedom guaranteed since 1849 by the Constitution, and numerous other religions are officially recognised, including several Christian denominations, Muslim, Jewish, Buddhist, Hindu and other congregations as well as Forn Siðr, a revival of Scandinavian pagan tradition. The Department of Ecclesiastical Affairs recognises roughly a hundred religious congregations for tax and legal purposes such as conducting wedding ceremonies.

Islam is the second largest religion in Denmark. In 2020, an estimated 4.4% of the Danish population were Muslims.

For historical reasons, there is a formal distinction between 'approved' () and 'recognised' () congregations of faith. The latter include 11 traditional denominations, such as Roman Catholics, the Reformed Church, the Mosaic Congregation, Methodists and Baptists, some of whose privileges in the country date hundreds of years back. These have the additional rights of having priests appointed by royal resolution and to christen/name children with legal effect.


Evangelical Lutheran (official) 74.8%, Muslim 5.3%, other (denominations of less than 1% each, include Roman Catholic, Jehovah's Witness, Serbian Orthodox Christian, Jewish, Baptist, and Buddhist) 19.9% (2017 est.)


Although the level of taxation in Denmark is among the highest in the world, the labor market participation rate is still high compared with other western countries. Municipal income tax makes up the largest part of taxation in Denmark, with central government income tax topping it up. These income taxes are higher than in other OECD countries. These direct taxes make up two thirds of the taxation on private households with indirect taxes of the central government, and municipalities (property tax), making up one third, i.e. with motor vehicles (passenger cars, motorcycles, commercial vehicles) sold from VAT registered dealerships – because of the registration fee – being among the most expensive in the world, with prices in Norway at the same level, and the most expensive in Singapore. Also VAT in Denmark is not reduced from the current 25%. The 25% are paid on all goods and services where VAT is applied. Indirect taxes are about average compared with other European OECD countries. Payroll taxes (Danish "sociale afgifter") are much lower than in other OECD countries. The tax structure ensures a broad tax base across the whole population. However, revenue from corporate taxes is lower compared with other European countries. Municipalities and the central government (regions are not allowed to levy any taxes, as they are financed by central government, and municipal block grants) redistribute a large amount of their tax income in transfer payments to municipalities with a low tax base and/or few tax payers. It is normal for children to be in nurseries, which requires a partial payment of the costs or is free of charge for low income households, and in kindergartens owned and operated, or financed, by the public sector. Child benefit is paid to parents for each child. The service to old age pensioners, and handicapped is extensive.

Denmark ranks high in the Corruption Perceptions Index, although the index is criticized for being limited in scope.



Economy of Denmark

The economy of Denmark is a modern high-income and highly developed mixed economy. The economy of Denmark is dominated by the service sector with 80% of all jobs, whereas about 11% of all employees work in manufacturing and 2% in agriculture. The nominal gross national income per capita was the ninth-highest in the world at $68,827 in 2023.

Correcting for purchasing power, per capita income was Int$57,781 or 10th-highest globally. The income distribution is relatively equal but inequality has somewhat increased during the last decades. In 2017, Denmark had the seventh-lowest Gini coefficient (a measure of economic inequality) of the then 28 European Union countries. With 5,932,654 inhabitants (1 January 2023), Denmark has the 38th largest national economy in the world measured by nominal gross domestic product (GDP), and the 52nd largest in the world measured by purchasing power parity (PPP).

Denmark has a very long tradition of adhering to a fixed exchange-rate system and still does so today. It is unique among OECD countries to do so while maintaining an independent currency: The Danish krone, which is pegged to the euro. Though eligible to join the EU's Economic and Monetary Union (EMU), Danish voters in a referendum in 2000 rejected exchanging the krone for the euro. Whereas Denmark's neighbours like Norway, Sweden, Poland and the United Kingdom generally follow inflation targeting in their monetary policy, the priority of Denmark's central bank is to maintain exchange rate stability. Consequently, the central bank has no role in a domestic stabilization policy. Since February 2015, the central bank has maintained a negative interest rate to contain an upward exchange rate pressure.

In an international context, a relatively large proportion of the population is part of the labour force, in particular because the female participation rate is very high. In 2017, 78.8% of all 15-to-64-year-old people were active on the labour market, the sixth-highest number among all OECD countries. With a 4.8% unemployment rate, unemployment is relatively low, in comparison to other European countries where the average unemployment rate is 6.7%. The labour market is traditionally characterized by a high degree of union membership rates and collective agreement coverage. Denmark invests heavily in active labor market policies and the concept of flexicurity has been important historically.

Denmark is an example of the Nordic model, characterized by an internationally high tax level, and a correspondingly high level of government-provided services (e.g. health care, child care and education services). There are also income transfers to various groups, such as retirees, disabled people, the unemployed, and students. Altogether, the amount of revenue from taxes paid in 2017 amounted to 46.1% of GDP. The Danish fiscal policy is generally considered healthy. The net government debt is very close to zero, amounting to 1.3% of GDP in 2017. The Danish fiscal policy is characterized by a long-term outlook, taking into account likely future fiscal demands. During the 2000s, a challenge was perceived to government expenditures in future decades. It was ultimately a challenge to fiscal sustainability from demographic development, in particular higher longevity. Responding to this, age eligibility rules for receiving public age-related transfers were changed. Since 2012, calculations of future fiscal challenges, from both the government and independent analysts, have generally perceived Danish fiscal policy to be sustainable. In recent years, it was considered overly sustainable.

Denmark's long-term economic development has largely followed the same pattern as other Northwestern European countries. In most of recorded history Denmark has been an agricultural country with most of the population living on a subsistence level. Since the 19th century Denmark has gone through an intense technological and institutional development. The material standard of living has experienced formerly unknown rates of growth, and the country has been industrialized and later turned into a modern service society.

Almost all of the land area of Denmark is arable. Unlike most of its neighbours, Denmark has not had extractable deposits of minerals or fossil fuels, except for the deposits of oil and natural gas in the North Sea, which started playing an economic role only during the 1980s. On the other hand, Denmark has had a logistic advantage through its long coastal line and the fact that no point on Danish land is more than 50 kilometers from the sea – an important fact for the whole period before the industrial revolution when sea transport was cheaper than land transport. Consequently, foreign trade has always been very important for the economic development of Denmark. 
Already during the Stone Age there was some foreign trade, and even though trade has made up only a very modest share of total Danish value added until the 19th century, it has been decisive for economic development, both in terms of procuring vital import goods (like metals) and because new knowledge and technological skills have often come to Denmark as a byproduct of goods exchange with other countries. The emerging trade implied specialization which created demand for means of payments, and the earliest known Danish coins date from the time of Svend Tveskæg around 995.

According to economic historian Angus Maddison, Denmark was the sixth-most prosperous country in the world around 1600. The population size relative to arable agricultural land was small so that the farmers were relatively affluent, and Denmark was geographically close to the most dynamic and economically leading European areas since the 16th century: the Netherlands, the northern parts of Germany, and Britain. Still, 80 to 85% of the population lived in small villages on a subsistence level.

Mercantilism was the leading economic doctrine during the 17th and 18th century in Denmark, leading to the establishment of monopolies like Asiatisk Kompagni, development of physical and financial infrastructure like the first Danish bank Kurantbanken in 1736 and the first "kreditforening" (a kind of building society) in 1797, and the acquisition of some minor Danish colonies like Tranquebar.

At the end of the 18th century major agricultural reforms took place that entailed decisive structural changes. However, the Napoleonic Wars caused Copenhagen to lose its status as an international centre of finance and trade. Politically, mercantilism was gradually replaced by liberal thoughts among the ruling elite. Following a monetary reform after the Napoleonic wars, the present Danish central bank Danmarks Nationalbank was founded in 1818.

There exists national accounting data for Denmark from 1820 onwards thanks to the pioneering work of Danish economic historian Svend Aage Hansen. They find that there has been a substantial and permanent, though fluctuating, economic growth all the time since 1820. The period 1822–94 saw on average an annual growth in factor incomes of 2% (0.9% per capita) From around 1830 the agricultural sector experienced a major boom lasting several decades, producing and exporting grains, not least to Britain after 1846 when British grain import duties were abolished. When grain production became less profitable in the second half of the century, the Danish farmers made an impressive and uniquely successful change from vegetarian to animal production leading to a new boom period. Parallelly industrialization took off in Denmark from the 1870s. At the turn of the century industry (including artisanry) fed almost 30% of the population.

During the 20th century agriculture slowly dwindled in importance relative to industry, but agricultural employment was only during the 1950s surpassed by industrial employment. The first half of the century was marked by the two world wars and the Great Depression during the 1930s. After World War II Denmark took part in the increasingly close international cooperation, joining OEEC/OECD, IMF, GATT/WTO, and from 1972 the European Economic Community, later European Union. Foreign trade increased heavily relative to GDP. The economic role of the public sector increased considerably, and the country was increasingly transformed from an industrial country to a country dominated by production of services. The years 1958–73 were an unprecedented high-growth period. The 1960s are the decade with the highest registered real per capita growth in GDP ever, i.e. 4.5% annually.
During the 1970s Denmark was plunged into a crisis, initiated by the 1973 oil crisis leading to the hitherto unknown phenomenon stagflation. For the next decades the Danish economy struggled with several major so-called "balance problems": High unemployment, current account deficits, inflation, and government debt. From the 1980s economic policies have increasingly been oriented towards a long-term perspective, and gradually a series of structural reforms have solved these problems. In 1994 active labour market policies were introduced that via a series of labour market reforms have helped reducing structural unemployment considerably. A series of tax reforms from 1987 onwards, reducing tax deductions on interest payments, and the increasing importance of compulsory labour market-based funded pensions from the 1990s have increased private savings rates considerably, consequently transforming secular current account deficits to secular surpluses. The announcement of a consistent and hence more credible fixed exchange rate in 1982 has helped reducing the inflation rate.

In the first decade of the 21st century new economic policy issues have emerged. A growing awareness that future demographic changes, in particular increasing longevity, could threaten fiscal sustainability, implying very large fiscal deficits in future decades, led to major political agreements in 2006 and 2011, both increasing the future eligibility age of receiving public age-related pensions. Mainly because of these changes, from 2012 onwards the Danish fiscal sustainability problem is generally considered to be solved. Instead, issues like decreasing productivity growth rates and increasing inequality in income distribution and consumption possibilities are prevalent in the public debate.

The global Great Recession during the late 2000s, the accompanying Euro area debt crisis and their repercussions marked the Danish economy for several years. Until 2017, unemployment rates have generally been considered to be above their structural level, implying a relatively stagnating economy from a business-cycle point of view. From 2017/18 this is no longer considered to be the case, and attention has been redirected to the need of avoiding a potential overheating situation.

In 2022 the popularity of Novo Nordisk's Ozempic and Wegovy for weight loss began greatly affecting the Danish economy. The pharmaceutical industry contributed two thirds of growth that year, and 1.7 points of the 1.9% year-over-year growth in the first quarter of 2023. Novo Nordisk's market capitalization—Europe's second-largest, after LVMH—exceeded the size of the entire national economy, and it is the largest payer of corporate taxes to the Danish state. Economists discussed whether the government needed to publish data including and excluding the company; as the enormous economic growth did not similarly increase employment, data including Novo Nordisk is misleading regarding the Danish business cycle. Some worried that the nation might become overdependent on the company, similar to what happened to the economy of Finland with Nokia, or that Novo Nordisk's success might cause Dutch disease.

Average per capita income is high in an international context. According to the World Bank, gross national income per capita was the tenth-highest in the world at $55,220 in 2017. Correcting for purchasing power, income was Int$52,390 or 16th-highest among the 187 countries.

During the last three decades household saving rates in Denmark have increased considerably. This is to a large extent caused by two major institutional changes: A series of tax reforms from 1987 to 2009 considerably reduced the effective subsidization of private debt implicit in the rules for tax deductions of household interest payments. Secondly, compulsory funded pension schemes became normal for most employees from the 1990s. Over the years, the wealth of the Danish pension funds have accumulated so that in 2016 it constituted twice the size of Denmark's GDP. The pension wealth consequently is a very important both for the life-cycle of a typical individual Danish household and for the national economy. A large part of the pension wealth is invested abroad, thus giving rise to a fair amount of foreign capital income. In 2015, average household assets were more than 600% of their disposable income, among OECD countries second only to the Netherlands. At the same time, average household gross debt was almost 300% of disposable income, which is also at the highest level in OECD. Household balance sheets are consequently very large in Denmark compared to most other countries. Danmarks Nationalbank, the Danish central bank, has attributed this to a well-developed financial system.

Income inequality has traditionally been low in Denmark. According to OECD figures, in 2000 Denmark had the lowest Gini coefficient of all countries. However, inequality has increased during the last decades. According to data from Statistics Denmark, the Gini coefficient for disposable income has increased from 22.1 in 1987 to 29.3 in 2017. The Danish Economic Council found in an analysis from 2016 that the increasing inequality in Denmark is due to several components: Pre-tax labour income is more unequally distributed today than before, capital income, which is generally less equally distributed than labour income, has increased as share of total income, and economic policy is less redistributive today, both because public income transfers play a smaller role today and because the tax system has become less progressive.

In international comparisons, Denmark has a relatively equal income distribution. According to the CIA World Factbook, Denmark had the twentieth-lowest Gini coefficient (29.0) of 158 countries in 2016. According to data from Eurostat, Denmark was the EU country with the seventh-lowest Gini coefficient in 2017. Slovakia, Slovenia, Czechia, Finland, Belgium and the Netherlands had a lower Gini coefficient for disposable income than Denmark.

The Danish labour market is characterized by a high degree of union membership rates and collective agreement coverage dating back from "Septemberforliget" (The September Settlement) in 1899 when the Danish Confederation of Trade Unions and the Confederation of Danish Employers recognized each other's right to organise and negotiate. The labour market is also traditionally characterized by a high degree of flexicurity, i.e. a combination of labour market flexibility and economic security for workers. The degree of flexibility is in part maintained through active labour market policies. Denmark first introduced active labour market policies (ALMPs) in the 1990s after an economic recession that resulted in high unemployment rates. Its labour market policies are decided through tripartite cooperation between employers, employees and the government. Denmark has one of the highest expenditures on ALMPs and in 2005, spent about 1.7% of its GDP on labour market policies. This was the highest amongst the OECD countries. Similarly, in 2010 Denmark was ranked number one amongst Nordic countries for expenditure on ALMPs.

Denmark's active labour market policies particularly focus on tackling youth unemployment. They have had a "youth initiative" or the Danish Youth Unemployment Programme in place since 1996. This includes mandatory activation for those unemployed under the age of 30. While unemployment benefits are provided, the policies are designed to motivate job-seeking. For example, unemployment benefits decrease by 50% after 6 months. This is combined with education, skill development and work training programs. For instance, the Building Bridge to Education program was started in 2014 to provide mentors and skill development classes to youth that are at risk of unemployment. Such active labour market policies have been successful for Denmark in the short-term and the long-term. For example, 80% of participants in the Building Bridge for Education program felt that "the initiative has helped them to move towards completing an education". On a more macro scale, a study of the impact of ALMPs in Denmark between 1995 and 2005 showed that such policies had positive impact not just on employment but also on earnings. The effective compensation rate for unemployed workers has been declining for the last decades, however. Unlike in most Western countries there is no legal minimum wage in Denmark.

A relatively large proportion of the population is active on the labour market, not least because of a very high female participation rate. The total participation rate for people aged 15 to 64 years was 78.8% in 2017. This was the 6th-highest number among OECD countries, only surpassed by Iceland, Switzerland, Sweden, New Zealand and the Netherlands. The average for all OECD countries together was 72.1%.

According to Eurostat, the unemployment rate was 5.7% in 2017. This places unemployment in Denmark somewhat below the EU average, which was 7.6%. 10 EU member countries had a lower unemployment rate than Denmark in 2017.

Altogether, total employment in 2017 amounted to 2,919,000 people according to Statistics Denmark.

The share of employees leaving jobs every year (for a new job, retirement or unemployment) in the private sector is around 30% – a level also observed in the U.K. and U.S.- but much higher than in continental Europe, where the corresponding figure is around 10%, and in Sweden. This attrition can be very costly, with new and old employees requiring half a year to return to old productivity levels, but with attrition bringing the number of people that have to be fired down.

As a small open economy, Denmark is very dependent on its foreign trade. In 2017, the value of total exports of goods and services made up 55% of GDP, whereas the value of total imports amounted to 47% of GDP. Trade in goods made up slightly more than 60% of both exports and imports, and trade in services the remaining close to 40%.

Machinery, chemicals and related products like medicine and agricultural products were the largest groups of export goods in 2017. Service exports were dominated by freight sea transport services from the Danish merchant navy. Most of Denmark's most important trading partners are neighbouring countries. The five main importers of Danish goods and services in 2017 were Germany, Sweden, United Kingdom, United States and Norway. The five countries from which Denmark imported most goods and services in 2017 were Germany, Sweden, the Netherlands, China and United Kingdom.

After having almost consistently an external balance of payments current account deficit since the beginning of the 1960s, Denmark has maintained a surplus on its BOP current account for every year since 1990, with the single exception of 1998. In 2017, the current account surplus amounted to approximately 8% of GDP. Consequently, Denmark has changed from a net debtor to a net creditor country. By 1 July 2018, the net foreign wealth or net international investment position of Denmark was equal to 64.6% of GDP, Denmark thus having the largest net foreign wealth relative to GDP of any EU country.

As the annual current account is equal to the value of domestic saving minus total domestic investment, the change from a structural deficit to a structural surplus is due to changes in these two national account components. In particular, the Danish national saving rate in financial assets increased by 11 per cent of GDP from 1980 to 2015. Two main reasons for this large change in domestic saving behaviour were the growing importance of large-scale compulsory pension schemes and several Danish fiscal policy reforms during the period which considerably decreased tax deductions of household interest expense, thus reducing the tax subsidy to private debt.

The Danish currency is the Danish krone, subdivided into 100 øre. The krone and øre were introduced in 1875, replacing the former rigsdaler and skilling. Denmark has a very long tradition of maintaining a fixed exchange-rate system, dating back to the period of the gold standard during the time of the Scandinavian Monetary Union from 1873 to 1914. After the breakdown of the international Bretton Woods system in 1971, Denmark devalued the krone repeatedly during the 1970s and the start of the 1980s, effectively maintaining a policy of "fixed, but adjustable" exchange rates. Rising inflation led to Denmark declaring a more consistent fixed exchange-rate policy in 1982. At first, the krone was pegged to the European Currency Unit or ECU, from 1987 to the Deutsche Mark, and from 1999 to the euro.

Although eligible, Denmark chose not to join the European Monetary Union when it was founded. In 2000, the Danish government advocated Danish EMU membership and called a referendum to settle the issue. With a turn-out of 87.6%, 53% of the voters rejected Danish membership. Occasionally, the question of calling another referendum on the issue has been discussed, but since the Financial crisis of 2007–2008 opinion polls have shown a clear majority against Denmark joining the EMU, and the question is not high on the political agenda presently.

Maintenance of the fixed exchange rate is the responsibility of Danmarks Nationalbank, the Danish central bank. As a consequence of the exchange rate policy, the bank must always adjust its interest rates to ensure a stable exchange rate and consequently cannot at the same time conduct monetary policy to stabilize e.g. domestic inflation or unemployment rates. This makes the conduct of stabilization policy fundamentally different from the situation in Denmark's neighbouring countries like Norway, Sweden, Poland and the United Kingdom, in which the central banks have a central stabilizing role. Denmark is presently the only OECD member country maintaining an independent currency with a fixed exchange rate. Consequently, the Danish krone is the only currency in the European Exchange Rate Mechanism II (ERM II), before Bulgaria and Croatia joined in 2020 (the latter uses the euro since 2023)

In the first months of 2015, Denmark experienced the largest pressure against the fixed exchange rate for many years because of very large capital inflows, causing a tendency for the Danish krone to appreciate. Danmarks Nationalbank reacted in various ways, chiefly by lowering its interest rates to record low levels. On 6 February 2015 the certificates of deposit rate, one of the four official Danish central bank rates, was lowered to −0.75%. In January 2016 the rate was raised to −0.65%, at which level it has been maintained since then.

Inflation in Denmark as measured by the official consumer price index of Statistics Denmark was 1.1% in 2017. Inflation has generally been low and stable for the last decades. Whereas in 1980 annual inflation was more than 12%, in the period 2000–2017 the average inflation rate was 1.8%.

Since a local-government reform in 2007, the general government organization in Denmark is carried out on three administrative levels: central government, regions, and municipalities. Regions administer mainly health care services, whereas municipalities administer primary education and social services. Municipalities in principle independently levy income and property taxes, but the scope for total municipal taxation and expenditure is closely regulated by annual negotiations between the municipalities and the Finance Minister of Denmark. At the central government level, the Ministry of Finance carries out the coordinating role of conducting economic policy. In 2012, the Danish parliament passed a Budget Law (effective from January 2014) which governs the over-all fiscal framework, stating among other things that the structural deficit must never exceed 0.5% of GDP, and that Danish fiscal policy is required to be sustainable, i.e. have a non-negative fiscal sustainability indicator. The Budget Law also assigned the role of independent fiscal institution (IFI, informally known as "fiscal watchdog") to the already-existing independent advisory body of the Danish Economic Councils.

Danish fiscal policy is generally considered healthy. Government net debt was close to zero at the end of 2017, amounting to DKK 27.3 billion, or 1.3% of GDP. The government sector having a fair amount of financial assets as well as liabilities, government gross debt amounted to 36.1% of GDP at the same date. The gross EMU-debt as percentage of GDP was the sixth-lowest among all 28 EU member countries, only Estonia, Luxembourg, Bulgaria, the Czech Republic and Romania having a lower gross debt. Denmark had a government budget surplus of 1.1% of GDP in 2017.

Long-run annual fiscal projections from the Danish government as well as the independent Danish Economic Council, taking into account likely future fiscal developments caused by demographic developments etc. (e.g. a likely ageing of the population caused by a considerable expansion of life expectancy), consider the Danish fiscal policy to be overly sustainable in the long run. In Spring 2018, the so-called Fiscal Sustainability Indicator was calculated to be 1.2 (by the Danish government) respectively 0.9% (by the Danish Economic Council) of GDP. This implies that under the assumptions employed in the projections, fiscal policy could be permanently loosened (via more generous public expenditures and/or lower taxes) by ca. 1% of GDP while still maintaining a stable government debt-to-GDP ratio in the long run.

The tax level as well as the government expenditure level in Denmark ranks among the highest in the world, which is traditionally ascribed to the Nordic model of which Denmark is an example, including the welfare state principles which historically evolved during the 20th century. In 2022, the official Danish tax level amounted to 42.2% of GDP. The all-record highest Danish tax level was 49.8% of GDP, reached in 2014 because of high extraordinary one-time tax revenues caused by a reorganization of the Danish-funded pension system. The Danish tax-to-GDP-ratio of 42% was the seventh-highest among all OECD countries in 2022, after France, Norway, Austria, Finland, Italy and Belgium. The OECD average was 34%. The tax structure of Denmark (the relative weight of different taxes) also differs from the OECD average, as the Danish tax system in 2015 was characterized by substantially higher revenues from taxes on personal income, whereas on the other hand, no revenues at all derive from social security contributions. A lower proportion of revenues in Denmark derive from taxes on corporate income and gains and property taxes than in OECD generally, whereas the proportion deriving from payroll taxes, VAT, and other taxes on goods and services correspond to the OECD average.

In 2016, the average marginal tax rate on labour income for all Danish tax-payers was 38.9%. The average marginal tax on personal capital income was 30.7%.

Professor of Economics at Princeton University Henrik Kleven has suggested that three distinct policies in Denmark and its Scandinavian neighbours imply that the high tax rates cause only relatively small distortions to the economy: 

in 2023, Denmark considered methods to increase taxes on energy dealers.

Parallel to the high tax level, government expenditures make up a large part of GDP, and the government sector carries out many different tasks. By September 2018, 831,000 people worked in the general government sector, corresponding to 29.9% of all employees. In 2017, total government expenditure amounted to 50.9% of GDP. Government consumption took up precisely 25% of GDP (e.g. education and health care expenditure), and government investment (infrastructure etc.) expenditure another 3.4% of GDP. Personal income transfers (for e.g. elderly or unemployed people) amounted to 16.8% of GDP.

Denmark has an unemployment insurance system called the A-kasse ("arbejdsløshedskasse"). This system requires a paying membership of a state-recognized unemployment fund. Most of these funds are managed by trade unions, and part of their expenses are financed through the tax system. Members of an A-kasse are not obliged to be members of a trade union. Not every Danish citizen or employee qualifies for a membership of an unemployment fund, and membership benefits will be terminated after 2 years of unemployment. A person that is not a member of an A-kasse cannot receive unemployment benefits. Unemployment funds do not pay benefits to sick members, who will be transferred to a municipal social support system instead. Denmark has a countrywide, but municipally administered social support system against poverty, securing that qualified citizens have a minimum living income. All Danish citizens above 18 years of age can apply for some financial support if they cannot support themselves or their family. Approval is not automatic, and the extent of this system has generally been diminished since the 1980s. Sick people can receive some financial support throughout the extent of their illness. Their ability to work will be re-evaluated by the municipality after 5 months of illness.

The welfare system related to the labor market has experienced several reforms and financial cuts since the late 1990s due to political agendas for increasing the labor supply. Several reforms of the rights of the unemployed have followed up, partially inspired by the Danish Economic Council. Halving the time unemployment benefits can be received from four to two years, and making it twice as hard to regain this right, was implemented in 2010 for example.

Disabled people can apply for permanent social pensions. The extent of the support depends on the ability to work, and people below 40 can not receive social pension unless they are deemed incapable of any kind of work.

Agriculture was once the most important industry in Denmark. Nowadays, it is of minor economic importance. In 2016, 62,000 people, or 2.5% of all employed people worked in agriculture and horticulture. Another 2,000 people worked in fishing. As value added per person is relatively low, the share of national value added is somewhat lower. Total gross value added in agriculture, forestry and fishing amounted to 1.6% of total output in Denmark (in 2017). Despite this, Denmark is still home to various types of agricultural production. Within animal husbandry, it includes dairy and beef cattle, pigs, poultry and fur animals (primarily mink) – all sectors that produce mainly for export. Regarding vegetable production, Denmark is a leading producer of grass-, clover- and horticultural seeds. The agriculture and food sector as a whole represented 25% of total Danish commodity exports in 2015.

63% of the land area of Denmark is used for agricultural production – the highest share in the world according to a report from University of Copenhagen in 2017. The Danish agricultural industry is historically characterized by freehold and family ownership, but due to structural development farms have become fewer and larger. In 2020 the number of farms was approximately 33,000, of which approximately 10,000 were owned by full-time farmers.

The tendency toward fewer and larger farms has been accompanied by an increase in animal production, using fewer resources per produced unit.

The number of dairy farmers has reduced to about 3,800 with an average herd size of 150 cows. The milk quota is 1,142 tonnes. Danish dairy farmers are among the largest and most modern producers in Europe. More than half of the cows live in new loose-housing systems. Export of dairy products accounts for more than 20 percent of the total Danish agricultural export. The total number of cattle in 2011 was approximately 1.5 million. Of these, 565,000 were dairy cows and 99,000 were suckler cows. The yearly number of slaughtering of beef cattle is around 550,000.

For more than 100 years the production of pigs and pig meat was a major source of income in Denmark. The Danish pig industry is among the world's leaders in areas such as breeding, quality, food safety, animal welfare and traceability creating the basis for Denmark being among the world's largest pig meat exporters. Approximately 90 percent of the production is exported. This accounts for almost half of all agricultural exports and for more than 5 percent of Denmark's total exports. About 4,200 farmers produce 28 million pigs annually. Of these, 20.9 million are slaughtered in Denmark.

Fur animal production on an industrial scale started in the 1930s in Denmark. Prior to a government-mandated culling during the COVID-19 pandemic, Denmark was the world's largest producer of mink furs, with 1,400 mink farmers fostering 17.2 million mink and producing around 14 million furs of the highest quality every year (see mink industry in Denmark). Approximately 98 percent of the skins sold at Kopenhagen Fur Auction were exported. Fur ranked as Danish agriculture's third largest export article, at more than DKK 7 billion annually. The number of farms peaked in the late 1980s at more than 5,000 farms, but the number has declined steadily since, as individual farms grew in size. Danish mink farmers claim their business to be sustainable, feeding the mink food industry waste and using all parts of the dead animal as meat, bone meal and biofuel. Special attention is given to the welfare of the mink, and regular "Open Farm" arrangements are made for the general public. Mink thrive in, but are not a native to Denmark, and it is considered an invasive species. American Mink are now widespread in Denmark and continues to cause problems for the native wildlife, in particular waterfowl. Denmark also has a small production of fox, chinchilla and rabbit furs.

Two hundred professional producers are responsible for the Danish egg production, which was 66 million kg in 2011. Chickens for slaughter are often produced in units with 40,000 broilers. In 2012, 100 million chickens were slaughtered. In the minor productions of poultry, 13 million ducks, 1.4 million geese and 5.0 million turkeys were slaughtered in 2012.

Organic farming and production has increased considerably and continuously in Denmark since 1987 when the first official regulations of this particular agricultural method came into effect. In 2017, the export of organic products reached DK 2.95 billion, a 153% increase from 2012 five years earlier, and a 21% increase from 2016. The import of organic products has always been higher than the exports though and reached DK 3.86 billion in 2017. After some years of stagnation, close to 10% of the cultivated land is now categorized as organically farmed, and 13.6% for the dairy industry, as of 2017.

Denmark has the highest retail consumption share for organic products in the world. In 2017, the share was at 13.3%, accounting for a total of DKK 12.1 billion.

Denmark has large proven reserves of oil and natural gas in the North Sea with Esbjerg being the main city for the oil and gas industry. Denmark is the largest producer of oil and natural gas in the EU. Production has decreased in recent years, though. Whereas in 2006 output (measured as gross value added or GVA) in mining and quarrying industries made up more than 4% of Denmark's total GVA, in 2017 it amounted to 1.2%. The sector is very capital-intensive, so the share of employment is much lower: About 2,000 persons worked in the oil and gas extraction sector in 2016, and another 1,000 persons in extraction of gravel and stone, or in total about 0.1% of total employment in Denmark.

Denmark houses a number of significant engineering and high-technology firms, within the sectors of industrial equipment, aerospace, robotics, pharmaceutical and electronics.

Danfoss, headquartered in Nordborg, designs and manufactures industrial electronics, heating and cooling equipment, as well as drivetrains and power solutions.

Denmark is also a large exporter of pumps, with the company Grundfos holding 50% of the market share, manufacturing circulation pumps.

In 2017 total output (gross value added) in manufacturing industries amounted to 14.4% of total output in Denmark. 325,000 people or a little less than 12% of all employed persons worked in manufacturing (including utilities, mining and quarrying) in 2016. Main sub-industries are manufacture of pharmaceuticals, machinery, and food products.

In 2017 total output (gross value added) in service industries amounted to 75.2% of total output in Denmark, and 79.9% of all employed people worked here (in 2016). Apart from public administration, education and health services, main service sub-industries were trade and transport services, and business services.

Significant investment has been made in building road and rail links between Copenhagen and Malmö, Sweden (the Øresund Bridge), and between Zealand and Funen (the Great Belt Fixed Link). The Copenhagen Malmö Port was also formed between the two cities as the common port for the cities of both nations.

The main railway operator is Danske Statsbaner (Danish State Railways) for passenger services and DB Schenker Rail for freight trains. The railway tracks are maintained by Banedanmark. Copenhagen has a small Metro system, the Copenhagen Metro and the greater Copenhagen area has an extensive electrified suburban railway network, the S-train.
Private vehicles are increasingly used as a means of transport. New cars are taxed by means of a registration tax (85% to 150%) and VAT (25%). The motorway network now covers 1,300 km.

Denmark is in a strong position in terms of integrating fluctuating and unpredictable energy sources such as wind power in the grid. It is this knowledge that Denmark now aims to exploit in the transport sector by focusing on intelligent battery systems (V2G) and plug-in vehicles.

Denmark has changed its energy consumption from 99% fossil fuels (92% oil (all imported) and 7% coal) and 1% biofuels in 1972 to 73% fossil fuels (37% oil (all domestic), 18% coal and 18% natural gas (all domestic)) and 27% renewables (largely biofuels) in 2015. The goal is a full independence of fossil fuels by 2050. This drastic change was initially inspired largely by the discovery of Danish oil and gas reserves in the North Sea in 1972 and the 1973 oil crisis. The course took a giant leap forward in 1984, when the Danish North Sea oil and gas fields, developed by native industry in close cooperation with the state, started major productions. In 1997, Denmark became self-sufficient with energy and the overall emission from the energy sector began to fall by 1996. Wind energy contribution to the total energy consumption has risen from 1% in 1997 to 5% in 2015.

Since 2000, Denmark has increased gross domestic product (GDP) and at the same time decreased energy consumption. Since 1972, the overall energy consumption has dropped by 6%, even though the GDP has doubled in the same period. Denmark had the 6th best energy security in the world in 2014. Denmark has had relatively high energy taxation to encourage careful use of energy since the oil crises in the 1970s, and Danish industry has adapted to this and gained a competitive edge. The so-called "green taxes" have been broadly criticised partly for being higher than in other countries, but also for being more of a tool for gathering government revenue than a method of promoting "greener" behaviour.

Denmark has low electricity costs (including costs for cleaner energy) in EU, but general taxes (11.7 billion DKK in 2015) make the electricity price for households the highest in Europe. , Denmark has no environment tax on electricity.

Denmark is a long-time leader in wind energy and a prominent exporter of Vestas and Siemens wind turbines, and in 2019 Denmark's exports of wind-turbine technology and services amounted to 8.9 billion. It has integrated fluctuating and less predictable energy sources such as wind power into the grid. Wind produced the equivalent of 43% of Denmark's total electricity consumption in 2017. The share of total energy production is smaller: In 2015, wind accounted for 5% of total Danish energy production.

Energinet.dk is the Danish national transmission system operator for electricity and natural gas. The electricity grids of western Denmark and eastern Denmark were not connected until 2010 when the 600MW Great Belt Power Link went into operation.

Cogeneration plants are the norm in Denmark, usually with district heating which serves 1.7 million households.

Waste-to-energy incinerators produce mostly heating and hot water. in Glostrup Municipality operates Denmark's largest incinerator, a cogeneration plant which supplies electricity to 80,000 households and heating equivalent to the consumption in 63,000 households (2016). Amager Bakke is an example of a new incinerator.

In addition to Denmark proper, the Kingdom of Denmark comprises two autonomous constituent countries in the North Atlantic Ocean: Greenland and the Faroe Islands. Both use the Danish krone as their currency, but form separate economies, having separate national accounts etc. Both countries receive an annual fiscal subsidy from Denmark which amounts to about 25% of Greenland's GDP and 11% of Faroese GDP. For both countries, fishing industry is a major economic activity.

Neither Greenland nor the Faroe Islands are members of the European Union. Greenland left the European Economic Community in 1986, and the Faroe Islands declined membership in 1973, when Denmark joined.

The following table shows the main economic indicators in 1980–2023. Inflation under 2% is in green.

Denmark has fostered and is home to many multi-national companies. Many of the largest are interdisciplinary with business – and sometimes research activities – in several fields. The most notable companies include:









Many of the largest food producers are also engaged in biotechnology and research. Notable companies dedicated to the pharmaceutical and biotechnology sector, includes:


Software



Denmark has a long tradition for cooperative production and trade on a large scale. The most notable cooperative societies today includes the agricultural coop of Dansk Landbrugs Grovvareselskab (DLG), dairy producer Arla Foods and the retail cooperative Coop Danmark. Coop Danmark started out as ""Fællesforeningen for Danmarks Brugsforeninger"" (FDB) in 1896 and now has around 1.4 million members in Denmark as of 2017. It is part of the larger multi-sector cooperative Coop amba which has 1.7 million members in that same year.

The cooperative structure also extends to both the housing and banking sector. Arbejdernes Landsbank, founded in 1919, is the largest bank cooperative and it is currently the 6th largest bank in the country as of 2018. The municipality of Copenhagen alone holds a total of 153 housing cooperatives and ""Arbejdernes Andelsboligforening Århus"" (AAB Århus) is the largest individual housing cooperative in Denmark, with 23,000 homes in Aarhus.

In 2022, the sector with the highest number of companies registered in Denmark is Finance, Insurance, and Real Estate with 204,853 companies followed by Services and Retail Trade with 204,050 and 30,563 companies respectively.




Transport in Denmark

Transport in Denmark is developed and modern. The motorway network covers 1,111 km while the railway network totals 2,667 km of operational track. The Great Belt Fixed Link (opened in 1997) connecting the islands of Zealand and Funen and the New Little Belt Bridge (opened in 1970) connecting Funen and Jutland greatly improved the traffic flow across the country on both motorways and rail. The two largest airports of Copenhagen and Billund provide a variety of domestic and international connections, while ferries provide services to the Faroe Islands, Greenland, Iceland, Germany, Sweden, and Norway, as well as domestic routes servicing most Danish islands.

In 2011, a total of appr. 28 million passengers used Danish airports.

Copenhagen Airport is the largest airport in Scandinavia, handling approximately 29m passengers per year (2016). It is located at Kastrup, 8 km south-east of central Copenhagen. It is connected by train to Copenhagen Central Station and beyond as well as to Malmö and other towns in Sweden.

For the west of the country, the major airport is Billund (3m passengers in 2016) although both Aalborg (1.4m passengers in 2011) and Aarhus (591.000 passengers in 2011) have smaller airports with regular connections to Copenhagen.

Denmark's main airports are:


Other airports include: 

Being an island state with a long coastline and always close to the sea, maritime transport has always been important in Denmark. From the primitive dugouts of the Stone Age to the complex designs of the Viking ships in the Viking Age, often built to exactly facilitate large scale cargo and passenger transportation. Denmark also engaged in the large scale cargo freights and slave transports of the European colonization endeavours in the Middle Ages and operated several smaller colonies of its own across the globe by the means of seafaring.

Today Denmark's ports handle some 48 million passengers and 109 million tonnes of cargo per year.

Passenger traffic is made up partly of ferry crossings within Denmark, partly of international ferry crossings and partly of cruise ship passengers. Some short ferry routes are being electrified and several more may be eligible, as in Norway.

Among the most important ports for passenger traffic (thousands of passengers per year in 2007) are:

In 2007, 288 cruise ships visited Copenhagen, rising to 376 in 2011 before returning to around 300 the following years. Around 800,000 cruise passengers and 200,000 crew visit Copenhagen each year.

Among the most important ports for cargo traffic (millions of tonnes per year in 2007) are:

Waterways have historically and traditionally been crucial to local transportation in Denmark proper. Especially the Gudenå river-system in central Jutland, has played an important role. The waterways were navigated by wooden barges and later on steamboats. A few historical steamboats are still in operation, like the SS Hjejlen from 1861 at Silkeborg.

There is a 160 km natural canal through the shallow Limfjorden in northern Jutland, linking the North Sea to the Kattegat.

Many waterways has formerly been redirected and led through manmade canals in the 1900s, but mainly for agricultural purposes and not to facilitate transportation on any major scale. Several cities have manmade canals used for transportation and traffic purposes. Of special mention are the and the Odense Canal, ferrying large numbers of both tourists and local citizens.

Denmark has a large merchant fleet relative to its size. In 2018, the fleet surpassed 20 million gt as the government sought to repatriate Danish-owned tonnage registered abroad, with measures including removal of the registration fee.

Denmark has created its own international register, called the Danish International Ship register (DIS), open to commercial vessels only. DIS ships do not have to meet Danish manning regulations.

The largest railway operator in Denmark is Danske Statsbaner (DSB) — Danish State Railways. Arriva operates some routes in Jutland, and several other smaller operators provide local services.

The total length of operational track is 3,476 km standard gauge, with 1,756 km electrified.

The railway system is connected to Sweden by bridge in Copenhagen and ferry in Helsingør and Frederikshavn, by land to Germany in Padborg and ferry in Rødby and to Norway by ferry in Hirtshals.

The road network in 2017 totalled 74,558 km of paved road. Motorways are toll-free except for the Great Belt Bridge joining Zealand and Funen and the Øresund Bridge linking Copenhagen to Malmö in Sweden.

Bicycling in Denmark is a common and popular utilitarian and recreational activity. Bicycling infrastructure is a dominant feature of both city and countryside infrastructure, with bicycle paths and bicycle ways in many places and an extensive network of bicycle routes, extending more than nationwide. In comparison, Denmark's coastline is . As a unique feature, Denmark has a VIN-system for bicycles which is mandatory by law. Often bicycling and bicycle culture in Denmark is compared to the Netherlands as a bicycle-nation.

Figures in 2015:



Danish Defence

The Danish Armed Forces (; ; ) is the unified armed forces of the Kingdom of Denmark charged with the defence of Denmark and its self-governing territories Greenland and the Faroe Islands. The military also promote Denmark's wider interests, support international peacekeeping efforts and provide humanitarian aid.

Since the creation of a standing military in 1510, the armed forces have seen action in many wars, most involving Sweden, but also involving the world's great powers, including the Thirty Years' War, the Great Northern War, and the Napoleonic Wars.

Today, the armed forces consists of: the Royal Danish Army, Denmark's principal land warfare branch; the Royal Danish Navy, a blue-water navy with a fleet of 20 commissioned ships; and the Royal Danish Air Force, an air force with an operational fleet consisting of both fixed-wing and rotary aircraft. The Defence also includes the Home Guard. Under the Danish Defence Law the Minister of Defence serves as the commander of Danish Defence (through the Chief of Defence and the Defence Command) and the Danish Home Guard (through the Home Guard Command). De facto the Danish Cabinet is the commanding authority of the Defence, though it cannot mobilize the armed forces, for purposes that are not strictly defence oriented, without the consent of parliament.

The history of the Danish military is deeply intertwined with the nation's geopolitical dynamics and historical events. The modern Danish military, which traces its roots back to the early 16th century, has undergone significant transformations, reflecting changes in Denmark's territorial extent, political landscape, and strategic priorities.

Early History and Territorial Influence (1510 Onwards):

- The foundation of the Royal Danish Navy in 1510 marked the beginning of a formal military structure in Denmark. This period saw the Danish Kingdom as a considerable force in Northern Europe, holding territories like Schleswig-Holstein, Norway, and overseas colonies in Africa and the Americas.

- The military power during this era was essential for protecting these territories and maintaining Denmark's influence in regional affairs.

Second Schleswig War and its Aftermath:

- The Second Schleswig War (1864), in which Denmark suffered defeat, had profound implications on its military and political landscape. This conflict, primarily over the control of the duchies of Schleswig and Holstein, led to significant territorial losses.

- The war's outcome turned the military into a politically contentious issue, sparking debates on defense strategies and military preparedness.

World War I and Interwar Period:

- During World War I, Denmark successfully maintained its neutrality, supported by a relatively strong military. This period was marked by cautious diplomacy and a focus on defending the nation's sovereignty without direct involvement in the conflict.

- However, the Interwar period saw a shift in government policy towards pacifism. This ideological change resulted in the reduction of the military's size and capabilities, reflecting a broader European trend towards disarmament after the devastation of World War I.

World War II and Organizational Transformation:

- The limited state of the Danish military in 1940 became a significant concern when Denmark faced invasion and subsequent occupation by Nazi Germany. This period highlighted the vulnerabilities and challenges of a small, under-prepared military force.

- Prior to and during World War II, the Danish military operated with distinct branches (army and navy), each with its separate ministry and even air force units. This fragmented structure was not conducive to effective joint operations.

Post-World War II Reforms and Modernization:

- Learning from the experiences of World War II, Denmark undertook a significant reorganization of its military. The branches were unified under the Danish Defence, established to centralize command and improve coordination in joint operations.

- This reorganization marked a critical shift in Denmark's military strategy, focusing on cohesive defense planning and operational synergy between the different military branches.

Contemporary Focus and International Role:

- In the contemporary period, the Danish military plays a vital role in international peacekeeping and NATO operations, reflecting Denmark's commitment to global security and cooperation.

- The modern Danish Defence is a testament to the nation's adaptability and resilience, evolving from its historic roots into a modern, integrated force capable of addressing both national defense needs and international responsibilities.

Overall, the evolution of the Danish military is a reflection of the nation's changing geopolitical circumstances, strategic priorities, and lessons learned from historical conflicts. This transformation has shaped Denmark's approach to defense, emphasizing unity, coordination, and a balance between national interests and international obligations.

Denmark tried to remain neutral after World War II, with the proposed Scandinavian defence union. However, Norway resigned from the talks, and with Cold War tensions on the rise and the 1948 Easter Crisis, Denmark was forced to join the North Atlantic Treaty. During the Cold War, Denmark began to rebuild its military and to prepare for possible attacks by the Soviet Union and its Warsaw Pact allies. During this time Denmark participated in a number of UN peacekeeping missions including UNEF and UNFICYP.

Following the end of the Cold War, Denmark began a more active foreign policy, deciding to participate in international operations. This began with the participation in the Bosnian War, where the Royal Danish Army served as part of the United Nations Protection Force and were in two skirmishes. This was the first time the Danish Army was a part of a combat operation since World War 2. On April 29, 1994, the Royal Danish Army, while on an operation to relieve an observation post as part of the United Nations Protection Force, the Jutland Dragoon Regiment came under artillery fire from the town of Kalesija. The United Nations Protection Force quickly returned fire and eliminated the artillery positions. On October 24, 1994, the Royal Danish Army, while on an operation to reinforce an observation post in the town of Gradačac, were fired upon by a T-55 Bosnian Serb tank. One of the three Danish Leopard 1 tanks experienced slight damage, but all returned fired and put the T-55 tank out of action.

With the September 11 attacks, Denmark joined US forces in the War on terror, participating in both the War in Afghanistan and the Iraq War. In Afghanistan, 37 soldiers have been killed in various hostile engagements or as a result of friendly fire, and 6 have been killed in non-combat related incidents, bringing the number of Danish fatalities to 43, being the highest loss per capita within the coalition forces. Denmark has since participated in Operation Ocean Shield, the 2011 military intervention in Libya and the American-led intervention in the Syrian Civil War.

The purpose of the Danish Defence is to prevent conflicts and war, preserve the sovereignty of Denmark, secure the continuing existence and integrity of the independent Kingdom of Denmark and further a peaceful development in the world with respect to human rights. This is defined in Law no. 122 of 27 February 2001 which took effect 1 March 2001.

Its primary tasks are: NATO participation in accordance with the strategy of the alliance, detect and repel any sovereignty violation of Danish territory (including Greenland and the Faroe Islands), defence cooperation with non-NATO members, especially Central and East European countries, international missions in the area of conflict prevention, crisis-control, humanitarian, peacemaking, peacekeeping, participation in "Total Defence" in cooperation with civilian resources and finally maintenance of a sizable force to execute these tasks at all times.

Total Defence () is "the use of all resources in order to maintain an organized and functional society, and to protect the population and values of society". This is achieved by combining the military, Home Guard, Danish Emergency Management Agency and elements of the police. The concept of total defence was created following World War II, where it was clear that the defence of the country could not only rely on the military, but there also need to be other measures to ensure a continuation of society. As a part of the Total Defence, all former conscripts can be recalled to duty, in order to serve in cases of emergency.

Since 1988, Danish defence budgets and security policy have been set by multi-year white paper agreements supported by a wide parliamentary majority including government and opposition parties. However, public opposition to increases in defence spending—during periods of economic constraints require reduced spending for social welfare — has created differences among the political parties regarding a broadly acceptable level of new defence expenditure.

The latest Defence agreement ("Defence Agreement 2018–23") was signed 28 January 2018, and calls for an increase in spending, cyber security and capabilities to act in international operations and international stabilization efforts. The reaction speed is increased, with an entire brigade on standby readiness; the military retains the capability to continually deploy 2,000 soldiers in international service or 5,000 over a short time span. The standard mandatory conscription is expanded to include 500 more, with some of these having a longer service time, with more focus on national challenges.

In 2006 the Danish military budget was the fifth largest single portion of the Danish Government's total budget, significantly less than that of the Ministry of Social Affairs (≈110 billion DKK), Ministry of Employment (≈67 billion DKK), Ministry of the Interior and Health (≈66 billion DKK) and Ministry of Education (≈30 billion DKK) and only slightly larger than that of the Ministry of Science, Technology and Innovation (≈14 billion DKK). This list lists the complete expenditures for the Danish Ministry of Defence.

The Danish Defence Force, counting all branches and all departments, itself has an income equal to about 1–5% of its expenditures, depending on the year. They are not deducted in this listing.

Approximately 95% of the budget goes directly to running the Danish military including the Home guard. Depending on year, 50–53% accounts for payment to personnel, roughly 14–21% on acquiring new material, 2–8% for larger ships, building projects or infrastructure and about 24–27% on other items, including purchasing of goods, renting, maintenance, services and taxes.

The remaining 5% is special expenditures to NATO, branch shared expenditures, special services and civil structures, here in including running the Danish Maritime Safety Administration, Danish Emergency Management Agency and the Administration of Conscientious Objectors (Militærnægteradministrationen ).

Because Denmark has a small and highly specialized military industry, the vast majority of Danish Defence's equipment is imported from NATO and the Nordic countries.

Danish Defence expenditures (1949–1989)
Danish Defence expenditures (1990–)

The Danish Royal Army () consists of 2 brigades, organised into 3 regiments, and a number of support centres, all commanded through the Army Staff. The army is a mixture of Mechanized infantry and Armoured cavalry with a limited capabilities in Armoured warfare.

The army also provides protection for the Danish royal family, in the form of the Royal Guard Company and the Guard Hussar Regiment Mounted Squadron.

The Royal Danish Navy () consists of frigates, patrol vessels, mine-countermeasure vessels, and other miscellaneous vessels, many of which are issued with the modular mission payload system StanFlex. The navy's chief responsibility is maritime defence and maintaining the sovereignty of Danish, Greenlandic and Faroese territorial waters.

A submarine service existed within the Royal Danish Navy for 95 years.

The Royal Danish Air Force () consists of both fixed-wing and rotary aircraft.

The Home Guard is voluntary service responsible for defence of the country, but has since 2008 also supported the army, in Afghanistan and Kosovo.



Current deployment of Danish forces, per 10-03-2016:





Women in the military can be traced back to 1946, with the creation of "Lottekorpset". This corps allowed women to serve, however, without entering with the normal armed forces, and they were not allowed to carry weapons. In 1962, women were allowed in the military.

Currently 1,122 or 7.3% of all personnel in the armed forces are women. Women do not have to serve conscription in Denmark, since 1998, it is however possible to serve under conscription-like circumstances; 17% of those serving conscription or conscription-like are women. Between 1991 and 31 December 2017, 1,965 women have been deployed to different international missions. Of those 3 women have lost their lives. In 1998, Police Constable Gitte Larsen was killed in Hebron on the West Bank. In 2003, "Overkonstabel" Susanne Lauritzen was killed in a traffic accident in Kosovo. In 2010, the first woman was killed in a combat situation, when "Konstabel" Sophia Bruun was killed by an IED in Afghanistan.

In 2005, Line Bonde became the first female fighter pilot in Denmark. In 2016, Lone Træholt became the first female general. She was the only female general in the Danish armed forces until the army promoted Jette Albinus to the rank of brigadier general on 11 September 2017.
In May 2018, the Royal Life Guards was forced to lower the height requirements for women, as the Danish Institute of Human Rights decided it was discrimination.

Technically all Danish 18-year-old males are conscripts (37,897 in 2010, of whom 53% were considered suitable for duty). Due to the large number of volunteers, 96-99% of the number required in the past three years, the number of men actually called up is relatively low (4,200 in 2012). There were additionally 567 female volunteers in 2010, who pass training on "conscript-like" conditions.

Conscripts to Danish Defence (army, navy and air force) generally serve four months, except:

There has been a right of conscientious objection since 1917.




Foreign relations of Denmark

The foreign policy of Denmark is based on its identity as a sovereign state in Europe, the Arctic and the North Atlantic. As such its primary foreign policy focus is on its relations with other nations as a sovereign state compromising the three constituent countries: Denmark, Greenland and the Faroe Islands. Denmark has long had good relations with other nations.
It has been involved in coordinating Western assistance to the Baltic states (Estonia, Latvia, and Lithuania). 

The country is a strong supporter of international peacekeeping. Danish forces were heavily engaged in the former Yugoslavia in the UN Protection Force (UNPROFOR), with IFOR, and now SFOR. Denmark also strongly supported American operations in Afghanistan and has contributed both monetarily and materially to the ISAF. These initiatives are a part of the "active foreign policy" of Denmark. 

Instead of the traditional adaptative foreign policy of The unity of the Realm, Kingdom of Denmark is today pursuing an active foreign policy, where human rights, democracy and other crucial values are to be defended actively. In recent years, Greenland and the Faroe Islands have been guaranteed a say in foreign policy issues, such as fishing, whaling and geopolitical concerns.

Following World War II, Denmark ended its two-hundred-year-long policy of neutrality. Denmark has been a member of NATO since its founding in 1949, and membership in NATO remains highly popular. There were several serious confrontations between the U.S. and Denmark on security policy in the so-called "footnote era" (1982–88), when an alternative parliamentary majority forced the government to adopt specific national positions on nuclear and arms control issues. 

The alternative majority in these issues was because the Social liberal Party (Radikale Venstre) supported the governing majority in economic policy issues, but was against certain NATO policies and voted with the left in these issues. The conservative led Centre-right government accepted this variety of "minority parliamentarism", that is, without making it a question of the government's parliamentary survival.
With the end of the Cold War, Denmark has been supportive of U.S. policy objectives in the Alliance.

Danes have a reputation as "reluctant" Europeans. When they rejected ratification of the Maastricht Treaty on 2 June 1992, they put the EC's plans for the European Union on hold. In December 1992, the rest of the EC agreed to exempt Denmark from certain aspects of the European Union, including a common security and defense policy, a common currency, EU citizenship, and certain aspects of legal cooperation. The Amsterdam Treaty was approved in the referendum of 28 May 1998. 

In the autumn of 2000, Danish citizens rejected membership of the Euro currency group in a referendum. The Lisbon treaty was ratified by the Danish parliament alone. It was not considered a surrendering of national sovereignty, which would have implied the holding of a referendum according to article 20 of the constitution.

In 1807 Denmark was neutral but Britain bombarded Copenhagen and seized the Danish Navy, Denmark became an ally of Napoleon. After Napoleon was profoundly defeated in Russia in 1812, the Allies repeatedly offered King Frederick VI a proposal to change sides and break with Napoleon. The king refused. Therefore, at the peace of Kiel in 1814, Denmark was forced to cede Norway to Sweden. Denmark thus became one of the chief losers of the Napoleonic Wars. Danish historiography portrayed King Frederick VI as stubborn and incompetent, and motivated by a blind loyalty to Napoleon. A more recent Danish historiographical approach emphasizes the Danish state was multi-territorial, and included the semi – separate Kingdom of Norway. It was dependent for food on grain imports controlled by Napoleon, and worried about Swedish ambitions. From the king's perspective, these factors called for an alliance with Napoleon. Furthermore, the king expected the war would end in a negotiated international conference, with Napoleon playing a powerful role that included saving Norway for Denmark.

The Danish government responded to the First World War by declaring neutrality 1914–1918. It maintained that status until 1945 and accordingly adjusted trade; humanitarianism; diplomacy; and attitudes. The war thus reshaped economic relations and shifting domestic power balances.

Since the end of the Cold War, Denmark has become more supportive of U.S. foreign policy. Denmark supported the U.S. invasion of Iraq in 2003 and contributed assets to the invasion. Denmark also participated in the Afghanistan War. Denmark increased its participation in military and peacekeeping operations compared to the pre-Cold War period. Whereas Denmark only participated in 13 military operations from 1945 to 1989, Denmark participated in 76 military operations between 1990 and 2018.



List of countries which Denmark maintains diplomatic relations with:





History of Djibouti

Djibouti is a country in the Horn of Africa bordered by Somaliland to the east, Eritrea to west and the Red Sea to the north, Ethiopia to the west and south, and the Gulf of Aden to the east.

In antiquity, the territory was part of the Land of Punt. Djibouti gained its independence on June 27, 1977. The Djibouti area, along with other localities in the Horn region, was later the seat of the medieval Adal and Ifat Sultanates. In the late 19th century, the colony of French Somaliland was established following treaties signed by the ruling Somali and Afar Sultans with the French. It was subsequently renamed to the French Territory of the Afars and the Issas in 1967. A decade later, the Djiboutian people voted for independence, officially marking the establishment of the Republic of Djibouti.

The Bab-el-Mandeb region has often been considered a primary crossing point for early hominins following a southern coastal route from East Africa to South Arabia and Southeast Asia.

Djibouti area has been inhabited since the Neolithic. According to linguists, the first Afroasiatic-speaking populations arrived in the region during this period from the family's proposed urheimat ("original homeland") in the Nile Valley, or the Near East. Other scholars propose that the Afroasiatic family developed in situ in the Horn, with its speakers subsequently dispersing from there.

The cut stones 3 million years old, collected in the area of Lake Abbe. In the Gobaad plain (between Dikhil and Lake Abbe), the remains of an Palaeoloxodon recki elephant were also discovered, visibly butchered using basalt tools found nearby. These remains would date from 1.4 million years BC. Subsequently identified other sites of these cuts, probably the work of Homo ergaster. An Acheulean site (from 800,000 to 400,000 years BC), where stone was cut, was excavated in the 1990s, in Gombourta, between Damerdjog and Loyada, 15 km south of Djibouti. Finally, in Gobaad, a Homo erectus jaw was found, dating from 100,000 BC. AD On Devil's Island, tools dating back 6,000 years have been found, which were no doubt used to open shells. In the area at the bottom of Goubet (Dankalélo, not far from Devil's Island), circular stone structures and fragments of painted pottery have also been discovered. Previous investigators have also reported a fragmentary maxilla, attributed to an older form of Homo sapiens and dated to ~250 Ka, from the valley of the Dagadlé Wadi.

Pottery predating the mid-2nd millennium has been found at Asa Koma, an inland lake area on the Gobaad Plain. The site's ware is characterized by punctate and incision geometric designs, which bear a similarity to the Sabir culture phase 1 ceramics from Ma'layba in Southern Arabia. Long-horned humpless cattle bones have likewise been discovered at Asa Koma, suggesting that domesticated cattle were present by around 3,500 years ago. Rock art of what appear to be antelopes and a giraffe are also found at Dorra and Balho. Handoga, dated to the fourth millennium BP, has in turn yielded obsidian microliths and plain ceramics used by early nomadic pastoralists with domesticated cattle.

The site of Wakrita is a small Neolithic establishment located on a wadi in the tectonic depression of Gobaad in Djibouti in the Horn of Africa. The 2005 excavations yielded abundant ceramics that enabled us to define one Neolithic cultural facies of this region, which was also identified at the nearby site of Asa Koma. The faunal remains confirm the importance of fishing in Neolithic settlements close to Lake Abbé, but also the importance of bovine husbandry and, for the first time in this area, evidence for caprine herding practices. Radiocarbon dating places this occupation at the beginning of the 2nd millennium BC, similar in range to Asa Koma. These two sites represent the oldest evidence of herding in the region, and they provide a better understanding of the development of Neolithic societies in this region.

Up to 4000 years BC. AD, the region benefited from a climate very different from the one it knows today and probably close to the Mediterranean climate. The water resources were numerous: lakes in the Gobaad, lakes Assal and Abbé larger and resembling real bodies of water. The humans therefore lived by gathering, fishing and hunting. The region was populated by a very rich fauna: felines, buffaloes, elephants, rhinos, etc., as evidenced, for example, by the bestiary of cave paintings at Balho. In the 3rd and 2nd millennia BC. A few nomads settled around the lakes and practiced fishing and cattle breeding. The burial of an 18-year-old woman, dating from this period, as well as the bones of hunted animals, bone tools and small jewels have been unearthed. About 1500 BC. AD, the climate is already changing, water is scarce. Engravings show dromedaries (animal of arid zones), some of which are ridden by armed warriors. Sedentary peoples return to Nomadic life. A stone tumuli (of various shapes), sheltering graves and dating from this period, have been unearthed all over the territory.

Together with Somaliland, Eritrea and the Red Sea coast of Sudan, Djibouti is considered the most likely location of the land known to the ancient Egyptians as "Punt" (or "Ta Netjeru", meaning "God's Land"). The old territory's first mention dates to the 25th century BC. The Puntites were a nation of people that had close relations with Ancient Egypt during the times of Pharaoh Sahure of the fifth dynasty and Queen Hatshepsut of the eighteenth dynasty. They "traded not only in their own produce of incense, ebony and short-horned cattle, but also in goods from other neighbouring regions, including gold, ivory and animal skins." According to the temple reliefs at Deir el-Bahari, the Land of Punt at the time of Hatshepsut was ruled by King Parahu and Queen Ati.

The Macrobians (Μακροβίοι) were a legendary people and kingdom positioned in the Horn of Africa mentioned by Herodotus. Later authors (such as Pliny on the authority of Ctesias' "Indika") place them in India instead. It is one of the legendary peoples postulated at the extremity of the known world (from the perspective of the Greeks), in this case in the extreme south, contrasting with the Hyperboreans in the extreme east.

Their name is due to their legendary longevity; an average person supposedly living to the age of 120. They were said to be the "tallest and handsomest of all men".

According to Herodotus' account, the Persian Emperor Cambyses II upon his conquest of Egypt (525 BC) sent ambassadors to Macrobia, bringing luxury gifts for the Macrobian king to entice his submission. The Macrobian ruler, who was elected based at least in part on stature, replied instead with a challenge for his Persian counterpart in the form of an unstrung bow: if the Persians could manage to string it, they would have the right to invade his country; but until then, they should thank the gods that the Macrobians never decided to invade their empire.

The rule of the Aksumite Kingdom may have at times extended to areas that are now within Djibouti, though the nature and extent of its control are not clear.

Islam was introduced to the area early on from the Arabian peninsula, shortly after the hijra. Zeila's two-mihrab Masjid al-Qiblatayn dates to the 7th century, and is the oldest mosque in the city. In the late 9th century, Al-Yaqubi wrote that Muslims were living along the northern Horn seaboard. He also mentioned that the Adal kingdom had its capital in Zeila, a port city in the northwestern Awdal region abutting Djibouti. This suggests that the Adal Sultanate with Zeila as its headquarters dates back to at least the 9th or 10th century. According to I.M. Lewis, the polity was governed by local dynasties consisting of Somalized Arabs or Arabized Somalis, who also ruled over the similarly established Sultanate of Mogadishu in the Benadir region to the south. Adal's history from this founding period forth would be characterized by a succession of battles with neighbouring Abyssinia. At its height, the Adal kingdom controlled large parts of modern-day Djibouti, Somaliland, Eritrea and Ethiopia. Between Djibouti City and Loyada are a number of anthropomorphic and phallic stelae. The Djibouti-Loyada stelae are of uncertain age, and some of them are adorned with a T-shaped symbol. Additionally, archaeological excavations at Tiya have yielded tombs. As of 1997, 118 stelae were reported in the area.

The Ifat Sultanate was a medieval kingdom in the Horn of Africa. Founded in 1285 by the Walashma dynasty, it was centered in Zeila. Ifat established bases in Djibouti and Somaliland, and from there expanded southward to the Ahmar Mountains. Its Sultan Umar Walashma (or his son Ali, according to another source) is recorded as having conquered the Sultanate of Shewa in 1285. Taddesse Tamrat explains Sultan Umar's military expedition as an effort to consolidate the Muslim territories in the Horn, in much the same way as Emperor Yekuno Amlak was attempting to unite the Christian territories in the highlands during the same period. These two states inevitably came into conflict over Shewa and territories further south. A lengthy war ensued, but the Muslim sultanates of the time were not strongly unified. Ifat was finally defeated by Emperor Amda Seyon I of Ethiopia in 1332, and withdrew from Shewa.

Governor Abou Baker ordered the Egyptian garrison at Sagallo to retire to Zeila. The cruiser Seignelay reached Sagallo shortly after the Egyptians had departed. French troops occupied the fort despite protests from the British Agent in Aden, Major Frederick Mercer Hunter, who dispatched troops to safeguard British and Egyptian interests in Zeila and prevent further extension of French influence in that direction.
On 14 April 1884 the Commander of the patrol sloop L’Inferent reported on the Egyptian occupation in the Gulf of Tadjoura. The Commander of the patrol sloop Le Vaudreuil reported that the Egyptians were occupying the interior between Obock and Tadjoura. Emperor Johannes IV of Ethiopia signed an accord with the United Kingdom to cease fighting the Egyptians and to allow the evacuation of Egyptian forces from Ethiopia and the Somali Coast ports.
The Egyptian garrison was withdrawn from Tadjoura. Léonce Lagarde deployed a patrol sloop to Tadjoura the following night.

The boundaries of the present-day Djibouti nation state were established during the Scramble for Africa. It was Rochet d'Hericourt's exploration into Shoa (1839–42) that marked the beginning of French interest in the Djiboutian coast of the Red Sea. Further exploration by Henri Lambert, French Consular Agent at Aden, and Captain Fleuriot de Langle led to a treaty of friendship and assistance between France and the sultans of Raheita, Tadjoura, and Gobaad, from whom the French purchased the anchorage of Obock in 1862.

Growing French interest in the area took place against a backdrop of British activity in Egypt and the opening of the Suez Canal in 1869. Between 1883 and 1887, France signed various treaties with the then ruling Somali and Afar Sultans, which allowed it to expand the protectorate to include the Gulf of Tadjoura. Léonce Lagarde was subsequently installed as the protectorate's governor. In 1894, he established a permanent French administration in the city of Djibouti and named the region "Côte française des Somalis" (French Somaliland), a name which continued until 1967. The territory's border with Ethiopia, marked out in 1897 by France and Emperor Menelik II of Ethiopia, was later reaffirmed by agreements with Emperor Haile Selassie I of Ethiopia in 1945 and 1954.

In 1889, a Russian by the name of Nikolay Ivanovitch Achinov (b. 1856), arrived with settlers, infantry and an Orthodox priest to Sagallo on the Gulf of Tadjoura. The French considered the presence of the Russians as a violation of their territorial rights and dispatched two gunboats. The Russians were bombarded and after some loss of life, surrendered. The colonists were deported to Odessa and the dream of Russian expansion in East Africa came to an end in less than one year.
The administrative capital was moved from Obock in 1896. The city of Djibouti, which had a harbor with good access that attracted trade caravans crossing East Africa, became the new administrative capital. The Franco-Ethiopian railway, linking Djibouti to the heart of Ethiopia, began in 1897 and reached Addis Ababa in June 1917, increasing the volume of trade passing through the port.

After the Italian invasion and occupation of Ethiopia in the mid-1930s, constant border skirmishes occurred between French forces in French Somaliland and Italian forces in Italian East Africa. In June 1940, during the early stages of World War II, France fell and the colony was then ruled by the pro-Axis Vichy (French) government while the Italians occupied some areas of the French Smaliland.

Indeed the Italians did undertake some offensive actions beginning on 18 June 1940, occupying nearly one third of French Somaliland in a few days. 

From Harrar Governorate, troops under General Guglielmo Nasi attacked the fort of Ali-Sabieh in the south and Dadda'to in the north. There were also skirmishes in the area of Dagguirou and around the lakes Abbe and Ally. Near Ali-Sabieh, there was some skirmishing over the Djibouti–Addis Ababa railway. In the first week of war, the Italian Navy sent the submarines "Torricelli" and "Perla" to patrol French territorial waters in the Gulf of Tadjoura in front of the ports of Djibouti, Tadjoura and Obock.

By the end of June the Italians had also occupied the border fortifications of Magdoul, Daimoli, Balambolta, Birt Eyla, Asmailo, Tewo, Abba, Alailou, Madda and Rahale.

Later, British and Commonwealth forces fought the neighboring Italians during the East African Campaign. In 1941, the Italians were defeated and the Vichy forces in French Somaliland were isolated. The Vichy French administration continued to hold out in the colony for over a year after the Italian collapse. In response, the British blockaded the port of Djibouti City but it could not prevent local French from providing information on the passing ship convoys. In 1942, about 4,000 British troops occupied the city. A local battalion from French Somaliland participated in the Liberation of Paris in 1944.

In 1958, on the eve of neighboring Somalia's independence in 1960, a referendum was held in Djibouti to decide whether to be an independent country or to remain with France. The referendum turned out in favour of a continued association with France, partly due to a combined yes vote by the sizable Afar ethnic group and resident Europeans. There were also reports of widespread vote rigging, with the French expelling thousands of Somalis before the referendum reached the polls. The majority of those who voted no were Somalis who were strongly in favour of joining a united Somalia as had been proposed by Mahmoud Harbi, Vice President of the Government Council. Harbi died in a plane crash two years later under mysterious circumstances.

In 1960, with the fall of the ruling Dini administration, Ali Aref Bourhan, a Harbist politician, assumed the seat of Vice President of the Government Council of French Somaliland, representing the UNI party. He would hold that position until 1966.

That same year, France rejected the United Nations' recommendation that it should grant French Somaliland independence. In August, an official visit to the territory by then French President, General Charles de Gaulle, was also met with demonstrations and rioting. In response to the protests, de Gaulle ordered another referendum.

On 19 March 1967, a second plebiscite was held to determine the fate of the territory. Initial results supported a continued but looser relationship with France. Voting was also divided along ethnic lines, with the resident Somalis generally voting for independence, with the goal of eventual reunion with Somalia, and the Afars largely opting to remain associated with France. However, the referendum was again marred by reports of vote rigging on the part of the French authorities, with some 10,000 Somalis deported under the pretext that they did not have valid identity cards. According to official figures, although the territory was at the time inhabited by 58,240 Somali and 48,270 Afar, only 14,689 Somali were allowed to register to vote versus 22,004 Afar. Somali representatives also charged that the French had simultaneously imported thousands of Afar nomads from neighboring Ethiopia to further tip the odds in their favor, but the French authorities denied this, suggesting that Afars already greatly outnumbered Somalis on the voting lists. Announcement of the plebiscite results sparked civil unrest, including several deaths. France also increased its military force along the frontier.

In 1967, shortly after the second referendum was held, the former "Côte française des Somalis" (French Somaliland) was renamed to "Territoire français des Afars et des Issas". This was both in acknowledgement of the large Afar constituency and to downplay the significance of the Somali composition (the Issa being a Somali sub-clan).

The French Territory of Afars and Issas also differed from French Somaliland in terms of government structure, as the position of governor changed to that of high commissioner. A nine-member council of government was also implemented. During the 1960s, the struggle for independence was led by the Front for the Liberation of the Somali Coast (FLCS), who waged an armed struggle for independence with much of its violence aimed at French personnel. FLCS used to initiate few mounting cross-border operations into French Somaliland from Somalia and Ethiopia to attacks on French targets. On 24 March 1975 the Front de Libération de la Côte des Somalis kidnapped the French Ambassador to Somalia, Jean Guery, to be exchanged against two activists of FLCS members who were both serving life terms in mainland France. He was exchanged for the two FLCS members in Aden, South Yemen. With a steadily enlarging Somali population, the likelihood of a third referendum appearing successful had grown even more dim. The prohibitive cost of maintaining the colony and the fact that after 1975, France found itself to be the last remaining colonial power in Africa was another factor that compelled observers to doubt that the French would attempt to hold on to the territory.

In 1976, the French garrison, centered on the 13th Demi-Brigade of the Foreign Legion (13 DBLE), had to be reinforced to contain Somali irredentist aspirations, revolting against the French-engineered Afar domination of the emerging government. In 1976, members of the Front de Libération de la Côte des Somalis which sought Djibouti's independence from France, also clashed with the Gendarmerie Nationale Intervention Group over a .

The FLCS was recognized as a national liberation movement by the Organization of African Unity (OAU), which participated in its financing. The FLCS evolved its demands between the request of integration in a possible "Greater Somalia" influenced by the Somali government or the simple independence of the territory. In 1975 the African People's League for the Independence (LPAI) and FLCS met in Kampala, Uganda with several meeting later they finally opted for independence path, causing tensions with Somalia.
A third independence referendum was held in the French Territory of the Afars and the Issas on 8 May 1977. The previous referendums were held in 1958 and 1967, which rejected independence. This referendum backed independence from France. A landslide 98.8% of the electorate supported disengagement from France, officially marking Djibouti's independence.

After independence the new government signed an agreement calling for a strong French garrison, though the 13 DBLE was envisaged to be withdrawn. While the unit was reduced in size, a full withdrawal never actually took place.

In 1981, Aptidon turned the country into a one party state by declaring that his party, the Rassemblement Populaire pour le Progrès (RPP) (People's Rally for Progress), was the sole legal one. Clayton writes that the French garrison played the major role in suppressing further minor unrest about this time, during which Djibouti became a one-party state on a much broader ethnic and political basis.

A civil war broke out in 1991, between the government and a predominantly Afar rebel group, the Front for the Restoration of Unity and Democracy (FRUD). The FRUD signed a peace accord with the government in December 1994, ending the conflict. Two FRUD members were made cabinet members, and in the presidential elections of 1999 the FRUD campaigned in support of the RPP.

Aptidon resigned as president 1999, at the age of 83, after being elected to a fifth term in 1997. His successor was his nephew, Ismail Omar Guelleh.

On 12 May 2001, President Ismail Omar Guelleh presided over the signing of what is termed the final peace accord officially ending the decade-long civil war between the government and the armed faction of the FRUD, led by Ahmed Dini Ahmed, an Afar nationalist and former Gouled political ally. The peace accord successfully completed the peace process begun on 7 February 2000 in Paris. Ahmed Dini Ahmed represented the FRUD.

In the presidential election held 8 April 2005, Ismail Omar Guelleh was re-elected to a second 6-year term at the head of a multi-party coalition that included the FRUD and other major parties. A loose coalition of opposition parties again boycotted the election. Currently, political power is shared by a Somali president and an Afar prime minister, with an Afar career diplomat as Foreign Minister and other cabinet posts roughly divided. However, Issas are predominate in the government, civil service, and the ruling party. That, together with a shortage of non-government employment, has bred resentment and continued political competition between the Issa Somalis and the Afars. In March 2006, Djibouti held its first regional elections and began implementing a decentralization plan. The broad pro-government coalition, including FRUD candidates, again ran unopposed when the government refused to meet opposition preconditions for participation. In the 2008 elections, the opposition Union for a Presidential Majority (UMP) party boycotted the election, leaving all 65 seats to the ruling RPP. Voter turnout figures were disputed. Guelleh was re-elected in the 2011 presidential election.

Due to its strategic location at the mouth of the Bab el Mandeb gateway to the Red Sea and the Suez Canal, Djibouti also hosts various foreign military bases. Camp Lemonnier is a United States Naval Expeditionary Base, situated at Djibouti-Ambouli International Airport and home to the Combined Joint Task Force - Horn of Africa (CJTF-HOA) of the U.S. Africa Command (USAFRICOM). In 2011, Japan also opened a local naval base staffed by 180 personnel to assist in marine defense. This initiative is expected to generate $30 million in revenue for the Djiboutian government.

In April 2021, Ismael Guelleh, the second President of Djibouti since independence from France in 1977, was re-elected for his fifth term.





Geography of Djibouti

Djibouti is a country in the Horn of Africa. It is bordered by Eritrea in the north, Ethiopia in the west and south, and Somalia in the southeast. To the east is its coastline on the Red Sea and the Gulf of Aden. Rainfall is sparse, and most of the territory has a semi-arid to arid environment. Lake Assal is a saline lake which lies 155 m (509 ft) below sea level, making it the lowest point on land in Africa and the third-lowest point on Earth after the Sea of Galilee and the Dead Sea. Djibouti has the fifth smallest population in Africa. Djibouti's major settlements include the capital Djibouti City, the port towns of Tadjoura and Obock, and the southern cities of Ali Sabieh and Dikhil. It is the forty-six country by area in Africa and 147st largest country in the world by land area, covering a total of , of which is land and is water.

Djibouti shares of border with Eritrea, with Ethiopia, and with Somalia (total ). It has a strategic location on the Horn of Africa and the Bab el Mandeb, along a route through the Red Sea and Suez Canal. Djibouti's coastline serves as a commercial gateway between the Arabian Peninsula and the Horn region's interior. The country is also the terminus of rail traffic into Ethiopia.

Djibouti can be divided into three physiographic regions
A great arc of mountains, consisting of the Mousa Ali, Goda Mountains, and Arrei Mountains surrounds Djibouti.

Djibouti has eight mountain ranges with peaks of over 1,000 m (3,281 ft).


The Grand Bara Desert covers parts of southern Djibouti in the Arta Region, Ali Sabieh Region and Dikhil Region. The majority of the Grand Bara Desert lies at a relatively low elevation, below 1,700 feet (560 m). Home of the popular Grand Bara footrace.

Most of Djibouti has been described as part of the Ethiopian xeric grasslands and shrublands ecoregion. The exception is a strip along the Red Sea coast, which is part of the Eritrean coastal desert; it is noted as an important migration route for birds of prey.
The area of the regions of Djibouti is set out in the table below.

There is not much seasonal variation in Djibouti's climate. Hot conditions prevail year-round along with winter rainfall. Mean daily maximum temperatures range from 32 to 41 °C (90 to 106 °F), except at high elevations. In Djibouti City, for instance, afternoon highs in April typically range from 28 °C (82 °F) to 34 °C (93 °F) in April. Nationally, mean daily minima generally vary between sites from about 15 to 30 °C (59 to 86 °F). The greatest range in climate occurs in eastern Djibouti, where temperatures sometimes surpass 41 °C (106 °F) in July on the littoral plains and fall below freezing point during December in the highlands. In this region, relative humidity ranges from about 40% in the mid-afternoon to 85% at night, changing somewhat according to the season.
Djibouti has 988,000 people living there.
Djibouti has either a hot semi-arid climate ("BSh") or a hot desert climate ("BWh"), although temperatures are much moderated at the high elevations. On the coastal seaboard, annual rainfall is less than 5 inches (131 mm); in the highlands, it is about 8 to 16 inches (200 to 400 mm). Although the coastal regions are hot and humid throughout the year, the hinterland is typically hot and dry. The climate conditions are highly variable within the country and vary locally by altitude. Summers are very humid along the coast but dry in the highlands. Heat waves are frequent. Annual precipitation amounts vary greatly from one year to another. In general, rain falls more frequently and extensively in the mountains. Sudden and brutal storms are also known to occur. Wadis turn for a few hours into raging torrents tearing everything in their path, and their course is regularized. Rainwater serves as an additional water supply for livestock and plants alongside seasonal watercourses. The highlands have temperate climate throughout the year. The climate of most lowland zones is arid and semiarid.

The climate of the interior shows notable differences from the coastline. Especially in the mornings, the temperature is pleasant: it is so in Arta, Randa and Day (where temperatures of 10 degrees Celsius have been recorded).

Graphically the seasons can be represented this way:

Lake Assal is the lowest point in Africa.

Land use:
"arable land:" 0.1%
<br>"permanent pasture:" 73.3%
<br>"forest:" 0.2% 
<br>"other:" 26.4% (2011)

Irrigated land: (2012)

Water is becoming a scarce resource in Djibouti due to climate change, which leads to different rainfall patterns as well as to inefficient methods of distribution within the country. Most of Djibouti's rainfall is in the four months, but over the last 25 years, the Djibouti's Ministry of Environment estimates that rainfall has decreased overall between 5 and 20 percent. It is predicted that in future years, there will be higher temperatures, lower rainfall, and longer droughts, leading to even less access to water. Moreover, seawater intrusion or fossil saltwater contamination of the limited freshwater aquifers due to groundwater overexploitation affect those who live close to the coastline.

In recent years, population growth has increased rapidly with the addition of many refugees.

Unlike much of the Horn of Africa and Middle East which is rich in lucrative crude oil, Djibouti has limited natural resources. These include potential geothermal power, gold, clay, granite, limestone, marble, salt, diatomite, gypsum, pumice, petroleum.

Natural hazards include earthquakes, drought, and occasional cyclonic disturbances from the Indian Ocean, which bring heavy rains, and flash floods. Natural resources include geothermal energy. Inadequate supplies of potable water, limited arable land and desertification are current issues.

Djibouti is a party to international agreements on biodiversity, climate change, desertification, endangered species, Law of the Sea, ozone layer protection, ship pollution, and wetlands.

Djibouti has a coastline which measures about 314 kilometres (195 mi). Much of the coastline is accessible and quite varied in geography and habitats.



The population of Djibouti in 2015 was 846,000.

For statistical purposes, the country has three areas; Djibouti City (population 529,000), Ali Sabieh (population 55,000), and Dikhil (population 54,000). Djibouti's population is diverse demographically; 60% Somali, 35% Afar, and 3% Arabs. In terms of religion, 94% Muslim, 6% Christian.

This is a list of the extreme points of Djibouti, the points that are farther north, south, east or west than any other location.


Demographics of Djibouti

Demographic features of Djibouti include population density, ethnicity, education level, health, economic status, religious affiliations and other aspects.

Djibouti is a multiethnic country. As of 2018, it has a population of around 884,017 inhabitants. Djibouti's population grew rapidly during the latter half of the 20th century, increasing from about 69,589 in 1955 to around 869,099 by 2015.

The ethnic composition of Djibouti is 56.2% Somali, 24.2% Afar, 15.6% Arabs, 6.675% Djibouti Arabs (indigenous), 4.525% Yemenis, 4.4% Omanis and 5% others. The Somali clan component is mainly composed of the Issa clan (Dir), followed by the Gadabuursi and the Isaaq.

The remaining 5% of Djibouti's population primarily consists of Ethiopians and Europeans (French, Italian and Swedish). In addition, as of 2021, 4,000 American troops, 1,350 French troops, 600 Japanese troops, 400 Chinese troops, and an unknown number of German troops are stationed at various bases throughout Djibouti. Approximately 76% of local residents are urban dwellers; the remainder are pastoralists. 40,000 people from Yemen live in Djibouti, accounting for 4.525% of its total population.

Djibouti is a multilingual nation. The majority of local residents speak Somali (650,000 speakers in Djibouti city and Ali Sabieh) and Afar (300,000 speakers) as a first language. These languages are the mother tongues of the Somali and Afar ethnic groups, respectively. Both languages belong to the larger Afroasiatic family. There are 2 official languages in Djibouti: Arabic and French.

Arabic is of religious importance. In formal settings, it consists of Modern Standard Arabic. Colloquially, about 59,000 local residents speak the Ta'izzi-Adeni Arabic dialect, also known as "Djibouti Arabic". French serves as a statutory national language. It was inherited from the colonial period, and is the primary language of instruction. Around 17,000 Djiboutians speak it as a first language. Immigrant languages include Omani Arabic (38,900 speakers), Amharic (1,400 speakers), Greek (1,000 speakers) and Hindi (600 speakers).

According to , the total population was in compared to 62,000 in 1950. The proportion of children below the age of 15 in 2010 was 35.8%, 60.9% was between 15 and 65 years of age, while 3.3% was 65 years or older.

The following are UN medium variant projections; numbers are in thousands:

Registration of vital events in Djibouti is incomplete. The Population Department of the United Nations prepared the following estimates.
Demographic statistics according to the World Population Review in 2022:


The following demographic statistics are from the CIA World Factbook:

Sunni Muslim 94% (nearly all Djiboutians), other 6% (mainly foreign-born residents - Shia Muslim, Christian, Hindu, Jewish, Baha'i, and atheist)

note: on 21 March 2022, the US Centers for Disease Control and Prevention (CDC) issued a Travel Alert for polio in Africa; Djibouti is currently considered a high risk to travelers for circulating vaccine-derived polioviruses (cVDPV); vaccine-derived poliovirus (VDPV) is a strain of the weakened poliovirus that was initially included in oral polio vaccine (OPV) and that has changed over time and behaves more like the wild or naturally occurring virus; this means it can be spread more easily to people who are unvaccinated against polio and who come in contact with the stool or respiratory secretions, such as from a sneeze, of an “infected” person who received oral polio vaccine; the CDC recommends that before any international travel, anyone unvaccinated, incompletely vaccinated, or with an unknown polio vaccination status should complete the routine polio vaccine series; before travel to any high-risk destination, the CDC recommends that adults who previously completed the full, routine polio vaccine series receive a single, lifetime booster dose of polio vaccine

Afar 35%, Somali 60% and Arab 2%

The languages of Djibouti are:

Politics of Djibouti

Politics of Djibouti takes place in a framework of a presidential representative democratic republic, whereby the executive power is exercised by the President and the Government. Legislative power is vested in both the Government and the National Assembly. The party system and legislature are dominated by the socialist People's Rally for Progress. In April 2010, a new constitutional amendment was approved. The President serves as both the head of state and head of government, and is directly elected for single six-year term. Government is headed by the President, who appoints the Prime Minister and the Council of Ministers on the proposal of the latter. There is also a 65-member chamber of deputies, where representatives are popularly elected for terms of five years. Administratively, the country is divided into five regions and one city, with eleven additional district subdivisions. Djibouti is also part of various international organisations, including the United Nations and Arab League.

In 1958, on the eve of neighboring Somalia's independence in 1960, a referendum was held in Djibouti to decide whether to join the Somali Republic or to remain with France. The referendum turned out in favour of a continued association with France, partly due to a combined "yes" vote by the sizeable Afar ethnic group and resident Europeans. There was also widespread vote rigging, with the French expelling thousands of Somalis before the referendum reached the polls. The majority of those who had voted "no" were Somalis who were strongly in favour of joining a united Somalia as had been proposed by Mahmoud Harbi, Vice President of the Government Council. Harbi was killed in a plane crash two years later.

In 1967, a second plebiscite was held to determine the fate of the territory. Initial results supported a continued but looser relationship with France. Voting was also divided along ethnic lines, with the resident Somalis generally voting for independence, with the goal of eventual union with Somalia, and the Afars largely opting to remain associated with France. However, the referendum was again marred by reports of vote rigging on the part of the French authorities. Shortly after the referendum was held, the former "Côte française des Somalis" (French Somaliland) was renamed to "Territoire français des Afars et des Issas".

In 1977, a third referendum took place. A landslide 98.8% of the electorate supported disengagement from France, officially marking Djibouti's independence.

Hassan Gouled Aptidon, a Somali politician who had campaigned for a "yes" vote in the referendum of 1958, eventually wound up as the nation's first president (1977–1999). He was re-elected, unopposed, to a second 6-year term in April 1987 and to a third 6-year term in May 1993 multiparty elections. The electorate approved the current constitution in September 1992. Many laws and decrees from before independence remain in effect.

In early 1992, the government decided to permit multiple party politics and agreed to the registration of four political parties. By the time of the national assembly elections in December 1992, only three had qualified. They are the "Rassemblement Populaire Pour le Progres" (People's Rally for Progress) (RPP) which was the only legal party from 1981 until 1992, the "Parti du Renouveau Démocratique" (The Party for Democratic Renewal) (PRD), and the "Parti National Démocratique" (National Democratic Party) (PND). Only the RPP and the PRD contested the national assembly elections, and the PND withdrew, claiming that there were too many unanswered questions on the conduct of the elections and too many opportunities for government fraud. The RPP won all 65 seats in the national assembly, with a turnout of less than 50% of the electorate.

In 1999, President Aptidon's chief of staff, head of security, and key adviser for over 20 years, Ismail Omar Guelleh was elected to the Presidency as the RPP candidate. He received 74% of the vote, the other 26% going to opposition candidate Moussa Ahmed Idriss, of the Unified Djiboutian Opposition (ODU). For the first time since independence, no group boycotted the election. Moussa Ahmed Idriss and the ODU later challenged the results based on election "irregularities" and the assertion that "foreigners" had voted in various districts of the capital; however, international and locally based observers considered the election to be generally fair, and cited only minor technical difficulties. Guelleh took the oath of office as the second President of the Republic of Djibouti on May 8, 1999, with the support of an alliance between the RPP and the government-recognised section of the Afar-led FRUD.

Currently, political power is shared by a Somali Issa president and an Afar prime minister, with cabinet posts roughly divided. However, it is the Issas who dominate the government, civil service, and the ruling party, a situation that has bred resentment and political competition between the Somali Issas and the Afars.

The government is dominated by the Somali Issa Mamasen, who enjoy the support of the Somali clans, especially the Isaaq (the clan of the current president's wife) and the Gadabuursi Dir (who are the second most prominent Somali clan in Djibouti politics). In early November 1991, civil war erupted in Djibouti between the government and a predominantly Afar rebel group, the Front for the Restoration of Unity and Democracy (FRUD). The FRUD signed a peace accord with the government in December 1994, ending the conflict. Two FRUD members were subsequently made cabinet members, and in the presidential elections of 1999 the FRUD campaigned in support of the RPP. In February 2000, another branch of FRUD signed a peace accord with the government. On 12 May 2001, President Ismail Omar Guelleh presided over the signing of what is termed the final peace accord officially ending the decade-long civil war between the government and the armed faction of the FRUD. The treaty successfully completed the peace process begun on 7 February 2000 in Paris, with Ahmed Dini Ahmed representing the FRUD.

On 8 April 2005, President Guelleh was sworn in for his second six-year term after a one-man election. He took 100% of the votes in a 78.9% turnout.

In early 2011, the Djiboutian citizenry took part in a series of protests against the long-serving government, which were associated with the larger Arab Spring demonstrations. Guelleh was re-elected to a third term later that year, with 80.63% of the vote in a 75% turnout. Although opposition groups boycotted the ballot over changes to the constitution permitting Guelleh to run again for office, international observers generally described the election as free and fair.

On 31 March 2013, Guelleh replaced long-serving Prime Minister Dilleita Mohamed Dilleita with former president of the Union for a Presidential Majority (UMP) Abdoulkader Kamil Mohamed.

In April 2021, Ismael Guelleh, the second President of Djibouti since independence from France in 1977, was re-elected for his fifth term.

The President is directly elected by popular vote for a five-year term. The Prime Minister is appointed by the President, and the Council of Ministers is solely responsible to the President, as specified in .

Djibouti is sectioned into five administrative regions and one city:

Ali Sabieh Region, Arta Region, Dikhil Region, Djibouti Region, Obock Region and Tadjourah Region.

The country is further sub-divided into eleven districts.

ACCT,
ACP,
AfDB,
AFESD,
AL,
AMF,
ECA,
FAO,
G-77,
IBRD,
ICAO,
ICC,
ICRM,
IDA,
IDB,
IFAD,
IFC,
IFRCS,
IGAD,
ILO,
IMF,
IMO,
Intelsat (nonsignatory user),
Interpol,
IOC,
ITU,
ITUC,
NAM,
OAU,
OIC,
OPCW,
UN,
UNCTAD,
UNESCO,
UNIDO,
UPU,
WFTU,
WHO,
WMO,
WToO,
WTrO

Economy of Djibouti

The economy of Djibouti is derived in large part from its strategic location on the Red Sea. Djibouti is mostly barren, with little development in the agricultural and industrial sectors. The country has a harsh climate, a largely unskilled labour force, and limited natural resources. The country's most important economic asset is its strategic location, connecting the Red Sea and the Gulf of Aden. As such, Djibouti's economy is commanded by the services sector, providing services as both a transit port for the region and as an international transshipment and refueling centre.

From 1991 to 1994, Djibouti experienced a civil war which had devastating effects on the economy. Since then, the country has benefited from political stability. In recent years, Djibouti has seen significant improvement in macroeconomic stability, with its annual gross domestic product improving at an average of over 3 percent since 2003. This comes after a decade of negative or low growth and is attributed to fiscal adjustment aimed at improving public financing, reforms in port management and foreign investment.

Despite the recent modest and stable growth, Djibouti is faced with many economic challenges, particularly job creation and poverty reduction. With an average annual population growth rate of 2.5 percent, the economy cannot significantly benefit national income per capita growth. Unemployment is extremely high, with some estimates placing it at almost 60 percent, and is a major contributor to widespread poverty. In recent years, the country's dependence on Chinese investment and debt has also come under scrutiny.

According to a 2020 report by the World bank, Djibouti was 112th among 190 economies when it comes to the ease of doing business.

After experiencing armed conflict and economic hardship during the 1990s, Djibouti has experienced stable economic growth in recent years as a result of relative political stability and achievements in macroeconomic adjustment efforts.

Fiscal adjustment measures included downsizing the civil service, implementing a pension reform that placed the system on a much stronger financial footing, and strengthening public expenditure institutions. From 2003 to 2005, annual real GDP growth averaged 3.1 percent in the mid-2000s, driven by good performance in the services sector, strong consumption and reached a value as high as 7.8 percent in 2019. In the 21st century, Inflation has been kept low through fixed pegging of the Djibouti franc to the US dollar, but experienced a sharp spike in the late 2000s, when it reached values three times higher than the average of the last 20 years.

Despite experiencing economic growth, the country continues to struggle with high unemployment. Official numbers put the unemployment rate at just over 10 percent, but international estimates consider it to be closer to 60 percent. Furthermore, reliance on diesel-generated electricity and the need to import basic necessities like food and water leave average consumers vulnerable to global price shocks.

Djibouti's gross domestic product expanded by an average of more than 6 percent per year, from US$341 million in 1985 to US$3.3 billion in 2019.

Low tax revenue and high spending on public infrastructure has seen Djibouti struggle with its budget deficit. Additionally, the country's public debt has increased sharply—from 50.2 percent of GDP in 2015 to an expected 72.9 percent in 2020.

Djibouti's merchandise trade balance has shown a large deficit. This is due to the country's enormous need for imports and narrow base of exports. Although Djibouti runs a substantial surplus in its services balance, the surplus has been smaller than the deficit in the merchandise trade balance. As a result, Djibouti's has developed a high level of trade deficit, reaching a peak of 130 billion Djibouti francs in 2019.

Positioned on a primary shipping lane between the Gulf of Aden and the Red Sea, Djibouti holds considerable strategic value in the international trade and shipping industries. The facilities of the Port of Djibouti are important to sea transportation companies for fuel bunkering and refuelling. Its transport facilities are used by several landlocked African countries for the re-export of their goods. Djibouti earns transit taxes and harbour fees from this trade, these form the bulk of government revenue. Threats of pirates patrolling the Gulf of Aden, off the coast of Somalia, with the intentions of capturing large cargo ships, oil, and chemical tankers has created the need for larger nations such as the United States, France, and Japan to embed logistics bases or military camps from which they can defend their freight from piracy.

The port of Djibouti functions as a small French naval facility, and the United States has also stationed hundreds of troops in Camp Lemonnier, Djibouti, its only African base, in an effort to counter terrorism in the region.

Since 2010 China has become an important trading and military partner for Djibouti, including it in its African Road and Belt Initiative through the construction of infrastructure projects like a railway link to Ethiopia and the Doraleh port. In 2017, it also began operating a large naval base near de Doraleh port, which serves as China's first ever overseas military base. In 2009, China overtook the United States in becoming Djibouti's largest trading partner. Between 57 percent and 70 percent of Djibouti's debt is made up of Chinese loans.

Chinese influence in Djibouti, particularly through its military base and financial debt, has been criticized in recent years as being more beneficial to the stability of the current political regime than for the country as a whole.

The following table shows the main economic indicators in 1980–2017.
Despite not being hit as hard as other countries by the COVID-19 pandemic, Djibouti's economy suffered the effects of the global slowdown in trade and diminished traffic through the Doraleh port. Real GDP growth slumped to 1.4 percent in 2020 from 7.8 percent in 2019. The pandemic also contributed to a sharp deceleration in investment, which increased by just 10.3 percent of GDP in 2020, compared to a 26.3 percent growth in 2019, as well as in the value added by the services sector, which saw a modest 2 percent increase in 2020, after growing by 8.2 percent in 2019.

Djibouti's recovery projections are closely tied to the timeframe in which global shipping and trade will return to pre-pandemic levels, with a full recovery expected to happen in the following couple of years,  if the COVID-19 pandemic does not last beyond the second half of 2021.

Djibouti's economy is based on service activities connected with the country's strategic location and status as a free trade zone in the Horn of Africa. Two-thirds of inhabitants live in the capital and the remainder of the populace is mostly nomadic herders. Low amounts of rainfall limit crop production to fruits and vegetables, and requiring most food to be imported. The government provides services as both a transit port for the region and an international transshipment and refueling centre. Djibouti has few natural resources and little industry. All of these factors contribute to its heavy dependence on foreign assistance to help support its balance of payments and to finance development projects.

An unemployment rate of 60 percent continues to be a major problem. Inflation is not a concern, however, because of the fixed tie of the franc to the US dollar. Per capita consumption dropped an estimated 35 percent over the last seven years because of recession, civil war, and a high population growth rate. Faced with a multitude of economic difficulties, the government has fallen in arrears on long-term external debt and has been struggling to meet the stipulations of foreign aid donors.

The Djiboutian franc is pegged to the US dollars since 1949 through the use of a currency board. The effectiveness of this longstanding and unique institution on the African continent has not been challenged since then.

According to a financial risk assessment from 2018, the country has been suffering from increasing corruption and a decline in international governance and transparency indices, growing debt and over-reliance on Ethiopia and China for trade and FDI, respectively.

Officially, the government of Djibouti welcomes all foreign direct investment. Djibouti's assets include a strategic geographic location, an open trade regime, a stable currency, substantial tax breaks and other incentives. Potential areas of investment include Djibouti's port and the telecommunications sectors. President Ismail Omar Guellehh first elected in 1999, has named privatization, economic reform, and increased foreign investment as top priorities for his government. The president pledged to seek the help of the international private sector to develop the country's infrastructure.

Djibouti has no major laws that would discourage incoming foreign investment. In principle there is no screening of investment or other discriminatory mechanisms. However, a number of hurdles to foreign investment in the country exist. For example, certain sectors, most notably public utilities, are state owned and some parts are not currently open to investors. In 2017, a law was passed granting the government the right to unilaterally alter or terminate contracts with foreign entities. Conditions of the structural adjustment agreement recently signed by Djibouti and the International Monetary Fund stipulate increased privatization of parastatal and government-owned monopolies. There are no patent laws in Djibouti.

Furthermore, there are concerns about the rule of law, the independence of courts, and how this affects the protection of investments in the country. A Freedom House report, for example, mentions the case of Dubai-based port operator DP World which has been embroiled in a legal battle with Djibouti since 2012, "when Djibouti sold part of its concession in the Doraleh Container Terminal to a Chinese state-owned competitor of DP World, the original concession partner."

In 2018, Djibouti seized DP World's port assets, but ruling the nationalization illegal, the London Court of International Arbitration in 2019 ordered Djibouti to restore the rights and benefits of the concession to DP World. The country subsequently rejected the ruling and asked the Djibouti high court to unilaterally nullify the LCIA decision.

A Santander report concluded that despite its strategic importance, FDI into Djibouti is hampered by "mediocre governance, corruption, the lack of a sound judicial framework, an unstable regional geopolitical situation, a poorly diversified economy with little resilience to outside shocks, and a fragile ecosystem prone to environmental crisis."

As in most African nations, access to licenses and approvals is complicated not so much by law as by administrative procedures. In Djibouti, the administrative process has been characterized as a form of 'circular dependency.' For example, the finance ministry will issue a license only if an investor possesses an approved investor visa, while the interior ministry will only issue an investor visa to a licensed business. The Djiboutian government is increasingly realizing the importance of establishing a one-stop shop to facilitate the investment process.

In May 2015 Choukri Djibah, Director of Gender in the Department of Women and Family, launched the project SIHA (Strategic Initiative for the Horn of Africa) designed to support and reinforce the economic capacity of women in Djibouti, funded with a grant from the European Union of 28 Million Djibouti francs.

Principal exports from the region transiting Djibouti are coffee, salt, hides, dried beans, cereals, other agricultural products, chalk, and wax. Djibouti itself has few exports, and the majority of its imports come from France. Most imports are consumed in Djibouti and the remainder goes to Ethiopia and Somalia. Djibouti's unfavorable balance of trade is offset partially by invisible earnings such as transit taxes and harbor dues. In 1999, U.S. exports to Djibouti totalled $26.7 million while U.S. imports from Djibouti were less than $1 million. The City of Djibouti has the only paved airport in the republic.

In 2013, 63,000 foreign tourists visited Djibouti, Djibouti City is the principal tourist destination for visitors, revenues from tourism fell just US$43 million in 2013.



Transport in Djibouti

Transport in Djibouti is facilitated through a relatively young system of roads, railways and ports. 

The national flag carrier is Air Djibouti. In total, there are other airlines, all operating out of Djibouti–Ambouli International Airport:


The aviation industry is regulated by the Civil Aviation Authority of Djibouti, a statutory board of the Djibouti government under the Ministry of Infrastructure & Transport.

The Port of Djibouti, run by the Djibouti Ports & Free Zones Authority and Port of Doraleh, is a key transhipment hub for the East African region. 


Djibouti Armed Forces

The Djibouti Armed Forces (DJAF; , , ) are the military forces of Djibouti. They consist of the Djiboutian National Army and its sub-branches the Djiboutian Air Force and Djiboutian Navy. As of 2018, the Djibouti Armed Forces consists of 20,470 (2018 est.) ground troops, which are divided into several regiments and battalions garrisoned in various areas throughout the country. The Djibouti Armed Forces are an important player in the Bab-el-Mandeb and Red Sea.

In 2015 General Zakaria Chiek Imbrahim was "chief d'etat-major general" (chief of staff) of the "Forces Armees Djiboutiennes". He assumed command in November 2013.

Djibouti has always been a very active member in the African Union and the Arab League.

Historically, Somali society accorded prestige to the warrior ("waranle") and rewarded military prowess. Except for men of religion ("wadaad"), who were few in number, all Somali males were considered potential warriors.
Djibouti's many Sultanates each maintained regular troops. In the early Middle Ages, the conquest of Shewa by the Ifat Sultanate ignited a rivalry for supremacy with the Solomonic Dynasty.

Many similar battles were fought between the succeeding Sultanate of Adal and the Solomonids, with both sides achieving victory and suffering defeat. During the protracted Ethiopian-Adal War (1529–1559), Imam Ahmad ibn Ibrihim al-Ghazi defeated several Ethiopian Emperors and embarked on a conquest referred to as the "Futuh Al-Habash" ("Conquest of Abyssinia"), which brought three-quarters of Christian Abyssinia under the power of the Muslim Adal Sultanate. Al-Ghazi's forces and their Ottoman allies came close to extinguishing the ancient Ethiopian kingdom, but the Abyssinians managed to secure the assistance of Cristóvão da Gama's Portuguese troops and maintain their domain's autonomy. However, both polities in the process exhausted their resources and manpower, which resulted in the contraction of both powers and changed regional dynamics for centuries to come.

The 1st Battalion of Somali Skirmishers, formed in 1915 from recruits from the French Somali Coast, was a unit belonging to the French Colonial Army. They distinguished himself during the First World War, notably during the resumption of Fort Douaumont, Battle of Verdun in October 1916 alongside the Régiment d'infanterie-chars de marine and the Second Battle of the Aisne in October 1917. 
In May and June 1918, they took part in the Third Battle Of The Aisne and in July in the Second Battle of the Marne. In August and September 1918, the Somali battalion fought on the Oise front and in October 1918 he obtained his second citation to the order of the army as well as the right to wear a Fourragère in the colors of the ribbon of the Croix de guerre 1914–1918. Between 1915 and 1918, over 2,088 Djiboutians served as combat in the First World War. Their losses are estimated at 517 killed and 1,000 to 1,200 injured.

During the Italian invasion and occupation of Ethiopia in the mid-1930s and during the early stages of World War II, constant border skirmishes occurred between the forces in French Somaliland and the forces in Italian East Africa. After the fall of France in 1940, French Somaliland declared loyalty to Vichy France. The colony remained loyal to Vichy France during the East African Campaign but stayed out of that conflict. British forces in Ethiopia begin dropping leaflets calling on the French Somaliland to rally to Free France. The newspaper Djibouti Libre published in Dire Dawa is also air dropped into the Vichy controlled colony and a 15-minute newscast is broadcast over the radio. In 1942: Vichy recalls Governor Pierre Nouailhetas after his superiors decide that he is in too close contact with the British. Nouailhetas delegates his authority to the military commander General Truffert. Two battalions, accompanied by civilians, leave Djibouti to join the British forces in British Somaliland. General Truffert is forced to resign and cede power to his adjutant General Dupont after a great majority of Djibouti’s military and civil administrators threaten to leave for British held Somaliland. This lasted until December 1942. By that time, the Italians had been defeated and the French colony was isolated by a British blockade. Free French and Allied forces recaptured the colony's capital of Djibouti at the end of 1942. A local battalion of Somali skirmishers to participate in the battles for the liberation of France, it participated in particular in the fighting at Pointe de Grave in April 1945. On April 22, 1945, General de Gaulle awarded the Somali battalion a citation to the army and decorated the battalion's pennant in Soulac-sur-Mer. The Somali battalion is dissolved on June 25, 1946.

The Ogaden War (13 July 1977 – 15 March 1978) was a conflict fought between the Ethiopian government and Somali government. The Djibouti government supported Somalia with military intelligence. In a notable illustration of the nature of Cold War alliances, the Soviet Union switched from supplying aid to Somalia to supporting Ethiopia, which had previously been backed by the United States. This in turn prompted the U.S. to later start supporting Somalia. The war ended when Somali forces retreated back across the border and a truce was declared.
In the 27 May to June 13, 1991, the Djiboutian Armed Forces and FFDJ participated in Operation Godoria. The President of the Djiboutian Republic, Hassan Gouled Aptidon described this as a "invasion". At the end of May 1991, the collapse of the Ethiopian regime the Assab loyalist division. Crossed the border at dawn, cornered on the northern border of Djibouti, Assab's division, 9,000 strong, crossed the Djiboutian-Ethiopian border with arms and luggage and headed towards Obock. Simultaneously, another division crossed the Western border and moved towards Dikhil. This violation of the borders by a regular foreign army falls strictly within the framework of the protocols passed between France and Djibouti. This is why, on May 26 at 10:30 p.m., Operation Godoria is launched, all Djiboutian and French forces, land, air and sea stationed in Djibouti participate in it. Djiboutian Army, prohibit Ethiopian troops from surging towards the south. Djiboutian and French troops deployed, facing the firmness of their interlocutors, the Ethiopian officers yielded to the demands and agreed to continue the disarmament already begun. The 5th Overseas Interarms Regiment took charge of a detachment of 4,300 military refugees, accompanied by a few families and embarked in 120 vehicles of all types heading towards the southern border. The initial aim is to clean up a border area of 150 km2, collect, remove supplies, inventory and hand over abandoned weapons to the Djiboutian authorities. The "Lynx Mike" detachment identifies thousands of individual and collective weapons, includes the T 55, ZU-23-2,BTR and BRDM, finally destroys the 50 tons of unpackaged ammunition of all calibers. From May 30 to June 13, there will be a total of 12,500 weapons from the AK47 to the T64, including LRMs, 122 howitzers and more than 200 tons of ammunition from the 200 kg bomb to the cartridge factory, via rockets LRM which will have been moved, sorted, stored, even for some of them neutralized or destroyed. For the first time since the accession to independence of Djibouti, the Djiboutian national army and the French forces placed in a highly operational environment, will have proved the validity of the defense agreements binding the two countries contributed to the success of this mission to safeguard the Republic of Djibouti. Perfectly impregnated with the spirit of the mission, the porpoises, from the colonel to the simple soldier, knew how to demand from this Ethiopian army, demoralized, but still supervised, the strict application of the orders emanating from the civil and military authorities, Djiboutian and French, in starting with disarmament before providing them with the food support that has become essential. Around 10:00 am, the convoy begins its progress in the direction of Ali Sabieh. Then reached Ali Sabieh where the refugees were taken care of by the Djiboutian Army and the High Commissioner for Refugees. Most will reach the region of Dire Dawa, in eastern Ethiopia.

The first war which involved the Djiboutian armed forces was the Djiboutian Civil War between the Djiboutian government, supported by France, and the Front for the Restoration of Unity and Democracy ("FRUD"). The war lasted from 1991 to 2001, although most of the hostilities ended when the moderate factions of FRUD signed a peace treaty with the government after suffering an extensive military setback when the government forces captured most of the rebel-held territory. A radical group continued to fight the government, but signed its own peace treaty in 2001. The war ended in a government victory, and FRUD became a political party.

Djibouti has fought in clashes against Eritrea over the Ras Doumeira peninsula, which both countries claim to be under their sovereignty. The first clash occurred in 1996 after a nearly two-months stand-off. In 1999, a political crisis occurred when both sides accused each other for supporting its enemies. In 2008, the countries clashed again when Djibouti refused to return Eritrean deserters and Eritrea responded by firing at the Djiboutian forces. In the following battles, some 44 Djiboutian troops and some estimated 100 Eritreans were killed.

In 2011, Djibouti troops also joined the African Union Mission to Somalia. Djibouti deployed troops to Somalia to fight Al-Shabaab forces and Al-Qaeda operatives, with the hopes of dismantling both groups to support the transitional governmental structures, implement a national security plan, train the Somali security forces, and to assist in creating a secure environment for the delivery of humanitarian aid. Djibouti's responsibilities include providing security in Hiran and Galguduud regions. 

As of 2013, the Djibouti Armed Forces (DJAF) are composed of three branches: the Djibouti National Army, which consists of the Coastal Navy, the Djiboutian Air Force (Force Aerienne Djiboutienne, FAD), and the National Gendarmerie (GN). The Army is by far the largest, followed by the Air Force and Navy. The Commander-in-Chief of the DJAF is the President of Djibouti and the Minister of Defence oversees the DJAF on a day-to-day basis.

Refer to decree No 2003-0166/PR/MDN on organization of Djibouti Armed Forces. The armed forces consist of:

The Djiboutian National Army (DNA) is the largest branch of the Djibouti Armed Forces. Just prior to independence in 1977, the French Territory of the Afars and the Issas established a national army to defend the Djiboutian's borders. The 6 June 1977 has since been marked as Armed Forces Day. After independence, the Front de Libération de la Côte des Somalis troops merged to form the 2,500 strong Djiboutian National Army. Djibouti maintains a modest military force of approximately 20,470 troops; the army is made of 18,600 troops (IISS 2018). The latter are divided into several regiments and battalions garrisoned in various areas throughout the country. The Army has four military districts (the Tadjourah, Dikhil, Ali-Sabieh and Obock districts). Clashes with the Military of Eritrea, in 2008, demonstrated the superior nature of the Djiboutian forces’ training and skills, but also highlighted the fact that the small military would be unable to counter the larger, if less well-equipped forces of its neighbours. The army has concentrated on mobility in its equipment purchases, suitable for patrol duties and counterattacks but ill-suited for armoured warfare. The 2008 border clashes at least temporarily swelled the ranks of the Djiboutian army, with retired personnel being recalled, but the military's size and capabilities are much reduced since the 1990s. The army to address more effectively its major defense disadvantage: lack of strategic depth. Thus in the early 2000s it looked outward for a model of army organization that would best advance defensive capabilities by restructuring forces into smaller, more mobile units instead of traditional divisions. The official tasks of the armed forces include strengthening the country against external attack, and maintaining border security. Djiboutian troops continue to monitor its borders with Eritrea, in the case of an attack. The Djiboutian Army is one of the small professional advanced armies in East Africa.
Its maneuver units are:

Italy delivered 10 howitzers M-109L (in 2013), tens IVECO trucks (ACM90, cranes, tankers, etc.), some IVECO armoured car Puma 4X4 and IVECO utility vehicles VM90.

In reforming the Djiboutian Army, most of the available financial resources have been directed to the development of the Land Forces. Over the years, Djiboutian Army has established partnerships with militaries in France, Egypt, Saudi Arabia, Morocco and the United States. Currently, the amount allocated to defense represents the largest single entry in the country's budget.

The Djiboutian National Gendarmerie is the national Gendarmerie force of Djibouti, tasked with high-risk and specialized law enforcement duties. It is one of the two main police forces in Djibouti (the other being the Djiboutian Police - a civilian force), both having jurisdiction over the civilian population. It is a branch of the Djiboutian Armed Forces placed under the jurisdiction of the Ministry of the Interior—with additional duties to the Ministry of Defense. Its area of responsibility includes smaller towns, rural and suburban areas.

The Djiboutian Navy (DN) is the naval service branch of the Djibouti Armed Forces. The force was launched two years after Djibouti gained its independence in 1977. It is responsible for securing Djibouti's territorial waters and seaboard as well as supporting army operations. The primary objective of the navy is to safeguard the nation's maritime borders, act to deter or defeat any threats or aggression against the territory, people or maritime interests of Djibouti, both in war and peace. Through joint exercises and humanitarian missions, including disaster relief, the Djiboutian Navy promotes bilateral relations between nations. It has a fleet of gunboats, fast missile boats and support, training, which can be deployed to defend the territorial waters and coastline of Djibouti as well as protect tankers passing through the Bab-el-Mandeb strait. The acquisition of the several boats from the US in 2006 considerably increased the navy's ability to patrol over longer distances and to remain at sea for several days at a time. Cooperation with the US and Yemeni navies is also increasing in an effort to protect and maintain the safety and security of the Sea Lanes of Communication (SLOC). The Navy is upgrading itself with the following technological developments.

The Djiboutian Coast Guard (DCG) ( GCD), is the coast guard of Djibouti is a division of the Djiboutian Navy responsible for protecting the interests of the Republic of Djibouti at sea. Formed in 2011, the coast guard is tasked with such as illegal fishing and exploitation of natural resources, search and rescue (SAR), protection of ecology, fishing, marine pollution, ballast waters, combat against terrorism, trafficking of people, narcotics, and similar. Like many other coast guards, it is a paramilitary organization that can support the Djiboutian Navy in wartime, but resides under separate civilian control in times of peace. The Coast Guard monitor vessels sailing in the Djiboutian territorial waters. The Djiboutian Coast Guard intercepted refugee and migrant boats travelling across the Bab-el-Mandeb.

The Djiboutian Air Force (DAF) (French: Force Aérienne du Djibouti (FADD) was established as part of the Djibouti Armed Forces after the country obtained its independence on June 27, 1977. Its first aircraft included three Nord N.2501 Noratlas transport aircraft and an Alouette II helicopter presented to it by the French. In 1982, the Djibouti Air Force was augmented by two Aerospatiale AS.355F Ecureuil 2 helicopters and a Cessna U206G Stationair, this was followed in 1985 by a Cessna 402C Utiliner. In 1985, the Alouette II was withdrawn from use and put on display at Ambouli Air Base at Djibouti's airport. In 1987, the three N.2501 Noratlas were also retired and subsequently returned to France. New equipment came, in 1991, in the form of a Cessna 208 Caravan, followed by Russian types in the early nineties. These included four Mil Mi 2, six Mil Mi 8 and two Mil Mi 17 helicopters and a single Antonov An 28 light transport aircraft. Pilot training for the 360 men of the DAF, if necessary, is conducted in France with continued on type flight training at home. The DAF has no units of its own and forms in whole a part of the Army, its sole base is Ambouli.

The main doctrine consists of the following principles:


The size and structure of the Djibouti Armed Forces is continually evolving.
As of 2018, Djibouti Armed Forces were reported to have 18,000–20,000 active personnel, 10,500–11,000 reserve personnel.

Djibouti first UN Peacekeeping mission was in 1994, when it deployed uniformed personnel to the UN Mission in Haiti (UNMIH) and the UN Assistance Mission for Rwanda (UNAMIR). Djibouti UN peacekeeping mission in the Darfur, Sudan in 2010, withdrew their personnel from Sudan on the 30 June 2021. Djibouti has committed to strengthening international action through the African Union to achieve collective security and uphold the goals enshrined in the Purposes and Principles of the UN Charter and the Constitutive Act of the African Union. Deployed in 3 countries in Somalia, Democratic Republic of the Congo and Central African Republic.
The table below shows the current deployment of Djiboutian Forces in UN Peacekeeping missions.

France's 5e RIAOM are currently stationed in Djibouti.

The Italian "Base Militare Nazionale di Supporto" (National Support Military Base) is capable to host 300 troops and some UAVs.

There is also Combined Joint Task Force - Horn of Africa, a U.S. force of more than 3,500, currently deployed in the country at Camp Lemonnier.

The Japan Self-Defense Force Base Djibouti was established in 2011. The "Deployment Airforce for Counter-Piracy Enforcement" (DAPE): Established in 2011 with approximately 600 deployed personnel from the Japan Maritime Self-Defense Force, on a rotational basis, operating naval vessels and maritime patrol aircraft. Japan reportedly pays $30 million per year for the military facilities, from which it conducts anti-piracy operations in the region. The base also acts as a hub for operations throughout the East African coastline.

The Chinese naval support base in Djibouti began construction in 2016 and was officially opened in 2017.

History of Dominica

The first written records in the history of Dominica began in November 1493, when Christopher Columbus spotted the island. Prior to European contact, Dominica was inhabited by the Arawak. Dominica was a French colony from 1715 until the end of the Seven Years' War in 1763, and then became a British colony from 1763 to 1978. It became an independent nation in 1978.

The Arawak were guided to Dominica, and other islands of the Caribbean, by the South Equatorial Current from the waters of the Orinoco River. These descendants of the early Taínos were overthrown by the Kalinago tribe of the Caribs. The Caribs, who settled here in the 14th century, called the island "Wai‘tu kubuli", which means "Tall is her body."

Christopher Columbus named the island after the day of the week on which he spotted it - a Sunday ('Dominica' in Latin) - which fell on 3 November 1493 on his second voyage.

Daunted by fierce resistance from the Caribs and discouraged by the absence of gold, the Spanish did not settle the island. Many of the remaining Carib people live in Dominica's Carib Territory, a district on Dominica's east coast.

In 1632, the French Compagnie des Îles de l'Amérique claimed Dominica along with all the other 'Petite Antilles' but no settlement was attempted. Between 1642 and 1650 a French missionary Raymond Breton became the first regular European visitor to the island. In 1660 the French and English agreed that both Dominica and St. Vincent should not be settled, but instead left to the Caribs as neutral territory. Dominica was officially neutral for the next century, but the attraction of its resources remained; rival expeditions of English and French foresters were harvesting timber by the start of the 18th century.

Spain had little to no success in colonizing Dominica and in 1690, the French established their first permanent settlements in Dominica. French woodcutters from Martinique and Guadeloupe begin to set up timber camps to supply the French islands with wood and gradually become permanent settlers. They brought the first enslaved people from West Africa to Dominica. In 1715, a revolt of "poor white" smallholders in the north of Martinique, known as La Gaoulé, caused an exodus of them to southern Dominica. They set up smallholdings. Meanwhile, French families and others from Guadeloupe settled in the north. In 1727, the first French commander, M. Le Grand, took charge of the island with a basic French government; Dominica formally became a colony of France, and the island was divided into districts or "quarters". Already installed in Martinique and Guadeloupe and cultivating sugar cane, the French gradually developed plantations in Dominica for coffee. They imported African slaves to fill the labor demands replacing the indigenous Caribs.

In 1761, during the Seven Years' War a British expedition against Dominica led by Lord Rollo was successful and the island was conquered along with several other Caribbean islands. After France was defeated by Britain in the Seven Years' War, it ceded the island to the British under the Treaty of Paris (1763). In 1778, during the American Revolutionary War, the French mounted a successful invasion with the active cooperation of the population. The 1783 Treaty of Paris, which ended the war, returned the island to Britain. French invasions in 1795 and 1805 ended in failure.

As part of the 1763 Treaty of Paris that ended the Seven Years' War, the island became a British possession. In 1778, during the American War of Independence, the French mounted a successful invasion with the active cooperation of the population, which was largely French. The 1783 Treaty of Paris, which ended the war, returned the island to Britain. French invasions in 1795 and 1805 ended in failure. The 22 February 1805 invasion burned much of Roseau to the ground.

In 1763, the British established a legislative assembly, representing only the white population. In 1831, reflecting a liberalization of official British racial attitudes, the Brown Privilege Bill conferred political and social rights on free nonwhites. Three Blacks were elected to the legislative assembly the following year. The abolition of slavery in 1834 enabled Dominica by 1838 to become the only British Caribbean colony to have a Black-controlled legislature in the 19th century. Most Black legislators were small holders or merchants who held economic and social views diametrically opposed to the interests of the small, wealthy English planter class. Reacting to a perceived threat, the planters lobbied for more direct British rule.

In 1865, after much agitation and tension, the colonial office replaced the elective assembly with one composed of one-half elected members and one-half appointed. The elected legislators were outmaneuvered on numerous occasions by planters allied with colonial administrators. In 1871, Dominica became part of the Leeward Island Federation. The power of the Black population progressively eroded. Crown Colony government was re-established in 1896.

Following World War I, an upsurge of political consciousness throughout the Caribbean led to the formation of the representative government association. Marshaling public frustration with the lack of a voice in the governing of Dominica, this group won one-third of the popularly elected seats of the legislative assembly in 1924 and one-half in 1936. Shortly thereafter, Dominica was transferred from the Leeward Island Administration and was governed as part of the Windwards until 1958, when it joined the short-lived West Indies Federation.

In 1961, a Dominica Labor Party government led by Edward Oliver LeBlanc was elected. After the federation dissolved, Dominica became an associated state of the United Kingdom on February 27, 1967 and formally took responsibility for its internal affairs. LeBlanc retired in 1974 and was replaced by Patrick John who became the islands' first Prime Minister.

On November 3, 1978, the Commonwealth of Dominica was granted independence by the United Kingdom.

In August 1979, Hurricane David, packing winds of , struck the island with devastating force. Forty-two people were killed and 75% of the islanders' homes were destroyed or severely damaged.

Independence did little to solve problems stemming from centuries of economic underdevelopment, and in mid-1979, political discontent led to the formation of an interim government, led by Oliver Seraphin. It was replaced after the 1980 elections by a government led by the Dominica Freedom Party under Prime Minister Eugenia Charles, the Caribbean's first female prime minister. Within a year of her inauguration she survived two unsuccessful coups and in October 1983, as chairperson of the Organisation of East Caribbean States, endorsed the US Invasion of Grenada.

Chronic economic problems were compounded by the severe impact of hurricanes in 1979 and in 1980. By the end of the 1980s, the economy had made a healthy recovery, which weakened in the 1990s due to a decrease in banana prices.

In 1995 the government was defeated in elections by the United Workers Party of Edison James. James became prime minister, serving until the February 2000 elections, when the Dominica United Workers Party (DUWP) was defeated by the Dominica Labour Party (DLP), led by Rosie Douglas. He was a former socialist activist, and many feared that his approach to politics might be impractical. However, these were somewhat quieted when he formed a coalition with the more conservative Dominica Freedom Party. Douglas died suddenly after only eight months in office, on October 1, 2000, and was replaced by Pierre Charles, also of the DLP. In 2003, Nicholas Liverpool was elected and sworn in as president, succeeding Vernon Shaw. On January 6, 2004, Prime Minister Pierre Charles, who had been suffering from heart problems since 2003, died. He became the second consecutive prime minister of Dominica to die in office of a heart attack. The foreign minister, Osborne Riviere immediately became prime minister, but the education minister, Roosevelt Skerrit succeeded him as prime minister and became the new leader of the Dominica Labour Party. Elections were held on May 5, 2005, with the ruling coalition maintaining power.

In 2017, Hurricane Maria struck Dominica and was the most powerful and devastating hurricane ever recorded in Dominica.

President Charles Angelo Savarin was re-elected in 2018.

In the 2019 general elections The Dominica Labour Party (DLP) was given another overwhelming mandate – for a record fifth consecutive five-year term. The party’s charismatic but often maligned leader, Roosevelt Skerrit, will serve a new five-year term as the Prime Minister of Dominica.




Geography of Dominica

Dominica is an island in the Caribbean Sea, located about halfway between the French islands of Guadeloupe (to the north) and Martinique (to the south). Its coordinates are 15 25 N, 61 20 W. It is known as "The Nature Island of the Caribbean" due to its spectacular, lush, and varied flora and fauna, which is protected by an extensive natural park system. It is the fourth largest island in the Eastern Caribbean with a population of people mainly of African descent.

The lowest point in the country is at sea level along the coast, and the highest is Morne Diablotins (). The extreme southwestern coast of the island includes a large collapsed submarine caldera. Portions of the exposed rim of this caldera form the southwestern tip of the island at Scotts Head. Natural resources include farming, hydropower and timber.

Geographically, Dominica is distinctive in many ways. The country has one of the most rugged landscapes in the Caribbean, covered by a largely unexploited, multi-layered rain forest. It is also among the Earth's most rain-drenched lands, and the water runoff forms cascading rivers and natural pools. The island, home to rare species of wildlife, is considered by many as a beautiful, unspoiled tropical preserve. According to a popular West Indian belief, Dominica is the only New World territory that Columbus would still recognize.

Dominica is the largest and most northerly of the Windward Islands. The island faces the Atlantic Ocean to the east and the Caribbean Sea to the west. Its nearest neighbours are the French islands of Guadeloupe, some north, and Martinique, about south. Oblong-shaped and slightly smaller than New York City, Dominica is in area, in length, and in width. Roseau, the nation's capital and major port, is favourably situated on the sheltered, southwestern coast.

The island's climate is tropical, moderated by northeast trade winds and heavy rainfall.

Dominica has a tropical rainforest climate and some areas bordering on a tropical monsoon climate with characteristically warm temperatures and heavy rainfall. Excessive heat and humidity are tempered somewhat by a steady flow of the northeast trade winds, which periodically develop into hurricanes during the Northern Hemisphere's summer. The steep interior slopes also alter temperatures and winds. Because of the moderating effects of the surrounding ocean, temperature ranges are slight. Average daytime temperatures generally vary from in January to in June. Diurnal ranges are usually no greater than in most places, but temperatures dipping to on the highest peaks are not uncommon.

Most of the island's ample supply of water is brought by the.. trade winds. Although amounts vary with the location, rain is possible throughout the year, with the greatest monthly totals recorded from June through October. Average yearly rainfall along the windward east coast frequently exceeds , and exposed mountainsides receive up to , among the highest accumulations in the world. Totals on the leeward west coast, however, are only about per year. Humidities are closely tied to rainfall patterns, with the highest values occurring on windward slopes and the lowest in sheltered areas. Relative humidity readings between 70 percent and 90 percent have been recorded in Roseau.

Hurricanes and severe winds, most likely to occur during the wettest months, occasionally are devastating. The most recent hurricane of note was the devastating Hurricane Maria in 2017. On August 17, 2007, Hurricane Dean, a Category 1 at the time, hit the island. A mother and her seven-year-old son died when a landslide caused by the heavy rains fell onto their house. In another incident two people were injured when a tree fell on their house. Prime Minister Roosevelt Skerrit estimated that 100 to 125 homes were damaged, and that the agriculture sector was extensively damaged, in particular the banana crop. Before that were David and Frederic in August 1979 and Allen in August 1980. The 1979 hurricanes caused over 40 deaths, 2,500 injuries, and extensive destruction of housing and crops. Many agricultural commodities were destroyed during the 1980 storm, and about 25 percent of the banana crop was destroyed by strong winds in 1984.

Below is the climate data for Roseau, the capital city located on the western side of Dominica partially shielded from the trade winds by the mountains.

Bays are as follows from the northern tip of the island in a clockwise direction:

Agoucha Bay,
Sandwich Bay,
Grand Baptiste Bay,
Petit Baptiste Bay, 
La Taille Bay, Rough Bay,
Marigot Bay,
Walker's Rest Bay,
Sophia Bay,
Londonderry Bay, 
Mango Hole Bay,
Middle Bay,
Panto Hole Bay,
Petite Soufriere Bay, 
Soufriere Bay, 
Woodbridge Bay,
Prince Rupert Bay,
Douglas Bay.

Dominica was the last island to be formed in the Caribbean. The island was created by volcanic action about 26 million years ago. It lies upon two opposing tectonic plates. This explains why an island a bit bigger than Martha's Vineyard has mountains approaching .

Geologically, Dominica is part of the rugged Lesser Antilles volcanic arc. The country's central spine, a northwest–southeast axis of steep volcanic slopes and deep gorges, generally varies in elevation from above sea level. Several east-west trending mountain spurs extend to the narrow coastal plain, which is studded with sea cliffs and has level stretches no wider than . The highest peak is Morne Diablotins, at ; Morne Trois Pitons, with an elevation of , lies farther south and is the site of the national park.

The interior features rugged mountains of volcanic origin. Volcanism is still quite evident on the island, the most popular examples being Dominica's Boiling Lake and "valley of desolation." The boiling lake (the world's second largest) is within a crater and is fed by a waterfall - the boiling is believed to be caused by the heat of a magma chamber beneath the lake. The valley of desolation is a sulfurous valley of volcanic vents and hot springs that inhibits significant plant growth - in stark contrast to the surrounding rain forest. Technically dormant today, this caldera last erupted in 1880. The area that exploded on 4 January 1880 was reported to be "fully nine square miles".
Dominica's rugged surface is marked by its volcanic past. Rock formations are mainly volcanic andesite and rhyolite, with fallen boulders and sharp-edged protrusions peppering slope bases. The light- to dark-hued clay and sandy soils, derived from the rocks and decomposed vegetation, are generally fertile and porous. Only a few interior valleys and coastal strips are flat enough for soil accumulations of consequence, however. Although scores of mostly mild seismic shocks were recorded in 1986, volcanic eruptions ceased thousands of years ago. Sulfuric springs and steam vents, largely concentrated in the central and southern parts of the island, remain active, however. One of the largest springs, Boiling Lake, is located in the national park.

Dominica is water-rich with swift-flowing highland streams, which cascade into deep gorges and form natural pools and crater lakes. The streams are not navigable, but many are sources of hydroelectric power. Trafalgar Falls, located near the national park, is one of the most spectacular sites on the island. The falls consists of twin waterfalls known as the mother and father or the Mama and the Papa. At the base of each waterfall are natural pools. Locals and tourists alike come here to enjoy the water. At the base of the Papa fall a natural hot spring can also be found which heats a portion of its pool. The principal rivers flowing westward are the Layou and the Roseau, and the major one emptying eastward is the Toulaman. The largest crater lake, called Boeri, is located in the national park. There are 83 "significant" waterways on the island out of a total of 365 with also includes rills and brooks.

There are 172 species of birds, including four species of hummingbird, broad-winged hawks, yellow-crowned night herons, and the brown trembler. Some plants and animals thought to be extinct on surrounding islands can still be found in Dominica's forests.

The sisserou parrot is Dominica's national bird and is indigenous to its mountain forests.

The Caribbean Sea offshore of the island of Dominica is home to many cetaceans. Most notably a small group of sperm whales live in this area year round. These are shy animals, but there is a good chance of seeing them if you go out on a calm day. Other cetaceans commonly seen in the area include pilot whale, Fraser's dolphin, pantropical spotted dolphin and bottlenose dolphin. Less commonly seen animals include Cuvier's beaked whale, false killer whale, pygmy sperm whale, dwarf sperm whale, Risso's dolphin, common dolphin, humpback whale and Bryde's whale. This makes Dominica a destination for tourists interested in whale-watching.

Map references:
Central America and the Caribbean

Area:
"total:"
751 km
"land:"
751 km

Coastline:
148 km

Maritime claims:
"territorial sea:"

"contiguous zone:"

"exclusive economic zone:"
Land use:
"arable land:"
8%
"permanent crops:"
24%
"other:"
68% (2012 est.)

Irrigated land:
NA km

Freshwater withdrawal (domestic/industrial/agricultural):
"total:" 0.02 km/a
"per capita:" 244.1 m/a (2004)

Natural hazards:
Flash floods are a constant threat; destructive hurricanes can be expected during the late summer months

Environment - international agreements:

"Party to:"
Biodiversity, Climate Change, Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Ozone Layer Protection, Ship Pollution, Whaling



Attribution: 

Demographics of Dominica

This is a demography of the population of Dominica including population density, ethnicity, religious affiliations and other aspects of the population.

According to the preliminary 2011 census results Dominica has a population of 71,293. The population growth rate is very low, due primarily to emigration to more prosperous Caribbean Islands, the United Kingdom, the United States, Canada, and Australia. The estimated mid-year population of is ().

The vast majority of Dominicans are of African descent (75% at the 2014 census). There is a significant mixed population (19%) at the 2014 census due to intermarriage, along with a small European origin minority (0.8%; descendants of French, British, and Irish colonists), East Indians (0.1%) groups, and there are small numbers of Lebanese/Syrians (0.1%) and Asians.

Dominica is the only Eastern Caribbean island that still has a population of pre-Columbian native Caribs (also known as Kalinago), who were exterminated, driven from neighbouring islands, or mixed with Africans and/or Europeans. According to the 2001 census there are only 2,001 Caribs remaining (2.9% of the total population). A considerable growth occurred since the 1991 census when 1,634 Caribs were counted (2.4% of the total population). 
The Caribs live in eight villages on the east coast of Dominica. This special Carib Territory was granted by the British Crown in 1903.
The present number of Kalinago is estimated at 4% more than 3,000.

Demographic statistics according to the CIA World Factbook, unless otherwise indicated.
















English is the official language and universally understood; however, because of historic French domination, Antillean Creole, a French-lexified creole language, is also widely spoken.

According to the 2001 census, 91.2% percent of the population of Dominica is considered Christian, 1.6% has a non-Christian religion and 6.1% has no religion or did not state a religion (1.1%).

Roughly 58% of Christians are Roman Catholics, a reflection of early French influence on the island, and one third are Protestant. The Evangelicals constitute the largest Protestant group, with 6.7% of the population. Seventh-day Adventists are the second largest group (6.1%). The next largest group are Pentecostals (5.6% of the population), followed by Baptists (4.1%). Other Christians include Methodists (3.7%), Church of God (1.2%), Jehovah's Witnesses (1.2%), Anglicanism (0.6%) and Brethren Christian (0.3%).
During the past decades the number of Roman Catholics and Anglicans has decreased, while the number of other Protestants has increased, especially Evangelicals, Seventh-day Adventists, Pentecostals (5.6% of the population) and Baptists).

The number of non-Christians is small. These religious groups include the Rastafarian Movement (1.3% of the population), Hinduism (0.1%) and Muslims (0.2%).

Politics of Dominica

The politics of Dominica takes place in a framework of a parliamentary representative democratic republic, whereby the Prime Minister of Dominica is the head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and the House of Assembly. The Judiciary is independent of the executive and the legislature.

A president and prime minister make up the executive branch. Nominated by the prime minister in consultation with the leader of the opposition party, the president is elected for a five-year term by the parliament. The president appoints as prime minister the person who command the majority of elected representatives in the parliament and also appoints, on the prime minister's recommendation, members of the parliament as cabinet ministers. The prime minister and cabinet are responsible to the parliament and can be removed on a no-confidence vote.

The House of Assembly has 32 members. Twenty-one members are elected for a five-year term in single-seat constituencies. Nine members are senators appointed by the President; five on the advice of the Prime Minister and four on the advice of the leader of the opposition. The Speaker is elected by the elected members after an election. There is also one ex officio member, the clerk of the house. The head of state – the president – is elected by the House of Assembly. The regional representatives decide whether senators are to be elected or appointed. If appointed, five are chosen by the president with the advice of the prime minister and four with the advice of the opposition leader. If elected, it is by vote of the regional representatives. Elections for representatives and senators must be held at least every five years, although the prime minister can call elections at any time.

Dominica has a two-party system, which means that there are two dominant political parties, with extreme difficulty for anybody to achieve electoral success under the banner of any other party. Dominica was once a three-party system, but in the past few years the Dominica Labour Party and the greatly diminished Dominica Freedom Party have built a coalition.

Dominica's legal system is based on English common law. There are three magistrate's courts and a High Court of Justice. Appeals can be made to the Eastern Caribbean Court of Appeal and, ultimately, to the Caribbean Court of Justice.

The Court of Appeal of the Eastern Caribbean Supreme Court is headquartered in Saint Lucia, but at least one of its 16 High Court judges must reside in Dominica and preside over the High Court of Justice. Dominica's current High Court judges are The Hon. Brian Cottle and The Hon. M. E. Birnie Stephenson-Brooks.

Councils elected by universal suffrage govern most towns. Supported largely by property taxation, the councils are responsible for the regulation of markets and sanitation and the maintenance of secondary roads and other municipal amenities. The island also is divided into 10 parishes, whose governance is unrelated to the town governments: Saint Andrew, Saint David, Saint George, Saint John, Saint Joseph, Saint Luke, Saint Mark, Saint Patrick, Saint Paul, and Saint Peter.

ACP, ALBA, Caricom, CDB, CELAC, Commonwealth of Nations, ECLAC, FAO, G-77, IBRD, ICC, ICRM, IDA, IFAD, IFC, IFRCS, ILO, IMF, IMO, Interpol, IOC, ITU, ITUC, NAM (observer), OAS, OIF, OECS, OPANAL, OPCW, UN, UNCTAD, UNESCO, UNIDO, UPU, WHO, WIPO, WMO, WTrO


Telecommunications in Dominica

Telecommunications in Dominica comprises telephone, radio, television and internet services. The primary regulatory authority is the National Telecommunication Regulatory Commission which regulates all related industries to comply with The Telecommunications Act 8 of 2000.

Calls from Dominica to the US, Canada, and other NANP Caribbean nations, are dialed as 1 + NANP area code + 7-digit number. Calls from Dominica to non-NANP countries are dialed as 011 + country code + phone number with local area code.




AM 0, FM 15, shortwave 0 (2007)

46,000 (1997)

0 (however, there are three cable television companies, Dominica Broadcast, Marpin Telecoms and Digicel Play – a merger of Digicel and SAT Telecommunications Ltd.)

11,000 (2007)




Dominica Defense Force

The Dominica Defense Forces (DDF) was the military of the Commonwealth of Dominica. There has been no standing army in Dominica since 1981, following the disbandment of the defence forces after two violent coup attempts against Dame Eugenia Charles. Defense is the responsibility of the Regional Security System (RSS).

By the 1960s, the police were the only security force in the country. As a result, a Volunteer Defence Force was established in 1974. In November 1975, a full-time Defence Force was established by an act of the House of Assembly to replace the Volunteer Defence Force, headed by Patrick John as Minister of Security. In March 1981, Charles announced the discovery of a coup d'état attempt known as Operation Red Dog, which involved Major Frederick Newton, the head of the Defence Force. A month later, parliament disbanded the Defence Force. 

The civil Commonwealth of Dominica Police Force includes a Special Service Unit and Coast Guard. In the event of war or other emergency, if proclaimed by the authorities, the Police Force shall be a military force which may be employed for State defence ("Police Act", Chapter 14:01).

Foreign relations of Dominica

Like its Eastern Caribbean neighbours, the main priority of Dominica's foreign relations is economic development. The country maintains missions in Washington, New York, London, and Brussels and is represented jointly with other Organisation of Eastern Caribbean States (OECS) members in Canada. Dominica is also a member of the Caribbean Development Bank (CDB), Organisation internationale de la Francophonie, and the Commonwealth of Nations. It became a member of the United Nations and the International Monetary Fund (IMF) in 1978 and of the World Bank and Organization of American States (OAS) in 1979.

As a member of CARICOM, in July 1994 Dominica strongly backed efforts by the United States to implement United Nations Security Council Resolution 940, designed to facilitate the departure of Haiti's de facto authorities from power. The country agreed to contribute personnel to the multinational force, which restored the democratically elected government of Haiti in October 1994.

In May 1997, Prime Minister James joined 14 other Caribbean leaders, and President Clinton, during the first-ever U.S.-regional summit in Bridgetown, Barbados. The summit strengthened the basis for regional cooperation on justice and counternarcotics issues, finance and development, and trade. Dominica previously maintained official relations with the Republic of China (commonly known as "Taiwan") instead of the People's Republic of China, but on 23 March 2004, a joint communique was signed in Beijing, paving the way for diplomatic recognition of the People's Republic. Beijing responded to Dominica's severing relations with the Republic of China by giving them a $12 million aid package, which includes $6 million in budget support for the year 2004 and $1 million annually for six years.

In June 2020, Dominica was one of 53 countries backing the Hong Kong national security law at the United Nations.

Dominica is also a member of the International Criminal Court with a Bilateral Immunity Agreement of protection for the US-military (as covered under Article 98).

Dominica claims Venezuelan controlled Isla Aves (Known in Dominica as Bird Rock) located roughly 90 km. west of Dominica.

List of countries which Dominica maintains diplomatic relations with

The Commonwealth of Dominica has been a member of the Commonwealth of Nations since 1978, when it became an independent from the United Kingdom as a republic in the Commonwealth of Nations.

Dominica's highest court of appeal is the Caribbean Court of Justice, in effect from 6 March 2015. Previously, the nation's ultimate court of appeal was the Judicial Committee of the Privy Council in London.



