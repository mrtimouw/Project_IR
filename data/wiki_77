Developmental psychology

Developmental psychology is the scientific study of how and why humans grow, change, and adapt across the course of their lives. Originally concerned with infants and children, the field has expanded to include adolescence, adult development, aging, and the entire lifespan. Developmental psychologists aim to explain how thinking, feeling, and behaviors change throughout life. This field examines change across three major dimensions, which are physical development, cognitive development, and social emotional development. Within these three dimensions are a broad range of topics including motor skills, executive functions, moral understanding, language acquisition, social change, personality, emotional development, self-concept, and identity formation.

Developmental psychology examines the influences of nature "and" nurture on the process of human development, as well as processes of change in context across time. Many researchers are interested in the interactions among personal characteristics, the individual's behavior, and environmental factors. This includes the social context and the built environment. Ongoing debates in regards to developmental psychology include biological essentialism vs. neuroplasticity and stages of development vs. dynamic systems of development. Research in developmental psychology has some limitations but at the moment researchers are working to understand how transitioning through stages of life and biological factors may impact our behaviors and development"."

Developmental psychology involves a range of fields, such as educational psychology, child psychopathology, forensic developmental psychology, child development, cognitive psychology, ecological psychology, and cultural psychology. Influential developmental psychologists from the 20th century include Urie Bronfenbrenner, Erik Erikson, Sigmund Freud, Anna Freud, Jean Piaget, Barbara Rogoff, Esther Thelen, and Lev Vygotsky.

Jean-Jacques Rousseau and John B. Watson are typically cited as providing the foundation for modern developmental psychology. In the mid-18th century, Jean Jacques Rousseau described three stages of development: "infants" (infancy), "puer" (childhood) and "adolescence" in "". Rousseau's ideas were adopted and supported by educators at the time.

Developmental psychology generally focuses on how and why certain changes (cognitive, social, intellectual, personality) occur over time in the course of a human life. Many theorists have made a profound contribution to this area of psychology. One of them, Erik Erikson developed a model of eight stages of psychological development. He believed that humans developed in stages throughout their lifetimes and that this would affect their behaviors.

In the late 19th century, psychologists familiar with the evolutionary theory of Darwin began seeking an evolutionary description of psychological development; prominent here was the pioneering psychologist G. Stanley Hall, who attempted to correlate ages of childhood with previous ages of humanity. James Mark Baldwin, who wrote essays on topics that included "Imitation: A Chapter in the Natural History of Consciousness" and "Mental Development in the Child and the Race: Methods and Processes", was significantly involved in the theory of developmental psychology. Sigmund Freud, whose concepts were developmental, significantly affected public perceptions.

Sigmund Freud developed a theory that suggested that humans behave as they do because they are constantly seeking pleasure. This process of seeking pleasure changes through stages because people evolve. Each period of seeking pleasure that a person experiences is represented by a stage of psychosexual development. These stages symbolize the process of arriving to become a maturing adult.

The first is the "oral stage", which begins at birth and ends around a year and a half of age. During the oral stage, the child finds pleasure in behaviors like sucking or other behaviors with the mouth. The second is the "anal stage", from about a year or a year and a half to three years of age. During the anal stage, the child defecates from the anus and is often fascinated with its defecation. This period of development often occurs during the time when the child is being toilet trained. The child becomes interested with feces and urine. Children begin to see themselves as independent from their parents. They begin to desire assertiveness and autonomy.

The third is the "phallic stage", which occurs from three to five years of age (most of a person's personality forms by this age). During the phallic stage, the child becomes aware of its sexual organs. Pleasure comes from finding acceptance and love from the opposite sex. The fourth is the "latency stage", which occurs from age five until puberty. During the latency stage, the child's sexual interests are repressed.

Stage five is the "genital stage", which takes place from puberty until adulthood. During the genital stage, puberty begins to occur. Children have now matured, and begin to think about other people instead of just themselves. Pleasure comes from feelings of affection from other people.

Freud believed there is tension between the conscious and unconscious because the conscious tries to hold back what the unconscious tries to express. To explain this, he developed three personality structures: id, ego, and superego. The id, the most primitive of the three, functions according to the pleasure principle: seek pleasure and avoid pain. The superego plays the critical and moralizing role, while the ego is the organized, realistic part that mediates between the desires of the id and the superego.

Jean Piaget, a Swiss theorist, posited that children learn by actively constructing knowledge through their interactions with their physical and social environments. He suggested that the adult's role in helping the child learn was to provide appropriate materials. In his interview techniques with children that formed an empirical basis for his theories, he used something similar to Socratic questioning to get children to reveal their thinking. He argued that a principal source of development was through the child's inevitable generation of contradictions through their interactions with their physical and social worlds. The child's resolution of these contradictions led to more integrated and advanced forms of interaction, a developmental process that he called, "equilibration." 

Piaget argued that intellectual development takes place through a series of stages generated through the equilibration process. Each stage consists of steps the child must master before moving to the next step. He believed that these stages are not separate from one another, but rather that each stage builds on the previous one in a continuous learning process. He proposed four stages: "sensorimotor", "pre-operational", "concrete operational", and "formal operational". Though he did not believe these stages occurred at any given age, many studies have determined when these cognitive abilities should take place.

Piaget claimed that logic and morality develop through constructive stages. Expanding on Piaget's work, Lawrence Kohlberg determined that the process of moral development was principally concerned with justice, and that it continued throughout the individual's lifetime.

He suggested three levels of moral reasoning; pre-conventional moral reasoning, conventional moral reasoning, and post-conventional moral reasoning. The pre-conventional moral reasoning is typical of children and is characterized by reasoning that is based on rewards and punishments associated with different courses of action. Conventional moral reason occurs during late childhood and early adolescence and is characterized by reasoning based on rules and conventions of society. Lastly, post-conventional moral reasoning is a stage during which the individual sees society's rules and conventions as relative and subjective, rather than as authoritative.

Kohlberg used the Heinz Dilemma to apply to his stages of moral development. The Heinz Dilemma involves Heinz's wife dying from cancer and Heinz having the dilemma to save his wife by stealing a drug. Preconventional morality, conventional morality, and post-conventional morality applies to Heinz's situation.

German-American psychologist Erik Erikson and his collaborator and wife, Joan Erikson, posits eight stages of individual human development influenced by biological, psychological, and social factors throughout the lifespan."" At each stage the person must resolve a challenge, or an existential dilemma. Successful resolution of the dilemma results in the person ingraining a positive virtue, but failure to resolve the fundamental challenge of that stage reinforces negative perceptions of the person or the world around them and the person's personal development is unable to progress.
The first stage, "Trust vs. Mistrust", takes place in infancy. The positive virtue for the first stage is hope, in the infant learning whom to trust and having hope for a supportive group of people to be there for him/her. The second stage is "Autonomy vs. Shame and Doubt" with the positive virtue being will. This takes place in early childhood when the child learns to become more independent by discovering what they are capable of whereas if the child is overly controlled, feelings of inadequacy are reinforced, which can lead to low self-esteem and doubt.

The third stage is "Initiative vs. Guilt". The virtue of being gained is a sense of purpose. This takes place primarily via play. This is the stage where the child will be curious and have many interactions with other kids. They will ask many questions as their curiosity grows. If too much guilt is present, the child may have a slower and harder time interacting with their world and other children in it.

The fourth stage is "Industry (competence) vs. Inferiority". The virtue for this stage is competency and is the result of the child's early experiences in school. This stage is when the child will try to win the approval of others and understand the value of their accomplishments.

The fifth stage is "Identity vs. Role Confusion". The virtue gained is fidelity and it takes place in adolescence. This is when the child ideally starts to identify their place in society, particularly in terms of their gender role.

The sixth stage is "Intimacy vs. Isolation", which happens in young adults and the virtue gained is love. This is when the person starts to share his/her life with someone else intimately and emotionally. Not doing so can reinforce feelings of isolation.

The seventh stage is "Generativity vs. Stagnation". This happens in adulthood and the virtue gained is care. A person becomes stable and starts to give back by raising a family and becoming involved in the community.

The eighth stage is "Ego Integrity vs. Despair". When one grows old, they look back on their life and contemplate their successes and failures. If they resolve this positively, the virtue of wisdom is gained. This is also the stage when one can gain a sense of closure and accept death without regret or fear.

Michael Commons enhanced and simplified Bärbel Inhelder and Piaget's developmental theory and offers a standard method of examining the universal pattern of development. The Model of Hierarchical Complexity (MHC) is not based on the assessment of domain-specific information, It divides the Order of Hierarchical Complexity of tasks to be addressed from the Stage performance on those tasks. A stage is the order hierarchical complexity of the tasks the participant's successfully addresses. He expanded Piaget's original eight stage (counting the half stages) to seventeen stages. The stages are:


The order of hierarchical complexity of tasks predicts how difficult the performance is with an R ranging from 0.9 to 0.98.

In the MHC, there are three main axioms for an order to meet in order for the higher order task to coordinate the next lower order task. Axioms are rules that are followed to determine how the MHC orders actions to form a hierarchy. These axioms are: a) defined in terms of tasks at the next lower order of hierarchical complexity task action; b) defined as the higher order task action that organizes two or more less complex actions; that is, the more complex action specifies the way in which the less complex actions combine; c) defined as the lower order task actions have to be carried out non-arbitrarily.

Ecological systems theory, originally formulated by Urie Bronfenbrenner, specifies four types of nested environmental systems, with bi-directional influences within and between the systems. The four systems are microsystem, mesosystem, exosystem, and macrosystem. Each system contains roles, norms and rules that can powerfully shape development. The microsystem is the direct environment in our lives such as our home and school. Mesosystem is how relationships connect to the microsystem. Exosystem is a larger social system where the child plays no role. Macrosystem refers to the cultural values, customs and laws of society.

The microsystem is the immediate environment surrounding and influencing the individual (example: school or the home setting). The mesosystem is the combination of two microsystems and how they influence each other (example: sibling relationships at home vs. peer relationships at school). The exosystem is the interaction among two or more settings that are indirectly linked (example: a father's job requiring more overtime ends up influencing his daughter's performance in school because he can no longer help with her homework). The macrosystem is broader taking into account social economic status, culture, beliefs, customs and morals (example: a child from a wealthier family sees a peer from a less wealthy family as inferior for that reason). Lastly, the chronosystem refers to the chronological nature of life events and how they interact and change the individual and their circumstances through transition (example: a mother losing her own mother to illness and no longer having that support in her life).

Since its publication in 1979, Bronfenbrenner's major statement of this theory, "The Ecology of Human Development", has had widespread influence on the way psychologists and others approach the study of human beings and their environments. As a result of this conceptualization of development, these environments—from the family to economic and political structures—have come to be viewed as part of the life course from childhood through to adulthood.

Lev Vygotsky was a Russian theorist from the Soviet era, who posited that children learn through hands-on experience and social interactions with members of their culture. Vygotsky believed that a child's development should be examined during problem-solving activities. Unlike Piaget, he claimed that timely and sensitive intervention by adults when a child is on the edge of learning a new task (called the "zone of proximal development") could help children learn new tasks. Zone of proximal development is a tool used to explain the learning of children and collaborating problem solving activities with an adult or peer. This adult role is often referred to as the skilled "master", whereas the child is considered the learning apprentice through an educational process often termed "cognitive apprenticeship" Martin Hill stated that "The world of reality does not apply to the mind of a child." This technique is called "scaffolding", because it builds upon knowledge children already have with new knowledge that adults can help the child learn. Vygotsky was strongly focused on the role of culture in determining the child's pattern of development, arguing that development moves from the social level to the individual level. In other words, Vygotsky claimed that psychology should focus on the progress of human consciousness through the relationship of an individual and their environment. He felt that if scholars continued to disregard this connection, then this disregard would inhibit the full comprehension of the human consciousness.

Constructivism is a paradigm in psychology that characterizes learning as a process of actively constructing knowledge. Individuals create meaning for themselves or make sense of new information by selecting, organizing, and integrating information with other knowledge, often in the context of social interactions. Constructivism can occur in two ways: individual and social. Individual constructivism is when a person constructs knowledge through cognitive processes of their own experiences rather than by memorizing facts provided by others. Social constructivism is when individuals construct knowledge through an interaction between the knowledge they bring to a situation and social or cultural exchanges within that content. A foundational concept of constructivism is that the purpose of cognition is to organize one's experiential world, instead of the ontological world around them.

Jean Piaget, a Swiss developmental psychologist, proposed that learning is an active process because children learn through experience and make mistakes and solve problems. Piaget proposed that learning should be whole by helping students understand that meaning is constructed.

Evolutionary developmental psychology is a research paradigm that applies the basic principles of Darwinian evolution, particularly natural selection, to understand the development of human behavior and cognition. It involves the study of both the genetic and environmental mechanisms that underlie the development of social and cognitive competencies, as well as the epigenetic (gene-environment interactions) processes that adapt these competencies to local conditions.

EDP considers both the reliably developing, species-typical features of ontogeny (developmental adaptations), as well as individual differences in behavior, from an evolutionary perspective. While evolutionary views tend to regard most individual differences as the result of either random genetic noise (evolutionary byproducts) and/or idiosyncrasies (for example, peer groups, education, neighborhoods, and chance encounters) rather than products of natural selection, EDP asserts that natural selection can favor the emergence of individual differences via "adaptive developmental plasticity". From this perspective, human development follows alternative life-history strategies in response to environmental variability, rather than following one species-typical pattern of development.

EDP is closely linked to the theoretical framework of evolutionary psychology (EP), but is also distinct from EP in several domains, including research emphasis (EDP focuses on adaptations of ontogeny, as opposed to adaptations of adulthood) and consideration of proximate ontogenetic and environmental factors (i.e., how development happens) in addition to more ultimate factors (i.e., why development happens), which are the focus of mainstream evolutionary psychology.

Attachment theory, originally developed by John Bowlby, focuses on the importance of open, intimate, emotionally meaningful relationships. Attachment is described as a biological system or powerful survival impulse that evolved to ensure the survival of the infant. A threatened or stressed child will move toward caregivers who create a sense of physical, emotional, and psychological safety for the individual. Attachment feeds on body contact and familiarity. Later Mary Ainsworth developed the Strange Situation protocol and the concept of the secure base. This tool has been found to help understand attachment, such as the Strange Situation Test and the Adult Attachment Interview. Both of which help determine factors to certain attachment styles. The Strange Situation Test helps find "disturbances in attachment" and whether certain attributes are found to contribute to a certain attachment issue. The Adult Attachment Interview is a tool that is similar to the Strange Situation Test but instead focuses attachment issues found in adults. Both tests have helped many researchers gain more information on the risks and how to identify them.

Theorists have proposed four types of attachment styles: secure, anxious-avoidant, anxious-resistant, and disorganized. Secure attachment is a healthy attachment between the infant and the caregiver. It is characterized by trust. Anxious-avoidant is an insecure attachment between an infant and a caregiver. This is characterized by the infant's indifference toward the caregiver. Anxious-resistant is an insecure attachment between the infant and the caregiver characterized by distress from the infant when separated and anger when reunited. Disorganized is an attachment style without a consistent pattern of responses upon return of the parent.

A child can be hindered in its natural tendency to form attachments. Some babies are raised without the stimulation and attention of a regular caregiver or locked away under conditions of abuse or extreme neglect. The possible short-term effects of this deprivation are anger, despair, detachment, and temporary delay in intellectual development. Long-term effects include increased aggression, clinging behavior, detachment, psychosomatic disorders, and an increased risk of depression as an adult.\

According to the theory, attachment is established in early childhood and attachment continues into adulthood. As such, proponents posit that the attachment style that individuals form in childhood impacts the way they manage stressors in intimate relationships as an adult.

A significant debate in developmental psychology is the relationship between innateness and environmental influence in regard to any particular aspect of development. This is often referred to as "nature and nurture" or nativism versus empiricism. A nativist account of development would argue that the processes in question are innate, that is, they are specified by the organism's genes. What makes a person who they are? Is it their environment or their genetics? This is the debate of nature vs nurture.

An empiricist perspective would argue that those processes are acquired in interaction with the environment. Today developmental psychologists rarely take such polarized positions with regard to most aspects of development; rather they investigate, among many other things, the relationship between innate and environmental influences. One of the ways this relationship has been explored in recent years is through the emerging field of evolutionary developmental psychology.

One area where this innateness debate has been prominently portrayed is in research on language acquisition. A major question in this area is whether or not certain properties of human language are specified genetically or can be acquired through learning. The empiricist position on the issue of language acquisition suggests that the language input provides the necessary information required for learning the structure of language and that infants acquire language through a process of statistical learning. From this perspective, language can be acquired via general learning methods that also apply to other aspects of development, such as perceptual learning.

The nativist position argues that the input from language is too impoverished for infants and children to acquire the structure of language. Linguist Noam Chomsky asserts that, evidenced by the lack of sufficient information in the language input, there is a universal grammar that applies to all human languages and is pre-specified. This has led to the idea that there is a special cognitive module suited for learning language, often called the language acquisition device. Chomsky's critique of the behaviorist model of language acquisition is regarded by many as a key turning point in the decline in the prominence of the theory of behaviorism generally. But Skinner's conception of "Verbal Behavior" has not died, perhaps in part because it has generated successful practical applications.

Maybe there could be "strong interactions of both nature and nurture".

One of the major discussions in developmental psychology includes whether development is discontinuous or continuous.

Continuous development is quantifiable and quantitative, whereas discontinuous development is qualitative. Quantitative estimations of development can be measuring the stature of a child, and measuring their memory or consideration span. "Particularly dramatic examples of qualitative changes are metamorphoses, such as the emergence of a caterpillar into a butterfly."

Those psychologists who bolster the continuous view of improvement propose that improvement includes slow and progressing changes all through the life span, with behavior within the prior stages of advancement giving the premise of abilities and capacities required for the other stages. "To many, the concept of continuous, quantifiable measurement seems to be the essence of science".

Not all psychologists, be that as it may, concur that advancement could be a continuous process. A few see advancement as a discontinuous process. They accept advancement includes unmistakable and partitioned stages with diverse sorts of behavior happening in each organization. This proposes that the development of certain capacities in each arrange, such as particular feelings or ways of considering, have a definite beginning and finishing point. Be that as it may, there's no correct time at which a capacity abruptly shows up or disappears. Although some sorts of considering, feeling or carrying on could seem to seem abruptly, it is more than likely that this has been developing gradually for some time.

Stage theories of development rest on the suspicion that development may be a discontinuous process including particular stages which are characterized by subjective contrasts in behavior. They moreover assume that the structure of the stages is not variable concurring to each person, in any case, the time of each arrangement may shift separately. Stage theories can be differentiated with ceaseless hypotheses, which set that development is an incremental process.

This issue involves the degree to which one becomes older renditions of their early experience or whether they develop into something different from who they were at an earlier point in development. It considers the extent to which early experiences (especially infancy) or later experiences are the key determinants of a person's development. Stability is defined as the consistent ordering of individual differences with respect to some attribute. Change is altering someone/something.

Most human development lifespan developmentalists recognize that extreme positions are unwise. Therefore, the key to a comprehensive understanding of development at any stage requires the interaction of different factors and not only one.

Theory of mind is the ability to attribute mental states to ourselves and others. It is a complex but vital process in which children begin to understand the emotions, motives, and feelings of not only themselves but also others. Theory of mind allows people to understand that others have unique beliefs and desires that are different from our own. This enables people to engage in daily social interactions as we explain the mental state around us. If a child does not fully develop theory of mind within this crucial 5-year period, they can suffer from communication barriers that follow them into adolescence and adulthood. Exposure to more people and the availability of stimuli that encourages social-cognitive growth is a factor that relies heavily on family.

Developmental psychology is concerned not only with describing the characteristics of psychological change over time but also seeks to explain the principles and internal workings underlying these changes. Psychologists have attempted to better understand these factors by using models. A model must simply account for the means by which a process takes place. This is sometimes done in reference to changes in the brain that may correspond to changes in behavior over the course of the development.

Mathematical modeling is useful in developmental psychology for implementing theory in a precise and easy-to-study manner, allowing generation, explanation, integration, and prediction of diverse phenomena. Several modeling techniques are applied to development: symbolic, connectionist (neural network), or dynamical systems models.

Dynamic systems models illustrate how many different features of a complex system may interact to yield emergent behaviors and abilities. Nonlinear dynamics has been applied to human systems specifically to address issues that require attention to temporality such as life transitions, human development, and behavioral or emotional change over time. Nonlinear dynamic systems is currently being explored as a way to explain discrete phenomena of human development such as affect, second language acquisition, and locomotion.

One critical aspect of developmental psychology is the study of neural development, which investigates how the brain changes and develops during different stages of life. Neural development focuses on how the brain changes and develops during different stages of life. Studies have shown that the human brain undergoes rapid changes during prenatal and early postnatal periods. These changes include the formation of neurons, the development of neural networks, and the establishment of synaptic connections. The formation of neurons and the establishment of basic neural circuits in the developing brain are crucial for laying the foundation of the brain's structure and function, and disruptions during this period can have long-term effects on cognitive and emotional development.

Experiences and environmental factors play a crucial role in shaping neural development. Early sensory experiences, such as exposure to language and visual stimuli, can influence the development of neural pathways related to perception and language processing.

Genetic factors play a huge roll in neural development. Genetic factors can influence the timing and pattern of neural development, as well as the susceptibility to certain developmental disorders, such as autism spectrum disorder and attention-deficit/hyperactivity disorder.

Research finds that the adolescent brain undergoes significant changes in neural connectivity and plasticity. During this period, there is a pruning process where certain neural connections are strengthened while others are eliminated, resulting in more efficient neural networks and increased cognitive abilities, such as decision-making and impulse control.

The study of neural development provides crucial insights into the complex interplay between genetics, environment, and experiences in shaping the developing brain. By understanding the neural processes underlying developmental changes, researchers gain a better understanding of cognitive, emotional, and social development in humans.

Cognitive development is primarily concerned with the ways that infants and children acquire, develop, and use internal mental capabilities such as: problem-solving, memory, and language. Major topics in cognitive development are the study of language acquisition and the development of perceptual and motor skills. Piaget was one of the influential early psychologists to study the development of cognitive abilities. His theory suggests that development proceeds through a set of stages from infancy to adulthood and that there is an end point or goal.

Other accounts, such as that of Lev Vygotsky, have suggested that development does not progress through stages, but rather that the developmental process that begins at birth and continues until death is too complex for such structure and finality. Rather, from this viewpoint, developmental processes proceed more continuously. Thus, development should be analyzed, instead of treated as a product to obtain.

K. Warner Schaie has expanded the study of cognitive development into adulthood. Rather than being stable from adolescence, Schaie sees adults as progressing in the application of their cognitive abilities.

Modern cognitive development has integrated the considerations of cognitive psychology and the psychology of individual differences into the interpretation and modeling of development. Specifically, the neo-Piagetian theories of cognitive development showed that the successive levels or stages of cognitive development are associated with increasing processing efficiency and working memory capacity. These increases explain differences between stages, progression to higher stages, and individual differences of children who are the same-age and of the same grade-level. However, other theories have moved away from Piagetian stage theories, and are influenced by accounts of domain-specific information processing, which posit that development is guided by innate evolutionarily-specified and content-specific information processing mechanisms.

Developmental psychologists who are interested in social development examine how individuals develop social and emotional competencies. For example, they study how children form friendships, how they understand and deal with emotions, and how identity develops. Research in this area may involve study of the relationship between cognition or cognitive development and social behavior.

Emotional regulation or ER refers to an individual's ability to modulate emotional responses across a variety of contexts. In young children, this modulation is in part controlled externally, by parents and other authority figures. As children develop, they take on more and more responsibility for their internal state. Studies have shown that the development of ER is affected by the emotional regulation children observe in parents and caretakers, the emotional climate in the home, and the reaction of parents and caretakers to the child's emotions.

Music also has an influence on stimulating and enhancing the senses of a child through self-expression.

A child's social and emotional development can be disrupted by motor coordination problems, evidenced by the environmental stress hypothesis. The environmental hypothesis explains how children with coordination problems and developmental coordination disorder are exposed to several psychosocial consequences which act as secondary stressors, leading to an increase in internalizing symptoms such as depression and anxiety. Motor coordination problems affect fine and gross motor movement as well as perceptual-motor skills. Secondary stressors commonly identified include the tendency for children with poor motor skills to be less likely to participate in organized play with other children and more likely to feel socially isolated.

Social and emotional development focuses on five keys areas: Self-Awareness, Self Management, Social Awareness, Relationship Skills and Responsible Decision Making.

Physical development concerns the physical maturation of an individual's body until it reaches the adult stature. Although physical growth is a highly regular process, all children differ tremendously in the timing of their growth spurts. Studies are being done to analyze how the differences in these timings affect and are related to other variables of developmental psychology such as information processing speed. Traditional measures of physical maturity using x-rays are less in practice nowadays, compared to simple measurements of body parts such as height, weight, head circumference, and arm span.

A few other studies and practices with physical developmental psychology are the phonological abilities of mature 5- to 11-year-olds, and the controversial hypotheses of left-handers being maturationally delayed compared to right-handers. A study by Eaton, Chipperfield, Ritchot, and Kostiuk in 1996 found in three different samples that there was no difference between right- and left-handers.

Researchers interested in memory development look at the way our memory develops from childhood and onward. According to fuzzy-trace theory, a theory of cognition originally proposed by Valerie F. Reyna and Charles Brainerd, people have two separate memory processes: verbatim and gist. These two traces begin to develop at different times as well as at a different pace. Children as young as four years old have verbatim memory, memory for surface information, which increases up to early adulthood, at which point it begins to decline. On the other hand, our capacity for gist memory, memory for semantic information, increases up to early adulthood, at which point it is consistent through old age. Furthermore, one's reliance on gist memory traces increases as one ages.

Developmental psychology employs many of the research methods used in other areas of psychology. However, infants and children cannot be tested in the same ways as adults, so different methods are often used to study their development.

Developmental psychologists have a number of methods to study changes in individuals over time. Common research methods include systematic observation, including naturalistic observation or structured observation; self-reports, which could be clinical interviews or structured interviews; clinical or case study method; and ethnography or participant observation. These methods differ in the extent of control researchers impose on study conditions, and how they construct ideas about which variables to study. Every developmental investigation can be characterized in terms of whether its underlying strategy involves the "experimental", "correlational", or "case study" approach. The experimental method involves "actual manipulation of various treatments, circumstances, or events to which the participant or subject is exposed; the "experimental design" points to cause-and-effect relationships. This method allows for strong inferences to be made of causal relationships between the manipulation of one or more independent variables and subsequent behavior, as measured by the dependent variable. The advantage of using this research method is that it permits determination of cause-and-effect relationships among variables. On the other hand, the limitation is that data obtained in an artificial environment may lack generalizability. The correlational method explores the relationship between two or more events by gathering information about these variables without researcher intervention. The advantage of using a correlational design is that it estimates the strength and direction of relationships among variables in the natural environment; however, the limitation is that it does not permit determination of cause-and-effect relationships among variables. The case study approach allows investigations to obtain an in-depth understanding of an individual participant by collecting data based on interviews, structured questionnaires, observations, and test scores. Each of these methods have its strengths and weaknesses but the experimental method when appropriate is the preferred method of developmental scientists because it provides a controlled situation and conclusions to be drawn about cause-and-effect relationships.

Most developmental studies, regardless of whether they employ the experimental, correlational, or case study method, can also be constructed using research designs. Research designs are logical frameworks used to make key comparisons within research studies such as:

In a longitudinal study, a researcher observes many individuals born at or around the same time (a cohort) and carries out new observations as members of the cohort age. This method can be used to draw conclusions about which types of development are universal (or normative) and occur in most members of a cohort. As an example a longitudinal study of early literacy development examined in detail the early literacy experiences of one child in each of 30 families.

Researchers may also observe ways that development varies between individuals, and hypothesize about the causes of variation in their data. Longitudinal studies often require large amounts of time and funding, making them unfeasible in some situations. Also, because members of a cohort all experience historical events unique to their generation, apparently normative developmental trends may, in fact, be universal only to their cohort.

In a cross-sectional study, a researcher observes differences between individuals of different ages at the same time. This generally requires fewer resources than the longitudinal method, and because the individuals come from different cohorts, shared historical events are not so much of a confounding factor. By the same token, however, cross-sectional research may not be the most effective way to study differences between participants, as these differences may result not from their different ages but from their exposure to "different" historical events.

A third study design, the sequential design, combines both methodologies. Here, a researcher observes members of different birth cohorts at the same time, and then tracks all participants over time, charting changes in the groups. While much more resource-intensive, the format aids in a clearer distinction between what changes can be attributed to an individual or historical environment from those that are truly universal.

Because every method has some weaknesses, developmental psychologists rarely rely on one study or even one method to reach conclusions by finding consistent evidence from as many converging sources as possible.

Prenatal development is of interest to psychologists investigating the context of early psychological development. The whole prenatal development involves three main stages: germinal stage, embryonic stage and fetal stage. Germinal stage begins at conception until 2 weeks; embryonic stage means the development from 2 weeks to 8 weeks; fetal stage represents 9 weeks until birth of the baby. The senses develop in the womb itself: a fetus can both see and hear by the second trimester (13 to 24 weeks of age). The sense of touch develops in the embryonic stage (5 to 8 weeks). Most of the brain's billions of neurons also are developed by the second trimester. Babies are hence born with some odor, taste and sound preferences, largely related to the mother's environment.

Some primitive reflexes too arise before birth and are still present in newborns. One hypothesis is that these reflexes are vestigial and have limited use in early human life. Piaget's theory of cognitive development suggested that some early reflexes are building blocks for infant sensorimotor development. For example, the tonic neck reflex may help development by bringing objects into the infant's field of view.

Other reflexes, such as the walking reflex, appear to be replaced by more sophisticated voluntary control later in infancy. This may be because the infant gains too much weight after birth to be strong enough to use the reflex, or because the reflex and subsequent development are functionally different. It has also been suggested that some reflexes (for example the moro and walking reflexes) are predominantly adaptations to life in the womb with little connection to early infant development. Primitive reflexes reappear in adults under certain conditions, such as neurological conditions like dementia or traumatic lesions.

Ultrasounds have shown that infants are capable of a range of movements in the womb, many of which appear to be more than simple reflexes. By the time they are born, infants can recognize and have a preference for their mother's voice suggesting some prenatal development of auditory perception. Prenatal development and birth complications may also be connected to neurodevelopmental disorders, for example in schizophrenia. With the advent of cognitive neuroscience, embryology and the neuroscience of prenatal development is of increasing interest to developmental psychology research.

Several environmental agents—teratogens—can cause damage during the prenatal period. These include prescription and nonprescription drugs, illegal drugs, tobacco, alcohol, environmental pollutants, infectious disease agents such as the rubella virus and the toxoplasmosis parasite, maternal malnutrition, maternal emotional stress, and Rh factor blood incompatibility between mother and child. There are many statistics which prove the effects of the aforementioned substances. A leading example of this would be that at least 100,000 "cocaine babies" were born in the United States annually in the late 1980s. "Cocaine babies" are proven to have quite severe and lasting difficulties which persist throughout infancy and right throughout childhood. The drug also encourages behavioural problems in the affected children and defects of various vital organs.

From birth until the first year, children are referred to as infants. As they grow, children respond to their environment in unique ways. Developmental psychologists vary widely in their assessment of infant psychology, and the influence the outside world has upon it.

The majority of a newborn infant's time is spent sleeping. At first, their sleep cycles are evenly spread throughout the day and night, but after a couple of months, infants generally become diurnal. In human or rodent infants, there is always the observation of a diurnal cortisol rhythm, which is sometimes entrained with a maternal substance. Nevertheless the circadian rhythm starts to take shape, and a 24-hour rhythm is observed in just some few months after birth.

Infants can be seen to have six states, grouped into pairs:

Infant perception is what a newborn can see, hear, smell, taste, and touch. These five features are considered as the "five senses". Because of these different senses, infants respond to stimuli differently.


Babies are born with the ability to discriminate virtually all sounds of all human languages. Infants of around six months can differentiate between phonemes in their own language, but not between similar phonemes in another language. Notably, infants are able to differentiate between various durations and sound levels and can easily differentiate all the languages they have encountered, hence easy for infants to understand a certain language compared to an adult.

At this stage infants also start to babble, whereby they start making vowel consonant sound as they try to understand the true meaning of language and copy whatever they are hearing in their surrounding producing their own phonemes.

Piaget suggested that an infant's perception and understanding of the world depended on their motor development, which was required for the infant to link visual, tactile and motor representations of objects. According to this theory, infants develop object permanence through touching and handling objects. Infants start to understanding that objects continue to exist when out of sight.

Piaget's sensorimotor stage comprised six sub-stages (see sensorimotor stages for more detail). In the early stages, development arises out of movements caused by primitive reflexes. Discovery of new behaviors results from classical and operant conditioning, and the formation of habits. From eight months the infant is able to uncover a hidden object but will persevere when the object is moved.

Piaget concluded that infants lacked object permanence before 18 months when infants' before this age failed to look for an object where it had last been seen. Instead, infants continued to look for an object where it was first seen, committing the "A-not-B error". Some researchers have suggested that before the age of 8-9 months, infants' inability to understand object permanence extends to people, which explains why infants at this age do not cry when their mothers are gone ("Out of sight, out of mind").

In the 1980s and 1990s, researchers developed new methods of assessing infants' understanding of the world with far more precision and subtlety than Piaget was able to do in his time. Since then, many studies based on these methods suggest that young infants understand far more about the world than first thought.

Based on recent findings, some researchers (such as Elizabeth Spelke and Renee Baillargeon) have proposed that an understanding of object permanence is not learned at all, but rather comprises part of the innate cognitive capacities of our species.

Other research has suggested that young infants in their first six months of life may possess an understanding of numerous aspects of the world around them, including:


There are critical periods in infancy and childhood during which development of certain perceptual, sensorimotor, social and language systems depends crucially on environmental stimulation. Feral children such as Genie, deprived of adequate stimulation, fail to acquire important skills and are unable to learn in later childhood. In this case, Genie is used to represent the case of a feral child because she was socially neglected and abused while she was just a young girl. She underwent abnormal child psychology which involved problems with her linguistics. This happened because she was neglected while she was very young with no one to care about her and had less human contact. The concept of critical periods is also well-established in neurophysiology, from the work of Hubel and Wiesel among others. Neurophysiology in infants generally provides correlating details that exists between neurophysiological details and clinical features and also focuses on vital information on rare and common neurological disorders that affect infants. 

Studies have been done to look at the differences in children who have developmental delays versus typical development. Normally when being compared to one another, mental age (MA) is not taken into consideration. There still may be differences in developmentally delayed (DD) children vs. typical development (TD) behavioral, emotional and other mental disorders. When compared to MA children there is a bigger difference between normal developmental behaviors overall. DDs can cause lower MA, so comparing DDs with TDs may not be as accurate. Pairing DDs specifically with TD children at similar MA can be more accurate. There are levels of behavioral differences that are considered as normal at certain ages. When evaluating DDs and MA in children, consider whether those with DDs have a larger amount of behavior that is not typical for their MA group. Developmental delays tend to contribute to other disorders or difficulties than their TD counterparts.

Infants shift between ages of one and two to a developmental stage known as toddlerhood. In this stage, an infant's transition into toddlerhood is highlighted through self-awareness, developing maturity in language use, and presence of memory and imagination.

During toddlerhood, babies begin learning how to walk, talk, and make decisions for themselves. An important characteristic of this age period is the development of language, where children are learning how to communicate and express their emotions and desires through the use of vocal sounds, babbling, and eventually words. Self-control also begins to develop. At this age, children take initiative to explore, experiment and learn from making mistakes. Caretakers who encourage toddlers to try new things and test their limits, help the child become autonomous, self-reliant, and confident. If the caretaker is overprotective or disapproving of independent actions, the toddler may begin to doubt their abilities and feel ashamed of the desire for independence. The child's autonomic development is inhibited, leaving them less prepared to deal with the world in the future. Toddlers also begin to identify themselves in gender roles, acting according to their perception of what a man or woman should do.

Socially, the period of toddler-hood is commonly called the "terrible twos". Toddlers often use their new-found language abilities to voice their desires, but are often misunderstood by parents due to their language skills just beginning to develop. A person at this stage testing their independence is another reason behind the stage's infamous label. Tantrums in a fit of frustration are also common.

Erik Erikson divides childhood into four stages, each with its distinct social crisis:

Play (or preschool) ages 3–5.
In the earliest years, children are "completely dependent on the care of others". Therefore, they develop a "social relationship" with their care givers and, later, with family members. During their preschool years (3-5), they "enlarge their social horizons" to include people outside the family.

Preoperational and then operational thinking develops, which means actions are reversible, and egocentric thought diminishes.

The motor skills of preschoolers increase so they can do more things for themselves. They become more independent. No longer completely dependent on the care of others, the world of this age group expands. More people have a role in shaping their individual personalities. Preschoolers explore and question their world. For Jean Piaget, the child is ""a little scientist" exploring and reflecting on these explorations to increase competence" and this is done in "a very independent way".

Play is a major activity for ages 3–5. For Piaget, through play "a child reaches higher levels of cognitive development."

In their expanded world, children in the 3–5 age group attempt to find their own way. If this is done in a socially acceptable way, the child develops the initiative. If not, the child develops guilt. Children who develop "guilt" rather than "initiative" have failed Erikson's psychosocial crisis for the 3–5 age group.

Middle and Late childhood ages 6–12.
For Erik Erikson, the psychosocial crisis during middle childhood is Industry vs. Inferiority which, if successfully met, instills a sense of Competency in the child.

In all cultures, middle childhood is a time for developing "skills that will be needed in their society." School offers an arena in which children can gain a view of themselves as "industrious (and worthy)". They are "graded for their school work and often for their industry". They can also develop industry outside of school in sports, games, and doing volunteer work. Children who achieve "success in school or games might develop a feeling of competence."

The "peril during this period is that feelings of inadequacy and inferiority will develop. Parents and teachers can "undermine" a child's development by failing to recognize accomplishments or being overly critical of a child's efforts.
Children who are "encouraged and praised" develop a belief in their competence. Lack of encouragement or ability to excel lead to "feelings of inadequacy and inferiority".

The Centers for Disease Control (CDC) divides Middle Childhood into two stages, 6–8 years and 9–11 years, and gives "developmental milestones for each stage".

"Middle Childhood (6–8)."
Entering elementary school, children in this age group begin to thinks about the future and their "place in the world". Working with other students and wanting their friendship and acceptance become more important. This leads to "more independence from parents and family". As students, they develop the mental and verbal skills "to describe experiences and talk about thoughts and feelings". They become less self-centered and show "more concern for others".

"Late Childhood (9–12)."
For children ages 9–11 "friendships and peer relationships" increase in strength, complexity, and importance. This results in greater "peer pressure". They grow even less dependent on their families and they are challenged academically. To meet this challenge, they increase their attention span and learn to see other points of view.

Adolescence is the period of life between the onset of puberty and the full commitment to an adult social role, such as worker, parent, and/or citizen. It is the period known for the formation of personal and social identity (see Erik Erikson) and the discovery of moral purpose (see William Damon). Intelligence is demonstrated through the logical use of symbols related to abstract concepts and formal reasoning. A return to egocentric thought often occurs early in the period. Only 35% develop the capacity to reason formally during adolescence or adulthood. (Huitt, W. and Hummel, J. January 1998)

It is divided into three parts, namely:

The adolescent unconsciously explores questions such as "Who am I? Who do I want to be?" Like toddlers, adolescents must explore, test limits, become autonomous, and commit to an identity, or sense of self. Different roles, behaviors and ideologies must be tried out to select an identity. Role confusion and inability to choose vocation can result from a failure to achieve a sense of identity through, for example, friends.

Early adulthood generally refers to the period between ages 18 to 39, and according to theorists such as Erik Erikson, is a stage where development is mainly focused on maintaining relationships. Examples include creating bond of intimacy, sustaining friendships, and starting a family. Some theorists state that development of intimacy skills rely on the resolution of previous developmental stages. A sense of identity gained in the previous stages is also necessary for intimacy to develop. If this skill is not learned the alternative is alienation, isolation, a fear of commitment, and the inability to depend on others.

A related framework for studying this part of the lifespan is that of emerging adulthood. Scholars of emerging adulthood, such as Jeffrey Arnett, are not necessarily interested in relationship development. Instead, this concept suggests that people transition after their teenage years into a period not characterized as relationship building and an overall sense of constancy with life, but with years of living with parents, phases of self-discovery, and experimentation.

Middle adulthood generally refers to the period between ages 40 to 64. During this period, middle-aged adults experience a conflict between generativity and stagnation. They may either feel a sense of contributing to society, the next generation, or their immediate community; or develop a sense of purposelessness.

Physically, the middle-aged experience a decline in muscular strength, reaction time, sensory keenness, and cardiac output. Also, women experience menopause at an average age of 48.8 and a sharp drop in the hormone estrogen. Men experience an equivalent endocrine system event to menopause. Andropause in males is a hormone fluctuation with physical and psychological effects that can be similar to those seen in menopausal females. As men age lowered testosterone levels can contribute to mood swings and a decline in sperm count. Sexual responsiveness can also be affected, including delays in erection and longer periods of penile stimulation required to achieve ejaculation.

The important influence of biological and social changes experienced by women and men in middle adulthood is reflected in the fact that depression is highest at age 48.5 around the world.

The World Health Organization finds "no general agreement on the age at which a person becomes old." Most "developed countries" set the age as 65 or 70. However, in developing countries inability to make "active contribution" to society, not chronological age, marks the beginning of old age. According to Erikson's stages of psychosocial development, old age is the stage in which individuals assess the quality of their lives. In reflecting on their lives, people in this age group develop a feeling of integrity if deciding that their lives were successful or a feeling of despair if evaluation of one's life indicates a failure to achieve goals.

Physically, older people experience a decline in muscular strength, reaction time, stamina, hearing, distance perception, and the sense of smell. They also are more susceptible to diseases such as cancer and pneumonia due to a weakened immune system. Programs aimed at balance, muscle strength, and mobility have been shown to reduce disability among mildly (but not more severely) disabled elderly.

Sexual expression depends in large part upon the emotional and physical health of the individual. Many older adults continue to be sexually active and satisfied with their sexual activity.

Mental disintegration may also occur, leading to dementia or ailments such as Alzheimer's disease. The average age of onset for dementia in males is 78.8 and 81.9 for women. It is generally believed that crystallized intelligence increases up to old age, while fluid intelligence decreases with age. Whether or not normal intelligence increases or decreases with age depends on the measure and study. Longitudinal studies show that perceptual speed, inductive reasoning, and spatial orientation decline. An article on adult cognitive development reports that cross-sectional studies show that "some abilities remained stable into early old age".

Parenting variables alone have typically accounted for 20 to 50 percent of the variance in child outcomes.

All parents have their own parenting styles. Parenting styles, according to Kimberly Kopko, are "based upon two aspects of parenting behavior; control and warmth. Parental control refers to the degree to which parents manage their children's behavior. Parental warmth refers to the degree to which parents are accepting and responsive to their children's behavior."

The following parenting styles have been described in the child development literature:


Parenting roles in child development have typically focused on the role of the mother. Recent literature, however, has looked toward the father as having an important role in child development. Affirming a role for fathers, studies have shown that children as young as 15 months benefit significantly from substantial engagement with their father. In particular, a study in the U.S. and New Zealand found the presence of the natural father was the most significant factor in reducing rates of early sexual activity and rates of teenage pregnancy in girls. Furthermore, another argument is that neither a mother nor a father is actually essential in successful parenting, and that single parents as well as homosexual couples can support positive child outcomes. According to this set of research, children need at least one consistently responsible adult with whom the child can have a positive emotional connection. Having more than one of these figures contributes to a higher likelihood of positive child outcomes.

Another parental factor often debated in terms of its effects on child development is divorce. Divorce in itself is not a determining factor of negative child outcomes. In fact, the majority of children from divorcing families fall into the normal range on measures of psychological and cognitive functioning. A number of mediating factors play a role in determining the effects divorce has on a child, for example, divorcing families with young children often face harsher consequences in terms of demographic, social, and economic changes than do families with older children. Positive coparenting after divorce is part of a pattern associated with positive child coping, while hostile parenting behaviors lead to a destructive pattern leaving children at risk. Additionally, direct parental relationship with the child also affects the development of a child after a divorce. Overall, protective factors facilitating positive child development after a divorce are maternal warmth, positive father-child relationship, and cooperation between parents.

A way to improve developmental psychology is a representation of cross-cultural studies. The psychology field in general assumes that "basic" human developments are represented in any population, specifically the Western-Educated-Industrialized-Rich and Democratic (W.E.I.R.D.) subjects that are relied on for a majority of their studies. Previous research generalizes the findings done with W.E.I.R.D. samples because many in the Psychological field assume certain aspects of development are exempted from or are not affected by life experiences. However, many of the assumptions have been proven incorrect or are not supported by empirical research. For example, according to Kohlberg, moral reasoning is dependent on cognitive abilities. While both analytical and holistic cognitive systems do have the potential to develop in any adult, the West is still on the extreme end of analytical thinking, and the non-West tend to use holistic processes. Furthermore, moral reasoning in the West only considers aspects that support autonomy and the individual, whereas non-Western adults emphasize moral behaviors supporting the community and maintaining an image of holiness or divinity. Not all aspects of human development are universal and we can learn a lot from observing different regions and subjects. 

An example of a non-West model for development stages is the Indian model, focusing a large amount of its psychological research on morality and interpersonal progress. The developmental stages in Indian models are founded by Hinduism, which primarily teaches stages of life in the process of someone discovering their fate or Dharma. This cross-cultural model can add another perspective to psychological development in which the West behavioral sciences have not emphasized kinship, ethnicity, or religion.

Indian psychologists study the relevance of attentive families during the early stages of life. The early life stages conceptualize a different parenting style from the West because it does not try to rush children out of dependency. The family is meant to help the child grow into the next developmental stage at a particular age. This way, when children finally integrate into society, they are interconnected with those around them and reach renunciation when they are older. Children are raised in joint families so that in early childhood (ages 6 months to 2 years) the other family members help gradually wean the child from its mother. During ages 2 to 5, the parents do not rush toilet training. Instead of training the child to perform this behavior, the child learns to do it as they mature at their own pace. This model of early human development encourages dependency, unlike Western models that value autonomy and independence. By being attentive and not forcing the child to become independent, they are confident and have a sense of belonging by late childhood and adolescence. This stage in life (5-15 years) is also when children start education and increase their knowledge of Dharma. It is within early and middle adulthood that we see moral development progress. Early, middle, and late adulthood are all concerned with caring for others and fulfilling Dharma. The main distinction between early adulthood to middle or late adulthood is how far their influence reaches. Early adulthood emphasizes the importance of fulfilling the immediate family needs, until later adulthood when they broaden their responsibilities to the general public. The old-age life stage development reaches renunciation or a complete understanding of Dharma.

The current mainstream views in the psychological field are against the Indian model for human development. The criticism against such models is that the parenting style is overly protective and encourages too much dependency. It focuses on interpersonal instead of individual goals. Also, there are some overlaps and similarities between Erikson's stages of human development and the Indian model but both of them still have major differences. The West prefers Erickson's ideas over the Indian model because they are supported by scientific studies. The life cycles based on Hinduism are not as favored, because it is not supported with research and it focuses on the ideal human development.



DNA replication

In molecular biology, DNA replication is the biological process of producing two identical replicas of DNA from one original DNA molecule. DNA replication occurs in all living organisms acting as the most essential part of biological inheritance. This is essential for cell division during growth and repair of damaged tissues, while it also ensures that each of the new cells receives its own copy of the DNA. The cell possesses the distinctive property of division, which makes replication of DNA essential.

DNA is made up of a double helix of two complementary strands. The double helix describes the appearance of a double-stranded DNA which is thus composed of two linear strands that run opposite to each other and twist together to form. During replication, these strands are separated. Each strand of the original DNA molecule then serves as a template for the production of its counterpart, a process referred to as semiconservative replication. As a result of semi-conservative replication, the new helix will be composed of an original DNA strand as well as a newly synthesized strand. Cellular proofreading and error-checking mechanisms ensure near perfect fidelity for DNA replication.

In a cell, DNA replication begins at specific locations, or origins of replication, in the genome which contains the genetic material of an organism. Unwinding of DNA at the origin and synthesis of new strands, accommodated by an enzyme known as helicase, results in replication forks growing bi-directionally from the origin. A number of proteins are associated with the replication fork to help in the initiation and continuation of DNA synthesis. Most prominently, DNA polymerase synthesizes the new strands by adding nucleotides that complement each (template) strand. DNA replication occurs during the S-stage of interphase.

DNA replication (DNA amplification) can also be performed "in vitro" (artificially, outside a cell). DNA polymerases isolated from cells and artificial DNA primers can be used to start DNA synthesis at known sequences in a template DNA molecule. Polymerase chain reaction (PCR), ligase chain reaction (LCR), and transcription-mediated amplification (TMA) are examples. In March 2021, researchers reported evidence suggesting that a preliminary form of transfer RNA, a necessary component of translation, the biological synthesis of new proteins in accordance with the genetic code, could have been a replicator molecule itself in the very early development of life, or abiogenesis.

DNA exists as a double-stranded structure, with both strands coiled together to form the characteristic double helix. Each single strand of DNA is a chain of four types of nucleotides. Nucleotides in DNA contain a deoxyribose sugar, a phosphate, and a nucleobase. The four types of nucleotide correspond to the four nucleobases adenine, cytosine, guanine, and thymine, commonly abbreviated as A, C, G, and T. Adenine and guanine are purine bases, while cytosine and thymine are pyrimidines. These nucleotides form phosphodiester bonds, creating the phosphate-deoxyribose backbone of the DNA double helix with the nucleobases pointing inward (i.e., toward the opposing strand). Nucleobases are matched between strands through hydrogen bonds to form base pairs. Adenine pairs with thymine (two hydrogen bonds), and guanine pairs with cytosine (three hydrogen bonds).

DNA strands have a directionality, and the different ends of a single strand are called the "3′ (three-prime) end" and the "5′ (five-prime) end". By convention, if the base sequence of a single strand of DNA is given, the left end of the sequence is the 5′ end, while the right end of the sequence is the 3′ end. The strands of the double helix are anti-parallel, with one being 5′ to 3′, and the opposite strand 3′ to 5′. These terms refer to the carbon atom in deoxyribose to which the next phosphate in the chain attaches. Directionality has consequences in DNA synthesis, because DNA polymerase can synthesize DNA in only one direction by adding nucleotides to the 3′ end of a DNA strand.

The pairing of complementary bases in DNA (through hydrogen bonding) means that the information contained within each strand is redundant. Phosphodiester (intra-strand) bonds are stronger than hydrogen (inter-strand) bonds. The actual job of the phosphodiester bonds is where in DNA polymers connect the 5' carbon atom of one nucleotide to the 3' carbon atom of another nucleotide, while the hydrogen bonds stabilize DNA double helices across the helix axis but not in the direction of the axis. This makes it possible to separate the strands from one another. The nucleotides on a single strand can therefore be used to reconstruct nucleotides on a newly synthesized partner strand.

DNA polymerases are a family of enzymes that carry out all forms of DNA replication. DNA polymerases in general cannot initiate synthesis of new strands but can only extend an existing DNA or RNA strand paired with a template strand. To begin synthesis, a short fragment of RNA, called a primer, must be created and paired with the template DNA strand.

DNA polymerase adds a new strand of DNA by extending the 3′ end of an existing nucleotide chain, adding new nucleotides matched to the template strand, one at a time, via the creation of phosphodiester bonds. The energy for this process of DNA polymerization comes from hydrolysis of the high-energy phosphate (phosphoanhydride) bonds between the three phosphates attached to each unincorporated base. Free bases with their attached phosphate groups are called nucleotides; in particular, bases with three attached phosphate groups are called nucleoside triphosphates. When a nucleotide is being added to a growing DNA strand, the formation of a phosphodiester bond between the proximal phosphate of the nucleotide to the growing chain is accompanied by hydrolysis of a high-energy phosphate bond with release of the two distal phosphate groups as a pyrophosphate. Enzymatic hydrolysis of the resulting pyrophosphate into inorganic phosphate consumes a second high-energy phosphate bond and renders the reaction effectively irreversible.

In general, DNA polymerases are highly accurate, with an intrinsic error rate of less than one mistake for every 10 nucleotides added. Some DNA polymerases can also delete nucleotides from the end of a developing strand in order to fix mismatched bases. This is known as proofreading. Finally, post-replication mismatch repair mechanisms monitor the DNA for errors, being capable of distinguishing mismatches in the newly synthesized DNA Strand from the original strand sequence. Together, these three discrimination steps enable replication fidelity of less than one mistake for every 10 nucleotides added.

The rate of DNA replication in a living cell was first measured as the rate of phage T4 DNA elongation in phage-infected "E. coli". During the period of exponential DNA increase at 37 °C, the rate was 749 nucleotides per second. The mutation rate per base pair per replication during phage T4 DNA synthesis is 1.7 per 10.

DNA replication, like all biological polymerization processes, proceeds in three enzymatically catalyzed and coordinated steps: initiation, elongation and termination.

For a cell to divide, it must first replicate its DNA. DNA replication is an all-or-none process; once replication begins, it proceeds to completion. Once replication is complete, it does not occur again in the same cell cycle. This is made possible by the division of initiation of the pre-replication complex.

In late mitosis and early G1 phase, a large complex of initiator proteins assembles into the pre-replication complex at particular points in the DNA, known as "origins". In "E. coli" the primary initiator protein is Dna A; in yeast, this is the origin recognition complex. Sequences used by initiator proteins tend to be "AT-rich" (rich in adenine and thymine bases), because A-T base pairs have two hydrogen bonds (rather than the three formed in a C-G pair) and thus are easier to strand-separate. In eukaryotes, the origin recognition complex catalyzes the assembly of initiator proteins into the pre-replication complex. In addition, a recent report suggests that budding yeast ORC dimerizes in a cell cycle dependent manner to control licensing. In turn, the process of ORC dimerization is mediated by a cell cycle-dependent Noc3p dimerization cycle in vivo, and this role of Noc3p is separable from its role in ribosome biogenesis. An essential Noc3p dimerization cycle mediates ORC double-hexamer formation in replication licensing ORC and Noc3p are continuously bound to the chromatin throughout the cell cycle. Cdc6 and Cdt1 then associate with the bound origin recognition complex at the origin in order to form a larger complex necessary to load the Mcm complex onto the DNA. In eukaryotes, the Mcm complex is the helicase that will split the DNA helix at the replication forks and origins. The Mcm complex is recruited at late G1 phase and loaded by the ORC-Cdc6-Cdt1 complex onto the DNA via ATP-dependent protein remodeling. The loading of the Mcm complex onto the origin DNA marks the completion of pre-replication complex formation.

If environmental conditions are right in late G1 phase, the G1 and G1/S cyclin-Cdk complexes are activated, which stimulate expression of genes that encode components of the DNA synthetic machinery. G1/S-Cdk activation also promotes the expression and activation of S-Cdk complexes, which may play a role in activating replication origins depending on species and cell type. Control of these Cdks vary depending on cell type and stage of development. This regulation is best understood in budding yeast, where the S cyclins Clb5 and Clb6 are primarily responsible for DNA replication. Clb5,6-Cdk1 complexes directly trigger the activation of replication origins and are therefore required throughout S phase to directly activate each origin.

In a similar manner, Cdc7 is also required through S phase to activate replication origins. Cdc7 is not active throughout the cell cycle, and its activation is strictly timed to avoid premature initiation of DNA replication. In late G1, Cdc7 activity rises abruptly as a result of association with the regulatory subunit DBF4, which binds Cdc7 directly and promotes its protein kinase activity. Cdc7 has been found to be a rate-limiting regulator of origin activity. Together, the G1/S-Cdks and/or S-Cdks and Cdc7 collaborate to directly activate the replication origins, leading to initiation of DNA synthesis.

In early S phase, S-Cdk and Cdc7 activation lead to the assembly of the preinitiation complex, a massive protein complex formed at the origin. Formation of the preinitiation complex displaces Cdc6 and Cdt1 from the origin replication complex, inactivating and disassembling the pre-replication complex. Loading the preinitiation complex onto the origin activates the Mcm helicase, causing unwinding of the DNA helix. The preinitiation complex also loads α-primase and other DNA polymerases onto the DNA.

After α-primase synthesizes the first primers, the primer-template junctions interact with the clamp loader, which loads the sliding clamp onto the DNA to begin DNA synthesis. The components of the preinitiation complex remain associated with replication forks as they move out from the origin.

DNA polymerase has 5′–3′ activity.
All known DNA replication systems require a free 3′ hydroxyl group before synthesis can be initiated (note: the DNA template is read in 3′ to 5′ direction whereas a new strand is synthesized in the 5′ to 3′ direction—this is often confused). Four distinct mechanisms for DNA synthesis are recognized:

Cellular organisms use the first of these pathways since it is the most well-known. In this mechanism, once the two strands are separated, primase adds RNA primers to the template strands. The leading strand receives one RNA primer while the lagging strand receives several. The leading strand is continuously extended from the primer by a DNA polymerase with high processivity, while the lagging strand is extended discontinuously from each primer forming Okazaki fragments. RNase removes the primer RNA fragments, and a low processivity DNA polymerase distinct from the replicative polymerase enters to fill the gaps. When this is complete, a single nick on the leading strand and several nicks on the lagging strand can be found. Ligase works to fill these nicks in, thus completing the newly replicated DNA molecule.

The primase used in this process differs significantly between bacteria and archaea/eukaryotes. Bacteria use a primase belonging to the DnaG protein superfamily which contains a catalytic domain of the TOPRIM fold type. The TOPRIM fold contains an α/β core with four conserved strands in a Rossmann-like topology. This structure is also found in the catalytic domains of topoisomerase Ia, topoisomerase II, the OLD-family nucleases and DNA repair proteins related to the RecR protein.

The primase used by archaea and eukaryotes, in contrast, contains a highly derived version of the RNA recognition motif (RRM). This primase is structurally similar to many viral RNA-dependent RNA polymerases, reverse transcriptases, cyclic nucleotide generating cyclases and DNA polymerases of the A/B/Y families that are involved in DNA replication and repair. In eukaryotic replication, the primase forms a complex with Pol α.

Multiple DNA polymerases take on different roles in the DNA replication process. In "E. coli", DNA Pol III is the polymerase enzyme primarily responsible for DNA replication. It assembles into a replication complex at the replication fork that exhibits extremely high processivity, remaining intact for the entire replication cycle. In contrast, DNA Pol I is the enzyme responsible for replacing RNA primers with DNA. DNA Pol I has a 5′ to 3′ exonuclease activity in addition to its polymerase activity, and uses its exonuclease activity to degrade the RNA primers ahead of it as it extends the DNA strand behind it, in a process called nick translation. Pol I is much less processive than Pol III because its primary function in DNA replication is to create many short DNA regions rather than a few very long regions.

In eukaryotes, the low-processivity enzyme, Pol α, helps to initiate replication because it forms a complex with primase. In eukaryotes, leading strand synthesis is thought to be conducted by Pol ε; however, this view has recently been challenged, suggesting a role for Pol δ. Primer removal is completed Pol δ while repair of DNA during replication is completed by Pol ε.

As DNA synthesis continues, the original DNA strands continue to unwind on each side of the bubble, forming a replication fork with two prongs. In bacteria, which have a single origin of replication on their circular chromosome, this process creates a "theta structure" (resembling the Greek letter theta: θ). In contrast, eukaryotes have longer linear chromosomes and initiate replication at multiple origins within these.

The replication fork is a structure that forms within the long helical DNA during DNA replication. It is produced by enzymes called helicases that break the hydrogen bonds that hold the DNA strands together in a helix. The resulting structure has two branching "prongs", each one made up of a single strand of DNA. These two strands serve as the template for the leading and lagging strands, which will be created as DNA polymerase matches complementary nucleotides to the templates; the templates may be properly referred to as the leading strand template and the lagging strand template.

DNA is read by DNA polymerase in the 3′ to 5′ direction, meaning the new strand is synthesized in the 5' to 3' direction. Since the leading and lagging strand templates are oriented in opposite directions at the replication fork, a major issue is how to achieve synthesis of new lagging strand DNA, whose direction of synthesis is opposite to the direction of the growing replication fork.

The leading strand is the strand of new DNA which is synthesized in the same direction as the growing replication fork. This sort of DNA replication is continuous.

The lagging strand is the strand of new DNA whose direction of synthesis is opposite to the direction of the growing replication fork. Because of its orientation, replication of the lagging strand is more complicated as compared to that of the leading strand. As a consequence, the DNA polymerase on this strand is seen to "lag behind" the other strand.

The lagging strand is synthesized in short, separated segments. On the lagging strand "template", a primase "reads" the template DNA and initiates synthesis of a short complementary RNA primer. A DNA polymerase extends the primed segments, forming Okazaki fragments. The RNA primers are then removed and replaced with DNA, and the fragments of DNA are joined by DNA ligase.

In all cases the helicase is composed of six polypeptides that wrap around only one strand of the DNA being replicated. The two polymerases are bound to the helicase heximer. In eukaryotes the helicase wraps around the leading strand, and in prokaryotes it wraps around the lagging strand.

As helicase unwinds DNA at the replication fork, the DNA ahead is forced to rotate. This process results in a build-up of twists in the DNA ahead. This build-up creates a torsional load that would eventually stop the replication fork. Topoisomerases are enzymes that temporarily break the strands of DNA, relieving the tension caused by unwinding the two strands of the DNA helix; topoisomerases (including DNA gyrase) achieve this by adding negative supercoils to the DNA helix.

Bare single-stranded DNA tends to fold back on itself forming secondary structures; these structures can interfere with the movement of DNA polymerase. To prevent this, single-strand binding proteins bind to the DNA until a second strand is synthesized, preventing secondary structure formation.

Double-stranded DNA is coiled around histones that play an important role in regulating gene expression so the replicated DNA must be coiled around histones at the same places as the original DNA. To ensure this, histone chaperones disassemble the chromatin before it is replicated and replace the histones in the correct place. Some steps in this reassembly are somewhat speculative.

Clamp proteins act as a sliding clamp on DNA, allowing the DNA polymerase to bind to its template and aid in processivity. The inner face of the clamp enables DNA to be threaded through it. Once the polymerase reaches the end of the template or detects double-stranded DNA, the sliding clamp undergoes a conformational change that releases the DNA polymerase. Clamp-loading proteins are used to initially load the clamp, recognizing the junction between template and RNA primers.

At the replication fork, many replication enzymes assemble on the DNA into a complex molecular machine called the replisome. The following is a list of major DNA replication enzymes that participate in the replisome:
"In vitro" single-molecule experiments (using optical tweezers and magnetic tweezers) have found synergetic interactions between the replisome enzymes (helicase, polymerase, and Single-strand DNA-binding protein) and with the DNA replication fork enhancing DNA-unwinding and DNA-replication. These results lead to the developement of kinetic models accounting for the synergetic interactions and their stability.

Replication machineries consist of factors involved in DNA replication and appearing on template ssDNAs. Replication machineries include primosotors are replication enzymes; DNA polymerase, DNA helicases, DNA clamps and DNA topoisomerases, and replication proteins; e.g. single-stranded DNA binding proteins (SSB). In the replication machineries these components coordinate. In most of the bacteria, all of the factors involved in DNA replication are located on replication forks and the complexes stay on the forks during DNA replication. Replication machineries are also referred to as replisomes, or DNA replication systems. These terms are generic terms for proteins located on replication forks. In eukaryotic and some bacterial cells the replisomes are not formed.

Since replication machineries do not move relatively to template DNAs such as factories, they are called a replication factory. In an alternative figure, DNA factories are similar to projectors and DNAs are like as cinematic films passing constantly into the projectors. In the replication factory model, after both DNA helicases for leading strands and lagging strands are loaded on the template DNAs, the helicases run along the DNAs into each other. The helicases remain associated for the remainder of replication process. Peter Meister et al. observed directly replication sites in budding yeast by monitoring green fluorescent protein (GFP)-tagged DNA polymerases α. They detected DNA replication of pairs of the tagged loci spaced apart symmetrically from a replication origin and found that the distance between the pairs decreased markedly by time. This finding suggests that the mechanism of DNA replication goes with DNA factories. That is, couples of replication factories are loaded on replication origins and the factories associated with each other. Also, template DNAs move into the factories, which bring extrusion of the template ssDNAs and new DNAs. Meister's finding is the first direct evidence of replication factory model. Subsequent research has shown that DNA helicases form dimers in many eukaryotic cells and bacterial replication machineries stay in single intranuclear location during DNA synthesis.

Replication Factories Disentangle Sister Chromatids. The disentanglement is essential for distributing the chromatids into daughter cells after DNA replication. Because sister chromatids after DNA replication hold each other by Cohesin rings, there is the only chance for the disentanglement in DNA replication. Fixing of replication machineries as replication factories can improve the success rate of DNA replication. If replication forks move freely in chromosomes, catenation of nuclei is aggravated and impedes mitotic segregation.

Eukaryotes initiate DNA replication at multiple points in the chromosome, so replication forks meet and terminate at many points in the chromosome. Because eukaryotes have linear chromosomes, DNA replication is unable to reach the very end of the chromosomes. Due to this problem, DNA is lost in each replication cycle from the end of the chromosome. Telomeres are regions of repetitive DNA close to the ends and help prevent loss of genes due to this shortening. Shortening of the telomeres is a normal process in somatic cells. This shortens the telomeres of the daughter DNA chromosome. As a result, cells can only divide a certain number of times before the DNA loss prevents further division. (This is known as the Hayflick limit.) Within the germ cell line, which passes DNA to the next generation, telomerase extends the repetitive sequences of the telomere region to prevent degradation. Telomerase can become mistakenly active in somatic cells, sometimes leading to cancer formation. Increased telomerase activity is one of the hallmarks of cancer.

Termination requires that the progress of the DNA replication fork must stop or be blocked. Termination at a specific locus, when it occurs, involves the interaction between two components: (1) a termination site sequence in the DNA, and (2) a protein which binds to this sequence to physically stop DNA replication. In various bacterial species, this is named the DNA replication terminus site-binding protein, or Ter protein.

Because bacteria have circular chromosomes, termination of replication occurs when the two replication forks meet each other on the opposite end of the parental chromosome. "E. coli" regulates this process through the use of termination sequences that, when bound by the Tus protein, enable only one direction of replication fork to pass through. As a result, the replication forks are constrained to always meet within the termination region of the chromosome.

Within eukaryotes, DNA replication is controlled within the context of the cell cycle. As the cell grows and divides, it progresses through stages in the cell cycle; DNA replication takes place during the S phase (synthesis phase). The progress of the eukaryotic cell through the cycle is controlled by cell cycle checkpoints. Progression through checkpoints is controlled through complex interactions between various proteins, including cyclins and cyclin-dependent kinases. Unlike bacteria, eukaryotic DNA replicates in the confines of the nucleus.

The G1/S checkpoint (or restriction checkpoint) regulates whether eukaryotic cells enter the process of DNA replication and subsequent division. Cells that do not proceed through this checkpoint remain in the G0 stage and do not replicate their DNA.

Once the DNA has gone through the "G1/S" test, it can only be copied once in every cell cycle. When the Mcm complex moves away from the origin, the pre-replication complex is dismantled. Because a new Mcm complex cannot be loaded at an origin until the pre-replication subunits are reactivated, one origin of replication can not be used twice in the same cell cycle.

Activation of S-Cdks in early S phase promotes the destruction or inhibition of individual pre-replication complex components, preventing immediate reassembly. S and M-Cdks continue to block pre-replication complex assembly even after S phase is complete, ensuring that assembly cannot occur again until all Cdk activity is reduced in late mitosis.

In budding yeast, inhibition of assembly is caused by Cdk-dependent phosphorylation of pre-replication complex components. At the onset of S phase, phosphorylation of Cdc6 by Cdk1 causes the binding of Cdc6 to the SCF ubiquitin protein ligase, which causes proteolytic destruction of Cdc6. Cdk-dependent phosphorylation of Mcm proteins promotes their export out of the nucleus along with Cdt1 during S phase, preventing the loading of new Mcm complexes at origins during a single cell cycle. Cdk phosphorylation of the origin replication complex also inhibits pre-replication complex assembly. The individual presence of any of these three mechanisms is sufficient to inhibit pre-replication complex assembly. However, mutations of all three proteins in the same cell does trigger reinitiation at many origins of replication within one cell cycle.

In animal cells, the protein geminin is a key inhibitor of pre-replication complex assembly. Geminin binds Cdt1, preventing its binding to the origin recognition complex. In G1, levels of geminin are kept low by the APC, which ubiquitinates geminin to target it for degradation. When geminin is destroyed, Cdt1 is released, allowing it to function in pre-replication complex assembly. At the end of G1, the APC is inactivated, allowing geminin to accumulate and bind Cdt1.

Replication of chloroplast and mitochondrial genomes occurs independently of the cell cycle, through the process of D-loop replication.

In vertebrate cells, replication sites concentrate into positions called replication foci. Replication sites can be detected by immunostaining daughter strands and replication enzymes and monitoring GFP-tagged replication factors. By these methods it is found that replication foci of varying size and positions appear in S phase of cell division and their number per nucleus is far smaller than the number of genomic replication forks.

P. Heun et al.,(2001) tracked GFP-tagged replication foci in budding yeast cells and revealed that replication origins move constantly in G1 and S phase and the dynamics decreased significantly in S phase. Traditionally, replication sites were fixed on spatial structure of chromosomes by nuclear matrix or lamins. The Heun's results denied the traditional concepts, budding yeasts do not have lamins, and support that replication origins self-assemble and form replication foci.

By firing of replication origins, controlled spatially and temporally, the formation of replication foci is regulated. D. A. Jackson et al.(1998) revealed that neighboring origins fire simultaneously in mammalian cells. Spatial juxtaposition of replication sites brings clustering of replication forks. The clustering do rescue of stalled replication forks and favors normal progress of replication forks. Progress of replication forks is inhibited by many factors; collision with proteins or with complexes binding strongly on DNA, deficiency of dNTPs, nicks on template DNAs and so on. If replication forks get stuck and the rest of the sequences from the stuck forks are not copied, then the daughter strands get nick nick unreplicated sites. The un-replicated sites on one parent's strand hold the other strand together but not daughter strands. Therefore, the resulting sister chromatids cannot separate from each other and cannot divide into 2 daughter cells. When neighboring origins fire and a fork from one origin is stalled, fork from other origin access on an opposite direction of the stalled fork and duplicate the un-replicated sites. As other mechanism of the rescue there is application of dormant replication origins that excess origins do not fire in normal DNA replication.

Most bacteria do not go through a well-defined cell cycle but instead continuously copy their DNA; during rapid growth, this can result in the concurrent occurrence of multiple rounds of replication. In "E. coli", the best-characterized bacteria, DNA replication is regulated through several mechanisms, including: the hemimethylation and sequestering of the origin sequence, the ratio of adenosine triphosphate (ATP) to adenosine diphosphate (ADP), and the levels of protein DnaA. All these control the binding of initiator proteins to the origin sequences.

Because "E. coli" methylates GATC DNA sequences, DNA synthesis results in hemimethylated sequences. This hemimethylated DNA is recognized by the protein SeqA, which binds and sequesters the origin sequence; in addition, DnaA (required for initiation of replication) binds less well to hemimethylated DNA. As a result, newly replicated origins are prevented from immediately initiating another round of DNA replication.

ATP builds up when the cell is in a rich medium, triggering DNA replication once the cell has reached a specific size. ATP competes with ADP to bind to DnaA, and the DnaA-ATP complex is able to initiate replication. A certain number of DnaA proteins are also required for DNA replication — each time the origin is copied, the number of binding sites for DnaA doubles, requiring the synthesis of more DnaA to enable another initiation of replication.

In fast-growing bacteria, such as "E. coli", chromosome replication takes more time than dividing the cell. The bacteria solve this by initiating a new round of replication before the previous one has been terminated. The new round of replication will form the chromosome of the cell that is born two generations after the dividing cell. This mechanism creates overlapping replication cycles.

There are many events that contribute to replication stress, including:

Researchers commonly replicate DNA "in vitro" using the polymerase chain reaction (PCR). PCR uses a pair of primers to span a target region in template DNA, and then polymerizes partner strands in each direction from these primers using a thermostable DNA polymerase. Repeating this process through multiple cycles amplifies the targeted DNA region. At the start of each cycle, the mixture of template and primers is heated, separating the newly synthesized molecule and template. Then, as the mixture cools, both of these become templates for annealing of new primers, and the polymerase extends from these. As a result, the number of copies of the target region doubles each round, increasing exponentially.


Dravidian

Dravidian, Dravidan, or Dravida may refer to:






Daisy Duck

Daisy Duck is a cartoon character created by The Walt Disney Company. As the girlfriend of Donald Duck, she is an anthropomorphic white duck that has large eyelashes and ruffled tail feathers around her lowest region to suggest a skirt. She is often seen wearing a hair bow, blouse, and heeled shoes. Daisy was introduced in the short film "Mr. Duck Steps Out" (1940) and was incorporated into Donald's comic stories several months later. Carl Barks, the screenwriter and lead storyboard artist for the film, was inspired by the 1937 short, "Don Donald", that featured a Latin character named Donna Duck, to revive the concept of a female counterpart for Donald.

Daisy appeared in 11 short films between 1940 and 1954, and far later in "Mickey's Christmas Carol" (1983) and "Fantasia 2000" (1999). In these roles, Daisy was always a supporting character, with the exception of "Donald's Dilemma" (1947). Daisy has received considerably more screen time in television, making regular appearances in "Quack Pack" (1996), "Mickey Mouse Works" (1999–2000), "House of Mouse" (2001–2003), "Mickey Mouse Clubhouse" (2006–2016), "Mickey Mouse" (2013–2019), "Mickey Mouse Mixed-Up Adventures" (2017–2021), "The Wonderful World of Mickey Mouse" (2020–2023) and "Mickey Mouse Funhouse" (2021–present). Daisy has also appeared in several direct-to-video films such as "Mickey's Once Upon a Christmas" (1999), "" (2004), and "Mickey's Twice Upon a Christmas" (2004).

Daisy is a close friend of Clarabelle Cow and Clara Cluck in the comics and Minnie Mouse's best friend. Daisy usually shows a strong affinity towards Donald, although she is often characterized as being more sophisticated than him. Particularly in the comics, because of this, Daisy regularly becomes frustrated with Donald's immaturity, and on those occasions she will often go out on dates with Donald's cousin and rival Gladstone Gander instead. Daisy is the aunt of April, May, and June, three young girl ducks who bear resemblance to Huey, Dewey, and Louie.

Since her early appearances, Daisy is attracted to Donald and devoted to him in the same way he is often devoted to her. This is most clearly seen in "Donald's Dilemma" as Daisy is almost to the point of suicide after Donald forgets her. Despite this, she is shown to have her boyfriend wrapped around her finger and is often shown to keep him in line whenever his anger starts to boil.

Besides her love for Donald, Daisy is also shown to be more sophisticated and intelligent than him. This causes her to frequently be frustrated with his immaturity, and their relationship occasionally has an off-again, on-again nature as a result, particularly in the comic books. In comics, when Daisy is fighting with Donald or temporarily breaks up with him, she goes on dates with Donald's cousin Gladstone Gander instead. In "Cured Duck" Daisy even gives Donald an ultimatum regarding his temper but later reforms in "Donald's Dilemma". Daisy herself sometimes exhibits a temper, but she has much greater self-control than Donald.

In the "Mouse Works"/"House of Mouse" cartoons, she was sometimes portrayed as intrusive and overly talkative. She would invite herself in without asking and would tag along on trips where she was not wanted. In "House of Mouse", Daisy was often waiting for her ″Big Break″, taking any and every opportunity to perform a number of talent acts on stage. Daisy was separated from Donald in that her quest for fame was not as prominent, and relied less on jealousy than eagerness.

Daisy is a white duck with an orange bill and legs. She usually has indigo eyeshadow, long distinct eyelashes and ruffled feathers around her lowest region to suggest a skirt.

She is usually seen sporting a blouse with puffed short sleeves and a v-neckline. She also wears a matching bow, heeled shoes and a single bangle on her wrist. The colors of her clothes change very often, but her signature colors are usually purple and pink.

The creators of the television series "Quack Pack", in keeping with their modernization theme, reworked Daisy's character into a career-oriented woman and thus gave her a different appearance to match. While keeping with the purple and pink motif, Daisy usually wore long dresses with high-heeled shoes and instead of wearing her trademark hair bow, the feathers atop her head got the same treatment as her tail feathers had before; the animators arranged them in such a manner to appear as if Daisy was sporting a more modern short hairstyle.

"House of Mouse" got her a blue and purple employee uniform, with a blue bow, earrings, and a long ponytail. In "Mickey Mouse Clubhouse", Daisy regained her purple blouse with a purple bow and shoes. She also wears a gold bangle and has a short ponytail, similar to the longer one seen in House of Mouse.

Daisy Duck has been voiced by several different voice actors over the years, yet by far the most extensive work has been done by Tress MacNeille, who took on the role in 1999.

Clarence Nash voiced Daisy in her debut in "Mr. Duck Steps Out". In the short, Nash voiced Daisy in a similar 'duck-like' voice as Donald's. Starting with "Donald's Crime" (1945), Ruth Clifford, best known as the voice of Minnie Mouse in the late 1940s and early 1950s, took over vocal duties on the character, giving her a more "normal" female human voice. Clifford would voice Daisy in a further four shorts between 1945 and 1948, with her last being "Donald's Dream Voice" (1948). For "Donald's Dilemma" (1947), actress Gloria Blondell voiced Daisy. Clifford returned to the role one final time in "Crazy Over Daisy" (1950). Vivi Janiss voiced the character in "Donald's Diary" (1954), while renowned voice actress June Foray (Rocky the Flying Squirrel) voiced her in her final classic shorts appearance, the educational Donald Duck short "How to Have an Accident at Work" (1959).

Voice actress Janet Waldo, best known as the voice of Judy Jetson, voiced Daisy in the Disneyland Records album "An Adaptation of Dickens' Christmas Carol, Performed by The Walt Disney Players" (1974).

In 1983, Daisy was voiced by Patricia Parris in "Mickey's Christmas Carol". Tony Anselmo voiced Daisy in "Down and Out with Donald Duck" (1987). Daisy was then voiced by Kath Soucie throughout her first regular television series "Quack Pack" (1996). From 1997 to 1999, Daisy was voiced by Diane Michelle in the anthology film "The Spirit of Mickey", the first season of "Mickey Mouse Works", and other media and games at the time. Michelle alternated in the role with Tress MacNeille for "Mickey's Once Upon a Christmas". In 1999, MacNeille took over as Daisy's full-time voice starting with the second season of "Mickey Mouse Works". MacNeille has voiced Daisy in the television series "House of Mouse", "Mickey Mouse Clubhouse", "Mickey Mouse", "Mickey Mouse Mixed-Up Adventures", "Legend of the Three Caballeros", "DuckTales", and "The Wonderful World of Mickey Mouse". MacNeille has also voiced Daisy in television specials, movies, and video games. Daisy was voiced by Russi Taylor in "Fantasia 2000", although she has no lines other than a scream. In the second season of "Mickey Mouse Funhouse", MacNeille was replaced by Debra Wilson as MacNeille was uninterested in continuing the series. Wilson, the first African-American performer of Daisy, also voiced the character in the holiday special "Mickey Saves Christmas".

Donna Duck made her sole animated appearance in the short film "Don Donald" (1937), directed by Ben Sharpsteen. It was the first installment of the "Donald Duck" film series and was also the first time Donald was shown with a love interest. In the story, Donald travels to Mexico to court a duck who is largely a female version of himself. She is portrayed with the same feisty temperament and as such was also voiced by Clarence Nash. At the end of the story, she spitefully abandons Donald in the desert after his car breaks down.

While Donna was not reused in film after her only appearance, she became an inspiration for the creation of Daisy. Donna appeared in early British Disney comics and was introduced in the American comic strip in 1951, as Daisy's unwitting rival for Donald's affections.

Other Disney characters, such as Goofy, were introduced under various names (Dippy Dawg) and appearances, leading some historians to conclude that Donna and Daisy are the same character. However, in these other instances, changes usually developed over time, during which the character remained in use. Donna, on the other hand, appeared only once, and it was several years before a new female love interest for Donald was designed. There were many significant differences between the two characters all-at-once, in personality, nationality, name and attire.

According to The Encyclopedia of Animated Disney Shorts and the Big Cartoon DataBase, "Don Donald" is considered Daisy's debut. "Don Donald" is included on the Disney-produced DVD "Best Pals: Donald and Daisy". In 1999, The Walt Disney Company released a collector's pin as part of their "Countdown to the Millennium" pin series, which reads "Daisy Duck debuts as Donna Duck 1937."

Daisy debuted in theatrical animation and has appeared in a total of 15 films. She appeared in 12 "Donald Duck" short films. These are, in order of release, "Mr. Duck Steps Out" (1940), "Donald's Crime" (1945), "Cured Duck" (1945), "Donald's Double Trouble" (1946), "Dumb Bell of the Yukon", "Sleepy Time Donald" (1947), "Donald's Dilemma", "Donald's Dream Voice" (1948), "Crazy Over Daisy" (1950), "Donald's Diary" (1954) & "How to Have an Accident at Work" (1959) as Donald's unnamed wife. She also made a brief cameo in the "Mickey Mouse" short film "The Nifty Nineties" (1941). After the classic shorts era, Daisy appeared in "Mickey's Christmas Carol" (1983) and "Fantasia 2000" (1999) with another cameo in "Who Framed Roger Rabbit" (1988).

Daisy Duck in her familiar name and design first appeared in "Mr. Duck Steps Out" (June 7, 1940). The short was directed by Jack King and scripted by Carl Barks. There Donald visits the house of his new romantic interest for their first known date. At first, Daisy acts shy and has her back turned to her visitor. But Donald soon notices her tail-feathers taking the form of a hand and signaling for him to come closer. But their time alone is soon interrupted by Huey, Dewey, and Louie who have followed their uncle and clearly compete with him for the attention of Daisy. Uncle and nephews take turns dancing the jitterbug with her while trying to get rid of each other. In their final effort, the three younger Ducks feed their uncle maize (corn) in the process of becoming popcorn. The process is completed within Donald himself who continues to move spastically around the house while maintaining the appearance of dancing. The short ends with an impressed Daisy showering her new boyfriend with kisses. Like her precursor, she was initially voiced by Clarence Nash, but later had a more ladylike voice.

The short stands out among other Donald shorts of the period for its use of modern music and surreal situations throughout.

One year following her introduction in "Mr. Duck Steps Out", Daisy, along with Donald and the nephews, made a brief cameo in the "Mickey Mouse" short "The Nifty Nineties", cementing her position as a recurring character.

Daisy's speaking role again came 4 years later in "Donald's Crime". While Daisy has a relatively small role in the film, her date with Donald is central to the plot and shows Donald's infatuation for her. Finding himself broke before the date; Donald steals money from his nephews, but afterward feels guilty. Donald imagines what Daisy might think of him knowing he stole money, and this leads him to reform in the end. Daisy was voiced in the film by actress Gloria Blondell, marking the first time Daisy had a "normal". The film also marked the first time Daisy appeared in an Academy Award nominated film (Best Animated Short).

Later that same year Daisy appeared again in "Cured Duck" (October 26, 1945). The short starts simply enough. Donald visits Daisy at her house. She asks him to open a window. He keeps trying to pull it open and eventually goes into a rage. By the time Daisy returns to the room, Donald has wrecked it. She demonstrates that the locking mechanism was on and criticizes his temper. She refuses to date Donald again until he learns to manage his anger. She claims Donald does not see her losing her own temper. Donald agrees to her terms and follows the surreal method of mail ordering an "insult machine", a device constantly hurling verbal and physical insults at him. He endures the whole process until feeling able to stay calm throughout it. He visits Daisy again and this time calmly opens the window. But when Daisy shows her boyfriend her new hat, his reaction is uncontrollable laughter. Daisy goes into a rage of her own and the short ends by pointing out that Donald is not the only Duck in need of anger management training. There is a continuation regarding her temper in the Mickey Mouse Works short "Donald's Dinner Date" where she and Donald have a date in a restaurant wherein they both end up with a bad temper thanks to Goofy.

Their relationship problems were also focused on in "Donald's Double Trouble" (June 28, 1946). This time Daisy criticizes his poor command of the English language and his less-than-refined manners. Unwilling to lose Daisy, Donald has to find an answer to the problem. But his solution involves his own look-alike who happens to have all the desired qualities. His unnamed look-alike happens to be unemployed at the moment and agrees to this plan. Donald provides the money for his dates with Daisy but soon comes to realize the look-alike serves as a rival suitor. The rest of the short focuses on his increasing jealousy and efforts to replace the look-alike during the next date. A failed attempt at a tunnel of love results in the two male Ducks exiting the tunnel in each other's hands by mistake. Daisy walks out completely drenched. She jumps up and down and sounds like a record played too fast as Donald and his look-alike run away.

In "Dumb Bell of the Yukon", Daisy is the motivation behind Donald's hunting trip after he reads a letter from her saying she likes fur coats. Daisy briefly appears in a non-speaking role in Donald's daydream, imagining how pleased she will be.

Her next appearance in "Sleepy Time Donald" (May 9, 1947) involved Daisy attempting to rescue a sleepwalking Donald from wandering into danger. Donald is loose in an urban environment and the humor results from the problems Daisy herself suffers while trying to keep him safe.

Daisy was the protagonist of "Donald's Dilemma" (July 11, 1947). In the short, Donald and Daisy are out on a date when a flower pot falls on his head. He regains consciousness soon enough but with some marked differences. Both his speaking and singing voices have been improved to the point of being able to enter a new career as a professional singer. He also acts more refined than usual. Most importantly Donald suffers from partial amnesia and has no memory of Daisy. Donald goes on becoming a well-known crooner and his rendition of When You Wish upon a Star becomes a hit. He is surrounded by female fans in his every step. Meanwhile, Daisy cannot even approach her former lover and her loss results in a number of psychological symptoms. Various scenes feature her suffering from anorexia, insomnia, and self-described insanity. An often censored scene features her losing her will to live and contemplating various methods of suicide. She narrates her story to a psychologist who determines that Donald would regain his memory with another flower pot falling on his head but warns that his improved voice may also be lost along with his singing career. He offers Daisy a dilemma. Either the world has its singer, but Daisy loses him, or Daisy regains her Donald, but the world loses him. Posed with the question "her or the world", Daisy answers with a resounding and possessive scream of "Me, Me, Me". Soon Donald has returned to his old self and has forgotten about his career. His fans forget about him. But Daisy has regained her lover. This is considered a darkly humorous look at their relationship.

Daisy also appears in "Donald's Dream Voice" (1948), where she encourages Donald to have faith in himself.

1950's "Crazy Over Daisy" features Donald going to Daisy's house for a date, and getting distracted by a fight with Chip 'n Dale. The short introduced Daisy's theme song "Crazy over Daisy," and in later appearances, Donald can be heard whistling the tune, such as in "Out on a Limb" and "Donald the Dude Duck."

Daisy's final appearance in the Golden Age of American animation was in "Donald's Diary" (1954). There she played the role of a beautiful lady who manages to start a long-term relationship with Donald. But after having a nightmare about the anxieties that would come from married life, Donald runs out on her and joins the French Foreign Legion. Several scenes of the short imply that Daisy has had several previous relationships with men. Donald carves their names on a tree. Not noticing than the opposing side of the tree features her name alongside that of several other boyfriends. The marriage scene in Donald's dream featured a group of sailors waving goodbye to Daisy and mourning the loss of their apparent lover. The story bore little continuity with the "real" Donald and Daisy as Huey, Dewey, and Louie appeared as Daisy's younger brothers. It was the only time in which Daisy's parents are seen.

In 1959, Daisy made a cameo in "Donald in Mathmagic Land". When the Spirit finds Donald's mind to be too cluttered with "Antiquated Ideas", "Bungling", "False Concepts", "Superstitions", and "Confusion" there is a picture of her in the background that is signed "Love, Daisy."

Daisy appeared in "Mickey's Christmas Carol" in 1983, playing the character Isabelle, the neglected love interest of a young Ebenezer Scrooge, played by Scrooge McDuck. The film was Daisy's first theatrical appearance in almost 30 years and was also the first time she appeared apart from Donald, although the nature of the film was that of Disney characters "playing" other characters and was not part of any story continuity. Daisy was voiced by Patricia Parris in the film.

In 1988, Daisy made a cameo appearance in the finale of "Who Framed Roger Rabbit" along with many other Disney characters.

Daisy's most recent theatrical appearance was "Fantasia 2000", released in late 1999. Like the original "Fantasia", the film constituted various musical segments. Donald and Daisy appeared in non-speaking roles for the seventh of eight segments, set to the "Pomp and Circumstance" marches. The segment is a retelling of Noah's Ark with the ducks acting as Noah's assistants. Donald and Daisy become separated in the chaos of the flood and each presumes the other to have drowned until they discover each other towards the near end afterwards. Daisy kisses Donald in happiness and joy when they are reunited and the duck couple walk out of the ark hand-in-hand admiring their new home.

Daisy appeared in the direct-to-video films "Mickey's Once Upon a Christmas", "Mickey's Twice Upon a Christmas", and "".

According to the unofficial timeline of Don Rosa, Daisy was born in 1920. According to Rosa, Daisy is Donald's sister-in-law – Daisy's brother had married Donald's twin sister, Della Duck, and together, the two became the parents of Huey, Dewey, and Louie Duck. This is his explanation of why the triplets tend to call her "Aunt Daisy" while no such courtesy is given to Gladstone Gander for example. Don Rosa has said that he considers Donald and Daisy to be nonrelated and that Duck simply is the Duckburg universe equal to Smith, being a common surname.

Donna Duck served as a precursor for Daisy in both animation and comics. She first appeared in a one-page illustration titled "Don Donald" and published in "Good Housekeeping" #3701 (January 1937). The page was illustrated by Thomas "Tom" Wood (1870s – October 4, 1940) who was head of the Walt Disney Studios' publicity department from 1933 until his death. She made a brief appearance in the "Donald and Donna" comic strip published in "Mickey Mouse Weekly" from May 15 to August 21, 1937. The "Weekly" was a United Kingdom publication and the strip was illustrated at the time by William A. Ward.

Daisy made her first comics appearance on November 4, 1940. She was introduced as the new neighbor of Donald and his potential love interest. The Donald Duck comic strip was at the time scripted by Bob Karp and illustrated by Al Taliaferro. She was seemingly soft-spoken but had a fiery temper and Donald often found himself a victim to her rage. For example, one strip had Daisy waiting for Donald to carve their names and their love for each other on a tree, only to discover the male Duck had carved "Daisy loves Donald" with her name hardly visible and his name in prominent bold letters, resulting in her breaking her umbrella on his head and dismissing him as a "conceited little pup".

Her first original comic book appearance was a cameo in the story "The Mighty Trapper" by Carl Barks, first published in "Walt Disney's Comics and Stories" No. 36 (September 1943), wherein Huey, Dewey, and Louie ask her to lend them an old fur coat. Barks did not use the character again until "Donald Tames His Temper" (January 1946) when Daisy demands that Donald learns to manage his anger as a New Year's resolution. Donald has to agree but points early on that Daisy herself has the temper of a "wild-eyed wildcat".

Her next appearance by Barks in "Biceps Blues" (June 1946) introduced a key concept to their relationship. When Daisy seems impressed by a certain type of male, Donald is forced to emulate that type, no matter how unsuited Donald is for emulating it successfully. In this early case, Daisy envies her "old school chum" Susy Swan for dating a notable weightlifter. Donald at first protests that she seems too impressed by a "gorilla" just because the "muscle-bound buffalo" can lift 300 pounds. But when Daisy simply ignores him and daydreams about dating Hercules, Donald decides to start weightlifting. The rest of the story focuses on his ineptitude at exercising and the eventual efforts of Huey, Dewey, and Louie to cheer him up by various tricks pointing to Donald becoming stronger. But when Donald arranges a demonstration for Daisy, Susy, and her boyfriend, their tricks are not able to save him from ridicule. Daisy then chases Donald in anger (Donald, in turn, chases Huey, Dewey, and Louie in anger) while Susy boasts about her luck in men to her weightlifter boyfriend, who simply grunts and nods and fails to understand her words. Daisy failed to see that Susy's boyfriend is strong but otherwise not too gifted, whereas Donald is one who would go great lengths for her.

Daisy continued to make frequent appearances in stories by Barks but the next important one for her development was "Wintertime Wager" (January 1948). There she first attempts to act as the voice of reason between competing cousins Donald Duck and Gladstone Gander and in fact manages to prevent Donald losing his house to Gladstone because of a wager. This story established that both of them wanted to be in her good graces. Their next joined meeting in "Gladstone Returns" (August 1948) has Donald and Gladstone competing in raising enough money for her charity effort.

Their rivalry increased when "Donald's Love Letters" (December 1949) revealed that both cousins were romantically interested in Daisy. From then on many stories by both Barks and others would develop around this love triangle. Daisy in turns dates both of them but this fact does not prevent the two competing suitors from attempting to earn more of her affection or trying to embarrass each other in front of her. Daisy can be counted on to be making regular appearances alongside either of them for several years to come. Often it would appear as if Gladstone had the upper hand in winning Daisy due to his luck, only to find fate thwarts his plans, such as a contest where the man who hunts the most turkeys gets to have dinner with Daisy, who has won a beauty contest. Gladstone wins the turkey hunt but finds himself having dinner with an ugly woman who is the runner-up queen, as Daisy is incapacitated, and Donald is the one nursing her.

Similarly, Daisy's precursor Donna and Daisy herself were featured together as rivals for Donald's affection in a newspaper strip published on August 7, 1951. In her last appearance, on August 11, 1951, Donna had a fiancé, a caricature of Disney cartoonist Manuel Gonzales, establishing a distinction between her character and Daisy.

In the comics, Daisy is also a member of a local gossip group called the "Chit-Chat Society", which plays bridge and sponsors charity fund-raisers. The core membership includes Clarabelle Cow and Clara Cluck, though occasionally some other unnamed characters appear.

In later years, Carl Barks 'modernized' Daisy in two stories: 'The not-so-ancient mariner' and 'Hall of the mermaid queen'. In the first story, Daisy is wearing a lot of different wigs and outfits. Gladstone Gander is also seen wearing a wig and a new wardrobe in the story. In the second story, Daisy has short, curly hair and a bow that is much smaller than usual.

In the 1950s, Disney launched a series of stories titled "Daisy Duck's Diary", where Daisy was given more of a leading role. This series, originally by such cartoonists as Dick Moores, Jack Bradbury, Tony Strobl and Carl Barks, have continued to the present day in Italy, Denmark and the Netherlands.

Since 1999 Daisy, like Donald Duck has her own magazine in the Netherlands. She had one in Brazil between 1986 and 1997, and a short-lived series in 2004 with republications of old stories.

Since the early 1970s, Daisy has been featured as a superhero crime fighter in Italian Disney comics. Daisy's alter ego as Super Daisy (Paperinika in Italian) was designed by writer Guido Martina and artist Giorgio Cavazzano as a female counterpart to the "Duck Avenger" ("Paperinik" in Italian). While Donald's superhero persona was originally created to place Donald into situations where he was finally a "winner" (versus his usual portrayal as a "loser"), when Super Daisy appeared in the same story as the Duck Avenger, she then became the "winner" and Donald was once more relegated to the role of "loser". This upset some children, who complained to the comics' editors, which resulted in the Italian comics ceasing to depict Daisy as a superhero, although Super Daisy continued to be featured in the Disney comics in Brazil.

As Super Daisy, Daisy has no superpowers but instead uses devices created by high society fashion designer Genialina Edy Son. Genialina personally designed Daisy's costume, as well as supplying her with crime-fighting gear such as sleeping pills and a James Bond-esque sports car. Frequently, Super Daisy both fights alongside and against the Duck Avenger. In the Brazilian stories, Super Daisy often teams up with other Disney comic superheroes, such as Super Goof (Goofy), Super Gilly ("Gilbert"), and the Red Bat (Fethry Duck).

While the Duck Avenger's main goal is enforcing justice in Duckburg, and proving himself better than Donald's usual, unlucky self, Super Daisy acts mostly on an extreme, somewhat warped form of feminism, donning her alternate identity to prove that women are better than men at whatever they do, openly antagonizing the Duck Avenger to prove her point. Later stories, such as the "Hero Club" inspired Italian story "Ultraheroes", show Super Daisy and the Duck Avenger at the center of a weird love triangle: Super Daisy, despite their bickering eventually warms to the Duck Avenger, feeling drawn to his righteous persona. They both feel unable to pursue their relationship, as they feel themselves cheating their non-superhero selves, as they do not realize each others' identity as companions in everyday life.

At the Walt Disney Parks and Resorts and on the Disney Cruise Line ships, Daisy is a character for meet-and-greets, parades, and shows. Her semi-elusiveness has made her extra popular to an extent, adding to the fact that Daisy is a member of the Sensational Six, therefore making Daisy merchandise even more appealing to collectors. After Disney World expanded Fantasyland in 2012, Daisy became available for meet-and-greets at Pete's Silly Sideshow. At Epcot, where she appears at the main entrance. She has also appeared in restaurants such as the Tusker House and Minnie's Springtime Diner at Hollywood & Vine.

Daisy appears in an MMORPG game called Toontown Online, based on the theme parks, where she walks around Daisy Gardens leaving comments about passing toons.

In the 1996 television series "Quack Pack", Daisy was presented as a much more liberated (and patient) woman than in her previous appearances, where she was employed as a television station reporter, with Donald as her cameraman. The couple also seem to have a better and steadier relationship compared to the other series. In "Quack Pack", Daisy had a pet iguana named Knuckles.

Daisy also appeared in the later television series "Mickey Mouse Works" and "House of Mouse" as a regular character. She is also part of the main characters in "Mickey Mouse Clubhouse" and its spin-offs "Minnie's Bow-Toons", "Mickey Mouse Mixed-Up Adventures" and "Mickey Mouse Funhouse".

Daisy made her first appearance in the 2017 incarnation of "DuckTales" in "Louie's Eleven", with MacNeille once again providing her voice. In this version, Daisy and Donald meet for the first time, and her appearance is similar to the theatrical short, "Donald's Diary" (1954). She is depicted as having a temper like Donald and is an assistant to Duckburg trendsetter, Emma Glamour. After Donald attempts to infiltrate one of Glamour's parties to help his band, the Three Caballeros, he and Daisy end up trapped in an elevator and develop a mutual attraction to each other. As of the episode "New Gods on the Block!", they became a couple. and "The Last Adventure!".

In the "Kingdom Hearts" video game series, appears as a countess in Disney Castle. In "Kingdom Hearts II", she scolds Donald for being gone too long. She makes a cameo appearance in "Kingdom Hearts Birth By Sleep" and "Kingdom Hearts III".

Daisy is a playable character in the video game "Disney Think Fast" and a playable race driver in the Nintendo 64 and Game Boy Color racing game "Mickey's Speedway USA". She is also a playable character in Disney Golf for the PlayStation 2 and in Disney's Party for the GameCube and Game Boy Advance.

For the Wii: In "Epic Mickey", a robot version of Daisy appears in the game, and in "Dance Dance Revolution Disney Grooves", Daisy appears as one of the random backup dancers.

Daisy runs the Daisy Gardens neighborhood in "Disney's Toontown Online".



Dot-com bubble

The dot-com bubble (or dot-com boom) was a stock market bubble that ballooned during the late-1990s and peaked on Friday, March 10, 2000. This period of market growth coincided with the widespread adoption of the World Wide Web and the Internet, resulting in a dispensation of available venture capital and the rapid growth of valuations in new dot-com startups. 

Between 1995 and its peak in March 2000, investments in the NASDAQ composite stock market index rose 800%, only to fall 78% from its peak by October 2002, giving up all its gains during the bubble.

During the dot-com crash, many online shopping companies, notably Pets.com, Webvan, and Boo.com, as well as several communication companies, such as Worldcom, NorthPoint Communications, and Global Crossing, failed and shut down. Others, like Lastminute.com, MP3.com and PeopleSound remained through its sale and buyers acquisition. Larger companies like Amazon and Cisco Systems lost large portions of their market capitalization, with Cisco losing 80% of its stock value.

Historically, the dot-com boom can be seen as similar to a number of other technology-inspired booms of the past including railroads in the 1840s, automobiles in the early 20th century, radio in the 1920s, television in the 1940s, transistor electronics in the 1950s, computer time-sharing in the 1960s, and home computers and biotechnology in the 1980s.

Low interest rates in 1998–99 facilitated an increase in start-up companies. Although a number of these new entrepreneurs had realistic plans and administrative ability, most of them lacked these characteristics but were able to sell their ideas to investors because of the novelty of the dot-com concept.

In 2000, the dot-com bubble burst, and many dot-com startups went out of business after burning through their venture capital and failing to become profitable. However, many others, particularly online retailers like eBay and Amazon, blossomed and became highly profitable. More conventional retailers found online merchandising to be a profitable additional source of revenue. While some online entertainment and news outlets failed when their seed capital ran out, others persisted and eventually became economically self-sufficient. Traditional media outlets (newspaper publishers, broadcasters and cablecasters in particular) also found the Web to be a useful and profitable additional channel for content distribution, and an additional means to generate advertising revenue. The sites that survived and eventually prospered after the bubble burst had two things in common: a sound business plan, and a niche in the marketplace that was, if not unique, particularly well-defined and well-served.

In the aftermath of the dot-com bubble, telecommunications companies had a great deal of overcapacity as many Internet business clients went bust. That, plus ongoing investment in local cell infrastructure kept connectivity charges low, and helped to make high-speed Internet connectivity more affordable. During this time, a handful of companies found success developing business models that helped make the World Wide Web a more compelling experience. These include airline booking sites, Google's search engine and its profitable approach to keyword-based advertising, as well as eBay's auction site and Amazon.com's online department store. The low price of reaching millions worldwide, and the possibility of selling to or hearing from those people at the same moment when they were reached, promised to overturn established business dogma in advertising, mail-order sales, customer relationship management, and many more areas. The web was a new killer app—it could bring together unrelated buyers and sellers in seamless and low-cost ways. Entrepreneurs around the world developed new business models, and ran to their nearest venture capitalist. While some of the new entrepreneurs had experience in business and economics, the majority were simply people with ideas, and did not manage the capital influx prudently. Additionally, many dot-com business plans were predicated on the assumption that by using the Internet, they would bypass the distribution channels of existing businesses and therefore not have to compete with them; when the established businesses with strong existing brands developed their own Internet presence, these hopes were shattered, and the newcomers were left attempting to break into markets dominated by larger, more established businesses.

The dot-com bubble burst in March 2000, with the technology heavy NASDAQ Composite index peaking at 5,048.62 on March 10 (5,132.52 intraday), more than double its value just a year before. By 2001, the bubble's deflation was running full speed. A majority of the dot-coms had ceased trading, after having burnt through their venture capital and IPO capital, often without ever making a profit. But despite this, the Internet continues to grow, driven by commerce, ever greater amounts of online information, knowledge, social networking and access by mobile devices.

The 1993 release of Mosaic and subsequent web browsers during the following years gave computer users access to the World Wide Web, popularizing use of the Internet. Internet use increased as a result of the reduction of the "digital divide" and advances in connectivity, uses of the Internet, and computer education. Between 1990 and 1997, the percentage of households in the United States owning computers increased from 15% to 35% as computer ownership progressed from a luxury to a necessity. This marked the shift to the Information Age, an economy based on information technology, and many new companies were founded.

At the same time, a decline in interest rates increased the availability of capital. The Taxpayer Relief Act of 1997, which lowered the top marginal capital gains tax in the United States, also made people more willing to make more speculative investments. Alan Greenspan, then-Chair of the Federal Reserve, allegedly fueled investments in the stock market by putting a positive spin on stock valuations. The Telecommunications Act of 1996 was expected to result in many new technologies from which many people wanted to profit.

As a result of these factors, many investors were eager to invest, at any valuation, in any dot-com company, especially if it had one of the Internet-related prefixes or a ".com" suffix in its name. Venture capital was easy to raise. Investment banks, which profited significantly from initial public offerings (IPO), fueled speculation and encouraged investment in technology. A combination of rapidly increasing stock prices in the quaternary sector of the economy and confidence that the companies would turn future profits created an environment in which many investors were willing to overlook traditional metrics, such as the price–earnings ratio, and base confidence on technological advancements, leading to a stock market bubble. Between 1995 and 2000, the Nasdaq Composite stock market index rose 400%. It reached a price–earnings ratio of 200, dwarfing the peak price–earnings ratio of 80 for the Japanese Nikkei 225 during the Japanese asset price bubble of 1991. In 1999, shares of Qualcomm rose in value by 2,619%, 12 other large-cap stocks each rose over 1,000% in value, and seven additional large-cap stocks each rose over 900% in value. Even though the Nasdaq Composite rose 85.6% and the S&P 500 rose 19.5% in 1999, more stocks fell in value than rose in value as investors sold stocks in slower growing companies to invest in Internet stocks.

An unprecedented amount of personal investing occurred during the boom and stories of people quitting their jobs to trade on the financial market were common. The news media took advantage of the public's desire to invest in the stock market; an article in "The Wall Street Journal" suggested that investors "re-think" the "quaint idea" of profits, and CNBC reported on the stock market with the same level of suspense as many networks provided to the broadcasting of sports events.

At the height of the boom, it was possible for a promising dot-com company to become a public company via an IPO and raise a substantial amount of money even if it had never made a profit—or, in some cases, realized any material revenue. People who received employee stock options became instant paper millionaires when their companies executed IPOs; however, most employees were barred from selling shares immediately due to lock-up periods. The most successful entrepreneurs, such as Mark Cuban, sold their shares or entered into hedges to protect their gains. Sir John Templeton successfully shorted many dot-com stocks at the peak of the bubble during what he called "temporary insanity" and a "once-in-a-lifetime opportunity". He shorted stocks just before the expiration of lockup periods ending six months after initial public offerings, correctly anticipating many dot-com company executives would sell shares as soon as possible, and that large-scale selling would force down share prices.

Most dot-com companies incurred net operating losses as they spent heavily on advertising and promotions to harness network effects to build market share or mind share as fast as possible, using the mottos "get big fast" and "get large or get lost". These companies offered their services or products for free or at a discount with the expectation that they could build enough brand awareness to charge profitable rates for their services in the future.

The "growth over profits" mentality and the aura of "new economy" invincibility led some companies to engage in lavish spending on elaborate business facilities and luxury vacations for employees. Upon the launch of a new product or website, a company would organize an expensive event called a dot-com party.

In the five years after the American Telecommunications Act of 1996 went into effect, telecommunications equipment companies invested more than $500 billion, mostly financed with debt, into laying fiber optic cable, adding new switches, and building wireless networks. In many areas, such as the Dulles Technology Corridor in Virginia, governments funded technology infrastructure and created favorable business and tax law to encourage companies to expand. The growth in capacity vastly outstripped the growth in demand. Spectrum auctions for 3G in the United Kingdom in April 2000, led by Chancellor of the Exchequer Gordon Brown, raised £22.5 billion. In Germany, in August 2000, the auctions raised £30 billion. A 3G spectrum auction in the United States in 1999 had to be re-run when the winners defaulted on their bids of $4 billion. The re-auction netted 10% of the original sales prices. When financing became hard to find as the bubble burst, the high debt ratios of these companies led to bankruptcy. Bond investors recovered just over 20% of their investments. However, several telecom executives sold stock before the crash including Philip Anschutz, who reaped $1.9 billion, Joseph Nacchio, who reaped $248 million, and Gary Winnick, who sold $748 million worth of shares.

Nearing the turn of the 2000s, spending on technology was volatile as companies prepared for the Year 2000 problem. There were concerns that computer systems would have trouble changing their clock and calendar systems from 1999 to 2000 which might trigger wider social or economic problems, but there was virtually no impact or disruption due to adequate preparation. Spending on marketing also reached new heights for the sector: Two dot-com companies purchased ad spots for Super Bowl XXXIII, and 17 dot-com companies bought ad spots the following year for Super Bowl XXXIV.

On January 10, 2000, America Online, led by Steve Case and Ted Leonsis, announced a merger with Time Warner, led by Gerald M. Levin. The merger was the largest to date and was questioned by many analysts. Then, on January 30, 2000, 12 ads of the 61 ads for Super Bowl XXXIV were purchased by dot-coms (sources state ranges from 12 up to 19 companies depending on the definition of "dot-com company"). At that time, the cost for a 30-second commercial was between $1.9 million and $2.2 million.

Meanwhile, Alan Greenspan, then Chair of the Federal Reserve, raised interest rates several times; these actions were believed by many to have caused the bursting of the dot-com bubble. According to Paul Krugman, however, "he didn't raise interest rates to curb the market's enthusiasm; he didn't even seek to impose margin requirements on stock market investors. Instead, [it is alleged] he waited until the bubble burst, as it did in 2000, then tried to clean up the mess afterward". Finance author and commentator E. Ray Canterbery agreed with Krugman's criticism.

On Friday March 10, 2000, the NASDAQ Composite stock market index peaked at 5,048.62. However, on March 13, 2000, news that Japan had once again entered a recession triggered a global sell off that disproportionately affected technology stocks. Soon after, Yahoo! and eBay ended merger talks and the Nasdaq fell 2.6%, but the S&P 500 rose 2.4% as investors shifted from strong performing technology stocks to poor performing established stocks.

On March 20, 2000, "Barron's" featured a cover article titled "Burning Up; Warning: Internet companies are running out of cash—fast", which predicted the imminent bankruptcy of many Internet companies. This led many people to rethink their investments. That same day, MicroStrategy announced a revenue restatement due to aggressive accounting practices. Its stock price, which had risen from $7 per share to as high as $333 per share in a year, fell $140 per share, or 62%, in a day. The next day, the Federal Reserve raised interest rates, leading to an inverted yield curve, although stocks rallied temporarily.

Tangentially to all of speculation, Judge Thomas Penfield Jackson issued his conclusions of law in the case of "United States v. Microsoft Corp." (2001) and ruled that Microsoft was guilty of monopolization and tying in violation of the Sherman Antitrust Act. This led to a one-day 15% decline in the value of shares in Microsoft and a 350-point, or 8%, drop in the value of the Nasdaq. Many people saw the legal actions as bad for technology in general. That same day, Bloomberg News published a widely read article that stated: "It's time, at last, to pay attention to the numbers".

On Friday, April 14, 2000, the Nasdaq Composite index fell 9%, ending a week in which it fell 25%. Investors were forced to sell stocks ahead of Tax Day, the due date to pay taxes on gains realized in the previous year. By June 2000, dot-com companies were forced to reevaluate their spending on advertising campaigns. On November 9, 2000, Pets.com, a much-hyped company that had backing from Amazon.com, went out of business only nine months after completing its IPO. By that time, most Internet stocks had declined in value by 75% from their highs, wiping out $1.755 trillion in value. In January 2001, just three dot-com companies bought advertising spots during Super Bowl XXXV. The September 11 attacks accelerated the stock-market drop. Investor confidence was further eroded by several accounting scandals and the resulting bankruptcies, including the Enron scandal in October 2001, the WorldCom scandal in June 2002, and the Adelphia Communications Corporation scandal in July 2002.

By the end of the stock market downturn of 2002, stocks had lost $5 trillion in market capitalization since the peak. At its trough on October 9, 2002, the NASDAQ-100 had dropped to 1,114, down 78% from its peak.

After venture capital was no longer available, the operational mentality of executives and investors completely changed. A dot-com company's lifespan was measured by its burn rate, the rate at which it spent its existing capital. Many dot-com companies ran out of capital and went through liquidation. Supporting industries, such as advertising and shipping, scaled back their operations as demand for services fell. However, many companies were able to endure the crash; 48% of dot-com companies survived through 2004, albeit at lower valuations.

Several companies and their executives, including Bernard Ebbers, Jeffrey Skilling, and Kenneth Lay, were accused or convicted of fraud for misusing shareholders' money, and the U.S. Securities and Exchange Commission levied large fines against investment firms including Citigroup and Merrill Lynch for misleading investors.

After suffering losses, retail investors transitioned their investment portfolios to more cautious positions. Popular Internet forums that focused on high tech stocks, such as Silicon Investor, Yahoo! Finance, and The Motley Fool declined in use significantly.

Layoffs of programmers resulted in a general glut in the job market. University enrollment for computer-related degrees dropped noticeably. Aeron chairs, which retailed for $1,100 each, were liquidated en masse.

As growth in the technology sector stabilized, companies consolidated; some, such as Amazon.com, eBay, and Google gained market share and came to dominate their respective fields. The most valuable public companies are now generally in the technology sector.

In a 2015 book, venture capitalist Fred Wilson, who funded many dot-com companies and lost 90% of his net worth when the bubble burst, said about the dot-com bubble:


Discounted cash flow

The discounted cash flow (DCF) analysis, in financial analysis, is a method used to value a security, project, company, or asset, that incorporates the time value of money. 
Discounted cash flow analysis is widely used in investment finance, real estate development, corporate financial management, and patent valuation. Used in industry as early as the 1700s or 1800s, it was widely discussed in financial economics in the 1960s, and U.S. courts began employing the concept in the 1980s and 1990s. 

In discount cash flow analysis, all future cash flows are estimated and discounted by using cost of capital to give their present values (PVs). The sum of all future cash flows, both incoming and outgoing, is the net present value (NPV), which is taken as the value of the cash flows in question;
see aside.

For further context see ; 
and for the mechanics see valuation using discounted cash flows, which includes modifications typical for startups, private equity and venture capital, corporate finance "projects", and mergers and acquisitions.

Using DCF analysis to compute the NPV takes as input cash flows and a discount rate and gives as output a present value. The opposite process takes cash flows and a price (present value) as inputs, and provides as output the discount rate; this is used in bond markets to obtain the yield.

Discounted cash flow calculations have been used in some form since money was first lent at interest in ancient times. Studies of ancient Egyptian and Babylonian mathematics suggest that they used techniques similar to discounting future cash flows. Modern discounted cash flow analysis has been used since at least the early 1700s in the UK coal industry.

Discounted cash flow valuation is differentiated from the accounting book value, which is based on the amount paid for the asset. Following the stock market crash of 1929, discounted cash flow analysis gained popularity as a valuation method for stocks. Irving Fisher in his 1930 book "The Theory of Interest" and John Burr Williams's 1938 text "The Theory of Investment Value" first formally expressed the DCF method in modern economic terms.

The discounted cash flow formula is derived from the present value formula for calculating the time value of money

and compounding returns:

Thus the discounted present value (for one cash flow in one future period) is expressed as:

where

Where multiple cash flows in multiple time periods are discounted, it is necessary to sum them as follows:

for each future cash flow ("FV") at any time period ("t") in years from the present time, summed over all time periods. The sum can then be used as a net present value figure. If the amount to be paid at time 0 (now) for all the future cash flows is known, then that amount can be substituted for "DPV" and the equation can be solved for "r", that is the internal rate of return.

All the above assumes that the interest rate remains constant throughout the whole period.

If the cash flow stream is assumed to continue indefinitely, the finite forecast is usually combined with the assumption of constant cash flow growth beyond the discrete projection period. The total value of such cash flow stream is the sum of the finite discounted cash flow forecast and the Terminal value (finance).

For continuous cash flows, the summation in the above formula is replaced by an integration:

where formula_6 is now the "rate" of cash flow, and formula_7.

The act of discounting future cash flows asks "how much money would have to be invested currently, at a given rate of return, to yield the forecast cash flow, at its future date?" In other words, discounting returns the present value of future cash flows, where the rate used is the cost of capital that "appropriately" reflects the risk, and timing, of the cash flows.

This "required return" thus incorporates:
For the latter, various models have been developed, where the premium is (typically) calculated as a function of the asset's performance with reference to some macroeconomic variable - for example, the CAPM compares the asset's historical returns to the "overall market's"; see and .

An alternate, although less common approach, is to apply a "fundamental valuation" method, such as the "T-model", which instead relies on accounting information.
Other methods of discounting, such as hyperbolic discounting, are studied in academia and said to reflect intuitive decision-making, but are not generally used in industry. In this context the above is referred to as "exponential discounting".

The terminology "expected return", although formally the mathematical expected value, is often used interchangeably with the above, where "expected" means "required" or "demanded" by investors.

The method may also be modified by industry, for example various formulae have been proposed when choosing a discount rate in a healthcare setting;
similarly in a mining setting, where risk-characteristics can differ (dramatically) by property. 

For these valuation purposes, a number of different DCF methods are distinguished today, some of which are outlined below. The details are likely to vary depending on the capital structure of the company. However the assumptions used in the appraisal (especially the equity discount rate and the projection of the cash flows to be achieved) are likely to be at least as important as the precise model used. Both the income stream selected and the associated cost of capital model determine the valuation result obtained with each method. (This is one reason these valuation methods are formally referred to as the Discounted Future Economic Income methods.) 
The below is offered as a high-level treatment; for the components / steps of business modeling here, see .



The following difficulties are identified with the application of DCF in valuation:
To address the lack of integration of the short and long term importance, value and risks associated with natural and social capital into the traditional DCF calculation, companies are valuing their environmental, social and governance (ESG) performance through an Integrated Management approach to reporting, that expands DCF or Net Present Value to Integrated Future Value (IntFV).

This allows companies to value their investments not just for their financial return but also the long term environmental and social return of their investments. By highlighting environmental, social and governance performance in reporting, decision makers have the opportunity to identify new areas for value creation that are not revealed through traditional financial reporting.
As an example, the social cost of carbon is one value that can be incorporated into Integrated Future Value calculations to encompass the damage to society from greenhouse gas emissions that result from an investment.

This is an integrated approach to reporting that supports Integrated Bottom Line (IBL) decision making, which takes triple bottom line (TBL) a step further and combines financial, environmental and social performance reporting into one balance sheet. This approach provides decision makers with the insight to identify opportunities for value creation that promote growth and change within an organization.



Lists of deities

This is an index of lists of deities of the different religions, cultures and mythologies of the world.


Dachau, Bavaria

Dachau () is a town in the Upper Bavaria district of Bavaria, a state in the southern part of Germany. It is a major district town—a "Große Kreisstadt"—of the administrative region of Upper Bavaria, about north-west of Munich. It is now a popular residential area for people working in Munich, with roughly 45,000 inhabitants. The historic centre of town with its 18th-century castle is situated on an elevation and visible over a great distance.

Dachau was founded in the 9th century. It was home to many artists during the late 19th and early 20th centuries; well-known author and editor Ludwig Thoma lived here for two years. The town is known for its proximity to the Dachau concentration camp, operated by Nazi Germany between 1933 and 1945, in which tens of thousands of prisoners died.

The origin of the name is not known. It may have originated with the Celts who lived there before the Germans came. An alternative idea is that it comes from the Old High German word daha meaning clay, and ouwe, water overflown land.

As the Amper River would divert into backwaters in several places, there were many fords making it possible to cross the river. The oldest findings of human presence here date back to the Stone Age. The most noteworthy findings were discovered near Feldgeding in the adjoining municipality Bergkirchen.
Around 1000 B.C. the Celts arrived in this area and settled. The name “Dachau” originated in the Celtic "Dahauua", which roughly translates to “loamy meadow” and also alludes to the loamy soil of the surrounding hills. Some theories assume the name “Amper” river may derive from the Celtic word for “water”. 
Approximately at the turn of the first millennium the Romans conquered the area and incorporated it into the province of Rhaetia. A Roman trade road between Salzburg and today's Augsburg is said to have run through Dachau. Remains of this old route are found along the Amper marshlands.

The first known documentation of Dachau occurs in a medieval deed issued by the Noble Erchana of Dahauua to the prince-bishop of Freising, both descendants of the lineage of the Aribonids. With this deed, dated to August 15, 805 A.D. ("the Feast of the Assumption of the Blessed Virgin Mary"), she donated her entire property in Dachau, including five so-called "Colonenhöfe" and some serfs and bondsman, to devolve to the Bishop of the Diocese of Freising after her death.

During much of the 12th century, Dachau was the primary residence of a smaller branch from the House of Wittelsbach led by Otto I, Count of Scheyern-Dauchau. When Conrad III died in 1182, Duke Otto I of Bavaria purchased the land and granted it market rights, that were then affirmed between 1270 and 1280 by Duke Ludwig II der Strenge (the Strict).

In 1467 Sigismund, Duke of Bavaria resigned and then kept only Bavaria-Dachau as his domain until his death in 1501.

Between 1546 and 1577, the House of Wittelsbach had the Dachau Palace erected in the Renaissance style. From June 1715 to Autumn 1717, Joseph Effner remodeled the palace to suit the contemporary taste in style.

At the beginning of the 19th century, the castle's north-, east- and south-wing had to be demolished due to their state of disrepair. The west-wing housing the dance hall with a superb view of the enchanting gardens, still remains today. On the first floor the original renaissance wood carved, coffered ceiling can be admired by visitors.

During the second half of the 19th century, the town began to attract landscape artists. The Dachau art colony, which flourished between 1890 and 1914, brought the town recognition as one of the most important artist's colonies in Germany beside Worpswede.

In 1933, the Dachau concentration camp was built east of the city by the SS of Nazi Germany and operated until 1945. It was the first of what became many Nazi concentration camps. 14,100 prisoners were killed in the camp by the Nazis and almost another 10,000 in its sub-camps.

Dachau is northwest of Munich. It is 483 meters above sea level by the river Amper, with a boundary demarcated by lateral moraines formed during the last ice age and the Amper glacial valley. It is also close to a large marshy area called Dachauer Moos. Highest elevation of the district is the so-called "Schlossberg", the lowest point is near the neighborhood of Prittlbach, at the border to the next community of Hebertshausen. The bordering communities are Bergkirchen to the west, Schwabhausen to the northwest, Röhrmoos to the north, Hebertshausen to the northeast, and Karlsfeld to the south. To the east the greater district Dachau borders on the greater district of Munich with the community of Oberschleißheim.

The city is divided into 3 zones:


Since 1972, the former municipality of Pellheim, along with the communities of Pellheim proper, Pullhausen, Assenhausen, Lohfeld, and Viehgarten, have been incorporated into Dachau.

Running from the west, the river Amper runs south of Dachau's old town, changes its direction at the former paper milling plant to the northeast and continues through Prittlbach into Hebertshausen.

Coming from Karlsfeld, the Würm crosses Dachau-East and merges into the river Amper just outside the district limit of Hebertshausen.

The Gröbenbach, which has its source south of Puchheim, runs through town coming from the south and merges into the Amper river at several locations near the festival grounds.

The Mühlbach, a man made canal, is diverted from the river Amper at the electrical power plant and runs parallel and flows back into it after passing the paper mill. The name derives from the frequent mills in former times along the canal which took advantage of the decline between Mühlbach and Amper. West of the so-called Festwiese runs another canal, called Lodererbach.

In town there are still parts of the Schleißheimer canal remaining today. This canal was built in the mid-eighteenth century as part of the northern Munich canal system to which the Nymphenburger Canal belongs as well. 
It functioned as a transportation route between Dachau and Schleißheim. The building material recovered from the demolition of three wings of the Dachau castle was transported to Schleißheim this way.

By allowing it to run to seed and through deliberate cultivation by the town of Dachau the canal is only still recognizable as such between Frühlingstraße and the Pollnbach. Outside the city limit the original canal continues on to Schloss Schleißheim.

Within the city boundaries, in Dachau Süd (South), there is also a small lake called Stadtweiher.

The city is served by Munich S-Bahn (S2) and Deutsche Bahn via Dachau railway station located in the South of the town. The station is also annexed to the central bus terminal. In Dachau the line S2 is split in two directions: Petershausen and Altomünster. Both lines are named S2 but with different direction names. The offshoot to Altomünster is also served by Dachau Stadt Railway Station which is much smaller than the main railway station. There are five bus lines which are operated by Stadtwerke Dachau: 719, 720, 722, 724 and 726. There is no tramway transport.

Dachau has a well-developed road infrastructure for regional transportation. The city is connected to Bundesautobahn 8 (via Fürstenfeldbruck) with Munich-Pasing southbound, and westbound terminating in Karlsruhe. Dachau is connected to Bundesautobahn 92 via Oberschleißheim connector which is located east of Dachau. Bundesautobahn 99 is connected with Dachau via Karlsfeld which is located south of Dachau. Bundesstraße No. 471 (via Rothschwaige) connects eastbound towns such as the neighboring city Fürstenfeldbruck and westbound towns such as Oberschleißheim. Bundesstraße No. 304 starts in the south of the city and connects southbound towns until the German-Austrian border. Additionally, several Staatsstraßen connect Dachau with surrounding towns and villages.



 City of Dachau

Dachau is twinned with:

Dachau also cooperates with:



Drosophila

Drosophila () is a genus of flies, belonging to the family Drosophilidae, whose members are often called "small fruit flies" or (less frequently) pomace flies, vinegar flies, or wine flies, a reference to the characteristic of many species to linger around overripe or rotting fruit. They should not be confused with the Tephritidae, a related family, which are also called fruit flies (sometimes referred to as "true fruit flies"); tephritids feed primarily on unripe or ripe fruit, with many species being regarded as destructive agricultural pests, especially the Mediterranean fruit fly.

One species of "Drosophila" in particular, "D. melanogaster", has been heavily used in research in genetics and is a common model organism in developmental biology. The terms "fruit fly" and ""Drosophila"" are often used synonymously with "D. melanogaster" in modern biological literature. The entire genus, however, contains more than 1,500 species and is very diverse in appearance, behavior, and breeding habitat.

The term ""Drosophila"", meaning "dew-loving", is a modern scientific Latin adaptation from Greek words , ', "dew", and , ', "lover".

"Drosophila" species are small flies, typically pale yellow to reddish brown to black, with red eyes. When the eyes (essentially a film of lenses) are removed, the brain is revealed. "Drosophila" brain structure and function develop and age significantly from larval to adult stage. Developing brain structures make these flies a prime candidate for neuro-genetic research. Many species, including the noted Hawaiian picture-wings, have distinct black patterns on the wings. The plumose (feathery) arista, bristling of the head and thorax, and wing venation are characters used to diagnose the family. Most are small, about long, but some, especially many of the Hawaiian species, are larger than a house fly.

Environmental challenge by natural toxins helped to prepare "Drosophila"e to detox DDT, by shaping the glutathione "S"-transferase mechanism that metabolizes both.

The "Drosophila" genome is subject to a high degree of selection, especially unusually widespread negative selection compared to other taxa. A majority of the genome is under selection of some sort, and a supermajority of this is occurring in non-coding DNA.

Effective population size has been credibly suggested to positively correlate with the effect size of both negative and positive selection. Recombination is likely to be a significant source of diversity. There is evidence that crossover is positively correlated with polymorphism in "D." populations.

"Drosophila" species are found all around the world, with more species in the tropical regions. "Drosophila" made their way to the Hawaiian Islands and radiated into over 800 species. They can be found in deserts, tropical rainforest, cities, swamps, and alpine zones. Some northern species hibernate. The northern species "D. montana" is the best cold-adapted, and is primarily found at high altitudes. Most species breed in various kinds of decaying plant and fungal material, including fruit, bark, slime fluxes, flowers, and mushrooms. "Drosophila" species that are fruit-breeding are attracted to various products of fermentation, especially ethanol and methanol. Fruits exploited by "Drosophila" species include those with a high pectin concentration, which is an indicator of how much alcohol will be produced during fermentation. Citrus, morinda, apples, pears, plums, and apricots belong into this category.

The larvae of at least one species, "D. suzukii", can also feed in fresh fruit and can sometimes be a pest. A few species have switched to being parasites or predators. Many species can be attracted to baits of fermented bananas or mushrooms, but others are not attracted to any kind of baits. Males may congregate at patches of suitable breeding substrate to compete for the females, or form leks, conducting courtship in an area separate from breeding sites.

Several "Drosophila" species, including "Drosophila melanogaster", "D. immigrans", and "D. simulans", are closely associated with humans, and are often referred to as domestic species. These and other species ("D. subobscura", and from a related genus "Zaprionus indianus") have been accidentally introduced around the world by human activities such as fruit transports.
Males of this genus are known to have the longest sperm cells of any studied organism on Earth, including one species, "Drosophila bifurca", that has sperm cells that are long. The cells mostly consist of a long, thread-like tail, and are delivered to the females in tangled coils. The other members of the genus "Drosophila" also make relatively few giant sperm cells, with that of "D. bifurca" being the longest. "D. melanogaster" sperm cells are a more modest 1.8 mm long, although this is still about 35 times longer than a human sperm. Several species in the "D. melanogaster" species group are known to mate by traumatic insemination.

"Drosophila" species vary widely in their reproductive capacity. Those such as "D. melanogaster" that breed in large, relatively rare resources have ovaries that mature 10–20 eggs at a time, so that they can be laid together on one site. Others that breed in more-abundant but less nutritious substrates, such as leaves, may only lay one egg per day. The eggs have one or more respiratory filaments near the anterior end; the tips of these extend above the surface and allow oxygen to reach the embryo. Larvae feed not on the vegetable matter itself, but on the yeasts and microorganisms present on the decaying breeding substrate. Development time varies widely between species (between 7 and more than 60 days) and depends on the environmental factors such as temperature, breeding substrate, and crowding.

Fruit flies lay eggs in response to environmental cycles. Eggs laid at a time (e.g., night) during which likelihood of survival is greater than in eggs laid at other times (e.g., day) yield more larvae than eggs that were laid at those times. "Ceteris paribus", the habit of laying eggs at this 'advantageous' time would yield more surviving offspring, and more grandchildren, than the habit of laying eggs during other times. This differential reproductive success would cause "D. melanogaster" to adapt to environmental cycles, because this behavior has a major reproductive advantage.

Their median lifespan is 35–45 days.

The following section is based on the following "Drosophila" species: "Drosophila simulans" and "Drosophila melanogaster".
Courtship behavior of male "Drosophila" is an attractive behaviour. Females respond via their perception of the behavior portrayed by the male. Male and female "Drosophila" use a variety of sensory cues to initiate and assess courtship readiness of a potential mate. The cues include the following behaviours: positioning, pheromone secretion, following females, making tapping sounds with legs, singing, wing spreading, creating wing vibrations, genitalia licking, bending the stomach, attempt to copulate, and the copulatory act itself. The songs of "Drosophila melanogaster" and "Drosophila simulans" have been studied extensively. These luring songs are sinusoidal in nature and varies within and between species.

The courtship behavior of "Drosophila melanogaster" has also been assessed for sex-related genes, which have been implicated in courtship behavior in both the male and female. Recent experiments explore the role of fruitless ("fru") and doublesex ("dsx"), a group of sex-behaviour linked genes.

The fruitless ("fru") gene in "Drosophila" helps regulate the network for male courtship behavior; when a mutation to this gene occurs altered same sex sexual behavior in males is observed. Male "Drosophila" with the "fru" mutation direct their courtship towards other males as opposed to typical courtship, which would be directed towards females. Loss of the "fru" mutation leads back to the typical courtship behavior.

A novel class of pheromones was found to be conserved across the subgenus "Drosophila" in 11 desert dwelling species. These pheromones are triacylglycerides that are secreted exclusively by males from their ejaculatory bulb and transferred to females during mating. The function of the pheromones is to make the females unattractive to subsequent suitors and thus inhibit courtship by other males.

The following section is based on the following "Drosophila" species: "Drosophila serrata", "Drosophila pseudoobscura", "Drosophila melanogaster", and "Drosophila neotestacea". Polyandry is a prominent mating system among "Drosophila". Females mating with multiple sex partners has been a beneficial mating strategy for "Drosophila". The benefits include both pre and post copulatory mating. Pre-copulatory strategies are the behaviours associated with mate choice and the genetic contributions, such as production of gametes, that are exhibited by both male and female "Drosophila" regarding mate choice. Post copulatory strategies include sperm competition, mating frequency, and sex-ratio meiotic drive.

These lists are not inclusive. Polyandry among the "Drosophila pseudoobscura" in North America vary in their number of mating partners. There is a connection between the number of time females choose to mate and chromosomal variants of the third chromosome. It is believed that the presence of the inverted polymorphism is why re-mating by females occurs. The stability of these polymorphisms may be related to the sex-ratio meiotic drive.

However, for "Drosophila subobscura," the main mating system is monandry, not normally seen in "Drosophila."

The following section is based on the following "Drosophila" species: "Drosophila melanogaster", "Drosophila simulans", and "Drosophila mauritiana". Sperm competition is a process that polyandrous "Drosophila" females use to increase the fitness of their offspring. The female "Drosophila" has two sperm storage organs, the spermathecae and seminal receptacle, that allows her to choose the sperm that will be used to inseminate her eggs. However, some species of "Drosophila" have evolved to only use one or the other. Females have little control when it comes to cryptic female choice. Female "Drosophila" through cryptic choice, one of several post-copulatory mechanisms, which allows for the detection and expelling of sperm that reduces inbreeding possibilities. Manier et al. 2013 has categorized the post copulatory sexual selection of "Drosophila melanogaster", "Drosophila simulans", and "Drosophila mauritiana" into the following three stages: insemination, sperm storage, and fertilizable sperm. Among the preceding species there are variations at each stage that play a role in the natural selection process. This sperm competition has been found to be a driving force in the establishment of reproductive isolation during speciation.

Parthenogenesis does not occur in "D. melanogaster", but in the "gyn-f9" mutant, gynogenesis occurs at low frequency. The natural populations of "D. mangebeirai" are entirely female, making it the only obligate parthenogenetic species of Drosophila. Parthenogenesis is facultative in "parthenogenetica" and "mercatorum".

"D. melanogaster" is a popular experimental animal because it is easily cultured en masse out of the wild, has a short generation time, and mutant animals are readily obtainable. In 1906, Thomas Hunt Morgan began his work on "D. melanogaster" and reported his first finding of a white eyed mutant in 1910 to the academic community. He was in search of a model organism to study genetic heredity and required a species that could randomly acquire genetic mutation that would visibly manifest as morphological changes in the adult animal. His work on "Drosophila" earned him the 1933 Nobel Prize in Medicine for identifying chromosomes as the vector of inheritance for genes. This and other "Drosophila" species are widely used in studies of genetics, embryogenesis, chronobiology, speciation, neurobiology, and other areas.

However, some species of "Drosophila" are difficult to culture in the laboratory, often because they breed on a single specific host in the wild. For some, it can be done with particular recipes for rearing media, or by introducing chemicals such as sterols that are found in the natural host; for others, it is (so far) impossible. In some cases, the larvae can develop on normal "Drosophila" lab medium, but the female will not lay eggs; for these it is often simply a matter of putting in a small piece of the natural host to receive the eggs.

The Drosophila Species Stock Center located at Cornell University in Ithaca, New York, maintains cultures of hundreds of species for researchers.

"Drosophila" is considered one of the most valuable genetic model organisms; both adults and embryos are experimental models. "Drosophila" is a prime candidate for genetic research because the relationship between human and fruit fly genes is very close. Human and fruit fly genes are so similar, that disease-producing genes in humans can be linked to those in flies. The fly has approximately 15,500 genes on its four chromosomes, whereas humans have about 22,000 genes among their 23 chromosomes. Thus the density of genes per chromosome in "Drosophila" is higher than the human genome. Low and manageable number of chromosomes make "Drosophila" species easier to study. These flies also carry genetic information and pass down traits throughout generations, much like their human counterparts. The traits can then be studied through different "Drosophila" lineages and the findings can be applied to deduce genetic trends in humans. Research conducted on "Drosophila" help determine the ground rules for transmission of genes in many organisms. "Drosophila" is a useful in vivo tool to analyze Alzheimer's disease. Rhomboid proteases were first detected in "Drosophila" but then found to be highly conserved across eukaryotes, mitochondria, and bacteria. Melanin's ability to protect DNA against ionizing radiation has been most extensively demonstrated in "Drosophila", including in the formative study by Hopwood et al 1985.

Like other animals, "Drosophila" is associated with various bacteria in its gut. The fly gut microbiota or microbiome seems to have a central influence on "Drosophila" fitness and life history characteristics. The microbiota in the gut of "Drosophila" represents an active current research field.

"Drosophila" species also harbour vertically transmitted endosymbionts, such as "Wolbachia" and "Spiroplasma". These endosymbionts can act as reproductive manipulators, such as cytoplasmic incompatibility induced by "Wolbachia" or male-killing induced by the "D. melanogaster Spiroplasma poulsonii" (named MSRO). The male-killing factor of the "D. melanogaster" MSRO strain was discovered in 2018, solving a decades-old mystery of the cause of male-killing. This represents the first bacterial factor that affects eukaryotic cells in a sex-specific fashion, and is the first mechanism identified for male-killing phenotypes. Alternatively, they may protect theirs hosts from infection. "Drosophila Wolbachia" can reduce viral loads upon infection, and is explored as a mechanism of controlling viral diseases ("e.g." Dengue fever) by transferring these "Wolbachia" to disease-vector mosquitoes. The "S. poulsonii" strain of "Drosophila neotestacea" protects its host from parasitic wasps and nematodes using toxins that preferentially attack the parasites instead of the host.

Since the "Drosophila" species is one of the most used model organisms, it was vastly used in genetics. However, the effect abiotic factors, such as temperature, has on the microbiome on Drosophila species has recently been of great interest. Certain variations in temperature have an impact on the microbiome. It was observed that higher temperatures (31 °C) lead to an increase of "Acetobacter" populations in the gut microbiome of "Drosophila melanogaster" as compared to lower temperatures (13 °C). In low temperatures (13 °C), the flies were more cold resistant and also had the highest concentration of "Wolbachia."

The microbiome in the gut can also be transplanted among organisms. It was found that "Drosophila melanogaster" became more cold-tolerant when the gut microbiota from "Drosophila melanogaster" that were reared at low temperatures. This depicted that the gut microbiome is correlated to physiological processes.

Moreover, the microbiome plays a role in aggression, immunity, egg-laying preferences, locomotion and metabolism. As for aggression, it plays a role to a certain degree during courtship. It was observed that germ-free flies were not as competitive compared to the wild-type males. Microbiome of the "Drosophila" species is also known to promote aggression by octopamine OA signalling. The microbiome has been shown to impact these fruit flies' social interactions, specifically aggressive behaviour that is seen during courtship and mating.

"Drosophila" species are prey for many generalist predators, such as robber flies. In Hawaii, the introduction of yellowjackets from mainland United States has led to the decline of many of the larger species. The larvae are preyed on by other fly larvae, staphylinid beetles, and ants.

As with many Eukaryotes, this genus is known to express SNAREs, and as with several others the components of the SNARE complex are known to be somewhat substitutable: Although the loss of SNAP-25 - a component of neuronal SNAREs - is lethal, SNAP-24 can fully replace it. For another example, an R-SNARE not normally found in synapses can substitute for synaptobrevin.

The Spätzle protein is a ligand of Toll. In addition to melanin's more commonly known roles in the endoskeleton and in neurochemistry, melanization is one step in the immune responses to some pathogens. Dudzic et al 2019 additionally find a large number of shared serine protease messengers between Spätzle/Toll and melanization and a large amount of crosstalk between these pathways.

The genus "Drosophila" as currently defined is paraphyletic (see below) and contains 1,450 described species, while the total number of species is estimated at thousands. The majority of the species are members of two subgenera: "Drosophila" (about 1,100 species) and "Sophophora" (including "D. (S.) melanogaster"; around 330 species).

The Hawaiian species of "Drosophila" (estimated to be more than 500, with roughly 380 species described) are sometimes recognized as a separate genus or subgenus, "Idiomyia", but this is not widely accepted. About 250 species are part of the genus "Scaptomyza", which arose from the Hawaiian "Drosophila" and later recolonized continental areas.

Evidence from phylogenetic studies suggests these genera arose from within the genus "Drosophila":

Several of the subgeneric and generic names are based on anagrams of "Drosophila", including "Dorsilopha", "Lordiphosa", "Siphlodora", "Phloridosa", and "Psilodorha".

"Drosophila" species are extensively used as model organisms in genetics (including population genetics), cell biology, biochemistry, and especially developmental biology. Therefore, extensive efforts are made to sequence drosphilid genomes. The genomes of these species have been fully sequenced:

The data have been used for many purposes, including evolutionary genome comparisons. "D. simulans" and "D. sechellia" are sister species, and provide viable offspring when crossed, while "D. melanogaster" and "D. simulans" produce infertile hybrid offspring. The "Drosophila" genome is often compared with the genomes of more distantly related species such as the honeybee "Apis mellifera" or the mosquito "Anopheles gambiae".

The modEncode consortium is currently sequencing eight more "Drosophila" genomes, and even more genomes are being sequenced by the i5K consortium.

Curated data are available at FlyBase.

The led by Andrew G. Clark, Michael Eisen, Douglas Smith, Casey Bergman, Brian Oliver, Therese Ann Markow, Thomas Kaufman, Manolis Kellis, William Gelbart, Venky Iyer, Daniel Pollard, Timothy Sackton, Amanda Larracuente, Nadia Singh, and including Wojciech Makalowski, Mohamed Noor, Temple F. Smith, Craig Venter, Peter Keightley, and Leonid Boguslavsky among its contributors presents ten new genomes and combines those with previously released genomes for "D. melanogaster" and "D. pseudoobscura" to analyse the evolutionary history and common genomic structure of the genus. This includes the discovery of transposable elements and illumination of their evolutionary history. Bartolomé et al 2009 find at least of the TEs in "D. melanogaster", "D. simulans" and "D. yakuba" have been acquired by horizontal transfer. They find an average of . Bartolomé also finds HT TEs follow other relatedness metrics, with "D. melanogaster"⇔"D. simulans" events being twice as common as either of them ⇔ "D. yakuba".



Dictatorship

A dictatorship is an autocratic form of government which is characterized by a leader, or a group of leaders, who hold governmental powers with few to no limitations. Politics in a dictatorship are controlled by a dictator, and they are facilitated through an inner circle of elites that includes advisers, generals, and other high-ranking officials. The dictator maintains control by influencing and appeasing the inner circle and repressing any opposition, which may include rival political parties, armed resistance, or disloyal members of the dictator's inner circle. Dictatorships can be formed by a military coup that overthrows the previous government through force or they can be formed by a self-coup in which elected leaders make their rule permanent. Dictatorships are authoritarian or totalitarian, and they can be classified as military dictatorships, one-party dictatorships, personalist dictatorships, or absolute monarchies.

The use of the term "dictatorship" emerged in the Roman Republic, referring to "a temporary grant of absolute power to a leader to handle some emergency." The earliest military dictatorships developed in the post-classical era, particularly in Shogun-era Japan and in England under Cromwell. Modern dictatorships first developed in the 19th century, which included Bonapartism in Europe and "caudillos" in Latin America. The 20th century saw the rise of fascist and communist dictatorships in Europe; fascism was eradicated in the aftermath of World War II in 1945, while communism spread to other continents, maintaining prominence until the end of the Cold War in 1991. The 20th century also saw the rise of personalist dictatorships in Africa and military dictatorships in Latin America, both of which became prominent in the 1960s and 1970s.

The period following the collapse of the Soviet Union witnessed a sporadic rise in democracies across the world, despite several dictatorships persisting into the 21st century, particularly in Africa and Asia. During the early 21st century, democratic governments came to outnumber authoritarian states by 98 to 80. The second decade was marked by a democratic recession, following the 2008 global financial crisis which drastically reduced the appeal of the Western model across the world. By 2019, the number of authoritarian governments had again surmounted that of democracies by 92 to 87.

Dictatorships often attempt to portray a democratic facade, frequently holding elections in order to establish their legitimacy or provide incentives to members of the ruling party, but these elections are not competitive for the opposition. Stability in a dictatorship is maintained through coercion and political repression, which involves the restriction of access to information, the tracking of the political opposition, and acts of violence. Dictatorships that fail to repress the opposition are susceptible to collapse through a coup or a revolution.

The power structures of dictatorships vary, and different definitions of dictatorship consider different elements of this structure. Political scientists such as Juan José Linz and Samuel P. Huntington identify key attributes that define the power structure of a dictatorship, including a single leader or a small group of leaders, the exercise of power with few limitations, limited political pluralism, and limited mass mobilization.

The dictator exercises most or total power over the government and society, but sometimes elites are necessary to carry out the dictator's rule. They form an inner circle, making up a class of elites that hold a degree of power within the dictatorship and receive benefits in exchange for their support. They may be military officers, party members, or friends or family of the dictator. Elites are also the primary political threats of a dictator, as they can leverage their power to influence or overthrow the dictatorship. The inner circle's support is necessary for a dictator's orders to be carried out, causing elites to serve as a check on the dictator's power. To enact policy, a dictator must either appease the regime's elites or attempt to replace them. Elites must also compete to wield more power than one another, but the amount of power held by elites also depends on their unity. Factions or divisions among the elites will mitigate their ability to bargain with the dictator, resulting in the dictator having more unrestrained power. A unified inner circle has the capacity to overthrow a dictator, and the dictator must make greater concessions to the inner circle to stay in power. This is particularly true when the inner circle is made up of military officers that have the resources to carry out a military coup.

The opposition to a dictatorship represents all of the factions that are not part of the dictatorship and anyone that does not support the regime. Organized opposition is a threat to the stability of a dictatorship, as it seeks to undermine public support for the dictator and calls for regime change. A dictator may address the opposition by repressing it through force, modifying laws to restrict its power, or appeasing it with limited benefits. The opposition can be an external group, or it can also include current and former members of the dictator's inner circle.

Totalitarianism is a variation of dictatorship characterized by the presence of a single political party and more specifically, by a powerful leader who imposes personal and political prominence. Power is enforced through a steadfast collaboration between the government and a highly developed ideology. A totalitarian government has "total control of mass communications and social and economic organizations". Political philosopher Hannah Arendt describes totalitarianism as a new and extreme form of dictatorship composed of "atomized, isolated individuals" in which ideology plays a leading role in defining how the entire society should be organized. Political scientist Juan José Linz identifies a spectrum of political systems with democracies and totalitarian regimes separated by authoritarian regimes with varied classifications of hybrid systems. He describes totalitarian regimes as exercising control over politics and political mobilization rather than merely suppressing it.

A dictatorship is formed when a specific group seizes power, with the composition of this group affecting how power is seized and how the eventual dictatorship will rule. The group may be military or political, it may be organized or disorganized, and it may disproportionately represent a certain demographic. After power is seized, the group must determine what positions its members will hold in the new government and how this government will operate, sometimes resulting in disagreements that split the group. Members of the group will typically make up the elites in a dictator's inner circle at the beginning of a new dictatorship, though the dictator may remove them as a means to gain additional power.

Unless they have undertaken a self-coup, those seizing power typically have little governmental experience and do not have a detailed policy plan in advance. If the dictator has not seized power through a political party, then a party may be formed as a mechanism to reward supporters and to concentrate power in the hands of political allies instead of militant allies. Parties formed after the seizure of power often have little influence and only exist to serve the dictator.

Most dictatorships are formed through military means or through a political party. Nearly half of dictatorships start as a military coup, though others have been started by foreign intervention, elected officials ending competitive elections, insurgent takeovers, popular uprisings by citizens, or legal maneuvering by autocratic elites to take power within their government. Between 1946 and 2010, 42% of dictatorships began by overthrowing a different dictatorship, and 26% began after achieving independence from a foreign government. Many others developed following a period of warlordism.

A classification of dictatorships, which began with political scientist Barbara Geddes in 1999, focuses on where power lies. Under this system, there are three types of dictatorships. Military dictatorships are controlled by military officers, one-party dictatorships are controlled by the leadership of a political party, and personalist dictatorships are controlled by a single individual. In some circumstances, monarchies are also considered dictatorships if the monarchs hold a significant amount of political power. Hybrid dictatorships are regimes that have a combination of these classifications.

Military dictatorships are regimes in which military officers hold power, determine who will lead the country, and exercise influence over policy. They are most common in developing nations in Africa, Asia, and Latin America. They are often unstable, and the average duration of a military dictatorship is only five years, but they are often followed by additional military coups and military dictatorships. While common in the 20th century, the prominence of military dictatorships declined in the 1970s and 1980s.

Military dictatorships are typically formed by a military coup in which senior officers use the military to overthrow the government. In democracies, the threat of a military coup is associated with the period immediately after a democracy's creation but prior to large-scale military reforms. In oligarchies, the threat of a military coup comes from the strength of the military weighed against the concessions made to the military. Other factors associated with military coups include extensive natural resources, limited use of the military internationally, and use of the military as an oppressive force domestically. Military coups do not necessarily result in military dictatorships, as power may then be passed to an individual or the military may allow democratic elections to take place.

Military dictatorships often have traits in common due to the shared background of military dictators. These dictators may view themselves as impartial in their oversight of a country due to their nonpartisan status, and they may view themselves as "guardians of the state". The predominance of violent force in military training manifests in an acceptance of violence as a political tool and the ability to organize violence on a large scale. Military dictators may also be less trusting or diplomatic and underestimate the use of bargaining and compromise in politics.

One-party dictatorships are governments in which a single political party dominates politics. Single-party dictatorships are one-party states in which only the party in power is legalized, sometimes along with minor allied parties, and all opposition parties are banned. Dominant-party dictatorships or electoral authoritarian dictatorships are one-party dictatorships in which opposition parties are nominally legal but cannot meaningfully influence government. Single-party dictatorships were most common during the Cold War, with dominant-party dictatorships becoming more common after the fall of the Soviet Union. Ruling parties in one-party dictatorships are distinct from political parties that were created to serve a dictator in that the ruling party in a one-party dictatorship permeates every level of society.

One-party dictatorships are more stable than other forms of authoritarian rule, as they are less susceptible to insurgency and see higher economic growth. Ruling parties allow a dictatorship to more broadly influence the populace and facilitate political agreement between party elites. Between 1950 and 2016, one-party dictatorships made up 57% of authoritarian regimes in the world, and one-party dictatorships have continued to expand more quickly than other forms of dictatorship in the latter half of the 20th century. Due to the structure of their leadership, one-party dictatorships are significantly less likely to face civil conflict, insurgency, or terrorism than other forms of dictatorship. The use of ruling parties also provides more legitimacy to its leadership and elites than other forms of dictatorship and facilitates a peaceful transfer of power at the end of a dictator's rule.

One-party dictatorships became prominent in Asia and Eastern Europe during the Cold War as communist governments were installed in several countries. One-party rule also developed in several countries in Africa during decolonization in the 1960s and 1970s, some of which produced authoritarian regimes. A ruling party in a one-party dictatorship may rule under any ideology or it may have no guiding ideology. Marxist one-party states are sometimes distinguished from other one-party states, but they function similarly. When a one-party dictatorship develops gradually through legal means, it can result in conflict between the party organization and the state apparatus and civil service, as the party rules in parallel and increasingly appoints its own members to positions of power. Parties that take power through violence are often able to implement larger changes in a shorter period of time.

Personalist dictatorships are regimes in which all of the power lies in the hands of a single individual. They differ from other forms of dictatorships in that the dictator has greater access to key political positions and the government's treasury, and they are more commonly subject to the discretion of the dictator. Personalist dictators may be members of the military or leaders of a political party, but neither the military nor the party exercises power independently from the dictator. In personalist dictatorships, the elite corps are usually made up of close friends or family members of the dictator, who typically handpicks these individuals to serve their posts. These dictatorships often emerge either from loosely organized seizures of power, giving the leader opportunity to consolidate power, or from democratically elected leaders in countries with weak institutions, giving the leader opportunity to change the constitution. Personalist dictatorships are more common in Sub-Saharan Africa due to less established institutions in the region.

Personalist dictators typically favor loyalty over competence in their governments and have a general distrust of intelligentsia. Elites in personalist dictatorships often do not have a professional political career and are unqualified for positions they are given. A personalist dictator will manage these appointees by segmenting the government so that they cannot collaborate. The result is that such regimes have no internal checks and balances, and are thus unrestrained when exerting repression on their people, making radical shifts in foreign policy, or starting wars with other countries. Due to the lack of accountability and the smaller group of elites, personalist dictatorships are more prone to corruption than other forms of dictatorship, and they are more repressive than other forms of dictatorship. Personalist dictatorships often collapse with the death of the dictator. They are more likely to end in violence and less likely to democratize than other forms of dictatorship.

Personalist dictatorships fit the exact classic stereotype of authoritarian rule. Within a personalist regime an issue called "The dictator's dilemma" arises. This idea references the heavy reliance on repression of the public in order to stay in power, which creates incentives for all constituents to falsify their preferences, which does not allow for dictators to know the genuine popular beliefs or their realistic measure of societal support. As a result of authoritarian politics, a series of major issues may ensue. Preference falsification, Internal politics, data scarcity, and restriction of media are just a few examples of the dangers of a personalistic authoritarian regime. Although, when it comes to polling and elections a dictator could use their power to override private preferences. Many personalist regimes will install open ballots to protect their regimes and implement heavy security measures and censorship for those whose personal preferences do not align with the values of the leader.

The shift in the power relation between the dictator and their inner circle has severe consequences for the behavior of such regimes as a whole. Personalist regimes diverge from other regimes when it comes to their longevity, methods of breakdown, levels of corruption, and proneness to conflicts. On average, they last twice as long as military dictatorships, but not as long as one-party dictatorships. Personalist dictatorships also experience growth differently, as they often lack the institutions or qualified leadership to sustain an economy.

An absolute monarchy is a monarchy in which the monarch rules without legal limitations. This makes it distinct from constitutional monarchy and ceremonial monarchy. In an absolute monarchy, power is limited to the royal family, and legitimacy is established by historical factors. Monarchies may be dynastic, in which the royal family serves as a ruling institution similar to a political party in a one-party state, or they may be non-dynastic, in which the monarch rules independently of the royal family as a personalist dictator. Monarchies allow for strict rules of succession that produce a peaceful transfer of power on the monarch's death, but this can also result in succession disputes if multiple members of the royal family claim a right to succeed. In the modern era, absolute monarchies are most common in the Middle East.

Dictatorship is historically associated with the Ancient Greek concept of tyranny, and several ancient Greek rulers have been described as "tyrants" that are comparable to modern dictators. The concept of "dictator" was first developed during the Roman Republic. A Roman dictator was a special magistrate that was temporarily appointed by the consul during times of crisis and granted total executive authority. The role of dictator was created for instances when a single leader was needed to command and restore stability. At least 85 such dictators were chosen over the course of the Roman Republic, the last of which was chosen to wage the Second Punic War. The dictatorship was revived 120 years later by Sulla after his crushing of a populist movement, and 33 years after that by Julius Caesar. Caesar subverted the tradition of temporary dictatorships when he was made , or a dictator for life, which led to the creation of the Roman Empire. The rule of a dictator was not necessarily considered tyrannical in Ancient Rome, though it has been described in some accounts as a "temporary tyranny" or an "elective tyranny".

Asia saw several military dictatorships during the post-classical era. Korea experienced military dictatorships under the rule of Yeon Gaesomun in the 7th century and under the rule of the Goryeo military regime in the 12th and 13th centuries. Shoguns were "de facto" military dictators in Japan beginning in 1185 and continuing for over six hundred years. During the Lê dynasty of Vietnam between the 16th and 18th centuries, the country was under "de facto" military rule by two rival military families: the Trịnh lords in the north and the Nguyễn lords in the south. In Europe, the Commonwealth of England under Oliver Cromwell, formed in 1649 after the Second English Civil War, has been described as a military dictatorship by its contemporary opponents and by some modern academics. Maximilien Robespierre has been similarly described as a dictator while he controlled the National Convention in France and carried out the Reign of Terror in 1793 and 1794.

Dictatorship developed as a major form of government in the 19th century, though the concept was not universally seen pejoratively at the time, with both a tyrannical concept and a quasi-constitutional concept of dictatorship understood to exist. In Europe it was often thought of in terms of Bonapartism and Caesarism, with the former describing the military rule of Napoleon and the latter describing the imperial rule of Napoleon III in the vein of Julius Caesar. The Spanish American wars of independence took place in the early-19th century, creating many new Latin American governments. Many of these governments fell under the control of "caudillos", or personalist dictators. Most caudillos came from a military background, and their rule was typically associated with pageantry and glamor. Caudillos were often nominally constrained by a constitution, but the caudillo had the power to draft a new constitution as he wished. Many are noted for their cruelty, while others are honored as national heroes.

In the time between World War I and World War II, several dictatorships were established in Europe through coups which were carried out by far-left and far-right movements. The aftermath of World War I resulted in a major shift in European politics, establishing new governments, facilitating internal change in older governments, and redrawing the boundaries between countries, allowing opportunities for these movements to seize power. The societal upheaval caused by World War I and the unstable peace it produced further contributed to instability that benefited extremist movements and rallied support for their causes. Far-left and far-right dictatorships used similar methods to maintain power, including cult of personality, concentration camps, forced labour, mass murder, and genocide.

The first communist state was created by Vladimir Lenin and the Bolsheviks with the establishment of Soviet Russia during the Russian Revolution in 1917. The government was described as a dictatorship of the proletariat in which power was exercised by soviets. The Bolsheviks consolidated power by 1922, forming the Soviet Union. Lenin was followed by Joseph Stalin in 1924, who consolidated total power and implemented totalitarian rule by 1929. The Russian Revolution inspired a wave of left-wing revolutionary movements in Europe between 1917 and 1923, but none saw the same level of success.

At the same time, nationalist movements grew throughout Europe. These movements were a response to what they perceived as decadence and societal decay due to the changing social norms and race relations brought about by liberalism. Fascism developed in Europe as a rejection of liberalism, socialism, and modernism, and the first fascist political parties formed in the 1920s. Italian dictator Benito Mussolini seized power in 1922, and began implementing reforms in 1925 to create the first fascist dictatorship. These reforms incorporated totalitarianism, fealty to the state, expansionism, corporatism, and anti-communism.

Adolf Hitler and the Nazi Party created a second fascist dictatorship in Germany in 1933, obtaining absolute power through a combination of electoral victory, violence, and emergency powers. Other nationalist movements in Europe established dictatorships based on the fascist model. During World War II, Italy and Germany occupied several countries in Europe, imposing fascist puppet states upon many of the countries that they invaded. After being defeated in World War II, the far-right dictatorships of Europe collapsed, with the exceptions of Spain and Portugal. The Soviet Union occupied nationalist dictatorships in the east and replaced them with communist dictatorships, while others established liberal democratic governments in the Western Bloc.

Dictatorships in Latin America were developed late into the 19th century and persisted into the 20th century like the Porfiriato of Mexico, and further military coups established new regimes, often in the name of nationalism. After a brief period of democratization, Latin America underwent a rapid transition toward dictatorship in the 1930s. Populist movements were strengthened following the economic turmoil of the Great Depression, producing populist dictatorships in several Latin American countries. European fascism was imported to Latin America as well, and the Vargas Era of Brazil was heavily influenced by the corporatism practiced in fascist Italy.

The decolonisation of Africa prompted the creation of new governments, many of which became dictatorships in the 1960s and 1970s. Early African dictatorships were primarily personalist socialist dictatorships, in which a single socialist would take power instead of a ruling party. As the Cold War went on, the Soviet Union increased its influence in Africa, and Marxist–Leninist dictatorships developed in several African countries. Military coups were also a common occurrence after decolonisation, with 14 African countries experiencing at least three successful military coups between 1959 and 2001. These new African governments were marked by severe instability, which provided opportunities for regime change and made fair elections a rare occurrence on the continent. This instability in turn required rulers to become increasingly authoritarian to stay in power, further propagating dictatorship in Africa.

The Chinese Civil War ended in 1949, splitting the Republic of China under Chiang Kai-shek and the People's Republic of China under Mao Zedong. Mao established the People's Republic of China as a one-party communist state under his governing ideology of Maoism. While the People's Republic of China was initially aligned with the Soviet Union, relations between the two countries deteriorated as the Soviet Union underwent de-Stalinization in the late-1950s. Mao consolidated his control of the People's Republic of China with the Cultural Revolution in the 1960s, which involved the destruction of all elements of capitalism and traditionalism in China. Deng Xiaoping took power as the "de facto" leader of China after Mao's death and implemented reforms to restore stability following the Cultural Revolution and reestablish free market economics. Chiang Kai-shek continued to rule as dictator of the National government's rump state in Taiwan until his death in 1975.
Marxist and nationalist movements became popular in Southeast Asia as a response to colonial control and the subsequent Japanese occupation of Southeast Asia, with both ideologies facilitating the creation of dictatorships after World War II. Communist dictatorships in the region aligned with China following the latter's establishment as a communist state. A similar phenomenon took place in Korea, where Kim Il Sung created a Soviet-backed communist dictatorship in North Korea and Syngman Rhee created a US-backed nationalist dictatorship in South Korea.

The Middle East was decolonized during the Cold War, and many nationalist movements gained strength post-independence. These nationalist movements supported non-alignment, keeping most Middle Eastern dictatorships out of the American and Soviet spheres of influence. These movements supported pan-Arab Nasserism during most of the Cold War, but they were largely replaced by Islamic nationalism by the 1980s. Several Middle Eastern countries were the subject of military coups in the 1950s and 1960s, including Iraq, Syria, North Yemen, and South Yemen. A 1953 coup overseen by the American and British governments restored Mohammad Reza Pahlavi as the absolute monarch of Iran, who in turn was overthrown during the Iranian Revolution of 1979 that established Ruhollah Khomeini as the Supreme Leader of Iran under an Islamist government.

During World War II, many countries of Central and Eastern Europe had been occupied by the Soviet Union. When the war ended, these countries were incorporated into the Soviet sphere of influence, and the Soviet Union exercised control over their governments. Josip Broz Tito declared a communist government in Yugoslavia during World War II, which was initially aligned with the Soviet Union. The relations between the countries were strained by Soviet attempts to influence Yugoslavia, leading to the Tito–Stalin split in 1948. Albania was established as a communist dictatorship under Enver Hoxha in 1944. It was initially aligned with Yugoslavia, but its alignment shifted throughout the Cold War between Yugoslavia, the Soviet Union, and China. The stability of the Soviet Union weakened in the 1980s. The Soviet economy became unsustainable, and communist governments lost the support of intellectuals and their population in general. In 1989, the Soviet Union was dissolved, and communism was abandoned by the countries of Central and Eastern Europe through a series of revolutions.

Military dictatorships remained prominent in Latin America during the Cold War, though the number of coups declined starting in the 1980s. Between 1967 and 1991, 12 Latin American countries underwent at least one military coup, with Haiti and Honduras experiencing three and Bolivia experiencing eight. A one-party communist dictatorship was formed in Cuba when the dictatorship of Fulgencio Batista, weakened by an American arms embargo against his regime, was overthrown in the Cuban Revolution, creating the only Soviet-backed dictatorship in the western hemisphere. To maintain power, Chilean dictator Augusto Pinochet organized Operation Condor with other South American dictators to facilitate cooperation between their respective intelligence agencies and secret police organizations.

The nature of dictatorship changed in much of the world at the onset of the 21st century. Between the 1990s and the 2000s, most dictators moved away from being "larger-than-life figures" that controlled the populace through terror and isolated themselves from the global community. This was replaced by a trend of developing a positive public image to maintain support among the populace and moderating rhetoric to integrate with the global community. In contrast to the overtly repressive nature of 20th century dictatorships, authoritarian strongmen of the 21st century are sometimes labelled "spin dictators", rulers who attempt to monopolise power by authoritarian upgrading, appealing to democratic sentiments and covertly pursue repressive measures; such as embracing modern technology, manipulation of information content, regulation of cyberspace, slandering dissidents, etc. On the other hand, a handful of dictators like Bashar al-Assad and Kim Jong Un rule with deadly repression, violence and state-terrorism to establish extensive securitization through fear, in line with many 20th century dictatorships.

The development of the internet and digital communication in the 21st century have prompted dictatorships to shift from traditional means of control to digital ones, including the use of artificial intelligence to analyze mass communications, internet censorship to restrict the flow of information, and troll farms to manipulate public opinion. 21st century dictatorships regularly hold sham elections with massive approval ratings, for seeking public legitimacy and maintaining the autocrat's image as a popular figure loved by the masses. The manipulated election results are often weaponized as propaganda tools in information warfare, to galvanize supporters of the dictatorships against dissidents as well as to manufacture compliance of the masses by publicising falsified data figures. Another objective is to portray the dictator as the guardian figure who unifies the country, without whom its security disintegrates and chaos ensues. North Korea is the only country in East Asia to be ruled by the Kim family after the death of Kim Il-sung and hands over to his son Kim Jong-il in 1994 and grandson Kim Jong-un in 2011, as of today in the 21st century.

Dictatorship in Europe largely ended after the fall of the Soviet Union in 1991, and the liberalization of most communist states. Belarus under the rule of Alexander Lukashenko has been described as "the last European dictatorship", though the rule of Vladimir Putin in Russia has also been described as a dictatorship. Latin America saw a period of liberalization similar to that of Europe at the end of the Cold War, with Cuba being the only Latin American country that did not experience any degree of liberalization between 1992 and 2010. The countries of Central Asia did not liberalize after the fall of the Soviet Union, instead forming as dictatorships led by former elites of the Communist Party and then later by successive dictators. These countries maintain parliaments and human rights organizations, but these remain under the control of the countries' respective dictators.

The Middle East and Northern Africa did not undergo liberalization during the third wave of democratisation, and most countries in this region remain dictatorships in the 21st century. Dictatorships in the Middle East and Northern Africa are either illiberal republics in which a president holds power through unfair elections, or they are absolute monarchies in which power is inherited. Iraq, Israel, Lebanon, and Palestine are the only democratic nations in the region, with Israel being the only nation in this region that affords broad political liberties to its citizens.

Most dictatorships exist in countries with high levels of poverty. Poverty has a destabilizing effect on government, causing democracy to fail and regimes to fall more often. The form of government does not correlate with the amount of economic growth, and dictatorships on average grow at the same rate as democracies, though dictatorships have been found to have larger fluctuations. Dictators are more likely to implement long-term investments into the country's economy if they feel secure in their power. Exceptions to the pattern of poverty in dictatorships include oil-rich Middle Eastern dictatorships and the East Asian Tigers during their periods of dictatorship.

The type of economy in a dictatorship can affect how it functions. Economies based on natural resources allow dictators more power, as they can easily extract rents without strengthening or cooperating with other institutions. More complex economies require additional cooperation between the dictator and other groups. The economic focus of a dictatorship often depends on the strength of the opposition, as a weaker opposition allows a dictator to extract additional wealth from the economy through corruption.

Several factors determine the stability of a dictatorship, and they must maintain some degree of popular support to prevent resistance groups from growing. This may be ensured through incentives, such as distribution of financial resources or promises of security, or it may be through repression, in which failing to support the regime is punished. Stability can be weakened when opposition groups grow and unify or when elites are not loyal to the regime. One-party dictatorships are generally more stable and last longer than military or personalist dictatorships.

A dictatorship may fall because of a military coup, foreign intervention, negotiation, or popular revolution. A military coup is often carried out when a regime is threatening the country's stability or during periods of societal unrest. Foreign intervention takes place when another country seeks to topple a regime by invading the country or supporting the opposition. A dictator may negotiate the end of a regime if it has lost legitimacy or if a violent removal seems likely. Revolution takes place when the opposition group grows large enough that elites in the regime cannot suppress it or choose not to. Negotiated removals are more likely to end in democracy, while removals by force are more likely to result in a new dictatorial regime. A dictator that has concentrated significant power is more likely to be exiled, imprisoned, or killed after ouster, and accordingly they are more likely to refuse negotiation and cling to power.

Dictatorships are typically more aggressive than democracy when in conflict with other nations, as dictators do not have to fear electoral costs of war. Military dictatorships are more prone to conflict due to the inherent military strength associated with such a regime, and personalist dictatorships are more prone to conflict due to the weaker institutions to check the dictator's power. In the 21st century, dictatorships have moved toward greater integration with the global community and increasingly attempt to present themselves as democratic. Dictatorships are often recipients of foreign aid on the condition that they make advances toward democratization. A study found that dictatorships that engage in oil drilling are more likely to remain in power, with 70.63% of the dictators who engage in oil drilling still being in power after five years of dictatorship, while only 59.92% of the non-oil producing dictators survive the first five years.

Most dictatorships hold elections to maintain legitimacy and stability, but these elections are typically uncompetitive and the opposition is not permitted to win. Elections allow a dictatorship to exercise some control over the opposition by setting the terms under which the opposition challenges the regime. Elections are also used to control elites within the dictatorship by requiring them to compete with one another and incentivizing them to build support with the populace, allowing the most popular and most competent elites to be promoted in the regime. Elections also support the legitimacy of a dictatorship by presenting the image of a democracy, establishing plausible deniability of its status as a dictatorship for both the populace and foreign governments. Should a dictatorship fail, elections also permit dictators and elites to accept defeat without fearing violent recourse. Dictatorships may influence the results of an election through electoral fraud, intimidation or bribing of candidates and voters, use of state resources such as media control, manipulation of electoral laws, restricting who may run as a candidate, or disenfranchising demographics that may oppose the dictatorship.

In the 20th century, most dictatorships held elections in which voters could only choose to support the dictatorship, with only one-quarter of partisan dictatorships permitting opposition candidates to participate. Since the end of the Cold War, more dictatorships have established "semi-competitive" elections in which opposition is allowed to participate in elections but is not allowed to win, with approximately two-thirds of dictatorships permitting opposition candidates in 2018. Opposition parties in dictatorships may be restricted by preventing them from campaigning, banning more popular opposition parties, preventing opposition members from forming a party, or requiring that candidates be a member of the ruling party. Dictatorships may hold semi-competitive elections to qualify for foreign aid, to demonstrate a dictator's control over the government, or to incentivize the party to expand its information-gathering capacity, particularly at the local level. Semi-competitive elections also have the effect of incentivizing members of the ruling party to provide better treatment of citizens so they will be chosen as party nominees due to their popularity.

In a dictatorship, violence is used to coerce or repress all opposition to the dictator's rule, and the strength of a dictatorship depends on its use of violence. This violence is frequently exercised through institutions such as military or police forces. The use of violence by a dictator is frequently most severe during the first few years of a dictatorship, because the regime has not yet solidified its rule and more detailed information for targeted coercion is not yet available. As the dictatorship becomes more established, it moves away from violence by resorting to the use of other coercive measures, such as restricting people's access to information and tracking the political opposition. Dictators are incentivized to avoid the use of violence once a reputation of violence is established, as it damages the dictatorship's other institutions and poses a threat to the dictator's rule should government forces become disloyal.

Institutions that coerce the opposition through the use of violence may serve different roles or they may be used to counterbalance one another in order to prevent one institution from becoming too powerful. Secret police are used to gather information about specific political opponents and carry out targeted acts of violence against them, paramilitary forces defend the regime from coups, and formal militaries defend the dictatorship during foreign invasions and major civil conflicts.

Terrorism is less common in dictatorships. Allowing the opposition to have representation in the regime, such as through a legislature, further reduces the likelihood of terrorist attacks in a dictatorship. Military and one-party dictatorships are more likely to experience terrorism than personalist dictatorships, as these regimes are under more pressure to undergo institutional change in response to terrorism.



Django Reinhardt

Jean Reinhardt (23 January 1910 – 16 May 1953), known by his Romani nickname Django ( or ), was a Romani-Belgian jazz guitarist and composer. He was one of the first major jazz talents to emerge in Europe and has been hailed as one of its most significant exponents.

With violinist Stéphane Grappelli, Reinhardt formed the Paris-based Quintette du Hot Club de France in 1934. The group was among the first to play jazz that featured the guitar as a lead instrument. Reinhardt recorded in France with many visiting American musicians, including Coleman Hawkins and Benny Carter, and briefly toured the United States with Duke Ellington's orchestra in 1946. He died suddenly of a stroke in 1953 at the age of 43.

Reinhardt's most popular compositions have become standards within gypsy jazz, including "Minor Swing", "Daphne", "Belleville", "Djangology", "Swing '42", and "Nuages". Jazz guitarist Frank Vignola says that nearly every major popular-music guitarist in the world has been influenced by Reinhardt. Over the last few decades, annual Django festivals have been held throughout Europe and the U.S., and a biography has been written about his life. In February 2017, the Berlin International Film Festival held the world premiere of the French film "Django".

Reinhardt was born on 23 January 1910 in Liberchies, Pont-à-Celles, Belgium, into a French/Belgian family of Manouche Romani descent. His French, Alsacian father, Jean Eugene Weiss, domiciled in Paris with his wife, went by Jean-Baptiste Reinhardt, his wife's surname, to avoid French military conscription. His mother, Laurence Reinhardt, was a dancer. The birth certificate refers to "Jean Reinhart, son of Jean Baptiste Reinhart, artist, and Laurence Reinhart, housewife, domiciled in Paris".

A number of authors have repeated the claim that Reinhardt's nickname, Django, is Romani for "I awake"; however, it may also simply have been a diminutive, or local Walloon version, of "Jean". Reinhardt spent most of his youth in Romani encampments close to Paris, where he started playing the violin, banjo and guitar. He became adept at stealing chickens. His father reportedly played music in a family band comprising himself and seven brothers; a surviving photograph shows this band including his father on piano.

Reinhardt was attracted to music at an early age, first playing the violin. At the age of 12, he received a banjo-guitar as a gift. He quickly taught himself to play, mimicking the fingerings of musicians he watched, who would have included local virtuoso players of the day such as Jean "Poulette" Castro and Auguste "Gusti" Malha, as well as from his uncle Guiligou, who played violin, banjo and guitar. Reinhardt was able to make a living playing music by the time he was 15, busking in cafés, often with his brother Joseph. At this time, he had not started playing jazz, although he had probably heard and had been intrigued by the version of jazz played by American expatriate bands like Billy Arnold's.

He received little formal education and acquired the rudiments of literacy only in adult life.

At the age of 17, Reinhardt married Florine "Bella" Mayer, a girl from the same Romani settlement, according to Romani custom (although not an official marriage under French law). The following year he recorded for the first time. On these recordings, made in 1928, Reinhardt plays the "banjo" (actually the banjo-guitar) accompanying the accordionists Maurice Alexander, Jean Vaissade and Victor Marceau, and the singer Maurice Chaumel. His name was now drawing international attention, such as from British bandleader Jack Hylton, who came to France just to hear him play. Hylton offered him a job on the spot, and Reinhardt accepted.

Before he had a chance to start with the band, however, Reinhardt nearly died. On the night of 2 November 1928, Reinhardt was going to bed in the wagon that he and his wife shared in the caravan. He knocked over a candle, which ignited the extremely flammable celluloid that his wife used to make artificial flowers. The wagon was quickly engulfed in flames. The couple escaped, but Reinhardt suffered extensive burns over half his body. During his 18-month hospitalization, doctors recommended amputation of his badly damaged right leg. Reinhardt refused the surgery and was eventually able to walk with the aid of a cane.

More crucial to his music, the fourth finger (ring finger) and fifth finger (little) of Reinhardt's left hand were badly burned. Doctors believed that he would never play guitar again. During many months of recuperation, Reinhardt taught himself to play again using primarily the index and third fingers of his left hand by making use of a new six-string steel-strung acoustic guitar that was bought for him by his brother, Joseph Reinhardt, who was also an accomplished guitarist. While he never regained the use of those two fingers, Reinhardt regained his musical mastery by focusing on his left index and middle fingers, using the two injured fingers only for chord work.

Within a year of the fire, in 1929, Bella Mayer gave birth to their son, Henri "Lousson" Reinhardt. Soon thereafter, the couple split up. The son eventually took the surname of his mother's new husband. As Lousson Baumgartner, the son himself became an accomplished musician who went on to record with his biological father.

After parting from his wife and son, Reinhardt traveled throughout France, getting occasional jobs playing music at small clubs. He had no specific goals, living a hand-to-mouth existence, spending his earnings as quickly as he made them. Accompanying him on his travels was his new girlfriend, Sophie Ziegler. Nicknamed "Naguine," she was a distant cousin.

In the years after the fire, Reinhardt was rehabilitating and experimenting on the guitar that his brother had given him. After having played a broad spectrum of music, he was introduced to American jazz by an acquaintance, Émile Savitry, whose record collection included such musical luminaries as Louis Armstrong, Duke Ellington, Joe Venuti, Eddie Lang, and Lonnie Johnson. (The swinging sound of Venuti's jazz violin and Eddie Lang's virtuoso guitar-playing anticipated the more famous sound of Reinhardt and Grappelli's later ensemble.) Hearing their music triggered in Reinhardt a vision and goal of becoming a jazz professional.

While developing his interest in jazz, Reinhardt met Stéphane Grappelli, a young violinist with similar musical interests. In 1928, Grappelli had been a member of the orchestra at the Ambassador Hotel while bandleader Paul Whiteman and Joe Venuti were performing there. In early 1934 both Reinhardt and Grappelli were members of Louis Vola's band.

From 1934 until the outbreak of World War II in 1939, Reinhardt and Grappelli worked together as the principal soloists of their newly formed quintet, the Quintette du Hot Club de France, in Paris. It became the most accomplished and innovative European jazz group of the period.

Reinhardt's brother Joseph and Roger Chaput also played on guitar, and Louis Vola was on bass. The Quintette was one of the few well-known jazz ensembles composed only of stringed instruments.

In Paris on 14 March 1933, Reinhardt recorded two takes each of "Parce que je vous aime" and "Si, j'aime Suzy", vocal numbers with lots of guitar fills and guitar support. He used three guitarists along with an accordion lead, violin, and bass. In August 1934, he made other recordings with more than one guitar (Joseph Reinhardt, Roger Chaput, and Reinhardt), including the first recording by the Quintette. In both years the great majority of their recordings featured a wide variety of horns, often in multiples, piano, and other instruments, but the all-string instrumentation is the one most often adopted by emulators of the Hot Club sound.

Decca Records in the United States released three records of Quintette tunes with Reinhardt on guitar, and one other, credited to "Stephane Grappelli & His Hot 4 with Django Reinhardt", in 1935.

Reinhardt also played and recorded with many American jazz musicians, such as Adelaide Hall, Coleman Hawkins, Benny Carter, and Rex Stewart (who later stayed in Paris). He participated in a jam session and radio performance with Louis Armstrong. Later in his career, Reinhardt played with Dizzy Gillespie in France. Also in the neighborhood was the artistic salon R-26, at which Reinhardt and Grappelli performed regularly as they developed their unique musical style.

In 1938, Reinhardt's quintet played to thousands at an all-star show held in London's Kilburn State auditorium. While playing, he noticed American film actor Eddie Cantor in the front row. When their set ended, Cantor rose to his feet, then went up on stage and kissed Reinhardt's hand, paying no concern to the audience. A few weeks later the quintet played at the London Palladium.

When World War II broke out, the original quintet was on tour in the United Kingdom. Reinhardt returned to Paris at once, leaving his wife in the UK. Grappelli remained in the United Kingdom for the duration of the war. Reinhardt re-formed the quintet, with Hubert Rostaing on clarinet replacing Grappelli.

While he tried to continue with his music, war with the Nazis presented Reinhardt with a potentially catastrophic obstacle, as he was a Romani jazz musician. Beginning in 1933, all German Romani were barred from living in cities, herded into settlement camps, and routinely sterilized. Romani men were required to wear a brown Gypsy ID triangle sewn on their chest, similar to the pink triangle that homosexuals wore, and much like the yellow Star of David that Jews had to subsequently wear. During the war, Romani were systematically killed in concentration camps. In France, they were used as slave labour on farms and in factories. During the Holocaust an estimated 600,000 to 1.5 million Romani throughout Europe were killed.

Hitler and Joseph Goebbels viewed jazz as un-German counterculture. Nonetheless, Goebbels stopped short of a complete ban on jazz, which now had many fans in Germany and elsewhere. Official policy towards jazz was much less strict in occupied France, according to author Andy Fry, with jazz music frequently played on both Radio France, the official station of Vichy France, and Radio Paris, which was controlled by the Germans. A new generation of French jazz enthusiasts, the Zazous, had arisen and swollen the ranks of the Hot Club. In addition to the increased interest, many American musicians based in Paris during the thirties had returned to the US at the beginning of the war, leaving more work for French musicians. Reinhardt was the most famous jazz musician in Europe at the time, working steadily during the early war years and earning a great deal of money, yet always under threat.

Reinhardt expanded his musical horizons during this period. Using an early amplification system, he was able to work in more of a big-band format, in large ensembles with horn sections. He also experimented with classical composition, writing a Mass for the Gypsies and a symphony. Since he did not read music, Reinhardt worked with an assistant to notate what he was improvising. His modernist piece "Rythme Futur" was also intended to be acceptable to the Nazis.

In 1943, Reinhardt married his long-term partner Sophie "Naguine" Ziegler in Salbris. They had a son, Babik Reinhardt, who became a respected guitarist.

In 1943 the tide of war turned against the Germans, with a considerable darkening of the situation in Paris. Severe rationing was in place, and members of Reinhardt's circle were being captured by the Nazis or joining the resistance.

Reinhardt's first attempt at escape from Occupied France led to capture. Fortunately for him, a jazz-loving German, Luftwaffe officer , allowed him to return to Paris. Reinhardt made a second attempt a few days later, but was stopped in the middle of the night by Swiss border guards, who forced him to return to Paris again.

One of his tunes, 1940's "Nuages", became an unofficial anthem in Paris to signify hope for liberation. During a concert at the Salle Pleyel, the popularity of the tune was such that the crowd made him replay it three times in a row. The single sold over 100,000 copies.

Unlike the estimated 600,000 Romani people who were interned and killed in the Porajmos, the Romani Holocaust, Reinhardt survived the war.

After the war, Reinhardt rejoined Grappelli in the UK. In the autumn of 1946, he made his first tour in the United States, debuting at Cleveland Music Hall as a special guest soloist with Duke Ellington and His Orchestra. He played with many musicians and composers, such as Maury Deutsch. At the end of the tour, Reinhardt played two nights at Carnegie Hall in New York City; he received a great ovation and took six curtain calls on the first night.

Despite his pride in touring with Ellington (one of two letters to Grappelli relates his excitement), he was not fully integrated into the band. He played a few tunes at the end of the show, backed by Ellington, with no special arrangements written for him. After the tour, Reinhardt secured an engagement at Café Society Uptown, where he played four solos a day, backed by the resident band. These performances drew large audiences. Having failed to bring his usual Selmer Modèle Jazz, he played on a borrowed electric guitar, which he felt hampered the delicacy of his style. He had been promised jobs in California, but they failed to develop. Tired of waiting, Reinhardt returned to France in February 1947.

After his return, Reinhardt appeared to find it difficult to adjust. He sometimes showed up for scheduled concerts without a guitar or amplifier, or wandered off to the park or beach. On a few occasions he refused to get out of bed. Reinhardt developed a reputation among his band, fans, and managers as extremely unreliable. He skipped sold-out concerts to "walk to the beach" or "smell the dew." During this period he continued to attend the R-26 artistic salon in Montmartre, improvising with his devoted collaborator, Stéphane Grappelli.

In Rome in 1949, Reinhardt recruited three Italian jazz players (on bass, piano, and snare drum) and recorded over 60 tunes in an Italian studio. He united with Grappelli, and used his acoustic Selmer-Maccaferri. The recording was issued for the first time in the late 1950s.

Back in Paris, in June 1950, Reinhardt was invited to join an entourage to welcome the return of Benny Goodman. He also attended a reception for Goodman, who, after the war ended, had asked Reinhardt to join him in the U.S. Goodman repeated his invitation and, out of politeness, Reinhardt accepted. However, Reinhardt later had second thoughts about what role he could play alongside Goodman, who was the "King of Swing", and remained in France.

In 1951, Reinhardt retired to Samois-sur-Seine, near Fontainebleau, where he lived until his death. He continued to play in Paris jazz clubs and began playing electric guitar. (He often used a Selmer fitted with an electric pickup, despite his initial hesitation about the instrument.) In his final recordings, made with his Nouvelle Quintette in the last few months of his life, he had begun moving in a new musical direction, in which he assimilated the vocabulary of bebop and fused it with his own melodic style.

On 16 May 1953, while walking home from Fontainebleau–Avon station after playing in a Paris club, he collapsed outside his house from a brain hemorrhage.
It was a Saturday, and it took a full day for a doctor to arrive. Reinhardt was declared dead on arrival at the hospital in Fontainebleau, at the age of 43.

Reinhardt developed his initial musical approach via tutoring by relatives and exposure to other gypsy guitar players of the day, then playing the banjo-guitar alongside accordionists in the world of the Paris . He played mainly with a plectrum for maximum volume and attack (particularly in the 1920s-early 30s when amplification in venues was minimal or non-existent), although he could also play fingerstyle on occasion, as evidenced by some recorded introductions and solos. Following his accident in 1928 in which his left hand was severely burned, he was left with the use of only his first two fingers. As a result, he developed a completely new left hand technique and started performing on guitar accompanying popular singers of the day, before discovering jazz and presenting his new hybrid style of gypsy approach plus jazz to the outside world via the Quintette du Hot Club de France.

Despite his left hand handicap, Reinhardt was able to recapture (in modified form) and then surpass his previous level of proficiency on the guitar (by now his main instrument), not only as a lead instrumental voice but also as a driving and harmonically interesting rhythm player; his virtuosity, incorporating many gypsy-derived influences, was also matched with a superb sense of melodic invention as well as general musicality in terms of choice of notes, timing, dynamics, and utilizing the maximum tonal range from an instrument previously thought of by many critics as potentially limited in expression. Playing completely by ear (he could neither read nor write music), he roamed freely across the full range of the fretboard giving full flight to his musical imagination and could play with ease in any key. Guitarists, particularly in Britain and the United States, could scarcely believe what they heard on the records that the Quintette was making; guitarist, gypsy jazz enthusiast and educator Ian Cruickshank writes:
Because of his damaged left hand (his ring and pinky fingers helped little in his playing) Reinhardt had to modify both his chordal and melodic approach extensively. For chords he developed a novel system based largely around 3-note chords, each of which could serve as the equivalent of several conventional chords in different inversions; for the treble notes he could employ his ring and little fingers to fret the relevant high strings even though he could not articulate these fingers independently, while in some chords he also employed his left hand thumb on the lowest string. Within his rapid melodic runs he frequently incorporated arpeggios, which could be played using two notes per string (played with his two "good" fingers, being his index and middle fingers) while shifting up or down the fingerboard, as opposed to the more conventional "box" approach of moving across strings within a single fretboard position (location). He also produced some of his characteristic "effects" by moving a fixed shape (such as a diminished chord) rapidly up and down the fretboard, resulting in what one writer has called "intervallic cycling of melodic motifs and chords". For an unsurpassed insight into these techniques in use, interested persons should not miss viewing the only known synchronised (sound and vision) footage of Reinhardt in performance, playing on an instrumental version of the song "J'Attendrai" for the short jazz film "Le Jazz Hot" in 1938–39 (copies available on YouTube and elsewhere).

Hugues Panassié, in his 1942 book "The Real Jazz", wrote:
Writing in 1945, Billy Neil and E. Gates stated that
Django-style enthusiast John Jorgenson has been quoted as saying:
In his later style ( onwards) Reinhardt began to incorporate more bebop influences in his compositions and improvisations, also fitting a Stimer electric pickup to his acoustic guitar. With the addition of amplification, his playing became more linear and "horn like", with the greater facility of the amplified instrument for longer sustain and to be heard in quiet passages, and in general less reliance on his gypsy "bag of tricks" as developed for his acoustic guitar style (also, in some of his late recordings, with a very different supporting group context from his "classic", pre-war Quintette sound). These "electric period" Reinhardt recordings have in general received less popular re-release and critical analysis than his pre-war releases (the latter also extending to the period from 1940 to 1945 when Grappelli was absent, which included some of his most famous compositions such as "Nuages"), but are also a fascinating area of Reinhardt's work to study, and have begun to be revived by players such as the Rosenberg Trio (with their 2010 release "Djangologists") and Biréli Lagrène. Wayne Jefferies, in his article "Django's Forgotten Era", writes:
Reinhardt's first son, Lousson (a.k.a. Henri Baumgartner), played jazz in a mostly bebop style in the 1950s and 1960s. He followed the Romani lifestyle and was relatively little recorded. Reinhardt's second son, Babik, became a guitarist in a more contemporary jazz style, and recorded a number of albums before his death in 2001. After Reinhardt died, his younger brother Joseph at first swore to abandon music, but he was persuaded to perform and record again. Joseph's son Markus Reinhardt is a violinist in the Romani style.

A third generation of direct descendants has developed as musicians: David Reinhardt, Reinhardt's grandson (by his son Babik), leads his own trio. Dallas Baumgartner, a great-grandson by Lousson, is a guitarist who travels with the Romani and keeps a low public profile. A distant relative, violinist Schnuckenack Reinhardt, became known in Germany as a performer of gypsy music and gypsy jazz up to his death in 2006, and assisted in keeping Reinhardt's legacy alive through the period following Django's death.

Reinhardt is regarded as one of the greatest guitar players of all time, and the first important European jazz musician to make a major contribution with jazz guitar. During his career he wrote nearly 100 songs, according to jazz guitarist Frank Vignola.

Using a Selmer guitar in the mid-1930s, his style took on new volume and expressiveness. Because of his physical disability, he played mainly using his index and middle fingers, and invented a distinctive style of jazz guitar.

For about a decade after Reinhardt's death, interest in his musical style was minimal. In the fifties, bebop superseded swing in jazz, rock and roll took off, and electric instruments became dominant in popular music. Since the mid-sixties, there has been a revival of interest in Reinhardt's music, a revival that has extended into the 21st century, with annual festivals and periodic tribute concerts. His devotees included classical guitarist Julian Bream and country guitarist Chet Atkins, who considered him one of the ten greatest guitarists of the twentieth century.

Jazz guitarists in the U.S., such as Charlie Byrd and Wes Montgomery, were influenced by his style. In fact, Byrd, who lived from 1925 to 1999, said that Reinhardt was his primary influence. Guitarist Mike Peters notes that "the word 'genius' is bantered about too much. But in jazz, Louis Armstrong was a genius, Duke Ellington was another one, and Reinhardt was also." David Grisman adds, "As far as I'm concerned, no one since has come anywhere close to Django Reinhardt as an improviser or technician."

The popularity of gypsy jazz has generated an increasing number of festivals, such as the Festival Django Reinhardt held every last weekend of June since 1983 in Samois-sur-Seine (France), and since 2017 in nearby Fontainebleau; the various DjangoFests held throughout Europe and the US; and "Django in June", an annual camp for Gypsy jazz musicians and aficionados held at Smith College in Massachusetts.

Woody Allen's film "Sweet and Lowdown" (1999), the story of a Django Reinhardt-like character, mentions Reinhardt and includes actual recordings in the film.

In February 2017, the Berlin International Film Festival held the world premiere of "Django", a French film directed by Etienne Comar. The movie covers Django's escape from Nazi-occupied Paris in 1943 and the fact that even under "constant danger, flight and the atrocities committed against his family", he continued composing and performing. Reinhardt's music was re-recorded for the film by the Dutch jazz band Rosenberg Trio with lead guitarist Stochelo Rosenberg.

The documentary film, "Djangomania!" was released in 2005. The hour-long film was directed and written by Jamie Kastner, who traveled throughout the world to show the influence of Django's music in various countries.

In 1984 the Kool Jazz Festival, held in Carnegie Hall and Avery Fisher Hall, was dedicated entirely to Reinhardt. Performers included Grappelli, Benny Carter, and Mike Peters with his group of seven musicians. The festival was organized by George Wein. Reinhardt is celebrated annually in the village of Liberchies, his birthplace.

Numerous musicians have written and recorded tributes to Reinhardt. The jazz standard "Django" (1954) was composed by John Lewis of the Modern Jazz Quartet in honour of Reinhardt. The Allman Brothers Band song "Jessica" was written by Dickey Betts in tribute to Reinhardt. American country music artists Willie Nelson and Merle Haggard named their sixth and final collaborative studio album "Django and Jimmie". It was released on 2 June 2015, by Legacy Recordings. The album contains the song "Django and Jimmie" which is a tribute to musicians Django Reinhardt and Jimmie Rodgers.

Ramelton, Co. Donegal, Ireland, each year hosts a festival in tribute to Django called "Django sur Lennon" or "Django on the Lennon" the Lennon being the name of the local river that runs through the village.

In coincidence with the 110th anniversary in 2020 of Django's birth, a graphic novel depicting his youth years was published under the title "Django Main de Feu", by writer Salva Rubio and artist Efa through Belgian publisher Dupuis.

On 23 January 2010, Google Doodle celebrated Django Reinhard’s 100th Birthday.

Many guitar players and other musicians have expressed admiration for Reinhardt or have cited him as a major influence. Jeff Beck described Reinhardt as "by far the most astonishing guitar player ever" and "quite superhuman".

Grateful Dead's Jerry Garcia and Black Sabbath's Tony Iommi, both of whom lost fingers in accidents, were inspired by Reinhardt's example of becoming an accomplished guitar player despite his injuries. Garcia was quoted in June 1985 in "Frets Magazine":

Denny Laine and Jimmy McCulloch, members of Paul McCartney's band Wings, have mentioned him as an inspiration.

Andrew Latimer, of the band Camel, has stated that he was influenced by Reinhardt.

Willie Nelson has been a lifelong Reinhardt fan, stating in his memoir, "This was a man who changed my musical life by giving me a whole new perspective on the guitar and, on an even more profound level, on my relationship with sound...During my formative years, as I listened to Django's records, especially songs like 'Nuages' that I would play for the rest of my life, I studied his technique. Even more, I studied his gentleness. I love the human sound he gave his acoustic guitar."

Jimmy Page of Led Zeppelin: "Django Reinhardt was fantastic. He must have been playing all the time to be that good."


Reinhardt recorded over 900 sides in his recording career, from 1928 to 1953, the majority as sides of the then-prevalent 78-RPM records, with the remainder as acetates, transcription discs, private and off-air recordings (of radio broadcasts), and part of a film soundtrack. Only one session (eight tracks) from March 1953 was ever recorded specifically for album release by Norman Granz in the then-new LP format, but Reinhardt died before the album could be released. In his earliest recordings Reinhardt played banjo (or, more accurately, banjo-guitar) accompanying accordionists and singers on dances and popular tunes of the day, with no jazz content, whereas in the last recordings before his death he played amplified guitar in the bebop idiom with a pool of younger, more modern French musicians.

A full chronological listing of his lifetime recorded output is available from the source cited here, and an index of individual tunes is available from the source cited here. A few fragments of film performance (without original sound) also survive, as does one complete performance with sound, of the tune "J'Attendrai" performed with the Quintet in 1938 for the short film "Le Jazz Hot".

Since his death, Reinhardt's music has been released on many compilations. "Intégrale Django Reinhardt", volumes 1–20 (40 CDs), released by the French company Frémeaux from 2002 to 2005, tried to include every known track on which he played.



A small number of waltzes composed by Reinhardt in his youth were never recorded by the composer, but were retained in the repertoire of his associates and several are still played today. They came to light via recordings by Matelo Ferret in 1960 (the waltzes "Montagne Sainte-Genevieve", "Gagoug", "Chez Jacquet" and "Choti"; Disques Vogue (F)EPL7740) and 1961 ("Djalamichto" and "En Verdine"; Disques Vogue (F)EPL7829). The first four are now available on Matelo's CD "Tziganskaïa and Other Rare Recordings", released by Hot Club Records (subsequently reissued as "Tziganskaïa: The Django Reinhardt Waltzes"); "Chez Jacquet" was also recorded by Baro Ferret in 1966.

The names "Gagoug" and "Choti" were reportedly conferred by Reinhardt's widow Naguine on request from Matelo, who had learned the tunes without names. Reinhardt also worked on composing a Mass for use by the gypsies, which was not completed although an 8-minute extract exists, played by the organist Léo Chauliac for Reinhardt's benefit, via a 1944 radio broadcast; this can be found on the CD release "Gipsy Jazz School" and also on volume 12 of the "Intégrale Django Reinhardt" CD compilation.



Dana Plato

Dana Michelle Plato (née Strain; November 7, 1964 – May 8, 1999) was an American actress. An influential teen idol of the late 1970s and early 1980s, she was best known for playing the role of Kimberly Drummond on the NBC/ABC sitcom "Diff'rent Strokes" (1978–1986).

Plato was born to a teen mother and was adopted as an infant. She was raised in the San Fernando Valley and was an accomplished figure skater before acting. Her acting career began with numerous commercial appearances, and her television debut came at the age of 10 with a brief appearance on the television series "The Six Million Dollar Man" (1975). Plato subsequently appeared in the horror films "" (1977) and "Return to Boggy Creek" (1977).

Plato's breakthrough feature was the Academy Award–winning film "California Suite" (1978), in which she played Jenny Warren. She earned widespread recognition and acclaim for playing Kimberly Drummond on "Diff'rent Strokes". The role also earned Plato nominations for a Young Artist Award for Best Young Actress in a Comedy Series and two TV Land Awards for Best Quintessential Non-Traditional Family. Following "Diff'rent Strokes", she worked sporadically in independent films and B movies. Plato was married twice; she had a child in 1984 during her marriage to guitarist Lanny Lambert.

Plato struggled with substance abuse for most of her life. She was arrested in 1991 for robbing a video store, and again the following year for forging a drug prescription. On May 8, 1999, at age 34, Plato was found dead in her motor home from an overdose of prescription drugs. Her death was initially considered accidental, but later ruled a suicide. Her personal life, in retrospect, has been described as a "tragedy".

Dana Plato was born Dana Michelle Strain on November 7, 1964, in Maywood, California, to Linda Strain, a teenager who was already caring for an 18-month-old child. In June 1965, the seven-month-old Dana was adopted by Dean Plato, who owned a trucking company, and his wife Florine "Kay" Plato. She was raised in the San Fernando Valley. When she was three, her adoptive parents divorced and she lived with her mother.

At a very young age, Plato began attending auditions with her mother, and by seven years old had appeared in over 100 television commercials. Plato was also an accomplished figure skater. During her years on "Diff'rent Strokes", Plato struggled with drug and alcohol problems; she admitted to drinking alcohol, using cannabis and cocaine, and suffering an overdose of diazepam when she was aged 14.

In 1995, during an appearance on "The Marilyn Kagen Show" alongside co-star Todd Bridges, she spoke of her childhood with her mother, stating: "My mother made sure that I was normal. The only thing that she did, the mistake she made, was that she kept me in a plastic bubble. So, I didn't learn about reality and life skills." Kagen suggested that Plato may have been used for a free meal ticket, which Plato denied, explaining that her mother's ways were so that she would not become a prima donna.

Plato made her television acting debut at the age of 10, making a brief appearance on the ABC television show "The Six Million Dollar Man". She then starred in the 1975 made-for-television film "Beyond the Bermuda Triangle". Plato made her film debut at the age of 13 in the uncredited role of Sandra Phalor in the horror film "" (1977). She starred as Evie Joe in the horror film "Return to Boggy Creek" in the same year. both films were received negatively by critics. Better received was the family-comedy film "California Suite" (1978), in which Plato played Jenny Warren; the film was also a commercial success, and earned accolades from the Academy Awards and the Golden Globe Awards. 
When Plato made a brief appearance on "The Gong Show", she was spotted by a producer who helped cast her as Kimberly Drummond, the older sister of adopted brothers Arnold and Willis Jackson, on the NBC sitcom "Diff'rent Strokes". The series debuted in 1978 and became an immediate hit. Plato appeared regularly on the show throughout its run, notably top-billed for four years. She was nominated for a Young Artist Award for her work on the program, and also was part of two TV Land Award nominations given to its cast. In 1984, following the birth of her son Tyler, Plato was dismissed from her starring role due to both her pregnancy and struggles in her personal life, which producers felt would negatively impact their "wholesome family comedy". She made a one episode appearance on season 8 episode 12 of "The Love Boat". Thereafter, Plato appeared recurringly on "Diff'rent Strokes" from 1985 to 1986, the show's end; in season 8, the episode which aired on January 17, 1986, was Plato's final appearance on the show, which showed her character suffering from bulimia. CBC News described her performance in the episode as a "series highpoint".

In 1981, Plato appeared in the television special "A Step in Time", which earned her a second Young Artist Award nomination. In 1983, she starred in the television film "High School U.S.A." as Cara Ames, alongside "Diff'rent Strokes" co-star Todd Bridges, who played Otto Lipton. In spite of the film being met with a mixed response from critics and viewers alike, it gained popularity at the time of its premiere, particularly for its cast. Plato attempted to establish herself as a serious actress, but found it difficult to achieve success. She had breast implants and modeled for a June 1989 "Playboy" pictorial. She also started taking roles in such B movies as "Bikini Beach Race" (1989) and "Lethal Cowboy" (1992). In 1990 she made a brief attempt at a musical career, sponsored by producer Howie Rice. She recorded six tracks with songwriter/producer Daniel Liston Keller at Paramount Studios in Hollywood, California, but the recordings were shelved and not released.

In 1992, Plato starred in the video game "Night Trap", becoming one of the first celebrities to appear in a video game. She was eager to work on the project, and Rob Fulop, one of the designers of "Night Trap", said that he and Plato had enjoyed working together. She made little effort to hide the fact that the project was a step-down compared to her previous career ventures. The game was a moderate success, and is considered a pioneering title because it was the first to use live actors. "Night Trap" received mixed to negative reviews upon release, and in retrospective has continued to polarize critics and audiences. It is best remembered for the controversy it created over the violence and sexuality that, along with that surrounding "Mortal Kombat", eventually led to the creation of the Entertainment Software Rating Board (ESRB).

Toward the end of her career, Plato chose roles that were erotic; she appeared nude in "Prime Suspect" (1989) and "Compelling Evidence" (1995), and in the softcore erotic drama "Different Strokes: The Story of Jack and Jill...and Jill" (1998), the title of which was changed after filming in order to tie it to Plato's past. In the same year, following her appearance in the film, Plato appeared in a cover story of the lesbian lifestyle-magazine "Girlfriends".

Plato's last works include "Desperation Boulevard" (1998), in which she appears as herself and which appears to be based on her life; "Silent Scream" (1999), in which she appears as Emma Jones; and "Pacino Is Missing" (2002), which was released after her death, in which she appears as an attorney.

In December 1983, Plato moved in with her boyfriend, rock guitarist Lanny Lambert. The couple married on April 24, 1984, and their only child, Tyler Edward Lambert, was born on July 2, 1984. When it was revealed that she was pregnant, she was written out of "Diff'rent Strokes". Her co-star Conrad Bain revealed that she was happy about her baby, stating in an interview with "People" magazine: "She deliberately got pregnant while doing the series, when I spoke to her about it, she was enthusiastic about having done that... [saying that] 'When I get the baby, I will never be alone again.'"

Plato separated from Lambert in January 1988, the same week her mother died of scleroderma. In desperation, she signed over power of attorney to an accountant who disappeared with the majority of her money, leaving her with less than $150,000. She claimed the accountant was never found nor prosecuted despite an exhaustive search, and that he had also stolen more than $11 million from other clients. In her March 1990 divorce, Plato lost custody of her son to Lambert and was given visitation rights. She then became engaged to Fred Potts, a filmmaker, but the romance ended. She was later married to actor and producer Scott Atkins (Scotty Gelt) in Vancouver for one month, but the marriage was annulled. Before her death, Plato was engaged to her manager Robert Menchaca, six years her junior, with whom she lived in a motor home in Navarre, Florida.

On February 28, 1991, Plato entered a Las Vegas video store, produced a pellet gun, and demanded the money in the cash register. After she left with the money, the clerk called 9-1-1 and said, "I've just been robbed by the girl who played Kimberly on "Diff'rent Strokes"." Approximately fifteen minutes after the robbery, Plato returned to the scene and was immediately arrested. She had stolen $164. Entertainer Wayne Newton posted her $13,000 bail, and Plato was given five years' probation. She subsequently became a subject of the national debate surrounding troubled child stars, particularly given the difficulties of her "Diff'rent Strokes" co-stars Todd Bridges and Gary Coleman.

In January 1992 Plato was arrested a second time, for forging a prescription for diazepam. She served thirty days in jail for violating the terms of her probation and immediately entered a drug rehabilitation program. Plato later moved to Las Vegas, where she struggled with poverty and unemployment. At one point she worked at a dry-cleaning store, where customers reported being impressed by her lack of airs.

On May 7, 1999, the day before she died, Plato appeared on "The Howard Stern Show". She spoke about her life, discussing her financial problems and past run-ins with the law. She admitted to being a recovering alcoholic and drug addict, but claimed she had been sober for more than ten years and was not using any drugs, with the exception of prescribed painkillers due to the recent extraction of her wisdom teeth. Many callers to the show insulted Plato and questioned her sobriety, which angered and provoked her, and she defiantly offered to take a drug test on the air. Some callers, as well as host Howard Stern, came to Plato's defense, though Stern also referred to himself as "an enabler" and sarcastically offered Plato drugs. Although she allowed a hair to be cut for the test, Stern later claimed she asked for it back after the interview.

On May 8, 1999, Plato and Menchaca were returning to California and stopped at Menchaca's mother's home in Moore, Oklahoma, for a Mother's Day visit. Later on in the visit, Plato said that she felt unwell and took a few doses of a hydrocodone / acetaminophen painkiller (Lortab), along with the muscle-relaxant carisoprodol (Soma), and went to lie down with Menchaca inside her Winnebago motor home, which was parked outside the house. Upon waking up, Menchaca and the family discovered that Plato had died in her sleep. It was initially assumed to be an accidental overdose but was later ruled a suicide based on Plato's long history of substance abuse. Some of Plato's friends, including her former "Diff'rent Strokes" costar Todd Bridges, have publicly disagreed with the ruling. Plato's body was cremated and her ashes were scattered over the Pacific Ocean.

In 2000, Fox broadcast a television movie based on Plato, titled "After Diff'rent Strokes: When the Laughter Stopped". The film was focused on her life and work after the show, including her death. It featured actors who at the time were unknown, as well as Bridges, who made a cameo appearance. In 2006, NBC aired the television film "Behind the Camera: The Unauthorized Story of Diff'rent Strokes", which was based on the lives of the child stars who had worked on the show. Bridges and Coleman appear at the end of the film standing near Plato's grave.

On May 6, 2010, two days before the eleventh anniversary of Plato's death, her son Tyler committed suicide with a gunshot wound to the head. He was 25 years old.

On November 7, 2019, on what would have been Plato's 55th birthday, Bridges commented on Twitter about their friendship, leaving a tribute to Plato: 

Drop kick

A drop kick is a type of kick in various codes of football. It involves a player intentionally dropping the ball and then kicking it either (different sports have different definitions) 'as it rises from the first bounce' (rugby) or 'as, or immediately after, it touches the ground' (gridiron football).

Drop kicks are used as a method of restarting play and scoring points in rugby union and rugby league. Also, association football goalkeepers often return the ball to play with drop kicks. The kick was once in wide use in both Australian rules football and gridiron football, but is rarely used anymore by either sport.

The drop kick technique in rugby codes is usually to hold the ball with one end pointing downwards in two hands above the kicking leg. The ball is dropped onto the ground in front of the kicking foot, which makes contact at the moment or fractionally after the ball touches the ground, called the "half-volley". The kicking foot usually makes contact with the ball slightly on the instep.

In a rugby union kick-off, or drop out, the kicker usually aims to kick the ball high but not a great distance, and so usually strikes the ball after it has started to bounce off the ground, so the contact is made close to the bottom of the ball.

In rugby league, drop kicks are mandatory to restart play from the goal line (called a goal line drop-out) after the defending team is tackled or knocks on in the in-goal area or the defending team causes the ball to go dead or into touch-in-goal. Drop kicks are also mandatory to restart play from the 20 metre line after an unsuccessful penalty goal attempt goes dead or into touch-in-goal and to score a drop goal (sometimes known as a field goal) in open play, which is worth one point.

Drop kicks are optional for a penalty kick to score a penalty goal (this being done rarely, as place kicks are generally used) and when kicking for touch (the sideline) from a penalty, although the option of a punt kick is usually taken instead.

In rugby union, a drop kick is used for the kick-off and restarts and to score a drop goal (sometimes called a field goal). Originally, it was one of only two ways to score points, along with the place kick.

Drop kicks are mandatory from the centre spot to start a half (a kick-off), from the centre spot to restart the game after points have been scored, to restart play from the 22-metre line (called a drop-out) after the ball is touched down or made dead in the in-goal area by the defending team when the attacking team kicked or took the ball into the in-goal area, and to score a drop goal (sometimes called a field goal) in open play, which is worth three points.

Drop kicks are optional for a conversion kick after a try has been scored.

The usage of drop kicks in rugby sevens is the same as in rugby union, except that drop kicks are used for all conversion attempts and for penalty kicks, both of which must be taken within 40 seconds of the try being scored or the award of the penalty.

In both American and Canadian football, one method of scoring a field goal, fair-catch kick (American only), or extra point is by drop-kicking the football through the goal, although the technique is very rarely used in modern play.

It contrasts with the punt, wherein the player kicks the ball without letting it hit the ground first, and the place kick, wherein the player kicks a stationary ball off the ground: "from placement". A drop kick is significantly more difficult; as Jim Thorpe once explained, "I regard the place kick as almost two to one safer than the drop kick in attempting a goal from the field."

The drop kick was often used in early football as a surprise tactic. The ball was snapped or lateraled to a back, who faked a run or pass, then drop-kicked a field goal attempt. This method of scoring worked well in the 1920s and early 1930s, when the ball was rounder at the ends, similar to a modern rugby ball.

Early football stars Thorpe, Charles Brickley, Frank Hudson, Paddy Driscoll, and Al Bloodgood were skilled drop-kickers; Driscoll in and Bloodgood in hold a tied NFL record of four drop kicked field goals in a single game. Driscoll's 55-yard drop kick in stood as the unofficial record for field goal range until Bert Rechichar kicked a 56-yard field goal (by placekick) in .

The ball was made more pointed at the ends in ; its creation is generally credited to Shorty Ray, a college football official at the time, and later the NFL's head of officiating. This made passing the ball easier, as was its intent, but made the drop kick obsolete, as the more pointed ball did not bounce up from the ground reliably. The drop kick was supplanted by the place kick, which cannot be attempted out of a formation generally used as a running or passing set. While it remains in the rules, the drop kick is seldom seen, and as explained below, is rarely effective when attempted.

In Canadian football, there are no formal restrictions on the circumstances under which a drop or a place kick can be attempted.

To date, the only successful drop kick in the NFL since 1941 was by Doug Flutie, the backup quarterback of the New England Patriots, against the Miami Dolphins on January 1, 2006, for an extra point after a touchdown. Flutie had estimated "an 80 percent chance" of making the drop kick, which was called to give Flutie, 43 at the time, the opportunity to make a historic kick in his final NFL game; the drop kick was his last play in the NFL.

The last successful drop kick before 2006 in the NFL was executed 64 years earlier in , on an extra point by Ray McLean of the Chicago Bears, coming late in their 37–9 victory over the New York Giants in the NFL Championship Game at Chicago's Wrigley Field on December 21. It was the final point of the game, with the outcome already decided, and followed a fumble recovery and run for the final touchdown with under two minutes remaining. The last drop kick for a field goal in the NFL was more than four years earlier, a nine-yarder by player-coach Dutch Clark of the Detroit Lions in . It was the initial score in a 16–7 home win over the Chicago Cardinals on September 19. Though it was not part of the NFL at the time, the All-America Football Conference (AAFC) saw its last successful drop kick in 1948, when Joe Vetrano of the San Francisco 49ers drop kicked an extra point after a muffed snap in a 31–28 home loss to the undefeated Cleveland Browns on November 28.

Dallas Cowboys punter Mat McBriar attempted a maneuver similar to a drop kick during the 2010 Thanksgiving Day game after a botched punt attempt, but the ball bounced several times before the kick and the sequence of events is officially recorded as a fumble, followed by an illegal kick, with the fumble being recovered by the New Orleans Saints 29 yards downfield from the spot of the kick. The Saints declined the illegal kick penalty.

Patriots kicker Stephen Gostkowski attempted an onside drop kick on a free kick after a safety against the Pittsburgh Steelers on October 30, ; it went out of bounds.

Saints quarterback Drew Brees, a former teammate of Flutie's, attempted a drop kick on an extra point late in the fourth quarter of the 2012 Pro Bowl, but it fell short. On December 20, , Buffalo Bills punter Colton Schmidt executed what is believed to be an unintentional drop kick after a botched punt against the Washington Redskins; because the Redskins recovered the kick, it was treated as a punt (and not as a field goal attempt, which would have pushed the ball back to the spot of the kick).

Seattle Seahawks punter Michael Dickson drop kicked a kickoff from the 50-yard-line on September 17, , against the Bears. The kick landed inside the five-yard-line and was returned to a spot less far out than a touchback would have been automatically returned to, making it a successful strategy. Dickson made an onside drop kick attempt at the end of the same game, which was unsuccessful (recovered by the Bears). Seahawks head coach Pete Carroll noted that he considered Dickson the team's backup kicker and would kick field goals and extra point attempts with the drop kick should there be an injury to placekicker Sebastian Janikowski. Following an injury to Janikowski, Dickson attempted several drop kickoffs on January 5, 2019, against the Dallas Cowboys, including an onside kick which was received normally as a fair catch.

The drop kick came under controversy in , after Justin Tucker of the Baltimore Ravens used the maneuver on a kickoff late in a game against the Kansas City Chiefs. The drop kick was intended to force the Chiefs to fair catch the ball, preventing them from running out the clock. As 2:01 was showing on the game clock and a fair-caught kickoff does not run any time off the clock, it would force the Chiefs to run a play before the two-minute warning. Several weeks after the kick, league offices claimed the maneuver was illegal. Ravens head coach John Harbaugh disputed this, noting that they had cleared it with the NFL before using the drop kick and were not penalized by the in-game officials. The NFL's statement claimed that the ball was not kicked immediately after the bounce. Tucker made his approach and dropped the ball to the ground. He did not like the bounce and picked the ball up, retreating back for a second approach and dropped the ball a second time before kicking it. The NFL's statement suggested a false start should have been called on Tucker for not kicking the ball on the first drop. An article on CBS Sports stated that the NFL had made a midseason rule change banning the drop kick, but no statement from the NFL has ever confirmed this. It was later clarified that Tucker's drop kick action was illegal because he did not kick the ball "immediately" after the ball touched the ground. Rather, Tucker threw the ball upwards, allowed it to drop to the ground, then kicked the ball as it was falling from its apex after bouncing.

San Francisco 49ers' kicker Robbie Gould attempted an onside drop kick against the Philadelphia Eagles on October 4, ; the recovery was unsuccessful. Five weeks later, the Bears also attempted an unsuccessful onside drop kick against the Tennessee Titans on November 8.

The last successful drop kick extra point in the NCAA was by Jason Millgan of Hartwick College on December 11, 1998, St. Lawrence University. Frosty Peters of Montana State College made 17 drop kicks in one game in 1924.

On December 30, 2023, the Auburn Tigers' punter Oscar Chapman attempted a dropkicked onside kick, which was recovered by the Maryland Terrapins.

In the Canadian game, the drop kick can be attempted at any time by either team. Any player on the kicking team behind the kicker, and including the kicker, can recover the kick. When a drop kick goes out of bounds, possession on the next scrimmage goes to the non-kicking team.

On September 8, 1974, Tom Wilkinson, quarterback for the Edmonton Eskimos, unsuccessfully attempted a drop kick field goal in the final seconds of a 24–2 romp over the Winnipeg Blue Bombers.

In an exhibition game on June 10, 1983, the Toronto Argonauts' quarterback Condredge Holloway had scored a touchdown against Hamilton. There was a bad snap on the convert, and the holder, Jan Carinci, managed to dropkick the ball through the uprights for the one point conversion.

During one game in 1993, Hamilton Tiger-Cats wide receiver Earl Winfield was unable to field a punt properly; in frustration, he kicked the ball out of bounds. The kick was considered a drop kick and led to a change of possession, with the punting team, Winnipeg, regaining possession of the ball.

In the former AFL (North American Arena Football League), a drop-kicked extra point was worth two points, rather than one point, while a drop-kicked field goal counted for four points rather than three. The most recent conversion of a drop kick was by Geoff Boyer of the Pittsburgh Power on June 16, 2012; it was the first successful conversion in the AFL since 1997. In 2018, Maine Mammoths kicker Henry Nell converted a drop kick as a PAT against the Massachusetts Pirates in the National Arena League.

In 2022, Salina Liberty kicker Jimmy Allen successfully converted 3 drop kick PAT attempts against the Topeka Tropics in a Champions Indoor Football game. Jimmy also converted a drop kick PAT playing for the Iowa Barnstormers in the IFL during a game against the Colorado Crush during a 2016 game.

Once the preferred method of conveying the ball over long distances, the drop kick has been superseded by the drop punt as a more accurate means of delivering the ball to a fellow player. Drop kicks were last regularly used in the 1970s, and by that time mostly for kicking in after a behind and very rarely in general play. AFL historian and statistician Col Hutchison believes that Sam Newman was the last player to kick a set-shot goal with a drop kick, in 1980, although goals in general play from a drop kick do occur on rare occasions, including subsequent goals by players such as Alastair Lynch and Darren Bewick. Hutchison says drop kicks were phased out of the game by Norm Smith in defence due to their risky nature; Ron Barassi, a player Smith coached, took this onboard for his own coaching career, banning it for all but Barry Cable, who, according to Hutchison, was a "magnificent disposer of the ball".


Diaeresis

Diaeresis (dieresis, diæresis, diëresis) may refer to:



Derry

Derry, officially Londonderry, is the largest city in County Londonderry, the second-largest in Northern Ireland and the fifth-largest on the island of Ireland. The old walled city lies on the west bank of the River Foyle, which is spanned by two road bridges and one footbridge. The city now covers both banks (Cityside on the west and Waterside on the east).

The population of the city was 85,279 at the 2021 census, while the Derry Urban Area had a population of 105,066 in 2011. The district administered by Derry City and Strabane District Council contains both Londonderry Port and City of Derry Airport. Derry is close to the border with County Donegal, with which it has had a close link for many centuries. The person traditionally seen as the founder of the original Derry is Saint , a holy man from , the old name for almost all of modern County Donegal, of which the west bank of the Foyle was a part before 1610.

In 2013, Derry was the inaugural UK City of Culture, having been awarded the title in 2010.

Despite the official name, the city is also commonly known as "Derry", which is an anglicisation of the Irish or , and translates as 'oak-grove/oak-wood'. The name derives from the settlement's earliest references, ('oak-grove of Calgach'). The name was changed from Derry in 1613 during the Plantation of Ulster to reflect the establishment of the city by the London guilds.

"Derry" has been used in the names of the local government district and council since 1984, when the council changed its name from "Londonderry City Council" to "Derry City Council". This also changed the name of the district, which had been created in 1973 and included both the city and surrounding rural areas. In the 2015 local government reform, the district was merged with the Strabane district to form the Derry City and Strabane district, with the councils likewise merged.

According to the city's Royal Charter of 10 April 1662, the official name is "Londonderry". This was reaffirmed in a High Court decision in 2007.

The 2007 court case arose because Derry City Council wanted clarification on whether the 1984 name change of the council and district had changed the official name of the city and what the procedure would be to effect a name change. The court clarified that Londonderry remained the official name and that the correct procedure to change the name would be via a petition to the Privy Council. Derry City Council afterward began this process, and was involved in conducting an equality impact assessment report (EQIA). Firstly it held an opinion poll of district residents in 2009, which reported that 75% of Catholics and 77% of Nationalists found the proposed change acceptable, compared to 6% of Protestants and 8% of Unionists. The EQIA then held two consultative forums, and solicited comments from the general public on whether or not the city should have its name changed to Derry. A total of 12,136 comments were received, of which 3,108 were broadly in favour of the proposal, and 9,028 opposed it. On 23 July 2015, the council voted in favour of a motion to change the official name of the city to Derry and to write to Mark H. Durkan, the Northern Irish Minister for the Environment, to ask how the change could be effected.

The name "Derry" is preferred by nationalists and it is broadly used throughout Northern Ireland's Catholic community, as well as that of the Republic of Ireland, whereas many unionists prefer "Londonderry"; however, in everyday conversation "Derry" is used by most Protestant residents of the city. Linguist Kevin McCafferty argues that "It is not, strictly speaking, correct that Northern Ireland Catholics call it Derry, while Protestants use the Londonderry form, although this pattern has become more common locally since the mid-1980s, when the city council changed its name by dropping the prefix". In McCafferty's survey of language use in the city, "only very few interviewees—all Protestants—use the official form".

Apart from the name of the local council, the city is usually known as "Londonderry" in official use within the UK. In the Republic of Ireland, the city and county are almost always referred to as "Derry", on maps, in the media and in conversation. In April 2009, however, the Republic of Ireland's Minister for Foreign Affairs, Micheál Martin, announced that Irish passport holders who were born there could record either "Derry" or "Londonderry" as their place of birth. Whereas official road signs in the Republic use the name "Derry", those in Northern Ireland bear "Londonderry" (sometimes abbreviated to "L'derry"), although some of these have been defaced with the reference to London obscured. Usage varies among local organisations, with both names being used. Examples are City of Derry Airport, City of Derry Rugby Club, Derry City FC and the Protestant Apprentice Boys of Derry, as opposed to Londonderry Port, Londonderry YMCA Rugby Club and Londonderry Chamber of Commerce. The bishopric has always remained that of Derry, both in the (Protestant, formerly-established) Church of Ireland (now combined with the bishopric of Raphoe), and in the Roman Catholic Church. Most companies within the city choose local area names such as Pennyburn, Rosemount or "Foyle" from the River Foyle to avoid alienating the other community. Derry~Londonderry railway station is often referred to as Waterside railway station within the city, but is called Derry/Londonderry at other stations. The council changed the name of the local government district covering the city to Derry on 7 May 1984, consequently renaming itself Derry City Council. This did not change the name of the city, although the city is coterminous with the district, and in law, the city council is also the "Corporation of Londonderry" or, more formally, the "Mayor, Aldermen and Citizens of the City of Londonderry". The form "Londonderry" is used for the post town by the Royal Mail; however, use of "Derry" will still ensure delivery.

The city is also nicknamed "the Maiden City" by virtue of the fact that its walls were never breached despite being besieged on three separate occasions in the 17th century, the most notable being the Siege of Derry of 1688–1689. It was also nicknamed "Stroke City" by local broadcaster Gerry Anderson, owing to the politically correct use by some of the dual name "Derry/Londonderry" (which has itself been used by BBC Television). A later addition to the landscape has been the erection of several large stone columns on main roads into the city welcoming drivers, euphemistically, to 'the Walled City'.

"Derry" is a common place name in Ireland, with at least six towns bearing that name and at least a further 79 places. The word "Derry" often forms part of the place name, for example, Derrybeg, Derryboy, Derrylea and Derrymore.

Londonderry, Yorkshire, near the Yorkshire Dales, was named for the Marquesses of Londonderry, as is Londonderry Island off Tierra del Fuego in Chile. In the United States, twin towns in New Hampshire called Derry and Londonderry lie about 75 miles from Londonderry, Vermont, with additional namesakes in Derry, Pennsylvania, Londonderry, Ohio, and in Canada Londonderry, Nova Scotia and Londonderry, Edmonton, Alberta. There is also Londonderry, New South Wales and the associated Londonderry electorate.

Derry is the only remaining completely intact walled city in Ireland, and one of the finest examples of a walled city in Europe. The walls constitute the largest monument in State care in Northern Ireland and, as part of the last walled city to be built in Europe, stand as the most complete and spectacular.

The Walls were built in 1613–1619 by The Honourable The Irish Society as defences for early 17th-century settlers from England and Scotland. The Walls, which are approximately in circumference and which vary in height and width between , are completely intact and form a walkway around the inner city. They provide a unique promenade to view the layout of the original town which still preserves its Renaissance-style street plan. The four original gates to the Walled City are Bishop's Gate, Ferryquay Gate, Butcher Gate and Shipquay Gate. Three further gates were added later, Magazine Gate, Castle Gate and New Gate, making seven gates in total. The architect was Peter Benson, a London-born builder, who was rewarded with several grants of land.

It is one of the few cities in Europe that never saw its fortifications breached, withstanding several sieges, including the famous Siege of Derry in 1689 which lasted 105 days; hence the city's nickname, "The Maiden City".

Derry is one of the oldest continuously inhabited places in Ireland. The earliest historical references date to the 6th century when a monastery was founded there by St Columba or Colmcille, a famous saint from what is now County Donegal, but for thousands of years before that people had been living in the vicinity.

Before leaving Ireland to spread Christianity elsewhere, Colmcille founded a monastery at Derry (which was then called ), on the west bank of the Foyle. According to oral and documented history, the site was granted to Colmcille by a local king. The monastery then remained in the hands of the federation of Columban churches who regarded Colmcille as their spiritual mentor. The year 546 is often referred to as the date that the original settlement was founded. However, it is now accepted by historians that this was an erroneous date assigned by medieval chroniclers. It is accepted that between the 6th century and the 11th century, Derry was known primarily as a monastic settlement.

The town became strategically more significant during the Tudor conquest of Ireland and came under frequent attack. During O'Doherty's Rebellion in 1608 it was attacked by Sir Cahir O'Doherty, Irish chieftain of Inishowen, who burnt much of the town and killed the governor George Paulet. The soldier and statesman Sir Henry Docwra made vigorous efforts to develop the town, earning the reputation of being "the founder of Derry"; but he was accused of failing to prevent the O'Doherty attack, and returned to England.

What became the City of Derry was part of the relatively new County Donegal up until 1610. In that year, the west bank of the future city was transferred by the English Crown to The Honourable The Irish Society and was combined with County Coleraine, part of County Antrim and a large portion of County Tyrone to form County Londonderry. Planters organised by London livery companies through The Honourable The Irish Society arrived in the 17th century as part of the Plantation of Ulster, and rebuilt the town with high walls to defend it from Irish insurgents who opposed the plantation. The aim was to settle Ulster with a population supportive of the Crown. It was then renamed "Londonderry".

This city was the first planned city in Ireland: it was begun in 1613, with the walls being completed in 1619, at a cost of £10,757. The central diamond within a walled city with four gates was thought to be a good design for defence. The grid pattern chosen was subsequently much copied in the colonies of British North America. The charter initially defined the city as extending three Irish miles (about 6.1 km) from the centre.

The modern city preserves the 17th-century layout of four main streets radiating from a central Diamond to four gateways  – Bishop's Gate, Ferryquay Gate, Shipquay Gate and Butcher's Gate. The city's oldest surviving building was also constructed at this time: the 1633 Plantation Gothic cathedral of St Columb. In the porch of the cathedral is a stone that records completion with the inscription: "If stones could speake, then London's prayse should sound, Who built this church and cittie from the grounde."

During the 1640s, the city suffered in the Wars of the Three Kingdoms, which began with the Irish Rebellion of 1641, when the Gaelic Irish insurgents made a failed attack on the city. In 1649 the city and its garrison, which supported the republican Parliament in London, were besieged by Scottish Presbyterian forces loyal to King Charles I. The Parliamentarians besieged in Derry were relieved by a strange alliance of Roundhead troops under George Monck and the Irish Catholic general Owen Roe O'Neill. These temporary allies were soon fighting each other again however, after the landing in Ireland of the New Model Army in 1649. The war in Ulster was finally brought to an end when the Parliamentarians crushed the Irish Catholic Ulster army at the Battle of Scarrifholis, near Letterkenny in nearby County Donegal, in 1650.

During the Glorious Revolution, only Derry and nearby Enniskillen had a Protestant garrison by November 1688. An army of around 1,200 men, mostly ""Redshanks"" (Highlanders), under Alexander MacDonnell, 3rd Earl of Antrim, was slowly organised (they set out on the week William of Orange landed in England). When they arrived on 7 December 1688 the gates were closed against them and the Siege of Derry began. In April 1689, King James came to the city and summoned it to surrender. The King was rebuffed and the siege lasted until the end of July with the arrival of a relief ship.

The city was rebuilt in the 18th century with many of its fine Georgian style houses still surviving. The city's first bridge across the River Foyle was built in 1790. During the 18th and 19th centuries, the port became an important embarkation point for Irish emigrants setting out for North America.

Also during the 19th century, it became a destination for migrants fleeing areas more severely affected by the Great Famine. One of the most notable shipping lines was the McCorkell Line operated by Wm. McCorkell & Co. Ltd. from 1778. The McCorkell's most famous ship was the "Minnehaha", which was known as the "Green Yacht from Derry".

During World War I, the city contributed over 5,000 men to the British Army from Catholic and Protestant families.

During the Irish War of Independence, the area was rocked by sectarian violence, partly prompted by the guerilla war raging between the Irish Republican Army and British forces, but also influenced by economic and social pressures. By mid-1920 there was severe sectarian rioting in the city. Many people died and in addition, many Catholics and Protestants were expelled from their homes during this communal unrest. After a week's violence, a truce was negotiated by local politicians on both unionist and republican sides.

In 1921, following the Anglo-Irish Treaty and the Partition of Ireland, it unexpectedly became a 'border city', separated from much of its traditional economic hinterland in County Donegal.

During World War II, the city played an important part in the Battle of the Atlantic. Ships from the Royal Navy, the Royal Canadian Navy, and other Allied navies were stationed in the city and the United States military established a base. Over 20,000 Royal Navy, 10,000 Royal Canadian Navy, and 6,000 United States Navy personnel were stationed in the city during the war.
The establishment of the American presence in the city was the result of a secret agreement between the Americans and the British before the Americans entered the war. It was the first American naval base in Europe and the terminal for American convoys en route to Europe.

The reason for such a high degree of military and naval activity was self-evident: Derry was the United Kingdom's westernmost port; indeed, the city was the westernmost Allied port in Europe: thus, Derry was a crucial jumping-off point, together with Glasgow and Liverpool, for the shipping convoys that ran between Europe and North America. The large numbers of military personnel in Derry substantially altered the character of the city, bringing in some outside colour to the local area, as well as some cosmopolitan and economic buoyancy during these years. Several airfields were built in the outlying regions of the city at this time, Maydown, Eglinton and Ballykelly. RAF Eglinton went on to become City of Derry Airport.

The city contributed a significant number of men to the war effort throughout the services, most notably the 500 men in the 9th (Londonderry) Heavy Anti-Aircraft Regiment, known as the 'Derry Boys'. This regiment served in North Africa, the Sudan, Italy and mainland UK. Many others served in the Merchant Navy taking part in the convoys that supplied the UK and Russia during the war.

The border location of the city, and the influx of trade from the military convoys allowed for significant smuggling operations to develop in the city.

At the conclusion of the Second World War, eventually some 60 U-boats of the German Kriegsmarine ended in the city's harbour at Lisahally after their surrender. The initial surrender was attended by Admiral Sir Max Horton, Commander-in-Chief of the Western Approaches, and Sir Basil Brooke, third Prime Minister of Northern Ireland.

The city languished after the second world war, with unemployment and development stagnating. A large campaign, led by the University for Derry Committee, to have Northern Ireland's second university located in the city, ended in failure.

Derry was a focal point for the nascent civil rights movement in Northern Ireland.
Catholics were discriminated against under Unionist government in Northern Ireland, both politically and economically. In the late 1960s the city became the flashpoint of disputes about institutional gerrymandering. Political scientist John Whyte explains that:

A civil rights demonstration in 1968 led by the Northern Ireland Civil Rights Association was banned by the Government and blocked using force by the Royal Ulster Constabulary. The events that followed the August 1969 Apprentice Boys parade resulted in the Battle of the Bogside, when Catholic rioters fought the police, leading to widespread civil disorder in Northern Ireland and is often dated as the starting point of the Troubles.

On Sunday 30 January 1972, 13 unarmed civilians were shot dead by British paratroopers during a civil rights march in the Bogside area. Another 13 were wounded and one further man later died of his wounds. This event came to be known as Bloody Sunday.

The conflict which became known as the Troubles is widely regarded as having started in Derry with the Battle of the Bogside. The Civil Rights Movement had also been very active in the city. In the early 1970s, the city was heavily militarised and there was widespread civil unrest. Several districts in the city constructed barricades to control access and prevent the forces of the state from entering.

Violence eased towards the end of the Troubles in the late 1980s and early 1990s. Irish journalist Ed Maloney claims in "The Secret History of the IRA" that republican leaders there negotiated a "de facto" ceasefire in the city as early as 1991. Whether this is true or not, the city did see less bloodshed by this time than Belfast or other localities.

The city was visited by an orca in November 1977 at the height of the Troubles; it was dubbed Dopey Dick by the thousands who came from miles around to see him.

From 1613 the city was governed by the Londonderry Corporation. In 1898 this became Londonderry County Borough Council, until 1969 when administration passed to the unelected Londonderry Development Commission. In 1973 a new district council with boundaries extending to the rural south-west was established under the name Londonderry City Council, renamed in 1984 to Derry City Council, consisting of five electoral areas: Cityside, Northland, Rural, Shantallow and Waterside. The council of 30 members was re-elected every four years. The council merged with Strabane District Council in April 2015 under local government reorganisation to become Derry and Strabane District Council.

The councillors elected in 2019 for the city are:

The devices on the city's arms are a skeleton and a three-towered castle on a black field, with the "chief" or top third of the shield showing the arms of the City of London: a red cross and sword on white. In the centre of the cross is a gold harp. In unofficial use the harp sometimes appears above the arms as a crest.

The arms were confirmed by Daniel Molyneux, the Ulster King of Arms, in 1613, following the town's incorporation. Molyneux's notes state that the original arms of Derry were "the picture of death (or a skeleton) sitting on a mossie ston and in the dexter point a castle". To this design he added, at the request of the new mayor, "a chief, the armes of London". Molyneux goes on to state that the skeleton is symbolic of Derry's ruin at the hands of the Irish rebel Cahir O'Doherty, and that the silver castle represents its renewal through the efforts of the London guilds: "[Derry] hath since bene (as it were) raysed from the dead by the worthy undertakinge of the Ho'ble Cittie of London, in memorie whereof it is hence forth called and knowen by the name of London Derrie."

Local legend offers different theories as to the origin of the skeleton. One identifies it as Walter de Burgh, who was starved to death in the Earl of Ulster's dungeons in 1332. Another identifies it as Cahir O'Doherty himself, who was killed in a skirmish near Kilmacrennan in 1608 (but was popularly believed to have wasted away while sequestered in his castle at Buncrana). In the days of gerrymandering and anti-Catholic discrimination, Derry's Catholics often claimed in dark wit that the skeleton was a Catholic waiting for a job and a council house. However, a report commissioned by the city council in 1979 established that there was no basis for any of the popular theories, and that the skeleton "[is] purely symbolic and does not refer to any identifiable person".

The 1613 arms depicted a harp in the centre of the cross, but this was omitted from later depictions of the city arms, and in the 1952 letters patent confirming the arms to the Londonderry Corporation. In 2002 Derry City Council applied to the College of Arms to have the harp restored, and Garter and Norroy & Ulster Kings of Arms issued letters patent to that effect in 2003, having accepted the 17th-century evidence.

The motto attached to the coat of arms reads in Latin, "Vita, Veritas, Victoria". This translates into English as "Life, Truth, Victory".

Derry is characterised by its distinctively hilly topography. The River Foyle forms a deep valley as it flows through the city, making Derry a place of very steep streets and sudden, startling views. The original walled city of Londonderry lies on a hill on the west bank of the River Foyle. In the past, the river branched and enclosed this wooded hill as an island; over the centuries, however, the western branch of the river dried up and became a low-lying and boggy district that is now called the Bogside.

Today, modern Derry extends considerably north and west of the city walls and east of the river. The half of the city on the west of the Foyle is known as the Cityside and the area east is called the Waterside. The Cityside and Waterside are connected by the Craigavon Bridge and Foyle Bridge, and by a footbridge in the centre of the city called Peace Bridge. The district also extends into rural areas to the southeast of the city.

This much larger city, however, remains characterised by the often extremely steep hills that form much of its terrain on both sides of the river. A notable exception to this lies on the northeastern edge of the city, on the shores of Lough Foyle, where large expanses of sea and mudflats were reclaimed in the middle of the 19th century. Today, these sloblands are protected from the sea by miles of sea walls and dikes. The area is an internationally important bird sanctuary, ranked among the top 30 wetland sites in the UK.

Other important nature reserves lie at Ness Country Park, east of Derry; and at Prehen Wood, within the city's south-eastern suburbs.

Derry has, like most of Ireland, a temperate maritime climate (Cfb) according to the Köppen climate classification system. The nearest official Met Office Weather Station for which climate data is available is Carmoney, just west of City of Derry Airport and about northeast of the city centre. However, observations ceased in 2004 and the nearest Weather Station is currently Ballykelly, due east-northeast. Typically, 27 nights of the year will report an air frost at Ballykelly, and at least 1 mm of precipitation will be reported on 170 days (1981–2010 averages).

The lowest temperature recorded at Carmoney was on 27 December 1995.

Derry Urban Area (DUA), including the city and the neighbouring settlements of Culmore, Newbuildings and Strathfoyle, is classified as a city by the Northern Ireland Statistics and Research Agency (NISRA) since its population exceeds 75,000. The mid-2006 population estimate for the wider Derry City Council area was 107,300. Population growth in 2005/06 was driven by natural change, with net out-migration of approximately 100 people.

The city was one of the few in Ireland to experience an increase in population during the Great Famine as migrants came to it from other, more heavily affected areas.

On census day (27 March 2011) there were 105,066 people living in Derry Urban Area. Of these, 27% were aged under 16 years and 14% were aged 60 and over; 49% of the population were male and 51% were female; 75% were from a Roman Catholic background and 23% (up three per cent from 2001) were from a Protestant background.

On census day (21 March 2021) there were 85,279 people living in Derry City and of these 77.88% (66,413) were from a Catholic background, 16.98% (14,481) were from Protestant and Other Christian (including Christian related) background, 1.24% had another religious background and 3.9% had no religion. 60.73% of individuals identify as Irish only, 13.18% identify as British only, 16.12% identify as Northern Irish only.

Concerns have been raised by both communities over the increasingly divided nature of the city. There were about 17,000 Protestants on the west bank of the River Foyle in 1971. The proportion rapidly declined during the 1970s; the 2011 census recorded 3,169 Protestants on the west bank, compared to 54,976 Catholics, and it is feared that the city could become permanently divided.

However, concerted efforts have been made by the local community, church and political leaders from both traditions to redress the problem. A conference to bring together key actors and promote tolerance was held in October 2006. Ken Good, the Church of Ireland Bishop of Derry and Raphoe, said he was happy living on the cityside. "I feel part of it. It is my city and I want to encourage other Protestants to feel exactly the same", he said.

Support for Protestants in the district has been strong from the SDLP politician Helen Quigley, who formerly served as the mayor of Derry. She made inclusion and tolerance key themes of her mayoralty. Cllr. Quigley said it was time for "everyone to take a stand to stop the scourge of sectarian and other assaults in the city."

The economy of the district was based significantly on the textile industry until relatively recently. For many years women were commonly the sole wage earners working in the shirt factories while the men in comparison had high levels of unemployment. This led to significant male emigration. The history of shirt making in the city dates to 1831, said to have been started by William Scott and his family who first exported shirts to Glasgow. Within 50 years, shirt making in the city was the most prolific in the UK with garments being exported all over the world. It was known so well that the industry received a mention in "Das Kapital" by Karl Marx, when discussing the factory system:

The industry reached its peak in the 1920s employing around 18,000 people. In modern times, however, the textile industry declined due largely to lower Asian wages.

A long-term foreign employer in the area is Du Pont, which has been based at Maydown since 1958, its first European production facility. Originally Neoprene was manufactured at Maydown and subsequently followed by Hypalon. More recently Lycra and Kevlar production units were active. Thanks to a worldwide demand for Kevlar, which is made at the plant, the facility undertook a £40 million upgrade to expand its global Kevlar production.

As of 2002, the three largest private-sector employers were American firms. Economic successes have included call centres and a large investment by Seagate, which has operated a factory in the Springtown Industrial Estate since 1993. As of 2019, Seagate was employing approximately 1,400 people in Derry.

A controversial new employer in the area was Raytheon Systems Limited, a software division of the American defence contractor, which was set up in Derry in 1999. Although some of the local people welcomed the jobs boost, others in the area objected to the jobs being provided by a firm involved heavily in the arms trade. Following four years of protest by the Foyle Ethical Investment Campaign, in 2004 Derry City Council passed a motion declaring the district "a 'no – go' area for the arms trade", and in 2006 its offices were briefly occupied by anti-war protestors who became known as the Raytheon 9. In 2009, the company announced that it was not renewing its lease when it expired in 2010 and was looking for a new location for its operations.

Other significant multinational employers in the region include Firstsource of India, INVISTA, Stream International, Perfecseal, NTL, Northbrook Technology of the United States, Arntz Belting and Invision Software of Germany, and Homeloan Management of the UK. Major local business employers include Desmonds, Northern Ireland's largest privately owned company, manufacturing and sourcing garments, E&I Engineering, St. Brendan's Irish Cream Liqueur and McCambridge Duffy, one of the largest insolvency practices in the UK.

Even though the city provides cheap labour by standards in Western Europe, critics have noted that the grants offered by the Northern Ireland Industrial Development Board have helped land jobs for the area that only last as long as the funding lasts. This was reflected in questions to the Parliamentary Under-Secretary of State for Northern Ireland, Richard Needham, in 1990. It was noted that it cost £30,000 to create one job in an American firm in Northern Ireland.

Critics of investment decisions affecting the district often point to the decision to build a new university building in nearby (predominantly Protestant) Coleraine rather than developing the Ulster University Magee Campus. Another major government decision affecting the city was the decision to create the new town of Craigavon outside Belfast, which again was detrimental to the development of the city. Even in October 2005, there was perceived bias against the comparatively impoverished North West of the province, with a major civil service job contract going to Belfast. Mark Durkan, the Social Democratic and Labour Party (SDLP) leader and Member of Parliament (MP) for Foyle was quoted in the "Belfast Telegraph" as saying:

In July 2005, the Irish Minister for Finance, Brian Cowen, called for a joint task force to drive economic growth in the cross-border region. This would have implications for Counties Londonderry, Tyrone, and Donegal across the border.

The city is the north west's foremost shopping district, housing two large shopping centres along with numerous shop-packed streets serving much of the greater county, as well as Tyrone and Donegal.

The city centre has two main shopping centres; the Foyleside Shopping Centre which has 45 stores and 1,430 parking spaces, and the Richmond Centre, which has 39 retail units. The Quayside Shopping Centre also serves the city side and there is also Lisnagelvin Shopping Centre on the Waterside. These centres, as well as local-run businesses, feature numerous national and international stores. Crescent Link Retail Park, located in the Waterside, has several chain stores and has become the second largest retail park in Northern Ireland (second only to Sprucefield in Lisburn). Plans have also been approved for Derry's first Asda store, which will be located at the retail park sharing a unit with Homebase. Sainsbury's also applied for planning permission for a store at Crescent Link, but Environment Minister Alex Attwood turned it down.

Until the store's closure in March 2016, the city was also home to the world's oldest independent department store, Austins. Established in 1830, Austins predates Jenners of Edinburgh by 5 years, Harrods of London by 15 years and Macy's of New York by 25 years. The store's five-story Edwardian building is located within the walled city in the area known as The Diamond.

Derry is renowned for its architecture. This can be primarily ascribed to the formal planning of the historic walled city of Derry at the core of the modern city. This is centred on the Diamond with a collection of late Georgian, Victorian and Edwardian buildings maintaining the gridlines of the main thoroughfares (Shipquay Street, Ferryquay Street, Butcher Street and Bishop Street) to the City Gates. St Columb's Cathedral does not follow the grid pattern reinforcing its civic status. This Church of Ireland Cathedral was the first post-Reformation Cathedral built for an Anglican church. The construction of the Roman Catholic St Eugene's Cathedral in the Bogside in the 19th century was another major architectural addition to the city. The Townscape Heritage Initiative has funded restoration works to key listed buildings and other older structures.

In the three centuries since their construction, the city walls have been adapted to meet the needs of a changing city. The best example of this adaptation is the insertion of three additional gates – Castle Gate, New Gate and Magazine Gate – into the walls in the course of the 19th century. Today, the fortifications form a continuous promenade around the city centre, complete with cannon, avenues of mature trees and views across Derry. Historic buildings within the city walls include St Augustine's Church, which sits on the city walls close to the site of the original monastic settlement; the copper-domed Austin's department store, which claims to be the oldest such store in the world; and the imposing Greek Revival Courthouse on Bishop Street. The red-brick late-Victorian Guildhall, also crowned by a copper dome, stands just beyond Shipquay Gate and close to the riverfront.

There are many museums and sites of interest in and around the city, including the Foyle Valley Railway Centre, the Amelia Earhart Centre And Wildlife Sanctuary, the Apprentice Boys Memorial Hall, Ballyoan Cemetery, The Bogside, numerous murals by the Bogside Artists, Derry Craft Village, Free Derry Corner, O'Doherty Tower (now home to part of the Tower Museum), the Harbour Museum, the Museum of Free Derry, Chapter House Museum, the Workhouse Museum, the Nerve Centre, St. Columb's Park and Leisure Centre, Creggan Country Park, Brooke Park, The Millennium Forum, the Void Gallery, and the Foyle and Craigavon bridges.

Attractions include museums, a vibrant shopping centre and trips to the Giant's Causeway, which is approximately away, though poorly connected by public transport. Lonely Planet called Derry the fourth best city in the world to see in 2013.

On 25 June 2011, the Peace Bridge opened. It is a cycle and footbridge that begins from the Guild Hall in the city centre of Derry City to Ebrington Square and St Columb's Park on the far side of the River Foyle. It was funded jointly by the Department for Social Development (NI), the Department of the Environment, Community and Local Government along with matching funding, totalling £14 million, from the SEUPB Peace III programme.

Future projects include the Walled City Signature Project, which intends to ensure that the city's walls become a world-class tourist experience.

The transport network is built out of a complex array of old and modern roads and railways throughout the city and county. The city's road network also makes use of two bridges to cross the River Foyle, the Craigavon Bridge and the Foyle Bridge, the longest bridge in Ireland. Derry also serves as a major transport hub for travel throughout nearby County Donegal.

In spite of it being the second city of Northern Ireland (and it being the second-largest city in all of Ulster), road and rail links to other cities are below par for its standing. Many business leaders claim that government investment in the city and infrastructure has been badly lacking. Some have stated that this is due to its outlying border location whilst others have cited a sectarian bias against the region west of the River Bann due to its high proportion of Catholics. There is no direct motorway link with Dublin or Belfast. The rail link to Belfast has been downgraded over the years so that, presently, it is not a viable alternative to the roads for industry to rely on. As of 2008, there were plans for £1 billion worth of transport infrastructure investment in and around the district. Planned upgrades to the A5 Dublin road agreed as part of the Good Friday Agreement and St Andrews Talks fell through when the government of the Republic of Ireland reneged on its funding citing the post-2008 economic downturn.

Most public transport in Northern Ireland is operated by the subsidiaries of Translink. Originally the city's internal bus network was run by Ulsterbus, which still provides the city's connections with other towns in Northern Ireland. The city's buses are now run by Ulsterbus Foyle, just as Translink Metro now provides the bus service in Belfast. The Ulsterbus Foyle network offers 13 routes across the city into the suburban areas, excluding an Easibus link which connects to the Waterside and Drumahoe, and a free Rail Link Bus runs from the Waterside Railway Station to the city centre. All buses leave from the Foyle Street Bus Station in the city centre.

Long-distance buses depart from Foyle Street Bus Station to destinations throughout Ireland. Buses are operated by both Ulsterbus and Bus Éireann on cross-border routes. Lough Swilly formerly operated buses to County Donegal, but the company entered liquidation and is no longer in operation. There is a half-hourly service to Belfast every day, called the Maiden City Flyer, which is the Goldline Express flagship route. There are hourly services to Strabane, Omagh, Coleraine, Letterkenny and Buncrana, and up to twelve services a day to bring people to Dublin. There is a daily service to Sligo, Galway, Shannon Airport and Limerick.

TFI Local Link provides additional cross-border public transport routes, with route 244 , 245 , 288 (Ballybofey/Derry), 952 , 957 ,1426 all servicing the city.

Private coach operator, Patrick Gallagher Coaches, also runs 2 routes during the week that service the city. The first goes from Crolly in County Donegal to Belfast (to the Leonardo Hotel in Belfast city centre, "formerly Jurys Inn"), and another that runs from County Donegal to the city.

City of Derry Airport, the council-owned airport near Eglinton, has grown during the early 21st century, with new investment in extending the runway and plans to redevelop the terminal.

The A2 (a dual carriageway) from Maydown to Eglinton, serves the airport. City of Derry airport is the main regional airport for County Donegal, County Londonderry and west County Tyrone as well as Derry City itself.

The airport is served by Loganair and Ryanair with scheduled flights to Glasgow Airport, Edinburgh Airport, Manchester Airport, Liverpool John Lennon Airport and London Stansted all year round with a summer schedule to Mallorca with TUI Airways

The city is served by a single rail link terminating at Derry ~ Londonderry railway station in Waterside that is subsidised, alongside much of Northern Ireland's railways, by Northern Ireland Railways (N.I.R.). The link primarily provides passenger services from the city to Belfast, via several stops that include , , and , and connections to links with other parts of Northern Ireland. The route itself is the only remaining rail link used by trains; most of the lines developed in the mid-19th century fell into decline towards the mid-20th century from competition by new road networks. The original rail network that served the city included four different railways that, between them, linked the city with much of the province of Ulster, plus a harbour railway network that linked the other four lines, and a tramway on the City side of the Foyle. Usage of the rail link between Derry and Belfast remains questionable for commuters, due to the journey time of over two hours making it slower centre-to-centre than the 100-minute Ulsterbus Goldline Express service.

Several railways began operation around the city of Derry within the middle of the 19th century. The companies that set up links helped to provide key links for the city towards other towns and cities across Ireland, for the transportation of passengers and freight. The lines that were constructed featured a mixture of Irish gauge and narrow gauge railways, and companies that operated them included:


In 1900, the gauge Donegal Railway was extended to the city from Strabane, with construction establishing the Londonderry Victoria Road railway terminus and creating a junction with the LPHC railway. The LPHC line was altered to dual gauge which allowed gauge traffic between the Donegal Railway and L&LSR as well as Irish gauge traffic between the GNR and B&NCR. By 1905, the government of the United Kingdom offered subsidies to both the L&LSR and the Donegal Railway to build extensions to their railway networks into remote parts of County Donegal, which soon developed Derry (alongside Strabane) into becoming a key rail hub by 1905 for the county and surrounding regions. In 1906 the Northern Counties Committee (NCC, successor to the B&NCR) and the GNR jointly took over the Donegal Railway, making it the County Donegal Railways Joint Committee (CDRJC).

Alongside the railways, the city was served by a standard gauge () tramway, the City of Derry Tramways. The tramway was opened in 1897 and consisted of horse trams that operated along a single line, long, which ran along the City side of the Foyle parallel to the LPHC's line on that side of the river. The line never converted to electrically operated trams, and was closed in 1919.

In 1922, the partition of Ireland dramatically caused disruptions to the city's rail links, except for the NNC route to . The creation of an international frontier with County Donegal changed trade patterns to the detriment of the railways affected by the partition, placing border posts on every line to and from Derry, causing great delays to trains and disrupting timekeeping from custom inspections - the L&LSR faced inspections between Pennyburn and Bridge End; the CDRJC faced inspections beyond Strabane; and the GNR line faced inspections between Derry and Strabane. Custom agreements negotiated over the next few years between Britain and Ireland enabled GNR trains to travel to and from Derry - such trains would be allowed to pass without inspection through the Free State, unless they served local stations on the west bank of the Foyle - while goods transported by all railways between different parts of the Free State would be allowed to pass through Northern Ireland under customs bond. Despite these agreements, local passenger and goods traffic continued to be delayed by customs examinations.

The decline of most of Derry's rail links took place after the Second World War, due to increasing competition by road links. The L&LSR closed its line in 1953, followed by the CDRJC in 1954. The Ulster Transport Authority, who took over the NCC in 1949 and the GNR's lines in Northern Ireland in 1958, took control of the LPHC railway before closing it in 1962, before eventually shutting down the former GNR line to Derry in 1965, after the submission of The Benson Report to the Northern Ireland Government two years prior to the closure. This left the former L&CR line to Coleraine as the sole railway link for the city, providing a passenger service to Belfast, alongside CIÉ freight services to Donegal. By the 1990s, the service began to deteriorate.

In 2008, the Department for Regional Development announced plans to relay the track between Derry and Coleraine - the plan, aimed at being completed by 2013, included adding a passing loop to increase traffic capacity, and increasing the number of trains with two additional diesel multiple units. Additional phases of the plan also included improvements to existing stations along the line, and the restoration of the former Victoria Road terminus building to prepare for the relocation of the city's current terminus station to the site, all for completion by late 2019. Costing around £86 million, the improvements were aimed at reducing the journey time to Belfast by 30 minutes and allowing commuter trains to arrive before 9 a.m. for the first time.

The largest road investment in the north west's history took place during 2010, with the building of the 'A2 Broadbridge Maydown to City of Derry Airport dualling' project and announcement of the 'A6 Londonderry to Dungiven Dualling Scheme' with the intention to reduce the travel time to Belfast. The latter project brings a dual-carriageway link between Northern Ireland's two largest cities one step closer. The project is costing £320 million and is expected to be completed in 2016.

In October 2006 the Government of Ireland announced that it was to invest €1 billion in Northern Ireland; with the planned projects including 'the A5 Western Transport Corridor', the complete upgrade of the A5 Derry – Omagh – Aughnacloy (– Dublin) road, around long, to dual carriageway standard.

In June 2008 Conor Murphy, Minister for Regional Development, announced that there will be a study into the feasibility of connecting the A5 and A6. Should it proceed, the scheme would most likely run from Drumahoe to south of Prehen along the south east of the city.

Londonderry Port at Lisahally is the United Kingdom's most westerly port and has capacity for 30,000-ton vessels. The Londonderry Port and Harbour Commissioners (LPHC) announced record turnover, record profits and record tonnage figures for the year ended March 2008. The figures are the result of a significant capital expenditure programme for the period 2000 to 2007 of about £22 million. Tonnage handled by LPHC increased by almost 65% between 2000 and 2007.

The port gave vital Allied service in the longest-running campaign of the Second World War, the Battle of the Atlantic, and saw the surrender of the German U-boat fleet at Lisahally on 8 May 1945.

The tidal River Foyle is navigable from the coast at Derry to approximately inland. In 1796, the Strabane Canal was opened, continuing the navigation a further southwards to Strabane. The canal was closed in 1962.

Derry is home to the Magee Campus of Ulster University, formerly Magee College. However, Lockwood's 1960s decision to locate Northern Ireland's second university in Coleraine rather than Derry helped contribute to the formation of the civil rights movement that ultimately led to The Troubles. Derry was the town more closely associated with higher learning, with Magee College already more than a century old by that time. In the mid-1980s an attempt was made at address this by forming Magee College as a campus of the Ulster University, but this failed to stifle calls for the establishment of an independent University in Derry. As of 2021, the Magee campus reportedly accommodated approximately 4,400 students, out of a total Ulster University student population of approximately 24,000, of which 15,000 are in the Belfast campus.

The North West Regional College is also based in the city, and accommodates over 10,000 student enrolments annually.

One of the two oldest secondary schools in Northern Ireland, Foyle College, is located in Derry. It was founded in 1616 by the Merchant Taylors. Other secondary schools include St. Columb's College, Oakgrove Integrated College, St Cecilia's College, St Mary's College, St. Joseph's Boys' School, Lisneal College, Thornhill College, Lumen Christi College and St. Brigid's College. There are also numerous primary schools.

The city is home to sports clubs and teams. Both association football and Gaelic football are popular in the area.

In association football, the city's most prominent clubs include Derry City who play in the national league of the Republic of Ireland; Institute of the NIFL Championship as well as Maiden City and Trojans, both of the Northern Ireland Intermediate League.
In addition to these clubs, which all play in national leagues, other clubs are based in the city. The local football league governed by the IFA is the North-West Junior League, which contains many clubs from the city, such as BBOB (Boys Brigade Old Boys) and Lincoln Courts. The city's other junior league is the Derry and District League and teams from the city and surrounding areas participate, including Don Boscos and Creggan Swifts. The Foyle Cup youth soccer tournament is held annually in the city. It has attracted many notable teams in the past, including Werder Bremen, IFK Göteborg and Ferencváros.

In Gaelic football Derry GAA are the county team and play in the Gaelic Athletic Association's National Football League, Ulster Senior Football Championship and All-Ireland Senior Football Championship. They also field hurling teams in the equivalent tournaments. There are many Gaelic games clubs in and around the city, for example Na Magha CLG, Steelstown GAC, Doire Colmcille CLG, Seán Dolans GAC, Na Piarsaigh CLG Doire Trasna and Slaughtmanus GAC.

There are many boxing clubs, the most well-known being the Ring Amateur Boxing Club, which is based on the City side, and associated with boxers Charlie Nash and John Duddy. Rochester's Amateur Boxing club is a club in the city's Waterside area.

Rugby union is also quite popular in the city, with the City of Derry Rugby Club situated not far from the city centre. City of Derry won both the Ulster Towns Cup and the Ulster Junior Cup in 2009. Londonderry YMCA RFC is another rugby club and is based in the village of Drumahoe which is on the outskirts of the city.

The city's only basketball club is North Star Basketball Club which has teams in the Basketball Northern Ireland senior and junior Leagues.

Cricket is also played in the city, particularly in the Waterside. The city is home to two cricket clubs, Brigade Cricket Club and Glendermott Cricket Club, both of whom play in the North West Senior League.

There are two golf clubs situated in the city, City of Derry Golf Club and Foyle International Golf Centre.

Artists and writers associated with the city and surrounding countryside include the Nobel Prize-winning poet Seamus Heaney, poet Seamus Deane, playwright Brian Friel, writer and music critic Nik Cohn, artist Willie Doherty, socio-political commentator and activist Eamonn McCann and bands such as The Undertones. The large political gable-wall murals of Bogside Artists, Free Derry Corner, the Foyle Film Festival, the Derry Walls, St Eugene's and St Columb's Cathedrals and the annual Halloween street carnival are popular tourist attractions. In 2010, Derry was named the UK's tenth 'most musical' city by PRS for Music.

In May 2013 a perpetual Peace Flame Monument was unveiled by Martin Luther King III and Presbyterian minister Rev. David Latimer. The flame was lit by children from both traditions in the city and is one of only 15 such flames across the world.

The local newspapers, the "Derry Journal" (known as the "Londonderry Journal" until 1880) and the "Londonderry Sentinel", reflect the divided history of the city: the "Journal" was founded in 1772 and is Ireland's second oldest newspaper; the "Sentinel" newspaper was formed in 1829 when new owners of the "Journal" embraced Catholic emancipation, and the editor left the paper to set up the "Sentinel".

There are numerous radio stations receivable: the largest stations based in the city are BBC Radio Foyle and the commercial station Q102.9.

There was a locally based television station, C9TV, one of only two local or 'restricted' television services in Northern Ireland, which ceased broadcasts in 2007.

The city's nightlife is mainly focused on the weekends, with several bars and clubs providing "student nights" during the weekdays. Waterloo Street and Strand Road provide the main venues. Waterloo Street, a steep street lined with both Irish traditional and modern pubs, frequently has live rock and traditional music at night.


Notable people who were born or have lived in Derry include:

The following people and military units have received the Freedom of the City of Derry.



European influence in Afghanistan

European influence in Afghanistan has been present in the country since the Victorian era, when the competing imperial powers of Britain and Russia contested for control over Afghanistan as part of the Great Game.

After the decline of the Durrani dynasty in 1823, Dost Mohammad Khan established the Barakzai dynasty. Dost Mohammad achieved prominence among his brothers through clever use of the support of his mother's Qizilbash tribesmen and his own youthful apprenticeship under his brother, Fateh Khan. However, in the same year, the Afghans lost their former stronghold of Peshawar to the Sikh Khalsa Army of Ranjit Singh at the Battle of Nowshera. The Afghan forces in the battle were supported by Azim Khan, half-brother of Dost Mohammad.

In 1834 Dost Mohammad defeated an invasion by the former ruler, Shuja Shah Durrani, but his absence from Kabul gave the Sikhs the opportunity to expand westward. Ranjit Singh's forces moved from Peshawar into territory ruled directly by Kabul. In 1836 Dost Mohammad's forces, under the command of his son Akbar Khan, defeated the Sikhs at the Battle of Jamrud, a post fifteen kilometres west of Peshawar. This was a pyrrhic victory and they failed to fully dislodge the Sikhs from Jamrud. The Afghan leader did not follow up this triumph by retaking Peshawar, however, but instead contacted Lord Auckland, the new British governor-general in British India, for help in dealing with the Sikhs. The letter marked the beginning of British influence in Afghanistan, and the subsequent Anglo-Russian struggle known as the Great Game.

The British became the major European power in the Indian subcontinent after the 1763 Treaty of Paris and began to show interest in Afghanistan as early as their 1809 treaty with Shuja Shah Durrani. It was the threat of the expanding Russian Empire beginning to push for an advantage in the Afghanistan region that placed pressure on British India, in what became known as the Great Game. The Great Game set in motion the confrontation of the British and Russian empires, whose spheres of influence moved steadily closer to one another until they met in Afghanistan. It also involved repeated attempts by the British to establish a puppet government in Kabul. The remainder of the 19th century saw greater European involvement in Afghanistan and her surrounding territories and heightened conflict among the ambitious local rulers as Afghanistan's fate played out globally.

The débâcle of the Afghan civil war left a vacuum in the Hindu Kush area that concerned the British, who were well aware of the many times in history it had been employed as an invasion route to South Asia. In the early decades of the 19th century, it became clear to the British that the major threat to their interests in India would not come from the fragmented Afghan empire, the Iranians, or the French, but from the Russians, who had already begun a steady advance southward from the Caucasus winning decisive wars against the Ottomans and Persians.

At the same time, the Russians feared the possibility a permanent British foothold in Central Asia as the British expanded northward, incorporating the Punjab, Sindh, and Kashmir into their empire; later to become Pakistan. The British viewed Russia's absorption of the Caucasus, the Kyrgyz and Turkmen lands, the Khanate of Khiva, and the Emirate of Bukhara with equal suspicion as a threat to their interests in the Indian subcontinent.
In addition to this rivalry between Britain and Russia, there were two specific reasons for British concern over Russia's intentions. First was the Russian influence at the Iranian court, which prompted the Russians to support Iran in its attempt to take Herat, historically the western gateway to Afghanistan and northern India. In 1837 Iran advanced on Herat with the support and advice of Russian officers. The second immediate reason was the presence in Kabul in 1837 of a Russian agent, Yan Vitkevich, who was ostensibly there, as was the British agent Alexander Burnes, for commercial discussions.

The British demanded that Dost Mohammad sever all contact with the Iranians and Russians, remove Vitkevich from Kabul, surrender all claims to Peshawar, and respect Peshawar's independence as well as that of Kandahar, which was under the control of his brothers at the time. In return, the British government intimated that it would ask Ranjit Singh to reconcile with the Afghans. When Auckland refused to put the agreement in writing, Dost Mohammad suspended negotiations the British and began negotiations with Vitkevich.

In 1838 Auckland, Ranjit Singh, and Shuja signed an agreement stating that Shuja would regain control of Kabul and Kandahar with the help of the British and Sikhs; he would accept Sikh rule of the former Afghan provinces already controlled by Ranjit Singh, and that Herat would remain independent. In practice, the plan replaced Dost Mohammad with a British figurehead whose autonomy would be similar to the princes who ruled over the princely states in British India.

It soon became apparent to the British that Sikh participation, advancing toward Kabul through the Khyber Pass while Shuja and the British advanced through Kandahar, would not be forthcoming. Auckland's plan in the spring of 1838 was for the Sikhs to place Shuja on the Afghan throne, with British support. By the end of the summer however, the plan had changed; now the British alone would impose the pliant Shuja Shah.

As a prelude to his invasion plans, the Governor-General of India Lord Auckland issued the Simla Manifesto in October 1838, setting forth the necessary reasons for British intervention in Afghanistan. The manifesto stated that in order to ensure the welfare of India, the British must have a trustworthy ally on India's western frontier. The British claim that their troops were merely supporting Shah Shujah's small army in retaking what was once his throne fooled no one. Although the Simla Manifesto stated that British troops would be withdrawn as soon as Shuja was installed in Kabul, Shuja's rule depended entirely on British support to suppress rebellion and on British funds to buy the support of tribal chiefs. The British denied that they were invading Afghanistan, instead claiming they were supporting its legitimate Shuja government "against foreign interference and factious opposition".

In November 1841 insurrection and massacre flared up in Kabul. The British vacillated and disagreed and were beleaguered in their inadequate cantonments. The British negotiated with the most influential sirdars, cut off as they were by winter and insurgent tribes from any hope of relief. Mohammad Akbar Khan, son of the captive Dost Mohammad, arrived in Kabul and became effective leader of the sirdars. At a conference with them Sir William MacNaghten was killed, but in spite of this, the sirdars' demands were agreed to by the British and they withdrew. During the withdrawal they were attacked by Ghilzai tribesmen and in running battles through the snowbound passes nearly the entire column of 4,500 troops and 12,000 camp followers were killed. Of the British only one, Dr. William Brydon, reached Jalalabad, while a few others were captured.

Afghan forces loyal to Akbar Khan besieged the remaining British contingents at Kandahar, Ghazni and Jalalabad. Ghazni fell, but the other garrisons held out, and with the help of reinforcements from India their besiegers were defeated. While preparations were under way for a renewed advance on Kabul, the new Governor-General Lord Ellenborough ordered British forces to leave Afghanistan after securing the release of the prisoners from Kabul and taking reprisals. The forces from Kandahar and Jalalabad again defeated Akbar Khan, retook and sacked Ghazni and Kabul, rescuing the prisoners before withdrawing through the Khyber Pass.

After months of chaos in Kabul, Mohammad Akbar Khan secured local control and in April 1843 his father Dost Mohammad, who had been released by the British, returned to the throne in Afghanistan. In the following decade, Dost Mohammad concentrated his efforts on reconquering Mazari Sharif, Konduz, Badakhshan, and Kandahar. Mohammad Akbar Khan died in 1845. During the Second Anglo-Sikh War (1848–49), Dost Mohammad's last effort to take Peshawar failed.

By 1854 the British wanted to resume relations with Dost Mohammad, whom they had essentially ignored in the intervening twelve years. The 1855 Treaty of Peshawar reopened diplomatic relations, proclaimed respect for each side's territorial integrity, and pledged both sides as friends of each other's friends and enemies of each other's enemies.

In 1857 an addendum to the 1855 treaty permitted a British military mission to become a presence in Kandahar (but not Kabul) during a conflict with the Persians, who had attacked Herat in 1856. During the Indian Rebellion of 1857, some British officials suggested restoring Peshawar to Dost Mohammad, in return for his support against the rebellious sepoys of the Bengal Army, but this view was rejected by British political officers on the North West frontier, who believed that Dost Mohammad would see this as a sign of weakness and turn against the British.

In 1863 Dost Mohammad retook Herat with British acquiescence. A few months later, he died. Sher Ali Khan, his third son, and proclaimed successor, failed to recapture Kabul from his older brother, Mohammad Afzal (whose troops were led by his son, Abdur Rahman) until 1868, after which Abdur Rahman retreated across the Amu Darya and bided his time.

In the years immediately following the First Anglo-Afghan War, and especially after the Indian Rebellion of 1857 against the British in India, Liberal Party governments in London took a political view of Afghanistan as a buffer state. By the time Sher Ali had established control in Kabul in 1868, he found the British ready to support his regime with arms and funds, but nothing more. Over the next ten years, relations between the Afghan ruler and Britain deteriorated steadily. The Afghan ruler was worried about the southward encroachment of Russia, which by 1873 had taken over the lands of the khan, or ruler, of Khiva. Sher Ali sent an envoy seeking British advice and support. The previous year the British had signed an agreement with the Russians in which the latter agreed to respect the northern boundaries of Afghanistan and to view the territories of the Afghan Emir as outside their sphere of influence. The British, however, refused to give any assurances to the disappointed Sher Ali.

After tension between Russia and Britain in Europe ended with the June 1878 Congress of Berlin, Russia turned its attention to Central Asia. That same summer, Russia sent an uninvited diplomatic mission to Kabul. Sher Ali tried, but failed, to keep them out. Russian envoys arrived in Kabul on 22 July 1878 and on 14 August, the British demanded that Sher Ali accept a British mission too.
The amir not only refused to receive a British mission but threatened to stop it if it were dispatched. Lord Lytton, the viceroy, ordered a diplomatic mission to set out for Kabul in September 1878 but the mission was turned back as it approached the eastern entrance of the Khyber Pass, triggering the Second Anglo-Afghan War. A British force of about 40,000 fighting men was distributed into military columns which penetrated Afghanistan at three different points. An alarmed Sher Ali attempted to appeal in person to the Tsar for assistance, but unable to do so, he returned to Mazari Sharif, where he died on 21 February 1879.

With British forces occupying much of the country, Sher Ali's son and successor, Mohammad Yaqub Khan, signed the Treaty of Gandamak in May 1879 in order to put a quick end to the conflict. According to this agreement and in return for an annual subsidy and vague assurances of assistance in case of foreign aggression, Yaqub relinquished control of Afghan foreign affairs to the British. British representatives were installed in Kabul and other locations, British control was extended to the Khyber and Michni Passes, and Afghanistan ceded various frontier areas and Quetta to Britain. The British forces then withdrew. Soon afterwards, an uprising in Kabul led to the killings of Britain's Resident in Kabul, Sir Pierre Cavagnari and his guards and staff on 3 September 1879, provoking the second phase of the Second Afghan War. Major General Sir Frederick Roberts led the Kabul Field Force over the Shutargardan Pass into central Afghanistan, defeated the Afghan Army at Char Asiab on 6 October 1879 and occupied Kabul. Ghazi Mohammad Jan Khan Wardak staged an uprising and attacked British forces near Kabul in the Siege of the Sherpur Cantonment in December 1879, but his defeat there resulted in the collapse of this rebellion.
Yaqub Khan, suspected of complicity in the killings of Cavagnari and his staff, was obliged to abdicate. The British considered a number of possible political settlements, including partitioning Afghanistan between multiple rulers or placing Yaqub's brother Ayub Khan on the throne, but ultimately decided to install his cousin Abdur Rahman Khan as emir instead. Ayub Khan, who had been serving as governor of Herat, rose in revolt, defeated a British detachment at the Battle of Maiwand in July 1880 and besieged Kandahar. Roberts then led the main British force from Kabul and decisively defeated Ayub Khan in September at the Battle of Kandahar, bringing his rebellion to an end. Abdur Rahman had confirmed the Treaty of Gandamak, leaving the British in control of the territories ceded by Yaqub Khan and ensuring British control of Afghanistan's foreign policy in exchange for protection and a subsidy. Abandoning the provocative policy of maintaining a British resident in Kabul, but having achieved all their other objectives, the British withdrew.

As far as British interests were concerned, Abdur Rahman answered their prayers: a forceful, intelligent leader capable of welding his divided people into a state; and he was willing to accept limitations to his power imposed by British control of his country's foreign affairs and the British buffer state policy. His twenty-one-year reign was marked by efforts to modernize and establish control of the kingdom, whose boundaries were delineated by the two empires bordering it. Abdur Rahman turned his considerable energies to what evolved into the creation of the modern state of Afghanistan.

He achieved this consolidation of Afghanistan in three ways. He suppressed various rebellions and followed up his victories with harsh punishment, execution, and deportation. He broke the stronghold of Pashtun tribes by forcibly transplanting them. He transplanted his most powerful Pashtun enemies, the Ghilzai, and other tribes from southern and south-central Afghanistan to areas north of the Hindu Kush with predominantly non-Pashtun populations. The last non-Muslim Afghans of Kafiristan north of Kabul were forcefully converted to Islam. Finally, he created a system of provincial governorates different from old tribal boundaries. Provincial governors had a great deal of power in local matters, and an army was placed at their disposal to enforce tax collection and suppress dissent. Abdur Rahman kept a close eye on these governors, however, by creating an effective intelligence system. During his reign, tribal organization began to be eroded as provincial government officials allowed land to change hands outside the traditional clan and tribal limits.

The Pashtuns battled and conquered the Uzbeks and forced them into the status of ruled people who were discriminated against. Out of anti-Russian strategic interests, the British assisted the Afghan conquest of the Uzbek Khanates, giving weapons to the Afghans and supporting the Afghan government's colonization of northern Afghanistan by Pashtuns, which involved sending massive amounts of Pashtun colonists onto Uzbek land.

In addition to forging a nation from the splintered regions making up Afghanistan, Abdur Rahman tried to modernize his kingdom by forging a regular army and the first institutionalized bureaucracy. Despite his distinctly authoritarian personality, Abdur Rahman called for a loya jirga, an assemblage of royal princes, important notables, and religious leaders. According to his autobiography, Abdur Rahman had three goals: subjugating the tribes, extending government control through a strong, visible army, and reinforcing the power of the ruler and the royal family.
During his visit to Rawalpindi in 1885, the Amir requested the Viceroy of India to depute a Muslim Envoy to Kabul who was noble birth and of ruling family background. Mirza Atta Ullah Khan, Sardar Bahadur s/o Khan Bahadur Mirza Fakir Ullah Khan (Saman Burj Wazirabad), a direct descendant of Jarral Rajput Rajas of Rajauri, was selected and approved by the Amir to be the British Envoy to Kabul.

Abdur Rahman also paid attention to technological advance. He brought foreign physicians, engineers (especially for mining), geologists, and printers to Afghanistan. He imported European machinery and encouraged the establishment of small factories to manufacture soap, candles, and leather goods. He sought European technical advice on communications, transport, and irrigation. Local Afghan tribes strongly resisted this modernization. Workmen making roads had to be protected by the army against local warriors. Nonetheless, despite these sweeping internal policies, Abdur Rahman's foreign policy was completely in foreign hands.

The first important frontier dispute was the Panjdeh crisis of 1885, precipitated by Russian encroachment into Central Asia. Having seized the Merv (now Mary) Oasis by 1884, Russian forces were directly adjacent to Afghanistan. Claims to the Panjdeh Oasis were in debate, with the Russians keen to take over all the region's Turkoman domains. After battling Afghan forces in the spring of 1885, the Russians seized the oasis. Russian and British troops were quickly alerted, but the two powers reached a compromise; Russia was in possession of the oasis, and Britain believed it could keep the Russians from advancing any farther. Without an Afghan say in the matter, the Joint Anglo-Russian Boundary Commission agreed that the Russians would relinquish the farthest territory captured in their advance but retain Panjdeh. This agreement on these border sections delineated for Afghanistan a permanent northern frontier at the Amu Darya, but also involved the loss of much territory, especially around Panjdeh.

The second section of Afghan border demarcated during Abdur Rahman's reign was in the Wakhan. The British insisted that Abdur Rahman accept sovereignty over this remote region, where unruly Kyrgyz held sway; he had no choice but to accept Britain's compromise. In 1895 and 1896, another Joint Anglo-Russian Boundary Commission agreed on the frontier boundary to the far northeast of Afghanistan, which bordered Chinese territory (although the Chinese did not formally accept this as a boundary between the two countries until 1964.)

For Abdur Rahman, delineating the boundary with India (through the Pashtun area) was far more significant, and it was during his reign that the Durand Line was drawn. Under pressure, Abdur Rahman agreed in 1893 to accept a mission headed by the British Indian foreign secretary, Sir Mortimer Durand, to define the limits of British and Afghan control in the Pashtun territories. Boundary limits were agreed on by Durand and Abdur Rahman before the end of 1893, but there is some question about the degree to which Abdur Rahman willingly ceded certain regions. There were indications that he regarded the Durand Line as a delimitation of separate areas of political responsibility, not a permanent international frontier, and that he did not explicitly cede control over certain parts (such as Kurram and Chitral) that were already in British control under the Treaty of Gandamak.

The Durand Line cut through tribes and bore little relation to the realities of demography or military strategy. The line laid the foundation not for peace between the border regions, but for heated disagreement between the governments of Afghanistan and British India, and later, Afghanistan and Pakistan over what came to be known as the issue of Pashtunistan or 'Land of the Pashtuns'. (See Siege of Malakand).

The clearest manifestation that Abdur Rahman had established control in Afghanistan was the peaceful succession of his eldest son, Habibullah Khan, to the throne on his father's death in October 1901. Although Abdur Rahman had fathered many children, he groomed Habibullah to succeed him, and he made it difficult for his other sons to contest the succession by keeping power from them and sequestering them in Kabul under his control.

Habibullah Khan, Abdur Rahman Khan's eldest son and child of a slave mother, kept a close watch on the palace intrigues revolving around his father's more distinguished wife (a granddaughter of Dost Mohammad), who sought the throne for her own son. Although made secure in his position as ruler by virtue of support from the army which was created by his father, Habibullah was not as domineering as Abdur Rahman. Consequently, the influence of religious leaders as well as that of Mahmud Tarzi, a cousin of the king, increased during his reign.

Mahmud Tarzi, a highly educated, well-traveled poet and journalist, founded an Afghan nationalist newspaper with Habibullah's agreement, and until 1919 he used the newspaper as a platform for rebutting clerical criticism of Western-influenced changes in government and society, for espousing full Afghan independence, and for other reforms. Tarzi's passionate Afghan nationalism influenced a future generation of Asian reformers.

The boundary with Iran was firmly delineated in 1904, replacing the ambiguous line made by a British commission in 1872. Agreement could not be reached, however, on sharing the waters of the Helmand River.

Like all foreign policy developments of this period affecting Afghanistan, the conclusion of the "Great Game" between Russia and Britain occurred without the Afghan ruler's participation. The 1907 Anglo-Russian Convention (the Convention of St. Petersburg) not only divided the region into separate areas of Russian and British influence but also established foundations for Afghan neutrality. The convention provided for Russian acquiescence that Afghanistan was now outside this sphere of influence, and for Russia to consult directly with Britain on matters relating to Russian-Afghan relations. Britain, for its part, would not occupy or annex Afghan territory, or interfere in Afghanistan's internal affairs.

During World War I, Afghanistan remained neutral despite pressure to support Turkey when its sultan proclaimed his nation's participation in what it considered a holy war. Habibullah did, however, entertain an Indo-German–Turkish mission in Kabul in 1915 that had as its titular head the Indian nationalist Mahendra Pratap and was led by Oskar Niedermayer and the German legate Werner Otto von Hentig. After much procrastination, he won an agreement from the Central Powers for a huge payment and arms provision in exchange for attacking British India. But the crafty Afghan ruler clearly viewed the war as an opportunity to play one side off against the other, for he also offered the British to resist a Central Powers attack on India in exchange for an end to British control of Afghan foreign policy.

Amanullah's ten years of reign initiated a period of dramatic change in Afghanistan in both foreign and domestic politics. Amanullah declared full independence and sparked the Third Anglo-Afghan War. Amanullah altered foreign policy in his new relations with external powers and transformed domestic politics with his social, political, and economic reforms. Although his reign ended abruptly, he achieved some notable successes, and his efforts failed as much due to the centrifugal forces of tribal Afghanistan and the machinations of Russia and Britain as to any political folly on his part.

Amanullah came to power just as the entente between Russia and Britain broke down following the Russian Revolution of 1917. Once again Afghanistan provided a stage on which the great powers played out their schemes against one another. Keen to modernise his country and remove all foreign influence, Amanullah, sought to shore up his powerbase. Amidst intrigue in the Afghan court, and political and civil unrest in India, he sought to divert attention from the internal divisions of Afghanistan and unite all faction behind him by attacking the British.

Using the civil unrest in India as an excuse to move troops to the Durand Line, Afghan troops crossed the border at the western end of the Khyber Pass on 3 May 1919 and occupied the village of Bagh, the scene of an earlier uprising in April. In response, the Indian government ordered a full mobilisation and on 6 May 1919 declared war. For the British it had come at a time when they were still recovering from the First World War. The troops that were stationed in India were mainly reserves and Territorials, who were awaiting demobilisation and keen to return to Britain, whilst the few regular regiments that were available were tired and depleted from five years of fighting.

Afghan forces achieved success in the initial days of the war, taking the British and Indians by surprise in two main thrusts as the Afghan regular army was joined by large numbers of Pashtun tribesmen from both sides of the border. A series of skirmishes then followed as the British and Indians recovered from their initial surprise. As a counterbalance to deficiencies in manpower and morale, the British had a considerable advantage in terms of equipment, possessing machine guns, armoured cars, motor transport, wireless communications and aircraft and it was the latter that would prove decisive.

British forces deployed air forces for the first time in the region, and the King's home was directly targeted in what is the first case of aerial bombardment in Afghanistan's history. The attacks played a key role in forcing an armistice but brought an angry rebuke from King Amanullah. He wrote: "It is a matter of great regret that the throwing of bombs by zeppelins on London was denounced as a most savage act and the bombardment of places of worship and sacred spots was considered a most abominable operation. While we now see with our own eyes that such operations were a habit which is prevalent among all civilized people of the west".

The fighting concluded in August 1919 and Britain virtually dictated the terms of the Anglo-Afghan Treaty of 1919, a temporary armistice that provided, on one somewhat ambiguous interpretation, for Afghan self-determination in foreign affairs. Before final negotiations were concluded in 1921, however, Afghanistan had already begun to establish its own foreign policy without repercussions anyway, including diplomatic relations with the new government in the Soviet Union in 1919. During the 1920s, Afghanistan established diplomatic relations with most major countries.

On 20 February 1919, Habibullah Khan was assassinated on a hunting trip. He had not declared a succession, but left his third son, Amanullah Khan, in charge in Kabul. Amanullah did have an older brother, Nasrullah Khan. But, because Amanullah controlled both the national treasury and the army, Amanullah was well situated to seize power. The army's support allowed Amanullah to suppress other claims and imprison those relatives who would not swear loyalty to him. Within a few months, the new amir had gained the allegiance of most tribal leaders and established control over the cities.
Amanullah Khan's reforms were heavily influenced by Europe. This came through the influence of Mahmud Tarzi, who was both Amanullah Khan's father-in-law and Foreign Minister. Mahmud Tarzi, a highly educated, well-traveled poet, journalist, and diplomat, was a key figure that brought Western dress and etiquette to Afghanistan. He also fought for progressive reforms such as woman's rights, educational rights, and freedom of press. All of these influences, brought by Tarzi and others, were welcomed by Amanullah Khan.

In 1926, Amanullah ended the Emirate of Afghanistan and proclaimed the Kingdom of Afghanistan with himself as king. In 1927 and 1928, King Amanullah Khan and his wife Soraya Tarzi visited Europe. On this trip they were honored and feted. In fact, in 1928 the King and Queen of Afghanistan received honorary degrees from the University of Oxford. This was an era when other Muslim nations, like Turkey and Egypt were also on the path to modernization. King Amanullah was so impressed with the social progress of Europe that he tried to implement them right away, this met with heavy resistance from the conservative society and eventually led to his demise.

Amanullah enjoyed early popularity within Afghanistan and he used his power to modernize the country. Amanullah created new cosmopolitan schools for both boys and girls in the region and overturned centuries-old traditions such as strict dress codes for women. He created a new capital city and increased trade with Europe and Asia. He also advanced a modernist constitution that incorporated equal rights and individual freedoms. This rapid modernization though, created a backlash, and a reactionary uprising known as the "Khost rebellion" which was suppressed in 1925.

After Amanullah travelled to Europe in late 1927, opposition to his rule increased. An uprising in Jalalabad culminated in a march to the capital, and much of the army deserted rather than resist. On 14 January 1929, Amanullah abdicated in favor of his brother, King Inayatullah Khan. On 17 January, Inayatullah abdicated and Habibullah Kalakani became the next ruler of Afghanistan and restored the emirate. However, his rule was short lived and, on 17 October 1929, Habibullah Kalakani was overthrown and replaced by King Nadir Khan.

After his abdication in 1929, Amanullah went into temporary exile in India. When he attempted to return to Afghanistan, he had little support from the people. From India, the ex-king traveled to Europe and settled in Italy, and later in Switzerland. Meanwhile, Nadir Khan made sure his return to Afghanistan was impossible by engaging in a propaganda war. Nadir Khan accused Amanullah Khan of kufr with his pro western policies.

In 1933, after the assassination of Nadir Khan, Mohammed Zahir Shah became king.





Dementia praecox

Dementia praecox (meaning a "premature dementia" or "precocious madness") is a disused psychiatric diagnosis that originally designated a chronic, deteriorating psychotic disorder characterized by rapid cognitive disintegration, usually beginning in the late teens or early adulthood. Over the years, the term "dementia praecox" was gradually replaced by the term "schizophrenia", which initially had a meaning that included what is today considered the autism spectrum.

The term "dementia praecox" was first used by German psychiatrist Heinrich Schüle in 1880.

It was also used in 1891 by Arnold Pick (1851–1924), a professor of psychiatry at Charles University in Prague. In a brief clinical report, he described a person with a psychotic disorder resembling "hebephrenia" (an adolescent-onset psychotic condition).

German psychiatrist Emil Kraepelin (1856–1926) popularised the term "dementia praecox" in his first detailed textbook descriptions of a condition that eventually became a different disease concept later relabeled as "schizophrenia". Kraepelin reduced the complex psychiatric taxonomies of the nineteenth century by dividing them into two classes: manic-depressive psychosis and dementia praecox. This division, commonly referred to as the Kraepelinian dichotomy, had a fundamental impact on twentieth-century psychiatry, though it has also been questioned.

The primary disturbance in dementia praecox was seen to be a disruption in cognitive or mental functioning in attention, memory, and goal-directed behaviour. Kraepelin contrasted this with manic-depressive psychosis, now termed bipolar disorder, and also with other forms of mood disorder, including major depressive disorder. He eventually concluded that it was not possible to distinguish his categories on the basis of cross-sectional symptoms.

Kraepelin viewed dementia praecox as a progressively deteriorating disease from which no one recovered. However, by 1913, and more explicitly by 1920, Kraepelin admitted that while there may be a residual cognitive defect in most cases, the prognosis was not as uniformly dire as he had stated in the 1890s. Still, he regarded it as a specific disease concept that implied incurable, inexplicable madness.

"Dementia" is an ancient term which has been in use since at least the time of Lucretius in 50 BC where it meant "being out of one's mind". Until the seventeenth century, dementia referred to states of cognitive and behavioural deterioration leading to psychosocial incompetence. This condition could be innate or acquired, and the concept had no reference to a necessarily irreversible condition. It is the concept in this popular notion of psychosocial incapacity that forms the basis for the idea of legal incapacity. By the eighteenth century, at the period when the term entered into European medical discourse, clinical concepts were added to the vernacular understanding such that dementia was now associated with intellectual deficits arising from any cause and at any age. By the end of the nineteenth century, the modern 'cognitive paradigm' of dementia was taking root. This holds that dementia is understood in terms of criteria relating to aetiology, age and course which excludes former members of the family of the demented such as adults with acquired head trauma or children with cognitive deficits. Moreover, it was now understood as an irreversible condition and a particular emphasis was placed on memory loss in regard to the deterioration of intellectual functions.

The term was used in passing to describe the characteristics of a subset of young mental patients by the French physician Bénédict Augustin Morel in 1852 in the first volume of his . and the term is used more frequently in his textbook which was published in 1860. Morel, whose name will be forever associated with religiously inspired concept of degeneration theory in psychiatry, used the term in a descriptive sense and not to define a specific and novel diagnostic category. It was applied as a means of setting apart a group of young men and women with "stupor". As such their condition was characterised by a certain torpor, enervation, and disorder of the will and was related to the diagnostic category of melancholia. He did not conceptualise their state as irreversible and thus his use of the term dementia was equivalent to that formed in the eighteenth century as outlined above.

While some have sought to interpret, if in a qualified fashion, the use by Morel of the term as amounting to the discovery of schizophrenia, others have argued convincingly that Morel's descriptive use of the term should not be considered in any sense as a precursor to Kraepelin's dementia praecox disease concept. This is due to the fact that their concepts of dementia differed significantly from each other, with Kraepelin employing the more modern sense of the word and that Morel was not describing a diagnostic category. Indeed, until the advent of Pick and Kraepelin, Morel's term had vanished without a trace and there is little evidence to suggest that either Pick or indeed Kraepelin were even aware of Morel's use of the term until long after they had published their own disease concepts bearing the same name. As Eugène Minkowski stated, "An abyss separates Morel's from that of Kraepelin."

Morel described several psychotic disorders that ended in dementia, and as a result he may be regarded as the first alienist or psychiatrist to develop a diagnostic system based on presumed outcome rather than on the current presentation of signs and symptoms. Morel, however, did not conduct any long-term or quantitative research on the course and outcome of dementia praecox (Kraepelin would be the first in history to do that) so this prognosis was based on speculation. It is impossible to discern whether the condition briefly described by Morel was equivalent to the disorder later called dementia praecox by Pick and Kraepelin.

Psychiatric nosology in the nineteenth-century was chaotic and characterised by a conflicting mosaic of contradictory systems. Psychiatric disease categories were based upon short-term and cross-sectional observations of patients from which were derived the putative characteristic signs and symptoms of a given disease concept. The dominant psychiatric paradigms which gave a semblance of order to this fragmentary picture were Morelian degeneration theory and the concept of "unitary psychosis" (). This latter notion, derived from the Belgian psychiatrist Joseph Guislain (1797–1860), held that the variety of symptoms attributed to mental illness were manifestations of a single underlying disease process. While these approaches had a diachronic aspect they lacked a conception of mental illness that encompassed a coherent notion of change over time in terms of the natural course of the illness and based upon an empirical observation of changing symptomatology.

In 1863, the Danzig-based psychiatrist Karl Ludwig Kahlbaum (1828–1899) published his text on psychiatric nosology ("The Classification of Psychiatric Diseases"). Although with the passage of time this work would prove profoundly influential, when it was published it was almost completely ignored by German academia despite the sophisticated and intelligent disease classification system which it proposed. In this book Kahlbaum categorized certain typical forms of psychosis () as a single coherent type based upon their shared progressive nature which betrayed, he argued, an ongoing degenerative disease process. For Kahlbaum the disease process of was distinguished by the passage of the patient through clearly defined disease phases: a melancholic stage; a manic stage; a confusional stage; and finally a demented stage.

In 1866, Kahlbaum became the director of a private psychiatric clinic in Görlitz (Prussia, today Saxony, a small town near Dresden). He was accompanied by his younger assistant, Ewald Hecker (1843–1909), and during a ten-year collaboration they conducted a series of research studies on young psychotic patients that would become a major influence on the development of modern psychiatry.

Together Kahlbaum and Hecker were the first to describe and name such syndromes as dysthymia, cyclothymia, paranoia, catatonia, and hebephrenia. Perhaps their most lasting contribution to psychiatry was the introduction of the "clinical method" from medicine to the study of mental diseases, a method which is now known as psychopathology.

When the element of time was added to the concept of diagnosis, a diagnosis became more than just a description of a collection of symptoms: diagnosis now also defined by prognosis (course and outcome). An additional feature of the clinical method was that the characteristic symptoms that define syndromes should be described without any prior assumption of brain pathology (although such links would be made later as scientific knowledge progressed). Karl Kahlbaum made an appeal for the adoption of the clinical method in psychiatry in his 1874 book on catatonia. Without Kahlbaum and Hecker there would be no dementia praecox.

Upon his appointment to a full professorship in psychiatry at the University of Dorpat (now Tartu, Estonia) in 1886, Kraepelin gave an inaugural address to the faculty outlining his research programme for the years ahead. Attacking the "brain mythology" of Meynert and the positions of Griesinger and Gudden, Kraepelin advocated that the ideas of Kahlbaum, who was then a marginal and little known figure in psychiatry, should be followed. Therefore, he argued, a research programme into the nature of psychiatric illness should look at a large number of patients over time to discover the course which mental disease could take. It has also been suggested that Kraepelin's decision to accept the Dorpat post was informed by the fact that there he could hope to gain experience with chronic patients and this, it was presumed, would facilitate the longitudinal study of mental illness.

Understanding that objective diagnostic methods must be based on scientific practice, Kraepelin had been conducting psychological and drug experiments on patients and normal subjects for some time when, in 1891, he left Dorpat and took up a position as professor and director of the psychiatric clinic at Heidelberg University. There he established a research program based on Kahlbaum's proposal for a more exact qualitative clinical approach, and his own innovation: a quantitative approach involving meticulous collection of data over time on each new patient admitted to the clinic (rather than only the interesting cases, as had been the habit until then).

Kraepelin believed that by thoroughly describing all of the clinic's new patients on index cards, which he had been using since 1887, researcher bias could be eliminated from the investigation process. He described the method in his posthumously published memoir:
The fourth edition of his textbook, , published in 1893, two years after his arrival at Heidelberg, contained some impressions of the patterns Kraepelin had begun to find in his index cards. Prognosis (course and outcome) began to feature alongside signs and symptoms in the description of syndromes, and he added a class of psychotic disorders designated "psychic degenerative processes", three of which were borrowed from Kahlbaum and Hecker: "dementia paranoides" (a degenerative type of Kahlbaum's paranoia, with sudden onset), "catatonia" (per Kahlbaum, 1874) and "dementia praecox", (Hecker's hebephrenia of 1871). Kraepelin continued to equate dementia praecox with hebephrenia for the next six years.

In the March 1896 fifth edition of , Kraepelin expressed confidence that his clinical method, involving analysis of both qualitative and quantitative data derived from long term observation of patients, would produce reliable diagnoses including prognosis:

In this edition dementia praecox is still essentially hebephrenia, and it, dementia paranoides and catatonia are described as distinct psychotic disorders among the "metabolic disorders leading to dementia".

In the 1899 (6th) edition of , Kraepelin established a paradigm for psychiatry that would dominate the following century, sorting most of the recognized forms of insanity into two major categories: dementia praecox and manic-depressive illness. Dementia praecox was characterized by disordered intellectual functioning, whereas manic-depressive illness was principally a disorder of affect or mood; and the former featured constant deterioration, virtually no recoveries and a poor outcome, while the latter featured periods of exacerbation followed by periods of remission, and many complete recoveries. The class, dementia praecox, comprised the paranoid, catatonic and hebephrenic psychotic disorders, and these forms were found in the Diagnostic and Statistical Manual of Mental Disorders until the fifth edition was released, in May 2013. These terms, however, are still found in general psychiatric nomenclature.

In the seventh, 1904, edition of , Kraepelin accepted the possibility that a small number of patients may recover from dementia praecox. Eugen Bleuler reported in 1908 that in many cases there was no inevitable progressive decline, there was temporary remission in some cases, and there were even cases of near recovery with the retention of some residual defect. In the eighth edition of Kraepelin's textbook, published in four volumes between 1909 and 1915, he described eleven forms of dementia, and dementia praecox was classed as one of the "endogenous dementias". Modifying his previous more gloomy prognosis in line with Bleuler's observations, Kraepelin reported that about 26% of his patients experienced partial remission of symptoms. Kraepelin died while working on the ninth edition of with Johannes Lange (1891–1938), who finished it and brought it to publication in 1927.

Though his work and that of his research associates had revealed a role for heredity, Kraepelin realized nothing could be said with certainty about the aetiology of dementia praecox, and he left out speculation regarding brain disease or neuropathology in his diagnostic descriptions. Nevertheless, from the 1896 edition onwards Kraepelin made clear his belief that poisoning of the brain, "auto-intoxication," probably by sex hormones, may underlie dementia praecox – a theory also entertained by Eugen Bleuler. Both theorists insisted dementia praecox is a biological disorder, not the product of psychological trauma. Thus, rather than a disease of hereditary degeneration or of structural brain pathology, Kraepelin believed dementia praecox was due to a systemic or "whole body" disease process, probably metabolic, which gradually affected many of the tissues and organs of the body before affecting the brain in a final, decisive cascade. Kraepelin, recognizing dementia praecox in Chinese, Japanese, Tamil and Malay patients, suggested in the eighth edition of that, "we must therefore seek the real cause of dementia praecox in conditions which are spread all over the world, which thus do not lie in race or in climate, in food or in any other general circumstance of life..."

Kraepelin had experimented with hypnosis but found it wanting, and disapproved of Freud's and Jung's introduction, based on no evidence, of psychogenic assumptions to the interpretation and treatment of mental illness. He argued that, without knowing the underlying cause of dementia praecox or manic-depressive illness, there could be no disease-specific treatment, and recommended the use of long baths and the occasional use of drugs such as opiates and barbiturates for the amelioration of distress, as well as occupational activities, where suitable, for all institutionalized patients. Based on his theory that dementia praecox is the product of autointoxication emanating from the sex glands, Kraepelin experimented, without success, with injections of thyroid, gonad and other glandular extracts.

Kraepelin noted the dissemination of his new disease concept when in 1899 he enumerated the term's appearance in almost twenty articles in the German-language medical press. In the early years of the twentieth century the twin pillars of the Kraepelinian dichotomy, dementia praecox and manic depressive psychosis, were assiduously adopted in clinical and research contexts among the Germanic psychiatric community. German-language psychiatric concepts were always introduced much faster in America (than, say, Britain) where émigré German, Swiss and Austrian physicians essentially created American psychiatry. Swiss-émigré Adolf Meyer (1866–1950), arguably the most influential psychiatrist in America for the first half of the 20th century, published the first critique of dementia praecox in an 1896 book review of the 5th edition of Kraepelin's textbook. But it was not until 1900 and 1901 that the first three American publications regarding dementia praecox appeared, one of which was a translation of a few sections of Kraepelin's 6th edition of 1899 on dementia praecox.

Adolf Meyer was the first to apply the new diagnostic term in America. He used it at the Worcester Lunatic Hospital in Massachusetts in the fall of 1896. He was also the first to apply Eugen Bleuler's term "schizophrenia" (in the form of "schizophrenic reaction") in 1913 at the Henry Phipps Psychiatric Clinic of the Johns Hopkins Hospital.

The dissemination of Kraepelin's disease concept to the Anglophone world was facilitated in 1902 when Ross Diefendorf, a lecturer in psychiatry at Yale, published an adapted version of the sixth edition of the . This was republished in 1904 and with a new version, based on the seventh edition of Kraepelin's appearing in 1907 and reissued in 1912. Both dementia praecox (in its three classic forms) and "manic-depressive psychosis" gained wider popularity in the larger institutions in the eastern United States after being included in the official nomenclature of diseases and conditions for record-keeping at Bellevue Hospital in New York City in 1903. The term lived on due to its promotion in the publications of the National Committee on Mental Hygiene (founded in 1909) and the Eugenics Records Office (1910). But perhaps the most important reason for the longevity of Kraepelin's term was its inclusion in 1918 as an official diagnostic category in the uniform system adopted for comparative statistical record-keeping in all American mental institutions, "The Statistical Manual for the Use of Institutions for the Insane". Its many revisions served as the official diagnostic classification scheme in America until 1952 when the first edition of the "Diagnostic and Statistical Manual: Mental Disorders", or DSM-I, appeared. Dementia praecox disappeared from official psychiatry with the publication of DSM-I, replaced by the Bleuler/Meyer hybridization, "schizophrenic reaction".

Schizophrenia was mentioned as an alternate term for dementia praecox in the 1918 "Statistical Manual". In both clinical work as well as research, between 1918 and 1952 five different terms were used interchangeably: dementia praecox, schizophrenia, dementia praecox (schizophrenia), schizophrenia (dementia praecox) and schizophrenic reaction. This made the psychiatric literature of the time confusing since, in a strict sense, Kraepelin's disease was not Bleuler's disease. They were defined differently, had different population parameters, and different concepts of prognosis.

The reception of dementia praecox as an accepted diagnosis in British psychiatry came more slowly, perhaps only taking hold around the time of World War I. There was substantial opposition to the use of the term "dementia" as misleading, partly due to findings of remission and recovery. Some argued that existing diagnoses such as "delusional insanity" or "adolescent insanity" were better or more clearly defined. In France a psychiatric tradition regarding the psychotic disorders predated Kraepelin, and the French never fully adopted Kraepelin's classification system. Instead the French maintained an independent classification system throughout the 20th century. From 1980, when DSM-III totally reshaped psychiatric diagnosis, French psychiatry began to finally alter its views of diagnosis to converge with the North American system. Kraepelin thus finally conquered France via America.

Due to the influence of alienists such as Adolf Meyer, August Hoch, George Kirby, Charles Macphie Campbell, Smith Ely Jelliffe and William Alanson White, psychogenic theories of dementia praecox dominated the American scene by 1911. In 1925 Bleuler's schizophrenia rose in prominence as an alternative to Kraepelin's dementia praecox. When Freudian perspectives became influential in American psychiatry in the 1920s schizophrenia became an attractive alternative concept. Bleuler corresponded with Freud and was connected to Freud's psychoanalytic movement, and the inclusion of Freudian interpretations of the symptoms of schizophrenia in his publications on the subject, as well as those of C.G. Jung, eased the adoption of his broader version of dementia praecox (schizophrenia) in America over Kraepelin's narrower and prognostically more negative one.

The term "schizophrenia" was first applied by American alienists and neurologists in private practice by 1909 and officially in institutional settings in 1913, but it took many years to catch on. It is first mentioned in "The New York Times" in 1925. Until 1952 the terms dementia praecox and schizophrenia were used interchangeably in American psychiatry, with occasional use of the hybrid terms "dementia praecox (schizophrenia)" or "schizophrenia (dementia praecox)".

Editions of the Diagnostic and Statistical Manual of Mental Disorders since the first in 1952 had reflected views of schizophrenia as "reactions" or "psychogenic" (DSM-I), or as manifesting Freudian notions of "defense mechanisms" (as in DSM-II of 1969 in which the symptoms of schizophrenia were interpreted as "psychologically self-protected"). The diagnostic criteria were vague, minimal and wide, including either concepts that no longer exist or that are now labeled as personality disorders (for example, schizotypal personality disorder). There was also no mention of the dire prognosis Kraepelin had made. Schizophrenia seemed to be more prevalent and more psychogenic and more treatable than either Kraepelin or Bleuler would have allowed.

As a direct result of the effort to construct Research Diagnostic Criteria in the 1970s that were independent of any clinical diagnostic manual, Kraepelin's idea that categories of mental disorder should reflect discrete and specific disease entities with a biological basis began to return to prominence. Vague dimensional approaches based on symptoms—so highly favored by the Meyerians and psychoanalysts—were overthrown. For research purposes, the definition of schizophrenia returned to the narrow range allowed by Kraepelin's dementia praecox concept. Furthermore, after 1980 the disorder was a progressively deteriorating one once again, with the notion that recovery, if it happened at all, was rare. This revision of schizophrenia became the basis of the diagnostic criteria in DSM-III (1980). Some of the psychiatrists who worked to bring about this revision referred to themselves as the "neo-Kraepelinians".




Dolphin

A dolphin is an aquatic mammal within the infraorder Cetacea. Dolphin species belong to the families Delphinidae (the oceanic dolphins), Platanistidae (the Indian river dolphins), Iniidae (the New World river dolphins), Pontoporiidae (the brackish dolphins), and possibly extinct Lipotidae (baiji or Chinese river dolphin). There are 40 extant species named as dolphins.

Dolphins range in size from the and Maui's dolphin to the and orca. Various species of dolphins exhibit sexual dimorphism where the males are larger than females. They have streamlined bodies and two limbs that are modified into flippers. Though not quite as flexible as seals, they are faster; some dolphins can briefly travel at speeds of or leap about . Dolphins use their conical teeth to capture fast-moving prey. They have well-developed hearing which is adapted for both air and water. It is so well developed that some can survive even if they are blind. Some species are well adapted for diving to great depths. They have a layer of fat, or blubber, under the skin to keep warm in the cold water.

Dolphins are widespread. Most species prefer the warm waters of the tropic zones, but some, such as the right whale dolphin, prefer colder climates. Dolphins feed largely on fish and squid, but a few, such as the orca, feed on large mammals such as seals. Male dolphins typically mate with multiple females every year, but females only mate every two to three years. Calves are typically born in the spring and summer months and females bear all the responsibility for raising them. Mothers of some species fast and nurse their young for a relatively long period of time. Dolphins produce a variety of vocalizations, usually in the form of clicks and whistles.

Dolphins are sometimes hunted in places such as Japan, in an activity known as dolphin drive hunting. Besides drive hunting, they also face threats from bycatch, habitat loss, and marine pollution. Dolphins have been depicted in various cultures worldwide. Dolphins are sometimes kept in captivity and trained to perform tricks. The most common dolphin species in captivity is the bottlenose dolphin, while there are around 60 orcas in captivity.

The name is originally from Greek ("delphís"), "dolphin", which was related to the Greek ("delphus"), "womb". The animal's name can therefore be interpreted as meaning "a 'fish' with a womb". The name was transmitted via the Latin "delphinus" (the romanization of the later Greek δελφῖνος – "delphinos"), which in Medieval Latin became and in Old French "daulphin", which reintroduced the "ph" into the word "dolphin". The term "mereswine" ("sea pig") has also historically been used.
The term "dolphin" can be used to refer to most species in the family Delphinidae (oceanic dolphins) and the river dolphin families of Iniidae (South American river dolphins), Pontoporiidae (La Plata dolphin), Lipotidae (Yangtze river dolphin) and Platanistidae (Ganges river dolphin and Indus river dolphin). Meanwhile, the mahi-mahi fish is called the dolphinfish. In common usage, the term "whale" is used only for the larger cetacean species, while the smaller ones with a beaked or longer nose are considered dolphins. The name "dolphin" is used casually as a synonym for bottlenose dolphin, the most common and familiar species of dolphin. There are six species of dolphins commonly thought of as whales, collectively known as blackfish: the orca, the melon-headed whale, the pygmy killer whale, the false killer whale, and the two species of pilot whales, all of which are classified under the family Delphinidae and qualify as dolphins. Although the terms "dolphin" and "porpoise" are sometimes used interchangeably, "porpoise" usually refers to the Phocoenidae family, which have a shorter beak and spade-shaped teeth and differ in their behavior.

A group of dolphins is called a "school" or a "pod". Male dolphins are called "bulls", females are called "cows" and young dolphins are called "calves".

In 1933, three hybrid dolphins beached off the Irish coast; they were hybrids between Risso's and bottlenose dolphins. This mating was later repeated in captivity, producing a hybrid calf. In captivity, a bottlenose and a rough-toothed dolphin produced hybrid offspring. A common-bottlenose hybrid lives at SeaWorld California. Other dolphin hybrids live in captivity around the world or have been reported in the wild, such as a bottlenose-Atlantic spotted hybrid. The best known hybrid is the wholphin, a false killer whale-bottlenose dolphin hybrid. The wolphin is a fertile hybrid. Two wolphins currently live at the Sea Life Park in Hawaii; the first was born in 1985 from a male false killer whale and a female bottlenose. Wolphins have also been observed in the wild.

Dolphins are descendants of land-dwelling mammals of the artiodactyl order (even-toed ungulates). They are related to the "Indohyus", an extinct chevrotain-like ungulate, from which they split approximately 48 million years ago.

The primitive cetaceans, or archaeocetes, first took to the sea approximately 49 million years ago and became fully aquatic by 5–10 million years later.

Archaeoceti is a parvorder comprising ancient whales. These ancient whales are the predecessors of modern whales, stretching back to their first ancestor that spent their lives near (rarely in) the water. Likewise, the archaeocetes can be anywhere from near fully terrestrial, to semi-aquatic to fully aquatic, but what defines an archaeocete is the presence of visible legs or asymmetrical teeth. Their features became adapted for living in the marine environment. Major anatomical changes include the hearing set-up that channeled vibrations from the jaw to the earbone which occurred with "Ambulocetus" 49 million years ago, a streamlining of the body and the growth of flukes on the tail which occurred around 43 million years ago with "Protocetus", the migration of the nasal openings toward the top of the cranium and the modification of the forelimbs into flippers which occurred with "Basilosaurus" 35 million years ago, and the shrinking and eventual disappearance of the hind limbs which took place with the first odontocetes and mysticetes 34 million years ago. The modern dolphin skeleton has two small, rod-shaped pelvic bones thought to be vestigial hind limbs. In October 2006, an unusual bottlenose dolphin was captured in Japan; it had small fins on each side of its genital slit, which scientists believe to be an unusually pronounced development of these vestigial hind limbs.

Today, the closest living relatives of cetaceans are the hippopotamuses; these share a semi-aquatic ancestor that branched off from other artiodactyls some 60 million years ago. Around 40 million years ago, a common ancestor between the two branched off into cetacea and anthracotheres; anthracotheres became extinct at the end of the Pleistocene two-and-a-half million years ago, eventually leaving only one surviving lineage: the two species of hippo.

Dolphins have torpedo-shaped bodies with generally non-flexible necks, limbs modified into flippers, a tail fin, and bulbous heads. Dolphin skulls have small eye orbits, long snouts, and eyes placed on the sides of its head; they lack external ear flaps. Dolphins range in size from the long and Maui's dolphin to the and orca. Overall, they tend to be dwarfed by other Cetartiodactyls. Several species have female-biased sexual dimorphism, with the females being larger than the males.

Dolphins have conical teeth, as opposed to porpoises' spade-shaped teeth. These conical teeth are used to catch swift prey such as fish, squid or large mammals, such as seals.

Breathing involves expelling stale air from their blowhole, in an upward blast, which may be visible in cold air, followed by inhaling fresh air into the lungs. Dolphins have rather small, unidentifiable spouts.

All dolphins have a thick layer of blubber, thickness varying on climate. This blubber can help with buoyancy, protection to some extent as predators would have a hard time getting through a thick layer of fat, and energy for leaner times; the primary usage for blubber is insulation from the harsh climate. Calves, generally, are born with a thin layer of blubber, which develops at different paces depending on the habitat.

Dolphins have a two-chambered stomach that is similar in structure to terrestrial carnivores. They have fundic and pyloric chambers.

Dolphins' reproductive organs are located inside the body, with genital slits on the ventral (belly) side. Males have two slits, one concealing the penis and one further behind for the anus. Females have one genital slit, housing the vagina and the anus, with a mammary slit on either side.

The integumentary system is an organ system mostly consisted of skin, hair, nails and endocrine glands. The skin of dolphins is very important as it is specialized to satisfy specific requirements. Some of these requirements include protection, fat storage, heat regulation, and sensory perception. The skin of a dolphin is made up of two parts: the epidermis and the blubber, which consists of two layers including the dermis and subcutis.
The dolphin's skin is known to have a smooth rubber texture and is without hair and glands, except mammary glands. At birth, a newborn dolphin has hairs lined up in a single band on both sides of the rostrum, which is their jaw, and usually has a total length of 16–17 cm .
Dolphins are a part of the species Cetacea. The epidermis of this species is characterized by the lack of keratin and by a prominent intertwine of epidermal rete pegs and long dermal papillae. The epidermal rete pegs are the epithelial extensions that project into the underlying connective tissue in both skin and mucous membranes. The dermal papillae are finger-like projections that help adhesion between the epidermal and dermal layers, as well as providing a larger surface area to nourish the epidermal layer. The thickness of a dolphin's epidermis varies, depending on species and age.

Blubber is found within the dermis and subcutis layer. The dermis blends gradually with the adipose layer, which is known as fat, because the fat may extend up to the epidermis border and collagen fiber bundles extend throughout the whole subcutaneous blubber which is fat found under the skin. The thickness of the subcutaneous blubber or fat depends on the dolphin's health, development, location, reproductive state, and how well it feeds. This fat is thickest on the dolphin's back and belly. Most of the dolphin's body fat is accumulated in a thick layer of blubber. Blubber differs from fat in that, in addition to fat cells, it contains a fibrous network of connective tissue.

The blubber functions to streamline the body and to form specialized locomotor structures such as the dorsal fin, propulsive fluke blades and caudal keels. There are many nerve endings that resemble small, onion-like configurations that are present in the superficial portion of the dermis. Mechanoreceptors are found within the interlocks of the epidermis with dermal ridges. There are nerve fibers in the dermis that extend to the epidermis. These nerve endings are known to be highly proprioceptive, which explains sensory perception. Proprioception, which is also known as kinesthesia, is the body's ability to sense its location, movements and actions. Dolphins are sensitive to vibrations and small pressure changes.
Blood vessels and nerve endings can be found within the dermis. There is a plexus of parallel running arteries and veins in the dorsal fin, fluke, and flippers. The blubber manipulates the blood vessels to help the dolphin stay warm. When the temperature drops, the blubber constricts the blood vessels to reduce blood flow in the dolphin. This allows the dolphin to spend less energy heating its own body, ultimately keeping the animal warmer without burning energy as quick. In order to release heat, the heat must pass the blubber layer. There are thermal windows that lack blubber, are not fully insulated and are somewhat thin and highly vascularized, including the dorsal fin, flukes, and flippers. These thermal windows are a good way for dolphins to get rid of excess heat if overheating. Additionally in order to conserve heat, dolphins use countercurrent heat exchange. Blood flows in different directions in order for heat to transfer across membranes. Heat from warm blood leaving the heart will heat up the cold blood that is headed back to the heart from the extremities, meaning that the heart always has warm blood and it decreases the heat lost to the water in those thermal windows.

Dolphins have two pectoral flippers, each containing four digits, a boneless dorsal fin for stability, and a fluke for propulsion. Although dolphins do not possess external hind limbs, some possess discrete rudimentary appendages, which may contain feet and digits. Orcas are fast swimmers in comparison to seals which typically cruise at ; the orca, in comparison, can travel at speeds up to . A study of a Pacific white-sided dolphin in an aquarium found fast burst acceleration, with the individual being able with 5 strokes (2.5 fluke beats) to go from 5.0 m s-1 to 8.7 m s-1 in 0.7 seconds.

The fusing of the neck vertebrae, while increasing stability when swimming at high speeds, decreases flexibility, which means most dolphins are unable to turn their heads. River dolphins have non-fused neck vertebrae and can turn their heads up to 90°. Dolphins swim by moving their fluke and rear body vertically, while their flippers are mainly used for steering. Some species porpoise out of the water, which allows them to travel faster. Their skeletal anatomy allows them to be fast swimmers. All species have a dorsal fin to prevent themselves from involuntarily spinning in the water.

Some dolphins are adapted for diving to great depths. In addition to their streamlined bodies, some can selectively slow their heart rate to conserve oxygen. Some can also re-route blood from tissue tolerant of water pressure to the heart, brain and other organs. Their hemoglobin and myoglobin store oxygen in body tissues, and they have twice as much myoglobin as hemoglobin.

A dolphin ear has specific adaptations to the marine environment. In humans, the middle ear works as an impedance equalizer between the outside air's low impedance and the cochlear fluid's high impedance. In dolphins, and other marine mammals, there is no great difference between the outer and inner environments. Instead of sound passing through the outer ear to the middle ear, dolphins receive sound through the throat, from which it passes through a low-impedance fat-filled cavity to the inner ear. The ear is acoustically isolated from the skull by air-filled sinus pockets, which allow for greater directional hearing underwater. Dolphins send out high frequency clicks from an organ known as a melon. This melon consists of fat, and the skull of any such creature containing a melon will have a large depression. This allows dolphins to use echolocation for orientation. Though most dolphins do not have hair, they do have hair follicles that may perform some sensory function. Beyond locating an object, echolocation also provides the animal with an idea on an object's shape and size, though how exactly this works is not yet understood. The small hairs on the rostrum of the boto (river dolphins of South America) are believed to function as a tactile sense, possibly to compensate for the boto's poor eyesight.

A dolphin eye is relatively small for its size, yet they do retain a good degree of eyesight. As well as this, the eyes of a dolphin are placed on the sides of its head, so their vision consists of two fields, rather than a binocular view like humans have. When dolphins surface, their lens and cornea correct the nearsightedness that results from the water's refraction of light. Their eyes contain both rod and cone cells, meaning they can see in both dim and bright light, but they have far more rod cells than they do cone cells. They lack short wavelength sensitive visual pigments in their cone cells, indicating a more limited capacity for color vision than most mammals. Most dolphins have slightly flattened eyeballs, enlarged pupils (which shrink as they surface to prevent damage), slightly flattened corneas and a "tapetum lucidum" (eye tissue behind the retina); these adaptations allow for large amounts of light to pass through the eye and, therefore, a very clear image of the surrounding area. They also have glands on the eyelids and outer corneal layer that act as protection for the cornea.

The olfactory lobes and nerve are absent in dolphins, suggesting that they have no sense of smell.

Dolphins are not thought to have a good sense of taste, as their taste buds are atrophied or missing altogether. Some have preferences for different kinds of fish, indicating some ability to taste.

Dolphins are known to teach, learn, cooperate, scheme, and grieve. The neocortex of many species is home to elongated spindle neurons that, prior to 2007, were known only in hominids. In humans, these cells are involved in social conduct, emotions, judgment, and theory of mind. Cetacean spindle neurons are found in areas of the brain that are analogous to where they are found in humans, suggesting that they perform a similar function.

Brain size was previously considered a major indicator of the intelligence of an animal. Since most of the brain is used for maintaining bodily functions, greater ratios of brain to body mass may increase the amount of brain mass available for more complex cognitive tasks. Allometric analysis indicates that mammalian brain size scales at approximately the ⅔ or ¾ exponent of the body mass. Comparison of a particular animal's brain size with the expected brain size based on such allometric analysis provides an encephalization quotient that can be used as another indication of animal intelligence. Orcas have the second largest brain mass of any animal on earth, next to the sperm whale. The brain to body mass ratio in some is second only to humans.

Self-awareness is seen, by some, to be a sign of highly developed, abstract thinking. Self-awareness, though not well-defined scientifically, is believed to be the precursor to more advanced processes like meta-cognitive reasoning (thinking about thinking) that are typical of humans. Research in this field has suggested that cetaceans, among others, possess self-awareness.
The most widely used test for self-awareness in animals is the mirror test in which a mirror is introduced to an animal, and the animal is then marked with a temporary dye. If the animal then goes to the mirror in order to view the mark, it has exhibited strong evidence of self-awareness.

Some disagree with these findings, arguing that the results of these tests are open to human interpretation and susceptible to the Clever Hans effect. This test is much less definitive than when used for primates, because primates can touch the mark or the mirror, while cetaceans cannot, making their alleged self-recognition behavior less certain. Skeptics argue that behaviors that are said to identify self-awareness resemble existing social behaviors, and so researchers could be misinterpreting self-awareness for social responses to another individual. The researchers counter-argue that the behaviors shown are evidence of self-awareness, as they are very different from normal responses to another individual. Whereas apes can merely touch the mark on themselves with their fingers, cetaceans show less definitive behavior of self-awareness; they can only twist and turn themselves to observe the mark.

In 1995, Marten and Psarakos used television to test dolphin self-awareness. They showed dolphins real-time video of themselves, video of another dolphin and recorded footage. They concluded that their evidence suggested self-awareness rather than social behavior. While this particular study has not been repeated since then, dolphins have since passed the mirror test. Some researchers have argued that evidence for self-awareness has not been convincingly demonstrated.

Dolphins are highly social animals, often living in pods of up to a dozen individuals, though pod sizes and structures vary greatly between species and locations. In places with a high abundance of food, pods can merge temporarily, forming a "superpod"; such groupings may exceed 1,000 dolphins. Membership in pods is not rigid; interchange is common. They establish strong social bonds, and will stay with injured or ill members, helping them to breathe by bringing them to the surface if needed. This altruism does not appear to be limited to their own species. The dolphin "Moko" in New Zealand has been observed guiding a female pygmy sperm whale together with her calf out of shallow water where they had stranded several times. They have also been seen protecting swimmers from sharks by swimming circles around the swimmers or charging the sharks to make them go away.

Dolphins communicate using a variety of clicks, whistle-like sounds and other vocalizations. Dolphins also use nonverbal communication by means of touch and posturing.

Dolphins also display culture, something long believed to be unique to humans (and possibly other primate species). In May 2005, a discovery in Australia found Indo-Pacific bottlenose dolphins ("Tursiops aduncus") teaching their young to use tools. They cover their snouts with sponges to protect them while foraging. This knowledge is mostly transferred by mothers to daughters, unlike simian primates, where knowledge is generally passed on to both sexes. Using sponges as mouth protection is a learned behavior. Another learned behavior was discovered among river dolphins in Brazil, where some male dolphins use weeds and sticks as part of a sexual display.

Forms of care-giving between fellows and even for members of different species(see Moko (dolphin)) are recorded in various species – such as trying to save weakened fellows or female pilot whales holding up dead calves for long periods.

Dolphins engage in acts of aggression towards each other. The older a male dolphin is, the more likely his body is to be covered with bite scars. Male dolphins can get into disputes over companions and females. Acts of aggression can become so intense that targeted dolphins sometimes go into exile after losing a fight.

Male bottlenose dolphins have been known to engage in infanticide. Dolphins have also been known to kill porpoises (porpicide) for reasons which are not fully understood, as porpoises generally do not share the same diet as dolphins and are therefore not competitors for food supplies. The Cornwall Wildlife Trust records about one such death a year. Possible explanations include misdirected infanticide, misdirected sexual aggression or play behaviour.

Dolphin copulation happens belly to belly; though many species engage in lengthy foreplay, the actual act is usually brief, but may be repeated several times within a short timespan. The gestation period varies with species; for the small tucuxi dolphin, this period is around 11 to 12 months, while for the orca, the gestation period is around 17 months. Typically dolphins give birth to a single calf, which is, unlike most other mammals, born tail first in most cases. They usually become sexually active at a young age, even before reaching sexual maturity. The age of sexual maturity varies by species and sex.

Dolphins are known to display non-reproductive sexual behavior, engaging in masturbation, stimulation of the genital area of other individuals using the rostrum or flippers, and homosexual contact.

Various species of dolphin have been known to engage in sexual behavior including copulation with dolphins of other species, and occasionally exhibit sexual behavior towards other animals, including humans. Sexual encounters may be violent, with male bottlenose dolphins sometimes showing aggressive behavior towards both females and other males. Male dolphins may also work together and attempt to herd females in estrus, keeping the females by their side by means of both physical aggression and intimidation, to increase their chances of reproductive success.

Generally, dolphins sleep with only one brain hemisphere in slow-wave sleep at a time, thus maintaining enough consciousness to breathe and to watch for possible predators and other threats. Sleep stages earlier in sleep can occur simultaneously in both hemispheres.
In captivity, dolphins seemingly enter a fully asleep state where both eyes are closed and there is no response to mild external stimuli. In this case, respiration is automatic; a tail kick reflex keeps the blowhole above the water if necessary. Anesthetized dolphins initially show a tail kick reflex. Though a similar state has been observed with wild sperm whales, it is not known if dolphins in the wild reach this state. The Indus river dolphin has a sleep method that is different from that of other dolphin species. Living in water with strong currents and potentially dangerous floating debris, it must swim continuously to avoid injury. As a result, this species sleeps in very short bursts which last between 4 and 60 seconds.

There are various feeding methods among and within species, some apparently exclusive to a single population. Fish and squid are the main food, but the false killer whale and the orca also feed on other marine mammals. Orcas on occasion also hunt whale species larger than themselves. Different breeds of dolphins vary widely in the number of teeth they possess. The orca usually carries 40–56 teeth while the popular bottlenose dolphin has anywhere from 72 to 116 conical teeth and its smaller cousin the common dolphin has 188–268 teeth: the number of teeth that an individual carries varies widely between within a single species. Hybrids between common and bottlenose bred in captivity had a number of teeth intermediate between that of their parents.

One common feeding method is herding, where a pod squeezes a school of fish into a small volume, known as a bait ball. Individual members then take turns plowing through the ball, feeding on the stunned fish. Corralling is a method where dolphins chase fish into shallow water to catch them more easily. Orcas and bottlenose dolphins have also been known to drive their prey onto a beach to feed on it, a behaviour known as beach or strand feeding. Some species also whack fish with their flukes, stunning them and sometimes knocking them out of the water.

Reports of cooperative human-dolphin fishing date back to the ancient Roman author and natural philosopher Pliny the Elder. A modern human-dolphin partnership currently operates in Laguna, Santa Catarina, Brazil. Here, dolphins drive fish towards fishermen waiting along the shore and signal the men to cast their nets. The dolphins' reward is the fish that escape the nets.

In Shark Bay, Australia, dolphins catch fish by trapping them in huge conch shells. In "shelling", a dolphin brings the shell to the surface and shakes it, so that fish sheltering within fall into the dolphin's mouth. From 2007 to 2018, in 5,278 encounters with dolphins, researchers observed 19 dolphins shelling 42 times. The behavior spreads mainly within generations, rather than being passed from mother to offspring.

Dolphins are capable of making a broad range of sounds using nasal airsacs located just below the blowhole. Roughly three categories of sounds can be identified: frequency modulated whistles, burst-pulsed sounds, and clicks. Dolphins communicate with whistle-like sounds produced by vibrating connective tissue, similar to the way human vocal cords function, and through burst-pulsed sounds, though the nature and extent of that ability is not known. The clicks are directional and are for echolocation, often occurring in a short series called a click train. The click rate increases when approaching an object of interest. Dolphin echolocation clicks are amongst the loudest sounds made by marine animals.

Bottlenose dolphins have been found to have signature whistles, a whistle that is unique to a specific individual. These whistles are used in order for dolphins to communicate with one another by identifying an individual. It can be seen as the dolphin equivalent of a name for humans. These signature whistles are developed during a dolphin's first year; it continues to maintain the same sound throughout its lifetime. In order to obtain each individual whistle sound, dolphins undergo vocal production learning. This consists of an experience with other dolphins that modifies the signal structure of an existing whistle sound. An auditory experience influences the whistle development of each dolphin. Dolphins are able to communicate to one another by addressing another dolphin through mimicking their whistle. The signature whistle of a male bottlenose dolphin tends to be similar to that of his mother, while the signature whistle of a female bottlenose dolphin tends to be more distinguishing. Bottlenose dolphins have a strong memory when it comes to these signature whistles, as they are able to relate to a signature whistle of an individual they have not encountered for over twenty years. Research done on signature whistle usage by other dolphin species is relatively limited. The research on other species done so far has yielded varied outcomes and inconclusive results.

Because dolphins are generally associated in groups, communication is necessary. Signal masking is when other similar sounds (conspecific sounds) interfere with the original acoustic sound. In larger groups, individual whistle sounds are less prominent. Dolphins tend to travel in pods, upon which there are groups of dolphins that range from a few to many. Although they are traveling in these pods, the dolphins do not necessarily swim right next to each other. Rather, they swim within the same general vicinity. In order to prevent losing one of their pod members, there are higher whistle rates. Because their group members were spread out, this was done in order to continue traveling together.

Dolphins frequently leap above the water surface, this being done for various reasons. When travelling, jumping can save the dolphin energy as there is less friction while in the air. This type of travel is known as porpoising. Other reasons include orientation, social displays, fighting, non-verbal communication, entertainment and attempting to dislodge parasites.

Dolphins show various types of playful behavior, often including objects, self-made bubble rings, other dolphins or other animals. When playing with objects or small animals, common behavior includes carrying the object or animal along using various parts of the body, passing it along to other members of the group or taking it from another member, or throwing it out of the water. Dolphins have also been observed harassing animals in other ways, for example by dragging birds underwater without showing any intent to eat them. Playful behaviour that involves another animal species with active participation of the other animal has also been observed. Playful dolphin interactions with humans are the most obvious examples, followed by those with humpback whales and dogs.

Juvenile dolphins off the coast of Western Australia have been observed chasing, capturing, and chewing on blowfish. While some reports state that the dolphins are becoming intoxicated on the tetrodotoxin in the fishes' skin, other reports have characterized this behavior as the normal curiosity and exploration of their environment in which dolphins engage.

Although this behaviour is highly unusual in wild dolphins, several Indo-Pacific bottlenose dolphins ("Tursiops aduncus") of the Port River, north of Adelaide, South Australia, have been seen to have exhibit "tail-walking". This activity mimicks a standing posture, using the tail to run backwards along the water. To perform this movement, the dolphin "forces the majority of its body vertically out of the water and maintains the position by vigorously pumping its tail".

This started in 1988 when a female named Billie was rescued after becoming trapped in a polluted marina, and spent two weeks recuperating with captive dolphins. Billie had previously been observed swimming and frolicking with racehorses exercising in the Port River in the 1980s. After becoming trapped in a reedy estuary further down the coast, she was rescued and placed with several captive dolphins at a marine park to recuperate. There she observed the captive dolphins performing tail-walking. After being returned to the Port River, she continued to perform this trick, and another dolphin, Wave, copied her. Wave, a very active tail-walker, passed on the skill to her daughters, Ripple and Tallula.

After Billie's premature death, Wave started tail-walking much more frequently, and other dolphins in the group were observed also performing the behaviour. In 2011, up to 12 dolphins were observed tail-walking, but only females appeared to learn the skill. In October 2021, a dolphin was observed tail-walking over a number of hours.

Scientists have found the spread of this behaviour, through up to two generations, surprising, as it brings no apparent advantage, and is very energy-consuming. A 2018 study by Mike Rossley et al. suggested:

Dolphins have few marine enemies. Some species or specific populations have none, making them apex predators. For most of the smaller species of dolphins, only a few of the larger sharks, such as the bull shark, dusky shark, tiger shark and great white shark, are a potential risk, especially for calves. Some of the larger dolphin species, especially orcas, may also prey on smaller dolphins, but this seems rare. Dolphins also suffer from a wide variety of diseases and parasites. The Cetacean morbillivirus in particular has been known to cause regional epizootics often leaving hundreds of animals of various species dead. Symptoms of infection are often a severe combination of pneumonia, encephalitis and damage to the immune system, which greatly impair the cetacean's ability to swim and stay afloat unassisted. A study at the U.S. National Marine Mammal Foundation revealed that dolphins, like humans, develop a natural form of type 2 diabetes which may lead to a better understanding of the disease and new treatments for both humans and dolphins.

Dolphins can tolerate and recover from extreme injuries such as shark bites although the exact methods used to achieve this are not known. The healing process is rapid and even very deep wounds do not cause dolphins to hemorrhage to death. Furthermore, even gaping wounds restore in such a way that the animal's body shape is restored, and infection of such large wounds seems rare.

A study published in the journal "Marine Mammal Science" suggests that at least some dolphins survive shark attacks using everything from sophisticated combat moves to teaming up against the shark.

Some dolphin species are at risk of extinction, especially some river dolphin species such as the Amazon river dolphin, and the Ganges and Yangtze river dolphin, which are critically or seriously endangered. A 2006 survey found no individuals of the Yangtze river dolphin. The species now appears to be functionally extinct.

Pesticides, heavy metals, plastics, and other industrial and agricultural pollutants that do not disintegrate rapidly in the environment concentrate in predators such as dolphins. Injuries or deaths due to collisions with boats, especially their propellers, are also common.

Various fishing methods, most notably purse seine fishing for tuna and the use of drift and gill nets, unintentionally kill many dolphins. Accidental by-catch in gill nets and incidental captures in antipredator nets that protect marine fish farms are common and pose a risk for mainly local dolphin populations. In some parts of the world, such as Taiji in Japan and the Faroe Islands, dolphins are traditionally considered food and are killed in harpoon or drive hunts. Dolphin meat is high in mercury and may thus pose a health danger to humans when consumed.

Queensland's shark culling program, which has killed roughly 50,000 sharks since 1962, has also killed thousands of dolphins as bycatch. "Shark control" programs in both Queensland and New South Wales use shark nets and drum lines, which entangle and kill dolphins. Queensland's "shark control" program has killed more than 1,000 dolphins in recent years, and at least 32 dolphins have been killed in Queensland since 2014. A shark culling program in KwaZulu-Natal has killed at least 2,310 dolphins.

Dolphin safe labels attempt to reassure consumers that fish and other marine products have been caught in a dolphin-friendly way. The earliest campaigns with "dolphin safe" labels were initiated in the 1980s as a result of cooperation between marine activists and the major tuna companies, and involved decreasing incidental dolphin kills by up to 50% by changing the type of nets used to catch tuna. The dolphins are netted only while fishermen are in pursuit of smaller tuna. Albacore are not netted this way, making albacore the only truly dolphin-safe tuna.
Loud underwater noises, such as those resulting from naval sonar use, live firing exercises, and certain offshore construction projects such as wind farms, may be harmful to dolphins, increasing stress, damaging hearing, and causing decompression sickness by forcing them to surface too quickly to escape the noise.

Dolphins and other smaller cetaceans are also hunted in an activity known as dolphin drive hunting. This is accomplished by driving a pod together with boats and usually into a bay or onto a beach. Their escape is prevented by closing off the route to the ocean with other boats or nets. Dolphins are hunted this way in several places around the world, including the Solomon Islands, the Faroe Islands, Peru, and Japan, the most well-known practitioner of this method. By numbers, dolphins are mostly hunted for their meat, though some end up in dolphinariums. Despite the controversial nature of the hunt resulting in international criticism, and the possible health risk that the often polluted meat causes, thousands of dolphins are caught in drive hunts each year.

Dolphins are marine mammals with broad geographic extent, making them susceptible to climate change in various ways. The most common effect of climate change on dolphins is the increasing water temperatures across the globe. This has caused a large variety of dolphin species to experience range shifts, in which the species move from their typical geographic region to cooler waters. Another side effect of increasing water temperatures is the increase in harmful algae blooms, which has caused a mass die-off of bottlenose dolphins.

In California, the 1982–83 El Niño warming event caused the near-bottom spawning market squid to leave southern California, which caused their predator, the pilot whale, to also leave. As the market squid returned six years later, Risso's dolphins came to feed on the squid. Bottlenose dolphins expanded their range from southern to central California, and stayed even after the warming event subsided. The Pacific white-sided dolphin has had a decline in population in the southwest Gulf of California, the southern boundary of their distribution. In the 1980s they were abundant with group sizes up to 200 across the entire cool season. Then, in the 2000s, only two groups were recorded with sizes of 20 and 30, and only across the central cool season. This decline was not related to a decline of other marine mammals or prey, so it was concluded to have been caused by climate change as it occurred during a period of warming. Additionally, the Pacific white-sided dolphin had an increase in occurrence on the west coast of Canada from 1984 to 1998.

In the Mediterranean, sea surface temperatures have increased, as well as salinity, upwelling intensity, and sea levels. Because of this, prey resources have been reduced causing a steep decline in the short-beaked common dolphin Mediterranean subpopulation, which was deemed endangered in 2003. This species now only exists in the Alboran Sea, due to its high productivity, distinct ecosystem, and differing conditions from the rest of the Mediterranean.

In northwest Europe, many dolphin species have experienced range shifts from the region's typically colder waters. Warm water dolphins, like the short-beaked common dolphin and striped dolphin, have expanded north of western Britain and into the northern North Sea, even in the winter, which may displace the white-beaked and Atlantic white-sided dolphin that are in that region. The white-beaked dolphin has shown an increase in the southern North Sea since the 1960s because of this. The rough-toothed dolphin and Atlantic spotted dolphin may move to northwest Europe. In northwest Scotland, white-beaked dolphins (local to the colder waters of the North Atlantic) have decreased while common dolphins (local to warmer waters) have increased from 1992 to 2003. Additionally, Fraser's dolphin, found in tropical waters, was recorded in the UK for the first time in 1996.

River dolphins are highly affected by climate change as high evaporation rates, increased water temperatures, decreased precipitation, and increased acidification occur. River dolphins typically have a higher densities when rivers have a lox index of freshwater degradation and better water quality. Specifically looking at the Ganges river dolphin, the high evaporation rates and increased flooding on the plains may lead to more human river regulation, decreasing the dolphin population.

As warmer waters lead to a decrease in dolphin prey, this led to other causes of dolphin population decrease. In the case of bottlenose dolphins, mullet populations decrease due to increasing water temperatures, which leads to a decrease in the dolphins' health and thus their population. At the Shark Bay World Heritage Area in Western Australia, the local Indo-Pacific bottlenose dolphin population had a significant decline after a marine heatwave in 2011. This heatwave caused a decrease in prey, which led to a decline in dolphin reproductive rates as female dolphins could not get enough nutrients to sustain a calf. The resultant decrease in fish population due to warming waters has also influenced humans to see dolphins as fishing competitors or even bait. Humans use dusky dolphins as bait or are killed off because they consume the same fish humans eat and sell for profit. In the central Brazilian Amazon alone, approximately 600 pink river dolphins are killed each year to be used as bait. 

Dolphins have long played a role in human culture.

In Greek myths, dolphins were seen invariably as helpers of humankind. Dolphins also seem to have been important to the Minoans, judging by artistic evidence from the ruined palace at Knossos. During the 2009 excavations of a major Mycenaean city at Iklaina, a striking fragment of a wall-paintings came to light, depicting a ship with three human figures and dolphins. Dolphins are common in Greek mythology, and many coins from ancient Greece have been found which feature a man, a boy or a deity riding on the back of a dolphin. The Ancient Greeks welcomed dolphins; spotting dolphins riding in a ship's wake was considered a good omen. In both ancient and later art, Cupid is often shown riding a dolphin. A dolphin rescued the poet Arion from drowning and carried him safe to land, at Cape Matapan, a promontory forming the southernmost point of the Peloponnesus. There was a temple to Poseidon and a statue of Arion riding the dolphin.

The Greeks reimagined the Phoenician god Melqart as Melikertês (Melicertes) and made him the son of Athamas and Ino. He drowned but was transfigured as the marine deity Palaemon, while his mother became Leucothea. ("cf" Ino.) At Corinth, he was so closely connected with the cult of Poseidon that the Isthmian Games, originally instituted in Poseidon's honor, came to be looked upon as the funeral games of Melicertes. Phalanthus was another legendary character brought safely to shore (in Italy) on the back of a dolphin, according to Pausanias.

Dionysus was once captured by Etruscan pirates who mistook him for a wealthy prince they could ransom. After the ship set sail Dionysus invoked his divine powers, causing vines to overgrow the ship where the mast and sails had been. He turned the oars into serpents, so terrifying the sailors that they jumped overboard, but Dionysus took pity on them and transformed them into dolphins so that they would spend their lives providing help for those in need. Dolphins were also the messengers of Poseidon and sometimes did errands for him as well. Dolphins were sacred to both Aphrodite and Apollo.

"Dolfin" was the name of an aristocratic family in the maritime Republic of Venice, whose most prominent member was the 13th-century Doge Giovanni Dolfin.

In Hindu mythology the Ganges river dolphin is associated with Ganga, the deity of the Ganges river. The dolphin is said to be among the creatures which heralded the goddess' descent from the heavens and her mount, the Makara, is sometimes depicted as a dolphin.

The Boto, a species of river dolphin that resides in the Amazon River, are believed to be shapeshifters, or "encantados", who are capable of having children with human women.

There are comparatively few surviving myths of dolphins in Polynesian cultures, in spite of their maritime traditions and reverence of other marine animals such as sharks and seabirds; unlike these, they are more often perceived as food than as totemic symbols. Dolphins are most clearly represented in Rapa Nui Rongorongo, and in the traditions of the Caroline Islands they are depicted similarly to the Boto, being sexually active shapeshifters.

Dolphins are also used as symbols, for instance in heraldry. When heraldry developed in the Middle Ages, little was known about the biology of the dolphin and it was often depicted as a sort of fish. The stylised heraldic dolphin still conventionally follows this tradition, sometimes showing the dolphin skin covered with fish scales.

A well-known historical example was the coat of arms of the former province of the Dauphiné in southern France, from which were derived the arms and the title of the Dauphin of France, the heir to the former throne of France (the title literally meaning "The Dolphin of France").

Dolphins are present in the coat of arms of Anguilla and the coat of arms of Romania, and the coat of arms of Barbados has a dolphin supporter.

The coat of arms of the town of Poole, Dorset, England, first recorded in 1563, includes a dolphin, which was historically depicted in stylised heraldic form, but which since 1976 has been depicted naturalistically.

The renewed popularity of dolphins in the 1960s resulted in the appearance of many dolphinaria around the world, making dolphins accessible to the public. Criticism and animal welfare laws forced many to close, although hundreds still exist around the world. In the United States, the best known are the SeaWorld marine mammal parks.
In the Middle East the best known are Dolphin Bay at Atlantis, The Palm and the Dubai Dolphinarium.
Various species of dolphins are kept in captivity. These small cetaceans are more often than not kept in theme parks, such as SeaWorld, commonly known as a dolphinarium. Bottlenose dolphins are the most common species of dolphin kept in dolphinariums as they are relatively easy to train, have a long lifespan in captivity and have a friendly appearance. Hundreds if not thousands of bottlenose dolphins live in captivity across the world, though exact numbers are hard to determine. Other species kept in captivity are spotted dolphins, false killer whales and common dolphins, Commerson's dolphins, as well as rough-toothed dolphins, but all in much lower numbers than the bottlenose dolphin. There are also fewer than ten pilot whales, Amazon river dolphins, Risso's dolphins, spinner dolphins, or tucuxi in captivity. An unusual and very rare hybrid dolphin, known as a wolphin, is kept at the Sea Life Park in Hawaii, which is a cross between a bottlenose dolphin and a false killer whale.

The number of orcas kept in captivity is very small, especially when compared to the number of bottlenose dolphins, with 60 captive orcas being held in aquaria . The orca's intelligence, trainability, striking appearance, playfulness in captivity and sheer size have made it a popular exhibit at aquaria and aquatic theme parks. From 1976 to 1997, 55 whales were taken from the wild in Iceland, 19 from Japan, and three from Argentina. These figures exclude animals that died during capture. Live captures fell dramatically in the 1990s, and by 1999, about 40% of the 48 animals on display in the world were captive-born.

Organizations such as the Mote Marine Laboratory rescue and rehabilitate sick, wounded, stranded or orphaned dolphins while others, such as the Whale and Dolphin Conservation and Hong Kong Dolphin Conservation Society, work on dolphin conservation and welfare. India has declared the dolphin as its national aquatic animal in an attempt to protect the endangered Ganges river dolphin. The Vikramshila Gangetic Dolphin Sanctuary has been created in the Ganges river for the protection of the animals.

There is debate over the welfare of cetaceans in captivity, and often welfare can vary greatly dependent on the levels of care being provided at a particular facility. In the United States, facilities are regularly inspected by federal agencies to ensure that a high standard of welfare is maintained. Additionally, facilities can apply to become accredited by the Association of Zoos and Aquariums (AZA), which (for accreditation) requires "the highest standards of animal care and welfare in the world" to be achieved. Facilities such as SeaWorld and the Georgia Aquarium are accredited by the AZA. Organizations such as World Animal Protection and the Whale and Dolphin Conservation campaign against the practice of keeping them in captivity. In captivity, they often develop pathologies, such as the dorsal fin collapse seen in 60–90% of male orca. Captives have vastly reduced life expectancies, on average only living into their 20s, although there are examples of orcas living longer, including several over 30 years old, and two captive orcas, Corky II and Lolita, are in their mid-40s. In the wild, females who survive infancy live 46 years on average, and up to 70–80 years in rare cases. Wild males who survive infancy live 31 years on average, and up to 50–60 years. Captivity usually bears little resemblance to wild habitat, and captive whales' social groups are foreign to those found in the wild. Critics claim captive life is stressful due to these factors and the requirement to perform circus tricks that are not part of wild orca behavior. Wild orcas may travel up to in a day, and critics say the animals are too big and intelligent to be suitable for captivity. Captives occasionally act aggressively towards themselves, their tankmates, or humans, which critics say is a result of stress.

Although dolphins generally interact well with humans, some attacks have occurred, most of them resulting in small injuries. Orcas, the largest species of dolphin, have been involved in fatal attacks on humans in captivity. The record-holder of documented orca fatal attacks is a male named Tilikum, who lived at SeaWorld from 1992 until his death in 2017. Tilikum has played a role in the death of three people in three different incidents (1991, 1999 and 2010). Tilikum's behaviour sparked the production of the documentary "Blackfish", which focuses on the consequences of keeping orcas in captivity. There are documented incidents in the wild, too, but none of them fatal.

Fatal attacks from other species are less common, but there is a registered occurrence off the coast of Brazil in 1994, when a man died after being attacked by a bottlenose dolphin named Tião. Tião had suffered harassment by human visitors, including attempts to stick ice cream sticks down his blowhole. Non-fatal incidents occur more frequently, both in the wild and in captivity.

While dolphin attacks occur far less frequently than attacks by other sea animals, such as sharks, some scientists are worried about the careless programs of human-dolphin interaction. Dr. Andrew J. Read, a biologist at the Duke University Marine Laboratory who studies dolphin attacks, points out that dolphins are large and wild predators, so people should be more careful when they interact with them.

Several scientists who have researched dolphin behaviour have proposed that dolphins' unusually high intelligence in comparison to other animals means that dolphins should be seen as non-human persons who should have their own specific rights and that it is morally unacceptable to keep them captive for entertainment purposes or to kill them either intentionally for consumption or unintentionally as by-catch. Four countries – Chile, Costa Rica, Hungary, and India – have declared dolphins to be "non-human persons" and have banned the capture and import of live dolphins for entertainment.

A number of militaries have employed dolphins for various purposes from finding mines to rescuing lost or trapped humans. The military use of dolphins drew scrutiny during the Vietnam War, when rumors circulated that the United States Navy was training dolphins to kill Vietnamese divers. The United States Navy denies that at any point dolphins were trained for combat. Dolphins are still being trained by the United States Navy for other tasks as part of the U.S. Navy Marine Mammal Program. The Russian military is believed to have closed its marine mammal program in the early 1990s. In 2000 the press reported that dolphins trained to kill by the Soviet Navy had been sold to Iran.

The military is also interested in disguising underwater communications as artificial dolphin clicks.

Dolphins are an increasingly popular choice of animal-assisted therapy for psychological problems and developmental disabilities. For example, a 2005 study found dolphins an effective treatment for mild to moderate depression. This study was criticized on several grounds, including a lack of knowledge on whether dolphins are more effective than common pets. Reviews of this and other published dolphin-assisted therapy (DAT) studies have found important methodological flaws and have concluded that there is no compelling scientific evidence that DAT is a legitimate therapy or that it affords more than fleeting mood improvement.

In some parts of the world, such as Taiji, Japan and the Faroe Islands, dolphins are traditionally considered as food, and are killed in harpoon or drive hunts.
Dolphin meat is consumed in a small number of countries worldwide, which include Japan and Peru (where it is referred to as "chancho marino", or "sea pork"). While Japan may be the best-known and most controversial example, only a very small minority of the population has ever sampled it.

Dolphin meat is dense and such a dark shade of red as to appear black. Fat is located in a layer of blubber between the meat and the skin. When dolphin meat is eaten in Japan, it is often cut into thin strips and eaten raw as "sashimi", garnished with onion and either horseradish or grated garlic, much as with "sashimi" of whale or horse meat ("basashi"). When cooked, dolphin meat is cut into bite-size cubes and then batter-fried or simmered in a "miso" sauce with vegetables. Cooked dolphin meat has a flavor very similar to beef liver.

There have been human health concerns associated with the consumption of dolphin meat in Japan after tests showed that dolphin meat contained high levels of mercury. There are no known cases of mercury poisoning as a result of consuming dolphin meat, though the government continues to monitor people in areas where dolphin meat consumption is high. The Japanese government recommends that children and pregnant women avoid eating dolphin meat on a regular basis.

Similar concerns exist with the consumption of dolphin meat in the Faroe Islands, where prenatal exposure to methylmercury and PCBs primarily from the consumption of pilot whale meat has resulted in neuropsychological deficits amongst children.



Conservation, research and news:

Photos:

Division ring

In algebra, a division ring, also called a skew field, is a nontrivial ring in which division by nonzero elements is defined. Specifically, it is a nontrivial ring in which every nonzero element has a multiplicative inverse, that is, an element usually denoted , such that . So, (right) "division" may be defined as , but this notation is avoided, as one may have .

A commutative division ring is a field. Wedderburn's little theorem asserts that all finite division rings are commutative and therefore finite fields. 

Historically, division rings were sometimes referred to as fields, while fields were called "commutative fields". In some languages, such as French, the word equivalent to "field" ("corps") is used for both commutative and noncommutative cases, and the distinction between the two cases is made by adding qualificatives such as "corps commutatif" (commutative field) or "corps gauche" (skew field).

All division rings are simple. That is, they have no two-sided ideal besides the zero ideal and itself.

All fields are division rings, and every non-field division ring is noncommutative. The best known example is the ring of quaternions. If one allows only rational instead of real coefficients in the constructions of the quaternions, one obtains another division ring. In general, if is a ring and is a simple module over , then, by Schur's lemma, the endomorphism ring of is a division ring; every division ring arises in this fashion from some simple module.

Much of linear algebra may be formulated, and remains correct, for modules over a division ring instead of vector spaces over a field. Doing so, one must specify whether one is considering right or left modules, and some care is needed in properly distinguishing left and right in formulas. In particular, every module has a basis, and Gaussian elimination can be used. So, everything that can be defined with these tools works on division algebras. Matrices and their products are defined similarly. However, a matrix that is left invertible need not to be right invertible, and if it is, its right inverse can differ from its left inverse. (See "".)

Determinants are not defined over noncommutative division algebras, and everything that requires this concept cannot be generalized to noncommutative division algebras. 

Working in coordinates, elements of a finite-dimensional right module can be represented by column vectors, which can be multiplied on the right by scalars, and on the left by matrices (representing linear maps); for elements of a finite-dimensional left module, row vectors must be used, which can be multiplied on the left by scalars, and on the right by matrices. The dual of a right module is a left module, and vice versa. The transpose of a matrix must be viewed as a matrix over the opposite division ring in order for the rule to remain valid.

Every module over a division ring is free; that is, it has a basis, and all bases of a module have the same number of elements. Linear maps between finite-dimensional modules over a division ring can be described by matrices; the fact that linear maps by definition commute with scalar multiplication is most conveniently represented in notation by writing them on the "opposite" side of vectors as scalars are. The Gaussian elimination algorithm remains applicable. The column rank of a matrix is the dimension of the right module generated by the columns, and the row rank is the dimension of the left module generated by the rows; the same proof as for the vector space case can be used to show that these ranks are the same and define the rank of a matrix.

Division rings are the only rings over which every module is free: a ring is a division ring if and only if every -module is free.

The center of a division ring is commutative and therefore a field. Every division ring is therefore a division algebra over its center. Division rings can be roughly classified according to whether or not they are finite dimensional or infinite dimensional over their centers. The former are called "centrally finite" and the latter "centrally infinite". Every field is one dimensional over its center. The ring of Hamiltonian quaternions forms a four-dimensional algebra over its center, which is isomorphic to the real numbers.


Wedderburn's little theorem: All finite division rings are commutative and therefore finite fields. (Ernst Witt gave a simple proof.)

Frobenius theorem: The only finite-dimensional associative division algebras over the reals are the reals themselves, the complex numbers, and the quaternions.

Division rings "used to be" called "fields" in an older usage. In many languages, a word meaning "body" is used for division rings, in some languages designating either commutative or noncommutative division rings, while in others specifically designating commutative division rings (what we now call fields in English). A more complete comparison is found in the article on fields.

The name "skew field" has an interesting semantic feature: a modifier (here "skew") "widens" the scope of the base term (here "field"). Thus a field is a particular type of skew field, and not all skew fields are fields.

While division rings and algebras as discussed here are assumed to have associative multiplication, nonassociative division algebras such as the octonions are also of interest.

A near-field is an algebraic structure similar to a division ring, except that it has only one of the two distributive laws.



Dia (software)

Dia ()
is free and open source general-purpose diagramming software, developed originally by Alexander Larsson. It uses a controlled single document interface (SDI) similar to GIMP and Inkscape.

Dia has a modular design with several shape packages available for different needs: flowchart, network diagrams, circuit diagrams, and more. It does not restrict symbols and connectors from various categories from being placed together.

Dia has special objects to help draw entity-relationship models, Unified Modeling Language (UML) diagrams, flowcharts, network diagrams, and simple electrical circuits. It is also possible to add support for new shapes by writing simple XML files, using a subset of Scalable Vector Graphics (SVG) to draw the shape.

Dia loads and saves diagrams in a custom XML format which is, by default, gzipped to save space. It can print large diagrams spanning multiple pages and can also be scripted using the Python programming language.

Dia can export diagrams to various formats, including:

Dia was originally created by Alexander Larsson but he moved on to work on GNOME and other projects. James Henstridge took over as lead developer, but he also moved on to other projects. He was followed by Cyrille Chepelov, then Lars Ræder Clausen.

Dia is currently maintained by Hans Breuer, Steffen Macke and Sameer Sahasrabuddhe.

It is written in C, and has an extension system which also supports writing extensions in Python.



Deep Space 1

Deep Space 1 (DS1) was a NASA technology demonstration spacecraft which flew by an asteroid and a comet. It was part of the New Millennium Program, dedicated to testing advanced technologies.

Launched on 24 October 1998, the "Deep Space 1" spacecraft carried out a flyby of asteroid 9969 Braille, which was its primary science target. The mission was extended twice to include an encounter with comet 19P/Borrelly and further engineering testing. Problems during its initial stages and with its star tracker led to repeated changes in mission configuration. While the flyby of the asteroid was only a partial success, the encounter with the comet retrieved valuable information.

The Deep Space series was continued by the "Deep Space 2" probes, which were launched in January 1999 piggybacked on the Mars Polar Lander and were intended to strike the surface of Mars (though contact was lost and the mission failed). "Deep Space 1" was the first NASA spacecraft to use ion propulsion rather than the traditional chemical-powered rockets.

The purpose of "Deep Space 1" was technology development and validation for future missions; 12 technologies were tested:

The Autonav system, developed by NASA's Jet Propulsion Laboratory, takes images of known bright asteroids. The asteroids in the inner Solar System move in relation to other bodies at a noticeable, predictable speed. Thus a spacecraft can determine its relative position by tracking such asteroids across the star background, which appears fixed over such timescales. Two or more asteroids let the spacecraft triangulate its position; two or more positions in time let the spacecraft determine its trajectory. Existing spacecraft are tracked by their interactions with the transmitters of the NASA Deep Space Network (DSN), in effect an inverse GPS. However, DSN tracking requires many skilled operators, and the DSN is overburdened by its use as a communications network. The use of Autonav reduces mission cost and DSN demands.

The Autonav system can also be used in reverse, tracking the position of bodies relative to the spacecraft. This is used to acquire targets for the scientific instruments. The spacecraft is programmed with the target's coarse location. After initial acquisition, Autonav keeps the subject in frame, even commandeering the spacecraft's attitude control. The next spacecraft to use Autonav was "Deep Impact".

Primary power for the mission was produced by a new solar array technology, the Solar Concentrator Array with Refractive Linear Element Technology (SCARLET), which uses linear Fresnel lenses made of silicone to concentrate sunlight onto solar cells. ABLE Engineering developed the concentrator technology and built the solar array for DS1, with Entech Inc, who supplied the Fresnel optics, and the NASA Glenn Research Center. The activity was sponsored by the Ballistic Missile Defense Organization, developed originally for the SSI - Conestoga 1620 payload, METEOR. The concentrating lens technology was combined with dual-junction solar cells, which had considerably better performance than the GaAs solar cells that were the state of the art at the time of the mission launch.

The SCARLET arrays generated 2.5 kilowatts at 1 AU, with less size and weight than conventional arrays.

Although ion engines had been developed at NASA since the late 1950s, with the exception of the SERT missions in the 1960s, the technology had not been demonstrated in flight on United States spacecraft, though hundreds of Hall-effect engines had been used on Soviet and Russian spacecraft. This lack of a performance history in space meant that despite the potential savings in propellant mass, the technology was considered too experimental to be used for high-cost missions. Furthermore, unforeseen side effects of ion propulsion might in some way interfere with typical scientific experiments, such as fields and particle measurements. Therefore, it was a primary mission of the "Deep Space 1" demonstration to show long-duration use of an ion thruster on a scientific mission.

The NASA Solar Technology Application Readiness (NSTAR) electrostatic ion thruster, developed at NASA Glenn, achieves a specific impulse of 1000–3000 seconds. This is an order of magnitude higher than traditional space propulsion methods, resulting in a mass savings of approximately half. This leads to much cheaper launch vehicles. Although the engine produces just thrust at maximal power (2,100 W on DS1), the craft achieved high speeds because ion engines thrust continuously for long periods.

The next spacecraft to use NSTAR engines was "Dawn", with three redundant units.

Remote Agent (RAX), remote intelligent self-repair software developed at NASA's Ames Research Center and the Jet Propulsion Laboratory, was the first artificial-intelligence control system to control a spacecraft without human supervision. Remote Agent successfully demonstrated the ability to plan onboard activities and correctly diagnose and respond to simulated faults in spacecraft components through its built-in REPL environment. Autonomous control will enable future spacecraft to operate at greater distances from Earth and to carry out more sophisticated science-gathering activities in deep space. Components of the Remote Agent software have been used to support other NASA missions. Major components of Remote Agent were a robust planner (EUROPA), a plan-execution system (EXEC) and a model-based diagnostic system (Livingstone). EUROPA was used as a ground-based planner for the Mars Exploration Rovers. EUROPA II was used to support the "Phoenix" Mars lander and the Mars Science Laboratory. Livingstone2 was flown as an experiment aboard Earth Observing-1 and on an F/A-18 Hornet at NASA's Dryden Flight Research Center.

Another method for reducing DSN burdens is the Beacon Monitor experiment. During the long cruise periods of the mission, spacecraft operations are essentially suspended. Instead of data, Deep Space 1 transmitted a carrier signal on a predetermined frequency. Without data decoding, the carrier could be detected by much simpler ground antennas and receivers. If DS1 detected an anomaly, it changed the carrier between four tones, based on urgency. Ground receivers then signal operators to divert DSN resources. This prevented skilled operators and expensive hardware from babysitting an unburdened mission operating nominally. A similar system was used on the "New Horizons" Pluto probe to keep costs down during its ten-year cruise from Jupiter to Pluto.

The Small Deep Space Transponder (SDST) is a compact and lightweight radio-communications system. Aside from using miniaturized components, the SDST is capable of communicating over the K band. Because this band is higher in frequency than bands currently in use by deep-space missions, the same amount of data can be sent by smaller equipment in space and on the ground. Conversely, existing DSN antennas can split time among more missions. At the time of launch, the DSN had a small number of K receivers installed on an experimental basis; K operations and missions are increasing.

The SDST was later used on other space missions such as the Mars Science Laboratory (the Mars rover "Curiosity").

Once at a target, DS1 senses the particle environment with the PEPE (Plasma Experiment for Planetary Exploration) instrument. This instrument measured the flux of ions and electrons as a function of their energy and direction. The composition of the ions was determined by using a time-of-flight mass spectrometer.

The MICAS (Miniature Integrated Camera And Spectrometer) instrument combined visible light imaging with infrared and ultraviolet spectroscopy to determine chemical composition. All channels share a telescope, which uses a silicon carbide mirror.

Both PEPE and MICAS were similar in capabilities to larger instruments or suites of instruments on other spacecraft. They were designed to be smaller and require lower power than those used on previous missions.

Prior to launch, "Deep Space 1" was intended to visit comet 76P/West–Kohoutek–Ikemura and asteroid 3352 McAuliffe. Because of the delayed launch, the targets were changed to asteroid 9969 Braille (at the time called 1992 KD) and comet 19P/Borrelly, with comet 107P/Wilson–Harrington being added following the early success of the mission. It achieved an impaired flyby of Braille and, due to problems with the star tracker, abandoned targeting Wilson–Harrington in order to maintain its flyby of comet 19P/Borrelly, which was successful. An August 2002 flyby of asteroid as another extended mission was considered, but ultimately was not advanced due to cost concerns. During the mission, high quality infrared spectra of Mars were also taken.

The ion propulsion engine initially failed after 4.5 minutes of operation. However, it was later restored to action and performed excellently. Early in the mission, material ejected during launch vehicle separation caused the closely spaced ion extraction grids to short-circuit. The contamination was eventually cleared, as the material was eroded by electrical arcing, sublimed by outgassing, or simply allowed to drift out. This was achieved by repeatedly restarting the engine in an engine repair mode, arcing across trapped material.

It was thought that the ion engine exhaust might interfere with other spacecraft systems, such as radio communications or the science instruments. The PEPE detectors had a secondary function to monitor such effects from the engine. No interference was found although the flux of ions from the thruster prevented PEPE from observing ions below approximately 20 eV.

Another failure was the loss of the star tracker. The star tracker determines spacecraft orientation by comparing the star field to its internal charts. The mission was saved when the MICAS camera was reprogrammed to substitute for the star tracker. Although MICAS is more sensitive, its field-of-view is an order of magnitude smaller, creating a greater information processing burden. Ironically, the star tracker was an off-the-shelf component, expected to be highly reliable.

Without a working star tracker, ion thrusting was temporarily suspended. The loss of thrust time forced the cancellation of a flyby past comet 107P/Wilson–Harrington.

The Autonav system required occasional manual corrections. Most problems were in identifying objects that were too dim, or were difficult to identify because of brighter objects causing diffraction spikes and reflections in the camera, causing Autonav to misidentify targets.

The Remote Agent system was presented with three simulated failures on the spacecraft and correctly handled each event.
Overall this constituted a successful demonstration of fully autonomous planning, diagnosis, and recovery.

The MICAS instrument was a design success, but the ultraviolet channel failed due to an electrical fault. Later in the mission, after the star tracker failure, MICAS assumed this duty as well. This caused continual interruptions in its scientific use during the remaining mission, including the Comet Borrelly encounter.

The flyby of the asteroid 9969 Braille was only a partial success. "Deep Space 1" was intended to perform the flyby at at only from the asteroid. Due to technical difficulties, including a software crash shortly before approach, the craft instead passed Braille at a distance of . This, plus Braille's lower albedo, meant that the asteroid was not bright enough for the Autonav to focus the camera in the right direction, and the picture shoot was delayed by almost an hour. The resulting pictures were disappointingly indistinct.

However, the flyby of Comet Borrelly was a great success and returned extremely detailed images of the comet's surface. Such images were of higher resolution than the only previous pictures of a comet -- Halley's Comet, taken by the "Giotto" spacecraft. The PEPE instrument reported that the comet's solar wind interaction was offset from the nucleus. This is believed to be due to emission of jets, which were not distributed evenly across the comet's surface.

Despite having no debris shields, the spacecraft survived the comet passage intact. Once again, the sparse comet jets did not appear to point towards the spacecraft. "Deep Space 1" then entered its second extended mission phase, focused on retesting the spacecraft's hardware technologies. The focus of this mission phase was on the ion engine systems. The spacecraft eventually ran out of hydrazine fuel for its attitude control thrusters. The highly efficient ion thruster had a sufficient amount of propellant left to perform attitude control in addition to main propulsion, thus allowing the mission to continue.

During late October and early November 1999, during the spacecraft's post-Braille encounter coast phase, "Deep Space 1" observed Mars with its MICAS instrument. Although this was a very distant flyby, the instrument did succeed in taking multiple infrared spectra of the planet.

"Deep Space 1" succeeded in its primary and secondary objectives, returning valuable science data and images. DS1's ion engines were shut down on 18 December 2001 at approximately 20:00:00 UTC, signaling the end of the mission. On-board communications were set to remain in active mode in case the craft should be needed in the future. However, attempts to resume contact in March 2002 were unsuccessful. It remains within the Solar System, in orbit around the Sun.




King David (disambiguation)

David was the second king of the United Kingdom of Israel and Judah.

King David may also refer to:




Jacques-Louis David

Jacques-Louis David (; 30 August 1748 – 29 December 1825) was a French painter in the Neoclassical style, considered to be the preeminent painter of the era. In the 1780s, his cerebral brand of history painting marked a change in taste away from Rococo frivolity toward classical austerity, severity, and heightened feeling, which harmonized with the moral climate of the final years of the Ancien Régime.

David later became an active supporter of the French Revolution and friend of Maximilien Robespierre (1758–1794), and was effectively a dictator of the arts under the French Republic. Imprisoned after Robespierre's fall from power, he aligned himself with yet another political regime upon his release: that of Napoleon, the First Consul of France. At this time he developed his Empire style, notable for its use of warm Venetian colours. After Napoleon's fall from Imperial power and the Bourbon revival, David exiled himself to Brussels, then in the United Kingdom of the Netherlands, where he remained until his death. David had , making him the strongest influence in French art of the early 19th century, especially academic Salon painting.

Jacques-Louis David was born into a prosperous French family in Paris on 30 August 1748. When he was about nine his father was killed in a duel and his mother left him with his well-off architect uncles. They saw to it that he received an excellent education at the Collège des Quatre-Nations, University of Paris, but he was never a good student—he had a facial tumor that impeded his speech, and he was always preoccupied with drawing. He covered his notebooks with drawings, and he once said, "I was always hiding behind the instructor's chair, drawing for the duration of the class". Soon, he desired to be a painter, but his uncles and mother wanted him to be an architect. He overcame the opposition, and went to learn from François Boucher (1703–1770), the leading painter of the time, who was also a distant relative. Boucher was a Rococo painter, but tastes were changing, and the fashion for Rococo was giving way to a more classical style. Boucher decided that instead of taking over David's tutelage, he would send David to his friend, Joseph-Marie Vien (1716–1809), a painter who embraced the classical reaction to Rococo. There, David attended the Royal Academy, based in what is now the Louvre.

Each year the Academy awarded an outstanding student the prestigious , which funded a 3- to 5-year stay in Rome. Since artists were now revisiting classical styles, the trip provided its winners the opportunity to study the remains of classical antiquity and the works of the Italian Renaissance masters at first hand. Called "pensionnaire" they were housed in the French Academy's Rome outpost, which from the years 1737 to 1793 was the Palazzo Mancini in the Via del Corso. David made three consecutive attempts to win the annual prize, (with "Minerva Fighting Mars", "Diana and Apollo Killing Niobe's Children" and "The Death of Seneca") with each failure allegedly contributing to his lifelong grudge against the institution. After his second loss in 1772, David went on a hunger strike, which lasted two and a half days before the faculty encouraged him to continue painting. Confident he now had the support and backing needed to win the prize, he resumed his studies with great zeal—only to fail to win the again the following year. Finally, in 1774, David was awarded the on the strength of his painting of "Erasistratus Discovering the Cause of Antiochus' Disease", a subject set by the judges. In October 1775 he made the journey to Italy with his mentor, Joseph-Marie Vien, who had just been appointed director of the French Academy at Rome.

While in Italy, David mostly studied the works of 17th-century masters such as Poussin, Caravaggio, and the Carracci. Although he declared, "the Antique will not seduce me, it lacks animation, it does not move", David filled twelve sketchbooks with drawings that he and his studio used as model books for the rest of his life. He was introduced to the painter Raphael Mengs (1728–1779), who opposed the Rococo tendency to sweeten and trivialize ancient subjects, advocating instead the rigorous study of classical sources and close adherence to ancient models. Mengs' principled, historicizing approach to the representation of classical subjects profoundly influenced David's pre-revolutionary painting, such as "The Vestal Virgin", probably from the 1780s. Mengs also introduced David to the theoretical writings on ancient sculpture by Johann Joachim Winckelmann (1717–1768), the German scholar held to be the founder of modern art history. As part of the , David toured the newly excavated ruins of Pompeii in 1779, which deepened his belief that the persistence of classical culture was an index of its eternal conceptual and formal power. During the trip David also assiduously studied the High Renaissance painters, Raphael making a profound and lasting impression on the young French artist.

Although David's fellow students at the academy found him difficult to get along with, they recognized his genius. David's stay at the French Academy in Rome was extended by a year. In July 1780, he returned to Paris. There, he found people ready to use their influence for him, and he was made an official member of the Royal Academy. He sent the Academy two paintings, and both were included in the Salon of 1781, a high honor. He was praised by his famous contemporary painters, but the administration of the Royal Academy was very hostile to this young upstart. After the Salon, the King granted David lodging in the Louvre, an ancient and much desired privilege of great artists. When the contractor of the King's buildings, M. Pécoul, was arranging with David, he asked the artist to marry his daughter, Marguerite Charlotte. This marriage brought him money and eventually four children. David had about 50 of his own pupils and was commissioned by the government to paint ""Horace defended by his Father"", but he soon decided, ""Only in Rome can I paint Romans."" His father-in-law provided the money he needed for the trip, and David headed for Rome with his wife, Charlotte, and three of his students, one of whom, Jean-Germain Drouais (1763–1788), was the winner of that year.

In Rome, David painted his famous "Oath of the Horatii", 1784. In this piece, the artist references Enlightenment values while alluding to Rousseau's social contract. The republican ideal of the general became the central focus of the painting with all three sons positioned in compliance with the father. The Oath between the characters can be read as an act of unification of men to the binding of the state. The issue of gender roles also becomes apparent in this piece, as the women in Horatii greatly contrast the group of brothers. David depicts the father with his back to the women, shutting them out of the oath. They also appear to be smaller in scale and physically isolated from the male figures. The masculine virility and discipline displayed by the men's rigid and confident stances is also severely contrasted to the slouching, swooning female softness created in the other half of the composition. Here we see the clear division of male-female attributes that confined the sexes to specific roles under Rousseau's popularized doctrine of "separate spheres".

These revolutionary ideals are also apparent in the "Distribution of Eagles". While "Oath of the Horatii" and "The Tennis Court Oath" stress the importance of masculine self-sacrifice for one's country and patriotism, the "Distribution of Eagles" would ask for self-sacrifice for one's Emperor (Napoleon) and the importance of battlefield glory.
In 1787, David did not become the Director of the French Academy in Rome, which was a position he wanted dearly. The Count in charge of the appointments said David was too young, but said he would support him in 6 to 12 years. This situation would be one of many that would cause him to lash out at the Academy in years to come.

For the Salon of 1787, David exhibited his famous "Death of Socrates". "Condemned to death, Socrates, strong, calm and at peace, discusses the immortality of the soul. Surrounded by Crito, his grieving friends and students, he is teaching, philosophizing, and in fact, thanking the God of Health, Asclepius, for the hemlock brew which will ensure a peaceful death... The wife of Socrates can be seen grieving alone outside the chamber, dismissed for her weakness. Plato is depicted as an old man seated at the end of the bed." Critics compared the Socrates with Michelangelo's Sistine Ceiling and Raphael's Stanze, and one, after ten visits to the Salon, described it as "in every sense perfect". Denis Diderot said it looked as if he copied it from some ancient bas-relief. The painting was very much in tune with the political climate at the time. For this painting, David was not honored by a royal "works of encouragement".

For his next painting, David created "The Lictors Bring to Brutus the Bodies of His Sons". The work had tremendous appeal for the time. Before the opening of the Salon, the French Revolution had begun. The National Assembly had been established, and the Bastille had fallen. The royal court did not want propaganda agitating the people, so all paintings had to be checked before being hung. David's portrait of Lavoisier, who was a chemist and physicist as well as an active member of the Jacobin party, was banned by the authorities for such reasons. When the newspapers reported that the government had not allowed the showing of "The Lictors Bring to Brutus the Bodies of His Sons", the people were outraged, and the royals were forced to give in. The painting was hung in the exhibition, protected by art students. The painting depicts Lucius Junius Brutus, the Roman leader, grieving for his sons. Brutus's sons had attempted to overthrow the government and restore the monarchy, so the father ordered their death to maintain the republic. Brutus was the heroic defender of the republic, sacrificing his own family for the good of the republic. On the right, the mother holds her two daughters, and the nurse is seen on the far right, in anguish. Brutus sits on the left, alone, brooding, seemingly dismissing the dead bodies of his sons. Knowing what he did was best for his country, but the tense posture of his feet and toes reveals his inner turmoil. The whole painting was a Republican symbol, and obviously had immense meaning during these times in France. It exemplified civic virtue, a value highly regarded during the Revolution.

In the beginning, David was a supporter of the Revolution, a friend of Robespierre, and a member of the Jacobin Club. While others were leaving the country for new and greater opportunities, David stayed behind to help destroy the old order; he was a regicide who voted in the National Convention for the Execution of Louis XVI. It is uncertain why he did this, as there were many more opportunities for him under the King than the new order; some people suggest David's love for the classical made him embrace everything about that period, including a republican government.
Others believed that they found the key to the artist's revolutionary career in his personality. Undoubtedly, David's artistic sensibility, mercurial temperament, volatile emotions, ardent enthusiasm, and fierce independence might have been expected to help turn him against the established order but they did not fully explain his devotion to the republican regime. Nor did the vague statements of those who insisted upon his "powerful ambition...and unusual energy of will" actually account for his revolutionary connections. Those who knew him maintained that "generous ardor", high-minded idealism and well-meaning though sometimes fanatical enthusiasm, rather than opportunism and jealousy, motivated his activities during this period.

Soon, David turned his critical sights on the Royal Academy of Painting and Sculpture. This attack was probably caused primarily by the hypocrisy of the organization and their personal opposition to his work, as seen in previous episodes in David's life. The Royal Academy was controlled by royalists, who opposed David's attempts at reform; so the National Assembly finally ordered it to make changes to conform to the new constitution.

David then began work on something that would later hound him: propaganda for the new republic. David's painting of Brutus was shown during the play "Brutus" by Voltaire.

In 1789, Jacques-Louis David attempted to leave his artistic mark on the historical beginnings of the French Revolution with his painting of "The Oath of the Tennis Court". David undertook this task not out of personal political conviction but rather because he was commissioned to do so. The painting was meant to commemorate the event of the same name but was never completed. A meeting of the Estates General was convened in May to address reforms of the monarchy. Dissent arose over whether the three estates would meet separately, as had been tradition, or as one body. The King's acquiescence in the demands of the upper orders led to the deputies of the Third Estate renaming themselves as the National Assembly on 17 June. They were locked out of the meeting hall three days later when they attempted to meet, and forced to reconvene to the royal indoor tennis court. Presided over by Jean-Sylvain Bailly, they made a 'solemn oath never to separate' until a national constitution had been created. In 1789 this event was seen as a symbol of the national unity against the "ancien regime". Rejecting the current conditions, the oath signified a new transition in human history and ideology. David was enlisted by the Society of Friends of the Constitution, the body that would eventually form the Jacobins, to enshrine this symbolic event.

This instance is notable in more ways than one because it eventually led David to finally become involved in politics as he joined the Jacobins. The picture was meant to be massive in scale; the figures in the foreground were to be life-sized portraits of the counterparts, including Jean-Sylvain Bailly, the President of the Constituent Assembly. Seeking additional funding, David turned to the Society of Friends of the Constitution. The funding for the project was to come from over three thousand subscribers hoping to receive a print of the image. However, when the funding was insufficient, the state ended up financing the project.

David set out in 1790 to transform the contemporary event into a major historical picture which would appear at the Salon of 1791 as a large pen-and-ink drawing. As in the "Oath of the Horatii", David represents the unity of men in the service of a patriotic ideal. The outstretched arms which are prominent in both works betray David's deeply held belief that acts of republican virtue akin to those of the Romans were being played out in France. In what was essentially an act of intellect and reason, David creates an air of drama in this work. The very power of the people appears to be "blowing" through the scene with the stormy weather, in a sense alluding to the storm that would be the revolution.

Symbolism in this work of art closely represents the revolutionary events taking place at the time. The figure in the middle is raising his right arm making the oath that they will never disband until they have reached their goal of creating a "constitution of the realm fixed upon solid foundations". The importance of this symbol is highlighted by the fact that the crowd's arms are angled to his hand forming a triangular shape. Additionally, the open space in the top half contrasted to the commotion in the lower half serves to emphasize the magnitude of the Tennis Court Oath.

In his attempt to depict political events of the Revolution in "real time", David was venturing down a new and untrodden path in the art world. However, Thomas Crow argues that this path "proved to be less a way forward than a cul-de-sac for history painting". Essentially, the history of the demise of David's "The Tennis Court Oath" illustrates the difficulty of creating works of art that portray current and controversial political occurrences. Political circumstances in France proved too volatile to allow the completion of the painting. The unity that was to be symbolized in "The Tennis Court Oath" no longer existed in radicalized 1792. The National Assembly had split between conservatives and radical Jacobins, both vying for political power. By 1792 there was no longer consensus that all the revolutionaries at the tennis court were "heroes". A sizeable number of the heroes of 1789 had become the villains of 1792. In this unstable political climate David's work remained unfinished. With only a few nude figures sketched onto the massive canvas, David abandoned "The Oath of the Tennis Court". To have completed it would have been politically unsound. After this incident, when David attempted to make a political statement in his paintings, he returned to the less politically charged use of metaphor to convey his message.

When Voltaire died in 1778, the church denied him a church burial, and his body was interred near a monastery. A year later, Voltaire's old friends began a campaign to have his body buried in the Panthéon, as church property had been confiscated by the French Government. In 1791, David was appointed to head the organizing committee for the ceremony, a parade through the streets of Paris to the Panthéon. Despite rain and opposition from conservatives due to the amount of money spent, the procession went ahead. Up to 100,000 people watched the "Father of the Revolution" being carried to his resting place. This was the first of many large festivals organized by David for the republic. He went on to organize festivals for martyrs that died fighting royalists. These funerals echoed the religious festivals of the pagan Greeks and Romans and are seen by many as Saturnalian.

David incorporated many revolutionary symbols into these theatrical performances and orchestrated ceremonial rituals, in effect radicalizing the applied arts themselves. The most popular symbol for which David was responsible as propaganda minister was drawn from classical Greek images; changing and transforming them with contemporary politics. In an elaborate festival held on the anniversary of the revolt that brought the monarchy to its knees, David's Hercules figure was revealed in a procession following the Goddess of Liberty (Marianne). Liberty, the symbol of Enlightenment ideals was here being overturned by the Hercules symbol; that of strength and passion for the protection of the Republic against disunity and factionalism. In his speech during the procession, David "explicitly emphasized the opposition between people and monarchy; Hercules was chosen, after all, to make this opposition more evident". The ideals that David linked to his Hercules single-handedly transformed the figure from a sign of the old regime into a powerful new symbol of revolution. "David turned him into the representation of a collective, popular power. He took one of the favorite signs of monarchy and reproduced, elevated, and monumentalized it into the sign of its opposite." Hercules, the image, became to the revolutionaries, something to rally around.

In June 1791, the King made an ill-fated attempt to flee the country, but was apprehended short of his goal on the Austrian Netherlands border and was forced to return under guard to Paris. Louis XVI had made secret requests to Emperor Leopold II of Austria, Marie-Antoinette's brother, to restore him to his throne. This was granted and Austria threatened France if the royal couple were hurt. In reaction, the people arrested the King. This led to an Invasion after the trials and execution of Louis and Marie-Antoinette. The Bourbon monarchy was destroyed by the French people in 1792—it would be restored after Napoleon, then destroyed again with the Restoration of the House of Bonaparte. When the new National Convention held its first meeting, David was sitting with his friends Jean-Paul Marat and Robespierre. In the convention, David soon earned the nickname "ferocious terrorist". Robespierre's agents discovered a secret vault containing the King's correspondence which proved he was trying to overthrow the government, and demanded his execution. The National Convention held the trial of Louis XVI; David voted for the death of the King, causing his wife, Marguerite Charlotte, a royalist, to divorce him.

When Louis XVI was executed on 21 January 1793, another man had already died as well—Louis Michel le Peletier de Saint-Fargeau. Le Peletier was killed on the preceding day by a royal bodyguard in revenge for having voted for the death of the King. David was called upon to organize a funeral, and he painted "Le Peletier Assassinated". In it, the assassin's sword was seen hanging by a single strand of horsehair above Le Peletier's body, a concept inspired by the proverbial ancient tale of the sword of Damocles, which illustrated the insecurity of power and position. This underscored the courage displayed by Le Peletier and his companions in routing an oppressive king. The sword pierces a piece of paper on which is written "I vote the death of the tyrant", and as a tribute at the bottom right of the picture David placed the inscription "David to Le Peletier. 20 January 1793". The painting was later destroyed by Le Peletier's royalist daughter, and is known by only a drawing, an engraving, and contemporary accounts. Nevertheless, this work was important in David's career because it was the first completed painting of the French Revolution, made in less than three months, and a work through which he initiated the regeneration process that would continue with "The Death of Marat", David's masterpiece.

On 13 July 1793, David's friend Marat was assassinated by Charlotte Corday with a knife she had hidden in her clothing. She gained entrance to Marat's house on the pretense of presenting him a list of people who should be executed as enemies of France. Marat thanked her and said that they would be guillotined next week upon which Corday immediately fatally stabbed him. She was guillotined shortly thereafter. Corday was of an opposing political party, whose name can be seen in the note Marat holds in David's subsequent painting, "The Death of Marat". Marat, a member of the National Convention and a journalist, had a skin disease that caused him to itch horribly. The only relief he could get was in his bath over which he improvised a desk to write his list of suspect counter-revolutionaries who were to be quickly tried and, if convicted, guillotined. David once again organized a spectacular funeral, and Marat was buried in the Panthéon. Marat's body was to be placed upon a Roman bed, his wound displayed and his right arm extended holding the pen which he had used to defend the Republic and its people. This concept was to be complicated by the fact that the corpse had begun to putrefy. Marat's body had to be periodically sprinkled with water and vinegar as the public crowded to see his corpse prior to the funeral on 15 and 16 July. The stench became so bad however that the funeral had to be brought forward to the evening of 16 July.

"The Death of Marat", perhaps David's most famous painting, has been called the Pietà of the revolution. Upon presenting the painting to the convention, he said "Citizens, the people were again calling for their friend; their desolate voice was heard: David, take up your brushes..., avenge Marat... I heard the voice of the people. I obeyed."

"The Death of Marat", 1793, became the leading image of the Terror and immortalized both Marat and David in the world of the revolution. This piece stands today as "a moving testimony to what can be achieved when an artist's political convictions are directly manifested in his work". A political martyr was instantly created as David portrayed Marat with all the marks of the real murder, in a fashion which greatly resembles that of Christ or his disciples. The subject although realistically depicted remains lifeless in a rather supernatural composition. With the surrogate tombstone placed in front of him and the almost holy light cast upon the whole scene; alluding to an out of this world existence. "Atheists though they were, David and Marat, like so many other fervent social reformers of the modern world, seem to have created a new kind of religion." At the very center of these beliefs, there stood the republic.

After the King's execution, war broke out between the new Republic and virtually every major power in Europe. David, as a member of the Committee of General Security, contributed directly to the Reign of Terror. David organized his last festival: the festival of the Supreme Being. Robespierre had realized what a tremendous propaganda tool these festivals were, and he decided to create a new religion, mixing moral ideas with the Republic and based on the ideas of Rousseau. This process had already begun by confiscating church lands and requiring priests to take an oath to the state. The festivals, called fêtes, would be the method of indoctrination. On the appointed day, 20 Prairial by the revolutionary calendar, Robespierre spoke, descended steps, and with a torch presented to him by David, incinerated a cardboard image symbolizing atheism, revealing an image of wisdom underneath.

Soon, the war began to go well; French troops marched across the southern half of the Netherlands (which would later become Belgium), and the emergency that had placed the Committee of Public Safety in control was no more. Then plotters seized Robespierre at the National Convention and he was later guillotined, in effect ending the Reign of Terror. As Robespierre was arrested, David yelled to his friend "if you drink hemlock, I shall drink it with you." After this, he supposedly fell ill, and did not attend the evening session because of "stomach pain", which saved him from being guillotined along with Robespierre. David was arrested and placed in prison twice, first from 2 August to 28 December 1794 and then from 29 May to 3 August 1795. Most of the time he served his sentence in the not uncomfortable Palais du Luxembourg in Paris. There he painted his own portrait, showing him much younger than he actually was, as well as that of his jailer.

After David's wife visited him in jail, he conceived the idea of telling the story of The rape of the Sabine women. "The Sabine Women Enforcing Peace by Running between the Combatants", also called "The Intervention of the Sabine Women" is said to have been painted to honor his wife, with the theme being love prevailing over conflict. The painting was also seen as a plea for the people to reunite after the bloodshed of the revolution.

David conceived a new style for this painting, one which he called the "Pure Greek Style", as opposed to the "Roman style" of his earlier historical paintings. The new style was influenced heavily by the work of art historian Johann Joachim Winckelmann. In David's words, "the most prominent general characteristics of the Greek masterpieces are a noble simplicity and silent greatness in pose as well as in expression." Instead of the muscularity and angularity of the figures of his past works, these were smoother, more feminine, and painterly.

This work also brought him to the attention of Napoleon. The story for the painting is as follows: "The Romans have abducted the daughters of their neighbors, the Sabines. To avenge this abduction, the Sabines attacked Rome, although not immediately—since Hersilia, the daughter of Tatius, the leader of the Sabines, had been married to Romulus, the Roman leader, and then had two children by him in the interim. Here we see Hersilia between her father and husband as she adjures the warriors on both sides not to take wives away from their husbands or mothers away from their children. The other Sabine Women join in her exhortations." 

During this time, the martyrs of the Revolution were taken from the Pantheon and buried in common ground, and revolutionary statues were destroyed. When David was finally released to the country, France had changed. His wife managed to get him released from prison, and he wrote letters to his former wife, and told her he never ceased loving her. He remarried her in 1796. Finally, wholly restored to his position, he retreated to his studio, took pupils and for the most part, retired from politics.

In August 1796, David and many other artists signed a petition orchestrated by Quatremère de Quincy which questioned the wisdom of the planned seizure of works of art from Rome. The Director Barras believed that David was "tricked" into signing, although one of David's students recalled that in 1798 his master lamented the fact that masterpieces had been imported from Italy.

David's close association with the Committee of Public Safety during the Terror resulted in his signing of the death warrant for Alexandre de Beauharnais, a minor noble. Beauharnais's widow, Joséphine, went on to marry Napoleon Bonaparte and became his empress; David himself depicted their coronation in the "Coronation of Napoleon and Josephine, 2 December 1804".
David had been an admirer of Napoleon from their first meeting, struck by Bonaparte's classical features. Requesting a sitting from the busy and impatient general, David was able to sketch Napoleon in 1797. David recorded the face of the conqueror of Italy, but the full composition of Napoleon holding the peace treaty with Austria remains unfinished. This was likely a decision by Napoleon himself after considering the current political situation. He may have considered the publicity the portrait would bring about to be ill-timed. Bonaparte had high esteem for David, and asked him to accompany him to Egypt in 1798, but David refused, seemingly unwilling to give up the material comfort, safety, and peace of mind he had obtained through the years. Draftsman and engraver Dominique Vivant Denon went to Egypt instead, providing mostly documentary and archaeological work.

After Napoleon's successful coup d'état in 1799, as First Consul he commissioned David to commemorate his daring crossing of the Alps. The crossing of the St. Bernard Pass had allowed the French to surprise the Austrian army and win victory at the Battle of Marengo on 14 June 1800. Although Napoleon had crossed the Alps on a mule, he requested that he be portrayed "calm upon a fiery steed". David complied with "Napoleon Crossing the Saint-Bernard." After the proclamation of the Empire in 1804, David became the official court painter of the regime. During this period he took students, one of whom was the Belgian painter Pieter van Hanselaere.

One of the works David was commissioned for was "The Coronation of Napoleon" (1805-1807). David was permitted to watch the event. He had plans of Notre Dame delivered and participants in the coronation came to his studio to pose individually, though never the Emperor. (The only time David obtained a sitting from Napoleon had been in 1797.) David did manage to get a private sitting with the Empress Joséphine and Napoleon's sister, Caroline Murat, through the intervention of erstwhile art patron Marshal Joachim Murat, the Emperor's brother-in-law. For his background, David had the choir of Notre Dame act as his fill-in characters. Pope Pius VII came to sit for the painting, and actually blessed David. Napoleon came to see the painter, stared at the canvas for an hour and said "David, I salute you." David had to redo several parts of the painting because of Napoleon's various whims, and for this painting, he received twenty-four thousand Francs.

David was made a Chevalier de la Légion d'honneur in 1803. He was promoted to an Officier in 1808. And, in 1815, he was promoted to a Commandant (now Commandeur) de la Légion d'honneur.

On the Bourbons returning to power, David figured in the list of proscribed former revolutionaries and Bonapartists for having voted execution for the deposed King Louis XVI; and for participating in the death of Louis XVII, the deposed king's son who was mistreated, starved and forced into a false confession of incest with his mother, Queen Marie-Antoinette, which contributed to her death sentence. 

The newly restored Bourbon King, Louis XVIII, however, granted amnesty to David and even offered him the position of court painter. David refused, preferring self-exile in Brussels. There, he trained and influenced Brussels artists such as François-Joseph Navez and Ignace Brice, painted "Cupid and Psyche" and quietly lived the remainder of his life with his wife (whom he had remarried). In that time, he painted smaller-scale mythological scenes, and portraits of citizens of Brussels and Napoleonic émigrés, such as the Baron Gerard.

David created his last great work, "Mars Being Disarmed by Venus and the Three Graces", from 1822 to 1824. In December 1823, he wrote: "This is the last picture I want to paint, but I want to surpass myself in it. I will put the date of my seventy-five years on it and afterwards I will never again pick up my brush." The finished painting—evoking painted porcelain because of its limpid coloration—was exhibited first in Brussels, then in Paris, where his former students flocked to view it.
The exhibition was profitable—13,000 francs, after deducting operating costs, thus, more than 10,000 people visited and viewed the painting. In his later years, David remained in full command of his artistic faculties, even after a stroke in the spring of 1825 disfigured his face and slurred his speech. In June 1825, he resolved to embark on an improved version of his "The Anger of Achilles" (also known as the "Sacrifice of Iphigenie"); the earlier version was completed in 1819 and is now in the collection of the Kimbell Art Museum in Fort Worth, Texas. David remarked to his friends who visited his studio "this [painting] is what is killing me" such was his determination to complete the work, but by October it must have already been well advanced, as his former pupil Gros wrote to congratulate him, having heard reports of the painting's merits. By the time David died, the painting had been completed and the commissioner Ambroise Firmin-Didot brought it back to Paris to include it in the exhibition "Pour les grecs" that he had organised and which opened in Paris in April 1826.

When David was leaving a theater, the driver of a carriage struck him, and he later died, on 29 December 1825. At his death, some portraits were auctioned in Paris, they sold for little; the famous "Death of Marat" was exhibited in a secluded room, to avoid outraging public sensibilities. Disallowed return to France for burial, for having been a regicide of King Louis XVI, the body of the painter Jacques-Louis David was buried in Brussels and moved in 1882 to Brussels Cemetery, while some say his heart was buried with his wife at Père Lachaise Cemetery, Paris.

The theme of the oath found in several works such as "The Oath of the Tennis Court", "The Distribution of the Eagles", and "Leonidas at Thermopylae", was perhaps inspired by the rituals of Freemasonry. In 1989 during the "David against David" conference Albert Boime presented evidence, a document dated in 1787, showing the painter's membership in the "La Moderation" Masonic Lodge.

Jacques-Louis David's facial abnormalities were traditionally reported to be a consequence of a deep facial sword wound after a fencing incident. These left him with a noticeable asymmetry during facial expression and resulted in his difficulty in eating or speaking. (He could not pronounce some consonants such as the letter 'r'.) A sword scar wound on the left side of his face is present in his self-portrait and sculptures and corresponds to some of the buccal branches of the facial nerve. An injury to this nerve and its branches are likely to have resulted in the difficulties with his left facial movement.

Furthermore, as a result of this injury, he suffered from a growth on his face that biographers and art historians have defined as a benign tumor. These, however, may have been a granuloma, or even a post-traumatic neuroma. As historian Simon Schama has pointed out, witty banter and public speaking ability were key aspects of the social culture of 18th-century France, so David's tumor could have been a heavy obstacle in his social life. David was sometimes referred to as "David of the Tumor".

In addition to his history paintings, David completed a number of privately commissioned portraits. Warren Roberts, among others, has pointed out the contrast between David's "public style" of painting, as shown in his history paintings, and his "private style", as shown in his portraits. His portraits were characterized by a sense of truth and realism. He focused on defining his subjects' features and characters without idealizing them. This is different from the style seen in his historical paintings, in which he idealizes his figures' features and bodies to align with Greek and Roman ideals of beauty. He puts a great deal of detail into his portraits, defining smaller features such as hands and fabric. The compositions of his portraits remain simple with blank backgrounds that allow the viewer to focus on the details of the subject.

The portrait he did of his wife (1813) is an example of his typical portrait style. The background is dark and simple without any clues as to the setting, which forces the viewer to focus entirely on her. Her features are un-idealized and truthful to her appearance. There is a great amount of detail that can be seen in his attention to portraying the satin material of the dress she wears, the drapery of the scarf around her, and her hands which rest in her lap.
In the painting of Brutus (1789), the man and his wife are separated, both morally and physically. Paintings such as these, depicting the great strength of patriotic sacrifice, made David a popular hero of the revolution.

In the "Portrait of Antoine-Laurent Lavoisier and his wife" (1788), the man and his wife are tied together in an intimate pose. She leans on his shoulder while he pauses from his work to look up at her. David casts them in a soft light, not in the sharp contrast of Brutus or of the Horatii. Also of interest—Lavoisier was a tax collector, as well as a famous chemist. Though he spent some of his money trying to clean up swamps and eradicate malaria, he was nonetheless sent to the guillotine during the Reign of Terror as an enemy of the people. David, then a powerful member of the National Assembly, stood idly by and watched.

Other portraits include paintings of his sister-in-law and her husband, Madame and Monsieur Seriziat. The picture of Monsieur Seriziat depicts a man of wealth, sitting comfortably with his horse-riding equipment. The picture of the Madame shows her wearing an unadorned white dress, holding her young child's hand as they lean against a bed. David painted these portraits of Madame and Monsieur Seriziat out of gratitude for letting him stay with them after he was in jail.

Towards the end of David's life, he painted a portrait of his old friend "Abbé Sieyès". Both had been involved in the Revolution, both had survived the purging of political radicals that followed the reign of terror.

The shift in David's perspective played an important role in the paintings of David's later life, including this one of Sieyès. During the height of The Terror, David was an ardent supporter of radicals such as Robespierre and Marat, and twice offered up his life in their defense. He organized revolutionary festivals and painted portraits of martyrs of the revolution, such as Lepeletier, who was assassinated for voting for the death of the king. David was an impassioned speaker at times in the National Assembly. In speaking to the Assembly about the young boy named Bara, another martyr of the revolution, David said, "O Bara! O Viala! The blood that you have spread still smokes; it rises toward Heaven and cries for vengeance."

After Robespierre was sent to the guillotine, however, David was imprisoned and changed the attitude of his rhetoric. During his imprisonment he wrote many letters, pleading his innocence. In one he wrote, "I am prevented from returning to my atelier, which, alas, I should never have left. I believed that in accepting the most honorable position, but very difficult to fill, that of legislator, that a righteous heart would suffice, but I lacked the second quality, understanding."

Later, while explaining his developing "Grecian style" for paintings such as "The Intervention of the Sabine Women", David further commented on a shift in attitude: "In all human activity the violent and transitory develops first; repose and profundity appear last. The recognition of these latter qualities requires time; only great masters have them, while their pupils have access only to violent passions."

Jacques-Louis David was, in his time, regarded as the leading painter in France, and arguably all of Western Europe; many of the painters honored by the restored Bourbons following the French Revolution had been David's pupils. David's student Antoine-Jean Gros for example, was made a Baron and honored by Napoleon Bonaparte's court. Another pupil of David's, Jean Auguste Dominique Ingres became the most important artist of the restored Royal Academy and the figurehead of the Neoclassical school of art, engaging the increasingly popular Romantic school of art that was beginning to challenge Neoclassicism. David invested in the formation of young artists for the Rome Prize, which was also a way to pursue his old rivalry with other contemporary painters such as Joseph-Benoît Suvée, who had also started teaching classes. To be one of David's students was considered prestigious and earned his students a lifetime reputation. He called on the more advanced students, such as Jérôme-Martin Langlois, to help him paint his large canvases. Musician and artist Therese Emilie Henriette Winkel; and painter Jean Baptiste Vermay also studied with David.

Despite David's reputation, he was more fiercely criticized right after his death than at any point during his life. His style came under the most serious criticism for being static, rigid, and uniform throughout all his work. David's art was also attacked for being cold and lacking warmth. David, however, made his career precisely by challenging what he saw as the earlier rigidity and conformity of the French Royal Academy's approach to art. David's later works also reflect his growth in the development of the Empire style, notable for its dynamism and warm colors. It is likely that much of the criticism of David following his death came from David's opponents; during his lifetime David made a great many enemies with his competitive and arrogant personality as well as his role in the Terror. David sent many people to the guillotine and personally signed the death warrants for King Louis XVI and Marie Antoinette. One significant episode in David's political career that earned him a great deal of contempt was the execution of Emilie Chalgrin. A fellow painter Carle Vernet had approached David, who was on the Committee of Public Safety, requesting him to intervene on behalf of his sister, Chalgrin. She had been accused of crimes against the Republic, most notably possessing stolen items. David refused to intervene in her favor, and she was executed. Vernet blamed David for her death, and the episode followed him for the rest of his life and after.

In the last 50 years David has enjoyed a revival in popular favor and in 1948 his two-hundredth birthday was celebrated with an exhibition at the Musée de l'Orangerie in Paris and at Versailles showing his life's works. Following World War II, Jacques-Louis David was increasingly regarded as a symbol of French national pride and identity, as well as a vital force in the development of European and French art in the modern era. The birth of Romanticism is traditionally credited to the paintings of eighteenth-century French artists such as Jacques-Louis David.

There are streets named after David in the French cities of Carcassonne and Montpellier.

"Danton" (Andrzej Wajda, France, 1982) – Historical drama. Many scenes include David as a silent character watching and drawing. The film focuses on the period of the Terror.





Design Science License

Design Science License (DSL) is a copyleft license for any type of free content such as text, images, music. Unlike other open source licenses, the DSL was intended to be used on any type of copyrightable work, including documentation and source code. It was the first “generalized copyleft” license. The DSL was written by Michael Stutz.

The DSL came out in the 1990s, before the formation of the Creative Commons. Once the Creative Commons arrived, Stutz considered the DSL experiment "over" and no longer recommended its use.


Drum kit

A drum kit (also called a drum set, trap set, or simply drums) is a collection of drums, cymbals, and sometimes other auxiliary percussion instruments set up to be played by one person. The drummer typically holds a pair of matching drumsticks, and uses their feet to operate hi-hat and bass drum pedals. 

A standard kit usually consists of:

The drum kit is a part of the standard rhythm section and is used in many types of popular and traditional music styles, ranging from rock and pop to blues and jazz.

Before the development of the classic drum kit, drums and cymbals used in military and orchestral music settings were played separately by different percussionists. In the 1840s, percussionists began to experiment with foot pedals as a way to enable them to play more than one instrument, but these devices would not be mass-produced for another 75 years. By the 1860s, percussionists started combining multiple drums into a kit. The bass drum, snare drum, cymbals, and other percussion instruments were all struck with hand-held drumsticks. Drummers in musical theater appeared in stage shows, where the budget for pit orchestras was often limited due to an insufficient amount of money able to purchase a full percussionist team. This contributed to the creation of the drum kit by developing techniques and devices that would enable one person to replace multiple percussionists.

Double-drumming was developed to enable one person to play both bass and snare drums with sticks, while the cymbals could be played by tapping the foot on a "low-boy". With this approach, the bass drum was usually played on beats one and three (in time). While the music was first designed to accompany marching soldiers, this simple and straightforward drumming approach led to the birth of ragtime music, when the simple marching beats became more syncopated. This resulted in a greater swing and dance feel. The drum kit was initially referred to as a "trap set", and from the late 1800s to the 1930s, drummers were referred to as "trap drummers". By the 1870s, drummers were using an overhang pedal. Most drummers in the 1870s preferred to do double-drumming without any pedal to play multiple drums, rather than use an overhang pedal. Companies patented their pedal systems, such as that of drummer Edward "Dee Dee" Chandler of New Orleans in 1904 or 1905. This led to the bass drum being played by percussionists standing and using their feet, hence the term "kick drum". 

William F. Ludwig Sr. and his brother Theobald founded Ludwig & Ludwig Co. in 1909 and patented the first commercially successful bass drum pedal system. 

In 1912, drummers replaced sticks with wire brushes and, later, metal fly swatters as the louder sounds made by using drumsticks could overpower other instruments.

By World War I, drum kits were often marching-band-style bass drums with many percussion items around them and suspended from them. Drum kits became a central part of jazz, especially Dixieland. The modern drum kit was developed in the vaudeville era, during the 1920s, in New Orleans.

Drummers such as Baby Dodds, Zutty Singleton, and Ray Bauduc took the idea of marching rhythms and combined the bass drum, snare drum, and "traps"a term used to refer to the percussion instruments associated with immigrant groups, which included miniature cymbals, tom toms, cowbells, and woodblocks. They started incorporating these elements into ragtime, which had been popular for a few decades, creating an approach that evolved into a jazz drumming style.

Budget constraints and space considerations in musical theater pit orchestras led bandleaders to pressure percussionists to cover more percussion parts. Metal consoles were developed to hold Chinese tom-toms, with swing-out stands for snare drums and cymbals. On top of the console was a "contraption" tray (shortened to "trap"), used to hold items like whistles, klaxons, and cowbells. These kits were dubbed "trap kits". Hi-hat stands became available around 1926.

In 1918, Baby Dodds, playing on Mississippi River riverboats with Louis Armstrong, modified the military marching setup, experimenting with playing the drum rims instead of woodblocks, hitting cymbals with sticks (which was not yet common), and adding a side cymbal above the bass drum, which became known as the ride cymbal. William Ludwig developed the "sock" or early low-mounted hi-hat after observing Dodds' drumming. Dodds asked Ludwig to raise the newly produced low-hat cymbal nine inches to make them easier to play, thus creating the modern hi-hat cymbal. Dodds was one of the first drummers to play the broken-triplet beat that became the standard rhythm of modern ride cymbal playing. He also popularized the use of Chinese cymbals. Recording technology was crude, which meant loud sounds could distort the recording. To get around this, Dodds used woodblocks and drum rims as quieter alternatives to cymbals and drum skins.

In the 1920s, freelance drummers were hired to play at shows, concerts, theaters, and clubs to support dancers and musicians of various genres. Orchestras were hired to accompany silent films, and the drummer was responsible for providing the sound effects. Sheet music from the 1920s shows that the drummer's sets were starting to evolve in size to support the various acts. However, by 1930, films with audio were more popular, and many were accompanied by pre-recorded soundtracks. This technological breakthrough put thousands of drummers who served as sound effects specialists out of work, with some drummers obtaining work as foley artists for those motion-picture sound tracks.

Kit drumming, whether accompanying voices and other instruments or performing a drum solo, consists of two elements:

A fill is a departure from the repetitive rhythm pattern in a song. A drum fill can be used to "fill in" the space between the end of one verse and the beginning of another verse or chorus. Fills vary from a simple few strokes on a tom or snare to a distinctive rhythm played on the hi-hat, to sequences several bars long that are short virtuosic drum solos. As well as adding interest and variation to the music, fills serve an important function in indicating significant changes of sections in songs as well as linking them together. A "vocal cue" is a short drum fill that introduces a singer's entrance into the piece. A fill ending with a cymbal crash on beat one is often used to lead into a chorus or verse.

A drum solo is an instrumental section that highlights the drums. While other instrument solos are typically accompanied by the other rhythm section instruments (e.g., bass guitar and electric guitar), for most drum solos, the band members stop playing so that all focus will be on the drummer. In some drum solos, the other rhythm section instrumentalists may play "punches" at certain pointssudden, loud chords of short duration. Drum solos are common in jazz but are also used in several rock genres, such as heavy metal and progressive rock. During drum solos, drummers have a degree of creative freedom, allowing them to use complex polyrhythms that would otherwise be unsuitable with an ensemble. In live concerts, drummers may be given extended drum solos, even in genres where drum solos are rare on recordings.

Most drummers hold the drumsticks in one of two types of grip:

The bass drum (also known as the "kick drum") is the lowest-pitched drum and usually provides the beat or timing element with basic pulse patterns. Some drummers may use two or more bass drums or a double pedal on a single bass drum, which enables a drummer to play a double-bass-drum style with only one drum. This saves space in recording/performance areas and reduces time and effort during set-up, taking down, and transportation. Double bass drumming is a technique used in certain genres, including heavy metal and progressive rock.

The snare drum provides the backbeat. When applied in this fashion, it supplies strong regular accents played by the non-dominant hand and is the backbone for many fills. Its distinctive sound can be attributed to the bed of stiff metal wires held under tension against the bottom head (known as the snare head). When the top head (known as the batter head) is struck with a drumstick, the snare wires vibrate, creating a snappy, staccato buzzing sound, along with the sound of the stick striking the batter head.

Tom-tom drums, or toms for short, are drums without snares and played with sticks (or whatever tools the music style requires) and are the most numerous drums in most kits. They provide the bulk of most drum fills and solos.

They include:

The smallest and largest drums without snares (octobans and gong drums, respectively) are sometimes considered toms. The naming of common configurations (four-piece, five-piece, etc.) is largely a reflection of the number of toms, as conventionally only the drums are counted, and these configurations all contain one snare and one or more bass drums, (though not regularly any standardized use of two bass/kick drums) the balance usually being made up by toms.

Octobans are smaller toms designed for use in a drum kit, extending the tom range upwards in pitch, primarily by their great depth and small diameter. They are also called rocket toms and tube toms.

Timbales are tuned much higher than a tom of the same diameter, typically have drum shells made of metal, and are normally played with very light, thin, non-tapered sticks. Timbales are more common in Latin music. They have thin heads and a very different tone than a tom but are used by some drummers/percussionists to extend the tom range upwards. Alternatively, they can be fitted with tom heads and tuned as shallow concert toms.

Attack timbales and mini timbales are reduced-diameter timbales designed for drum kit usage, the smaller diameter allowing for thicker heads providing the same pitch and head tension. They are recognizable in genres of the 2010s and more traditional forms of Latin, reggae, and numerous other styles.

Gong drums are a rare extension of a drum kit. This single-headed mountable drum appears similar to a bass drum (around 20–24 inches in diameter) but is played with sticks rather than a foot-operated pedal and therefore has the same purpose as a floor tom.

Most hand drums cannot be played with drumsticks without risking damage to the head and bearing edge, which is not protected by a metal drum rim. For use in a drum kit, they may be fitted with a metal drum head and played with sticks with care, or played by hand.

In most drum kits and drum/percussion kits, cymbals are as prominent as the drums themselves. The oldest idiophones in music are cymbals, a version of which were used throughout the ancient Near East very early in the Bronze Age period. Cymbals are mostly associated with Turkey and Turkish craftsmanship, where Zildjian has made them since 1623.

While most drummers purchase cymbals individually, beginner cymbal packs were brought to market to provide entry-level cymbals for the novice drummer. The kits normally contain four cymbals: one ride, one crash, and a pair of hi-hats. Some contain only three cymbals, using a crash/ride instead of the separate ride and crash. The sizes closely follow those given in Common configurations below. Most drummers extend the normal configuration by adding another crash, a splash, and/or a china/effects cymbal.

The ride cymbal is most often used for keeping a constant rhythm pattern, every beat or more often, as the music requires. Development of this ride technique is generally credited to jazz drummer Baby Dodds.

Most drummers have a single main ride, located near their dominant handwithin easy playing reach, as it is used regularlyoften a 20"–22" in diameter, but diameters of 16"–26" are not uncommon. It is usually a medium-heavy- to heavy-weight cymbal whose sound that cuts through other instrumental sounds. Some drummers use a swish cymbal, sizzle cymbal, or other exotic or lighter metal rides, as the main or only ride in their kit, particularly for jazz, gospel, or ballad/folk sounds. In the 1960s, Ringo Starr of the Beatles used a sizzle cymbal as a second ride, particularly during guitar solos.

Hi-hat cymbals (nicknamed "hats") consist of two cymbals mounted, one upside down, with their bottoms facing each other, on a hollow metal support cylinder with folding support legs that keep the support cylinder vertical. Like the bass drum, the hi-hat has a foot pedal. The bottom cymbal is fixed in place. The top cymbal is mounted on a thin rod, which is inserted into the hollow cymbal stand. The thin rod is connected to a foot pedal. When the foot pedal is pressed down, it causes the thin rod to move down, causing the upper cymbal to move and strike the lower. When the foot is lifted off the pedal, the upper cymbal rises, due to the pedal's spring-loaded mechanism. The hi-hats can be sounded by striking the cymbals with one or two sticks or just by closing and opening the cymbals with the foot pedal. The ability to create rhythms on the hi-hats with the foot alone expands the drummer's ability to create sounds, as the hands are freed up to play on the drums or other cymbals. Different sounds can be created by striking "open hi-hats" (without the pedal depressed, which creates a noisy sound nicknamed "sloppy hats") or a crisp "closed hi-hats" sound (with the pedal pressed down). High hats can also be struck with the pedal partially depressed.

A unique effect can be created by striking an open hi-hat (where the two cymbals are apart) and then closing the cymbals with the foot pedal. This effect is widely used in disco and funk. The hi-hat has a similar function to the ride cymbal; the two are rarely played consistently for long periods at the same time, but one or the other is often used to keep what is known as the "ride rhythm" (e.g., eighth or sixteenth notes) in a song. The hi-hats are played by the right stick of a right-handed drummer. Changing between ride and hi-hat, or between either and a "leaner" sound with neither, is often used to mark a change from one song section to another.

Crash cymbals are usually the strongest accent markers within the kit, marking crescendos and climaxes, vocal entries, and major changes of mood, swells, and effects. A crash cymbal is often accompanied by a strong kick on the bass drum pedal, both for musical effect and to support the stroke. It provides a fuller sound and is a commonly taught technique.

In jazz, using the smallest kits and at very high volumes, ride cymbals may be played with the technique and sound of a crash cymbal. Some hi-hats will also give a useful crash, particularly thinner hats or those with a severe taper. Alternatively, specialized crash/ride and ride/crash cymbals are designed to combine both functions.

All cymbals, other than rides, hi-hats, and crashes/splashes, are usually called effects cymbals when used in a drum kit, though this is a non-classical or colloquial designation that has become standardized. Most extended kits include one or more splash cymbals and at least one china cymbal. Major cymbal makers produce cymbal extension packs consisting of one splash and one china, or more rarely a second crash, a splash, and a china, to match some of their starter packs of ride, crash, and hi-hats. However, any combination of options can be found in the marketplace.

Some cymbals may be considered effects in some kits but "basic" in another set of components. Likewise, Ozone crashes have the same purpose as a standard crash cymbal, but are considered to be effects cymbals due to their rarity, and the holes cut into them, which provide a darker, more resonant attack.

Cymbals, of any type, used to provide an accent, rather than a regular pattern or groove, are known as accent cymbals. While any cymbal can be used to provide an accent, the term is more narrowly applied to cymbals for which the main purpose is to provide an accent. Accent cymbals include chime cymbals, small-bell domed cymbals, and those cymbals with a clear sonorous/oriental chime to them, such as specialized crash, splash, and china cymbals.

Low-volume cymbals are a specialty type of cymbal, made to produce about 80% less volume than a typical cymbal. The entire surface of the cymbal is perforated by holes. Drummers use low-volume cymbals to play in small venues or as a way to practice without disturbing others.

Other instruments that have regularly been incorporated into drum kits include:

See also Extended kits below.

Electronic drums are used for many reasons. Some drummers use electronic drums for playing in small venues, such as coffeehouses or church services, where a very low volume for the band is desired. Since fully electronic drums do not create any acoustic sound (apart from the quiet sound of the stick hitting the sensor pads), all of the drum sounds come from a keyboard amplifier or PA system; as such, the volume of electronic drums can be much lower than an acoustic kit. Some use electronic drums as practice instruments because they can be listened to with headphones, which enable a drummer to practice without disturbing others. Others use electronic drums to take advantage of the huge range of sounds that modern drum modules can produce, which range from sampled sounds of real drums, cymbals, and percussion instruments such as gongs or tubular bells that would be impractical to take to a small gig, to electronic and synthesized sounds, including non-instrument sounds such as ocean waves.

A fully electronic kit is easier to soundcheck than acoustic drums, assuming that the electronic drum module has levels that the drummer has preset in their practice room; in contrast, when an acoustic kit is sound checked, most drums and cymbals need to be mic'd and each mic needs to be tested by the drummer so its level and tone equalization can be adjusted by the sound engineer. Also, even after all the individual drum and cymbal mics are sound checked, the engineer needs to listen to the drummer play a standard groove, to check that the balance between the kit instruments is right. Finally, the engineer needs to set up the monitor mix for the drummer, which the drummer uses to hear their instruments and the instruments and vocals of the rest of the band. With a fully electronic kit, many of these steps can be eliminated.

Drummers' usage of electronic drum equipment can range from adding a single electronic pad to an entire drum kit (e.g., to have access to an instrument that might otherwise be impractical, such as a large gong), to using a mix of acoustic drums/cymbals and electronic pads, to using an acoustic kit in which the drums and cymbals have triggers, which can be used to sound electronic drums and other sounds, to having an exclusively electronic kit, which is often set up with the rubber or mesh drum pads and rubber "cymbals" in the usual drum kit locations. A fully electronic kit weighs much less and takes up less space to transport than an acoustic kit and it can be set up more quickly. One of the disadvantages of a fully electronic kit is that it may not have the same "feel" as an acoustic kit, and the drum sounds, even if they are high-quality samples, may not sound the same as acoustic drums.

Electronic drum pads are the second most widely used type of MIDI performance controllers, after electronic keyboards. Drum controllers may be built into drum machines, they may be standalone control surfaces (e.g., rubber drum pads), or they may emulate the look and feel of acoustic percussion instruments. The pads built into drum machines are typically too small and fragile to be played with sticks, so they are usually played with fingers. Dedicated drum pads such as the Roland Octapad or the DrumKAT are playable with hands or sticks and are often built to resemble the general form of acoustic drums. There are also percussion controllers such as the vibraphone-style MalletKAT, and Don Buchla's Marimba Lumina.

MIDI triggers can also be installed into acoustic drum and percussion instruments. Pads that trigger a MIDI device can be homemade from a piezoelectric sensor and a practice pad or other piece of foam rubber, which is possible in two ways:


In either case, an electronic control unit (sound module/"brain") with suitable sampled/modeled or synthesized drum sounds, amplification equipment (a PA system, keyboard amp, etc.), and stage monitor speakers are required to hear the electronically produced sounds. See Triggered drum kit.

A trigger pad could contain up to four independent sensors, each of them capable of sending information describing the timing and dynamic intensity of a stroke to the drum module/brain. A circular drum pad may have only one sensor for triggering, but a 2016-era cymbal-shaped rubber pad/cymbal will often contain two; one for the body and one for the bell at the center of the cymbal, and perhaps a cymbal choke trigger, to allow drummers to produce this effect.

Trigger sensors are most commonly used to replace the acoustic drum sounds, but they can also be used effectively with an acoustic kit to augment or supplement an instrument's sound for the needs of the session or show. For example, in a live performance in a difficult acoustical space, a trigger may be placed on each drum or cymbal and used to trigger a similar sound on a drum module. These sounds are then amplified through a PA system so the audience can hear them, and they can be amplified to any level without the risks of audio feedback or bleed problems associated with microphones and PAs in certain settings.

The sound of electronic drums and cymbals themselves is heard by the drummer and possibly other musicians in close proximity, but, even so, the foldback (audio monitor) system is usually fed from the electronic sounds rather than the live acoustic sounds. The drums can be heavily dampened (made to resonate less or have the sound subdued), and their tuning and quality is less critical in the latter scenario. In this way, much of the atmosphere of the live performance is retained in a large venue, but without some of the problems associated with purely microphone-amplified drums. Triggers and sensors can also be used in conjunction with conventional or built-in microphones. If some components of a kit prove more difficult to mic than others (e.g., an excessively "boomy" low tom), triggers may be used on only the more difficult instruments, balancing out a drummer's/band's sound in the mix.

Trigger pads and drums, on the other hand, when deployed in a conventional set-up, are most commonly used to produce sounds not possible with an acoustic kit, or at least not with what is available. Any sound that can be sampled/recorded can be played when the pad is struck, by assigning the recorded sounds to specific triggers. Recordings or samples of barking dogs, sirens, breaking glass, and stereo recordings of aircraft taking off and landing have all been used. Along with the more obvious electronically generated drums, there are other sounds that (depending on the device used) can also be played/triggered by electronic drums.

Virtual drums are a type of audio software that simulates the sound of a drum kit using synthesized drum kit sounds or digital samples of acoustic drum sounds. Different drum software products offer a recording function, the ability to select from several acoustically distinctive drum kits (e.g., jazz, rock, metal), as well as the option to incorporate different songs into the session. Some computer software can turn any hard surface into a virtual drum kit using only one microphone.

Hardware is the name given to the metal stands that support the drums, cymbals, and other percussion instruments. Generally, the term also includes the hi-hat pedal and clutch, and bass drum pedal or pedals, and the drum stool.

Hardware is carried along with sticks and other accessories in the traps case, and includes:

Many or even all of the stands may be replaced by a drum rack, which is particularly useful for large drum kits.

Drummers often set up their own drum hardware onstage and adjust it to their comfort level. Major bands on tour will often have a drum tech who knows how to set up the drummer's hardware and instruments in the desired location and with the desired configuration.

Drum kits are traditionally categorized by the number of drums, ignoring cymbals and other instruments. Snare, tom-tom, and bass drums are always counted; other drums, such as octobans, may or may not be counted.

Traditionally, in America and the United Kingdom, drum sizes are expressed as "depth x diameter", both measured in inches. Many drum kit manufacturers have recently been expressing sizes as "diameter x depth", still in inches. For example, a hanging tom 12 inches in diameter and 8 inches deep would be described by Tama as 8 inches × 12 inches, but by Pearl as 12 inches × 8 inches, and a standard diameter Ludwig snare drum 5 inches deep is a 5-inch × 14-inch instrument, while the UK's Premier Manufacturer offers the same dimensions as a 14-inch × 5-inch snare. The sizes of drums and cymbals given below are typical. Many instruments differ slightly or radically from them. Where no size is given, it is because there is too much variety to give a typical size.

A three-piece drum set is the most basic set. A conventional three-piece kit consists of a bass drum, a 14"-diameter snare drum, 12"–14" hi-hats, a single 12"-diameter hanging tom, 8"–9" in depth, and a suspended 14"–18" cymbal, the latter two mounted on the bass drum. These kits were common in the 1950s and 1960s and are still used. It is a common configuration of kits sold through mail order, and, with smaller sized drums and cymbals, of kits for children.

A four-piece kit extends the three-piece by adding one tom, either a second hanging tom mounted on the bass drum (a notable user is Chris Frantz of Talking Heads) and often displacing the cymbal, or by adding a floor tom. Normally another cymbal is added as well, so there are separate ride and crash cymbals, either on two stands, or the ride cymbal mounted on the bass drum to the player's right and the crash cymbal on a separate stand. The standard cymbal sizes are 16" for the crash, and 18"–20", ride, with the 20" ride cymbal the most common.

When a floor tom is added to make a four-piece kit, the floor tom is usually 14" for jazz, and 16" otherwise. This configuration is common in jazz and rock. Notable users include Ringo Starr of The Beatles, Mitch Mitchell of the Jimi Hendrix Experience, John Barbata of the Turtles, and various jazz drummers throughout the 20th century, including Art Blakey, Buddy Rich, and Jo Jones. For jazz, which normally emphasizes the use of a ride cymbal for swing patterns, the lack of second hanging tom in a four-piece kit allows the cymbal to be positioned closer to the drummer, making it easier to play.

If a second hanging tom is used, it is 10" diameter and 8" deep for fusion, or 13" diameter and one inch deeper than for the 12" diameter tom. Otherwise, a 14" diameter hanging tom is added to the 12", both being 8" deep. In any case, both toms are most often mounted on the bass drum with the smaller of the two next to the hi-hats (which are to the left for a right-handed drummer). These kits are particularly useful for smaller venues, where space is limited, such as coffeehouses, cafés, hotel lounges, and small pubs.

The five-piece kit is the full-size kit and is the most common configuration used across various genres and styles. It adds a third tom to the four-piece kit, making for three toms in all. A fusion kit will normally add a 14" tom, either a floor tom or a hanging tom on a stand to the right of the bass drum; in either case, making the tom lineup 10", 12" and 14". Having three toms enables drummers to have high-, middle-, and low-pitched toms, which gives them more options for fills and solos.

Other kits will normally have 12" and 13" hanging toms and either a 14" hanging tom on a stand, a 14" floor tom, or a 16" floor tom. It is common to have 10" and 12" hanging toms, with a 16" floor tom. This configuration is often called a hybrid setup. The bass drum is most commonly 22" in diameter, but rock kits may use 24", fusion 20", jazz 18", and, in larger bands, up to 26". A second crash cymbal is common, typically an inch or two larger or smaller than the 16" one, with the larger of the two to the right for a right-handed drummer. A big band drummer may use crashes up to 20" and a ride up to 24" or, very rarely, 26". A rock kit may also substitute a larger ride cymbal or larger hi-hats, typically 22" for the ride and 15" for the hats.

Most five-piece kits, except for entry-level, also have one or more effects cymbals. Adding cymbals beyond the basic ride, hi-hats, and one-crash configuration requires more stands, in addition to the standard drum hardware packs. Because of this, many higher-cost kits for professionals are sold with little or no hardware, to allow the drummer to choose the stands and bass drum pedal they prefer. At the other extreme, many inexpensive, entry-level kits are sold as a five-piece kit complete with two cymbal stands, most often one straight and one boom, and some even with a standard cymbal pack, a stool, and a pair of 5A drum sticks. In the 2010s, digital kits were often offered in a five-piece kit, usually with one plastic crash cymbal trigger and one ride cymbal trigger. Fully electronic drums do not produce any acoustic sound beyond the quiet tapping of sticks on the plastic or rubber heads. Their trigger-pads are wired up to a synth module or sampler.

If the toms are omitted completely, or the bass drum is replaced by a pedal-operated beater on the bottom skin of a floor tom and the hanging toms omitted, the result is a two-piece cocktail drum kit, originally developed for cocktail lounge acts. Such kits are particularly favored in musical genres such as trad jazz, bebop, rockabilly, and jump blues. Some rockabilly kits and beginner kits for very young players omit the hi-hat stand. In rockabilly, this allows the drummer to play standing rather than seated. A very simple jazz kit for informal or amateur jam sessions consists of a bass drum, snare drum, and hi-hat, often with only a single cymbal (normally a ride, with or without sizzlers).

Although these kits may be small with respect to the number of drums used, the drums themselves are most often of normal size, or even larger in the case of the bass drum. Kits using smaller drums, in both smaller and larger configurations, are for particular uses, such as boutique kits designed to reduce the visual impact of a large kit, kits that need to fit into small spaces in coffeehouses, traveling kits to reduce luggage volume, and junior kits for very young players. Smaller drums also tend to be quieter, again suiting smaller venues, and many of these kits extend this with extra muffling, which allows for quiet or even silent practice.

Common extensions beyond the standard configurations include:

See also other acoustic instruments above. Another versatile extension becoming increasingly common is the use of some electronic drums in a mainly acoustic kit.

Less common extensions found particularly, but not exclusively, in very large kits, include:

Sticks are traditionally made from wood (particularly maple, hickory, and oak), but more recently, metal, carbon fiber, and other materials have been used for sticks. The prototypical wooden drum stick was primarily designed for use with the snare drum, and optimized for playing snare rudiments. Sticks come in a variety of weights and tip designs; 7N is a common jazz stick with a nylon tip, while a 5B is a common wood tipped stick, heavier than a 7N but with a similar profile, and a common standard for beginners. Numbers range from 1 (heaviest) to 10 (lightest).

The meanings of both numbers and letters vary from manufacturer to manufacturer, and some sticks are not described using this system at all, just being known as "Smooth Jazz" (typically a 7N or 9N) or "Speed Rock" (typically a 2B or 3B) for example. Many famous drummers endorse sticks made to their particular preference and sold under their signature.

Besides drumsticks, drummers will also use brushes and Rutes in jazz and similar soft music. More rarely, other beaters such as cartwheel mallets (known to kit drummers as "soft sticks") may be used. It is not uncommon for rock drummers to use the "wrong" (butt) end of a stick for a heavier sound; some makers produce tipless sticks with two butt ends.

A stick bag is the standard way for a drummer to bring drumsticks to a live performance. For easy access, the stick bag is commonly mounted on the side of the floor tom, just within reach of the drummer's right hand, for a right-handed drummer.

Drum muffles are types of mutes that can reduce the ring, boomy overtone frequencies, or overall volume on a snare, bass, or tom. Controlling the ring is useful in studio or live settings when unwanted frequencies can clash with other instruments in the mix. There are internal and external muffling devices which rest on the inside or outside of the drumhead, respectively. Common types of mufflers include muffling rings, gels and duct tape, and improvised methods, such as placing a wallet near the edge of the head. Some drummers muffle the sound of a drum by putting a cloth over the drumhead.

Snare drum and tom-tom
Typical ways to muffle a snare or tom include placing an object on the outer edge of the drumhead. A piece of cloth, a wallet, gel, or fitted rings made of mylar are common objects. Also used are external clip-on muffles. Internal mufflers that lie on the inside of the drumhead are often built into a drum, but are generally considered less effective than external muffles, as they stifle the initial tone, rather than simply reducing its sustain.

Bass drum
Muffling the bass can be achieved with the same muffling techniques as for the snare, but bass drums in a drum kit are more commonly muffled by adding pillows, a sleeping bag, or other soft filling inside the drum, between the heads. Cutting a small hole in the resonant head can also produce a more muffled tone, and allows the manipulation of internally placed muffling. The Evans EQ pad places a pad against the batterhead and, when struck, the pad moves off the head momentarily, then returns to rest against the head, thus reducing the sustain without choking the tone.

Silencers/mutes
Another type of drum muffler is a piece of rubber that fits over the entire drumhead or cymbal. It interrupts contact between the stick and the head, which dampens the sound. They are typically used in practice settings.

Cymbals are usually muted with the fingers or hand, to reduce the length or volume of ringing (e.g., the cymbal choke technique which is a key part of heavy metal drumming). Cymbals can also be muted with special rubber rings or duct tape.

Historical uses
Muffled drums are often associated with funeral ceremonies as well, such as the funerals of Queen Victoria and John F. Kennedy. The use of muffled drums has been written about by such poets as Henry Wadsworth Longfellow, John Mayne, and Theodore O'Hara. Drums have also been used for therapy and learning purposes, such as when an experienced player will sit with a number of students and by the end of the session have all of them relaxed and playing complex rhythms.

There are various types of stick holder accessories, including bags that can be attached to a drum and angled sheath-style stick holders, which can hold a single pair of sticks.

A sizzler is a metal chain, or combination of chains, that is hung across a cymbal, creating a distinctive metallic sound when the cymbal is struck, similar to that of a sizzle cymbal. Using a sizzler is the non-destructive alternative to drilling holes in a cymbal and putting metal rivets in the holes. Another benefit of using a "sizzler" chain is that the chain is removable, with the cymbal being easily returned to its normal sound.

Some sizzlers feature pivoting arms that allow the chains to be quickly lowered onto, or raised from, the cymbal, allowing the effect to be used for some songs and removed for others.

Three types of protective covers are common for kit drums:

As with all musical instruments, the best protection is provided by a combination of a hard-shelled case with interior padding, such as foam, next to the drums and cymbals.

Microphones ("mics") are used with drum kits to pick up the sound of the drums and cymbals for a sound recording and/or to pick up the sound of the drum kit so that it can be amplified through a PA system or sound reinforcement system. While most drummers use microphones and amplification in live shows, so that the sound engineer can adjust the levels of the drums and cymbals, some bands that play quieter genres of music and in small venues, such as coffeehouses, play acoustically, without mics or PA amplification. Small jazz groups, such as jazz quartets or organ trios that are playing in a small bar, will often just use acoustic drums. Of course, if the same small jazz groups play on the mainstage of a big jazz festival, the drums will be miced so that they can be adjusted in the sound system mix. A middle-ground approach is used by some bands that play in small venues: they do not mic every drum and cymbal, but only the instruments that the sound engineer wants to be able to control in the mix, such as the bass drum and the snare.

In miking a drum kit, dynamic microphones, which can handle high sound-pressure levels, are usually used to close-mic drums, which is predominantly the way to mic drums for live shows. Condenser microphones are used for overheads and room mics, an approach which is more common with sound recording applications. Close miking of drums may be done using stands or by mounting the microphones on the rims of the drums, or even using microphones built into the drum itself, which eliminates the need for stands for such microphones, reducing both clutter and set-up time, as well as better isolating them.

For some styles of music, drummers use electronic effects on drums, such as individual noise gates that mute the attached microphone when the signal is below a threshold volume. This allows the sound engineer to use a higher overall volume for the drum kit by reducing the number of "active" mics which could produce unwanted feedback at any one time. When a drum kit is entirely miked and amplified through the sound reinforcement system, the drummer or the sound engineer can add other electronic effects to the drum sound, such as reverb or digital delay.

Some drummers arrive at the venue with their drum kit and use the mics and mic stands provided by the venue's sound engineer. Other drummers bring all their own mics, or selected mics (e.g., good-quality snare and bass drum mics), to ensure that they have good quality mics on hand. In bars and nightclubs, the microphones supplied by the venue can sometimes be in substandard condition, due to the heavy use they experience.

Drummers using electronic drums, drum machines, or hybrid acoustic-electric kits (which blend traditional acoustic drums and cymbals with electronic pads) typically use a monitor speaker, keyboard amplifier, or even a small PA system to hear the electronic drum sounds. Even a drummer playing entirely acoustic drums may use a monitor speaker to hear the drums, especially if playing in a loud rock or metal band, where there is substantial onstage volume from large, powerful guitar stacks. Drummers are often given a large speaker cabinet with a 15" subwoofer to help them monitor their bass drum sound (along with a full-range monitor speaker to hear the rest of their kit). Some sound engineers and drummers prefer to use an electronic vibration system, colloquially known as a "butt shaker" or "throne thumper" to monitor the bass drum, because this lowers the stage volume. With a "butt shaker", the "thump" of each bass drum strike causes a vibration in the drum stool; this way the drummer "feels" their beat on the posterior, rather than hears it.

In-Ear Monitors are also popular among drummers since they also work as earplugs.

A number of accessories are designed for the bass drum. The bass drum can take advantage of the bass reflex speaker design, in which a tuned port (a hole and a carefully measured tube) are put in a speaker enclosure to improve the bass response at the lowest frequencies. Bass drumhead patches protect the drumhead from the impact of the felt beater. Bass drum pillows are fabric bags with filling or stuffing that can be used to alter the tone or resonance of the bass drum. A less expensive alternative to using a specialized bass drum pillow is to use an old sleeping bag.

Some drummers wear special drummer's gloves to improve their grip on the sticks when they play. Drumming gloves often have a textured grip surface made of a synthetic or rubber material and mesh or vents on the parts of the glove not used to hold sticks, to ventilate perspiration. Some drummers wear gloves to prevent blisters.

In some styles or settings—such as country music clubs or churches, small venues, or when a live recording is being made—the drummer may use a transparent Perspex or Plexiglas "drum screen" (also known as a "drum shield") to dampen the onstage volume of the drums. A screen that completely surrounds the drum kit is known as a "drum booth". In live sound applications, drum shields are used so that the audio engineer can have more control over the volume of drums that the audience hears through the PA system mix, or to reduce the overall volume of the drums, as a way to reduce the overall volume of the band. In some recording studios, foam and fabric baffles are used in addition to, or in place of, clear panels. The drawback with foam/cloth baffle panels is that the drummer cannot see well other performers, the record producer, or the audio engineer.

Drummers often bring a carpet, mats, or rugs to venues to prevent the bass drum and hi-hat stand from "crawling" (moving away) on a slippery surface, which can be caused by the drum head striking the bass drum. The carpet also reduces short reverberations (which is generally but not always an advantage), and helps to prevent damage to the flooring or floor coverings. In shows where multiple drummers will bring their kits onstage over the night, it is common for drummers to mark the location of their stands and pedals with tape, to allow for quicker positioning of a kit to a drummer's accustomed position. Bass drums and hi-hat stands commonly have retractable spikes, to help them grip surfaces such as carpet, or rubber feet, to remain stationary on hard surfaces.

Drummers use a variety of accessories when practicing. Metronomes and beat counters are used to develop a sense of a steady beat. Drum muffling pads may be used to lessen the volume of drums during practicing. A practice pad, held on the lap, on a leg, or mounted on a stand, is used for near-silent practice with drumsticks. A set of practice pads mounted to simulate an entire drum kit is known as a practice kit. In the 2010s, these have largely been superseded by electronic drums, which can be listened to with headphones for quiet practice and by kits with non-sounding mesh heads.

Drummers use a drum key for tuning their drums and adjusting some drum hardware. Besides the basic type of drum key (a T-handled wrench) there are various tuning wrenches and tools. Basic drum keys are divided into three types which allows for tuning of three types of tuning screws on drums: square (most used), slotted, and hexagonal. Ratchet-type wrenches allow high-tension drums to be tuned easily. Spin keys (utilizing a ball joint) allow for rapid head changing. Torque-wrench keys are available, graphically revealing the torque given to each lug. Also, tension gauges, or meters, which are set on the head, aid drummers to achieve a consistent tuning. Drummers can tune drums "by ear" or use a digital drum tuner, which "measures tympanic pressure" on the drumhead to provide accurate tuning.

Drum kit music is either written in music notation (called "drum parts"), learned and played by ear, improvised, or some combination of any of all three of these methods. Professional session musician drummers and big-band drummers are often required to read drum parts. Drum parts are most commonly written on a standard five-line staff. As of 2016, a special "percussion clef" is used, while previously the bass clef was used. However, even if the bass, or no, clef is used, each line and space is assigned an instrument in the kit, rather than a pitch. In jazz, traditional music, folk music, rock music, and pop music, drummers are expected to be able to learn songs by ear (from a recording or from another musician who is playing or singing the song) and improvise. The degree of improvisation differs among different styles. Jazz and jazz fusion drummers may have lengthy improvised solos in every song. In rock music and blues, there are also drum solos in some songs, although they tend to be shorter than those in jazz. Drummers in all popular music and traditional music styles are expected to be able to improvise accompaniment parts to songs, once they are told the genre or style (e.g., shuffle, ballad, blues).

On early recording media (until 1925), such as wax cylinders and discs carved with an engraving needle, sound balancing meant that musicians had to be moved back in the room. Drums were often put far from the horn (part of the mechanical transducer) to reduce sound distortion.

In the 2020s, drum parts in many popular music styles are often recorded apart from the other instruments and singers, using multitrack recording techniques. Once the drums are recorded, the other instruments (rhythm guitar, piano, etc.), and then vocals, are added. To ensure that the drum tempo is consistent at this type of recording, the drummer usually plays along with a click track (a type of digital metronome) in headphones. The ability to play accurately along with a click track has become an important skill for professional drummers.

Manufacturers using the American traditional format in their catalogs include these:
Those using the European measures of diameter and depth include these:




Dying Earth

Dying Earth is a fantasy series by the American author Jack Vance, comprising four books originally published from 1950 to 1984.
Some have been called picaresque. They vary from short story collections to a fix-up (novel created from older short stories), perhaps all the way to novel.

The first book in the series, "The Dying Earth", was ranked number 16 of 33 "All Time Best Fantasy Novels" by "Locus" in 1987, based on a poll of subscribers, although it was marketed as a collection and the Internet Speculative Fiction Database (ISFDB) calls it a "loosely connected series of stories".

The stories of the "Dying Earth" series are set in the distant future, at a point when the sun is almost exhausted and magic has asserted itself as a dominant force. The Moon has disappeared and the Sun is in danger of burning out at any time, often flickering as if about to go out, before shining again. The various civilizations of Earth have collapsed for the most part into decadence or religious fanaticism and its inhabitants overcome with a fatalistic outlook. The Earth is mostly barren and cold, and has become infested with various predatory monsters (possibly created by a magician in a former age).

Magic in the Dying Earth is performed by memorizing syllables, and the human brain can only accommodate a certain number at once. When a spell is used, the syllables vanish from the caster's mind. Creatures called sandestins can be summoned and used to perform more complex actions, but are considered dangerous to rely upon. Magic has loose links to the science of old, and advanced mathematics is treated like arcane lore.

The Dying Earth exists alongside several Overworlds and Underworlds. These help add a sense of profound longing and entrapment to the series. While humans can, with relative ease, physically travel to the horrific Underworlds (as Cugel does on several occasions, to his dismay) the vast majority of the population are only capable of mentally visiting the wondrous Overworlds through rare artifacts (e.g. through the "Eyes of the Overworld") or dangerous magic phenomena (such as the ship Cugel encounters in the deserts). Though they can look at the wonders and pretend they are really there, humans can never truly inhabit or escape to these utopias as their physical bodies remain stuck on the Dying Earth and will die with the sun regardless. These siren-like visions of paradise lead to the deaths, insanity, and suffering of many, especially during Cugel's journeys.

While most remaining civilizations on the Dying Earth are utterly unique in their customs and cultures, there are some common threads. Because the moon is gone and wind is often weak (the sun no longer heats the earth as much) the oceans are largely placid bodies of water with no tide and tiny waves. To cross them, boats are propelled by giant sea-worms. These worms are cared for and controlled by "Wormingers". In addition, the manses of magicians, protected by walls and spells and monsters, are relatively common sights in inhabited lands.

Vance wrote the stories of the first book while he served in the United States Merchant Marine during World War II. In the late 1940s several of his other stories were published in magazines.
According to pulp editor Sam Merwin, Vance's earliest magazine submissions in the 1940s were heavily influenced by the style of James Branch Cabell. Fantasy historian Lin Carter has noted several probable lasting influences of Cabell on Vance's work, and suggests that the early "pseudo-Cabell" experiments bore fruit in "The Dying Earth" (1950).

The series comprises four books by Vance and some sequels by other authors that may be or may not have been canonical.


One 741-page omnibus edition has been issued as "The Compleat Dying Earth" (SF Book Club, 1999) and in both the US and UK as "Tales of the Dying Earth" (2000).

All four books were published with Tables of Contents, the first and fourth as collections. The second and third contained mostly material previously published in short story form but were marketed as novels, the second as a fix-up and the third without acknowledging any previous publication.

1. "The Dying Earth" (the author's preferred title is "Mazirian the Magician") was openly a collection of six stories, all original, although written during Vance's war service. ISFDB calls them "slightly connected" and catalogs the last as a novella (17,500 to 40,000 word count).

2. "The Eyes of the Overworld" (the author's preferred title is "Cugel the Clever") was a fix-up of six stories, presented as seven. All were novelettes by word count (7500 to 17,500). Five were previously published as noted here.

3. "Cugel's Saga" (the author's preferred title is "Cugel: The Skybreak Spatterlight") was marketed as a novel. ISFDB calls it "[t]wice as large and less episodic than "The Eyes of the Overworld"" but qualifies that label. "This is marketed as a novel, but there is a table of contents, and some of the parts were previously published (although none are acknowledged thus)." It catalogs previous publication of three chapters without remark on the degree of revision.

4. "Rhialto the Marvellous" was marketed as a collection, a Foreword and three stories, one previously published. The Foreword is non-narrative canonical fiction presenting the general state of the world in the 21st Aeon (a "short story" loosely).

Some sequels have been written by other authors, either with Vance's authorization or as tributes to his work.

Michael Shea's first publication, the novel "A Quest for Simbilis" (DAW Books, 1974, ), was an authorized sequel to "Eyes". However, "When Vance returned to the milieu, his "Cugel's Saga" continued the events of "The Eyes of the Overworld" in a different direction."

The tribute anthology "Songs of the Dying Earth" (2009) contains short fiction set in the world of the Dying Earth by numerous writers alongside tributes to Vance's work and influence.

In 2010 Shea wrote another authorized story belonging to the "Dying Earth" series and featuring Cugel as one of characters: "Hew the Tintmaster", published in the anthology "Swords & Dark Magic: The New Sword and Sorcery", ed. Jonathan Strahan and Lou Anders (Eos, 2010, pp. 323–362).

WorldCat contributing libraries report holding all four books in French, Spanish, and (in omnibus edition) Hebrew translations; and report holding "The Dying Earth" in five other languages: Finnish, German, Japanese, Polish, and Russian.

The whole first volume (of six stories) has been translated also into Esperanto together with two Cugel stories and made available on-line as e-books by a long-time fan and Vance Integral Edition co-worker. Permission to translate and distribute (only into Esperanto) was obtained informally direct from the author and, since his death in 2013, continues with ongoing permission from the author's estate. To date these are three: "Mazirian the Magician", "The Sorcerer Pharesm", and "The Bagful of Dreams" available for free download as EPub, Mobi and PDF.

The entire series has seen several Italian translations, and in Italy Vance remains one of the US scifi authors most often translated and published 

The Dying Earth subgenre of science fiction is named in recognition of Vance's role in standardizing a setting, the entropically dying earth and sun. Its importance was recognized with the publication of "Songs of the Dying Earth", a tribute anthology edited by George R. R. Martin and Gardner Dozois (Subterranean, 2009). Each short story in the anthology is set on the Dying Earth, and concludes with a short acknowledgement by the author of Vance's influence on them.

Gene Wolfe's "The Book of the New Sun" (1980–83) is set in a slightly similar world, and was written under Vance's influence. Wolfe suggested in "The Castle of the Otter", a collection of essays, that he inserted the book "The Dying Earth" into his fictional world under the title "The Book of Gold" (specifically, Wolfe wrote that the "Book of Gold" mentioned in "The Book of the New Sun" is different for each reader, but for him it was "The Dying Earth"). Wolfe has extended the series.

Michael Shea's novel "Nifft the Lean" (1982), his second book eight years after "A Quest for Simbilis", also owes much debt to Vance's creation, since the protagonist of the story is a petty thief (not unlike Cugel the Clever), who travels and struggles in an exotic world. Shea returned to Nifft with 1997 and 2000 sequels.

The Archonate stories by Matthew Hughes — the 1994 novel "Fools Errant" and numerous works in this millennium —
take place in "the penultimate age of Old Earth," a period of science and technology that is on the verge of transforming into the magical era of the time of the Dying Earth.
Booklist has called him Vance's "heir apparent." (Review by Carl Hays of The Gist Hunter and Other Stories, Booklist, August 2005)

The original creators of the "Dungeons & Dragons" games were fans of Jack Vance and incorporated many aspects of the "Dying Earth" series into the game. The magic system, in which a wizard is limited in the number of spells that can be simultaneously remembered and forgets them once they are cast, was based on the magic of Dying Earth. In role-playing game circles, this sort of magic system is called "Vancian" or "Vancean". Some of the spells from "Dungeons & Dragons" are based on spells mentioned in the "Dying Earth" series, such as the "prismatic spray". Magic items from the "Dying Earth" stories such as ioun stones also made their way into "Dungeons & Dragons". One of the deities of magic in "Dungeons & Dragons" is named Vecna, an anagram of "Vance".

The "Talislanta" role-playing game designed by Stephan Michael Sechi and originally published in 1987 by Bard Games was inspired by the works of Jack Vance so much so that the first release, "The Chronicles of Talislanta", is dedicated to the author.

There is an official "Dying Earth" role-playing game published by Pelgrane Press with an occasional magazine "The Excellent Prismatic Spray" (named after a magic spell). The game situates players in Vance's world populated by desperately extravagant people. Many other role-playing settings pay homage to the series by including fantasy elements he invented such as the darkness-dwelling Grues.

"Goodman Games" have announced the publication of the setting using their "Dungeon Crawl Classics" roleplaying game system, running a successful "Kickstarter" campaign for it. The game was released in 2023.


Dispute resolution

Dispute resolution or dispute settlement is the process of resolving disputes between parties. The term "dispute resolution" is sometimes used interchangeably with "conflict resolution". 

Prominent venues for dispute settlement in international law include the International Court of Justice (formerly the Permanent Court of International Justice); the United Nations Human Rights Committee (which operates under the ICCPR) and European Court of Human Rights; the Panels and Appellate Body of the World Trade Organization; and the International Tribunal for the Law of the Sea. Half of all international agreements include a dispute settlement mechanism.

States are also known to establish their own arbitration tribunals to settle disputes. Prominent private international courts, which adjudicate disputes between commercial private entities, include the International Court of Arbitration (of the International Chamber of Commerce) and the London Court of International Arbitration.

Methods of dispute resolution include:

One could theoretically include violence or even war as part of this spectrum, but dispute resolution practitioners do not usually do so; violence rarely ends disputes effectively, and indeed, often only escalates them. Also, violence rarely causes the parties involved in the dispute to no longer disagree on the issue that caused the violence. For example, a country successfully winning a war to annex part of another country's territory does not cause the former waring nations to no longer seriously disagree to whom the territory rightly belongs to and tensions may still remain high between the two nations. 

Dispute resolution processes fall into two major types:

Not all disputes, even those in which skilled intervention occurs, end in resolution. Such intractable disputes form a special area in dispute resolution studies.

Dispute resolution is an important requirement in international trade, including negotiation, mediation, arbitration and litigation.

The legal system provides resolutions for many different types of disputes. Some disputants will not reach agreement through a collaborative process. Some disputes need the coercive power of the state to enforce a resolution. Perhaps more importantly, many people want a professional advocate when they become involved in a dispute, particularly if the dispute involves perceived legal rights, legal wrongdoing, or threat of legal action against them.

The most common form of judicial dispute resolution is litigation. Litigation is initiated when one party files suit against another. In the United States, litigation is facilitated by the government within federal, state, and municipal courts. While litigation is often used to resolve disputes, it is strictly speaking a form of conflict adjudication and not a form of conflict resolution per se. This is because litigation only determines the legal rights and obligations of parties involved in a dispute and does not necessarily solve the disagreement between the parties involved in the dispute. For example, supreme court cases can rule on whether US states have the constitutional right to criminalize abortion but will not cause the parties involved in the case to no longer disagree on whether states do indeed have the constitutional authority to restrict access to abortion as one of the parties may disagree with the supreme courts reasoning and still disagree with the party that the supreme court sided with. Litigation proceedings are very formal and are governed by rules, such as rules of evidence and procedure, which are established by the legislature. Outcomes are decided by an impartial judge and/or jury, based on the factual questions of the case and the application law. The verdict of the court is binding, not advisory; however, both parties have the right to appeal the judgment to a higher court. Judicial dispute resolution is typically adversarial in nature, for example, involving antagonistic parties or opposing interests seeking an outcome most favorable to their position. 

Due to the antagonistic nature of litigation, collaborators frequently opt for solving disputes privately. 

Retired judges or private lawyers often become arbitrators or mediators; however, trained and qualified non-legal dispute resolution specialists form a growing body within the field of alternative dispute resolution (ADR). In the United States, many states now have mediation or other ADR programs annexed to the courts, to facilitate settlement of lawsuits.

Some use the term "dispute resolution" to refer only to alternative dispute resolution (ADR), that is, extrajudicial processes such as arbitration, collaborative law, and mediation used to resolve conflict and potential conflict between and among individuals, business entities, governmental agencies, and (in the public international law context) states. ADR generally depends on agreement by the parties to use ADR processes, either before or after a dispute has arisen. ADR has experienced steadily increasing acceptance and utilization because of a perception of greater flexibility, costs below those of traditional litigation, and speedy resolution of disputes, among other perceived advantages. However, some have criticized these methods as taking away the right to seek redress of grievances in the courts, suggesting that extrajudicial dispute resolution may not offer the fairest way for parties not in an equal bargaining relationship, for example in a dispute between a consumer and a large corporation. In addition, in some circumstances, arbitration and other ADR processes may become as expensive as litigation or more so.


Catan: Cities &amp; Knights

Catan: Cities & Knights (), formerly "The Cities and Knights of Catan" is an expansion to the board game "The Settlers of Catan" for three to four players (five to six player play is also possible with the "Settlers" and "Cities & Knights" five to six player extensions; two-player play is possible with the "" expansion). It contains features taken from "The Settlers of Catan", with emphasis on city development and the use of knights, which are used as a method of attacking other players as well as helping opponents defend Catan against a common foe. "Cities & Knights" can also be combined with the "" expansion or with scenarios (again, five to six player play only possible with the applicable five to six player extension(s)).

Because of the new rules introduced in "Cities & Knights", the game is played to 13 victory points, as opposed to 10 as in the base game "The Settlers of Catan".

The following cards are not used in Cities & Knights:

One of the main additions to the game is commodities, which are a type of secondary resource produced only by cities. Like resources, commodities are associated with a type of terrain, can be stolen by the robber (with "Seafarers", also the pirate), count against the resource hand limit, and may not be collected if the robber is on the terrain. Resources may be traded for commodities, and commodities may be traded for resources. Commodities can then be used to build city improvements (provided the player has a city), which provide additional benefits.

The commodities are paper (which comes from forest terrain), coin (from mountain terrain), and cloth (from pasture terrain).

When combining "Cities & Knights" with "Barbarian Attack", the written rules are ambiguous with regards to whether commodities are collected along with normal resources when collecting from a Gold River tile, as well as whether or not commodities can be collected directly from Gold River tiles. However, online rules state that "Gold can only buy you resources, not commodities."

A city on grain or brick gives two of each, as in the original "Settlers". A city on wool, ore, or wood, produces one corresponding resource as well as one corresponding commodity (cloth, coin, or paper). Grain and brick, however, are used for new purchasing options: grain activates knights, and brick can be used to build city walls.

In total there are 36 commodity cards: 12 paper (from forest), 12 cloth (from pasture), and 12 coin (from mountains).

A player with a city may use commodities to build city improvements, which allow several advantages. There are city improvements in five levels, and in three different categories. Each category of improvements requires a different commodity and higher levels require more cards of that commodity. At the third level, players earn a special ability, depending on the type of improvement.

The first player with an improvement at the fourth level can claim any of their cities as a metropolis, worth four victory points instead of two for that city. Each type of improvement has only one associated metropolis, and no city can be a metropolis of two different types (because of this, a player without a non-metropolis city may not build improvements beyond the third level). If a player is the first to build an improvement to the final level (out-building the current holder of the metropolis), they take the metropolis from its current holder.

The other significant concept in "Cities & Knights" is the concept of knights, which replace the concept of soldiers and the largest army. Knights are units that require continuous maintenance through their activation mechanism, but have a wide variety of functions. Knights can be promoted through three ranks, although promotion to the final rank is a special ability granted by the city improvement the Fortress.

Knights are placed on the board in a similar manner to settlements, and can be used to block opposing roads, active or not. However, knights must be activated in order to perform other functions, which immediately deactivate the knight. Knights cannot perform actions on the same turn they are activated, but can be reactivated on the same turn as performing an action. These actions include:

If a knight is promoted or forced to retreat, its active status does not change.

The standard "Cities & Knights" game comes with 24 knights, 6 of each color. The 5/6 player extension adds a further 12 knights, 6 each of two new colors.

"Cities & Knights" introduces a third die, known as the event die, which serves two functions. The first applies to the concept of barbarians, a periodic foe that all players must work together to defend against. Three of the sides of the event die have a picture of a ship on them. The other three sides have a symbol of a city gate, allowing players who have sufficiently built up a city to obtain progress cards (see below).

The barbarians are represented by a ship positioned on a track representing the distance between the ship and Catan (i.e. the board). Each time the event die shows a black ship, the barbarian ship takes one step closer to Catan. When the barbarians arrive at Catan, a special phase is immediately performed before all other actions (including collecting resources). In this special phase, the barbarians' attack strength, corresponding to the combined number of cities and metropolises held by all players, is compared to Catan's defense strength, corresponding to the combined levels (i.e. 1 point for each basic, 2 for each strong, and 3 for each mighty) of all activated knights in play.

If the barbarians are successful in their attack (if they have a strength greater than Catan), then the players must pay the consequence. The player(s) who had the least defense will be attacked, and will have one city reduced to a settlement. If they only have settlements, or metropolises, then they are immune to barbarians and do not count as the player contributing the least defense.

Should Catan prevail, the player who contributes the most to Catan's defense receives a special "Defender of Catan" card, worth a victory point. Regardless of the outcome, all knights are immediately deactivated, and the barbarian ship returns to its starting point on the track. In the event of a tie among the greatest contributors of knights, none of the tied players earn a Defender of Catan card. Instead, each of the tied players draw a progress card (explained below) of the type of their choosing. There are 6 Defender of Catan cards.

As the likelihood of having the barbarian move closer to Catan is very high, a variant in common usage is that the robber (and with "Seafarers", the pirate) does not move until the first barbarian attack, nor can a knight move the robber before that point.

Examples where cities are lost:


The other significant outcome of the event die is Progress cards, which replace development cards. Because of the mechanics of progress cards explained below, one of the two white dice used in "Settlers" is replaced by a red die.

Progress cards are organized into three categories, corresponding to the three types of improvements. Yellow progress cards aid in commercial development, green progress cards aid in technological advancements, and blue progress cards allow for political moves. When a castle appears on the event die, progress cards of the corresponding type may be drawn depending on the value of the red die. Higher levels of city improvements increase the chance that progress cards will be drawn, with the highest level of city improvement allowing progress cards to be drawn regardless of the value on the red die.

Progress cards, unlike the development cards they replace, can be played on the turn that they are drawn, and more than one progress card can be played per turn. However, they can generally only be played after the dice are rolled. Progress cards granting victory points are an exception, being played immediately (without regards to whose turn it is), while the Alchemist progress card, which allows a player to select the roll of the white and red dice, necessitates the card being played instead of rolling the numerical dice. (The event die is still rolled as normal.)

Players are allowed to keep four progress cards (five in a five to six player game), and any additional ones must be discarded on the spot (unless the 5th card is a victory point, which is played immediately and the original progress cards remain). The only exception to this rule is when the player receives a 5th non-victory point progress card during their turn, in which case the player may choose to play any one of the five progress cards in hand, bringing the progress card count back down to four. While this clarification is not overtly stated in the Cities & Knights rule book, it is enforced in the online version of the game.

In total, there are 54 progress cards: 18 science, 18 politics, and 18 trade.

Out of all the available progress cards, progress cards containing victory points can be only earned in the science and politics categories.

City walls are a minor addition to "Cities & Knights" that increase the number of resource and commodity cards a player is allowed in their hand before having to discard on a roll of 7. However, they do not protect the player from the robber or barbarians. Only cities and metropolises may have walls, and each city or metropolis can only have one wall, up to three walls per player. Each wall that the player has deployed permits the player to hold two more cards before being required to discard on a roll of seven. This results in a maximum of 13 cards.

If the barbarians pillage your city, then the city wall is also destroyed and the wall is removed from the board.

The game comes with 12 city walls, 3 of each color.

The merchant is another addition to "Cities & Knights". Like the robber, the merchant is placed on a single land hex. Unlike the robber, the merchant has a beneficial effect.

The merchant can only be deployed through the use of a Merchant progress card (of which there are six), on a land hex near a city or a settlement. The player with the control of the merchant can trade the resource (not commodity) of that type at a two-to-one rate, as if the player had a control of a corresponding two-to-one harbor.

The player with the control of the merchant also earns a victory point. Both the victory point and the trade privilege are lost if another player takes control of the merchant.

In place of "The Settlers of Catan" standard improvement cost card, "Cities & Knights" gives a calendar type flip-chart to each player, matching that player's color. The top of the chart has the standard costs from the "Settlers" game (for settlements, upgrade to city, and roads). It does not include the Development Card cost as those cards are not used in a "Cities & Knights" game. It does include the costs of hiring a knight, upgrading a knight's level or strength, and the cost to activate a knight. It also includes the cost of a ship, which are not used in a regular game of "Cities & Knights", but presumably this is to cater for players who have combined "Cities & Knights" and "Seafarers".

Those are only the rudimentary costs of the game however. The calendar also shows the costs of the next city improvement in each of the three categories — as a city is improved in a category, that segment has its card flipped down calendar style to reveal the newly built improvement, any advantages gained by the improvement, and the updated cost of upgrading to the next level in that category. Each segment, as it is flipped down, also shows the updated dice pattern needed to earn the player a progress card in that category.

"Catan: Legend of the Conquerors" is a scenario released in 2017 for the expansion "Catan: Cities & Knights". A blog post was made in connection with the release. The game adds swamp hexes to the board. The game also adds a cannon which can be combined with a knight to increase the strength of a knight by one, which makes the maximum possible strength 4, when applied to a mighty knight of strength 3 (formula_1). To build a cannon, you pay 1 lumber and 1 ore for a foundry. When you combine a cannon and a knight you have a cannoneer. The game also adds a horse farm that you can build for one lumber and one grain. The horse farm gives you a horse that you can use to turn one of your knights into cavalry. A cavalry unit can move between road networks, even if there is no connection between them. The cannon and horse cannot be combined. The blog post writes, "Some strategists may like the idea of equipping a knight with a horse and a cannon, thus making it some kind of overpowering “mounted cannoneer.” However, you are not allowed to place both playing pieces adjacent to a knight. This being said, it’s also hard to imagine a knight on a horse holding a cannon in his arms and firing it in all directions... "



The official website for the world of Catan. (2016). Retrieved May 17, 2016, from <nowiki>http://www.catan.com/service/game-rules</nowiki>

Catan: Seafarers

Catan: Seafarers, or Seafarers of Catan in older editions, () is an expansion of the board game "Catan" for three to four players (five-to-six-player play is also possible with both of the respective five-to-six-player extensions). The main feature of this expansion is the addition of ships, gold fields, and the pirate to the game, allowing play between multiple islands. The expansion also provides numerous scenarios, some of which have custom rules. The "Seafarers" rules and scenarios are also, for the most part, compatible with "" and "".

The concepts introduced in "Seafarers" were part of designer Klaus Teuber's original design for "Settlers".

"Seafarers" introduces the concept of ships, which serve as roads over water or along the coast. Each ship costs one lumber and one wool to create (lumber for the hull and wool for the sails). A settlement must first be built before a player can switch from building roads to building ships, or vice versa. Thus, a chain of ships is always anchored at a settlement on the coast. A shipping line that is not anchored at both ends by different settlements can also move the last ship at the open end, although this can only be done once per turn and may not be done with any ships that were created on the same turn.

The "Longest Road" card is now renamed the "Longest Trade Route" since this is now calculated by counting the number of contiguous ships "plus" roads that a player has. A settlement or city is necessary between a road and a ship for the two to be considered continuous for the purposes of this card.

The Road Building card allows a player to build 2 roads, 2 ships, or one of each when used.

Along with the concept of ships, "Seafarers" also introduces the notion of the pirate, which acts as a waterborne robber which steals from nearby ships (similar to how the robber steals from nearby settlements). The pirate can also prevent ships from being built or moved nearby, but it does not interfere with harbors. The pirate does not prevent settlements from being built

When a seven is rolled or a Knight card is played, the player may move either the robber OR the pirate.

"Seafarers" also introduces the "Gold River" or "Gold Field" terrain, which grants nearby players one resource of their choice for every settlement adjacent to a gold tile and 2 resources for every city. Since being able to choose any resource type allows more building power, gold rivers are often either marked with number token of only 2 or 3 dots and/or are far away from starting positions to offset this.

When combined with "Cities & Knights", the rules state that you are not allowed to take commodities instead of resources if a city is nearby.

Some scenarios have extra rules encompassing the concept of exploration, which is done by having the hex tiles placed face down. Should a player build next to unexplored terrain, the terrain tile is turned face up, and the player is rewarded with a resource should the tile revealed be resource-producing. In other scenarios, the board is divided into islands, and if the player builds a settlement on an island other than the ones they begin on, the settlement is worth extra victory points.

The "Cities and Knights" manual recommends that players not use the "Cities & Knights" rules in scenarios where exploration is a factor.

Unlike "The Settlers of Catan" and "Catan: Cities & Knights", in which the only random element of setup is the placement of land tiles, number tokens, and harbors in an identically-shaped playing area, "Catan: Seafarers" has a number of different scenarios or maps from which to choose. Each map uses a different selection of tiles laid out in a specific pattern, which may not use all of the tiles. Other attributes also set each map apart, for example, restrictions on the placement of initial settlements, whether tiles are distributed randomly, the number of victory points needed to win, and special victory point awards, usually for building on islands across the sea.

"Seafarers" provides scenarios for three or four players (the older fourth edition used the same maps for three- and four-player versions of the scenarios), while the extension provides scenarios for six players (the older third edition also included separate maps for five- and six-player scenarios). The scenarios between the older editions of "Seafarers" and the newest are generally incompatible, knowing the different frames included with the game. (In particular, older editions of "Settlers" did not come with a frame for their board; a separate add-on was made available for players of the older-edition "Settlers" games, containing the newer edition frames, so as to make them compatible with the newer edition of "Seafarers"; the older edition of "Seafarers" included a square frame, and while both older and newer editions of the frames have the same width across, the newer editions are not square-shaped, and are longer down the middle of the board compared to the sides.)

"Heading to New Shores" ("New Shores" in older editions) is the scenario resembling Teuber's original design for the game. The game board consists of the main "Settlers" island as well as a few smaller islands, which award a special victory point to each player for their first settlements on them. This scenario is meant for players new to "Seafarers", with elements of "Seafarers" incorporated into the more familiar main board.

"The Four Islands" is the first scenario introduced where new mechanics introduced to "Seafarers" is brought into the forefront. In this scenario, the map is split up into four islands of roughly equal size and resource distribution. (The six-player version found in the extension has the map split into six islands; the scenario is titled "The Six Islands", but is played identically. Older editions of the extension had a five-player version with five islands, called "The Five Islands".) Players may claim up to two of the islands as their home islands, and settling on any of the other islands awards a special victory point.

"The Fog Island" ("Oceans" in older editions) is the first scenario where exploration is used. The board starts off with a portion of the map left blank: when players expand into the blank region, terrain hexes are drawn at random from a supply and placed in the empty space, and, if a land hex is "discovered", a number token may be assigned. As a reward for discovering land, the player making the discovery is rewarded with a bonus resource card corresponding to the type of land hex discovered.

"Through the Desert" ("Into the Desert" in older edition) is similar to "The Four Islands", but consists of a large continent and smaller outlying islands. On the large island, there exists a "wall of deserts" that separates the island into a large main area and separate smaller strips of land. As the name of the scenario implies, expanding through the desert into these smaller strips of land, or by sea to the outlying islands, award bonus victory points.

"The Forgotten Tribe", originally titled "Friendly Neighbors", was a downloadable scenario (but only in the German language) which was incorporated into newer editions of "Seafarers".

The map consists of a main island and smaller outlying islands, where the namesake forgotten tribe resides. Players may not expand into the outlying islands, but by building ships so that they border the outlying islands, players may be awarded with victory points, development cards, or harbors that players may place on the coast of the main island at a later time.

Introduced in the newer editions, "Cloth for Catan" continues the adventures with the Forgotten Tribe. The scenario was previously available for older editions as a downloadable scenario (but only in German), titled "Coffee for Catan".

Players begin with settlements on the outside of the map, but may build ships to reach the Forgotten Tribe's islands, which are in the center. By connecting to the Forgotten Tribe's settlements (represented by number tokens), players may earn cloth tokens when the number token for the Forgotten Tribe's villages are rolled. Cloth tokens, in turn, are worth one victory point for each pair obtained.

"The Pirate Island", introduced in newer editions, is the first scenario which changes the mechanics of new gameplay elements introduced in "Seafarers". "The Pirate Island" had previously been available as a downloadable scenario (but only in German) suitable for the older editions.

In this scenario, players begin with a pre-placed settlement on a main island. Ships may only be built in one single line, which must pass through a fixed waypoint (different for each player) en route to a pirate fortress (each player has their own pirate fortress). Once ships connect to the pirate fortress, they may attempt to attack the pirate fortress once per turn. Ships may be lost if the attack is unsuccessful, but after three successful attacks, the pirate fortress is converted into a settlement. Players must convert their pirate fortresses and have 10 victory points before being able to claim victory.

Furthermore, the pirate mechanics have also changed: the pirate moves through the middle of the map in a fixed path every turn, and attacks the owner of any nearby settlements. Players win resources if they are able to fend off the pirate attack (which depends on the number rolled by the dice, as well as the number of warships in the defending player's possession; warships are created from using Knight cards on existing ships), but lose resources if they are unsuccessful. Maritime expansion is only permitted by building a settlement at the waypoint, however, this increases the chances of a pirate attack.

"The Wonders of Catan" was a downloadable scenario for older editions of "Seafarers" in both German and English, and was incorporated into "Seafarers" in newer editions.

In this scenario, there are a number of "wonders", each with a large cost of building as well as a prerequisite. If a player meets the prerequisite for a wonder, they may claim the wonder for themselves. A player may only claim one wonder, and each wonder may only be claimed by one player. Wonders must be built in four parts, and each wonder has a different build cost. The winner is the first player to complete their wonder, or the first player to have 10 victory points and have more parts of their wonder complete than any other player.

"The Great Crossing" was a scenario in the older editions of "Seafarers", which has been dropped in newer editions. The map is divided into two islands, Catan and Transcatania. Players begin with both settlements on one of the islands, and must build ships connecting settlements between the two islands. Players earn victory points for connecting their settlements with settlements (not necessarily theirs) from the opposite island using ships, or to another player's shipping lines which connect two settlements together.

"Greater Catan" was a scenario included in the older editions of "Seafarers" but is not included in newer editions. Due to the sheer amounts of equipment needed, two copies of "Settlers" and "Seafarers" are required to set up this scenario. The map consists of a standard "Settlers" island, along with a smaller chain of outlying islands. Only the main island initially has number tokens: number tokens are assigned to the outlying islands as they are expanded. However, the supply of number tokens is smaller than the number of hexes in the scenario: when the number tokens run out and players expand into a new part of the outlying islands, number tokens are moved from the main island to the outlying islands.

Hexes on the main island for which there are no number tokens do not produce resources, but number tokens are moved in such a way so as to avoid rendering a city unproductive; furthermore, whenever possible number tokens must be reassigned from hexes bordering a player's own settlements and cities, so as to prevent harming another player's economy without harming a player's own economy at the same time.

"New World" is a scenario that blankets all other scenarios that may be created from the parts of "Settlers" and "Seafarers". This scenario uses an entirely random map, and players are encouraged to try and create a tile layout that plays well. The only difference between versions in "Seafarers", the extension, and the older editions therein is the size of the frames.

"The Seafarers of Catan" was reviewed in the online second volume of "Pyramid".



Dynamical system

In mathematics, a dynamical system is a system in which a function describes the time dependence of a point in an ambient space, such as in a parametric curve. Examples include the mathematical models that describe the swinging of a clock pendulum, the flow of water in a pipe, the random motion of particles in the air, and the number of fish each springtime in a lake. The most general definition unifies several concepts in mathematics such as ordinary differential equations and ergodic theory by allowing different choices of the space and how time is measured. Time can be measured by integers, by real or complex numbers or can be a more general algebraic object, losing the memory of its physical origin, and the space may be a manifold or simply a set, without the need of a smooth space-time structure defined on it.

At any given time, a dynamical system has a state representing a point in an appropriate state space. This state is often given by a tuple of real numbers or by a vector in a geometrical manifold. The "evolution rule" of the dynamical system is a function that describes what future states follow from the current state. Often the function is deterministic, that is, for a given time interval only one future state follows from the current state. However, some systems are stochastic, in that random events also affect the evolution of the state variables.

In physics, a dynamical system is described as a "particle or ensemble of particles whose state varies over time and thus obeys differential equations involving time derivatives". In order to make a prediction about the system's future behavior, an analytical solution of such equations or their integration over time through computer simulation is realized.

The study of dynamical systems is the focus of dynamical systems theory, which has applications to a wide variety of fields such as mathematics, physics, biology, chemistry, engineering, economics, history, and medicine. Dynamical systems are a fundamental part of chaos theory, logistic map dynamics, bifurcation theory, the self-assembly and self-organization processes, and the edge of chaos concept.

The concept of a dynamical system has its origins in Newtonian mechanics. There, as in other natural sciences and engineering disciplines, the evolution rule of dynamical systems is an implicit relation that gives the state of the system for only a short time into the future. (The relation is either a differential equation, difference equation or other time scale.) To determine the state for all future times requires iterating the relation many times—each advancing time a small step. The iteration procedure is referred to as "solving the system" or "integrating the system". If the system can be solved, then, given an initial point, it is possible to determine all its future positions, a collection of points known as a "trajectory" or "orbit".

Before the advent of computers, finding an orbit required sophisticated mathematical techniques and could be accomplished only for a small class of dynamical systems. Numerical methods implemented on electronic computing machines have simplified the task of determining the orbits of a dynamical system.

For simple dynamical systems, knowing the trajectory is often sufficient, but most dynamical systems are too complicated to be understood in terms of individual trajectories. The difficulties arise because:

Many people regard French mathematician Henri Poincaré as the founder of dynamical systems. Poincaré published two now classical monographs, "New Methods of Celestial Mechanics" (1892–1899) and "Lectures on Celestial Mechanics" (1905–1910). In them, he successfully applied the results of their research to the problem of the motion of three bodies and studied in detail the behavior of solutions (frequency, stability, asymptotic, and so on). These papers included the Poincaré recurrence theorem, which states that certain systems will, after a sufficiently long but finite time, return to a state very close to the initial state.

Aleksandr Lyapunov developed many important approximation methods. His methods, which he developed in 1899, make it possible to define the stability of sets of ordinary differential equations. He created the modern theory of the stability of a dynamical system.

In 1913, George David Birkhoff proved Poincaré's "Last Geometric Theorem", a special case of the three-body problem, a result that made him world-famous. In 1927, he published his "Dynamical Systems". Birkhoff's most durable result has been his 1931 discovery of what is now called the ergodic theorem. Combining insights from physics on the ergodic hypothesis with measure theory, this theorem solved, at least in principle, a fundamental problem of statistical mechanics. The ergodic theorem has also had repercussions for dynamics.

Stephen Smale made significant advances as well. His first contribution was the Smale horseshoe that jumpstarted significant research in dynamical systems. He also outlined a research program carried out by many others.

Oleksandr Mykolaiovych Sharkovsky developed Sharkovsky's theorem on the periods of discrete dynamical systems in 1964. One of the implications of the theorem is that if a discrete dynamical system on the real line has a periodic point of period 3, then it must have periodic points of every other period.

In the late 20th century the dynamical system perspective to partial differential equations started gaining popularity. Palestinian mechanical engineer Ali H. Nayfeh applied nonlinear dynamics in mechanical and engineering systems. His pioneering work in applied nonlinear dynamics has been influential in the construction and maintenance of machines and structures that are common in daily life, such as ships, cranes, bridges, buildings, skyscrapers, jet engines, rocket engines, aircraft and spacecraft.

In the most general sense,
a dynamical system is a tuple ("T", "X", Φ) where "T" is a monoid, written additively, "X" is a non-empty set and Φ is a function
with
and for any "x" in "X":
for formula_6 and formula_7, where we have defined the set formula_8 for any "x" in "X".

In particular, in the case that formula_9 we have for every "x" in "X" that formula_10 and thus that Φ defines a monoid action of "T" on "X".

The function Φ("t","x") is called the evolution function of the dynamical system: it associates to every point "x" in the set "X" a unique image, depending on the variable "t", called the evolution parameter. "X" is called phase space or state space, while the variable "x" represents an initial state of the system.

We often write 
if we take one of the variables as constant. The function 
is called the flow through "x" and its graph is called the trajectory through "x". The set
is called the orbit through "x".
Note that the orbit through "x" is the image of the flow through "x".
A subset "S" of the state space "X" is called Φ-invariant if for all "x" in "S" and all "t" in "T"
Thus, in particular, if "S" is Φ-invariant, formula_16 for all "x" in "S". That is, the flow through "x" must be defined for all time for every element of "S".

More commonly there are two classes of definitions for a dynamical system: one is motivated by ordinary differential equations and is geometrical in flavor; and the other is motivated by ergodic theory and is measure theoretical in flavor.

In the geometrical definition, a dynamical system is the tuple formula_17. formula_18 is the domain for time – there are many choices, usually the reals or the integers, possibly restricted to be non-negative. formula_19 is a manifold, i.e. locally a Banach space or Euclidean space, or in the discrete case a graph. "f" is an evolution rule "t" → "f" (with formula_20) such that "f" is a diffeomorphism of the manifold to itself. So, f is a "smooth" mapping of the time-domain formula_21 into the space of diffeomorphisms of the manifold to itself. In other terms, "f"("t") is a diffeomorphism, for every time "t" in the domain formula_21 .

A "real dynamical system", "real-time dynamical system", "continuous time dynamical system", or "flow" is a tuple ("T", "M", Φ) with "T" an open interval in the real numbers R, "M" a manifold locally diffeomorphic to a Banach space, and Φ a continuous function. If Φ is continuously differentiable we say the system is a "differentiable dynamical system". If the manifold "M" is locally diffeomorphic to R, the dynamical system is "finite-dimensional"; if not, the dynamical system is "infinite-dimensional". Note that this does not assume a symplectic structure. When "T" is taken to be the reals, the dynamical system is called "global" or a "flow"; and if "T" is restricted to the non-negative reals, then the dynamical system is a "semi-flow". 

A "discrete dynamical system", "discrete-time dynamical system" is a tuple ("T", "M", Φ), where "M" is a manifold locally diffeomorphic to a Banach space, and Φ is a function. When "T" is taken to be the integers, it is a "cascade" or a "map". If "T" is restricted to the non-negative integers we call the system a "semi-cascade".

A "cellular automaton" is a tuple ("T", "M", Φ), with "T" a lattice such as the integers or a higher-dimensional integer grid, "M" is a set of functions from an integer lattice (again, with one or more dimensions) to a finite set, and Φ a (locally defined) evolution function. As such cellular automata are dynamical systems. The lattice in "M" represents the "space" lattice, while the one in "T" represents the "time" lattice.

Dynamical systems are usually defined over a single independent variable, thought of as time. A more general class of systems are defined over multiple independent variables and are therefore called multidimensional systems. Such systems are useful for modeling, for example, image processing.

Given a global dynamical system (R, "X", Φ) on a locally compact and Hausdorff topological space "X", it is often useful to study the continuous extension Φ* of Φ to the one-point compactification "X*" of "X". Although we lose the differential structure of the original system we can now use compactness arguments to analyze the new system (R, "X*", Φ*).

In compact dynamical systems the limit set of any orbit is non-empty, compact and simply connected.

A dynamical system may be defined formally as a measure-preserving transformation of a measure space, the triplet ("T", ("X", Σ, "μ"), Φ). Here, "T" is a monoid (usually the non-negative integers), "X" is a set, and ("X", Σ, "μ") is a probability space, meaning that Σ is a sigma-algebra on "X" and μ is a finite measure on ("X", Σ). A map Φ: "X" → "X" is said to be Σ-measurable if and only if, for every σ in Σ, one has formula_23. A map Φ is said to preserve the measure if and only if, for every "σ" in Σ, one has formula_24. Combining the above, a map Φ is said to be a measure-preserving transformation of "X" , if it is a map from "X" to itself, it is Σ-measurable, and is measure-preserving. The triplet ("T", ("X", Σ, "μ"), Φ), for such a Φ, is then defined to be a dynamical system.

The map Φ embodies the time evolution of the dynamical system. Thus, for discrete dynamical systems the iterates formula_25 for every integer "n" are studied. For continuous dynamical systems, the map Φ is understood to be a finite time evolution map and the construction is more complicated.

The measure theoretical definition assumes the existence of a measure-preserving transformation. Many different invariant measures can be associated to any one evolution rule. If the dynamical system is given by a system of differential equations the appropriate measure must be determined. This makes it difficult to develop ergodic theory starting from differential equations, so it becomes convenient to have a dynamical systems-motivated definition within ergodic theory that side-steps the choice of measure and assumes the choice has been made. A simple construction (sometimes called the Krylov–Bogolyubov theorem) shows that for a large class of systems it is always possible to construct a measure so as to make the evolution rule of the dynamical system a measure-preserving transformation. In the construction a given measure of the state space is summed for all future points of a trajectory, assuring the invariance.

Some systems have a natural measure, such as the Liouville measure in Hamiltonian systems, chosen over other invariant measures, such as the measures supported on periodic orbits of the Hamiltonian system. For chaotic dissipative systems the choice of invariant measure is technically more challenging. The measure needs to be supported on the attractor, but attractors have zero Lebesgue measure and the invariant measures must be singular with respect to the Lebesgue measure. A small region of phase space shrinks under time evolution.

For hyperbolic dynamical systems, the Sinai–Ruelle–Bowen measures appear to be the natural choice. They are constructed on the geometrical structure of stable and unstable manifolds of the dynamical system; they behave physically under small perturbations; and they explain many of the observed statistics of hyperbolic systems.

The concept of "evolution in time" is central to the theory of dynamical systems as seen in the previous sections: the basic reason for this fact is that the starting motivation of the theory was the study of time behavior of classical mechanical systems. But a system of ordinary differential equations must be solved before it becomes a dynamic system. For example consider an initial value problem such as the following:

where 

There is no need for higher order derivatives in the equation, nor for the parameter "t" in "v"("t","x"), because these can be eliminated by considering systems of higher dimensions.

Depending on the properties of this vector field, the mechanical system is called 

The solution can be found using standard ODE techniques and is denoted as the evolution function already introduced above

The dynamical system is then ("T", "M", Φ).

Some formal manipulation of the system of differential equations shown above gives a more general form of equations a dynamical system must satisfy

where <math>\mathfrak{G}:

Dhimmi

Historically, dhimmi status was originally applied to Jews, Christians, and Sabians, who are considered "People of the Book" in Islamic theology. Later, this status was also applied to Zoroastrians, Sikhs, Hindus, Jains, and Buddhists. 
Jews and Christians were required to pay the "jizyah" while others, depending on the different rulings of the four Madhhabs, might be required to accept Islam, pay the jizya, be exiled, or be killed.

During the rule of al-Mutawakkil, the tenth Abbasid Caliph, numerous restrictions reinforced the second-class citizen status of dhimmīs and forced their communities into ghettos. For instance, they were required to distinguish themselves from their Muslim neighbors by their dress. They were not permitted to build new churches or synagogues or repair old churches according to the Pact of Umar. 

Under "Sharia", the "dhimmi" communities were usually governed by their own laws in place of some of the laws applicable to the Muslim community. For example, the Jewish community of Medina was allowed to have its own Halakhic courts, and the Ottoman millet system allowed its various dhimmi communities to rule themselves under separate legal courts. These courts did not cover cases that involved religious groups outside of their own communities, or capital offences. "Dhimmi" communities were also allowed to engage in certain practices that were usually forbidden for the Muslim community, such as the consumption of alcohol and pork.

Some Muslims reject the "dhimma" system by arguing that it is a system which is inappropriate in the age of nation-states and democracies. There is a range of opinions among 20th-century and contemporary Islamic theologians about whether the notion of "dhimma" is appropriate for modern times, and, if so, what form it should take in an Islamic state.

There are differences among the Islamic Madhhabs regarding which non-Muslims can pay jizya and have dhimmi status. The Hanafi and Maliki Madhabs generally allow non-Muslims to have dhimmi status. In contrast, the Shafi'i and Hanbali Madhabs only allow Christians, Jews and Zoroastrians to have dhimmi status, and they maintain that all other non-Muslims must either convert to Islam or be fought.

Based on Quranic verses and Islamic traditions, "sharia" law distinguishes between Muslims, followers of other Abrahamic religions, and Pagans or people belonging to other polytheistic religions. As monotheists, Jews and Christians have traditionally been considered "People of the Book", and afforded a special legal status known as "dhimmi" derived from a theoretical contract—"dhimma" or "residence in return for taxes". Islamic legal systems based on "sharia" law incorporated the religious laws and courts of Christians, Jews, and Hindus, as seen in the early caliphate, al-Andalus, Indian subcontinent, and the Ottoman Millet system.

In Yemenite Jewish sources, a treaty was drafted between Muhammad and his Jewish subjects, known as "kitāb ḏimmat al-nabi", written in the 17th year of the Hijra (638 CE), which gave express liberty to the Jews living in Arabia to observe the Sabbath and to grow-out their side-locks, but required them to pay the "jizya" (poll-tax) annually for their protection. Muslim governments in the Indus basin readily extended the "dhimmi" status to the Hindus and Buddhists of India. Eventually, the largest school of Islamic jurisprudence applied this term to all Non-Muslims living in Muslim lands outside the sacred area surrounding Mecca, Arabia.

In medieval Islamic societies, the "qadi" (Islamic judge) usually could not interfere in the matters of non-Muslims unless the parties voluntarily chose to be judged according to Islamic law, thus the "dhimmi" communities living in Islamic states usually had their own laws independent from the "sharia" law, as with the Jews who would have their own rabbinical courts. These courts did not cover cases that involved other religious groups, or capital offences or threats to public order. By the 18th century, however, "dhimmi" frequently attended the Ottoman Muslim courts, where cases were taken against them by Muslims, or they took cases against Muslims or other "dhimmi". Oaths sworn by "dhimmi" in these courts were tailored to their beliefs. Non-Muslims were allowed to engage in certain practices (such as the consumption of alcohol and pork) that were usually forbidden by Islamic law, in point of fact, any Muslim who pours away their wine or forcibly appropriates it is liable to pay compensation. Some Islamic theologians held that Zoroastrian "self-marriages", considered incestuous under "sharia", should also be tolerated. Ibn Qayyim Al-Jawziyya (1292–1350) opined that most scholars of the Hanbali school held that non-Muslims were entitled to such practices, as long as they were not presented to sharia courts and the religious minorities in question held them to be permissible. This ruling was based on the precedent that there were no records of the Islamic prophet Muhammad forbidding such self-marriages among Zoroastrians, despite coming into contact with Zoroastrians and knowing about this practice. Religious minorities were also free to do as they wished in their own homes, provided they did not publicly engage in illicit sexual activity in ways that could threaten public morals.

There are parallels for this in Roman and Jewish law. According to law professor H. Patrick Glenn of McGill University, "[t]oday it is said that the dhimmi are 'excluded from the specifically Muslim privileges, but on the other hand they are excluded from the specifically Muslim duties' while (and here there are clear parallels with western public and private law treatment of aliens—Fremdenrecht, la condition de estrangers), '[f]or the rest, the Muslim and the dhimmi are equal in practically the whole of the law of property and of contracts and obligations'." Quoting the Qur'anic statement, "Let Christians judge according to what We have revealed in the Gospel", Muhammad Hamidullah writes that Islam decentralized and "communalized" law and justice. However, the classical "dhimma" contract is no longer enforced. Western influence over the Muslim world has been instrumental in eliminating the restrictions and protections of the "dhimma" contract.

The "dhimma" contract is an integral part of traditional Islamic law. From the 9th century AD, the power to interpret and refine law in traditional Islamic societies was in the hands of the scholars ("ulama"). This separation of powers served to limit the range of actions available to the ruler, who could not easily decree or reinterpret law independently and expect the continued support of the community. Through succeeding centuries and empires, the balance between the ulema and the rulers shifted and reformed, but the balance of power was never decisively changed. At the beginning of the 19th century, the Industrial Revolution and the French Revolution introduced an era of European world hegemony that included the domination of most of the Muslim lands. At the end of the Second World War, the European powers found themselves too weakened to maintain their empires. The wide variety in forms of government, systems of law, attitudes toward modernity and interpretations of sharia are a result of the ensuing drives for independence and modernity in the Muslim world.

Muslim states, sects, schools of thought and individuals differ as to exactly what sharia law entails. In addition, Muslim states today utilize a spectrum of legal systems. Most states have a mixed system that implements certain aspects of sharia while acknowledging the supremacy of a constitution. A few, such as Turkey, have declared themselves secular. Local and customary laws may take precedence in certain matters, as well. Islamic law is therefore polynormative, and despite several cases of regression in recent years, the trend is towards liberalization. Questions of human rights and the status of minorities cannot be generalized with regards to the Muslim world. They must instead be examined on a case-by-case basis, within specific political and cultural contexts, using perspectives drawn from the historical framework.

The status of the dhimmi "was for long accepted with resignation by the Christians and with gratitude by the Jews" but the rising power of Christendom and the radical ideas of the French Revolution caused a wave of discontent among Christian dhimmis. The continuing and growing pressure from the European powers combined with pressure from Muslim reformers gradually relaxed the inequalities between Muslims and non-Muslims.

On 18 February 1856, the Ottoman Reform Edict of 1856 (Hatt-i Humayan) was issued, building upon the 1839 edict. It came about partly as a result of pressure from and the efforts of the ambassadors of France, Austria and the United Kingdom, whose respective countries were needed as allies in the Crimean War. It again proclaimed the principle of equality between Muslims and non-Muslims, and produced many specific reforms to this end. For example, the jizya tax was abolished and non-Muslims were allowed to join the army.


Jews and Christians living under early Muslim rule were considered dhimmis, a status that was later also extended to other non-Muslims like Hindus and Buddhists. They were allowed to "freely practice their religion, and to enjoy a large measure of communal autonomy" and guaranteed their personal safety and security of property, in return for paying tribute and acknowledging Muslim rule. Islamic law and custom prohibited the enslavement of free dhimmis within lands under Islamic rule. Taxation from the perspective of dhimmis who came under the Muslim rule, was "a concrete continuation of the taxes paid to earlier regimes" (but much lower under the Muslim rule). They were also exempted from the zakat tax paid by Muslims. The dhimmi communities living in Islamic states had their own laws independent from the Sharia law, such as the Jews who had their own Halakhic courts. The dhimmi communities had their own leaders, courts, personal and religious laws, and "generally speaking, Muslim tolerance of unbelievers was far better than anything available in Christendom, until the rise of secularism in the 17th century". "Muslims guaranteed freedom of worship and livelihood, provided that they remained loyal to the Muslim state and paid a poll tax". "Muslim governments appointed Christian and Jewish professionals to their bureaucracies", and thus, Christians and Jews "contributed to the making of the Islamic civilization".

However, dhimmis faced social and symbolic restrictions, and a pattern of stricter, then more lax, enforcement developed over time. Marshall Hodgson, a historian of Islam, writes that during the era of the High Caliphate (7th–13th Centuries), zealous Shariah-minded Muslims gladly elaborated their code of symbolic restrictions on the dhimmis.

From an Islamic legal perspective, the pledge of protection granted dhimmis the freedom to practice their religion and spared them forced conversions. The dhimmis also served a variety of useful purposes, mostly economic, which was another point of concern to jurists. Religious minorities were free to do whatever they wished in their own homes, but could not "publicly engage in illicit sex in ways that threaten public morals". In some cases, religious practices that Muslims found repugnant were allowed. One example was the Zoroastrian practice of incestuous "self-marriage" where a man could marry his mother, sister or daughter. According to the famous Islamic legal scholar Ibn Qayyim Al-Jawziyya (1292–1350), non-Muslims had the right to engage in such religious practices even if it offended Muslims, under the conditions that such cases not be presented to Islamic Sharia courts and that these religious minorities believed that the practice in question is permissible according to their religion. This ruling was based on the precedent that Muhammad did not forbid such self-marriages among Zoroastrians despite coming in contact with them and having knowledge of their practices.

The Arabs generally established garrisons outside towns in the conquered territories, and had little interaction with the local dhimmi populations for purposes other than the collection of taxes. The conquered Christian, Jewish, Mazdean and Buddhist communities were otherwise left to lead their lives as before.

According to historians Lewis and Stillman, local Christians in Syria, Iraq, and Egypt were non-Chalcedonians and many may have felt better off under early Muslim rule than under that of the Byzantine Orthodox of Constantinople. In 1095, Pope Urban II urged western European Christians to come to the aid of the Christians of Palestine. The subsequent Crusades brought Roman Catholic Christians into contact with Orthodox Christians whose beliefs they discovered to differ from their own perhaps more than they had realized, and whose position under the rule of the Muslim Fatimid Caliphate was less uncomfortable than had been supposed. Consequently, the Eastern Christians provided perhaps less support to the Crusaders than had been expected. When the Arab East came under Ottoman rule in the 16th century, Christian populations and fortunes rebounded significantly. The Ottomans had long experience dealing with Christian and Jewish minorities, and were more tolerant towards religious minorities than the former Muslim rulers, the Mamluks of Egypt.

However, Christians living under Islamic rule have suffered certain legal disadvantages and at times persecution. In the Ottoman Empire, in accordance with the "dhimmi" system implemented in Muslim countries, they, like all other Christians and also Jews, were accorded certain freedoms. The dhimmi system in the Ottoman Empire was largely based upon the Pact of Umar. The client status established the rights of the non-Muslims to property, livelihood and freedom of worship but they were in essence treated as second-class citizens in the empire and referred to in Turkish as "gavours", a pejorative word meaning "infidel" or "unbeliever". The clause of the Pact of Umar which prohibited non-Muslims from building new places of worship was historically imposed on some communities of the Ottoman Empire and ignored in other cases, at discretion of the local authorities. Although there were no laws mandating religious ghettos, this led to non-Muslim communities being clustered around existing houses of worship.

In addition to other legal limitations, dhimmis, including the Christians among them, were not considered equals to Muslims and several prohibitions were placed on them. Their testimony against Muslims was inadmissible in courts of law wherein a Muslim could be punished; this meant that their testimony could only be considered in commercial cases. They were forbidden to carry weapons or ride atop horses and camels. Their houses could not overlook those of Muslims; and their religious practices were severely circumscribed (e.g., the ringing of church bells was strictly forbidden).

Because the early Islamic conquests initially preserved much of the existing administrative machinery and culture, in many territories they amounted to little more than a change of rulers for the subject populations, which "brought peace to peoples demoralized and disaffected by the casualties and heavy taxation that resulted from the years of Byzantine-Persian warfare".

María Rosa Menocal, argues that the Jewish dhimmis living under the caliphate, while allowed fewer rights than Muslims, were still better off than in the Christian parts of Europe. Jews from other parts of Europe made their way to al-Andalus, where in parallel to Christian sects regarded as heretical by Catholic Europe, they were not just tolerated, but where opportunities to practice faith and trade were open without restriction save for the prohibitions on proselytization.

Bernard Lewis states:

Professor of Jewish medieval history at Hebrew University of Jerusalem, Hayim Hillel Ben-Sasson, notes:

According to the French historian Claude Cahen, Islam has "shown more toleration than Europe towards the Jews who remained in Muslim lands."

Comparing the treatment of Jews in the medieval Islamic world and medieval Christian Europe, Mark R. Cohen notes that, in contrast to Jews in Christian Europe, the "Jews in Islam were well integrated into the economic life of the larger society", and that they were allowed to practice their religion more freely than they could do in Christian Europe.

According to the scholar Mordechai Zaken, tribal chieftains (also known as aghas) in tribal Muslim societies such as the Kurdish society in Kurdistan would tax their Jewish subjects. The Jews were in fact civilians protected by their chieftains in and around their communities; in return they paid part of their harvest as dues, and contributed their skills and services to their patron chieftain.

By the 10th century, the Turks of Central Asia had invaded the Indic plains, and spread Islam in Northwestern parts of India. At the end of the 12th century, the Muslims advanced quickly into the Ganges Plain. In one decade, a Muslim army led by Turkic slaves consolidated resistance around Lahore and brought northern India, as far as Bengal, under Muslim rule. From these Turkic slaves would come sultans, including the founder of the sultanate of Delhi. By the 15th century, major parts of Northern India was ruled by Muslim rulers, mostly descended from invaders. In the 16th century, India came under the influence of the Mughals. Babur, the first ruler of the Mughal empire, established a foothold in the north which paved the way for further expansion by his successors. Although the Mughal emperor Akbar has been described as a universalist, most Mughal emperors were oppressive of native Hindu, Buddhist and later Sikh populations. Aurangzeb specifically was inclined towards a highly fundamentalist approach.

There were a number of restrictions on dhimmis. In a modern sense the dhimmis would be described as second-class citizens. According to historian Marshall Hodgson, from very early times Muslim rulers would very often humiliate and punish dhimmis (usually Christians or Jews that refused to convert to Islam). It was official policy that dhimmis should “feel inferior and to know ‘their place".

Although "dhimmis" were allowed to perform their religious rituals, they were obliged to do so in a manner not conspicuous to Muslims. Loud prayers were forbidden, as were the ringing of church bells and the blowing of the shofar. They were also not allowed to build or repair churches and synagogues without Muslim consent. Moreover, dhimmis were not allowed to seek converts among Muslims. In the Mamluk Egypt, where non-Mamluk Muslims were not allowed to ride horses and camels, dhimmis were prohibited even from riding donkeys inside cities. Sometimes, Muslim rulers issued regulations requiring dhimmis to attach distinctive signs to their houses.

Most of the restrictions were social and symbolic in nature, and a pattern of stricter, then more lax, enforcement developed over time. The major financial disabilities of the dhimmi were the jizya poll tax and the fact dhimmis and Muslims could not inherit from each other. That would create an incentive to convert if someone from the family had already converted. Ira M. Lapidus states that the "payment of the poll tax seems to have been regular, but other obligations were inconsistently enforced and did not prevent many non-Muslims from being important political, business, and scholarly figures. In the late ninth and early tenth centuries, Jewish bankers and financiers were important at the 'Abbasid court." The jurists and scholars of Islamic sharia law called for humane treatment of the dhimmis.

A Muslim man may marry a Jewish or Christian dhimmī woman, who may keep her own religion (though her children were automatically considered Muslims and had to be raised as such), but a Muslim woman cannot marry a dhimmī man unless he converts to Islam. Dhimmīs are prohibited from converting Muslims under severe penalties, while Muslims are encouraged to convert dhimmīs. 

Payment of the "jizya" obligated Muslim authorities to protect dhimmis in civil and military matters. Sura 9 (At-Tawba), verse 29 stipulates that "jizya" be exacted from non-Muslims as a condition required for jihad to cease. Islamic jurists required adult, free, healthy males among the dhimma community to pay the jizya, while exempting women, children, the elderly, slaves, those affected by mental or physical handicaps, and travelers who did not settle in Muslim lands. According to Abu Yusuf dhimmi should be imprisoned until they pay the jizya in full. Other jurists specified that dhimmis who don't pay jizya should have their heads shaved and made to wear a dress distinctive from those dhimmis who paid the jizya and Muslims.

Lewis states there are varying opinions among scholars as to how much of a burden jizya was. According to Norman Stillman: ""jizya" and "kharaj" were a "crushing burden for the non-Muslim peasantry who eked out a bare living in a subsistence economy." Both agree that ultimately, the additional taxation on non-Muslims was a critical factor that drove many dhimmis to leave their religion and accept Islam. However, in some regions the jizya on populations was significantly lower than the zakat, meaning dhimmi populations maintained an economic advantage. According to Cohen, taxation, from the perspective of dhimmis who came under Muslim rule, was "a concrete continuation of the taxes paid to earlier regimes". Lewis observes that the change from Byzantine to Arab rule was welcomed by many among the dhimmis who found the new yoke far lighter than the old, both in taxation and in other matters, and that some, even among the Christians of Syria and Egypt, preferred the rule of Islam to that of Byzantines. Montgomery Watt states, "the Christians were probably better off as dhimmis under Muslim-Arab rulers than they had been under the Byzantine Greeks." In some places, for example Egypt, the jizya was a tax incentive for Christians to convert to Islam.

Some scholars have tried compute the relative taxation on Muslims vs non-Muslims in the early Abbasid period. According to one estimate, Muslims had an average tax rate of 17–20 dirhams per person, which rose to 30 dirhams per person when in kind levies are included. Non-Muslims paid either 12, 24 or 48 dirhams per person, depending on their taxation category, though most probably paid 12.

The importance of dhimmis as a source of revenue for the Rashidun Caliphate is illustrated in a letter ascribed to Umar I and cited by Abu Yusuf: "if we take dhimmis and share them out, what will be left for the Muslims who come after us? By God, Muslims would not find a man to talk to and profit from his labors."

The early Islamic scholars took a relatively humane and practical attitude towards the collection of "jizya", compared to the 11th century commentators writing when Islam was under threat both at home and abroad.

The jurist Abu Yusuf, the chief judge of the caliph Harun al-Rashid, rules as follows regarding the manner of collecting the jizya

In the border provinces, dhimmis were sometimes recruited for military operations. In such cases, they were exempted from jizya for the year of service.

Religious pluralism existed in medieval Islamic law and ethics. The religious laws and courts of other religions, including Christianity, Judaism and Hinduism, were usually accommodated within the Islamic legal framework, as exemplified in the Caliphate, Al-Andalus, Ottoman Empire and Indian subcontinent. In medieval Islamic societies, the qadi (Islamic judge) usually could not interfere in the matters of non-Muslims unless the parties voluntarily chose to be judged according to Islamic law. The dhimmi communities living in Islamic states usually had their own laws independent from the Sharia law, such as the Jews who had their own Halakha courts.

Dhimmis were allowed to operate their own courts following their own legal systems. However, dhimmis frequently attended the Muslim courts in order to record property and business transactions within their own communities. Cases were taken out against Muslims, against other dhimmis and even against members of the dhimmi's own family. Dhimmis often took cases relating to marriage, divorce or inheritance to the Muslim courts so these cases would be decided under sharia law. Oaths sworn by dhimmis in the Muslim courts were sometimes the same as the oaths taken by Muslims, sometimes tailored to the dhimmis' beliefs.

Muslim men could generally marry dhimmi women who are considered People of the Book, however Islamic jurists rejected the possibility any non-Muslim man might marry a Muslim woman. Bernard Lewis notes that "similar position existed under the laws of Byzantine Empire, according to which a Christian could marry a Jewish woman, but a Jew could not marry a Christian woman under pain of death".

Lewis states

A hadith by Muhammad, "Whoever killed a (a person who is granted the pledge of protection by the Muslims) shall not smell the fragrance of Paradise though its fragrance can be smelt at a distance of forty years (of traveling).", is cited as a foundation for the right of non-Muslim citizens to live peacefully and undisturbed in an Islamic state. Anwar Shah Kashmiri writes in his commentary on Sahih al-Bukhari "Fayd al-Bari" on this hadith: "You know the gravity of sin for killing a Muslim, for its odiousness has reached the point of disbelief, and it necessitates that [the killer abides in Hell] forever. As for killing a non-Muslim citizen [], it is similarly no small matter, for the one who does it will not smell the fragrance of Paradise."

A similar hadith in regard to the status of the dhimmis: "Whoever wrongs one with whom a compact (treaty) has been made "[i.e., a dhimmi]" and lays on him a burden beyond his strength, I will be his accuser."

The Constitution of Medina, a formal agreement between Muhammad and all the significant tribes and families of Medina (including Muslims, Jews and pagans), declared that non-Muslims in the Ummah had the following rights:

A precedent for the dhimma contract was established with the agreement between Muhammad and the Jews after the Battle of Khaybar, an oasis near Medina. Khaybar was the first territory attacked and conquered by Muslims. When the Jews of Khaybar surrendered to Muhammad after a siege, Muhammad allowed them to remain in Khaybar in return for handing over to the Muslims one half their annual produce.

The Pact of Umar, traditionally believed to be between caliph Umar and the conquered Jerusalem Christians in the seventh century, was another source of regulations pertaining to dhimmis. However, Western orientalists doubt the authenticity of the pact, arguing it is usually the victors and not the vanquished who impose rather than propose, the terms of peace, and that it is highly unlikely that the people who spoke no Arabic and knew nothing of Islam could draft such a document. Academic historians believe the Pact of Umar in the form it is known today was a product of later jurists who attributed it to Umar in order to lend greater authority to their own opinions. The similarities between the Pact of Umar and the Theodosian and Justinian Codes of the Eastern Roman Empire suggest that perhaps much of the Pact of Umar was borrowed from these earlier codes by later Islamic jurists. At least some of the clauses of the pact mirror the measures first introduced by the Umayyad caliph Umar II or by the early Abbasid caliphs.

During the Middle Ages, local associations known as "futuwwa" clubs developed across the Islamic lands. There were usually several futuwwah in each town. These clubs catered to varying interests, primarily sports, and might involve distinctive manners of dress and custom. They were known for their hospitality, idealism and loyalty to the group. They often had a militaristic aspect, purportedly for the mutual protection of the membership. These clubs commonly crossed social strata, including among their membership local notables, dhimmi and slaves – to the exclusion of those associated with the local ruler, or amir.

Muslims and Jews were sometimes partners in trade, with the Muslim taking days off on Fridays and Jews taking off on Saturdays.

Andrew Wheatcroft describes how some social customs such as different conceptions of dirt and cleanliness made it difficult for the religious communities to live close to each other, either under Muslim or under Christian rule.

The dhimma and the jizya poll tax are no longer imposed in Muslim majority countries. In the 21st century, jizya is widely regarded as being at odds with contemporary secular conceptions of citizens' civil rights and equality before the law, although there have been occasional reports of religious minorities in conflict zones and areas subject to political instability being forced to pay jizya.

In 2009 it was claimed that a group of militants that referred to themselves as the Taliban imposed the "jizya" on Pakistan's minority Sikh community after occupying some of their homes and kidnapping a Sikh leader.

As late as 2013, in Egypt "jizya" was reportedly being imposed by the Muslim Brotherhood on 15,000 Christian Copts of Dalga Village.

In February 2014, the Islamic State of Iraq and the Levant (ISIL) announced that it intended to extract jizya from Christians in the city of Raqqa, Syria, which it controlled at the time. Christians who refused to accept the dhimma contract and pay the tax were to have to either convert to Islam, leave or be executed. Wealthy Christians would have to pay half an ounce of gold, the equivalent of $664 twice a year; middle-class Christians were to have to pay half that amount and poorer ones were to be charged one-fourth that amount. In June, 2014 the Institute for the Study of War reported that ISIL claims to have collected jizya and fay. On 18 July 2014 ISIL ordered the Christians in Mosul to accept the dhimma contract and pay the jizya or convert to Islam. If they refused to accept either of the options they would be killed.



Doctor V64

The Doctor V64 (also referred to simply as the V64) is a development and backup device made by Bung Enterprises Ltd that is used in conjunction with the Nintendo 64. The Doctor V64 also had the ability to play video CDs and audio CDs. Additionally, it could apply stereo 3D effects to the audio.

The V64 was released in 1996 and was priced around $450 USD. It was the first commercially-available backup device for the Nintendo 64 unit. The Partner N64 development kit, which was manufactured by Silicon Graphics and sold officially by Nintendo, was a comparatively expensive development machine. The V64 served as a lower-cost development machine, though its unofficial status would later lead to conflict with Nintendo. Some third-party developers used a number of V64s in their development process.

The CPU of the V64 is a 6502, and the operating system is contained in a BIOS.

The V64 unit contains a CD-ROM drive which sits underneath the Nintendo 64 and plugs into the expansion slot on the underside of the Nintendo 64. The expansion slot is essentially a mirror image of the cartridge slot on the top of the unit, with the same electrical connections; thus, the Nintendo 64 reads data from the Doctor V64 in the same manner as it would from a cartridge plugged into the normal slot.

In order to get around Nintendo's lockout chip, when using the V64, a game cartridge is plugged into the Nintendo 64 through an adaptor which connects only the lockout chip. The game cart used for the operation had to contain the same lockout chip used by the game back up.

The second problem concerned saving progress. Most N64 games are saved to the cart itself instead of external memory cards. If the player wanted to keep their progress, then the cartridge used had to have the same type of non-volatile memory hardware. Alternatively, Bung produced the "DX256" and "DS1" add-ons to allow (EEPROM and SRAM respectively) saves to be made without using the inserted cartridge. These devices were inserted into the top-slot of the N64 with the game cartridge being then inserted into the top of them to just provide the security bypass. Save slots on the DX256 were selected using an alpha and numeric encoder knobs on the front of the device.

The Doctor V64 could be used to read the data from a game cartridge and transfer the data to a PC via the parallel port. This allowed developers and homebrew programmers to upload their game images to the Doctor V64 without having to create a CD backup each time. It also allowed users to upload game images taken from the Internet.

Following the Doctor V64's success, Bung released the Doctor V64 Jr. in December 1998. This was a condensed, cost-efficient version of the original V64. The Doctor V64 Jr. has no CD drive and plugs into the normal cartridge slot on the top of the Nintendo 64. Data is loaded into the Doctor V64 Jr.'s battery-backed RAM from a PC via a parallel port connection. The Doctor V64 Jr. has up to 512 megabits (64 MB) of memory storage. This was done to provide for future Nintendo 64 carts that employed larger memory storage, but the high costs associated with ordering large storage carts kept this occurrence at a minimum. Only a handful of 512-megabit games were released for the Nintendo 64 system.

In 1998 and 1999, there was a homebrew competition known as "Presence of Mind" (POM), an N64 demo competition led by dextrose.com. The contest consisted of submitting a user-developed N64 program, game, or utility. Bung Enterprises promoted the event and supplied prizes (usually Doctor V64 related accessories). Though a contest was planned for 2000, the interest in the N64 was already fading, and so did the event. POM contest demo entries can still be found on the Internet.

The Doctor V64 unit was the first commercially available backup device for the Nintendo 64 unit. Though the unit was sold as a development machine, it could be modified to enable the creation and use of commercial game backups. Unlike official development units, the purchase of V64s was not restricted to software companies only. For this reason, the unit became a popular choice among those looking to proliferate unlicensed copies of games.

Original Doctor V64 units sold by Bung did not allow the playing of backups. A person would have to modify the unit by themselves in order to make it backup friendly. This usually required a user to download and install a modified Doctor V64 BIOS. Additionally, the cartridge adapter had to be opened and soldered in order to allow for the operational procedure. Though Bung never sold backup enabled V64s, many re-sellers would modify the units themselves.

During the N64's lifetime, Nintendo revised the N64's model, making the serial port area smaller. This slight change in the N64's plastic casing made the connection to the Doctor V64 difficult to achieve without user modification. This revision may have been a direct reaction from Nintendo to discourage the use of V64 devices, and may also explain why Bung decided to discontinue the use of this port in the later Doctor V64 Jr. models.

Nintendo made many legal efforts worldwide in order to stop the sale of Doctor V64 units. They sued Bung directly as well as specific store retailers in Europe and North America for copyright infringement. Eventually, Nintendo managed to have the courts prohibit the sale of Doctor V64 units in the United States.

The Doctor V64 implemented text-based menu-driven screens. The menus consisted of white text superimposed over a black background. Utilizing the buttons on the V64 unit, a user would navigate the menus and issue commands. Though the menu was mainly designed for game developers, it is possible to back up cartridges with it (through the use of an unofficial V64 BIOS). Some of the menu items related to game backups were removed from the V64's BIOS near the end of its life due to pressure from Nintendo. These items are only available by obtaining a patched V64 BIOS.

Most early V64 models shipped with a standard IDE 8X CD-ROM . During the manufacturing lifetime of the device, latter V64 models shipped with 16X and eventually 20X drives. V64 units could be purchased without a CD-ROM drive. It is possible to replace the unit with a faster IDE CD-ROM unit (such as the 52X model in the image on this page).

Many Doctor V64s shipped internationally were ordered without an installed CD-ROM drive, to save on shipping costs associated with weight, to avoid import duty on the drive, and to allow users to customize the units in response to the ever-increasing speeds of drives available. The variance in the power draw of different manufacturers drives at different speeds caused issues with disc spin-ups exceeding the wattage rating of the included Bung PSU. This led to users swapping out the Bung PSU for a more powerful model, or selecting low draw drives (mainly Panasonic drives sometimes badged as Creative).

V64s can read CD-Rs and CD-RWs (provided the installed CD-ROM unit supports rewritable media). Supported media has to be recorded in Mode 1, ISO 9660 format. Doctor V64s only support the 8.3 DOS naming convention. As such, Joliet file system is not supported.

Depending on the model, V64s came with either 128 megabits (16 MB) or 256 megabits (32 MB) of RAM. Original V64 units shipped with 128 megabits of RAM. V64 units started shipping with 256 megabits when developers started using bigger sized memory carts for their games. Users had the option of buying a memory upgrade from Bung and other re-sellers.

The Doctor V64 uses a 4 Pin MiniDIN jack (as used for S-Video) for connecting the power supply cord. Power supplies included with Doctor V64s were very unreliable. Bung replaced the power supply with a sturdier version in later V64 units. Replacing broken power supplies became one of the most common maintenance problems with the V64. It is possible to modify an AT PC power supply for V64 use. Only 4 cables have to be connected to the V64 for it to function.


De Havilland Mosquito

The de Havilland DH.98 Mosquito is a British twin-engined, multirole combat aircraft, introduced during the Second World War. Unusual in that its airframe was constructed mostly of wood, it was nicknamed the "Wooden Wonder", or "Mossie". Lord Beaverbrook, Minister of Aircraft Production, nicknamed it "Freeman's Folly", alluding to Air Chief Marshal Sir Wilfrid Freeman, who defended Geoffrey de Havilland and his design concept against orders to scrap the project. In 1941, it was one of the fastest operational aircraft in the world.

Originally conceived as an unarmed fast bomber, the Mosquito's use evolved during the war into many roles, including low- to medium-altitude daytime tactical bomber, high-altitude night bomber, pathfinder, day or night fighter, fighter-bomber, intruder, maritime strike, and photo-reconnaissance aircraft. It was also used by the British Overseas Airways Corporation as a fast transport to carry small, high-value cargo to and from neutral countries through enemy-controlled airspace. The crew of two, pilot and navigator, sat side by side. A single passenger could ride in the aircraft's bomb bay when necessary.

The Mosquito FB Mk. VI was often flown in special raids, such as Operation Jericho (an attack on Amiens Prison in early 1944), and precision attacks against military intelligence, security, and police facilities (such as Gestapo headquarters). On 30 January 1943, the 10th anniversary of Hitler being made chancellor and the Nazis gaining power, a morning Mosquito attack knocked out the main Berlin broadcasting station while Hermann Göring was speaking, taking his speech off the air.
The Mosquito flew with the Royal Air Force (RAF) and other air forces in the European, Mediterranean, and Italian theatres. The Mosquito was also operated by the RAF in the Southeast Asian theatre and by the Royal Australian Air Force based in the Halmaheras and Borneo during the Pacific War. During the 1950s, the RAF replaced the Mosquito with the jet-powered English Electric Canberra.

By the early to mid-1930s, de Havilland had built a reputation for innovative high-speed aircraft with the DH.88 Comet racer. Later, the DH.91 Albatross airliner pioneered the composite wood construction used for the Mosquito. The 22-passenger Albatross could cruise at at , faster than the Handley Page H.P.42 and other biplanes it was replacing. The wooden monocoque construction not only saved weight and compensated for the low power of the de Havilland Gipsy Twelve engines used by this aircraft, but also simplified production and reduced construction time.

On 8 September 1936, the British Air Ministry issued Specification P.13/36, which called for a twin-engined medium bomber capable of carrying a bomb load of for with a maximum speed of at ; a maximum bomb load of carried over shorter ranges was also required. Aviation firms entered heavy designs with new high-powered engines and multiple defensive turrets, leading to the production of the Avro Manchester and Handley Page Halifax.

In May 1937, as a comparison to P.13/36, George Volkert, the chief designer of Handley Page, put forward the concept of a fast, unarmed bomber. In 20 pages, Volkert planned an aerodynamically clean, medium bomber to carry of bombs at a cruising speed of . Support existed in the RAF and Air Ministry; Captain R. N. Liptrot, Research Director Aircraft 3, appraised Volkert's design, calculating that its top speed would exceed that of the new Supermarine Spitfire, but counter-arguments held that although such a design had merit, it would not necessarily be faster than enemy fighters for long. The ministry was also considering using non-strategic materials for aircraft production, which, in 1938, had led to specification B.9/38 and the Armstrong Whitworth Albemarle medium bomber, largely constructed from spruce and plywood attached to a steel-tube frame. The idea of a small, fast bomber gained support at a much earlier stage than is sometimes acknowledged, though the Air Ministry likely envisaged it using light alloy components.

Based on his experience with the Albatross, Geoffrey de Havilland believed that a bomber with a good aerodynamic design and smooth, minimal skin area, would exceed the P.13/36 specification. Furthermore, adapting the Albatross principles could save time. In April 1938, performance estimates were produced for a twin Rolls-Royce Merlin-powered DH.91, with the Bristol Hercules (radial engine) and Napier Sabre (H-engine) as alternatives. On 7 July 1938, de Havilland wrote to Air Marshal Wilfrid Freeman, the Air Council's member for Research and Development, discussing the specification and arguing that in war, shortages of aluminium and steel would occur, but supplies of wood-based products were "adequate." Although inferior in tension, the strength-to-weight ratio of wood is equal to or better than light alloys or steel, hence this approach was feasible.

A follow-up letter to Freeman on 27 July said that the P.13/36 specification could not be met by a twin Merlin-powered aircraft and either the top speed or load capacity would be compromised, depending on which was paramount. For example, a larger, slower, turret-armed aircraft would have a range of carrying a 4,000 lb bomb load, with a maximum of at , and a cruising speed of at . De Havilland believed that a compromise, including eliminating surplus equipment, would improve matters. On 4 October 1938, de Havilland projected the performance of another design based on the Albatross, powered by two Merlin Xs, with a three-man crew and six or eight forward-firing guns, plus one or two manually operated guns and a tail turret. Based on a total loaded weight of , it would have a top speed of and cruising speed of at .

Still believing this could be improved, and after examining more concepts based on the Albatross and the new all-metal DH.95 Flamingo, de Havilland settled on designing a new aircraft that would be aerodynamically clean, wooden, and powered by the Merlin, which offered substantial future development. The new design would be faster than foreseeable enemy fighter aircraft, and could dispense with a defensive armament, which would slow it and make interception or losses to antiaircraft guns more likely. Instead, high speed and good manoeuvrability would make evading fighters and ground fire easier. The lack of turrets simplified production, reduced drag, and reduced production time, with a delivery rate far in advance of competing designs. Without armament, the crew could be reduced to a pilot and navigator. Whereas contemporary RAF design philosophy favoured well-armed heavy bombers, this mode of design was more akin to the German philosophy of the "Schnellbomber". At a meeting in early October 1938 with Geoffrey de Havilland and Charles Walker (de Havilland's chief engineer), the Air Ministry showed little interest, and instead asked de Havilland to build wings for other bombers as a subcontractor.

By September 1939, de Havilland had produced preliminary estimates for single- and twin-engined variations of light-bomber designs using different engines, speculating on the effects of defensive armament on their designs. One design, completed on 6 September, was for an aircraft powered by a single Napier Sabre, with a wingspan of and capable of carrying a bomb load . On 20 September, in another letter to Wilfrid Freeman, de Havilland wrote "...we believe that we could produce a twin-engine[d] bomber which would have a performance so outstanding that little defensive equipment would be needed." By 4 October, work had progressed to a twin-engined light bomber with a wingspan of and powered by Merlin or Griffon engines, the Merlin favoured because of availability. On 7 October 1939, a month into the war, the nucleus of a design team under Eric Bishop moved to the security and secrecy of Salisbury Hall to work on what was later known as the DH.98. For more versatility, Bishop made provision for four 20 mm cannon in the forward half of the bomb bay, under the cockpit, firing via blast tubes and troughs under the fuselage.

The DH.98 was too radical for the ministry, which wanted a heavily armed, multirole aircraft, combining medium bomber, reconnaissance, and general-purpose roles, that was also capable of carrying torpedoes. With the outbreak of war, the ministry became more receptive, but was still sceptical about an unarmed bomber. They thought the Germans would produce fighters that were faster than had been expected. and suggested the incorporation of two forward- and two rear-firing machine guns for defence. The ministry also opposed a two-man bomber, wanting at least a third crewman to reduce the work of the others on long flights. The Air Council added further requirements such as remotely controlled guns, a top speed of at 15,000 ft on two-thirds engine power, and a range of with a 4,000-lb bomb load. To appease the ministry, de Havilland built mock-ups with a gun turret just aft of the cockpit, but apart from this compromise, de Havilland made no changes.

On 12 November, at a meeting considering fast-bomber ideas put forward by de Havilland, Blackburn, and Bristol, Air Marshal Freeman directed de Havilland to produce a fast aircraft, powered initially by Merlin engines, with options of using progressively more powerful engines, including the Rolls-Royce Griffon and the Napier Sabre. Although estimates were presented for a slightly larger Griffon-powered aircraft, armed with a four-gun tail turret, Freeman got the requirement for defensive weapons dropped, and a draft requirement was raised calling for a high-speed, light-reconnaissance bomber capable of at 18,000 ft.

On 12 December, the Vice-Chief of the Air Staff, Director General of Research and Development, and the Air Officer Commanding-in-Chief (AOC-in-C) of RAF Bomber Command met to finalise the design and decide how to fit it into the RAF's aims. The AOC-in-C would not accept an unarmed bomber, but insisted on its suitability for reconnaissance missions with F8 or F24 cameras. After company representatives, the ministry, and the RAF's operational commands examined a full-scale mock-up at Hatfield on 29 December 1939, the project received backing. This was confirmed on 1 January 1940, when Freeman chaired a meeting with Geoffrey de Havilland, John Buchanan (Deputy of Aircraft Production), and John Connolly (Buchanan's chief of staff). De Havilland claimed the DH.98 was the "fastest bomber in the world ... it must be useful". Freeman supported it for RAF service, ordering a single prototype for an unarmed bomber to specification B.1/40/dh, which called for a light bomber/reconnaissance aircraft powered by two Rolls-Royce RM3SM (an early designation for the Merlin 21) with ducted radiators, capable of carrying a bomb load. The aircraft was to have a speed of at and a cruising speed of at with a range of at on full tanks. Maximum service ceiling was to be .

On 1 March 1940, Air Marshal Roderic Hill issued a contract under Specification B.1/40, for 50 bomber-reconnaissance variants of the DH.98; this contract included the prototype, which was given the factory serial "E-0234". In May 1940, specification F.21/40 was issued, calling for a long-range fighter armed with four 20 mm cannon and four .303 machine guns in the nose, after which de Havilland was authorised to build a prototype of a fighter version of the DH.98. After debate, it was decided that this prototype, given the military serial number "W4052", was to carry airborne interception (AI) Mk IV equipment as a day and night fighter. By June 1940, the DH.98 had been named "Mosquito". Having the fighter variant kept the Mosquito project alive, as doubts remained within the government and Air Ministry regarding the usefulness of an unarmed bomber, even after the prototype had shown its capabilities.

With design of the DH.98 started, mock-ups were built, the most detailed at Salisbury Hall, where "E-0234" was later constructed. Initially, the concept was for the crew to be enclosed in the fuselage behind a transparent nose (similar to the Bristol Blenheim or Heinkel He 111H), but this was quickly altered to a more solid nose with a conventional canopy.

Work was cancelled again after the evacuation of the British Army from France, when Lord Beaverbrook, as Minister of Aircraft Production, concentrating production on aircraft types for the defence of the UK decided no production capacity remained for aircraft like the DH.98, which was not expected to be in service until early 1942. Beaverbrook told Air Vice-Marshal Freeman that work on the project should stop, but he did not issue a specific instruction, and Freeman ignored the request. In June 1940, however, Lord Beaverbrook and the Air Staff ordered that production should concentrate on five existing types, namely the Supermarine Spitfire, Hawker Hurricane fighter, Vickers Wellington, Armstrong-Whitworth Whitley, and Bristol Blenheim bombers. Work on the DH.98 prototype stopped. Apparently, the project shut down when the design team were denied materials for the prototype.

The Mosquito was only reinstated as a priority in July 1940, after de Havilland's general manager, L.C.L. Murray, promised Lord Beaverbrook 50 Mosquitoes by December 1941. This was only after Beaverbrook was satisfied that Mosquito production would not hinder de Havilland's primary work of producing Tiger Moth and Airspeed Oxford trainers, repairing Hurricanes, and manufacturing Merlin engines under licence. In promising Beaverbrook such a number by the end of 1941, de Havilland was taking a gamble, because they were unlikely to be built in such a limited time. As it transpired, only 20 aircraft were built in 1941, but the other 30 were delivered by mid-March 1942. During the Battle of Britain, interruptions to production due to air raid warnings caused nearly a third of de Havilland's factory time to be lost. Nevertheless, work on the prototype went ahead quickly at Salisbury Hall since "E-0234" was completed by November 1940.

In the aftermath of the Battle of Britain, the original order was changed to 20 bomber variants and 30 fighters. Whether the fighter version should have dual or single controls, or should carry a turret, was still uncertain, so three prototypes were built: "W4052", "W4053", and "W4073". The second and third, both turret armed, were later disarmed, to become the prototypes for the T.III trainer. This caused some delays, since half-built wing components had to be strengthened for the required higher combat loading. The nose sections also had to be changed from a design with a clear perspex bomb-aimer's position, to one with a solid nose housing four .303 machine guns and their ammunition.

On 3 November 1940, the prototype aircraft, painted in "prototype yellow" and still coded "E-0234", was dismantled, transported by road to Hatfield and placed in a small, blast-proof assembly building. Two Merlin 21 two-speed, single-stage supercharged engines were installed, driving three-bladed de Havilland Hydromatic constant-speed controllable-pitch propellers. Engine runs were made on 19 November. On 24 November, taxiing trials were carried out by Geoffrey de Havilland Jr., the de Havilland test pilot. On 25 November, the aircraft made its first flight, piloted by de Havilland Jr., accompanied by John E. Walker, the chief engine installation designer.

For this maiden flight, "E-0234", weighing , took off from the grass airstrip at the Hatfield site. The takeoff was reported as "straightforward and easy" and the undercarriage was not retracted until a considerable altitude was attained. The aircraft reached , with the only problem being the undercarriage doors – which were operated by bungee cords attached to the main undercarriage legs – that remained open by some at that speed. This problem persisted for some time. The left wing of "E-0234" also had a tendency to drag to port slightly, so a rigging adjustment, i.e., a slight change in the angle of the wing, was carried out before further flights.
On 5 December 1940, the prototype, with the military serial number "W4050", experienced tail buffeting at speeds between . The pilot noticed this most in the control column, with handling becoming more difficult. During testing on 10 December, wool tufts were attached to suspect areas to investigate the direction of airflow. The conclusion was that the airflow separating from the rear section of the inner engine nacelles was disturbed, leading to a localised stall and the disturbed airflow was striking the tailplane, causing buffeting. To smooth the air flow and deflect it from forcefully striking the tailplane, nonretractable slots fitted to the inner engine nacelles and to the leading edge of the tailplane were tested. These slots and wing-root fairings fitted to the forward fuselage and leading edge of the radiator intakes stopped some of the vibration experienced, but did not cure the tailplane buffeting.

In February 1941, buffeting was eliminated by incorporating triangular fillets on the trailing edge of the wings and lengthening the nacelles, the trailing edge of which curved up to fair into the fillet some behind the wing's trailing edge; this meant the flaps had to be divided into inboard and outboard sections. With the buffeting problems largely resolved, John Cunningham flew "W4050" on 9 February 1941. He was greatly impressed by the "lightness of the controls and generally pleasant handling characteristics". Cunningham concluded that when the type was fitted with AI equipment, it might replace the Bristol Beaufighter night fighter.

During its trials on 16 January 1941, "W4050" outpaced a Spitfire at . The original estimates were that as the Mosquito prototype had twice the surface area and over twice the weight of the Spitfire Mk.II, but also with twice its power, the Mosquito would end up being faster. Over the next few months, "W4050" surpassed this estimate, easily beating the Spitfire Mk.II in testing at RAF Boscombe Down in February 1941, reaching a top speed of at altitude, compared to a top speed of at for the Spitfire.

On 19 February, official trials began at the Aeroplane and Armament Experimental Establishment (AAEE) based at Boscombe Down, although the de Havilland representative was surprised by a delay in starting the tests. On 24 February, as "W4050" taxied across the rough airfield, the tailwheel jammed leading to the fuselage fracturing. Repairs were made by early March, using part of the fuselage of the photo-reconnaissance prototype "W4051". In spite of this setback, the "Initial Handling Report 767" issued by the AAEE stated, "The aeroplane is pleasant to fly ... aileron control light and effective..." The maximum speed reached was at , with an estimated maximum ceiling of and a maximum rate of climb of at .

"W4050" continued to be used for various test programmes, as the experimental "workhorse" for the Mosquito family. In late October 1941, it returned to the factory to be fitted with Merlin 61s, the first production Merlins fitted with a two-speed, two-stage supercharger. The first flight with the new engines was on 20 June 1942. "W4050" recorded a maximum speed of at (fitted with straight-through air intakes with snow guards, engines in full supercharger gear) and at without snow guards. In October 1942, in connection with development work on the NF Mk.XV, "W4050" was fitted with extended wingtips, increasing the span to , first flying in this configuration on 8 December. Fitted with high-altitude-rated, two-stage, two-speed Merlin 77s, it reached in December 1943. Soon after these flights, "W4050" was grounded and scheduled to be scrapped, but instead served as an instructional airframe at Hatfield. In September 1958, "W4050" was returned to the Salisbury Hall hangar where it was built, restored to its original configuration, and became one of the primary exhibits of the de Havilland Aircraft Heritage Centre.
"W4051", which was designed from the outset to be the prototype for the photo-reconnaissance versions of the Mosquito, was slated to make its first flight in early 1941. However, the fuselage fracture in "W4050" meant that "W4051's" fuselage was used as a replacement; "W4051" was then rebuilt using a production standard fuselage and first flew on 10 June 1941. This prototype continued to use the short engine nacelles, single-piece trailing-edge flaps, and the "No. 1" tailplane used by "W4050", but had production-standard wings and became the only Mosquito prototype to fly operationally.

Construction of the fighter prototype, "W4052", was also carried out at the secret Salisbury Hall facility. It was powered by Merlin 21s, and had an altered canopy structure with a flat, bullet-proof windscreen; the solid nose had mounted four .303 British Browning machine guns and their ammunition boxes, accessible by a large, sideways hinged panel. Four 20-mm Hispano Mk.II cannon were housed in a compartment under the cockpit floor with the breeches projecting into the bomb bay and the automatic bomb bay doors were replaced by manually operated bay doors, which incorporated cartridge ejector chutes.

As a day and night fighter, prototype "W4052" was equipped with AI Mk IV equipment, complete with an "arrowhead" transmission aerial mounted between the central Brownings and receiving aerials through the outer wing tips, and it was painted in black RDM2a "Special Night" finish. It was also the first prototype constructed with the extended engine nacelles. "W4052" was later tested with other modifications, including bomb racks, drop tanks, barrage balloon cable cutters in the leading edge of the wings, Hamilton airscrews and braking propellers, and drooping aileron systems that enabled steep approaches and a larger rudder tab. The prototype continued to serve as a test machine until it was scrapped on 28 January 1946. "4055" flew the first operational Mosquito flight on 17 September 1941.

During flight testing, the Mosquito prototypes were modified to test a number of configurations. "W4050" was fitted with a turret behind the cockpit for drag tests, after which the idea was abandoned in July 1941. "W4052" had the first version of the Youngman Frill airbrake fitted to the fighter prototype. The frill was mounted around the fuselage behind the wing and was opened by bellows and venturi effect to provide rapid deceleration during interceptions and was tested between January and August 1942, but was also abandoned when lowering the undercarriage was found to have the same effect with less buffeting.
The Air Ministry authorised mass production plans on 21 June 1941, by which time the Mosquito had become one of the world's fastest operational aircraft. It ordered 19 photo-reconnaissance (PR) models and 176 fighters. A further 50 were unspecified; in July 1941, these were confirmed to be unarmed fast bombers. By the end of January 1942, contracts had been awarded for 1,378 Mosquitoes of all variants, including 20 T.III trainers and 334 FB.VI bombers. Another 400 were to be built by de Havilland Canada.

On 20 April 1941, "W4050" was demonstrated to Lord Beaverbrook, the Minister of Aircraft Production. The Mosquito made a series of flights, including one rolling climb on one engine. Also present were US General Henry H. Arnold and his aide Major Elwood Quesada, who wrote "I ... recall the first time I saw the Mosquito as being impressed by its performance, which we were aware of. We were impressed by the appearance of the airplane that looks fast usually is fast, and the Mosquito was, by the standards of the time, an extremely well-streamlined airplane, and it was highly regarded, highly respected."

The trials set up future production plans between Britain, Australia, and Canada. Six days later, Arnold returned to America with a full set of manufacturer's drawings. As a result of his report, five companies (Beech, Curtiss-Wright, Fairchild, Fleetwings, and Hughes) were asked to evaluate the de Havilland data. The report by Beech Aircraft summed up the general view: "It appears as though this airplane has sacrificed serviceability, structural strength, ease of construction and flying characteristics in an attempt to use construction material which is not suitable for the manufacture of efficient airplanes." The Americans did not pursue the proposal for licensed production, the consensus arguing that the Lockheed P-38 Lightning could fulfill the same duties. However, Arnold urged the United States Army Air Forces (USAAF) to evaluate the design even if they would not adopt it. On 12 December 1941, after the attack on Pearl Harbor, the USAAF requested one airframe for this purpose.

While timber construction was considered outmoded by some, de Havilland claimed that their successes with techniques used for the DH 91 Albatross could lead to a fast, light bomber using monocoque-sandwich shell construction. Arguments in favour of this included speed of prototyping, rapid development, minimisation of jig-building time, and employment of a separate category of workforce. The ply-balsa-ply monocoque fuselage and one-piece wings with doped fabric covering would give excellent aerodynamic performance and low weight, combined with strength and stiffness. At the same time, the design team had to fight conservative Air Ministry views on defensive armament. Guns and gun turrets, favoured by the ministry, would impair the aircraft's aerodynamic properties and reduce speed and manoeuvrability, in the opinion of the designers. Whilst submitting these arguments, Geoffrey de Havilland funded his private venture until a very late stage. The project was a success beyond all expectations. The initial bomber and photo-reconnaissance versions were extremely fast, whilst the armament of subsequent variants might be regarded as primarily offensive.

The most-produced variant, designated the FB Mk. VI (Fighter-bomber Mark 6), was powered by two Merlin Mk.23 or Mk.25 engines driving three-bladed de Havilland hydromatic propellers. The typical fixed armament for an FB Mk. VI was four Browning .303 machine guns and four 20-mm Hispano cannons, while the offensive load consisted of up to of bombs, or eight RP-3 unguided rockets.

The design was noted for light and effective control surfaces that provided good manoeuvrability, but required that the rudder not be used aggressively at high speeds. Poor aileron control at low speeds when landing and taking off was also a problem for inexperienced crews. For flying at low speeds, the flaps had to be set at 15°, speed reduced to , and rpm set to 2,650. The speed could be reduced to an acceptable for low-speed flying. For cruising, the optimum speed for obtaining maximum range was at weight.

The Mosquito had a high stalling speed of with undercarriage and flaps raised. When both were lowered, the stalling speed decreased from . Stall speed at normal approach angle and conditions was . Warning of the stall was given by buffeting and would occur before stall was reached. The conditions and impact of the stall were not severe. The wing did not drop unless the control column was pulled back. The nose drooped gently and recovery was easy.

Early on in the Mosquito's operational life, the intake shrouds that were to cool the exhausts on production aircraft overheated. Flame dampers prevented exhaust glow on night operations, but they had an effect on performance. Multiple ejector and open-ended exhaust stubs helped solve the problem and were used in the PR.VIII, B.IX, and B.XVI variants. This increased speed performance in the B.IX alone by .

The oval-section fuselage was a frameless monocoque shell built in two vertically separate halves formed over a mahogany or concrete mould. Pressure was applied with band clamps. Some of the 1/2—3/4" shell sandwich skins comprised 3/32" birch three-ply outers, with 7/16" cores of Ecuadorean balsa. In many generally smaller but vital areas, such as around apertures and attachment zones, stronger timbers, including aircraft-quality spruce, replaced the balsa core. The main areas of the sandwich skin were only thick. Together with various forms of wood reinforcement, often of laminated construction, the sandwich skin gave great stiffness and torsional resistance. The separate fuselage halves speeded construction, permitting access by personnel working in parallel with others, as the work progressed.

Work on the separate half-fuselages included installation of control mechanisms and cabling. Screwed inserts into the inner skins that would be under stress in service were reinforced using round shear plates made from a fabric-Bakelite composite.
Transverse bulkheads were also compositely built-up with several species of timber, plywood, and balsa. Seven vertically halved bulkheads were installed within each moulded fuselage shell before the main "boxing up" operation. Bulkhead number seven was especially strongly built, since it carried the fitments and transmitted the aerodynamic loadings for the tailplane and rudder. The fuselage had a large ventral section cut-out, strongly reinforced, that allowed the fuselage to be lowered onto the wing centre-section at a later stage of assembly.

For early production aircraft, the structural assembly adhesive was casein-based. At a later stage, this was replaced by "Aerolite", a synthetic urea-formaldehyde type, which was more durable. To provide for the edge joints for the fuselage halves, zones near the outer edges of the shells had their balsa sandwich cores replaced by much stronger inner laminations of birch plywood. For the bonding together of the two halves ("boxing up"), a longitudinal cut was machined into these edges. The profile of this cut was a form of V-groove. Part of the edge bonding process also included adding further longitudinal plywood lap strips on the outside of the shells. The half bulkheads of each shell were bonded to their corresponding pair in a similar way. Two laminated wooden clamps were used in the after portion of the fuselage to provide supports during this complex gluing work. The resulting large structural components had to be kept completely still and held in the correct environment until the glue cured.

For finishing, a covering of doped madapollam (a fine, plain-woven cotton) fabric was stretched tightly over the shell and several coats of red, followed by silver dope, were added, followed by the final camouflage paint.

The all-wood wing pairs comprised a single structural unit throughout the wingspan, with no central longitudinal joint. Instead, the spars ran from wingtip to wingtip. There was a single continuous main spar and another continuous rear spar. Because of the combination of dihedral with the forward sweep of the trailing edges of the wings, this rear spar was one of the most complex units to laminate and to finish machining after the bonding and curing. It had to produce the correct 3D tilt in each of two planes. Also, it was designed and made to taper from the wing roots towards the wingtips. Both principal spars were of ply box construction, using in general 0.25-in plywood webs with laminated spruce flanges, plus a number of additional reinforcements and special details.

Spruce and plywood ribs were connected with gusset joints. Some heavy-duty ribs contained pieces of ash and walnut, as well as the special five ply that included veneers laid up at 45°. The upper skin construction was in two layers of 0.25-in five-ply birch, separated by Douglas fir stringers running in the span-wise direction. The wings were covered with madapollam fabric and doped in a similar manner to the fuselage. The wing was installed into the roots by means of four large attachment points. The engine radiators were fitted in the inner wing, just outboard of the fuselage on either side. These gave less drag. The radiators themselves were split into three sections: an oil cooler section outboard, the middle section forming the coolant radiator and the inboard section serving the cabin heater.

The wing contained metal-framed and -skinned ailerons, but the flaps were made of wood and were hydraulically controlled. The nacelles were mostly wood, although for strength, the engine mounts were all metal, as were the undercarriage parts. Engine mounts of welded steel tube were added, along with simple landing gear oleos filled with rubber blocks. Wood was used to carry only in-plane loads, with metal fittings used for all triaxially loaded components such as landing gear, engine mounts, control-surface mounting brackets, and the wing-to-fuselage junction. The outer leading wing edge had to be brought further forward to accommodate this design. The main tail unit was all wood built. The control surfaces, the rudder, and elevator were aluminium-framed and fabric-covered. The total weight of metal castings and forgings used in the aircraft was only .
In November 1944, several crashes occurred in the Far East. At first, these were thought to be a result of wing-structure failures. The casein glue, it was said, cracked when exposed to extreme heat and/or monsoon conditions. This caused the upper surfaces to "lift" from the main spar. An investigating team led by Major Hereward de Havilland travelled to India and produced a report in early December 1944 stating, "the accidents were not caused by the deterioration of the glue, but by shrinkage of the airframe during the wet monsoon season". However, a later inquiry by Cabot & Myers firmly attributed the accidents to faulty manufacture and this was confirmed by a further investigation team by the Ministry of Aircraft Production at Defford, which found faults in six Mosquito marks (all built at de Havilland's Hatfield and Leavesden plants). The defects were similar, and none of the aircraft had been exposed to monsoon conditions or termite attack.

The investigators concluded that construction defects occurred at the two plants. They found that the "...standard of glueing ... left much to be desired." Records at the time showed that accidents caused by "loss of control" were three times more frequent on Mosquitoes than on any other type of aircraft. The Air Ministry forestalled any loss of confidence in the Mosquito by holding to Major de Havilland's initial investigation in India that the accidents were caused "largely by climate" To solve the problem of seepage into the interior, a strip of plywood was set along the span of the wing to seal the entire length of the skin joint.

The fuel systems gave the Mosquito good range and endurance, using up to nine fuel tanks. Two outer wing tanks each contained of fuel. These were complemented by two inner wing fuel tanks, each containing , located between the wing root and engine nacelle. In the central fuselage were twin fuel tanks mounted between bulkhead number two and three aft of the cockpit. In the FB.VI, these tanks contained each, while in the B.IV and other unarmed Mosquitoes each of the two centre tanks contained . Both the inner wing, and fuselage tanks are listed as the "main tanks" and the total internal fuel load of was initially deemed appropriate for the type. In addition, the FB Mk. VI could have larger fuselage tanks, increasing the capacity to . Drop tanks of or could be mounted under each wing, increasing the total fuel load to .

The design of the Mk.VI allowed for a provisional long-range fuel tank to increase range for action over enemy territory, for the installation of bomb release equipment specific to depth charges for strikes against enemy shipping, or for the simultaneous use of rocket projectiles along with a drop tank under each wing supplementing the main fuel cells. The FB.VI had a wingspan of , a length (over guns) of . It had a maximum speed of at . Maximum take-off weight was and the range of the aircraft was with a service ceiling of .

To reduce fuel vaporisation at the high altitudes of photographic reconnaissance variants, the central and inner wing tanks were pressurised. The pressure venting cock located behind the pilot's seat controlled the pressure valve. As the altitude increased, the valve increased the volume applied by a pump. This system was extended to include field modifications of the fuel tank system.

The engine oil tanks were in the engine nacelles. Each nacelle contained a oil tank, including a air space. The oil tanks themselves had no separate coolant controlling systems. The coolant header tank was in the forward nacelle, behind the propeller. The remaining coolant systems were controlled by the coolant radiators shutters in the forward inner wing compartment, between the nacelle and the fuselage and behind the main engine cooling radiators, which were fitted in the leading edge. Electric-pneumatic operated radiator shutters directed and controlled airflow through the ducts and into the coolant valves, to predetermined temperatures.

Electrical power came from a 24 volt DC generator on the starboard (No. 2) engine and an alternator on the port engine, which also supplied AC power for radios. The radiator shutters, supercharger gear change, gun camera, bomb bay, bomb/rocket release and all the other crew controlled instruments were powered by a 24 V battery. The radio communication devices included VHF and HF communications, GEE navigation, and IFF and G.P. devices. The electric generators also powered the fire extinguishers. Located on the starboard side of the cockpit, the switches would operate automatically in the event of a crash. In flight, a warning light would flash to indicate a fire, should the pilot not already be aware of it. In later models, to save liquids and engine clean up time in case of belly landing, the fire extinguisher was changed to semi-automatic triggers.

The main landing gear, housed in the nacelles behind the engines, were raised and lowered hydraulically. The main landing gear shock absorbers were de Havilland manufactured and used a system of rubber in compression, rather than hydraulic oleos, with twin pneumatic brakes for each wheel. The Dunlop-Marstrand anti-shimmy tailwheel was also retractable.

The de Havilland Mosquito operated in many roles, performing medium bomber, reconnaissance, tactical strike, anti-submarine warfare, shipping attacks and night fighter duties, until the end of the war. In July 1941, the first production Mosquito "W4051" (a production fuselage combined with some prototype flying surfaces – see Prototypes and test flights) was sent to No. 1 Photographic Reconnaissance Unit (PRU), at RAF Benson. The secret reconnaissance flights of this aircraft were the first operational missions of the Mosquito. In 1944, the journal "Flight" gave 19 September 1941 as date of the first PR mission, at an altitude "of some 20,000 ft".

On 15 November 1941, 105 Squadron, RAF, took delivery at RAF Swanton Morley, Norfolk, of the first operational Mosquito Mk. B.IV bomber, serial no. "W4064". Throughout 1942, 105 Squadron, based next at RAF Horsham St. Faith, then from 29 September, RAF Marham, undertook daylight low-level and shallow dive attacks. Apart from the Oslo and Berlin raids, the strikes were mainly on industrial and infrastructure targets in occupied Netherlands and Norway, France and northern and western Germany. The crews faced deadly flak and fighters, particularly Focke-Wulf Fw 190s, which they called "snappers". Germany still controlled continental airspace and the Fw 190s were often already airborne and at an advantageous altitude. Collisions within the formations also caused casualties. It was the Mosquito's excellent handling capabilities, rather than pure speed, that facilitated successful evasions.

The Mosquito was first announced publicly on 26 September 1942 after the Oslo Mosquito raid of 25 September. It was featured in "The Times" on 28 September and the next day the newspaper published two captioned photographs illustrating the bomb strikes and damage. On 6 December 1942, Mosquitoes from Nos. 105 and 139 Squadrons made up part of the bomber force used in Operation Oyster, the large No. 2 Group raid against the Philips works at Eindhoven.

From mid-1942 to mid-1943, Mosquito bombers flew high-speed, medium and low-altitude daylight missions against factories, railways and other pinpoint targets in Germany and German-occupied Europe. From June 1943, Mosquito bombers were formed into the Light Night Striking Force to guide RAF Bomber Command heavy bomber raids and as "nuisance" bombers, dropping Blockbuster bombs – "cookies" – in high-altitude, high-speed raids that German night fighters were almost powerless to intercept.

As a night fighter from mid-1942, the Mosquito intercepted "Luftwaffe" raids on Britain, notably those of Operation Steinbock in 1944. Starting in July 1942, Mosquito night-fighter units raided "Luftwaffe" airfields. As part of 100 Group, it was flown as a night fighter and as an intruder supporting Bomber Command heavy bombers that reduced losses during 1944 and 1945.

The Mosquito fighter-bomber served as a strike aircraft in the Second Tactical Air Force (2TAF) from its inception on 1 June 1943. The main objective was to prepare for the invasion of occupied Europe a year later. In Operation Overlord three Mosquito FB Mk. VI wings flew close air support for the Allied armies in co-operation with other RAF units equipped with the North American B-25 Mitchell medium bomber. In the months between the foundation of 2TAF and its duties from D day onwards, vital training was interspersed with attacks on V-1 flying bomb launch sites.

In another example of the daylight precision raids carried out by the Mosquitoes of Nos. 105 and 139 Squadrons, on 30 January 1943, the 10th anniversary of the Nazis' seizure of power, a morning Mosquito attack knocked out the main Berlin broadcasting station while "Luftwaffe" Chief Reichsmarschall Hermann Göring was speaking, putting his speech off the air. A second sortie in the afternoon inconvenienced another speech, by Propaganda Minister Joseph Goebbels. Lecturing a group of German aircraft manufacturers, Göring said:

During this daylight-raiding phase, Nos. 105 and 139 Squadrons flew 139 combat operations and aircrew losses were high. Even the losses incurred in the squadrons' dangerous Blenheim era were exceeded in percentage terms. The Roll of Honour shows 51 aircrew deaths from the end of May 1942 to April 1943. In the corresponding period, crews gained three Mentions in Despatches, two DFMs and three DFCs. The low-level daylight attacks finished on 27 May 1943 with strikes on the Schott glass and Zeiss instrument works, both in Jena. Subsequently, when low-level precision attacks required Mosquitoes, they were allotted to squadrons operating the FB.IV version. Examples include the Aarhus air raid and Operation Jericho.

Since the beginning of the year, the German fighter force had become seriously overstretched. In April 1943, in response to "political humiliation" caused by the Mosquito, Göring ordered the formation of special "Luftwaffe" units ("Jagdgeschwader 25", commanded by "Oberstleutnant" Herbert Ihlefeld and "Jagdgeschwader 50", under "Major" Hermann Graf) to combat the Mosquito attacks, though these units, which were "little more than glorified squadrons", were unsuccessful against the elusive RAF aircraft. Post-war German histories also indicate that there was a belief within the Luftwaffe that Mosquito aircraft "gave only a weak radar signal.".

The first Mosquito Squadron to be equipped with Oboe (navigation) was No. 109, based at RAF Wyton, after working as an experimental unit at RAF Boscombe Down. They used Oboe in anger for the first time on 31 December 1942 and 1 January 1943, target marking for a force of heavy bombers attacking Düsseldorf.. On 1 June, the two pioneering Squadrons joined No. 109 Squadron in the re-formed No. 8 Group RAF (Bomber Command). Initially they were engaged in moderately high altitude (about ) night bombing, with 67 trips during that summer, mainly to Berlin. Soon after, Nos. 105 and 139 Squadron bombers were widely used by the RAF Pathfinder Force, marking targets for the main night-time strategic bombing force.

In what were, initially, diversionary "nuisance raids," Mosquito bombers dropped 4,000 lb Blockbuster bombs or "Cookies." Particularly after the introduction of H2S (radar) in some Mosquitoes, these raids carrying larger bombs succeeded to the extent that they provided a significant additional form of attack to the large formations of "heavies." Latterly in the war, there were a significant number of all-Mosquito raids on big German cities involving up to 100 or more aircraft. On the night of 20/21 February 1945, for example, Mosquitoes of No. 8 Group mounted the first of 36 consecutive night raids on Berlin.

From 1943, Mosquitoes with RAF Coastal Command attacked "Kriegsmarine" U-boats and intercepted transport ship concentrations. After Operation Overlord, the U-boat threat in the Western Approaches decreased fairly quickly, but correspondingly the Norwegian and Danish waters posed greater dangers. Hence the RAF Coastal Command Mosquitoes were moved to Scotland to counter this threat. The Strike Wing at Banff stood up in September 1944 and comprised Mosquito aircraft of No's 143, 144, 235 and 248 Squadrons Royal Air Force and No.333 Squadron Royal Norwegian Air Force. Despite an initially high loss rate, the Mosquito bomber variants ended the war with the lowest losses of any aircraft in RAF Bomber Command service.

The Mosquito also proved a very capable night fighter. Some of the most successful RAF pilots flew these variants. For example, Wing Commander Branse Burbridge claimed 21 kills.

Mosquitoes of No. 100 Group RAF acted as night intruders operating at high level in support of the Bomber Command "heavies", to counter the enemy tactic of merging into the bomber stream, which, towards the end of 1943, was causing serious allied losses. These RCM (radio countermeasures) aircraft were fitted with a device called "Serrate" to allow them to track down German night fighters from their "Lichtenstein B/C" (low-UHF-band) and "Lichtenstein SN-2" (lower end of the VHF FM broadcast band) radar emissions, as well as a device named "Perfectos" that tracked German IFF signals. These methods were responsible for the destruction of 257 German aircraft from December 1943 to April 1945. Mosquito fighters from all units accounted for 487 German aircraft during the war, the vast majority of which were night fighters.

One Mosquito is listed as belonging to German secret operations unit "Kampfgeschwader 200", which tested, evaluated and sometimes clandestinely operated captured enemy aircraft during the war. The aircraft was listed on the order of battle of "Versuchsverband OKL"s, "2 Staffel", "Stab Gruppe" on 10 November and 31 December 1944. However, on both lists, the Mosquito is listed as unserviceable.

The Mosquito flew its last official European war mission on 21 May 1945, when Mosquitoes of 143 Squadron and 248 Squadron RAF were ordered to continue to hunt German submarines that might be tempted to continue the fight; instead of submarines all the Mosquitoes encountered were passive E-boats.

The last operational RAF Mosquitoes were the Mosquito TT.35's, which were finally retired from No. 3 Civilian Anti-Aircraft Co-Operation Unit (CAACU) in May 1963.

In 1947–49, up to 180 Canadian surplus Mosquitoes flew many operations for the Nationalist Chinese under Chiang Kai-shek in the civil war against Communist forces. Pilots from three squadrons of Mosquitoes claimed to have sunk or damaged 500 ships during one invasion attempt. As the Communists assumed control, the remaining aircraft were evacuated to Formosa, where they flew missions against shipping.

Until the end of 1942 the RAF always used Roman numerals (I, II, ...) for mark numbers; 1943–1948 was a transition period during which new aircraft entering service were given Arabic numerals (1, 2, ...) for mark numbers, but older aircraft retained their Roman numerals. From 1948 onwards, Arabic numerals were used exclusively.

Three prototypes were built, each with a different configuration. The first to fly was "W4050" on 25 November 1940, followed by the fighter "W4052" on 15 May 1941 and the photo-reconnaissance prototype "W4051" on 10 June 1941. "W4051" later flew operationally with 1 Photographic Reconnaissance Unit (1 PRU).

A total of 10 Mosquito PR Mk.Is were built, four of them "long range" versions equipped with a overload fuel tank in the fuselage. The contract called for 10 of the PR Mk.I airframes to be converted to B Mk.IV Series 1s. All of the PR Mk.Is, and the B Mk.IV Series 1s, had the original short engine nacelles and short span (19 ft 5.5 in) tailplanes. Their engine cowlings incorporated the original pattern of integrated exhaust manifolds, which, after relatively brief flight time, had a troublesome habit of burning and blistering the cowling panels. The first operational sortie by a Mosquito was made by a PR Mk.I, W4055, on 17 September 1941; during this sortie the unarmed Mosquito PR.I evaded three Messerschmitt Bf 109s at . Powered by two Merlin 21s, the PR Mk.I had a maximum speed of , a cruise speed of , a ceiling of , a range of , and a climb rate of per minute.

Over 30 Mosquito B Mk.IV bombers were converted into the PR Mk.IV photo-reconnaissance aircraft. The first operational flight by a PR Mk.IV was made by "DK284" in April 1942.

The Mosquito PR Mk.VIII, built as a stopgap pending the introduction of the refined PR Mk.IX, was the next photo-reconnaissance version. The five VIIIs were converted from B Mk.IVs and became the first operational Mosquito version to be powered by two-stage, two-speed supercharged engines, using Rolls-Royce Merlin 61 engines in place of Merlin 21/22s. The first PR Mk.VIII, "DK324" first flew on 20 October 1942. The PR Mk.VIII had a maximum speed of , an economical cruise speed of at 20,000 ft, and at 30,000 ft, a ceiling of , a range of , and a climb rate of 2,500 ft per minute (760 m).

The Mosquito PR Mk.IX, 90 of which were built, was the first Mosquito variant with two-stage, two-speed engines to be produced in quantity; the first of these, "LR405", first flew in April 1943. The PR Mk.IX was based on the Mosquito B Mk.IX bomber and was powered by two Merlin 72/73 or 76/77 engines. It could carry either two , two or two droppable fuel tanks.

The Mosquito PR Mk.XVI had a pressurised cockpit and, like the Mk.IX, was powered by two Rolls-Royce Merlin 72/73 or 76/77 piston engines. This version was equipped with three overload fuel tanks, totalling in the bomb bay, and could also carry two or drop tanks. A total of 435 of the PR Mk.XVI were built. The PR Mk.XVI had a maximum speed of , a cruise speed of , ceiling of , a range of , and a climb rate of 2,900 feet per minute (884 m).
The Mosquito PR Mk.32 was a long-range, high-altitude, pressurised photo-reconnaissance version. It was powered by a pair of two-stage supercharged Rolls-Royce Merlin 113 and Merlin 114 piston engines, the Merlin 113 on the starboard side and the Merlin 114 on the port. First flown in August 1944, only five were built and all were conversions from PR.XVIs.

The Mosquito PR Mk.34 and PR Mk.34A was a very long-range unarmed high altitude photo-reconnaissance version. The fuel tank and cockpit protection armour were removed. Additional fuel was carried in a bulged bomb bay: 1,192 gallons—the equivalent of . A further two 200-gallon (910-litre) drop tanks under the outer wings gave a range of cruising at . Powered by two Merlin 114s first used in the PR.32. The port Merlin 114 drove a Marshal cabin supercharger. A total of 181 were built, including 50 built by Percival Aircraft Company at Luton. The PR.34's maximum speed (TAS) was at sea level, at and at .
All PR.34s were installed with four split F52 vertical cameras, two forward, two aft of the fuselage tank and one F24 oblique camera. Sometimes a K-17 camera was used for air surveys. In August 1945, the PR.34A was the final photo-reconnaissance variant with one Merlin 113A and 114A each delivering .

Colonel Roy M. Stanley II, USAF (RET) wrote: "I consider the Mosquito the best photo-reconnaissance aircraft of the war".

After the end of World War II Spartan Air Services used ten ex-RAF Mosquitoes, mostly B.35s plus one of only six PR.35s built, for high-altitude photographic survey work in Canada.

On 21 June 1941 the Air Ministry ordered that the last 10 Mosquitoes, ordered as photo-reconnaissance aircraft, should be converted to bombers. These 10 aircraft were part of the original 1 March 1940 production order and became the B Mk.IV Series 1. "W4052" was to be the prototype and flew for the first time on 8 September 1941.

The bomber prototype led to the B Mk.IV, of which 273 were built: apart from the 10 Series 1s, all of the rest were built as Series 2s with extended nacelles, revised exhaust manifolds, with integrated flame dampers, and larger tailplanes. Series 2 bombers also differed from the Series 1 in having an increased payload of four bombs, instead of the four bombs of Series 1. This was made possible by "cropping", or shortening the tail of the bomb so that these four heavier weapons could be carried (or a 2,000 lb (920 kg) total load). The B Mk.IV entered service in May 1942 with 105 Squadron.

In April 1943 it was decided to convert a B Mk.IV to carry a Blockbuster bomb (nicknamed a Cookie). The conversion, including modified bomb bay suspension arrangements, bulged bomb bay doors and fairings, was relatively straightforward and 54 B.IVs were modified and distributed to squadrons of the Light Night Striking Force. 27 B Mk.IVs were later converted for special operations with the Highball anti-shipping weapon, and were used by 618 Squadron, formed in April 1943 specifically to use this weapon. A B Mk.IV, "DK290" was initially used as a trials aircraft for the bomb, followed by "DZ471,530 and 533". The B Mk.IV had a maximum speed of , a cruising speed of , ceiling of , a range of , and a climb rate of 2,500 ft per minute (12.7 m/s).
Other bomber variants of the Mosquito included the Merlin 21 powered B Mk.V high-altitude version. Trials with this configuration were made with "W4057", which had strengthened wings and two additional fuel tanks, or alternatively, two bombs. This design was not produced in Britain, but formed the basic design of the Canadian-built B.VII. Only "W4057" was built in prototype form. The Merlin 31 powered B Mk.VII was built by de Havilland Canada and first flown on 24 September 1942. It only saw service in Canada, 25 were built. Six were handed over to the United States Army Air Forces.

B Mk.IX (54 built) was powered by the Merlin 72,73, 76 or 77. The two-stage Merlin variant was based on the PR.IX. The prototype "DK 324" was converted from a PR.VIII and first flew on 24 March 1943. In October 1943 it was decided that all B Mk.IVs and all B Mk.IXs then in service would be converted to carry the "Cookie", and all B Mk.IXs built after that date were designed to allow them to be converted to carry the weapon. The B Mk.IX had a maximum speed of , an economical cruise speed of at 20,000 ft, and at 30,000 ft, ceiling of , a range of , and a climb rate of 2,850 feet per minute (14.5 m/s). The IX could carry a maximum load of of bombs. A Mosquito B Mk.IX holds the record for the most combat operations flown by an Allied bomber in the Second World War. "LR503", known as "F for Freddie" (from its squadron code letters, GB*F), first served with No. 109 and subsequently, No. 105 RAF squadrons. It flew 213 sorties during the war, only to crash at Calgary airport during the Eighth Victory Loan Bond Drive on 10 May 1945, two days after Victory in Europe Day, killing both the pilot, Flt. Lt. Maurice Briggs, DSO, DFC, DFM and navigator Fl. Off. John Baker, DFC and Bar.

The B Mk.XVI was powered by the same variations as the B.IX. All B Mk.XVIs were capable of being converted to carry the "Cookie". The two-stage powerplants were added along with a pressurised cabin. "DZ540" first flew on 1 January 1944. The prototype was converted from a IV (402 built). The next variant, the B Mk.XX, was powered by Packard Merlins 31 and 33s. It was the Canadian version of the IV. Altogether, 245 were built. The B Mk.XVI had a maximum speed of , an economical cruise speed of at 20,000 ft, and at 30,000 ft, ceiling of , a range of , and a climb rate of 2,800 ft per minute (14 m/s). The type could carry of bombs.

The B.35 was powered by Merlin 113 and 114As. Some were converted to TT.35s (Target Tugs) and others were used as PR.35s (photo-reconnaissance). The B.35 had a maximum speed of , a cruising speed of , ceiling of , a range of , and a climb rate of 2,700 ft per minute (13.7 m/s). A total of 174 B.35s were delivered up to the end of 1945. A further 100 were delivered from 1946 for a grand total of 274, 65 of which were built by Airspeed Ltd.

Developed during 1940, the first prototype of the Mosquito F Mk.II was completed on 15 May 1941. These Mosquitoes were fitted with four Hispano cannon in the fuselage belly and four .303 (7.7 mm) Browning machine guns mounted in the nose. On production Mk.IIs the machine guns and ammunition tanks were accessed via two centrally hinged, sideways opening doors in the upper nose section. To arm and service the cannon the bomb bay doors were replaced by manually operated bay doors: the F and NF Mk.IIs could not carry bombs. The type was also fitted with a gun camera in a compartment above the machine guns in the nose and was fitted with exhaust flame dampers to reduce the glare from the Merlin XXs.

In the summer of 1942, Britain experienced day-time incursions of the high-altitude reconnaissance bomber, the Junkers Ju 86P. Although the Ju 86P only carried a light bomb load, it overflew sensitive areas, including Bristol, Bedfordshire and Hertfordshire. Bombs were dropped on Luton and elsewhere, and this particular aircraft was seen from the main de Havilland offices and factory at Hatfield. An attempt to intercept it with a Spitfire from RAF Manston was unsuccessful. As a result of the potential threat, a decision was quickly taken to develop a high-altitude Mosquito interceptor, using the "MP469" prototype.

"MP469" entered the experimental shop on 7 September and made its initial flight on 14 September, piloted by John de Havilland. The bomber nose was altered using a normal fighter nose, armed with four standard .303 (7.7 mm) Browning machine guns. The low pressure cabin retained a bomber canopy structure and a two-piece windscreen. The control wheel was replaced with a fighter control stick. The wingspan was increased to . The airframe was lightened by removing armour plating, some fuel tanks and other fitments. Smaller-diameter main wheels were fitted after the first few flights. At a loaded weight of this HA Mk.XV was lighter than a standard Mk.II. For this first conversion, the engines were a pair of Merlin 61s. On 15 September, John de Havilland reached an altitude of in this version. The aircraft was delivered to a High Altitude Flight which had been formed at RAF Northolt. However, the high-level German daylight intruders were no longer to be seen. It was subsequently revealed that only five Ju 86P aircraft had been built and they had only flown 12 sorties. Nevertheless, the general need for high altitude interceptors was recognised – but now the emphasis was to be upon night fighters.

The A&AEE tested the climb and speed of night fighter conversion of MP469 in January 1943 for the Ministry of Aircraft Production. Wingspan had been increased to , the Brownings had been moved to a fairing below the fuselage. According to Birtles, an AI radar was mounted in the nose and the Merlins were upgraded to Mk76 type, although Boscombe Down reported Merlin 61s. In addition to MP469, four more B Mk.IVs were converted into NF MK XVs. The Fighter Interception Unit at RAF Ford carried out service trials, March 1943, and then these five aircraft went to 85 Squadron, Hunsdon, where they were flown from April until August of that year. The greatest height reached in service was .

Apart from the F Mk.XV, all Mosquito fighters and fighter bombers featured a modified canopy structure incorporating a flat, single piece armoured windscreen, and the crew entry/exit door was moved from the bottom of the forward fuselage to the right side of the nose, just forward of the wing leading edge.

At the end of 1940, the Air Staff's preferred turret-equipped night fighter design to Operational Requirement O.R. 95 was the Gloster F.18/40 (derived from their F.9/37). However, although in agreement as to the quality of the Gloster company's design, the Ministry of Aircraft Production was concerned that Gloster would not be able to work on the F.18/40 and also the jet fighter design, considered the greater priority. Consequently, in mid-1941 the Air Staff and MAP agreed that the Gloster aircraft would be dropped and the Mosquito, when fitted with a turret would be considered for the night fighter requirement.

The first production night fighter Mosquitoes – minus turrets – were designated NF Mk.II. A total of 466 were built with the first entering service with No. 157 Squadron in January 1942, replacing the Douglas Havoc. These aircraft were similar to the F Mk.II, but were fitted with the AI Mk.IV metric wavelength radar. The herring-bone transmitting antenna was mounted on the nose and the dipole receiving antennae were carried under the outer wings. A number of NF IIs had their radar equipment removed and additional fuel tanks installed in the bay behind the cannon for use as night intruders. These aircraft, designated NF II (Special) were first used by 23 Squadron in operations over Europe in 1942. 23 Squadron was then deployed to Malta on 20 December 1942, and operated against targets in Italy.

Ninety-seven NF Mk.IIs were upgraded with 3.3 GHz frequency, low-SHF-band AI Mk.VIII radar and these were designated NF Mk.XII. The NF Mk.XIII, of which 270 were built, was the production equivalent of the Mk.XII conversions. These "centimetric" radar sets were mounted in a solid "thimble" (Mk.XII / XIII) or universal "bull nose" (Mk.XVII / XIX) radome, which required the machine guns to be dispensed with.
Four F Mk.XVs were converted to the NF Mk.XV. These were fitted with AI Mk.VIII in a "thimble" radome, and the .303 Brownings were moved into a gun pack fitted under the forward fuselage.

The NF Mk.XIX was an improved version of the NF XIII. It could be fitted with American or British AI radars; 220 were built.

The NF Mk.30 was the final wartime variant and was a high-altitude version, powered by two Rolls-Royce Merlin 76s. The NF Mk.30 had a maximum speed of at . It also carried early electronic countermeasures equipment. 526 were built.

Other Mosquito night fighter variants planned but never built included the NF Mk.X and NF Mk.XIV (the latter based on the NF Mk.XIII), both of which were to have two-stage Merlins. The NF Mk.31 was a variant of the NF Mk.30, but powered by Packard Merlins.

After the war, two more night fighter versions were developed:
The NF Mk.36 was similar to the Mosquito NF Mk.30, but fitted with the American-built AI.Mk.X radar. Powered by two Rolls-Royce Merlin 113/114 piston engines; 266 built. Max level speeds (TAS) with flame dampers fitted were at sea level, at , and at .

The NF Mk.38, 101 of which were built, was also similar to the Mosquito NF Mk.30, but fitted with the British-built AI Mk.IX radar. This variant suffered from stability problems and did not enter RAF service: 60 were eventually sold to Yugoslavia. According to the Pilot's Notes and Air Ministry 'Special Flying Instruction TF/487', which posted limits on the Mosquito's maximum speeds, the NF Mk.38 had a VNE of 370 knots (425 mph), without under-wing stores, and within the altitude range of sea level to . However, from 10,000 to the maximum speed was 348 knots (400 mph). As the height increased other recorded speeds were; 15,000 to 320 knots (368 mph); 20,000 to , 295 knots (339 mph); 25,000 to , 260 knots (299 mph); 30,000 to , 235 knots (270 mph). With two added 100-gallon fuel tanks this performance fell; between sea level and 15,000 feet 330 knots (379 mph); between 15,000 and 320 knots (368 mph); 20,000 to , 295 knots (339 mph); 25,000 to , 260 knots (299 mph); 30,000 to , 235 knots (270 mph). Little difference was noted above .

The FB Mk. VI, which first flew on 1 June 1942, was powered by two, single-stage two-speed, Merlin 21s or Merlin 25s, and introduced a re-stressed and reinforced "basic" wing structure capable of carrying single bombs on racks housed in streamlined fairings under each wing, or up to eight RP-3 25lb or 60 lb rockets. In addition fuel lines were added to the wings to enable single or drop tanks to be carried under each wing. The usual fixed armament was four 20 mm Hispano Mk.II cannon and four .303 (7.7 mm) Browning machine guns, while two bombs could be carried in the bomb bay.

Unlike the F Mk.II, the ventral bay doors were split into two pairs, with the forward pair being used to access the cannon, while the rear pair acted as bomb bay doors. The maximum fuel load was distributed between internal fuel tanks, plus two overload tanks, each of capacity, which could be fitted in the bomb bay, and two drop tanks. All-out level speed is often given as , although this speed applies to aircraft fitted with saxophone exhausts. The test aircraft ("HJ679") fitted with stub exhausts was found to be performing below expectations. It was returned to de Havilland at Hatfield where it was serviced. Its top speed was then tested and found to be , in line with expectations. 2,298 FB Mk. VIs were built, nearly one-third of Mosquito production. Two were converted to TR.33 carrier-borne, maritime strike prototypes.

The FB Mk. VI proved capable of holding its own against fighter aircraft, in addition to strike/bombing roles. For example, on 15 January 1945 Mosquito FB Mk. VIs of 143 Squadron were engaged by 30 Focke-Wulf Fw 190s from "Jagdgeschwader 5": the Mosquitoes sank an armed trawler and two merchant ships, but five Mosquitoes were lost (two reportedly to flak), while shooting down five Fw 190s.

Another fighter-bomber variant was the Mosquito FB Mk. XVIII (sometimes known as the "Tsetse") of which one was converted from a FB Mk. VI to serve as prototype and 17 were purpose-built. The Mk.XVIII was armed with a Molins "6-pounder Class M" cannon: this was a modified QF 6-pounder (57 mm) anti-tank gun fitted with an auto-loader to allow both semi- or fully automatic fire. 25 rounds were carried, with the entire installation weighing . In addition, of armour was added within the engine cowlings, around the nose and under the cockpit floor to protect the engines and crew from heavily armed U-boats, the intended primary target of the Mk.XVIII. Two or four .303 (7.7 mm) Browning machine guns were retained in the nose and were used to "sight" the main weapon onto the target.

The Air Ministry initially suspected that this variant would not work, but tests proved otherwise. Although the gun provided the Mosquito with yet more anti-shipping firepower for use against U-boats, it required a steady approach run to aim and fire the gun, making its wooden construction an even greater liability, in the face of intense anti-aircraft fire. The gun had a muzzle velocity of and an excellent range of some . It was sensitive to sidewards movement; an attack required a dive from at a 30° angle with the turn and bank indicator on centre. A move during the dive could jam the gun. The prototype "HJ732" was converted from a FB.VI and was first flown on 8 June 1943.

The effect of the new weapon was demonstrated on 10 March 1944 when Mk.XVIIIs from 248 Squadron (escorted by four Mk.VIs) engaged a German convoy of one U-boat and four destroyers, protected by 10 Ju 88s. Three of the Ju 88s were shot down. Pilot Tony Phillips destroyed one Ju 88 with four shells, one of which tore an engine off the Ju 88. The U-boat was damaged. On 25 March, was sunk by Molins-equipped Mosquitoes. On 10 June, was abandoned in the face of intense air attack from No. 248 Squadron, and was later sunk by a Liberator of No. 206 Squadron. On 5 April 1945 Mosquitoes with Molins attacked five German surface ships in the Kattegat and again demonstrated their value by setting them all on fire and sinking them. A German "Sperrbrecher" ("minefield breaker") was lost with all hands, with some 200 bodies being recovered by Swedish vessels. Some 900 German soldiers died in total. On 9 April, German U-boats , and were spotted in formation heading for Norway. All were sunk with rockets. and followed on 19 April and 2 May 1945, also sunk by rockets.
Despite the preference for rockets, a further development of the large gun idea was carried out using the even larger, 96 mm calibre QF 32-pounder, a gun based on the QF 3.7-inch AA gun designed for tank use, the airborne version using a novel form of muzzle brake. Developed to prove the feasibility of using such a large weapon in the Mosquito, this installation was not completed until after the war, when it was flown and fired in a single aircraft without problems, then scrapped.

Designs based on the Mk.VI were the FB Mk. 26, built in Canada, and the FB Mk.40, built in Australia, powered by Packard Merlins. The FB.26 improved from the FB.21 using single stage Packard Merlin 225s. Some 300 were built and another 37 converted to T.29 standard. 212 FB.40s were built by de Havilland Australia. Six were converted to PR.40; 28 to PR.41s, one to FB.42 and 22 to T.43 trainers. Most were powered by Packard-built Merlin 31 or 33s.

The Mosquito was also built as the Mosquito T Mk.III two-seat trainer. This version, powered by two Rolls-Royce Merlin 21s, was unarmed and had a modified cockpit fitted with dual control arrangements. A total of 348 of the T Mk.III were built for the RAF and Fleet Air Arm. de Havilland Australia built 11 T Mk.43 trainers, similar to the Mk.III.

To meet specification N.15/44 for a navalised Mosquito for Royal Navy use as a torpedo bomber, de Havilland produced a carrier-borne variant. A Mosquito FB.VI was modified as a prototype designated Sea Mosquito TR Mk.33 with folding wings, arrester hook, thimble nose radome, Merlin 25 engines with four-bladed propellers and a new oleo-pneumatic landing gear rather than the standard rubber-in-compression gear. Initial carrier tests of the Sea Mosquito were carried out by Eric "Winkle" Brown aboard HMS "Indefatigable", the first landing-on taking place on 25 March 1944. An order for 100 TR.33s was placed although only 50 were built at Leavesden. Armament was four 20 mm cannon, two 500 lb bombs in the bomb bay (another two could be fitted under the wings), eight 60 lb rockets (four under each wing) and a standard torpedo under the fuselage. The first production TR.33 flew on 10 November 1945. This series was followed by six Sea Mosquito TR Mk.37s, which were built at Chester (Broughton) and differed in having ASV Mk.XIII radar instead of the TR.33's AN/APS-6.

The RAF's target tug version was the Mosquito TT Mk.35, which were the last aircraft to remain in operational service with No 3 CAACU at Exeter, being finally retired in 1963. These aircraft were then featured in the film 633 Squadron.
A number of B Mk.XVIs bombers were converted into TT Mk.39 target tug aircraft. The Royal Navy also operated the Mosquito TT Mk.39 for target towing.
Two ex-RAF FB.6s were converted to TT.6 standard at Manchester (Ringway) Airport by Fairey Aviation in 1953–1954, and delivered to the Belgian Air Force for use as towing aircraft from the Sylt firing ranges.

A total of 1,032 (wartime 
+ 2 afterwards) Mosquitoes were built by De Havilland Canada at Downsview Airfield in Downsview Ontario (now Downsview Park in Toronto Ontario).


A number of Mosquito IVs were modified by Vickers-Armstrongs to carry Highball "bouncing bombs" and were allocated Vickers Type numbers:

About 5,000 of the total of 7,781 Mosquitoes built had major structural components fabricated from wood in High Wycombe, Buckinghamshire, England. Fuselages, wings and tailplanes were made at furniture companies such as Ronson, E. Gomme, Parker Knoll, Austinsuite and Styles & Mealing. Wing spars were made by J. B. Heath and Dancer & Hearne. Many of the other parts, including flaps, flap shrouds, fins, leading edge assemblies and bomb doors were also produced in the Buckinghamshire town. Dancer & Hearne processed much of the wood from start to finish, receiving timber and transforming it into finished wing spars at their factory in Penn Street on the outskirts of High Wycombe.

Initially much of the specialised yellow birch wood veneer and finished plywood used for the prototypes and early production aircraft was shipped from firms in Wisconsin, US. Prominent in this role were Roddis Plywood and Veneer Manufacturing in Marshfield. In conjunction with the USDA Forest Products Laboratory, Hamilton Roddis had developed new plywood adhesives and hot pressing technology. Later on, paper birch was logged in large quantities from the interior of British Columbia along the Fraser and Quesnel Rivers and processed in Quesnel and New Westminster by the Pacific Veneer Company. According to the Quesnel archives, BC paper birch supplied ½ of the wartime British Empire birch used for Mosquitoes and other aircraft.

As the supply of Ecuadorean balsa was threatened by the U-boats in the Atlantic Ocean, the Ministry of Aircraft Production approved a research effort to supplant the balsa with calcium alginate foam, made from local brown algae. By 1944 the foam was ready, but the U-boat threat had been reduced, the larger B-25 bombers were in sufficient supply to handle most of the bombing raids, and the foam was not used in Mosquito production.

In July 1941, it was decided that DH Canada would build Mosquitoes at Downsview, Ontario. This was to continue even if Germany invaded Great Britain. Packard Merlin engines produced under licence were bench-tested by August and the first two aircraft were built in September. Production was to increase to fifty per month by early 1942. Initially, the Canadian production was for bomber variants; later, fighters, fighter-bombers and training aircraft were also made. DH Chief Production Engineer, Harry Povey, was sent first, then W. D. Hunter followed on an extended stay, to liaise with materials and parts suppliers. As was the case with initial UK production, Tego-bonded plywood and birch veneer was obtained from firms in Wisconsin, principally Roddis Plywood and Veneer Manufacturing, Marshfield. Enemy action delayed the shipping of jigs and moulds and it was decided to build these locally. During 1942, production improved to over 80 machines per month, as sub-contractors and suppliers became established. A mechanised production line based in part on car building methods started in 1944. As the war progressed, Canadian Mosquitoes may have utilized paper birch supplied by the Pacific Veneer Company of New Westminster using birch logs from the Cariboo, although records only say this birch was shipped to England for production there. When flight testing could no longer keep up, this was moved to the Central Aircraft Company airfield, London, Ontario, where the approved Mosquitoes left for commissioning and subsequent ferry transfer to Europe.

Ferrying Mosquitoes and many other types of WWII aircraft from Canada to Europe was dangerous, resulting in losses of lives and machines, but in the exigencies of war it was regarded as the best option for twin-engine and multi-engine aircraft. In the parlance of the day, among RAF personnel, "it was no piece of cake." Considerable efforts were made by de Havilland Canada to resolve problems with engine and oil systems and an additional five hours of flight testing were introduced before the ferry flight, but the actual cause of some of the losses was unknown. Nevertheless, by the end of the war, nearly 500 Mosquito bombers and fighter-bombers had been ferried successfully by the Canadian operation.

After DH Canada had been established for the Mosquito, further manufacturing was set up at DH Australia, in Sydney. One of the DH staff who travelled there was the distinguished test pilot, Pat Fillingham. These production lines added totals of 1,133 aircraft of varying types from Canada plus 212 aircraft from Australia.

In total, both during the war and after, de Havilland exported 46 FB.VIs and 29 PR. XVIs to Australia; two FB.VI and 18 NF.30s to Belgium; approximately 250 FB.26, T.29 and T.27s from Canada to Nationalist China. A significant number never went into service due to deterioration on the voyage and to crashes during Chinese pilot training; however, five were captured by the People's Liberation Army during the Chinese Civil War; 19 FB.VIs to Czechoslovakia in 1948; 6 FB.VIs to Dominica; a few B.IVs, 57 FB.VIs, 29 PR.XVIs and 23 NF.30s to France. Some T.IIIs were exported to Israel along with 60 FB.VIs, and at least five PR.XVIs and 14 naval versions. Four T.IIIs, 76 FB.VIs, one FB.40 and four T.43s were exported to New Zealand. Three T.IIIs were exported to Norway, and 18 FB.VIs, which were later converted to night fighter standard. South Africa received two F.II and 14 PR.XVI/XIs and Sweden received 60 NF.XIXs. Turkey received 96 FB.VIs and several T.IIIs, and Yugoslavia had 60 NF.38s, 80 FB.VIs and three T.IIIs delivered. At least a single de Havilland Mosquito was delivered to the Soviet Union marked 'DK 296'.

Total Mosquito production was 7,781, of which 6,710 were built during the war.

A number of Mosquitoes were lost in civilian airline service, mostly with British Overseas Airways Corporation during World War II.

On 21 July 1996, Mosquito G-ASKH, wearing the markings of RR299, crashed 1 mile west of Manchester Barton Airport. Pilot Kevin Moorhouse and Engineer Steve Watson were both killed in the crash. At the time, this was the last airworthy Mosquito T.III.

There are approximately 30 non-flying Mosquitoes around the world with four airworthy examples, three in the United States and one in Canada. The largest collection of Mosquitoes is at the de Havilland Aircraft Museum in the United Kingdom, which owns three aircraft, including the first prototype, "W4050", the only initial prototype of a Second World War British aircraft design still in existence in the 21st century.




Dave Thomas (businessman)

Rex David Thomas (July 2, 1932 – January 8, 2002) was an American businessman, philanthropist, and fast-food tycoon. Thomas was the founder and chief executive officer of Wendy's, a fast-food restaurant chain specializing in hamburgers. In this role, Thomas appeared in more than 800 commercial advertisements for the chain from 1989 to 2002, more than any other company founder in television history.

Rex David Thomas was born July 2, 1932, in Atlantic City, New Jersey. His biological father's name was Sam and his biological mother's name was Molly. Thomas was adopted between six weeks and six months later by Rex and Auleva Thomas, and as an adult became a well-known advocate for adoption, founding the Dave Thomas Foundation for Adoption. After his adoptive mother's death when he was five, his father moved around the country seeking work. Thomas spent some of his early childhood near Kalamazoo, Michigan, with his grandmother, Minnie Sinclair, whom he credited with teaching him the importance of service and treating others well and with respect, lessons that helped him in his future business life.

At age 12, Thomas had his first job at Regas Restaurant, a fine dining restaurant in downtown Knoxville, Tennessee, then lost it in a dispute with his boss. He vowed never to lose another job. Decades later, Regas Restaurant installed a large autographed poster of Thomas just inside their entrance, which remained until the business closed in 2010. By 15, he was moving with his father and working at the Hobby House Restaurant in Fort Wayne, Indiana. When his father prepared to move again, Thomas decided to stay in Fort Wayne, dropping out of high school to work full-time at the restaurant. Thomas, who considered ending his schooling the greatest mistake of his life, did not graduate from high school until 1993, when he obtained a GED.

He subsequently became an education advocate and founded the Dave Thomas Education Center in Coconut Creek, Florida, which offers GED classes to young adults.

At the outbreak of the Korean War in 1950, rather than waiting for the draft, he volunteered for the U.S. Army at age 18 to have some choice in assignments. Having food production and service experience, Thomas requested the Cook's and Baker's School at Fort Benning, Georgia. He was sent to West Germany as a mess sergeant and was responsible for the daily meals of 2,000 soldiers, rising to the rank of staff sergeant. After his discharge in 1953, Thomas returned to Fort Wayne and the Hobby House.

In the mid-1950s, Kentucky Fried Chicken founder Col. Harland Sanders came to Fort Wayne, hoping to find restaurateurs with established businesses to whom he could try to sell KFC franchises. At first, Thomas – who was the head cook at a restaurant – and the Clauss family declined Sanders' offer, but Sanders persisted, and the Clauss family franchised their restaurant with KFC; they also later owned many other KFC franchises in the Midwest. During this time, Thomas worked with Sanders on many projects to make KFC more profitable and give it brand recognition. Among other ideas for improvements, Thomas suggested that KFC reduce the number of items on its menu and instead focus on a signature dish; he also proposed that KFC make commercials in which Sanders would personally appear. Thomas was sent by the Clauss family in the mid-1960s to help turn around four of their failing KFC stores in Columbus, Ohio.

By 1968, Thomas had increased sales in the four fried chicken restaurants so much that he sold his share in them back to Sanders for more than $1.5 million. This experience would prove invaluable to Thomas when he began Wendy's about a year later.

After serving as a regional director for Kentucky Fried Chicken, Thomas became part of the investor group which founded Arthur Treacher's. His involvement with the new restaurant lasted less than a year before he went on to found Wendy's.

Thomas opened his first Wendy's in Columbus, Ohio, November 15, 1969. This original restaurant remained operational until March 2, 2007, when it was closed due to lagging sales. Thomas named the restaurant after his eight-year-old daughter Melinda Lou, whose nickname was "Wendy", stemming from the child's inability to say her own name at a young age. According to "Bio TV", Dave claims that people nicknamed his daughter "Wenda. Not Wendy, but Wenda. 'I'm going to call it Wendy's Old Fashioned Hamburgers'." Before his death in 2002, Thomas admitted regret for naming the franchise after his daughter, saying "I should've just named it after myself, because it put a lot of pressure on [her]."

In 1982, Thomas resigned from his day-to-day operations at Wendy's. However, by 1985, several company business decisions, including an awkward new breakfast menu and loss in brand awareness due to fizzled marketing efforts, led the company's new president to urge Thomas back into a more active role with Wendy's. Thomas began to visit franchises and espouse his hardworking, so-called "mop-bucket attitude". In 1989, he took on a significant role as the TV spokesperson in a series of commercials for the brand. Thomas was not a natural actor, and initially, his performances were criticized as stiff and ineffective by advertising critics.

By 1990, after efforts by Wendy's advertising agency, Backer Spielvolgel Bates, to get humor into the campaign, a decision was made to portray Thomas in a more self-deprecating and folksy manner, which proved much more popular with test audiences. Consumer brand awareness of Wendy's eventually regained levels it had not achieved since octogenarian Clara Peller's highly popular "Where's the beef?" campaign of 1984.

With his natural self-effacing style and his relaxed manner, Thomas quickly became a household name. A company survey during the 1990s, a decade during which Thomas starred in every Wendy's commercial that aired, found that 90% of Americans knew who Thomas was. After more than 800 commercials, it was clear that Thomas played a major role in Wendy's' status as the third most popular burger restaurant in the U.S.

In 1982, Thomas and a consortium of entrepreneurs created and launched The Wellington School in Upper Arlington, Ohio. The group of entrepreneurs spent three years refining plans, raising money, finding a property, and recruiting teachers and students.

The school opened with 137 students and 19 employees as the first co-ed independent school in the greater Columbus metropolitan area. The first graduating class was in 1989 with 32 students. In 2010, a new building opened. In 2012, the Little Jags preschool program for 3-year-olds began.

Thomas was a Christian. He was married for 47 years to Lorraine Thomas and started his family with her in Upper Arlington, Ohio. In addition to Melinda, they had three more daughters – Pam, Lori, and Molly – and a son, Kenny. After Kenny died in 2013, his sisters still continued to own and run multiple Wendy's locations. Thomas founded the chain Sisters Chicken and Biscuits in 1978, named in reference to his other three daughters.

Thomas had been afflicted with a carcinoid neuroendocrine tumor for a decade, before it metastasized to his liver. He died on January 8, 2002, in his home in Fort Lauderdale, Florida, at the age of 69. Thomas was buried in Union Cemetery in Columbus, Ohio. At the time of his death, there were more than 6,000 Wendy's restaurants operating in North America.

In 1979, Thomas received the Horatio Alger Award for his success with his restaurant chain Wendy's, which had reached annual sales of US$1 billion with franchises then.

In 1980, Thomas received the Golden Plate Award of the American Academy of Achievement.

Thomas, realizing that his success as a high school dropout might convince other teenagers to quit school (something he later claimed was a mistake), became a student at Coconut Creek High School. He earned a GED in 1993. Thomas was inducted into the Junior Achievement U.S. Business Hall of Fame in 1999.

Thomas was an honorary Kentucky colonel, as was former boss Harland Sanders.

Thomas was posthumously awarded the Presidential Medal of Freedom in 2003.

Thomas was raised a Master Mason in Sol. D. Bayless Lodge No. 359 of Fort Wayne, Indiana, and became a 32° Mason, N.M.J., on November 16, 1961, in the Scottish Rite Bodies of Fort Wayne. He was unanimously elected to the Scottish Rite's highest honor, the Grand Cross, by The Supreme Council, 33°, in Executive Session on October 3, 1997, in Washington, D.C.

A small triangular block and the surrounding streets and traffic pattern in the Northeast quadrant of Washington, D.C., is unofficially known in the D.C. area as Dave Thomas Circle, due to the longtime presence of a Wendy's franchise and its parking lot on that block.


Device driver

In computing, a device driver is a computer program that operates or controls a particular type of device that is attached to a computer or automaton. A driver provides a software interface to hardware devices, enabling operating systems and other computer programs to access hardware functions without needing to know precise details about the hardware being used.

A driver communicates with the device through the computer bus or communications subsystem to which the hardware connects. When a calling program invokes a routine in the driver, the driver issues commands to the device (drives it). Once the device sends data back to the driver, the driver may invoke routines in the original calling program.

Drivers are hardware dependent and operating-system-specific. They usually provide the interrupt handling required for any necessary asynchronous time-dependent hardware interface.

The main purpose of device drivers is to provide abstraction by acting as a translator between a hardware device and the applications or operating systems that use it. Programmers can write higher-level application code independently of whatever specific hardware the end-user is using.
For example, a high-level application for interacting with a serial port may simply have two functions for "send data" and "receive data". At a lower level, a device driver implementing these functions would communicate to the particular serial port controller installed on a user's computer. The commands needed to control a 16550 UART are much different from the commands needed to control an FTDI serial port converter, but each hardware-specific device driver abstracts these details into the same (or similar) software interface.

Writing a device driver requires an in-depth understanding of how the hardware and the software works for a given platform function. Because drivers require low-level access to hardware functions in order to operate, drivers typically operate in a highly privileged environment and can cause system operational issues if something goes wrong. In contrast, most user-level software on modern operating systems can be stopped without greatly affecting the rest of the system. Even drivers executing in user mode can crash a system if the device is erroneously programmed. These factors make it more difficult and dangerous to diagnose problems.

The task of writing drivers thus usually falls to software engineers or computer engineers who work for hardware-development companies. This is because they have better information than most outsiders about the design of their hardware. Moreover, it was traditionally considered in the hardware manufacturer's interest to guarantee that their clients can use their hardware in an optimum way. Typically, the Logical Device Driver (LDD) is written by the operating system vendor, while the Physical Device Driver (PDD) is implemented by the device vendor. However, in recent years, non-vendors have written numerous device drivers for proprietary devices, mainly for use with free and open source operating systems. In such cases, it is important that the hardware manufacturer provide information on how the device communicates. Although this information can instead be learned by reverse engineering, this is much more difficult with hardware than it is with software.

Microsoft has attempted to reduce system instability due to poorly written device drivers by creating a new framework for driver development, called Windows Driver Frameworks (WDF). This includes User-Mode Driver Framework (UMDF) that encourages development of certain types of drivers—primarily those that implement a message-based protocol for communicating with their devices—as user-mode drivers. If such drivers malfunction, they do not cause system instability. The Kernel-Mode Driver Framework (KMDF) model continues to allow development of kernel-mode device drivers, but attempts to provide standard implementations of functions that are known to cause problems, including cancellation of I/O operations, power management, and plug and play device support.

Apple has an open-source framework for developing drivers on macOS, called I/O Kit.

In Linux environments, programmers can build device drivers as parts of the kernel, separately as loadable modules, or as user-mode drivers (for certain types of devices where kernel interfaces exist, such as for USB devices). Makedev includes a list of the devices in Linux, including ttyS (terminal), lp (parallel port), hd (disk), loop, and sound (these include mixer, sequencer, dsp, and audio).

Microsoft Windows .sys files and Linux .ko files can contain loadable device drivers. The advantage of loadable device drivers is that they can be loaded only when necessary and then unloaded, thus saving kernel memory.

Depending on the operating system, device drivers may be permitted to run at various different privilege levels. The choice of which level of privilege the drivers are in is largely decided by the type of kernel an operating system uses. An operating system which uses a monolithic kernel, such as the Linux kernel, will typically run device drivers with the same privilege as all other kernel objects. By contrast, a system designed around microkernel, such as Minix, will place drivers as processes independent from the kernel but that use the it for essential input-output functionalities and to pass messages between user programs and each other.
On Windows NT, a system with a hybrid kernel, it is common for device drivers to run in either kernel-mode or user-mode. 

The most common mechanism for segregating memory into various privilege levels is via protection rings. On many systems, such as those with x86 and ARM processors, switching between rings imposes a performance penalty, a factor that operating system developers and embedded software engineers consider when creating drivers for devices which are preferred to be run with low latency, such as network interface cards. The primary benefit of running a driver in user mode is improved stability, since a poorly written user-mode device driver cannot crash the system by overwriting kernel memory.

Because of the diversity of hardware and operating systems, drivers operate in many different environments. Drivers may interface with:


Common levels of abstraction for device drivers include:

So choosing and installing the correct device drivers for given hardware is often a key component of computer system configuration.

Virtual device drivers represent a particular variant of device drivers. They are used to emulate a hardware device, particularly in virtualization environments, for example when a DOS program is run on a Microsoft Windows computer or when a guest operating system is run on, for example, a Xen host. Instead of enabling the guest operating system to dialog with hardware, virtual device drivers take the opposite role and emulates a piece of hardware, so that the guest operating system and its drivers running inside a virtual machine can have the illusion of accessing real hardware. Attempts by the guest operating system to access the hardware are routed to the virtual device driver in the host operating system as e.g., function calls. The virtual device driver can also send simulated processor-level events like interrupts into the virtual machine.

Virtual devices may also operate in a non-virtualized environment. For example, a virtual network adapter is used with a virtual private network, while a virtual disk device is used with iSCSI. A good example for virtual device drivers can be Daemon Tools.

There are several variants of virtual device drivers, such as VxDs, VLMs, and VDDs.


Solaris descriptions of commonly used device drivers:


A device on the PCI bus or USB is identified by two IDs which consist of 4 hexadecimal numbers each. The vendor ID identifies the vendor of the device. The device ID identifies a specific device from that manufacturer/vendor.

A PCI device has often an ID pair for the main chip of the device, and also a subsystem ID pair which identifies the vendor, which may be different from the chip manufacturer.

Devices often have a large number of diverse and customized device drivers running in their operating system (OS) kernel and often contain various bugs and vulnerabilities, making them a target for exploits. "Bring Your Own Vulnerable Driver" (BYOVD) uses signed, old drivers that contain flaws that allow hackers to insert malicious code into the kernel.<ref name="arstechnica/microsoft-blunder"></ref>

There is a lack of effective kernel vulnerability detection tools, especially for closed-source OSes such as Microsoft Windows where the source code of the device drivers is mostly not public (open source) and the drivers often also have many privileges.

Such vulnerabilities also exist in drivers in laptops, drivers for WiFi and bluetooth, gaming/graphics drivers, and drivers in printers.

A group of security researchers considers the lack of isolation as one of the main factors undermining kernel security, and published a isolation framework to protect operating system kernels, primarily the monolithic Linux kernel which, according to them, gets ~80,000 commits/year to its drivers. 


Dimona

Dimona (, ) is an Israeli city in the Negev desert, to the south-east of Beersheba and west of the Dead Sea above the Arava valley in the Southern District of Israel. In its population was . The Shimon Peres Negev Nuclear Research Center, colloquially known as the "Dimona Reactor", is located southeast of the city.

The Negev Naming Committee chose the name based upon that of a biblical town, mentioned in Joshua 15:21-22, on the basis that "the sound of this name had been preserved in the Arabic name Harabat Umm Dumna."

Dimona was one of the development towns created in the 1950s under the leadership of Israel's first Prime Minister, David Ben-Gurion. Dimona itself was conceived in 1953. The location chosen was close to the Dead Sea Works. It was established in 1955. The first residents were Jewish immigrants from North Africa, with an initial 36 families being the first to settle there. Its population in 1955 was about 300. The North African immigrants also constructed the city's houses. The population was composed mainly of North African, particularly Moroccan immigrants, though immigrants from Yemen and Eastern Europe also arrived, as did Bene Israel immigrants from India.

When the Israeli nuclear program began in 1958, a location not far from the city was chosen for the Negev Nuclear Research Center due to its relative isolation in the desert and availability of housing. In the late 1950s and early 1960s, immigrants from Eastern Europe arrived. A textile factory was opened in 1958. That same year, Dimona became a local council. In 1961, it had a population of 5,000. The emblem of Dimona (as a local council), adopted 2 March 1961, appeared on a stamp issued on 24 March 1965. Dimona was declared a city in 1969. In 1971, it had a population of 23,700.

In spite of a gradual decrease during the 1980s, the city's population began to grow once again in the 1990s when it took in immigrants from the former Soviet Union and Ethiopia. Currently, Dimona is the third largest city in the Negev, with the population of almost 34,000. Due to projected rapid population growth in the Negev, the city is expected to triple in size by 2025.

Dimona is described as "mini-India" by many for its 7,500-strong Indian Jewish community. It is also home to Israel's Black Hebrew community, formerly governed by its founder and spiritual leader, Ben Ammi Ben-Israel, now deceased. The Black Hebrews number about 3,000 in Dimona, with additional families in Arad, Mitzpe Ramon and the Tiberias area. Their official status in Israel was an ongoing issue for many years, but in May 1990, the issue was resolved with the issuing of first B/1 visas, and a year later, issuing of temporary residency. Status was extended to August 2003, when the Israeli Ministry of Interior granted permanent residency.

In the early 1980s, textile plants, such as Dimona Textiles Ltd., dominated the industrial landscape. Many plants have since closed. Dimona Silica Industries Ltd. manufactures precipitated silica and calcium carbonate fillers. About a third of the city's population works in industrial workplaces (chemical plants near the Dead Sea like the Dead Sea Works, high-tech companies and textile shops), and another third in the area of services. Due to the introduction of new technologies, many workers have been made redundant in the recent years, creating a total unemployment rate of about 10%. Dimona has taken part of Israel's solar transformation. The Rotem Industrial Complex outside of the city has dozens of solar mirrors that focus the sun's rays on a tower that in turn heats a water boiler to create steam, turning a turbine to create electricity. Luz II, Ltd. plans to use the solar array to test new technology for the three new solar plants to be built in California for Pacific Gas and Electric Company.

Dimona is located in the Negev Desert. The city stands at an elevation of around above sea level.

Dimona has a semi-arid climate (Köppen climate classification: "BSh"). The average annual temperature is , and around of precipitation falls annually.

In the early 1950s, an extension to Dimona and south was constructed from the Railway to Beersheba, designed for freight traffic. A passenger service began in 2005, after pressure from Dimona's municipality. Dimona Railway Station is located in the southwestern part of the city. The main bus terminal is the Dimona Central Bus Station, with lines to Beersheba, Tel Aviv, Eilat, and nearby towns.


Dimona is twinned with:


DC Comics

DC Comics, Inc. (doing business as DC) is an American comic book publisher and the flagship unit of DC Entertainment, a subsidiary of Warner Bros. Discovery.

DC Comics is one of the largest and oldest American comic book companies, with their first comic under the DC banner being published in 1937. The majority of its publications take place within the fictional DC Universe and feature numerous culturally iconic heroic characters, such as Superman, Batman, Wonder Woman, Green Lantern, the Flash, and Aquaman; as well as famous fictional teams including the Justice League, the Justice Society of America, the Teen Titans, and the Suicide Squad. The universe also features an assortment of well-known supervillains such as the Joker, Lex Luthor, Deathstroke, the Reverse-Flash, Brainiac, and Darkseid. The company has published non-DC Universe-related material, including "Watchmen", "V for Vendetta", "Fables" and many titles under their alternative imprint Vertigo and now DC Black Label.

Originally in Manhattan at 432 Fourth Avenue, the DC Comics offices have been located at 480 and later 575 Lexington Avenue; 909 Third Avenue; 75 Rockefeller Plaza; 666 Fifth Avenue; and 1325 Avenue of the Americas. DC had its headquarters at 1700 Broadway, Midtown Manhattan, New York City, but DC Entertainment relocated its headquarters to Burbank, California in April 2015.

Penguin Random House Publisher Services distributes DC Comics' books to the bookstore market, while Diamond Comic Distributors supplied the comics shop direct market until June 2020, when Lunar Distribution and UCS Comic Distributors, who already dominated direct market distribution on account of the disruption to Diamond that resulted from the COVID-19 pandemic, replaced Diamond to distribute to that market.

DC Comics and its longtime major competitor Marvel Comics (acquired in 2009 by The Walt Disney Company, Warner Bros. Discovery's main competitor) together shared approximately 70% of the American comic book market in 2017, though this number may give a distorted view since graphic novels are excluded. With the sales of all books included, DC is the second biggest publisher, after Viz Media, and Marvel is third.

Entrepreneur Major Malcolm Wheeler-Nicholson founded National Allied Publications in 1935 intended as an American comic book publishing company. The first publishing of the company debuted with the tabloid-sized "New Fun: The Big Comic Magazine" #1 (the first of a comic series later called "More Fun Comics") with a cover date of February 1935. It was an anthology title essentially for original stories not reprinted from newspaper strips, unlike many comic book series before it. While superhero comics are what DC Comics is known for throughout modern times, the genres in the first anthology titles consisted of funnies, Western comics and adventure-related stories. The character Doctor Occult, created by Jerry Siegel and Joe Shuster in December 1935 with issue No. 6 of "New Fun Comics", is considered the earliest recurring superhero created by DC who is still used. The company created a second recurring title called "New Comics" No. 1, released in December 1935, which was the start of the long-running "Adventure Comics" series featuring many anthology titles as well.

Wheeler-Nicholson's next and final title, "Detective Comics", advertised with a cover illustration dated December 1936, eventually premiered three months late with a March 1937 cover date. The themed anthology that revolved originally around fictional detective stories became in modern times the longest-running ongoing comic series. A notable debut in the first issue was Slam Bradley, created in a collaboration between Malcolm Wheeler-Nicholson, Jerry Siegel and Joe Shuster. In 1937, in debt to printing-plant owner and magazine distributor Harry Donenfeld — who also published pulp magazines and operated as a principal in the magazine distributorship Independent News — Wheeler-Nicholson had to take Donenfeld on as a partner to publish "Detective Comics" No. 1. Detective Comics, Inc. (which would help inspire the abbreviation DC) was formed, with Wheeler-Nicholson and Jack S. Liebowitz, Donenfeld's accountant, listed as owners. Major Wheeler-Nicholson remained for a year, but cash-flow problems continued, and he was forced out. Shortly afterwards, Detective Comics, Inc. purchased the remains of National Allied, also known as Nicholson Publishing, at a bankruptcy auction.

Meanwhile, Max Gaines formed the sister company All-American Publications in 1939. Detective Comics, Inc. soon launched a new anthology title, entitled "Action Comics". Issue#1, cover dated June 1938, first featured characters such as Superman by Siegel and Shuster, Zatara by Fred Guardineer and Tex Thompson by Ken Finch and Bernard Baily. It is considered to be the first comic book to feature the new character archetype, soon known as "superheroes", and was a sales hit bringing to life a new age of comic books, with the credit going to the first appearance of Superman both being featured on the cover and within the issue. It is now one of the most expensive and valuable comic book issues of all time. The issue's first featured tale which starred Superman was the first to feature an origin story of superheroes with the reveal of an unnamed planet, later known as Krypton, that he is said to be from. The issue also contained the first essential supporting character and one of the earliest essential female characters in comics with Lois Lane as Superman's first depicted romantic interest. The Green Hornet-inspired character known as the Crimson Avenger by Jim Chamber was featured in "Detective Comics" No. 20 (October 1938). The character makes a distinction of being the first masked vigilante published by DC. An unnamed "office boy" retconned as Jimmy Olsen's first appearance was revealed in "Action Comics" #6's (November 1938) Superman story by Siegel and Shuster.

Starting in 1939, Siegel and Shuster's Superman would be the first comic-derived character to appear outside of comic magazines and later appear in newspaper strips starring himself, which first introduced Superman's biological parents, Jor-El and Lara. All-American Publications' first comic series called "All-American Comics" was first published in April 1939. The series "Detective Comics" would make successful history as first featuring Batman by Bob Kane and Bill Finger in issue No.27 (March 1939) with the request of more superhero titles. Batman was depicted as a masked vigilante wearing a caped suit known as the Batsuit, along with riding a car that would later be referred to as the Batmobile. Also within the Batman story was the supporting character, James Gordon, Police commissioner of what later would be Gotham City Police Department. Despite being a parody, All-American Publications introduced the earliest female character who would later be a female superhero called Red Tornado (though disguised as a male) in Ma Hunkel who first appeared in the "Scribbly" stories in "All-American Comics" No. 3 (June 1939). Another important Batman debut was the introduction of the fictional mansion known as Wayne Manor first seen in "Detective Comics" No. 28 (June 1939). The series "Adventure Comics" would eventually follow in the footsteps of "Action Comics" and "Detective Comics," featuring a new recurring superhero. The superhero called Sandman was first written in issue No. 40 (cover date: July 1939). "Action Comics" No. 13 (June 1939) introduced the first recurring Superman enemy referred to as the Ultra-Humanite first introduced by Siegel and Shuster, commonly cited as one of the earliest supervillains in comic books. The character Superman had another breakthrough when he was given his own comic book, which was unheard of at the time. The first issue, introduced in June 1939, helped directly introduce Superman's adoptive parents, Jonathan and Martha Kent, by Siegel and Shuster. "Detective Comics" #29 (July 1939) introduced the Batman's utility belt by Gardner Fox. Outside of DC's publishing, a character later integrated as DC was introduced by Fox Feature Syndicate named the Blue Beetle released in August 1939. Fictional cities would be a common theme of DC. The first revealed city was Superman's home city, Metropolis, that was originally named in "Action Comics" No. 16 in September 1939. "Detective Comics" No. 31 in September 1939 by Gardner Fox, Bob Kane and Sheldon Moldoff introduced a romantic interest of Batman named Julie Madison, the weapon known as the Batarang that Batman commonly uses, and the fictional aircraft called the Batplane. Batman's origin would first be shown in "Detective Comics" No. 33 (Nov. 1939) first depicting the death of Thomas Wayne and Martha Wayne by a mugger. The origin story would remain crucial for the fictional character since the inception.
The "Daily Planet" (a common setting of Superman) was first named in a Superman newspaper strip around November 1939. The superhero Doll Man was the first superhero by Quality, which DC now owns. Fawcett Comics was formed around 1939 and would become DC's original competitor company in the next decade.

National Allied Publications soon merged with Detective Comics, Inc., forming National Comics Publications on September 30, 1946. National Comics Publications absorbed an affiliated concern, Max Gaines' and Liebowitz' All-American Publications. In the same year Gaines let Liebowitz buy him out, and kept only "Picture Stories from the Bible" as the foundation of his own new company, EC Comics. At that point, "Liebowitz promptly orchestrated the merger of All-American and Detective Comics into National Comics... Next he took charge of organizing National Comics, [the self-distributorship] Independent News, and their affiliated firms into a single corporate entity, National Periodical Publications". National Periodical Publications became publicly traded on the stock market in 1961.

Despite the official names "National Comics" and "National Periodical Publications", the company began branding itself as "Superman-DC" as early as 1940, and the company became known colloquially as DC Comics for years before the official adoption of that name in 1977.

The company began to move aggressively against what it saw as copyright-violating imitations from other companies, such as Fox Comics' Wonder Man, which (according to court testimony) Fox started as a copy of Superman. This extended to DC suing Fawcett Comics over Captain Marvel, at the time comics' top-selling character (see "National Comics Publications, Inc. v. Fawcett Publications, Inc."). Faced with declining sales and the prospect of bankruptcy if it lost, Fawcett capitulated in 1953 and ceased publishing comics. Years later, Fawcett sold the rights for Captain Marvel to DC—which in 1972 revived Captain Marvel in the new title "Shazam!" featuring artwork by his creator, C. C. Beck. In the meantime, the abandoned trademark had been seized by Marvel Comics in 1967, with the creation of their Captain Marvel, forbidding the DC comic itself to be called that. While Captain Marvel did not recapture his old popularity, he later appeared in a Saturday morning live action TV adaptation and gained a prominent place in the mainstream continuity DC calls the DC Universe.

When the popularity of superheroes faded in the late 1940s, the company focused on such genres as science fiction, Westerns, humor, and romance. DC also published crime and horror titles, but relatively tame ones, and thus avoided the mid-1950s backlash against such comics. A handful of the most popular superhero-titles, including "Action Comics" and "Detective Comics", the medium's two longest-running titles, continued publication.

In the mid-1950s, editorial director Irwin Donenfeld and publisher Liebowitz directed editor Julius Schwartz (whose roots lay in the science-fiction book market) to produce a one-shot Flash story in the try-out title "Showcase". Instead of reviving the old character, Schwartz had writers Robert Kanigher and John Broome, penciler Carmine Infantino, and inker Joe Kubert create an entirely new super-speedster, updating and modernizing the Flash's civilian identity, costume, and origin with a science-fiction bent. The Flash's reimagining in "Showcase" No. 4 (October 1956) proved sufficiently popular that it soon led to a similar revamping of the Green Lantern character, the introduction of the modern all-star team Justice League of America (JLA), and many more superheroes, heralding what historians and fans call the Silver Age of Comic Books.

National did not reimagine its continuing characters (primarily Superman, Batman, and Wonder Woman), but radically overhauled them. The Superman family of titles, under editor Mort Weisinger, introduced such enduring characters as Supergirl, Bizarro, and Brainiac. The Batman titles, under editor Jack Schiff, introduced the successful Batwoman, Bat-Girl, Ace the Bat-Hound, and Bat-Mite in an attempt to modernize the strip with non-science-fiction elements. Schwartz, together with artist Infantino, then revitalized Batman in what the company promoted as the "New Look", with relatively down-to-Earth stories re-emphasizing Batman as a detective. Meanwhile, editor Kanigher successfully introduced a whole family of Wonder Woman characters having fantastic adventures in a mythological context.

Since the 1940s, when Superman, Batman, and many of the company's other heroes began appearing in stories together, DC's characters inhabited a shared continuity that, decades later, was dubbed the "DC Universe" by fans. With the story "Flash of Two Worlds", in "Flash" No. 123 (September 1961), editor Schwartz (with writer Gardner Fox and artists Infantino and Joe Giella) introduced a concept that allowed slotting the 1930s and 1940s Golden Age heroes into this continuity via the explanation that they lived on an other-dimensional "Earth 2", as opposed to the modern heroes' "Earth 1"—in the process creating the foundation for what was later called the DC Multiverse.

DC's introduction of the reimagined superheroes did not go unnoticed by other comics companies. In 1961, with DC's JLA as the specific spur, Marvel Comics writer-editor Stan Lee and a robust creator Jack Kirby ushered in the sub-Silver Age "Marvel Age" of comics with the debut issue of "The Fantastic Four". Reportedly, DC ignored the initial success of Marvel with this editorial change until its consistently strengthening sales, albeit also benefiting Independent News' business as their distributor as well, made that impossible. That commercial situation especially applied with Marvel's superior sell-through percentage numbers which were typically 70% to DC's roughly 50%, which meant DC's publications were barely making a profit in comparison after returns from the distributors were calculated while Marvel was making an excellent profit by comparison.

However, the senior DC staff were reportedly at a loss at this time to understand how this small publishing house was achieving this increasingly threatening commercial strength. For instance, when Marvel's product was examined in a meeting, Marvel's emphasis on more sophisticated character-based narrative and artist-driven visual storytelling was apparently ignored for self-deluding guesses at the brand's popularity which included superficial reasons like the presence of the color red or word balloons on the cover, or that the perceived crudeness of the interior art was somehow more appealing to readers. When Lee learned about DC's subsequent experimental attempts to imitate these perceived details, he amused himself by arranging direct defiance of those assumptions in Marvel's publications as sales strengthened further to frustrate the competition.

However, this ignorance of Marvel's true appeal did not extend to some of the writing talent during this period, from which there were some attempts to emulate Marvel's narrative approach. For instance, there was the "Doom Patrol" series by Arnold Drake, a writer who previously warned the management of the new rival's strength; a superhero team of outsiders who resented their freakish powers, which Drake later speculated was plagiarized by Stan Lee to create "The X-Men". There was also the young Jim Shooter who purposely emulated Marvel's writing when he wrote for DC after much study of both companies' styles, such as for the "Legion of Super-Heroes" feature. In 1966, National Periodical Publications had set up its own television arm, led by Allen Ducovny to develop and produce projects for television, with Superman TV Corporation to handle its television distribution of NPP's TV shows.

A 1966 Batman TV show on the ABC network sparked a temporary spike in comic book sales, and a brief fad for superheroes in Saturday morning animation (Filmation created most of DC's initial cartoons) and other media. DC significantly lightened the tone of many DC comics—particularly "Batman" and "Detective Comics"—to better complement the "camp" tone of the TV series. This tone coincided with the famous "Go-Go Checks" checkerboard cover-dress which featured a black-and-white checkerboard strip (all DC books cover dated February 1966 until August 1967) at the top of each comic, a misguided attempt by then-managing editor Irwin Donenfeld to make DC's output "stand out on the newsracks". In particular, DC artist, Carmine Infantino, complained that the visual cover distinctiveness made DC's titles easier for readers to see and then avoid in favor of Marvel's titles.

In 1967, Batman artist Infantino (who had designed popular Silver Age characters Batgirl and the Phantom Stranger) rose from art director to become DC's editorial director. With the growing popularity of upstart rival Marvel Comics threatening to topple DC from its longtime number-one position in the comics industry, he attempted to infuse the company with more focus towards marketing new and existing titles and characters with more adult sensibilities towards an emerging older age group of superhero comic book fans that grew out of Marvel's efforts to market their superhero line to college-aged adults. He also recruited major talents such as ex-Marvel artist and Spider-Man co-creator Steve Ditko and promising newcomers Neal Adams and Denny O'Neil and replaced some existing DC editors with artist-editors, including Joe Kubert and Dick Giordano, to give DC's output a more artistic critical eye.

In 1967, National Periodical Publications was purchased by Kinney National Company, which purchased Warner Bros.-Seven Arts in 1969. Kinney National spun off its non-entertainment assets in 1972 (as National Kinney Corporation) and changed its name to Warner Communications Inc.

In 1970, Jack Kirby moved from Marvel Comics to DC, at the end of the Silver Age of Comics, in which Kirby's contributions to Marvel played a large, integral role.

As artist Gil Kane described:

Jack was the single most influential figure in the turnaround in Marvel's fortunes from the time he rejoined the company ... It wasn't merely that Jack conceived most of the characters that are being done, but ... Jack's point of view and philosophy of drawing became the governing philosophy of the entire publishing company and, beyond the publishing company, of the entire field ... [Marvel took] Jack and use[d] him as a primer. They would get artists ... and they taught them the ABCs, which amounted to learning Jack Kirby ... Jack was like the Holy Scripture and they simply had to follow him without deviation. That's what was told to me ... It was how they taught everyone to reconcile all those opposing attitudes to one single master point of view.

Given "carte blanche" to write and illustrate his own stories, he created a handful of thematically-linked series he called collectively "The Fourth World". In the existing series "Superman's Pal Jimmy Olsen" and in his own, newly-launched series "New Gods", "Mister Miracle", and "The Forever People", Kirby introduced such enduring characters and concepts as arch-villain Darkseid and the other-dimensional realm Apokolips. Furthermore, Kirby intended their stories to be reprinted in collected editions, in a publishing format that was later called the trade paperback, which became a standard industry practice decades later. While sales were respectable, they did not meet DC management's initially high expectations, and also suffered from a lack of comprehension and internal support from Infantino. By 1973 the "Fourth World" was all cancelled, although Kirby's conceptions soon became integral to the broadening of the DC Universe, especially after the major toy-company, Kenner Products, judged them ideal for their action-figure adaptation of the DC Universe, the Super Powers Collection. Obligated by his contract, Kirby created other unrelated series for DC, including "Kamandi", "The Demon", and "OMAC", before ultimately returning to Marvel Comics in 1976.

Following the science-fiction innovations of the Silver Age, the comics of the 1970s and 1980s became known as the Bronze Age, as fantasy gave way to more naturalistic and sometimes darker themes. Illegal drug use, banned by the Comics Code Authority, explicitly appeared in comics for the first time in Marvel Comics' story "Green Goblin Reborn!" in "The Amazing Spider-Man" No. 96 (May 1971), and after the Code's updating in response, DC offered a drug-fueled storyline in writer Dennis O'Neil and artist Neal Adams' "Green Lantern", beginning with the story "Snowbirds Don't Fly" in the retitled "Green Lantern / Green Arrow" No. 85 (September 1971), which depicted Speedy, the teen sidekick of superhero archer Green Arrow, as having become a heroin addict.

Jenette Kahn, a former children's magazine publisher, replaced Infantino as editorial director in January 1976. As it happened, her first task even before being formally hired, was to convince Bill Sarnoff, the head of Warner Publishing, to keep DC as a publishing concern, as opposed to simply managing their licensing of their properties. With that established, DC had attempted to compete with the now-surging Marvel by dramatically increasing its output and attempting to win the market by flooding it. This included launching series featuring such new characters as "Firestorm" and "Shade, the Changing Man", as well as an increasing array of non-superhero titles, in an attempt to recapture the pre-Wertham days of post-War comicdom.

In 1977, the company officially changed its name to DC Comics. It had used the brand "Superman-DC" since the 1950s, and was colloquially known as DC Comics for years.

In June 1978, five months before the release of the first Superman movie, Kahn expanded the line further, increasing the number of titles and story pages, and raising the price from 35 cents to 50 cents. Most series received eight-page back-up features while some had full-length twenty-five-page stories. This was a move the company called the "DC Explosion". The move was not successful, however, and corporate parent Warner dramatically cut back on these largely unsuccessful titles, firing many staffers in what industry watchers dubbed "the DC Implosion". In September 1978, the line was dramatically reduced and standard-size books returned to 17-page stories but for a still increased 40 cents. By 1980, the books returned to 50 cents with a 25-page story count but the story pages replaced house ads in the books.

Seeking new ways to boost market share, the new team of publisher Kahn, vice president Paul Levitz, and managing editor Giordano addressed the issue of talent instability. To that end—and following the example of Atlas/Seaboard Comics and such independent companies as Eclipse Comics—DC began to offer royalties in place of the industry-standard work-for-hire agreement in which creators worked for a flat fee and signed away all rights, giving talent a financial incentive tied to the success of their work. As it happened, the implementation of these incentives proved opportune considering Marvel Comics' Editor-in-Chief, Jim Shooter, was alienating much of his company's creative staff with his authoritarian manner and major talents there went to DC like Roy Thomas, Gene Colan, Marv Wolfman, and George Perez.

In addition, emulating the era's new television form, the miniseries while addressing the matter of an excessive number of ongoing titles fizzling out within a few issues of their start, DC created the industry concept of the comic book limited series. This publishing format allowed for the deliberate creation of finite storylines within a more flexible publishing format that could showcase creations without forcing the talent into unsustainable open-ended commitments. The first such title was "World of Krypton" in 1979, and its positive results led to subsequent similar titles and later more ambitious productions like "Camelot 3000" for the direct market in 1982.

These changes in policy shaped the future of the medium as a whole, and in the short term allowed DC to entice creators away from rival Marvel, and encourage stability on individual titles. In November 1980 DC launched the ongoing series "The New Teen Titans", by writer Marv Wolfman and artist George Pérez, two popular talents with a history of success. Their superhero-team comic, superficially similar to Marvel's ensemble series "X-Men", but rooted in DC history, earned significant sales in part due to the stability of the creative team, who both continued with the title for six full years. In addition, Wolfman and Pérez took advantage of the limited-series option to create a spin-off title, "Tales of the New Teen Titans", to present origin stories of their original characters without having to break the narrative flow of the main series or oblige them to double their work load with another ongoing title.

This successful revitalization of the Silver Age Teen Titans led DC's editors to seek the same for the wider DC Universe. The result, the Wolfman/Pérez 12-issue limited series "Crisis on Infinite Earths", gave the company an opportunity to realign and jettison some of the characters' complicated backstory and continuity discrepancies. A companion publication, two volumes entitled "The History of the DC Universe", set out the revised history of the major DC characters. "Crisis" featured many key deaths that shaped the DC Universe for the following decades, and it separated the timeline of DC publications into pre- and post-"Crisis".

Meanwhile, a parallel update had started in the non-superhero and horror titles. Since early 1984, the work of British writer Alan Moore had revitalized the horror series "The Saga of the Swamp Thing", and soon numerous British writers, including Neil Gaiman and Grant Morrison, began freelancing for the company. The resulting influx of sophisticated horror-fantasy material led to DC in 1993 establishing the Vertigo mature-readers imprint, which did not subscribe to the Comics Code Authority.

Two DC limited series, "" by Frank Miller and "Watchmen" by Moore and artist Dave Gibbons, drew attention in the mainstream press for their dark psychological complexity and promotion of the antihero. These titles helped pave the way for comics to be more widely accepted in literary-criticism circles and to make inroads into the book industry, with collected editions of these series as commercially successful trade paperbacks.

The mid-1980s also saw the end of many long-running DC war comics, including series that had been in print since the 1960s. These titles, all with over 100 issues, included "Sgt. Rock", "G.I. Combat", "The Unknown Soldier", and "Weird War Tales".

In March 1989, Warner Communications merged with Time Inc., making DC Comics a subsidiary of Time Warner. In June, the first Tim Burton-directed Batman movie was released, and DC began publishing its hardcover series of DC Archive Editions, collections of many of their early, key comics series, featuring rare and expensive stories unseen by many modern fans. Restoration for many of the Archive Editions was handled by Rick Keene with colour restoration by DC's long-time resident colourist, Bob LeRose. These collections attempted to retroactively credit many of the writers and artists who had worked without much recognition for DC during the early period of comics when individual credits were few and far between.

The comics industry experienced a brief boom in the early 1990s, thanks to a combination of speculative purchasing (mass purchase of the books as collectible items, with intent to resell at a higher value as the rising value of older issues, was thought to imply that "all" comics would rise dramatically in price) and several storylines which gained attention from the mainstream media. DC's extended storylines in which Superman was killed, and superhero "Green Lantern" turned into the supervillain Parallax resulted in dramatically increased sales, but the increases were as temporary as the hero's replacements. Sales dropped off as the industry went into a major slump, while manufactured "collectables" numbering in the millions replaced quality with quantity until fans and speculators alike deserted the medium in droves.

DC's Piranha Press and other imprints (including the mature readers line Vertigo, and Helix, a short-lived science fiction imprint) were introduced to facilitate compartmentalized diversification and allow for specialized marketing of individual product lines. They increased the use of non-traditional contractual arrangements, including the dramatic rise of creator-owned projects, leading to a significant increase in critically lauded work (much of it for Vertigo) and the licensing of material from other companies. DC also increased publication of book-store friendly formats, including trade paperback collections of individual serial comics, as well as original graphic novels.

One of the other imprints was Impact Comics from 1991 to 1992 in which the Archie Comics superheroes were licensed and revamped. The stories in the line were part of its own shared universe.

DC entered into a publishing agreement with Milestone Media that gave DC a line of comics featuring a culturally and racially diverse range of superhero characters. Although the Milestone line ceased publication after a few years, it yielded the popular animated series "Static Shock". DC established Paradox Press to publish material such as the large-format "Big Book of..." series of multi-artist interpretations on individual themes, and such crime fiction as the graphic novel "Road to Perdition". In 1998, DC purchased WildStorm Comics, Jim Lee's imprint under the Image Comics banner, continuing it for many years as a wholly separate imprint – and fictional universe – with its own style and audience. As part of this purchase, DC also began to publish titles under the fledgling WildStorm sub-imprint America's Best Comics (ABC), a series of titles created by Alan Moore, including "The League of Extraordinary Gentlemen", "Tom Strong", and "Promethea". Moore strongly contested this situation, and DC eventually stopped publishing ABC.

In March 2003 DC acquired publishing and merchandising rights to the long-running fantasy series "Elfquest", previously self-published by creators Wendy and Richard Pini under their WaRP Graphics publication banner. This series then followed another non-DC title, Tower Comics' series T.H.U.N.D.E.R. Agents, in collection into DC Archive Editions. In 2004 DC temporarily acquired the North American publishing rights to graphic novels from European publishers 2000 AD and Humanoids. It also rebranded its younger-audience titles with the mascot Johnny DC and established the CMX imprint to reprint translated manga. In 2006, CMX took over from Dark Horse Comics publication of the webcomic "Megatokyo" in print form. DC also took advantage of the demise of Kitchen Sink Press and acquired the rights to much of the work of Will Eisner, such as his "The Spirit" series and his graphic novels.

In 2004, DC began laying the groundwork for a full continuity-reshuffling sequel to "Crisis on Infinite Earths", promising substantial changes to the DC Universe (and side-stepping the 1994 "Zero Hour" event which similarly tried to ret-con the history of the DCU). In 2005, the critically lauded "Batman Begins" film was released; also, the company published several limited series establishing increasingly escalated conflicts among DC's heroes, with events climaxing in the "Infinite Crisis" limited series. Immediately after this event, DC's ongoing series jumped forward a full year in their in-story continuity, as DC launched a weekly series, "52", to gradually fill in the missing time. Concurrently, DC lost the copyright to "Superboy" (while retaining the trademark) when the heirs of Jerry Siegel used a provision of the 1976 revision to the copyright law to regain ownership.

In 2005, DC launched its "All-Star" line (evoking the title of the 1940s publication), designed to feature some of the company's best-known characters in stories that eschewed the long and convoluted continuity of the DC Universe. The line began with "All-Star Batman & Robin the Boy Wonder" and "All-Star Superman", with "All-Star Wonder Woman" and "All-Star Batgirl" announced in 2006 but neither being released nor scheduled as of the end of 2009.

DC licensed characters from the Archie Comics imprint Red Circle Comics by 2007. They appeared in the Red Circle line, based in the DC Universe, with a series of one-shots followed by a miniseries that lead into two ongoing titles, each lasting 10 issues.

In 2011, DC rebooted all of its running titles following the Flashpoint storyline. The reboot called The New 52 gave new origin stories and costume designs to many of DC's characters.

DC licensed pulp characters including Doc Savage and the Spirit which it then used, along with some DC heroes, as part of the First Wave comics line launched in 2010 and lasting through fall 2011.

In May 2011, DC announced it would begin releasing digital versions of their comics on the same day as paper versions.

On June 1, 2011, DC announced that it would end all ongoing series set in the DC Universe in August and relaunch its comic line with 52 issue #1s, starting with "Justice League" on August 31 (written by Geoff Johns and drawn by Jim Lee), with the rest to follow later on in September.

On June 4, 2013, DC unveiled two new digital comic innovations to enhance interactivity: "DC" and "DC Multiverse". "DC" layers dynamic artwork onto digital comic panels, adding a new level of dimension to digital storytelling, while "DC Multiverse" allows readers to determine a specific story outcome by selecting individual characters, storylines and plot developments while reading the comic, meaning one digital comic has multiple outcomes. "DC" appeared in the digital-first title, "Batman '66", based on the 1960s television series and "DC Multiverse" appeared in "", a digital-first title based on the .

In 2014, DC announced an eight-issue miniseries titled "Convergence" which began in April 2015.

In 2016, DC announced a line-wide relaunch titled DC Rebirth. The new line would launch with an 80-page one-shot titled DC Universe: Rebirth, written by Geoff Johns, with art from Gary Frank, Ethan Van Sciver, and more. After that, many new series would launch with a twice-monthly release schedule and new creative teams for nearly every title. The relaunch was meant to bring back the legacy and heart many felt had been missing from DC characters since the launch of the New 52. Rebirth brought huge success, both financially and critically.

On February 21, 2020, the Co-Publisher of DC Comics, Dan DiDio stepped down after 10 years at that position. The company did not give a reason for the move, nor did it indicate whether it was his decision or the company's. The leadership change was the latest event in the company restructuring which began the previous month, as several top executives were laid off from the company. However, Bleeding Cool reported that he was fired.

In June 2020, Warner Bros. announced a separate DC-themed online-only convention. Known as DC FanDome, the free "immersive virtual fan experience" was a 24-hour-long event held on August 22, 2020. The main presentation, entitled "DC FanDome: Hall of Heroes", was held as scheduled on August 22. The remaining programming was provided through a one-day video on demand experience, "DC FanDome: Explore the Multiverse", on September 12.

As Warner Bros. and DC's response to San Diego Comic-Con's cancellation due to the COVID-19 pandemic, the convention featured information about DC-based content including the DC Extended Universe film franchise, the Arrowverse television franchise, comic books, and video games. The convention also returned for the virtual premiere of "Wonder Woman 1984" and returned once again on October 16, 2021.

In August 2020, roughly one-third of DC's editorial ranks were laid off, including the editor-in-chief, senior story editor, executive editor, and several senior VPs.

In March 2021, DC relaunched their entire line once again under the banner of Infinite Frontier. After the events of the storyline, the DC Multiverse was expanded into a larger "Omniverse" where everything is canon, effectively reversing the changes The New 52 introduced a decade prior.

Furthermore, AT&T spun off WarnerMedia to Discovery, forming Warner Bros. Discovery. This merger was completed on April 8, 2022.

In January 2023, DC relaunched their line under the banner of Dawn of DC following the conclusion of Dark Crisis on Infinite Earths and Lazarus Planet. Later that year, Jim Lee was promoted to President of DC in May.





Diophantine equation

In mathematics, a Diophantine equation is an equation, typically a polynomial equation in two or more unknowns with integer coefficients, for which only integer solutions are of interest. A linear Diophantine equation equates to a constant the sum of two or more monomials, each of degree one. An exponential Diophantine equation is one in which unknowns can appear in exponents.

Diophantine problems have fewer equations than unknowns and involve finding integers that solve simultaneously all equations. As such systems of equations define algebraic curves, algebraic surfaces, or, more generally, algebraic sets, their study is a part of algebraic geometry that is called "Diophantine geometry".

The word "Diophantine" refers to the Hellenistic mathematician of the 3rd century, Diophantus of Alexandria, who made a study of such equations and was one of the first mathematicians to introduce symbolism into algebra. The mathematical study of Diophantine problems that Diophantus initiated is now called Diophantine analysis.

While individual equations present a kind of puzzle and have been considered throughout history, the formulation of general theories of Diophantine equations (beyond the case of linear and quadratic equations) was an achievement of the twentieth century.

In the following Diophantine equations, , and are the unknowns and the other letters are given constants:

The simplest linear Diophantine equation takes the form 
formula_1 
where , and are given integers. The solutions are described by the following theorem:

Proof: If is this greatest common divisor, Bézout's identity asserts the existence of integers and such that . If is a multiple of , then for some integer , and is a solution. On the other hand, for every pair of integers and , the greatest common divisor of and divides . Thus, if the equation has a solution, then must be a multiple of . If and , then for every solution , we have 
formula_2 
showing that is another solution. Finally, given two solutions such that 
formula_3 
one deduces that formula_4 
As and are coprime, Euclid's lemma shows that divides , and thus that there exists an integer such that both 
formula_5 
Therefore, 
formula_6
which completes the proof.

The Chinese remainder theorem describes an important class of linear Diophantine systems of equations: let formula_7 be pairwise coprime integers greater than one, formula_8 be arbitrary integers, and be the product formula_9 The Chinese remainder theorem asserts that the following linear Diophantine system has exactly one solution formula_10 such that , and that the other solutions are obtained by adding to a multiple of :
formula_11

More generally, every system of linear Diophantine equations may be solved by computing the Smith normal form of its matrix, in a way that is similar to the use of the reduced row echelon form to solve a system of linear equations over a field. Using matrix notation every system of linear Diophantine equations may be written
formula_12
where is an matrix of integers, is an column matrix of unknowns and is an column matrix of integers.

The computation of the Smith normal form of provides two unimodular matrices (that is matrices that are invertible over the integers and have ±1 as determinant) and of respective dimensions and , such that the matrix
formula_13
is such that is not zero for not greater than some integer , and all the other entries are zero. The system to be solved may thus be rewritten as
formula_14
Calling the entries of and those of , this leads to the system
formula_15

This system is equivalent to the given one in the following sense: A column matrix of integers is a solution of the given system if and only if for some column matrix of integers such that .

It follows that the system has a solution if and only if divides for and for . If this condition is fulfilled, the solutions of the given system are
formula_16
where are arbitrary integers.

Hermite normal form may also be used for solving systems of linear Diophantine equations. However, Hermite normal form does not directly provide the solutions; to get the solutions from the Hermite normal form, one has to successively solve several linear equations. Nevertheless, Richard Zippel wrote that the Smith normal form "is somewhat more than is actually needed to solve linear diophantine equations. Instead of reducing the equation to diagonal form, we only need to make it triangular, which is called the Hermite normal form. The Hermite normal form is substantially easier to compute than the Smith normal form."

Integer linear programming amounts to finding some integer solutions (optimal in some sense) of linear systems that include also inequations. Thus systems of linear Diophantine equations are basic in this context, and textbooks on integer programming usually have a treatment of systems of linear Diophantine equations.

A homogeneous Diophantine equation is a Diophantine equation that is defined by a homogeneous polynomial. A typical such equation is the equation of Fermat's Last Theorem

As a homogeneous polynomial in indeterminates defines a hypersurface in the projective space of dimension , solving a homogeneous Diophantine equation is the same as finding the rational points of a projective hypersurface.

Solving a homogeneous Diophantine equation is generally a very difficult problem, even in the simplest non-trivial case of three indeterminates (in the case of two indeterminates the problem is equivalent with testing if a rational number is the th power of another rational number). A witness of the difficulty of the problem is Fermat's Last Theorem (for , there is no integer solution of the above equation), which needed more than three centuries of mathematicians' efforts before being solved.

For degrees higher than three, most known results are theorems asserting that there are no solutions (for example Fermat's Last Theorem) or that the number of solutions is finite (for example Falting's theorem). 

For the degree three, there are general solving methods, which work on almost all equations that are encountered in practice, but no algorithm is known that works for every cubic equation.

Homogeneous Diophantine equations of degree two are easier to solve. The standard solving method proceeds in two steps. One has first to find one solution, or to prove that there is no solution. When a solution has been found, all solutions are then deduced.

For proving that there is no solution, one may reduce the equation modulo. For example, the Diophantine equation
does not have any other solution than the trivial solution . In fact, by dividing , and by their greatest common divisor, one may suppose that they are coprime. The squares modulo 4 are congruent to 0 and 1. Thus the left-hand side of the equation is congruent to 0, 1, or 2, and the right-hand side is congruent to 0 or 3. Thus the equality may be obtained only if , and are all even, and are thus not coprime. Thus the only solution is the trivial solution . This shows that there is no rational point on a circle of radius formula_19 centered at the origin.

More generally, the Hasse principle allows deciding whether a homogeneous Diophantine equation of degree two has an integer solution, and computing a solution if there exist. 

If a non-trivial integer solution is known, one may produce all other solutions in the following way.

Let 
be a homogeneous Diophantine equation, where formula_21 is a quadratic form (that is, a homogeneous polynomial of degree 2), with integer coefficients. The "trivial solution" is the solution where all formula_22 are zero. If formula_23 is a non-trivial integer solution of this equation, then formula_24 are the homogeneous coordinates of a rational point of the hypersurface defined by . Conversely, if formula_25 are homogeneous coordinates of a rational point of this hypersurface, where formula_26 are integers, then formula_27 is an integer solution of the Diophantine equation. Moreover, the integer solutions that define a given rational point are all sequences of the form 
where is any integer, and is the greatest common divisor of the formula_29

It follows that solving the Diophantine equation formula_20 is completely reduced to finding the rational points of the corresponding projective hypersurface.

Let now formula_31 be an integer solution of the equation formula_32 As is a polynomial of degree two, a line passing through crosses the hypersurface at a single other point, which is rational if and only if the line is rational (that is, if the line is defined by rational parameters). This allows parameterizing the hypersurface by the lines passing through , and the rational points are those that are obtained from rational lines, that is, those that correspond to rational values of the parameters.

More precisely, one may proceed as follows. 

By permuting the indices, one may suppose, without loss of generality that formula_33 Then one may pass to the affine case by considering the affine hypersurface defined by 
which has the rational point

If this rational point is a singular point, that is if all partial derivatives are zero at , all lines passing through are contained in the hypersurface, and one has a cone. The change of variables 
does not change the rational points, and transforms into a homogeneous polynomial in variables. In this case, the problem may thus be solved by applying the method to an equation with fewer variables.

If the polynomial is a product of linear polynomials (possibly with non-rational coefficients), then it defines two hyperplanes. The intersection of these hyperplanes is a rational flat, and contains rational singular points. This case is thus a special instance of the preceding case.

In the general case, consider the parametric equation of a line passing through :
Substituting this in , one gets a polynomial of degree two in , that is zero for . It is thus divisible by . The quotient is linear in , and may be solved for expressing as a quotient of two polynomials of degree at most two in formula_38 with integer coefficients:
Substituting this in the expressions for formula_40 one gets, for ,
where formula_42 are polynomials of degree at most two with integer coefficients.

Then, one can return to the homogeneous case. Let, for , 
be the homogenization of formula_44 These quadratic polynomials with integer coefficients form a parameterization of the projective hypersurface defined by :

A point of the projective hypersurface defined by is rational if and only if it may be obtained from rational values of formula_46 As formula_47 are homogeneous polynomials, the point is not changed if all are multiplied by the same rational number. Thus, one may suppose that formula_48 are coprime integers. It follows that the integer solutions of the Diophantine equation are exactly the sequences formula_49 where, for ,
where is an integer, formula_48 are coprime integers, and is the greatest common divisor of the integers formula_52

One could hope that the coprimality of the , could imply that . Unfortunately this is not the case, as shown in the next section.

The equation 
is probably the first homogeneous Diophantine equation of degree two that has been studied. Its solutions are the Pythagorean triples. This is also the homogeneous equation of the unit circle. In this section, we show how the above method allows retrieving Euclid's formula for generating Pythagorean triples.

For retrieving exactly Euclid's formula, we start from the solution , corresponding to the point of the unit circle. A line passing through this point may be parameterized by its slope:
Putting this in the circle equation 
one gets 
Dividing by , results in
which is easy to solve in :
It follows
Homogenizing as described above one gets all solutions as 
where is any integer, and are coprime integers, and is the greatest common divisor of the three numerators. In fact, if and are both odd, and if one is odd and the other is even.

The "primitive triples" are the solutions where and .

This description of the solutions differs slightly from Euclid's formula because Euclid's formula considers only the solutions such that , and are all positive, and does not distinguish between two triples that differ by the exchange of and ,

The questions asked in Diophantine analysis include:


These traditional problems often lay unsolved for centuries, and mathematicians gradually came to understand their depth (in some cases), rather than treat them as puzzles.

The given information is that a father's age is 1 less than twice that of his son, and that the digits making up the father's age are reversed in the son's age (i.e. ). This leads to the equation , thus . Inspection gives the result , , and thus equals 73 years and equals 37 years. One may easily show that there is not any other solution with and positive integers less than 10.

Many well known puzzles in the field of recreational mathematics lead to diophantine equations. Examples include the cannonball problem, Archimedes's cattle problem and the monkey and the coconuts.

In 1637, Pierre de Fermat scribbled on the margin of his copy of "Arithmetica": "It is impossible to separate a cube into two cubes, or a fourth power into two fourth powers, or in general, any power higher than the second into two like powers." Stated in more modern language, "The equation has no solutions for any higher than 2." Following this, he wrote: "I have discovered a truly marvelous proof of this proposition, which this margin is too narrow to contain." Such a proof eluded mathematicians for centuries, however, and as such his statement became famous as Fermat's Last Theorem. It was not until 1995 that it was proven by the British mathematician Andrew Wiles.

In 1657, Fermat attempted to solve the Diophantine equation (solved by Brahmagupta over 1000 years earlier). The equation was eventually solved by Euler in the early 18th century, who also solved a number of other Diophantine equations. The smallest solution of this equation in positive integers is , (see Chakravala method).

In 1900, David Hilbert proposed the solvability of all Diophantine equations as the tenth of his fundamental problems. In 1970, Yuri Matiyasevich solved it negatively, building on work of Julia Robinson, Martin Davis, and Hilary Putnam to prove that a general algorithm for solving all Diophantine equations cannot exist.

Diophantine geometry, is the application of techniques from algebraic geometry which considers equations that also have a geometric meaning. The central idea of Diophantine geometry is that of a rational point, namely a solution to a polynomial equation or a system of polynomial equations, which is a vector in a prescribed field , when is "not" algebraically closed.

The oldest general method for solving a Diophantine equationor for proving that there is no solution is the method of infinite descent, which was introduced by Pierre de Fermat. Another general method is the Hasse principle that uses modular arithmetic modulo all prime numbers for finding the solutions. Despite many improvements these methods cannot solve most Diophantine equations.

The difficulty of solving Diophantine equations is illustrated by Hilbert's tenth problem, which was set in 1900 by David Hilbert; it was to find an algorithm to determine whether a given polynomial Diophantine equation with integer coefficients has an integer solution. Matiyasevich's theorem implies that such an algorithm cannot exist.

During the 20th century, a new approach has been deeply explored, consisting of using algebraic geometry. In fact, a Diophantine equation can be viewed as the equation of an hypersurface, and the solutions of the equation are the points of the hypersurface that have integer coordinates.

This approach led eventually to the proof by Andrew Wiles in 1994 of Fermat's Last Theorem, stated without proof around 1637. This is another illustration of the difficulty of solving Diophantine equations.

An example of an infinite diophantine equation is:
formula_61
which can be expressed as "How many ways can a given integer be written as the sum of a square plus twice a square plus thrice a square and so on?" The number of ways this can be done for each forms an integer sequence. Infinite Diophantine equations are related to theta functions and infinite dimensional lattices. This equation always has a solution for any positive . Compare this to:
formula_62
which does not always have a solution for positive .

If a Diophantine equation has as an additional variable or variables occurring as exponents, it is an exponential Diophantine equation. Examples include the Ramanujan–Nagell equation, , and the equation of the Fermat–Catalan conjecture and Beal's conjecture, with inequality restrictions on the exponents. A general theory for such equations is not available; particular cases such as Catalan's conjecture have been tackled. However, the majority are solved via ad hoc methods such as Størmer's theorem or even trial and error.





Diophantus

Diophantus of Alexandria (born ; died ) was a Greek mathematician, who was the author of two main works: "On Polygonal Numbers", which survives incomplete, and the "Arithmetica" in thirteen books, most of it extant, made up of arithmetical problems that are solved through algebraic equations.

Diophantus was the first Greek mathematician who recognized positive rational numbers as numbers, by allowing fractions for coefficients and solutions. He coined the term παρισότης (parisotes) to refer to an approximate equality. This term was rendered as "adaequalitas" in Latin, and became the technique of adequality developed by Pierre de Fermat to find maxima for functions and tangent lines to curves. 

Although not the earliest, the "Arithmetica" has the most well-known use of algebraic notation to solve arithmetical problems coming from Greek antiquity, and some of its problems served as inspiration for later mathematicians working in analysis and number theory. In modern use, Diophantine equations are algebraic equations with integer coefficients for which integer solutions are sought. Diophantine geometry and Diophantine approximations are other two subareas of number theory that are named after him. 

Diophantus was born into a Greek family and is known to have lived in Alexandria, Egypt, during the Roman era, between AD 200 and 214 to 284 or 298. Much of our knowledge of the life of Diophantus is derived from a 5th-century Greek anthology of number games and puzzles created by Metrodorus. One of the problems (sometimes called his epitaph) states:Here lies Diophantus,' the wonder behold. Through art algebraic, the stone tells how old: 'God gave him his boyhood one-sixth of his life, One twelfth more as youth while whiskers grew rife; And then yet one-seventh ere marriage begun; In five years there came a bouncing new son. Alas, the dear child of master and sage After attaining half the measure of his father's life chill fate took him. After consoling his fate by the science of numbers for four years, he ended his life.'This puzzle implies that Diophantus' age can be expressed as

which gives a value of 84 years. However, the accuracy of the information cannot be confirmed.

In popular culture, this puzzle was the Puzzle No.142 in "Professor Layton and Pandora's Box" as one of the hardest solving puzzles in the game, which needed to be unlocked by solving other puzzles first.

"Arithmetica" is the major work of Diophantus and the most prominent work on premodern algebra in Greek mathematics. It is a collection of problems giving numerical solutions of both determinate and indeterminate equations. Of the original thirteen books of which "Arithmetica" consisted only six have survived, though there are some who believe that four Arabic books discovered in 1968 are also by Diophantus. Some Diophantine problems from "Arithmetica" have been found in Arabic sources.

It should be mentioned here that Diophantus never used general methods in his solutions. Hermann Hankel, renowned German mathematician made the following remark regarding Diophantus:Our author (Diophantos) not the slightest trace of a general, comprehensive method is discernible; each problem calls for some special method which refuses to work even for the most closely related problems. For this reason it is difficult for the modern scholar to solve the 101st problem even after having studied 100 of Diophantos's solutions.

Like many other Greek mathematical treatises, Diophantus was forgotten in Western Europe during the Dark Ages, since the study of ancient Greek, and literacy in general, had greatly declined. The portion of the Greek "Arithmetica" that survived, however, was, like all ancient Greek texts transmitted to the early modern world, copied by, and thus known to, medieval Byzantine scholars. Scholia on Diophantus by the Byzantine Greek scholar John Chortasmenos (1370–1437) are preserved together with a comprehensive commentary written by the earlier Greek scholar Maximos Planudes (1260 – 1305), who produced an edition of Diophantus within the library of the Chora Monastery in Byzantine Constantinople. In addition, some portion of the "Arithmetica" probably survived in the Arab tradition (see above). In 1463 German mathematician Regiomontanus wrote:No one has yet translated from the Greek into Latin the thirteen books of Diophantus, in which the very flower of the whole of arithmetic lies hidden."Arithmetica" was first translated from Greek into Latin by Bombelli in 1570, but the translation was never published. However, Bombelli borrowed many of the problems for his own book "Algebra". The "editio princeps" of "Arithmetica" was published in 1575 by Xylander. The Latin translation of "Arithmetica" by Bachet in 1621 became the first Latin edition that was widely available. Pierre de Fermat owned a copy, studied it and made notes in the margins. A later 1895 Latin translation by Paul Tannery was said to be an improvement by Thomas L. Heath, who used it in the 1910 second edition of his English translation.

The 1621 edition of "Arithmetica" by Bachet gained fame after Pierre de Fermat wrote his famous "Last Theorem" in the margins of his copy: If an integer is greater than 2, then has no solutions in non-zero integers , , and . I have a truly marvelous proof of this proposition which this margin is too narrow to contain.Fermat's proof was never found, and the problem of finding a proof for the theorem went unsolved for centuries. A proof was finally found in 1994 by Andrew Wiles after working on it for seven years. It is believed that Fermat did not actually have the proof he claimed to have. Although the original copy in which Fermat wrote this is lost today, Fermat's son edited the next edition of Diophantus, published in 1670. Even though the text is otherwise inferior to the 1621 edition, Fermat's annotations—including the "Last Theorem"—were printed in this version.

Fermat was not the first mathematician so moved to write in his own marginal notes to Diophantus; the Byzantine scholar John Chortasmenos (1370–1437) had written "Thy soul, Diophantus, be with Satan because of the difficulty of your other theorems and particularly of the present theorem" next to the same problem.

Diophantus wrote several other books besides "Arithmetica", but only a few of them have survived.

Diophantus himself refers to a work which consists of a collection of lemmas called "The Porisms" (or "Porismata"), but this book is entirely lost.

Although "The Porisms" is lost, we know three lemmas contained there, since Diophantus refers to them in the "Arithmetica". One lemma states that the difference of the cubes of two rational numbers is equal to the sum of the cubes of two other rational numbers, i.e. given any and , with , there exist , all positive and rational, such that

Diophantus is also known to have written on polygonal numbers, a topic of great interest to Pythagoras and Pythagoreans. Fragments of a book dealing with polygonal numbers are extant.

A book called "Preliminaries to the Geometric Elements" has been traditionally attributed to Hero of Alexandria. It has been studied recently by Wilbur Knorr, who suggested that the attribution to Hero is incorrect, and that the true author is Diophantus.

Diophantus' work has had a large influence in history. Editions of "Arithmetica" exerted a profound influence on the development of algebra in Europe in the late sixteenth and through the 17th and 18th centuries. Diophantus and his works also influenced Arab mathematics and were of great fame among Arab mathematicians. Diophantus' work created a foundation for work on algebra and in fact much of advanced mathematics is based on algebra. How much he affected India is a matter of debate.

Diophantus has been considered "the father of algebra" because of his contributions to number theory, mathematical notations and the earliest known use of syncopated notation in his book series "Arithmetica". However this is usually debated, because Al-Khwarizmi was also given the title as "the father of algebra", nevertheless both mathematicians were responsible for paving the way for algebra today.

Today, Diophantine analysis is the area of study where integer (whole-number) solutions are sought for equations, and Diophantine equations are polynomial equations with integer coefficients to which only integer solutions are sought. It is usually rather difficult to tell whether a given Diophantine equation is solvable. Most of the problems in "Arithmetica" lead to quadratic equations. Diophantus looked at 3 different types of quadratic equations: , , and . The reason why there were three cases to Diophantus, while today we have only one case, is that he did not have any notion for zero and he avoided negative coefficients by considering the given numbers , , to all be positive in each of the three cases above. Diophantus was always satisfied with a rational solution and did not require a whole number which means he accepted fractions as solutions to his problems. Diophantus considered negative or irrational square root solutions "useless", "meaningless", and even "absurd". To give one specific example, he calls the equation 'absurd' because it would lead to a negative value for . One solution was all he looked for in a quadratic equation. There is no evidence that suggests Diophantus even realized that there could be two solutions to a quadratic equation. He also considered simultaneous quadratic equations.

Diophantus made important advances in mathematical notation, becoming the first person known to use algebraic notation and symbolism. Before him everyone wrote out equations completely. Diophantus introduced an algebraic symbolism that used an abridged notation for frequently occurring operations, and an abbreviation for the unknown and for the powers of the unknown. Mathematical historian Kurt Vogel states:The symbolism that Diophantus introduced for the first time, and undoubtedly devised himself, provided a short and readily comprehensible means of expressing an equation... Since an abbreviation is also employed for the word 'equals', Diophantus took a fundamental step from verbal algebra towards symbolic algebra.Although Diophantus made important advances in symbolism, he still lacked the necessary notation to express more general methods. This caused his work to be more concerned with particular problems rather than general situations. Some of the limitations of Diophantus' notation are that he only had notation for one unknown and, when problems involved more than a single unknown, Diophantus was reduced to expressing "first unknown", "second unknown", etc. in words. He also lacked a symbol for a general number . Where we would write , Diophantus has to resort to constructions like: "... a sixfold number increased by twelve, which is divided by the difference by which the square of the number exceeds three". Algebra still had a long way to go before very general problems could be written down and solved succinctly.





Dong

Dong or DONG may refer to:






Duke Kahanamoku

Duke Paoa Kahinu Mokoe Hulikohola Kahanamoku (August 24, 1890 – January 22, 1968) was a Hawaiian competition swimmer who popularized the sport of surfing. A Native Hawaiian, he was born to a minor noble family less than three years before the overthrow of the Hawaiian Kingdom. He lived to see the territory's admission as a state, and became a United States citizen. He was a five-time Olympic medalist in swimming, winning medals in 1912, 1920 and 1924.

Kahanamoku joined fraternal organizations: he was a Scottish Rite Freemason in the Honolulu lodge, and a Shriner. He worked as a law enforcement officer, an actor, a beach volleyball player, and a businessman.

According to Kahanamoku, he was born in Honolulu at Haleʻākala, the home of Bernice Pauahi Bishop, which was later converted into the Arlington Hotel. 

He was born into a family of Native Hawaiians headed by Duke Halapu Kahanamoku and Julia Paʻakonia Lonokahikina Paoa. He had five brothers, and three sisters. His brothers were Sargent, Samuel, David, William and Louis, all of whom participated in competitive aquatic sports. His sisters were Bernice, Kapiolani and Maria.

"Duke" was not a title or a nickname, but a given name. He was named after his father, Duke Halapu Kahanamoku, who was christened by Bernice Pauahi Bishop in honor of Prince Alfred, Duke of Edinburgh, who was visiting Hawaii at the time. His father was a policeman. His mother Julia Paakonia Lonokahikina Paoa was a deeply religious woman with a strong sense of family ancestry.

His parents were from prominent Hawaiian "ohana" (families). The Kahanamoku and the Paoa ohana were considered to be lower-ranking nobles, who were in service to the "aliʻi nui", or royalty. His paternal grandfather was Kahanamoku and his grandmother, Kapiolani Kaoeha (sometimes spelled "Kahoea"), a descendant of Alapainui. They were "kahu", retainers and trusted advisors of the Kamehamehas, to whom they were related. His maternal grandparents Paoa, son of Paoa Hoolae and Hiikaalani, and Mele Uliama, were also of aliʻi descent.

In 1893, his family moved to Kālia, Waikiki (near the present site of Hilton Hawaiian Village), to be closer to his mother's parents and family. Kahanamoku grew up with his siblings and 31 Paoa cousins. He attended the Waikiki Grammar School, Kaahumanu School, and the Kamehameha Schools, although he never graduated because he had to quit to help support the family.

Growing up on the outskirts of Waikiki, Kahanamoku spent much of his youth at the beach, where he developed his surfing and swimming skills. In his youth, Kahanamoku preferred a traditional surf board, which he called his ""papa nui"", constructed after the fashion of ancient Hawaiian olo boards. Made from the wood of a koa tree, it was long and weighed . The board was without a skeg, which had yet to be invented. In his later surfing career, he would often use smaller boards but always preferred those made of wood.

Kahanamoku was also a powerful swimmer. On August 11, 1911, Kahanamoku was timed at 55.4 seconds in the freestyle, beating the existing world record by 4.6 seconds, in the salt water of Honolulu Harbor. He also broke the record in the and equaled it in the . But the Amateur Athletic Union (AAU), in disbelief, would not recognize these feats until many years later. The AAU initially claimed that the judges must have been using alarm clocks rather than stopwatches and later claimed that ocean currents aided Kahanamoku.

Kahanamoku easily qualified for the U.S. Olympic swimming team in 1912. At the 1912 Summer Olympics in Stockholm, he won a gold medal in the 100-meter freestyle, and a silver medal with the second-place U.S. team in the men's 4×200-meter freestyle relay.

During the 1920 Olympics in Antwerp, Kahanamoku won gold medals in both the 100 meters (bettering fellow Hawaiian Pua Kealoha) and in the relay. He finished the 100 meters with a silver medal during the 1924 Olympics in Paris, with the gold going to Johnny Weissmuller and the bronze to Kahanamoku's brother, Samuel. By then age 34, Kahanamoku won no more Olympic medals. But he served as an alternate for the U.S. water polo team at the 1932 Summer Olympics.

Between Olympic competitions, and after retiring from the Olympics, Kahanamoku traveled internationally to give swimming exhibitions. It was during this period that he popularized the sport of surfing, previously known only in Hawaii, by incorporating surfing exhibitions into his touring exhibitions as well. He attracted people to surfing in mainland America first in 1912 while in Southern California. He trained and loaned equipment to new surfers, such as Dorothy Becker.

His surfing exhibition at Sydney, Australia's Freshwater Beach on December 24, 1914, is widely regarded as a seminal event in the development of surfing in Australia. The board that Kahanamoku built from a piece of pine from a local hardware store is retained by the Freshwater Surf Life Saving Club. A statue of Kahanamoku was erected in his honor on the Northern headland of Freshwater Lake, New South Wales.

During his time living in Southern California, Kahanamoku performed in Hollywood as a background actor and a character actor in several films. He made connections in this way with people who could further publicize the sport of surfing. Kahanamoku was involved with the Los Angeles Athletic Club, acting as a lifeguard and competing in both swimming and water polo teams.

While living in Newport Beach, California, on June 14, 1925, Kahanamoku rescued eight men from a fishing vessel that capsized in heavy surf while it was attempting to enter the city's harbor. Using his surfboard, Kahanamoku made repeated trips from shore to the capsized ship, and helped rescue several people. Two other surfers saved four more fishermen, while five succumbed to the seas before they could be rescued. At the time the Newport Beach police chief called Kahanamoku's efforts "The most superhuman surfboard rescue act the world has ever seen." It also led to lifeguards across the US to begin using surfboards as standard equipment for water rescues.

He was the first person to be inducted into both the Swimming Hall of Fame and the Surfing Hall of Fame. The Duke Kahanamoku Invitational Surfing Championships in Hawaii, the first major professional surfing contest event ever held in the huge surf on the North Shore of Oahu, was named in his honor. He is a member of the U.S. Olympic Hall of Fame.

Later Kahanamoku was elected to serve as the Sheriff of Honolulu, Hawaii from 1932 to 1961, completing 13 consecutive terms. During World War II, he also served as a military police officer for the United States; Hawai'i was not yet a state and was administered.

In the postwar period, he also appeared in a number of television programs and films, such as "Mister Roberts" (1955). He was well-liked throughout the Hollywood community.

Kahanamoku became a friend and surfing companion of heiress Doris Duke. She built a home (now a museum) on Oahu named Shangri-la. Kahanamoku gave private surfing lessons to Franklin D. Roosevelt Jr. and John Aspinwall Roosevelt, the children of Franklin D. Roosevelt.

In 1946, Kahanamoku was the "pro forma" defendant in the landmark Supreme Court case "Duncan v. Kahanamoku". While Kahanamoku was a military police officer during World War II, he arrested Duncan, a civilian shipfitter, for public intoxication.

At the time, Hawaii, not yet a state, was being administered by the United States under the Hawaiian Organic Act. This effectively instituted martial law on the island. After Duncan was tried by a military tribunal, he appealed to the Supreme Court. In a "post hoc" ruling, the court ruled that trial by military tribunal for the civilian was, in this case, unconstitutional.

On August 2, 1940, Kahanamoku married dance instructor Nadine Alexander, who had relocated to Hawaii from Cleveland, Ohio, after she had been hired to teach at the Royal Hawaiian Hotel. Duke was 50 years old, Nadine was 35.

He was initiated, passed and raised to the degree of Master Mason in Hawaiian Lodge Masonic Lodge No 21

Kahanamoku died of a heart attack on January 22, 1968, at age 77. For his burial at sea, a long motorcade of mourners, accompanied by a 30-man police escort, traveled in procession across town to Waikiki Beach. Reverend Abraham Akaka, the pastor of Kawaiahao Church, performed the service. A group of beach boys sang Hawaiian songs, including "Aloha Oe", and Kahanamoku's ashes were scattered into the ocean.

In 1994 a statue of Kahanamoku by Barry Donohoo was inaugurated in Freshwater, NSW, Australia. It is the showpiece of the Australian Surfers Walk of Fame.

On February 28, 2015, a monument featuring a replica of Kahanamoku's surfboard was unveiled at New Brighton beach, Christchurch, New Zealand in honor of the 100th anniversary of Kahanamoku's visit to New Brighton.

A statue of Kahanamoku was installed in Huntington Beach, California. A nearby restaurant is named for him and is close to Huntington Beach pier. The City of Huntington Beach identifies with the legacy of surfing, and a museum dedicated to that sport is located here.

In April 2022 NSW Heritage announced that Kahanamoku would be included in the first batch of Blue Plaques to be issued, to recognize his contribution to recreation and surfing.

A sculpture of Kahanamoku flanked by a male knee paddler and a female prone paddler commemorating the Catalina Classic Paddleboard Race was installed on the Manhattan Beach Pier in 2023.

Hawaii music promoter Kimo Wilder McVay capitalized on Kahanamoku's popularity by naming his Waikiki showroom "Duke Kahanamoku's" at the International Market Place and giving Kahanamoku a financial interest in the showroom in exchange for the use of his name. It was a major Waikiki showroom in the 1960s and is remembered as the home of Don Ho & The Aliis from 1964 through 1969. The showroom continued to be known as Duke Kahanamoku's until Hawaii showman Jack Cione bought it in the mid-1970s and renamed it Le Boom Boom.

The Duke Kahanamoku Aquatic Complex (DKAC) serves as the home for the University of Hawai‘i’s swimming and diving and women’s water polo teams. The facility, located on the University’s lower campus, includes a 50-meter training pool and a separate 25-yard competition and diving pool. The long course pool is four feet at both ends, seven feet in the middle, and an average depth of six feet.

Kahanamoku's name is also used by Duke's Canoe Club & Barefoot Bar, known as Duke's Waikiki, a beachfront bar and restaurant in the Outrigger Waikiki on the Beach Hotel. There is a chain of restaurants named after him in California, Florida and Hawaii called Duke's.

On August 24, 2002, the 112th anniversary of Kahanamoku's birth, the U.S. Postal Service issued a first-class commemorative stamp with Duke's picture on it. The First Day Ceremony was held at the Hilton Hawaiian Village in Waikiki and was attended by thousands. At this ceremony, attendees could attach the Duke stamp to an envelope and get it canceled with a First Day of Issue postmark. These first day covers are very collectible.

On August 24, 2015, a Google Doodle honored the 125th anniversary of Duke Kahanamoku's birthday.

In 2021, a 88-minute feature film was made about Kahanamoku's life.




Distinguished Service Medal (U.S. Army)

The Distinguished Service Medal (DSM) is a military decoration of the United States Army that is presented to soldiers who have distinguished themselves by exceptionally meritorious service to the government in a duty of great responsibility. The performance must be such as to merit recognition for service that is clearly exceptional. The exceptional performance of normal duty will not alone justify an award of this decoration.

The Army's Distinguished Service Medal is equivalent to the Naval Service's Navy Distinguished Service Medal, Air and Space Forces' Distinguished Service Medal, and the Coast Guard Distinguished Service Medal. Prior to the creation of the Air Force's Distinguished Service Medal in 1960, United States Air Force airmen were awarded the Army's Distinguished Service Medal.




The Distinguished Service Medal is awarded to any person who, while serving in any capacity with the United States Army, has distinguished themselves by exceptionally meritorious service to the Government in a duty of great responsibility.

The performance must be such as to merit recognition for service which is clearly exceptional. Exceptional performance of normal duty will not alone justify an award of this decoration. For service not related to actual war, the term "duty of a great responsibility" applies to a narrower range of positions than in time of war and requires evidence of a conspicuously significant achievement. However, justification of the award may accrue by virtue of exceptionally meritorious service in a succession of high positions of great importance. Awards may be made to persons other than members of the Armed Forces of the United States for wartime services only, and only then under exceptional circumstances with the express approval of the president in each case.


The Distinguished Service Medal was authorized by Presidential Order dated January 2, 1918, and confirmed by Congress on July 9, 1918. It was announced by War Department General Order No. 6, 1918-01-12, with the following information concerning the medal: "A bronze medal of appropriate design and a ribbon to be worn in lieu thereof, to be awarded by the President to any person who, while serving in any capacity with the Army shall hereafter distinguish himself or herself, or who, since 04-06-1917, has distinguished himself or herself by exceptionally meritorious service to the Government in a duty of great responsibility in time of war or in connection with military operations against an armed enemy of the United States." The Act of Congress on July 9, 1918, recognized the need for different types and degrees of heroism and meritorious service and included such provisions for award criteria. The current statutory authorization for the Distinguished Service Medal is Title 10, United States Code, Section 3743.


More than 2,000 awards were made during World War I, and by the time the United States entered World War II, approximately 2,800 awards had been made. From July 1, 1941, to June 6, 1969, when the Department of the Army stopped publishing awards of the DSM in Department of the Army General Orders, over 2,800 further awards were made.

Prior to World War II the DSM was the only decoration for non-combat service in the U.S. Army. As a result, before World War II the DSM was awarded to a wider range of recipients than during and after World War II. During World War I awards of the DSM to officers below the rank of brigadier general were fairly common but became rare once the Legion of Merit was established in 1942.

Until the first award of the Air Force Distinguished Service Medal in 1965, United States Air Force personnel received this award as well, as was the case with several other Department of the Army decorations until the Department of the Air Force fully established its own system of decorations.

Because the Army Distinguished Service Medal is principally awarded to general officers, a list of notable recipients would include nearly every general, and some admirals, since 1918, many of whom received multiple awards, as well as a few civilians and sergeants major prominent for their contributions to national defense.

General Martin Dempsey, former chairman of the Joint Chiefs of Staff, holds the record for receiving the greatest number of awards of the Army Distinguished Service Medal, at six. He also received three awards of the Defense Distinguished Service Medal as well as one award each of the Navy Distinguished Service Medal, the Air Force Distinguished Service Medal, and the Coast Guard Distinguished Service Medal, for a total of twelve Distinguished Service Medals.

Generals of the Army Douglas MacArthur and Dwight Eisenhower are tied with five awards each received of the Army Distinguished Service Medal. They also each received one award of the Navy Distinguished Service Medal, for a total of six DSMs each.

General Lucius D. Clay (Four Star) received three Army DSM awards for his service that included Commanding General, U.S. Army Forces (European Theater) and Military Governor of Germany. During his tenure, Gen. Clay solved his greatest challenge: the Soviet Blockade of Berlin, which was imposed in June 1948. Gen. Clay triggered the Berlin Airlift, which served the city residents during the harsh winter of 1948–1949. He is also a recipient of the Legion of Merit.

General Norman Schwarzkopf received two awards of the Army DSM and one award each of the Defense DSM, Navy DSM, the Air Force DSM and the Coast Guard DSM, for a total of six DSMs.

General Lloyd Austin received four awards of the Army DSM and five awards of the Defense DSM for a total of nine DSMs.

Among notable recipients below flag rank are: X-1 test pilot Chuck Yeager and X-15 test pilot Robert M. White, who both received the DSM as U.S. Air Force majors; Air Force Major Rudolf Anderson, the U-2 pilot shot down during the Cuban Missile Crisis; director Frank Capra, decorated in 1945 as an army colonel; actor James Stewart, decorated in 1945 as an Army Air Forces colonel (later Air Force Brigadier General); Colonel Wendell Fertig, who led Filipino guerrillas behind Japanese lines; Colonel (later Major General) John K. Singlaub, who led partisan forces in the Korean War; and Major Maude C. Davison, who led the "Angels of Bataan and Corregidor" during their imprisonment by the Japanese, and Colonel William S. Taylor, Program Manager Multiple Launch Rocket System. Among notable civilian recipients are Harry L. Hopkins, Robert S. McNamara and Henry L. Stimson.

Notable American and foreign recipients include:



Note – includes Army Air Service, Army Air Corps and Army Air Forces





Major General Franklin L McKean - https://ocsalumni.org/at_biz_dir/franklin-l-mckean/


Defense Distinguished Service Medal

The Defense Distinguished Service Medal is a military decoration of the United States Department of Defense, which is presented to United States Armed Forces service members for exceptionally distinguished performance of duty contributing to the national security or defense of the United States. The medal was created on July 9, 1970, by President Richard Nixon in . President Nixon awarded the first medal, on the day the Executive Order was signed, to General Earle Wheeler, who was retiring from the US Army after serving as Chief of Staff of the United States Army and then Chairman of the Joint Chiefs of Staff.

It is equivalent to the United States Department of Homeland Security's Homeland Security Distinguished Service Medal.

The Defense Distinguished Service Medal is the United States Department of Defense's highest non-combat related military award and it is the highest joint service decoration. The Defense Distinguished Service Medal is awarded only while assigned to a joint activity. Normally, such responsibilities deserving of the Defense Distinguished Service Medal are held by the most senior officers such as the Chairman and Vice Chairman of the Joint Chiefs of Staff, the chiefs and vice chiefs of the military services, and commanders and deputy commanders of the Combatant Commands, the Director of the Joint Staff, and others whose duties bring them frequently into direct contact with the Secretary of Defense, the Deputy Secretary of Defense, and other senior government officials. In addition, the medal may also be awarded to other service members whose direct and individual contributions to national security or national defense are recognized as being so exceptional in scope and value as to be equivalent to contributions normally associated with positions encompassing broader responsibilities.

This decoration takes precedence over the Distinguished Service Medals of the services and is not to be awarded to any individual for a period of service for which an Army, Navy, Air Force or Coast Guard Distinguished Service Medal is awarded.

The medal is gold in color and on the obverse it features a medium blue enameled pentagon (point up). Superimposed on this is an American bald eagle with wings outspread facing left grasping three crossed arrows in its talons and on its breast is a shield of the United States. The pentagon and eagle are enclosed within a gold pieced circle consisting, in the upper half of 13 five-pointed stars and in the lower half, a wreath of laurel on the left and olive on the right. At the top is a suspender of five graduated gold rays. The reverse of the medal has the inscription ""For Distinguished Service"" at the top in raised letters, and within the pentagon the inscription "FROM THE SECRETARY OF DEFENSE TO", all in raised letters.

Additional awards of the Defense Distinguished Service Medal are denoted by oak leaf clusters.

- John Zirkelbach (two awards)

Dacoity

Dacoity is a term used for "banditry" in the Indian subcontinent. The spelling is the anglicised version of the Hindi word डाकू (daaku); "dacoit" is a colloquial Indian English word with this meaning and it appears in the "Glossary of Colloquial Anglo-Indian Words and Phrases" (1903). Banditry is criminal activity involving robbery by groups of armed bandits. The East India Company established the Thuggee and Dacoity Department in 1830, and the Thuggee and Dacoity Suppression Acts, 1836–1848 were enacted in British India under East India Company rule. Areas with ravines or forests, such as Chambal and Chilapata Forests, were once known for dacoits.

The word "dacoity", the anglicized version of the Hindi word "ḍakaitī" (historically spelled "dakaitee"). Hindi डकैती comes from "ḍākū" (historically spelled "dakoo", Hindi: डाकू, meaning "armed robber").

The term dacoit (Hindi: डकैत "ḍakait") means "a bandit" according to the "OED" ("A member of a class of robbers in India and Burma, who plunder in armed bands").

The dacoity have had a large impact in the Bhind and Morena of Chambal regions in Madhya Pradesh, Rajasthan, Haryana and Uttar Pradesh in north-central India. The exact reasons for the emergence of dacoity in the Chambal valley have been disputed. Most explanations have simply suggested feudal exploitation as the cause that provoked many people of this region to take to arms. The area was also underdeveloped and poor, so that banditry posed great economic incentives. However, the fact that many gangs operating in this valley were composed of higher castes and wealthy people appears to suggest that feudalism may only be a partial explanation of dacoity in Chambal valley (Bhaduri, 1972; Khan, 1981; Jatar, 1980; Katare, 1972). Furthermore, traditional honour codes and blood feuds would drive some into criminality.

In Chambal, India, organized crime controlled much of the countryside from the time of the British Raj up to the early 2000s, with the police offering high rewards for the most notorious bandit chiefs. The criminals regularly targeted local businesses, though they preferred to kidnap wealthy people, and demand ransom from their relatives - cutting off fingers, noses, and ears to pressure them into paying high sums. Many dacoity also posed as social bandits toward the local poor, paying medical bills and funding weddings. One ex-dacoit described his own criminal past by claiming that "I was a rebel. I fought injustice." Following intense anti-banditry campaigns by the Indian Police, highway robbery was almost completely eradicated in the early 2000s. Nevertheless, Chambal is still popularly believed to be unsafe and bandit-infested by many Indians. One police officer noted that the fading of the dacoity was also due to social changes, as few young people were any longer willing to endure the harsh life as a highway robber in the countryside. Instead, they prefer to join crime groups in the city, where life is easier.

While thugs and dacoits operating in northern and central India are more popularly known and referenced in books, films and academic journal, a significant number of accounts also come from Bengal. Writing about the dacoits of Bengal, the colonial official CH Keighly mentions the “great difference between gangs of hereditary dacoits or thugs in other parts of India and the dacoits of Bengal”. It is notable that unlike the rest of India, dacoits in Bengal did not come from a particular social class, caste, or creed. 

Dacoit gangs in Nadia and Hooghly were particularly known for their ritualistic practices before the night of dacoity. Before setting off for their mission, the members would assemble to perform “kalipuja” led by the Sirdar (leader). The dacoits would form a straight line and a pot of liquor, torches, and weapons to be used in the dacoity were laid down in a clear space. The Sirdar would then dip his finger in oil and touch the forehead of all the dacoits, making them promise never to confess. Even during the raid, when dacoits opened chests and discovered a good fortune, they would shout “Kali, Jai Kali”.

Dacoity was highly prevalent in 19 century west Bengal. One of the gangs, led by a charismatic leader named Bhabani Pathak, was known for its loyalty to their leader. After the British captured Bhabani, the inner workings and social factors that led to the construction of this gang were revealed. Leaders such as Bhabani were known as Sirdars and had a symbiotic relationship with their followers. Among other benefits, a Sirdar would lend loans to members and provided them protection. This allowed for the formation of a special bond between the Sirdar and followers which meant that cases of desertion and exiting the gang were virtually unheard of. 

In Burdwan, dacoities were heavily planned and considerable thought went into their seamless execution. Sirdars in Burdwan operated by employing several informants who kept them updated about prospective targets. When a target was finalized, the Sirdar and relevant gang members were constantly made aware about his whereabouts. The informants were always on the lookout for wealthy businessmen and kept a close watch on those that exchanged bank notes of considerable value or received a shipment of merchandise that they would store in their houses.

The term is also applied, according to the "OED", to "pirates who formerly infested the Ganges between Calcutta and Burhampore".

Dacoits existed in Burma as well – Rudyard Kipling's fictional Private Mulvaney hunted Burmese dacoits in "The Taking of Lungtungpen". Sax Rohmer's criminal mastermind Dr. Fu Manchu also employed Burmese dacoits as his henchmen.

Indian police forces use "Known Dacoit" (K.D.) as a label to classify criminals.

Introduced in 1836, the suppression acts brought about several legislative measures including the establishment of special courts, authorization for the use of rewards for informants, and the power to arrest suspects. The suppression acts marked the beginning of active British intervention in policing and law enforcement in Indian society. These acts were known to be authoritarian and further deepened the uneven power dynamic between the British and the Indians.

The British often saw Indians as primitive, violent, and unruly, and this often acted as a justification for colonization and further consolidated their “civilization mission” pretext. The practice of thuggee and dacoity was seen in a similar Eurocentric light, without understanding the local context. An orientalist view of such activities was portrayed in the rest of the world to account for several repressive legislative measures that the British took. Under this punitive approach, several innocent individuals fell prey to false suspicion and were incriminated.

Notable dacoits include:

In Madhya Pradesh, women belonging to a village defence group have been issued firearm permits to fend off dacoity. The Chief minister of the state, Shivraj Singh Chouhan, recognised the role the women had played in defending their villages without guns. He stated that he wanted to enable these women to better defend both themselves and their villages, and issued the gun permits to advance this goal.

As the dacoits flourished through the 1940s–1970s, they were the subject of various Hindi films made during this era, leading to the emergence of the dacoit film genre in Hindi Film Industry. The genre began with Mehboob Khan's "Aurat" (1940), which he remade as "Mother India" (1957). "Mother India" received an Academy Award nomination, and defined the dacoit film genre, along with Dilip Kumar's "Gunga Jumna" (1961). Other popular films in this genre included Raj Kapoor’s "Jis Desh Mein Ganga Behti Hai" (1961) and Moni Bhattacharjee's "Mujhe Jeene Do" (1963).

Pakistani actor Akmal Khan had two dacoit films, "Malangi" (1965) and "Imam Din Gohavia" (1967). Other films in this genre included "Khote Sikkay" (1973), "Mera Gaon Mera Desh" (1971), and "Kuchhe Dhaage" (1973) both by Raj Khosla.

The most famous dacoit film is "Sholay" (1975), written by Salim–Javed, and starring Dharmendra, Amitabh Bachchan, and Amjad Khan as the dacoit character Gabbar Singh. It was a masala film that combined the dacoit film conventions of "Mother India" and "Gunga Jumna" with that of Spaghetti Westerns, spawning the "Dacoit Western" genre, also known as the "Curry Western" genre. The film also borrowed elements from Akira Kurosawa's "Seven Samurai". "Sholay" became a classic in the genre, and its success led to a surge of films in this genre, including "Ganga Ki Saugandh" (1978), once again starring Amitabh Bachchan and Amjad Khan.

An internationally acclaimed example of the genre is "Bandit Queen" (1994).

The Tamil movie starring Karthi, "Theeran Adhigaaram Ondru" (2017) deals elaborately with bandits. The film reveals the real dacoity incidents which held in Tamil Nadu between 1995 and 2005. Director Vinoth did a two-year research about bandits to develop the script.

A related genre of crime films are Mumbai underworld films.

Bengali novel Devi Chowdhurani by author Bankim Chandra Chatterjee in 1867.

A Hindi novel named "Painstth Lakh ki Dacoity" (1977) was written by Surender Mohan Pathak; it was translated as "The 65 Lakh Heist".

Dacoits armed with pistols and swords appear in "".

They frequently appeared in the French language "Bob Morane" series of novels by Henri Vernes, principally as the main thugs or assassins of the hero's recurring villain, Mr. Ming and in English as the agents of Sax Rohmer’s Fu Manchu.




Davis, California

Davis is the most populous city in Yolo County, California, United States. Located in the Sacramento Valley region of Northern California, the city had a population of 66,850 in 2020, not including the on-campus population of the University of California, Davis, which was over 9,400 (not including students' families) in 2016. there were 38,369 students enrolled at the university.

Davis sits on land that originally belonged to the Indigenous Patwin, a southern branch of Wintun people, who were killed or forced from their lands by the 1830s as part of the California Genocide through a combination of mass murders, smallpox and other diseases, and both Mexican and American systems of Indigenous slavery. Patwin burial grounds have been found across Davis, including on the site of the UC Davis Mondavi Center. After the killing and expulsion of the Patwin, territory that eventually became Davis emerged from one of California's most complicated ranchos, Laguna de Santos Callé. The 1852 Land Commission concurred with US Attorneys who argued that the grant was "fraudulent in all its parts," and in his 1860 District Court ruling Justice Ogden Hoffman observed that "It is impossible to contemplate without disgust the series of perjuries which compose the record" of the land grant. Nevertheless, Jerome C. Davis, a prominent farmer and one of the early claimants to land in Laguna de Santos Callé, lobbied all the way to the United States Congress in order to retain the land that eventually became Davis. Davis became a depot on the Southern Pacific Railroad in 1868, when it was named "Davisville" after Jerome C. Davis. However, the post office at Davisville shortened the town name to "Davis" in 1907. The name stuck, and the city of Davis was incorporated on March 28, 1917.

From its inception as a farming community, Davis is known primarily for its contributions to agricultural policy along with veterinary care and animal husbandry. Following the passage of the University Farm Bill in 1905 by the California State Legislature, Governor George Pardee selected Davis out of 50 other sites as the future home to the University of California's University Farm, officially opening to students in 1908. The farm, later renamed the Northern Branch of the College of Agriculture in 1922, was upgraded to become the seventh UC general campus, the University of California, Davis, in 1959.

Davis is located in Yolo County, California, west of Sacramento, northeast of San Francisco, north of Los Angeles, at the intersection of Interstate 80 and State Route 113. Neighboring towns include Dixon, Winters, Woodland, and West Sacramento.

Davis lies in the Sacramento Valley, the northern portion of the Central Valley, in Northern California, at an elevation of about above sea level.

According to the United States Census Bureau, the city has a total area of . of it is land and of it (0.19%) is water.

The topography is flat, which has helped Davis to become known as a haven for bicyclists.

The Davis climate resembles that of nearby Sacramento and is typical of California's Central Valley Mediterranean climate region: warm and dry in the spring, summer and autumn, and cool and wet in the winter. It is classified as a Köppen Csa climate. Summer days are hot, ranging from , but the nights turn pleasantly cool, almost always dropping below . The Delta Breeze, a flow of cool marine air originating from the Pacific Ocean via San Francisco Bay and the Sacramento–San Joaquin River Delta, frequently provides relief in the evening. Winter temperatures generally reach between in the afternoon; nights average at about , but occasionally fall below freezing.

Average temperatures range from in December and January to in July and August. Thick ground fog called tule fog settles into Davis during late fall and winter. This fog can be dense, with visibility nearly zero. As in other areas of northern California, the tule fog is a leading cause of road accidents in the winter season.

Mean rainfall per annum is about . The bulk of rain occurs between about mid-November to mid-March, with typically no precipitation falling from mid-June to mid-September.

Record temperatures range from a high of on July 17, 1925, to a low of on December 11, 1932.

Davis is internally divided by two freeways (Interstate 80 and State Route 113), a north–south railroad (California Northern), an east–west mainline (Union Pacific) and several major streets. The city is unofficially divided into six main districts made up of smaller neighborhoods (often originally named as housing subdivisions):

The University of California, Davis is located south of Russell Boulevard and west of A Street and then south of 1st Street. The land occupied by the university is not incorporated within the boundaries of the city of Davis and lies within both Yolo and Solano Counties.

Local energy planning began in Davis after the energy crisis of 1973. A new building code promoted energy efficiency. Energy use in buildings decreased dramatically and in 1981 Davis citizens won a $100,000 prize from utility PG&E, for cutting electricity use during the summer peak.

On November 14, 1984, the Davis City Council declared the city to be a nuclear-free zone. In 1998, the City passed a "Dark Skies" ordinance in an effort to reduce light pollution in the night sky.

In 2013, Davis became part of the state Cool Roof Initiative with the "CoolDavis" campaign, requiring all new roofing projects to meet Cool Roof Rating Council (CRRC) requirements, including the installation of light-colored roofs. The aim is to reflect more sunlight back into space via the albedo effect, and reduce the amount of heat absorbed in hopes of limiting climate change.

Davis is part of the Sacramento–Arden-Arcade–Roseville Metropolitan Statistical Area.

According to the 2020 Census the population of Davis was 66,850 people. 

In 2020 the racial demographics were as follows:

53.6% White 

2.3% Black

13.8% Hispanic or Latino 

23.3% Asian

1.1% Native American 

9.6% 2 or more races 

The 2010 United States Census reported that Davis had a population of 65,622. The population density was . The racial makeup of Davis was 42,571 (64.9%) White, 1,528 (2.3%) African American, 339 (0.5%) Native American, 14,355 (21.9%) Asian, 136 (0.2%) Pacific Islander, 3,121 (4.8%) from other races, and 3,572 (5.4%) from two or more races. Hispanic or Latino of any race were 8,172 persons (12.5%).

In 2006, Davis was ranked as the second most educated city (in terms of the percentage of residents with graduate degrees) in the US by CNN "Money Magazine", after Arlington County, Virginia.

Davis' Asian population of 14,355 was apportioned among 1,631 Indian Americans, 6,395 Chinese Americans, 1,560 Korean Americans, 1,185 Vietnamese Americans, 1,033 Filipino Americans, 953 Japanese Americans, and 1,598 other Asian Americans.

Davis' Hispanic and Latino population of 8,172 was apportioned among 5,618 Mexican American, 221 Puerto Rican American, 80 Cuban American, and 2,253 other Hispanic and Latino.

The Census reported that 63,522 people (96.8% of the population) lived in households, 1,823 (2.8%) lived in non-institutionalized group quarters, and 277 (0.4%) were institutionalized.

There were 24,873 households, of which 6,119 (24.6%) had children under the age of 18 living in them, 9,343 (37.6%) were opposite-sex married couples living together, 1,880 (7.6%) had a female householder with no husband present, and 702 (2.8%) had a male householder with no wife present. There were 1,295 (5.2%) unmarried opposite-sex partnerships, and 210 (0.8%) same-sex married couples or partnerships. 5,952 households (23.9%) were made up of individuals, and 1,665 (6.7%) had someone living alone who was 65 years of age or older. The average household size was 2.55. There were 11,925 families (47.9% of all households); the average family size was 2.97.

The population age and sex distribution was 10,760 people (16.4%) under the age of 18, 21,757 people (33.2%) aged 18 to 24, 14,823 people (22.6%) aged 25 to 44, 12,685 people (19.3%) aged 45 to 64, and 5,597 people (8.5%) who were 65 years of age or older. The median age was 25.2 years. For every 100 females, there were 90.5 males. For every 100 females age 18 and over, there were 88.0 males.

There were 25,869 housing units, with an average density of , of which 10,699 (43.0%) were owner-occupied, and 14,174 (57.0%) were occupied by renters. The homeowner vacancy rate was 0.9%; the rental vacancy rate was 3.5%. 27,594 people (42.0% of the population) lived in owner-occupied housing units and 35,928 people (54.7%) lived in rental housing units.

As of the United States 2000 Census, there were 60,308 people, 22,948 households, and 11,290 families residing in the city. The population density was . There were 23,617 housing units at an average density of . The racial composition of the city was 70.07% White, 2.35% Black or African American, 0.67% Native American, 17.5% Asian, 0.24% Pacific Islander, 4.26% from other races, and 4.87% from two or more races. 9.61% of the population were Hispanic or Latino of any race.

There were 22,948 households, of which 26.4% had children under the age of 18 living with them, 38.3% were married couples living together, 8.2% had a female householder with no husband present, and 50.8% were non-families. 25.0% of all households were composed of individuals, and 5.2% had someone living alone who was 65 years of age or older. The average household size was 2.50 and the average family size was 3.00.

In the city, the population age distribution was 18.6% under the age of 18, 30.9% from 18 to 24, 27.1% from 25 to 44, 16.7% from 45 to 64, and 6.6% who were 65 years of age or older. The median age was 25 years. For every 100 females, there were 91.2 males. For every 100 females age 18 and over, there were 87.8 males.

The median income for a household in the city was $42,454, and the median income for a family was $74,051. Males had a median income of $51,189 versus $36,082 for females. The per capita income for the city was $22,937. About 5.4% of families and 24.5% of the population were below the poverty line, including 6.8% of those under age 18 and 2.8% of those age 65 or over.

This city of approximately 62,000 people abuts a university campus of 32,000 students. Although the university's land is not incorporated within the city, many students live off-campus in the city.

According to the city's 2020 Comprehensive Annual Financial Report, the top employers in the city are:

A community currency scheme was in use in Davis, called "Davis Dollars".

Bicycling has been one of the most popular modes of transportation in Davis for decades, particularly among school-age children and UC Davis students. In 2010, Davis became the new home of the United States Bicycling Hall of Fame.
Bicycle infrastructure became a political issue in the 1960s, culminating in the election of a pro-bicycle majority to the City Council in 1966. By the early 1970s, Davis became a pioneer in the implementation of cycling facilities. As the city expands, new facilities are usually mandated. As a result, Davis residents today enjoy an extensive network of bike lanes, bike paths, and grade-separated bicycle crossings. The flat terrain and temperate climate are also conducive to bicycling.
In 2005 the Bicycle-Friendly Community program of the League of American Bicyclists recognized Davis as the first Platinum Level city in the US In March 2006, "Bicycling Magazine" named Davis the best small town for cycling in its compilation of "America's Best Biking Cities." Bicycling appears to be declining among Davis residents: from 1990 to 2000, the US Census Bureau reported a decline in the fraction of commuters traveling by bicycle, from 22 percent to 15 percent. This resulted in the reestablishment of the city's Bicycle Advisory Commission and creation of advocate groups such as "Davis Bicycles!". In 2016, Fifth Street, a main road in Davis was converted from four lanes to two lanes to allow for bicycle lanes and encourage more bicycling.

In 1996, 2001, 2006, and 2009 the UC Davis "Cal Aggie Cycling" Team won the national road cycling competition. The team also competes off-road and on the track, and has competed in the national competitions of these disciplines. In 2007, UC Davis also organized a record breaking bicycle parade numbering 822 bicycles.

A continuous stream of bands, speakers and various workshops occurs throughout Mother's Day weekend on each of Whole Earth Festival's (WEF) three stages and other specialty areas. The WEF is organized entirely by UC Davis students, in association with the Associated Students of UC Davis and the university.

Celebrate Davis is the annual free festival held by the Davis Chamber of Commerce. It features booths by Davis businesses, live music, food vendors, live animals, activities like rock climbing and zip-line. It concludes with fireworks after dark. Parking is problematic, so most people ride their bikes and use the free valet parking.

Picnic Day is an annual event at the University of California, Davis and is always held on the third Saturday in April. It is the largest student-run event in the US. Picnic Day starts off with a parade, which features the UC Davis California Aggie Marching Band-uh!, and runs through campus and around downtown Davis and ends with the Battle of the Bands, which lasts until the last band stops playing (sometimes until 2 am). There are over 150 free events and over 50,000 attend every year. Other highlights include: the Dachshund races, a.k.a. the Doxie Derby, held in the Pavilion; the Davis Rock Challenge, the Chemistry Magic Show, and the sheep dog trials. Many departments have exhibits and demonstrations, such as the Cole Facility, which until recently showed a fistulated cow (a cow that has been fitted with a plastic portal (a "fistula") into its digestive system to observe digestion processes). Its name was "Hole-y Cow".

The Davis Transmedia Art Walk is a free—self-guided—public art tour includes 23 public murals, 16 sculptures, and 15 galleries and museums all in downtown Davis and the University of Davis campus. A free Davis Art Walk map serves as a detailed guide to the entire collection. The art pieces are all within walking distance of each other. The walk is a roughly circuitous path that can be completed within an hour or two. Every piece of art on the Art Walk has been embedded with an RFID chip. Using a cellphone that supports this technology, you access multimedia files that relate to each work. You can even leave a comment or "burn your own message" for other visitors to see. Artist hosted tours are held on the weekend by appointment only. To pick up a copy of the Davis Art Walk map, visit the Yolo County Visitors Bureau (132 E St., Suite 200; (530) 297–1900) or the John Natsoulas Center for the Arts (521 1st St.; (530) 756–3938).

The Manetti Shrem Museum of Art, located on the UC Davis campus, opened on November 13, 2016, and carries on the legacy of the university's world-renowned first generation art faculty, which contributed to innovations in conceptual, performance and video art in the 1960s and 70s. The museum has generated nationwide attention with exhibits by artists such as Wayne Thiebaud, Bruce Nauman, John Cage, and Robert Arneson as well as its striking architecture, featuring a 50,000 square-foot “Grand Canopy” of perforated aluminum triangular beams, supported by 40 steel columns. Every year the museum exhibits works by graduating art students. The museum is free and hosts lecture series and events throughout the year, as well as weekend art studio activities for all ages.

The Mondavi Center, located on the UC Davis campus, is one of the biggest non-seasonal attractions in Davis. The Mondavi Center is a theater which hosts many world-class touring acts, including star performers such as Yo-Yo Ma, Yitzhak Perlman and Wynton Marsalis, and draws a large audience from Sacramento.

The UC Davis Arboretum is an arboretum and botanical garden. Plants from all over the world grow in different sections of the park. There are notable oak and native plant collections and a small redwood grove. A small waterway spans the arboretum along the bed of the old North Fork of Putah Creek. Occasionally herons, kingfishers, and cormorants can be seen around the waterways, as well as the ever-present ducks. Tours of the arboretum led by volunteer naturalists are often held for grade-school children.

The Domes, (AKA Baggins End Innovative Housing), is an on-campus cooperative housing community designed by project manager Ron Swenson and future student-residents in 1972. Consisting of 14 polyurethane foam-insulated fiberglass domes and located in the Sustainable Research Area at the western end of Orchard Road, it is governed by its 26 UCD student residents. It is one of the few student co-housing cooperative communities in the US, and is an early example of the modern-day growing tiny house movement. The community has successfully resisted several threats to its continuation over the years.

The Davis Farmers Market is held every Wednesday evening and Saturday morning. Participants sell a range of fruits and vegetables, baked goods, dairy and meat products (often from certified organic farms), crafts, and plants and flowers. From April to October, the market hosts "Picnic in the Park", with musical events and food sold from restaurant stands.
The Davis Farmers Market won first place in the 2009, and second place in the 2010 "America's Favorite Farmers Markets" held by the American Farmland Trust under the large Farmers market classification.

Davis has one newspaper, "The Davis Enterprise", a thrice-weekly founded in 1897. UC Davis also has a weekly newspaper called "The California Aggie" which covers campus, local and national news. Davis Media Access, a community media center, is the umbrella organization of television station DCTV. There are also numerous commercial stations broadcasting from nearby Sacramento. Davis has two community radio stations: KDVS 90.3 FM, on the University of California campus, and KDRT 95.7 FM, a subsidiary of Davis Media Access and one of the first low-power FM radio stations in the United States. Davis has the world's largest English-language local wiki, DavisWiki. In 2006, "The People's Vanguard of Davis" began news reporting about the city of Davis, the Davis Joint Unified School District, the county of Yolo, and the Sacramento area.

Davis' Toad Tunnel is a wildlife crossing that was constructed in 1995 and has drawn much attention over the years, including a mention on "The Daily Show". Because of the building of an overpass, animal lovers worried about toads being killed by cars commuting from South Davis to North Davis, since the toads traveled from one side of a dirt lot (which the overpass replaced) to the reservoir at the other end. After much controversy, a decision was made to build a toad tunnel, which runs beneath the Pole Line Road overpass which crosses Interstate 80. The project cost $14,000, . The tunnel is wide and high.

The University of California, Davis, or UC Davis, a campus of the University of California, had a 2019 Fall enrollment of 38,369 students. UC Davis has a dominant influence on the social and cultural life of the town.

Also known as Deganawidah-Quetzalcoatl University and much smaller than UC Davis, D-Q University was a two-year institution located on Road 31 in Yolo County west of State Route 113. This is just west of Davis near the Yolo County Airport. About to the west, the Road 31 exit from Interstate 505 is marked with cryptic signage, "DQU." The site is about above mean sea level (AMSL). NAD83 coordinates for the campus are 

The college closed in 2005. The curriculum was said to include heritage and traditional American Indian ceremonies. The and 5 buildings were formerly a military reservation according to a National Park Service publication, "Five Views." The full name of the school is included here so that readers can accurately identify the topic. According to some tribal members, use of the spelled-out name of the university can be offensive. People who want to be culturally respectful refer to the institution as "D-Q University". Tribal members in appropriate circumstances may use the full name.

An off-campus branch of Sacramento City College is located in Davis. The satellite is located in West Village, an area built by UC Davis to house students and others affiliated with the university.

Davis' public school system is administrated by the Davis Joint Unified School District.

The city has nine public elementary schools (North Davis, Birch Lane, Pioneer Elementary, Patwin, Cesar Chavez, Robert E. Willett, Marguerite Montgomery, Fred T. Korematsu at Mace Ranch, and Fairfield Elementary (which is outside the city limits but opened in 1866 and is Davis Joint Unified School District's oldest public school)). Davis has one school for independent study (Davis School for Independent Study), four public junior high schools (Ralph Waldo Emerson, Oliver Wendell Holmes, Frances Harper, and Leonardo da Vinci Junior High), one main high school (Davis Senior High School), one alternative high school (Martin Luther King High School), and a small project based high school (Leonardo da Vinci High School). Cesar Chavez is a Spanish immersion school, with no English integration until the third grade. The junior high schools contain grades 7 through 9. Due to a decline in the school-age population in Davis, two of the elementary schools in south Davis may have their district boundaries changed, or magnet programs may be moved to equalize enrollment. Valley Oak was closed after the 2007–08 school year, and their campus was granted to Da Vinci High (which had formerly been located in the back of Davis Senior High's campus) and a special-ed preschool. On average, class size is about 25 students: 1 teacher.

At one time, Chavez and Willett were incorporated together to provide elementary education K–6 to both English-speaking and Spanish immersion students in West Davis. César Chávez served grades K–3 and was called West Davis Elementary, and Robert E. Willett (named for a long-time teacher at the school, now deceased) served grades 4–6 and was known as West Davis Intermediate. Willett now serves K–6 English-speaking students, and Chavez supports the Spanish immersion program for K–6.


These are some notable Davis residents, other than UC Davis faculty who were not previously from Davis.


Davis' sister cities are:




Damon Runyon

Alfred Damon Runyon (October 4, 1880 – December 10, 1946) was an American journalist and short-story writer.

He was best known for his short stories celebrating the world of Broadway in New York City that grew out of the Prohibition era. To New Yorkers of his generation, a "Damon Runyon character" evoked a distinctive social type from Brooklyn or Midtown Manhattan. The adjective "Runyonesque" refers to this type of character and the type of situations and dialog that Runyon depicts.

He spun humorous and sentimental tales of gamblers, hustlers, actors, and gangsters, few of whom go by "square" names, preferring instead colorful monikers such as "Nathan Detroit", "Benny Southstreet", "Big Jule", "Harry the Horse", "Good Time Charley", "Dave the Dude", or "The Seldom Seen Kid".

His distinctive vernacular style is known as "Runyonese": a mixture of formal speech and colorful slang, almost always in the present tense, and always devoid of contractions. He is credited with coining the phrase "Hooray Henry", a term now used in British English to describe the upper-class version of a loud-mouthed, arrogant twit.

Runyon's fictional world is also known to the general public through the musical "Guys and Dolls" based on two of his stories, "The Idyll of Miss Sarah Brown" and "Blood Pressure". The musical additionally borrows characters and story elements from a few other Runyon stories, most notably "Pick The Winner". The film "Little Miss Marker" (and its three remakes, "Sorrowful Jones", "40 Pounds of Trouble" and the 1980 "Little Miss Marker") grew from his short story of the same name.

Runyon was also a newspaper reporter, covering sports and general news for decades for various publications and syndicates owned by William Randolph Hearst. Already known for his fiction, he wrote a well-remembered "present tense" article on Franklin Delano Roosevelt's Presidential inauguration in 1933 for the Universal Service, a Hearst syndicate, which was merged with the co-owned International News Service in 1937.

Damon Runyon was born Alfred Damon Runyan to Alfred Lee and Elizabeth (Damon) Runyan. His relatives in his birthplace of Manhattan, Kansas, included several newspapermen. His grandfather was a newspaper printer from New Jersey who had relocated to Manhattan, Kansas, in 1855, and his father was the editor of his newspaper in the town. In 1882 Runyon's father was forced to sell his newspaper, and the family moved westward. The family eventually settled in Pueblo, Colorado, in 1887, where Runyon spent the rest of his youth. By most accounts, he attended school only through the fourth grade. He began to work in the newspaper trade under his father in Pueblo. In present-day Pueblo, Runyon Field, the Damon Runyon Repertory Theater Company, and Runyon Lake are named in his honor.

In 1898, when still in his teens, Runyon enlisted in the US Army to fight in the Spanish–American War. While in the service, he was assigned to write for the "Manila Freedom" and "Soldier's Letter".

After military service, he worked for Colorado newspapers, beginning in Pueblo. His first job as a reporter was in September 1900, when he was hired by the "Pueblo Star"; he then worked in the Rocky Mountain area during the first decade of the 1900s: at the "Denver Daily News", he served as "sporting editor" (today a "sports editor") and then as a staff writer. His expertise was in covering the semi-professional teams in Colorado. He briefly managed a semi-pro team in Trinidad, Colorado. At one of the newspapers where he worked, the spelling of his last name was changed from "Runyan" to "Runyon", a change he let stand.

After failing in an attempt to organize a Colorado minor baseball league, which lasted less than a week, Runyon moved to New York City in 1910. In his first New York byline, the "American" editor dropped the "Alfred" and the name "Damon Runyon" appeared for the first time. For the next ten years, he covered the New York Giants and professional boxing for the "New York American".

He was the Hearst newspapers' baseball columnist for many years, beginning in 1911, and his knack for spotting the eccentric and the unusual, on the field or in the stands, is credited with revolutionizing the way baseball was covered. Perhaps as confirmation, Runyon was voted 1967 J. G. Taylor Spink Award by the Baseball Writers' Association of America (BBWAA), for which he was honored at ceremonies at the National Baseball Hall of Fame in July 1968. He is also a member of the International Boxing Hall Of Fame and is known for dubbing heavyweight champion James J. Braddock the "Cinderella Man". Runyon frequently contributed sports poems to the "American" on boxing and baseball themes and wrote numerous short stories and essays. 
Gambling, particularly on craps or horse races, was a common theme of Runyon's works, and he was a notorious gambler. One of his paraphrases from a line in Ecclesiastes ran: "The race is not always to the swift, nor the battle to the strong, but that's how the smart money bets."

A heavy drinker as a young man, he seems to have quit drinking soon after arriving in New York, after his drinking nearly cost him the courtship of the woman who became his first wife, Ellen Egan. He remained a heavy smoker.

His best friend was mobster accountant Otto Berman, and he incorporated Berman into several of his stories under the alias "Regret, the horse player". When Berman was killed in a hit on Berman's boss, Dutch Schultz, Runyon quickly assumed the role of damage control for his deceased friend, mostly by correcting erroneous press releases – including one that stated Berman was one of Schultz's gunmen, to which Runyon replied, "Otto would have been as effective a bodyguard as a two-year-old."

While in New York City, Runyon courted and eventually married Ellen Egan. Their marriage produced two children, Mary and Damon Jr. A modern writer remarks that "by contemporary standards, Runyon was a marginal husband and father." In 1928, Egan separated from Runyon permanently and moved to Bronxville with their children after hearing persistent rumors about her husband's infidelities. As it became subsequently known, Runyon, in 1916, was covering the border raids of Mexican bandit Pancho Villa as a reporter for the "American" newspaper owned by William Randolph Hearst. He had first met Villa in Texas while covering spring training of the state's teams. While in Mexico, Runyon visited one afternoon the Ciudad Juárez racetrack where Villa was present and placed a bet through a young messenger girl in Villa's entourage. The 14-year-old girl, whose name was Patrice Amati del Grande, erroneously placed Runyon's bet on a different horse that nonetheless won the race. She confided to the lucky bettor that she wanted to be a dancer when she grew up and Runyon told her that if, instead, she would attend school, for which he would pay, she could come after her graduation to see him New York and he would get her a dancing job in the city; Runyon did indeed pay for her enrollment in the local convent school.

In 1925, 19-year-old Grande came to New York City looking for Runyon and found him through the "American"'s receptionist. The two became lovers and he found her work at local speakeasies. In 1928, after the separation between Runyon and Ellen Egan turned into a divorce, Runyon and Grande were married by his friend, city mayor Jimmy Walker. His former wife became an alcoholic and died in 1931 from a heart attack. In 1946, some time after Grande began an affair with a younger man, the couple got divorced.

In late 1946, the same year he and his second wife were divorced, Runyon died, at age 66, in New York City from the throat cancer that had been diagnosed two years earlier, in 1944, when he underwent an unsuccessful operation that left him practically unable to speak. 

His body was cremated, and his ashes were scattered from a DC-3 airplane over Broadway in Manhattan by Eddie Rickenbacker on December 18, 1946. This was an infringement of the law but widely approved. The family plot of Damon Runyon is located at Woodlawn Cemetery in The Bronx, New York.

Runyon, in his will, left to his former second wife his house in Florida, his racing stables, and the money from his insurance. He split in half the royalties from his works to his children and Grande. His daughter Mary was eventually institutionalized for alcoholism while his son Damon Jr., after working as a journalist in Washington, D.C., committed suicide in 1968.


The English comedy writer Frank Muir comments that Runyon's plots were, in the manner of O. Henry, neatly constructed with professionally wrought endings, but their distinction lay in the manner of their telling, as the author invented a peculiar argot for his characters to speak. Runyon almost totally avoids the past tense (English humorist E. C. Bentley thought there was only one instance and was willing to "lay plenty of 6 to 5 that it is nothing but a misprint", but "was" appears in the short stories "The Lily of St Pierre" and "A Piece of Pie"; "had" appears in "The Lily of St Pierre", "Undertaker Song" and "Bloodhounds of Broadway"), and makes little use of the future tense, using the present for both. He also avoided the conditional, using instead the future indicative in situations that would normally require conditional. An example: "Now most any doll on Broadway will be very glad indeed to have Handsome Jack Madigan give her a tumble" ("Guys and Dolls", "Social error"). Bentley comments that "there is a sort of ungrammatical purity about it [Runyon's resolute avoidance of the past tense], an almost religious exactitude." There is an homage to Runyon that makes use of this peculiarity ("Chronic Offender" by Spider Robinson), which involves a time machine and a man going by the name "Harry the Horse".

He uses many slang terms (which go unexplained in his stories), such as:


There are many recurring composite phrases such as:


Bentley notes that Runyon's "telling use of the recurrent phrase and fixed epithet" demonstrates a debt to Homer.

Runyon's stories also employ occasional rhyming slang, similar to the cockney variety but native to New York (e.g.: "Miss Missouri Martin makes the following crack one night to her: 'Well, I do not see any Simple Simon on your lean and linger.' This is Miss Missouri Martin's way of saying she sees no diamond on Miss Billy Perry's finger." (from "Romance in the Roaring Forties")).

The comic effect of his style results partly from the juxtaposition of broad slang with mock pomposity. Women, when not "dolls", "Judies", "pancakes", "tomatoes", or "broads", may be "characters of a female nature", for example. He typically avoided contractions such as "don't" in the example above, which also contributes significantly to the humorously pompous effect. In one sequence, a gangster tells another character to do as he is told, or else "find another world in which to live".

Runyon's short stories are told in the first person by a protagonist who is never named and whose role is unclear; he knows many gangsters and does not appear to have a job, but he does not admit to any criminal involvement, and seems to be largely a bystander. He describes himself as "being known to one and all as a guy who is just around". The radio program "The Damon Runyon Theatre" dramatized 52 of Runyon's works in 1949, and for these the protagonist was given the name "Broadway", although it was admitted that this was not his real name, much in the way "Harry the Horse" and "Sorrowful Jones" are aliases.







There are many collections of Runyon's stories, in particular "Runyon on Broadway" and "Runyon from First to Last". A publisher's note in the latter claims that collection contains all of Runyon's short stories not included in "Runyon on Broadway", but two Broadway stories originally published in "Collier's Weekly" are not in either collection: "Maybe a Queen" and "Leopard's Spots", both collected in "More Guys And Dolls" (1950). The radio show, in addition, has a story, "Joe Terrace", that appears in 'More Guys and Dolls' and the August 29, 1936, issue of "Colliers". It is one of his "Our Town" stories that does not appear in the "In Our Town" book, and the only episode of the show which is not a Broadway' story, however, the action is changed in the show from Our Town to Broadway.

The "Our Town" stories are short vignettes of life in a small town, largely based on Runyon's experiences. They are written in a simple, descriptive style and contain twists and odd endings based on the personalities of the people involved. Each story's title is the name of the principal character. Twenty-seven of them were published in the 1946 book "In Our Town".

"Runyon on Broadway" contains the following stories:
More Than Somewhat
Furthermore

Take It Easy
"Runyon from First to Last" includes the following stories and sketches:
The First Stories (early non-Broadway stories):
Stories à la Carte (Broadway stories written in Runyonese):


The Last Stories (Broadway stories written in Runyonese):
Written in Sickness (sketches):

"In Our Town" contains the following stories:


The following "Our Town" stories were not included in "In Our Town":

Twenty of his stories became motion pictures.

In 1938, his unproduced play "Saratoga Chips" became the basis of The Ritz Brothers film "Straight, Place and Show".


"The Damon Runyon Theater" radio series dramatized 52 of Runyon's short stories in weekly broadcasts running from October 1948 to September 1949 (with reruns until 1951). The series was produced by Alan Ladd's Mayfair Transcription Company for syndication to local radio stations. John Brown played the character "Broadway", who doubled as host and narrator. The cast also comprised Alan Reed, Luis Van Rooten, Joseph Du Val, Gerald Mohr, Frank Lovejoy, Herb Vigran, Sheldon Leonard, William Conrad, Jeff Chandler, Lionel Stander, Sidney Miller, Olive Deering and Joe De Santis. Pat O'Brien was initially engaged for the role of "Broadway". The original stories were adapted for the radio by Russell Hughes.

"Broadway's New York had a crisis each week, though the streets had a rose-tinged aura", wrote radio historian John Dunning. "The sad shows then were all the sadder; plays like "For a Pal" had a special poignance. The bulk of Runyon's work had been untapped by radio, and the well was deep."

"Damon Runyon Theatre" aired on CBS-TV from 1955 to 1956.

Mike McShane told Runyon stories as monologues on British TV in 1994, and an accompanying book was released, both titled "Broadway Stories".

"Three Wise Guys" was a 2005 TV movie.



Don Tennant

Donald G. Tennant (November 23, 1922 – December 8, 2001) was an American advertising agency executive.

He worked at the Leo Burnett agency in Chicago, Illinois. The agency placed anthropomorphic faces of 'critters' on packaged goods.Tennant was in charge of the Marlboro account and invented the Marlboro Man.

Devo

Devo (, originally ), often stylized as DEVO, is an American new wave band from Akron, Ohio, formed in 1973. Their classic line-up consisted of two sets of brothers, the Mothersbaughs (Mark and Bob) and the Casales (Gerald and Bob), along with Alan Myers. The band had a No. 14 "Billboard" chart hit in 1980 with the single "Whip It", the song that gave the band mainstream popularity.

Devo's music and visual presentation (including stage shows and costumes) mingle kitsch science fiction themes, deadpan surrealist humor and mordantly satirical social commentary. The band's namesake, the tongue-in-cheek social theory of "de-evolution", was an integral concept in their early work, which was marked by experimental and dissonant art punk that merged rock music with electronics. Their output in the 1980s embraced synth-pop and a more mainstream, less conceptual style, though the band's satirical and quirky humor remained intact. Their music has proven influential on subsequent movements, particularly on new wave, industrial, and alternative rock artists. Devo (most enthusiastically Gerald Casale) was also a pioneer of the music video format.

The name "Devo" comes from the concept of "de-evolution" and the band's related idea that instead of continuing to evolve, mankind had begun to regress, as evidenced by the dysfunction and herd mentality of American society. In the late 1960s, this idea was developed as a joke by Kent State University art students Gerald Casale and Bob Lewis, who created a number of satirical art pieces in a devolution vein. At this time, Casale had also performed with the local band 15-60-75 (The Numbers Band). They met Mark Mothersbaugh around 1970, a talented keyboardist who had been playing with the band Flossy Bobbitt. Mothersbaugh brought a more humorous feel to the band, introducing them to material like the pamphlet "Jocko Homo Heavenbound", which includes an illustration of a winged devil labelled "D-EVOLUTION" and would later inspire the song "Jocko Homo". The "joke" about de-evolution became serious following the Kent State massacre of May 4, 1970. This event would be cited multiple times as the impetus for forming the band Devo. Throughout the band's career, they have often been considered a "joke band" by the music press.

The first form of Devo was the "Sextet Devo" which performed at the 1973 Kent State performing arts festival. It included Casale, Lewis and Mothersbaugh, as well as Gerald's brother Bob Casale on guitar, and friends Rod Reisman and Fred Weber on drums and vocals, respectively. This performance was filmed and an excerpt was later included on the home video release "The Complete Truth About De-Evolution". This lineup performed only once. Devo returned to perform in the Student Governance Center (featured prominently in the film) at the 1974 Creative Arts Festival with a lineup including the Casale brothers, Bob Lewis, Mark Mothersbaugh, and Jim Mothersbaugh on drums.
The band continued to perform, generally as a quartet, but with a fluid lineup including Mark's brothers Bob Mothersbaugh and Jim Mothersbaugh. Bob played electric guitar, and Jim provided percussion using a set of home-made electronic drums. Their first two music videos, "Secret Agent Man" and "Jocko Homo", which both appeared in "The Truth About De-Evolution", were filmed in Akron, and Cuyahoga Falls, Ohio, the hometown of most members. This lineup of Devo lasted until late 1975 when Jim left the band. Lewis would sometimes play guitar during this period, but mainly stayed in a managerial role. In concert, Devo would often perform in the guise of theatrical characters, such as Booji Boy and the Chinaman. Live concerts from this period were often confrontational, and would remain so until 1977. A recording of an early Devo performance from 1975 with the quartet lineup appears on "" (1992), ending with the promoters unplugging Devo's equipment.

Following Jim Mothersbaugh's departure, Bob Mothersbaugh found a new drummer, Alan Myers, who played on a conventional, acoustic drum kit. Casale re-recruited his brother Bob Casale, and the lineup of Devo remained the same for nearly ten years.

Devo gained some fame in 1976 when their short film "The Truth About De-Evolution", directed by Chuck Statler, won a prize at the Ann Arbor Film Festival. This attracted the attention of David Bowie, who began work to get the band a recording contract with Warner Music Group. In 1977, Devo were asked by Neil Young to participate in the making of his film "Human Highway". Released in 1982, the film featured the band as "nuclear garbagemen". The band members were asked to write their own parts and Mark Mothersbaugh scored and recorded much of the soundtrack, his first of many.

In March 1977, Devo released their first single, "Mongoloid" backed with "Jocko Homo", the B-side of which came from the soundtrack to "The Truth About De-Evolution", on their independent label Booji Boy. This was followed by a cover of the Rolling Stones' "(I Can't Get No) Satisfaction".

In 1978, the "B Stiff" EP was released by British independent label Stiff, which included the single "Be Stiff" plus two previous Booji Boy releases. "Mechanical Man", a 4-track 7-inch extended play (EP) of demos, an apparent bootleg, but actually put out by the band, was also released that year.

Recommendations from David Bowie and Iggy Pop enabled Devo to secure a recording contract with Warner Bros. in 1978. After Bowie backed out of the business deal due to previous commitments, their first album, "Q: Are We Not Men? A: We Are Devo!" was produced by Brian Eno and featured re-recordings of their previous singles "Mongoloid" and "(I Can't Get No) Satisfaction". On October 14, 1978, Devo gained national exposure with an appearance on the late-night show "Saturday Night Live", a week after the Rolling Stones, performing "(I Can't Get No) Satisfaction" and "Jocko Homo".

The band followed up with "Duty Now for the Future" in 1979, which moved the band more towards electronic instrumentation. While not as successful as their first album, it did produce some fan favorites with the songs "Blockhead" and "The Day My Baby Gave Me a Surprize" , as well as a cover of the Johnny Rivers hit "Secret Agent Man". "Secret Agent Man" had been recorded first in 1974 for Devo's first film and performed live as early as 1976. In 1979, Devo traveled to Japan for the first time, and a live show from this tour was partially recorded. Devo appeared on "Don Kirshner's Rock Concert" in 1979, performing "Blockhead", "Secret Agent Man", "Uncontrollable Urge", and "Mongoloid". Also in 1979, Rhino, in conjunction with the Los Angeles radio station KROQ-FM, released "Devotees", a tribute album. It contained a set of covers of Devo songs interspersed with renditions of popular songs in Devo's style.

Devo actively embraced the parody religion Church of the SubGenius. In concert, Devo sometimes performed as their own opening act, pretending to be a Christian soft rock band called "Dove (the Band of Love)", which is an anagram of "Devo". They appeared as Dove in the 1980 televangelism spoof film "Pray TV".

Devo gained a new level of visibility with 1980's "Freedom of Choice". This album included their best-known hit, "Whip It", which quickly became a Top 40 hit. The album moved to an almost completely electronic sound, with the exception of acoustic drums and Bob Mothersbaugh's guitar. The tour for "Freedom of Choice" was ambitious for the band, including dates in Japan, the United Kingdom, France, Germany, Italy, the Netherlands, and Canada. The band used a minimalist set including large custom light boxes which could be laid on their back to form a second, smaller stage during the second half of the set. Other popular songs from "Freedom of Choice" were "Girl U Want", the title-track, and "Gates of Steel". The band released popular music videos for "Whip It" and "Girl U Want". Devo made two appearances on the TV show "Fridays" in 1980, as well as on "Don Kirshner's Rock Concert", "American Bandstand", and other shows. The band members often wore red, terraced energy dome hats as part of its stage outfit. The dome was first worn during the band's "Freedom of Choice" campaign of 1980. It reappeared in the 1981, 1982, and 1988 tours, as well as in most of their performances since 1997. Devo also recorded two albums of their own songs as elevator music for their fan club, Club Devo, released on cassette in 1981 and 1984. These were later re-released on the album "E-Z Listening Disc" (1987), with all but two of the original Club Devo songs. These songs were often played as house music before Devo concerts.

In August 1981, the band's "DEV-O Live" EP spent three weeks at the top of the Australian charts. In 1982, they toured Australia and appeared on the TV show "Countdown". Devo enjoyed continued popularity in Australia, where the nationally broadcast 1970s–1980s pop TV show "Countdown" was one of the first programs in the world to broadcast their video clips. They were given consistent radio support by Sydney-based non-commercial rock station Double Jay (2JJ) and Brisbane-based independent community station Triple Zed (4ZZZ), two of the first rock stations outside America to play their recordings. The late-night music program "Nightmoves" aired "The Truth About De-Evolution".

In 1981, Devo contributed a cover of "Working in the Coal Mine", recorded during the "Freedom of Choice" sessions, to the film "Heavy Metal". They offered the song to be used in the film when Warner Bros. refused to include it on the album. Warner then included it as an independent bonus single accompanying their 1981 release, "New Traditionalists". For this album Devo wore self-described "Utopian Boy Scout uniforms" topped with a "New Traditionalist Pomp"—a plastic half-wig modeled on the hairstyle of John F. Kennedy. Among the singles from the album was "Through Being Cool", written as a reaction to their new-found fame from "Whip It" and seen as a response to new fans who had misinterpreted the message behind the hit song. The album's accompanying tour featured the band performing an intensely physical show with treadmills and a large Greek temple set. That same year they served as Toni Basil's backing band on "Word of Mouth", her debut album, which included versions of three Devo songs, recorded with Basil singing lead.

"Oh, No! It's Devo" followed in 1982. Produced by Roy Thomas Baker, the album featured a more synth-pop-oriented sound than its predecessors. According to Gerald Casale, the album's sound was inspired by reviewers alternately describing them as both "fascists" and "clowns". The album's tour featured the band performing seven songs in front of a 12-foot high rear-projection screen with synchronized video, an image recreated using blue screen effects in the album's accompanying music videos. Devo also contributed two songs, "Theme from Doctor Detroit" and "Luv-Luv", to the 1983 Dan Aykroyd film "Doctor Detroit", and produced a music video for "Theme from Doctor Detroit" featuring clips from the film interspersed with live-action segments.

The band's sixth studio album, "Shout" (1984), which featured extensive use of the Fairlight CMI digital sampling synthesizer, was received poorly, and the expensive music video they'd produced for their cover of the Jimi Hendrix Experience's "Are You Experienced?" was criticized by some as being "disrespectful", all of which caused Warner Bros. to buy out the remainder of Devo's contract. Shortly thereafter, Myers left the band, citing creative unfulfillment.

In the interim, Mark Mothersbaugh began composing music for the TV show "Pee-wee's Playhouse" and released an elaborately packaged solo cassette, "Musik for Insomniaks", which was later expanded and released as two CDs in 1988.

In 1987, Devo re-formed with former Sparks drummer David Kendrick to replace Myers. Their first project was a soundtrack for the horror film "Slaughterhouse Rock" (1988), starring Toni Basil. The band released the album "Total Devo" in 1988, on Enigma Records. This album included two songs used in the "Slaughterhouse Rock" soundtrack. The song "Baby Doll" was used that same year in the comedy film "Tapeheads", with newly recorded Swedish lyrics, and was credited to (and shown in a music video by) a fictitious Swedish band called Cube-Squared. Devo followed this up with a world tour, and released the live album "" in 1989. However, "Total Devo" was not a commercial success and received poor critical reviews.

In 1989, members of Devo were involved in the project Visiting Kids, releasing a self-titled EP on the New Rose label in 1990. The band featured Mark's then-wife Nancye Ferguson, as well as David Kendrick, Bob Mothersbaugh, and Bob's daughter Alex Mothersbaugh. Their record was produced by Bob Casale and Mark Mothersbaugh, and Mark also co-wrote some of the songs. Visiting Kids appeared on the soundtrack to the film "Rockula", as well as on "Late Night with David Letterman". A promotional video was filmed for the song "Trilobites".

In 1990, "Smooth Noodle Maps", Devo's last album for twenty years, was released. It too was a critical and commercial failure which, along with its two singles "Stuck in a Loop" and "Post Post-Modern Man", were Devo's worst-selling efforts; all failed to appear on the U.S. charts. Devo launched a concert tour in support of the album, but poor ticket sales and the bankruptcy and dissolution of Enigma Records, which was responsible for organizing and financing the tour, caused it to be cancelled part way through.

In 1990, the members of Devo, bar Bob Mothersbaugh, appeared in the film "The Spirit of '76". Two albums of demo recordings from 1974 to 1977, namely "" (1990) and "" (1991), were released on Rykodisc, as well as an album of early live recordings, "Devo Live: The Mongoloid Years" (1992).

The band played one final show in March 1991 before breaking up. In an interview with Mark Mothersbaugh concerning their 1996 computer game "Devo Presents Adventures of the Smart Patrol", he explained, "Around '88, '89, '90 maybe, we did our last tour in Europe, and it was kind of at that point, We were watching "This Is Spinal Tap" on the bus and said, 'Oh my God, that's our life.' And we just said, 'Things have to change.' So we kind of agreed from there that we wouldn't do live shows anymore."

Following the split, Mark Mothersbaugh established Mutato Muzika, a commercial music production studio, along with Bob Mothersbaugh and Bob Casale. Mothersbaugh meant to further a career as a composer, and the latter worked as an audio engineer. Mothersbaugh has had considerable success writing and producing music for television programs, including "Pee-wee's Playhouse" and "Rugrats", video games, cartoons, and films, where he worked alongside director Wes Anderson. David Kendrick also worked at Mutato for a period during the early 1990s. Gerald Casale began a career as a director of music videos and commercials, working with bands including Rush, Soundgarden, Silverchair and the Foo Fighters. In the wake of Devo's dissolution, Bob Mothersbaugh attempted to start a solo career with The Bob I Band, recording an album that was never released. The tapes for this are now lost, though a bootleg recording of the band in concert exists and can be obtained through the bootleg aggregator Booji Boy's Basement.

While they did not release any studio albums during this period, Devo sporadically reconvened to record a number of songs for various films and compilations, including a new recording of "Girl U Want" on the soundtrack to the 1995 film "Tank Girl" and a cover of the Nine Inch Nails hit "Head Like a Hole" for the 1996 North American version of the film "Supercop".

In January 1996, Devo performed a reunion concert at the Sundance Film Festival in Park City, Utah. The band performed on part of the 1996 Lollapalooza tour in the rotating Mystery Spot. On these tours and most subsequent tours, Devo performed a set-list mostly composed of material from between 1978 and 1982, ignoring their Enigma Records-era material. Also in 1996, Devo released a multimedia CD-ROM adventure game, "Adventures of the Smart Patrol" with Inscape. The game was not a success, but the Lollapalooza tour was received well enough to allow Devo to return in 1997 as a headliner. Devo performed sporadically from 1997 onwards.

In 1999, the "Oh, No! It's Devo" era outtakes "Faster and Faster" and "One Dumb Thing", as well as the "Shout" era outtake "Modern Life", were restored, completed and used in the video game "Interstate '82", developed by Activision and released. Also that year, Mothersbaugh started the Devo side-project The Wipeouters, after their band in junior high, featuring himself (keyboards, organ), Bob Mothersbaugh (guitar), Bob Casale (guitar), and Mutato Muzika composer Josh Mancell (drums). The Wipeouters performed the theme song to the Nickelodeon animated series "Rocket Power", and in 2001 they released an album of surf rock material, titled "P'Twaaang!!!".

Around this same time, Devo's online fandom continued to grow, leading to 'Devotional', a Devo fan convention held annually in Cleveland, Ohio. The festival was most recently held in September 2022.

In 2005, Devo recorded a new version of "Whip It" to be used in Swiffer television commercials, a decision they have said they regretted. During an interview with the "Dallas Observer", Gerald Casale said, "It's just aesthetically offensive. It's got everything a commercial that turns people off has." The song "Beautiful World" was also used in a re-recorded form for an advertisement for Target stores. Due to rights issues with their back catalog, Devo has re-recorded songs for films and advertisements.

In 2005, Gerald Casale announced his "solo" project, Jihad Jerry & the Evildoers (the Evildoers, including the other members of Devo), and released the first EP, "Army Girls Gone Wild" in 2006. A full-length album, "Mine Is Not a Holy War", was released on September 12, 2006, after a several-month delay. It featured mostly new material, plus re-recordings of four obscure Devo songs: "I Need a Chick" and "I Been Refused" (from ""), "Find Out" (which appeared on the single and EP of "Peek-a-Boo!" in 1982), and "Beehive" (which was recorded by the band in 1974, whereupon it was apparently abandoned, with the exception of one appearance at a special show in 2001). Devo continued to tour actively in 2005 and 2006, unveiling a new stage show at appearances in October 2006, with the Jihad Jerry character performing "Beautiful World" as an encore.

Also in 2006, Devo worked on a project with Disney known as Devo 2.0. A band of child performers was assembled and re-recorded Devo songs. A quote from the "Akron Beacon Journal" stated, "Devo recently finished a new project in cahoots with Disney called Devo 2.0, which features the band playing old songs and two new ones with vocals provided by children. Their debut album, a two disc CD/DVD combo entitled "DEV2.0", was released on March 14, 2006. The lyrics of some of the songs were changed for family-friendly airplay, which has been claimed by the band to be a play on irony of the messages of their classic hits."
In an April 2007 interview, Gerald Casale mentioned a tentative project for a biographical film about Devo's early days. According to Casale, a script was supposedly in development, called "The Beginning Was the End". Devo played their first European tour since 1990 in the summer of 2007, including a performance at Festival Internacional de Benicàssim.

In December 2007, Devo released their first new single since 1990, "Watch Us Work It", which was featured in a commercial for Dell. The song features a sampled drum track from the "New Traditionalists" song "The Super Thing". Casale said that the song was chosen from a batch that the band was working on, and that it was the closest the band had been to releasing a new album.
Devo performed at the South by Southwest (SXSW) festival in March 2009, unveiling a new stage show with synchronized video backdrops (similar to the 1982 tour), new costumes, and three new songs: "Don't Shoot, I'm a Man!", "What We Do", and "Fresh". On September 16, Warner Bros. and Devo announced re-releases of "Q: Are We Not Men? A: We Are Devo!" and "Freedom of Choice", as well as a subsequent tour, where they would perform both albums in their entirety.

A new album, "Something for Everybody", was eventually released on June 15, 2010, preceded by a 12-inch single of "Fresh"/"What We Do" on June 10. Devo was awarded the first Moog Innovator Award on October 29, during Moogfest 2010 in Asheville, North Carolina. The Moog Innovator Award has been said to celebrate "pioneering artists whose genre-defying work exemplifies the bold, innovative spirit of Bob Moog". Devo was scheduled to perform at Moogfest, but Bob Mothersbaugh severely injured his hand three days prior, and the band was forced to cancel. Mark Mothersbaugh and Gerald Casale collaborated with Austin-based band the Octopus Project to perform "Girl U Want" and "Beautiful World" at the event instead.

The band split from Warner Bros in 2012 and launched a new "post-Warner Brothers" website that would offer "new protective gear" and "unreleased material from the archives in vinyl disc format". In August of that year, the band released a single called "Don't Roof Rack Me, Bro (Seamus Unleashed)", dedicated to the Republican Party presidential candidate Mitt Romney's former pet dog Seamus. The title refers to the Mitt Romney dog incident of 1983, when Romney travelled twelve hours with the dog in a crate on his car's roof rack.

On June 24, 2013, the group's former drummer Alan Myers died of stomach cancer in Los Angeles, California. He was 58. News reports at the time of his death incorrectly cited brain cancer as the cause. One month later, Devo released their "Something Else for Everybody" album, which collected "Unreleased Demos and Focus Group Rejects" from 2006–2009. Gerald Casale had earlier teased the album in a 2012 interview with "Billboard" magazine.

On February 17, 2014, founding member Bob Casale died of heart failure at age 61. Shortly afterwards, the group, a quartet for the first time in 38 years, embarked on their Hardcore Devo Tour, a ten-show tour across the US and Canada between June 18 and July 2, 2014. The tour focused on material the group had written before the release of their first album, which was largely written when the group were a quartet. Partial proceeds for the ten shows went to support Bob Casale's family after his sudden death. The show featured the group performing material written during 1974–1977. The June 28 Oakland show was filmed and later released as the concert film "Hardcore Devo Live!", released on Blu-ray, DVD, and Video on Demand on February 10, 2015, accompanied by CD and double-vinyl audio releases.

Immediately following from the Hardcore tour, Devo continued to tour a 'greatest hits' style show. Josh Hager joined the band at this time, playing both keyboards and guitar. On April 29, 2016, Devo performed at Will Ferrell and Chad Smith's Red Hot Benefit.

On May 22, Robert Mothersbaugh Sr., father of Mark, Bob, and Jim Mothersbaugh, died. Robert portrayed General Boy in various Devo films.

In 2017, the official Twitter account for the "Are We Not Men?" documentary film, which had been in production since 2009, stated that "the film was finished years ago" and that "mm [Mark Mothersbaugh] is blocking its release". Jeff Winner, who was consulting producer for the Devo documentary, went on to state that he and director Tony Pemberton had "delivered the film that was contracted, and on schedule. It's now in the hands of the band to decide when/how it's released/distributed."

Devo headlined the Burger Boogaloo festival in Oakland, California, on June 30, 2018, with comedian and former Trenchmouth drummer Fred Armisen on drums. On October 12, 2020, Devo performed at the Desert Daze festival, with Jeff Friedl on drums.

In January 2021, Funko released two Devo Funko Pops inspired by the group's "Whip It" and "Satisfaction" music videos. One month later, the band starred in "Devolution: A Devo Theory", a television documentary based entirely on their theory of devolution, which had been completed in 2020. In September, Devo performed a short three-date tour of the USA, including a show at Riot Fest. These performances marked the return of Josh Freese on drums, who had not played live with Devo in over five years.

Shortly afterwards, Gerald Casale announced the release of an official Devo potato-based vodka through the Trust Me Vodka brand. The packaging for the drink was themed around Devo imagery and featured original artwork. It was signed by the group's co-founders Gerald Casale and Mark Mothersbaugh, as well as Bob Mothersbaugh.

On October 24, 2021, John Hinckley Jr posted on Twitter that he had not received any royalties for Devo's song "I Desire" in 35 years. "I Desire" had been written by Mark Mothersbaugh and Gerald Casale for their 1982 album "Oh, No! It's Devo", inspired by a poem written by Hinckley that was published in a tabloid newspaper, following his attempt to assassinate then-current president Ronald Reagan. Hinckley had been adequately credited for his contributions through a co-writing credit on all releases. Casale claimed that Devo were not at fault, as it was the publishing company's duty to pay him, not the band's.

Devotional 2021, an annual convention for Devo fans, was held on November 5–6, with the annual 5KDEVO race taking place on the 7th. On November 15, it was announced that Devo would perform a one-off show at the Rooftop at Pier 17 on May 18, 2022, in order to make up for their cancelled Radio City Music Hall gig in September 2021. Tickets went on sale on the 18th.

In December, it was announced that rare images of Devo would feature in a book of rock photography from 1977–1980 titled "HARD + FAST", to be released on February 1, 2022. The book will also include a 7-inch single of live recordings from the band, which were also released on SoundCloud prior to the book's release. The recordings were dated 1977, but the performances are identical to those found on an audience bootleg recorded on October 10, 1978.

Devo were nominated for induction into the Rock and Roll Hall of Fame in 2018, 2021 and 2022.

On May 14 and 15, 2022, Devo performed at the Cruel World Festival at the Rose Bowl's Brookside golf course in Pasadena, California, followed three days later by their performance at The Rooftop at Pier 17.

In a February 20, 2023, article by the "Akron Beacon Journal" promoting the film "Cocaine Bear", Mothersbaugh announced that 2023 would be celebrated as Devo's 50th anniversary, and that he had plans for Devo to remain active for 50 more years. He also stated that he, Gerald Casale and Bob Mothersbaugh were all interested in touring and jokingly wished for the remaining members of Devo to be buried in a car park near the Rock and Roll Hall of Fame. Two weeks later, Devo announced that they would perform at London's Eventim Apollo on August 19 as part of their "farewell tour". Other stops on the tour include the Øyafestivalen in Norway, Way Out West festival in Sweden, Flow Festival in Finland and Luna Fest in Portugal throughout August 2023. On March 1, a show at Green Man Festival in Wales was added to the tour.

On March 22, BMG, Fremantle Documentaries, and Warner Music Entertainment announced that they would be producing and financing a Chris Smith directed documentary titled "Devo". According to a statement by the band the film "explores Devo's evolution from hippie artistes to art-rockers with a message, to their unexpected mainstream success as a hit rock band and the pioneers of the MTV age." The film will follow the group's career arc up to its status as "elder statesmen". Smith is known for directing "American Movie", "Fyre", and executive producing "Tiger King", the latter of which was scored by Mark Mothersbaugh, with Bob Mothersbaugh co-scoring its first season.

The film will be produced by Chris Holmes and Anita Greenspan for Mutato Entertainment, and will be executive produced by William Kennedy, Stuart Souter, and Kathy Rivkin Daum for BMG, Mandy Chang for Fremantle, and at Warners, Charlie Cohen for WME and Mark Pinkus for Rhino Entertainment. As of these announcements, the film had entered production.

In April, Devo's energy domes were featured in Fat Mike's Punk Rock Museum.

On July 6, it was confirmed in a post made to the group's Instagram account that Jeff Friedl would play drums on their 2023 tour. This tour would be the group's last and as they retired from live performance, the compilation "Art Devo 1973–1977" and a documentary would be released.

At the 2024 Sundance Film Festival, a documentary about the band directed by Chris Smith was premiered.

Current members

Former members

Touring members

Studio albums



Dale Chihuly

Dale Chihuly () (born September 20, 1941) is an American glass artist and entrepreneur. He is well known in the field of blown glass, "moving it into the realm of large-scale sculpture".

Dale Patrick Chihuly was born on September 20, 1941, in Tacoma, Washington. His parents were George and Viola Chihuly; his paternal grandfather was born in Slovakia. In 1957, his older brother and only sibling George died in a Navy aviation training accident in Pensacola, Florida. In 1958, Chihuly's father died of a heart attack at the age of 51.

Chihuly had no interest in continuing his formal education after graduating from Woodrow Wilson High School in 1959. However, at his mother's urging, he enrolled at the College of Puget Sound. A year later, he transferred to the University of Washington in Seattle to study interior design. In 1961, he joined the Delta Kappa Epsilon fraternity (Kappa Epsilon chapter), and the same year he learned how to melt and fuse glass. In 1962, Chihuly dropped out of the university to study art in Florence. He later traveled to the Middle East where he met architect Robert Landsman. Their meeting and his time abroad spurred Chihuly to return to his studies. In 1963, he took a weaving class where he incorporated glass shards into tapestries. He received an award for his work from the Seattle Weavers Guild in 1964. Chihuly graduated from the University of Washington in 1965 with a Bachelor of Arts degree in interior design.

Chihuly began experimenting with glassblowing in 1965, and in 1966 he received a full scholarship to attend the University of Wisconsin–Madison. He studied under Harvey Littleton, who had established the first glass program in the United States at the university. In 1967, Chihuly received a Master of Science degree in sculpture. After graduating, he enrolled at the Rhode Island School of Design, where he met and became close friends with Italo Scanga. Chihuly earned a Master of Fine Arts degree in sculpture from the RISD in 1968. That same year, he was awarded a Louis Comfort Tiffany Foundation grant for his work in glass, as well as a Fulbright Fellowship. He traveled to Venice to work at the Venini factory on the island of Murano, where he first saw the team approach to blowing glass. After returning to the United States, Chihuly spent the first of four consecutive summers teaching at the Haystack Mountain School of Crafts in Deer Isle, Maine. In 1969, he traveled to Europe, in part to meet Erwin Eisch in Germany and Stanislav Libenský and Jaroslava Brychtová in Czechoslovakia.
Chihuly donated a portion of a large exhibit to his alma mater, the University of Wisconsin, in 1997 and it is on permanent display in the Kohl Center. In 2013 the university awarded him an Honorary Doctorate of Fine Arts.

In 1971, with the support of John Hauberg and Anne Gould Hauberg, Chihuly co-founded the Pilchuck Glass School near Stanwood, Washington. Chihuly also founded the HillTop Artists program in Tacoma, Washington at Hilltop Heritage Middle School and Wilson High School.

In 1976, while Chihuly was in England, he was involved in a head-on car accident that propelled him through the windshield. His face was severely cut by glass and he was blinded in his left eye. After recovering, he continued to blow glass until he dislocated his right shoulder in 1979 while bodysurfing.

In 1983, Chihuly returned to his native Pacific Northwest where he continued to develop his own work at the Pilchuck Glass School, which he had helped to found in 1971. No longer able to hold the glassblowing pipe, he hired others to do the work. Chihuly explained the change in a 2006 interview, saying "Once I stepped back, I liked the view", and said that it allowed him to see the work from more perspectives, enabling him to anticipate problems earlier. Chihuly's role has been described as "more choreographer than dancer, more supervisor than participant, more director than actor". "San Diego Union-Tribune" reporter Erin Glass wrote that she "wonders at the vision of not just the artist Chihuly, but the very successful entrepreneur Chihuly, whose estimated sales by 2004 was reported by "The Seattle Times" as $29 million."

Chihuly and his team of artists were the subjects of the documentary "." They were also featured in the documentary "Chihuly in the Hotshop," syndicated to public television stations by American Public Television starting on November 1, 2008.

In 2010, the Space Needle Corporation submitted a proposal for an exhibition of Chihuly's work at a site in the Seattle Center, in competition with proposals for other uses from several other groups. The project, which sees the new Chihuly exhibition hall occupy the site of the former Fun Forest amusement park in the Seattle Center park and entertainment complex, received the final approval from the Seattle City Council on April 25, 2011. Called Chihuly Garden and Glass, it opened May 21, 2012.

In 2006, Chihuly filed a lawsuit against his former longtime employee, glassblower Bryan Rubino, and businessman Robert Kaindl, claiming copyright and trademark infringement. Kaindl's pieces used titles Chihuly had employed for his own works, such as Seaforms and Ikebana, and resembled the construction of Chihuly's pieces. Legal experts stated that influence on art style did not constitute copyright infringement. Chihuly settled the lawsuit with Rubino initially, and later with Kaindl as well.

Regina Hackett, a "Seattle Post-Intelligencer" art critic, provided a chronology of Chihuly's work during the 1970s, 1980s, and 1990s:

For his exhibition in Jerusalem, in 1999–2000, in addition to the glass pieces, he had enormous blocks of transparent ice brought in from an Alaskan artesian well and formed a wall, echoing the stones of the nearby Citadel. Lights with color gels were set up behind them for illumination. Chihuly said the melting wall represented the "dissolution of barriers" between people. This exhibit holds the world record for most visitors to a temporary exhibit with more than 1.3 million visitors.

Chihuly's largest permanent exhibit is at the Oklahoma City Museum of Art. Other large collections can be found at the Morean Arts Center in St. Petersburg, Florida, and Chihuly Garden and Glass in Seattle, Washington.

Chihuly also maintains two retail stores in partnership with MGM Resorts International, one at the Bellagio on the Las Vegas Strip, and the other at the MGM Grand Casino in Macau.

Chihuly's art appears in over 400 permanent collections all over the world, including in the United States, Canada, England, Israel, China, Singapore, the United Arab Emirates, and Australia.




Dean Kamen

Dean Lawrence Kamen (born April 5, 1951) is an American engineer, inventor, and businessman. He is known for his invention of the Segway and iBOT, as well as founding the non-profit organization FIRST with Woodie Flowers. Kamen holds over 1,000 patents.

Kamen was born on Long Island, New York, to a Jewish family. 
His father was Jack Kamen, an illustrator for "Mad", "Weird Science" and other EC Comics publications. During his teenage years, Kamen was already being paid for his ideas; local bands and museums paid him to build light and sound systems. His annual earnings reached $60,000 before his high school graduation.

He attended Worcester Polytechnic Institute, but in 1976 quit before graduating, after five years of private advanced research for the insulin pump AutoSyringe.

Kamen is known best for inventing the product that eventually became known as the Segway PT, an electric, self-balancing human transporter with a computer-controlled gyroscopic stabilization and control system. The device is balanced on two parallel wheels and is controlled by moving body weight. The machine's development was the object of much speculation and hype after segments of a book quoting Steve Jobs and other notable information technology visionaries espousing its society-revolutionizing potential were leaked in December 2001.

Kamen was already a successful inventor: his company "Auto Syringe" manufactures and markets the first drug infusion pump. His company DEKA also holds patents for the technology used in portable dialysis machines, an insulin pump (based on the drug infusion pump technology), and an all-terrain electric wheelchair known as the iBOT, using many of the same gyroscopic balancing technologies that later made their way into the Segway.

Kamen has worked extensively on a project involving Stirling engine designs, attempting to create two machines: one that would generate power, and the Slingshot that would serve as a water purification system. He hopes the project will help improve living standards in developing countries. Kamen has a patent on his water purifier, and other patents pending. In 2014, the film "SlingShot" was released, detailing Kamen's quest to use his vapor compression distiller to fix the world's water crisis.

Kamen is also the co-inventor of a compressed air device that would launch a human into the air in order to quickly launch SWAT teams or other emergency workers to the roofs of tall, inaccessible buildings.

In 2009 Kamen stated that his company DEKA was now working on solar powered inventions.

Kamen and DEKA also developed the DEKA Arm System or "Luke", a prosthetic arm replacement that offers its user much more fine motor control than traditional prosthetic limbs. It was approved for use by the US Food and Drug Administration (FDA) in May 2014, and DEKA is looking for partners to mass-produce the prosthesis.

In 1989, Kamen founded FIRST (For Inspiration and Recognition of Science and Technology), an organization intended to build students' interests in science, technology, engineering, and mathematics (STEM). In 1992, working with MIT Professor Emeritus Woodie Flowers, Kamen created the FIRST Robotics Competition (FRC), which evolved into an international competition that by 2020 had drawn 3,647 teams and more than 91,000 students.

FIRST organizes robotics competition leagues for students in grades K-12, including FIRST LEGO League Discover for ages 4–6, FIRST LEGO League Explore for younger elementary school students, FIRST LEGO League Challenge for older elementary school and middle school students, FIRST Tech Challenge (FTC) for middle and high school students, and FIRST Robotics Competition (FRC) for high school students. In 2017, FIRST held its first Olympics-style competition – FGC (FIRST Global Challenge) – in Washington, D.C.

In 2010, Kamen called FIRST the invention he is most proud of, and said that 1 million students had taken part in the contests.

In 2017, Kamen founded the Advanced Regenerative Manufacturing Institute (ARMI) and launched BioFabUSA, a Manufacturing USA Innovation Institute with an $80 million grant from the Department of Defense. BioFabUSA's mission is to "..."make practical the large-scale manufacturing of engineered tissues and tissue-related technologies, to benefit existing industries and grow new ones"" In addition to DoD funding, Kamen brought together a consortium of private sector entities to form a public-private partnership which pledged $214M additional private dollars.

In early 2020, ARMI was awarded a grant from the Department of Health and Human Services to establish the first Foundry for American Biotechnology, known as NextFab "to produce technological solutions that help the United States protect against and respond to health security threats, enhance daily medical care, and add to the U.S. bioeconomy".

Kamen has won numerous awards. He was elected to the National Academy of Engineering in 1997 for inventing and commercializing biomedical devices and fluid measurement and control systems, and for popularizing engineering among young people. In 1999 he was awarded the 5th Annual Heinz Award in Technology, the Economy and Employment, and in 2000 received the National Medal of Technology from then President Clinton for inventions that have advanced medical care worldwide. In April 2002, Kamen was awarded the Lemelson-MIT Prize for inventors, for his invention of the Segway and of an infusion pump for diabetics. In 2003 his "Project Slingshot", an inexpensive portable water purification system, was named a runner-up for "coolest invention of 2003" by "Time" magazine.

In 2005 he was inducted into the National Inventors Hall of Fame for his invention of the AutoSyringe. In 2006 Kamen was awarded the "Global Humanitarian Action Award" by the United Nations. In 2007 he received the ASME Medal, the highest award from the American Society of Mechanical Engineers, in 2008 he was the recipient of the IRI Achievement Award from the Industrial Research Institute, and in 2011 Kamen was awarded the Benjamin Franklin Medal in Mechanical Engineering of the Franklin Institute.

Kamen received an honorary Doctor of Engineering degree from Worcester Polytechnic Institute in 1992, Rensselaer Polytechnic Institute May 17, 1996, a Doctor of Engineering degree from Kettering University in 2001, an honorary Doctor of Science degree from Clarkson University on May 13, 2001, an honorary "Doctor of Science" degree from the University of Arizona on May 16, 2009, and an honorary doctorate from the Wentworth Institute of Technology when he spoke at the college's centennial celebration in 2004, and other honorary doctorates from North Carolina State University in 2005, Bates College in 2007, the Georgia Institute of Technology in 2008, the Illinois Institute of Technology in 2008 the Plymouth State University in May 2008 and Rose-Hulman Institute of Technology in 2012. In 2015, Kamen received an honorary Doctor of Engineering and Technology degree from Yale University. In 2017, Kamen was honored with an institutional honorary degree from Université de Sherbrooke.

Kamen received the Stevens Honor Award on November 6, 2009, given by the Stevens Institute of Technology and the Stevens Alumni Association. On November 14, 2013, he received the James C. Morgan Global Humanitarian Award.

Kamen received the 2018 Public Service Award from the National Science Board, honoring his exemplary public service and contributions to the public's understanding of science and engineering.

In 2007, his residence was a hexagonal, shed style mansion he dubbed Westwind, located in Bedford, New Hampshire, just outside Manchester. The house has at least four levels and is very eclectically conceived, with such things as: hallways resembling mine shafts; 1960s novelty furniture; a collection of vintage wheelchairs; spiral staircases; at least one secret passage; an observation tower; a fully equipped machine shop; and a huge cast iron steam engine which once belonged to Henry Ford (built into the multi-story center atrium of the house) which Kamen is working to convert into a Stirling engine-powered kinetic sculpture. Kamen owns and pilots an Embraer Phenom 300 light jet aircraft and three Enstrom helicopters, including a 280FX, a 480, and a 480B. He regularly commutes to work via his helicopters and had a hangar built into his house. In 2016 he flew as a passenger in a B-2 Spirit bomber at Whiteman AFB, marking the opening of the 2016 FRC World Championship in St. Louis.

He is the main subject of "Code Name Ginger: the Story Behind Segway and Dean Kamen's Quest to Invent a New World", a nonfiction narrative book by journalist Steve Kemper published by Harvard Business School Press in 2003 (released in paperback as "Reinventing the Wheel").

His company, DEKA, annually creates intricate mechanical presents for him. The company has created a robotic chess player, which is a mechanical arm attached to a chess board, and a vintage-looking computer with antique wood, and a converted typewriter as a keyboard. In addition, DEKA has received funding from DARPA to work on a brain-controlled prosthetic limb called the Luke Arm.

Kamen is a member of the USA Science and Engineering Festival's Advisory Board and is also a member of the Xconomists, an ad hoc team of editorial advisors for the tech news and media company, Xconomy. He is also on the Board of Trustees of the X Prize Foundation.

"Dean of Invention", a TV show on Planet Green, premiered on October 22, 2010. It starred Kamen and correspondent Joanne Colan, in which they investigate new technologies,

Kamen was a keynote speaker at the 2015 Congress of Future Science and Technology Leaders.

In the 2016 New Hampshire Senate election, Kamen endorsed Kelly Ayotte, appearing in an ad supporting her. 



Derivative (finance)

In finance, a derivative is a contract that "derives" its value from the performance of an underlying entity. This underlying entity can be an asset, index, or interest rate, and is often simply called the underlying. Derivatives can be used for a number of purposes, including insuring against price movements (hedging), increasing exposure to price movements for speculation, or getting access to otherwise hard-to-trade assets or markets.

Some of the more common derivatives include forwards, futures, options, swaps, and variations of these such as synthetic collateralized debt obligations and credit default swaps. Most derivatives are traded over-the-counter (off-exchange) or on an exchange such as the Chicago Mercantile Exchange, while most insurance contracts have developed into a separate industry. In the United States, after the financial crisis of 2007–2009, there has been increased pressure to move derivatives to trade on exchanges.

Derivatives are one of the three main categories of financial instruments, the other two being equity (i.e., stocks or shares) and debt (i.e., bonds and mortgages). The oldest example of a derivative in history, attested to by Aristotle, is thought to be a contract transaction of olives, entered into by ancient Greek philosopher Thales, who made a profit in the exchange. However, Aristotle did not define this arrangement as a derivative but as a monopoly (Aristotle's Politics, Book I, Chapter XI). Bucket shops, outlawed in 1936 in the US, are a more recent historical example.

Derivatives are contracts between two parties that specify conditions (especially the dates, resulting values and definitions of the underlying variables, the parties' contractual obligations, and the notional amount) under which payments are to be made between the parties. The assets include commodities, stocks, bonds, interest rates and currencies, but they can also be other derivatives, which adds another layer of complexity to proper valuation. The components of a firm's capital structure, e.g., bonds and stock, can also be considered derivatives, more precisely options, with the underlying being the firm's assets, but this is unusual outside of technical contexts.

From the economic point of view, financial derivatives are cash flows that are conditioned stochastically and discounted to present value. The market risk inherent in the underlying asset is attached to the financial derivative through contractual agreements and hence can be traded separately. The underlying asset does not have to be acquired. Derivatives therefore allow the breakup of ownership and participation in the market value of an asset. This also provides a considerable amount of freedom regarding the contract design. That contractual freedom allows derivative designers to modify the participation in the performance of the underlying asset almost arbitrarily. Thus, the participation in the market value of the underlying can be effectively weaker, stronger (leverage effect), or implemented as inverse. Hence, specifically the market price risk of the underlying asset can be controlled in almost every situation.

There are two groups of derivative contracts: the privately traded over-the-counter (OTC) derivatives such as swaps that do not go through an exchange or other intermediary, and exchange-traded derivatives (ETD) that are traded through specialized derivatives exchanges or other exchanges.

Derivatives are more common in the modern era, but their origins trace back several centuries. One of the oldest derivatives is rice futures, which have been traded on the Dojima Rice Exchange since the eighteenth century. Derivatives are broadly categorized by the relationship between the underlying asset and the derivative (such as forward, option, swap); the type of underlying asset (such as equity derivatives, foreign exchange derivatives, interest rate derivatives, commodity derivatives, or credit derivatives); the market in which they trade (such as exchange-traded or over-the-counter); and their pay-off profile.

Derivatives may broadly be categorized as "lock" or "option" products. Lock products (such as swaps, futures, or forwards) obligate the contractual parties to the terms over the life of the contract. Option products (such as interest rate swaps) provide the buyer the right, but not the obligation to enter the contract under the terms specified.

Derivatives can be used either for risk management (i.e. to "hedge" by providing offsetting compensation in case of an undesired event, a kind of "insurance") or for speculation (i.e. making a financial "bet"). This distinction is important because the former is a prudent aspect of operations and financial management for many firms across many industries; the latter offers managers and investors a risky opportunity to increase profit, which may not be properly disclosed to stakeholders.

Along with many other financial products and services, derivatives reform is an element of the Dodd–Frank Wall Street Reform and Consumer Protection Act of 2010. The Act delegated many rule-making details of regulatory oversight to the Commodity Futures Trading Commission (CFTC) and those details are not finalized nor fully implemented as of late 2012.

To give an idea of the size of the derivative market, "The Economist" has reported that as of June 2011, the over-the-counter (OTC) derivatives market amounted to approximately $700 trillion, and the size of the market traded on exchanges totaled an additional $83 trillion. For the fourth quarter 2017 the European Securities Market Authority estimated the size of European derivatives market at a size of €660 trillion with 74 million outstanding contracts.

However, these are "notional" values, and some economists say that these aggregated values greatly exaggerate the market value and the true credit risk faced by the parties involved. For example, in 2010, while the aggregate of OTC derivatives exceeded $600 trillion, the value of the market was estimated to be much lower, at $21 trillion. The credit-risk equivalent of the derivative contracts was estimated at $3.3 trillion.

Still, even these scaled-down figures represent huge amounts of money. For perspective, the budget for total expenditure of the United States government during 2012 was $3.5 trillion, and the total current value of the U.S. stock market is an estimated $23 trillion. Meanwhile, the global annual Gross Domestic Product is about $65 trillion.

At least for one type of derivative, credit default swaps (CDS), for which the inherent risk is considered high , the higher, nominal value remains relevant. It was this type of derivative that investment magnate Warren Buffett referred to in his famous 2002 speech in which he warned against "financial weapons of mass destruction". CDS notional value in early 2012 amounted to $25.5 trillion, down from $55 trillion in 2008.

Derivatives are used for the following:

Lock products are theoretically valued at zero at the time of execution and thus do not typically require an up-front exchange between the parties. Based upon movements in the underlying asset over time, however, the value of the contract will fluctuate, and the derivative may be either an asset (i.e., "in the money") or a liability (i.e., "out of the money") at different points throughout its life. Importantly, either party is therefore exposed to the credit quality of its counterparty and is interested in protecting itself in an event of default.

Option products have immediate value at the outset because they provide specified protection (intrinsic value) over a given time period (time value). One common form of option product familiar to many consumers is insurance for homes and automobiles. The insured would pay more for a policy with greater liability protections (intrinsic value) and one that extends for a year rather than six months (time value). Because of the immediate option value, the option purchaser typically pays an up front premium. Just like for lock products, movements in the underlying asset will cause the option's intrinsic value to change over time while its time value deteriorates steadily until the contract expires. An important difference between a lock product is that, after the initial exchange, the option purchaser has no further liability to its counterparty; upon maturity, the purchaser will execute the option if it has positive value (i.e., if it is "in the money") or expire at no cost (other than to the initial premium) (i.e., if the option is "out of the money").

Derivatives allow risk related to the price of the underlying asset to be transferred from one party to another. For example, a wheat farmer and a miller could sign a futures contract to exchange a specified amount of cash for a specified amount of wheat in the future. Both parties have reduced a future risk: for the wheat farmer, the uncertainty of the price, and for the miller, the availability of wheat. However, there is still the risk that no wheat will be available because of events unspecified by the contract, such as the weather, or that one party will renege on the contract. Although a third party, called a clearing house, insures a futures contract, not all derivatives are insured against counter-party risk.

From another perspective, the farmer and the miller both reduce a risk and acquire a risk when they sign the futures contract: the farmer reduces the risk that the price of wheat will fall below the price specified in the contract and acquires the risk that the price of wheat will rise above the price specified in the contract (thereby losing additional income that he could have earned). The miller, on the other hand, acquires the risk that the price of wheat will fall below the price specified in the contract (thereby paying more in the future than he otherwise would have) and reduces the risk that the price of wheat will rise above the price specified in the contract. In this sense, one party is the insurer (risk taker) for one type of risk, and the counter-party is the insurer (risk taker) for another type of risk.

Hedging also occurs when an individual or institution buys an asset (such as a commodity, a bond that has coupon payments, a stock that pays dividends, and so on) and sells it using a futures contract. The individual or institution has access to the asset for a specified amount of time, and can then sell it in the future at a specified price according to the futures contract. Of course, this allows the individual or institution the benefit of holding the asset, while reducing the risk that the future selling price will deviate unexpectedly from the market's current assessment of the future value of the asset.
Derivatives trading of this kind may serve the financial interests of certain particular businesses. For example, a corporation borrows a large sum of money at a specific interest rate. The interest rate on the loan reprices every six months. The corporation is concerned that the rate of interest may be much higher in six months. The corporation could buy a forward rate agreement (FRA), which is a contract to pay a fixed rate of interest six months after purchases on a notional amount of money. If the interest rate after six months is above the contract rate, the seller will pay the difference to the corporation, or FRA buyer. If the rate is lower, the corporation will pay the difference to the seller. The purchase of the FRA serves to reduce the uncertainty concerning the rate increase and stabilize earnings.

Derivatives can be used to acquire risk, rather than to hedge against risk. Thus, some individuals and institutions will enter into a derivative contract to speculate on the value of the underlying asset. Speculators look to buy an asset in the future at a low price according to a derivative contract when the future market price is high, or to sell an asset in the future at a high price according to a derivative contract when the future market price is less.

Speculative trading in derivatives gained a great deal of notoriety in 1995 when Nick Leeson, a trader at Barings Bank, made poor and unauthorized investments in futures contracts. Through a combination of poor judgment, lack of oversight by the bank's management and regulators, and unfortunate events like the Kobe earthquake, Leeson incurred a $1.3 billion loss that bankrupted the centuries-old institution.

Individuals and institutions may also look for arbitrage opportunities, as when the current buying price of an asset falls below the price specified in a futures contract to sell the asset.

The true proportion of derivatives contracts used for hedging purposes is unknown, but it appears to be relatively small. Also, derivatives contracts account for only 3–6% of the median firms' total currency and interest rate exposure. Nonetheless, we know that many firms' derivatives activities have at least some speculative component for a variety of reasons.

In broad terms, there are two groups of derivative contracts, which are distinguished by the way they are traded in the market:

Over-the-counter (OTC) derivatives are contracts that are traded (and privately negotiated) directly between two parties, without going through an exchange or other intermediary. Products such as swaps, forward rate agreements, exotic options – and other exotic derivatives – are almost always traded in this way. The OTC derivative market is the largest market for derivatives, and is largely unregulated with respect to disclosure of information between the parties, since the OTC market is made up of banks and other highly sophisticated parties, such as hedge funds. Reporting of OTC amounts is difficult because trades can occur in private, without activity being visible on any exchanges

According to the Bank for International Settlements, who first surveyed OTC derivatives in 1995, reported that the "gross market value, which represent the cost of replacing all open contracts at the prevailing market prices, ... increased by 74% since 2004, to $11 trillion at the end of June 2007 (BIS 2007:24)." Positions in the OTC derivatives market increased to $516 trillion at the end of June 2007, 135% higher than the level recorded in 2004. The total outstanding notional amount is US$708 trillion (as of June 2011). Of this total notional amount, 67% are interest rate contracts, 8% are credit default swaps (CDS), 9% are foreign exchange contracts, 2% are commodity contracts, 1% are equity contracts, and 12% are other. Because OTC derivatives are not traded on an exchange, there is no central counter-party. Therefore, they are subject to counterparty risk, like an ordinary contract, since each counter-party relies on the other to perform.

Exchange-traded derivatives (ETD) are those derivatives instruments that are traded via specialized derivatives exchanges or other exchanges. A derivatives exchange is a market where individuals trade standardized contracts that have been defined by the exchange. A derivatives exchange acts as an intermediary to all related transactions, and takes initial margin from both sides of the trade to act as a guarantee. The world's largest derivatives exchanges (by number of transactions) are the Korea Exchange (which lists KOSPI Index Futures & Options), Eurex (which lists a wide range of European products such as interest rate & index products), and CME Group (made up of the 2007 merger of the Chicago Mercantile Exchange and the Chicago Board of Trade and the 2008 acquisition of the New York Mercantile Exchange). According to BIS, the combined turnover in the world's derivatives exchanges totaled US$344 trillion during Q4 2005. By December 2007 the Bank for International Settlements reported that "derivatives traded on exchanges surged 27% to a record $681 trillion."

Inverse exchange-traded funds (IETFs) and leveraged exchange-traded funds (LETFs) are two special types of exchange traded funds (ETFs) that are available to common traders and investors on major exchanges like the NYSE and Nasdaq. To maintain these products' net asset value, these funds' administrators must employ more sophisticated financial engineering methods than what's usually required for maintenance of traditional ETFs. These instruments must also be regularly rebalanced and re-indexed each day.

Some of the common variants of derivative contracts are as follows:
Some common examples of these derivatives are the following:

A collateralized debt obligation (CDO) is a type of structured asset-backed security (ABS). An "asset-backed security" is used as an umbrella term for a type of security backed by a pool of assets—including collateralized debt obligations and mortgage-backed securities (MBS) (Example: "The capital market in which asset-backed securities are issued and traded is composed of three main categories: ABS, MBS and CDOs".)—and sometimes for a particular type of that security—one backed by consumer loans (example: "As a rule of thumb, securitization issues backed by mortgages are called MBS, and securitization issues backed by debt obligations are called CDO, [and] Securitization issues backed by consumer-backed products—car loans, consumer loans and credit cards, among others—are called ABS.) Originally developed for the corporate debt markets, over time CDOs evolved to encompass the mortgage and mortgage-backed security (MBS) markets.

Like other private-label securities backed by assets, a CDO can be thought of as a promise to pay investors in a prescribed sequence, based on the cash flow the CDO collects from the pool of bonds or other assets it owns. The CDO is "sliced" into "tranches", which "catch" the cash flow of interest and principal payments in sequence based on seniority. If some loans default and the cash collected by the CDO is insufficient to pay all of its investors, those in the lowest, most "junior" tranches suffer losses first. The last to lose payment from default are the safest, most senior tranches. Consequently, coupon payments (and interest rates) vary by tranche with the safest/most senior tranches paying the lowest and the lowest tranches paying the highest rates to compensate for higher default risk. As an example, a CDO might issue the following tranches in order of safeness: Senior AAA (sometimes known as "super senior"); Junior AAA; AA; A; BBB; Residual.

Separate special-purpose entities—rather than the parent investment bank—issue the CDOs and pay interest to investors. As CDOs developed, some sponsors repackaged tranches into yet another iteration called "CDO-Squared" or the "CDOs of CDOs". 
In the early 2000s, CDOs were generally diversified, but by 2006–2007—when the CDO market grew to hundreds of billions of dollars—this changed. CDO collateral became dominated not by loans, but by lower level (BBB or A) tranches recycled from other asset-backed securities, whose assets were usually non-prime mortgages. These CDOs have been called "the engine that powered the mortgage supply chain" for nonprime mortgages, and are credited with giving lenders greater incentive to make non-prime loans leading up to the 2007-9 subprime mortgage crisis.

A credit default swap (CDS) is a financial swap agreement that the seller of the CDS will compensate the buyer (the creditor of the reference loan) in the event of a loan default (by the debtor) or other credit event. The buyer of the CDS makes a series of payments (the CDS "fee" or "spread") to the seller and, in exchange, receives a payoff if the loan defaults. It was invented by Blythe Masters from JP Morgan in 1994.
In the event of default the buyer of the CDS receives compensation (usually the face value of the loan), and the seller of the CDS takes possession of the defaulted loan. However, anyone with sufficient collateral to trade with a bank or hedge fund can purchase a CDS, even buyers who do not hold the loan instrument and who have no direct insurable interest in the loan (these are called "naked" CDSs). If there are more CDS contracts outstanding than bonds in existence, a protocol exists to hold a credit event auction; the payment received is usually substantially less than the face value of the loan.
Credit default swaps have existed since the early 1990s, and increased in use after 2003. By the end of 2007, the outstanding CDS amount was $62.2 trillion, falling to $26.3 trillion by mid-year 2010 but reportedly $25.5 trillion in early 2012. CDSs are not traded on an exchange and there is no required reporting of transactions to a government agency. During the 2007–2010 financial crisis the lack of transparency in this large market became a concern to regulators as it could pose a systemic risk.

CDS data can be used by financial professionals, regulators, and the media to monitor how the market views credit risk of any entity on which a CDS is available, which can be compared to that provided by credit rating agencies. U.S. courts may soon be following suit.
Most CDSs are documented using standard forms drafted by the International Swaps and Derivatives Association (ISDA), although there are many variants. In addition to the basic, single-name swaps, there are basket default swaps (BDSs), index CDSs, funded CDSs (also called credit-linked notes), as well as loan-only credit default swaps (LCDS). In addition to corporations and governments, the reference entity can include a special-purpose vehicle issuing asset-backed securities.
Some claim that derivatives such as CDS are potentially dangerous in that they combine priority in bankruptcy with a lack of transparency. A CDS can be unsecured (without collateral) and be at higher risk for a default.

In finance, a forward contract or simply a forward is a non-standardized contract between two parties to buy or to sell an asset at a specified future time at an amount agreed upon today, making it a type of derivative instrument. This is in contrast to a spot contract, which is an agreement to buy or sell an asset on its spot date, which may vary depending on the instrument, for example most of the FX contracts have Spot Date two business days from today. The party agreeing to buy the underlying asset in the future assumes a long position, and the party agreeing to sell the asset in the future assumes a short position. The price agreed upon is called the delivery price, which is equal to the forward price at the time the contract is entered into.
The price of the underlying instrument, in whatever form, is paid before control of the instrument changes. This is one of the many forms of buy/sell orders where the time and date of trade is not the same as the value date where the securities themselves are exchanged.

The forward price of such a contract is commonly contrasted with the spot price, which is the price at which the asset changes hands on the spot date. The difference between the spot and the forward price is the forward premium or forward discount, generally considered in the form of a profit, or loss, by the purchasing party. Forwards, like other derivative securities, can be used to hedge risk (typically currency or exchange rate risk), as a means of speculation, or to allow a party to take advantage of a quality of the underlying instrument which is time-sensitive.

A closely related contract is a futures contract; they differ in certain respects. Forward contracts are very similar to futures contracts, except they are not exchange-traded, or defined on standardized assets. Forwards also typically have no interim partial settlements or "true-ups" in margin requirements like futures—such that the parties do not exchange additional property securing the party at gain and the entire unrealized gain or loss builds up while the contract is open. However, being traded over the counter (OTC), forward contracts specification can be customized and may include mark-to-market and daily margin calls. Hence, a forward contract arrangement might call for the loss party to pledge collateral or additional collateral to better secure the party at gain. In other words, the terms of the forward contract will determine the collateral calls based upon certain "trigger" events relevant to a particular counterparty such as among other things, credit ratings, value of assets under management or redemptions over a specific time frame (e.g., quarterly, annually).

In finance, a 'futures contract' (more colloquially, futures) is a standardized contract between two parties to buy or sell a specified asset of standardized quantity and quality for a price agreed upon today (the "futures price") with delivery and payment occurring at a specified future date, the "delivery date", making it a derivative product (i.e. a financial product that is derived from an underlying asset). The contracts are negotiated at a futures exchange, which acts as an intermediary between buyer and seller. The party agreeing to buy the underlying asset in the future, the "buyer" of the contract, is said to be "long", and the party agreeing to sell the asset in the future, the "seller" of the contract, is said to be "short".

While the futures contract specifies a trade taking place in the future, the purpose of the futures exchange is to act as intermediary and mitigate the risk of default by either party in the intervening period. For this reason, the futures exchange requires both parties to put up an initial amount of cash (performance bond), the margin. Margins, sometimes set as a percentage of the value of the futures contract, need to be proportionally maintained at all times during the life of the contract to underpin this mitigation because the price of the contract will vary in keeping with supply and demand and will change daily and thus one party or the other will theoretically be making or losing money. To mitigate risk and the possibility of default by either party, the product is marked to market on a daily basis whereby the difference between the prior agreed-upon price and the actual daily futures price is settled on a daily basis. This is sometimes known as the variation margin where the futures exchange will draw money out of the losing party's margin account and put it into the other party's thus ensuring that the correct daily loss or profit is reflected in the respective account. If the margin account goes below a certain value set by the Exchange, then a margin call is made and the account owner must replenish the margin account. This process is known as "marking to market". Thus on the delivery date, the amount exchanged is not the specified price on the contract but the spot value (i.e., the original value agreed upon, since any gain or loss has already been previously settled by marking to market). Upon marketing the strike price is often reached and creates much income for the "caller".

A closely related contract is a forward contract. A forward is like a futures in that it specifies the exchange of goods for a specified price at a specified future date. However, a forward is not traded on an exchange and thus does not have the interim partial payments due to marking to market. Nor is the contract standardized, as on the exchange.
Unlike an option, both parties of a futures contract must fulfill the contract on the delivery date. The seller delivers the underlying asset to the buyer, or, if it is a cash-settled futures contract, then cash is transferred from the futures trader who sustained a loss to the one who made a profit. To exit the commitment prior to the settlement date, the holder of a futures position can close out its contract obligations by taking the opposite position on another futures contract on the same asset and settlement date. The difference in futures prices is then a profit or loss.

A mortgage-backed security (MBS) is an asset-backed security that is secured by a mortgage, or more commonly a collection ("pool") of sometimes hundreds of mortgages. The mortgages are sold to a group of individuals (a government agency or investment bank) that "securitizes", or packages, the loans together into a security that can be sold to investors. The mortgages of an MBS may be residential or commercial, depending on whether it is an Agency MBS or a Non-Agency MBS; in the United States they may be issued by structures set up by government-sponsored enterprises like Fannie Mae or Freddie Mac, or they can be "private-label", issued by structures set up by investment banks. The structure of the MBS may be known as "pass-through", where the interest and principal payments from the borrower or homebuyer pass through it to the MBS holder, or it may be more complex, made up of a pool of other MBSs. Other types of MBS include collateralized mortgage obligations (CMOs, often structured as real estate mortgage investment conduits) and collateralized debt obligations (CDOs).

The shares of subprime MBSs issued by various structures, such as CMOs, are not identical but rather issued as tranches (French for "slices"), each with a different level of priority in the debt repayment stream, giving them different levels of risk and reward. Tranches—especially the lower-priority, higher-interest tranches—of an MBS are/were often further repackaged and resold as collaterized debt obligations. These subprime MBSs issued by investment banks were a major issue in the subprime mortgage crisis of 2006–2008
The total face value of an MBS decreases over time, because like mortgages, and unlike bonds, and most other fixed-income securities, the principal in an MBS is not paid back as a single payment to the bond holder at maturity but rather is paid along with the interest in each periodic payment (monthly, quarterly, etc.). This decrease in face value is measured by the MBS's "factor", the percentage of the original "face" that remains to be repaid.

In finance, an option is a contract which gives the "buyer" (the owner) the right, but not the obligation, to buy or sell an underlying asset or instrument at a specified strike price on or before a specified date. The "seller" has the corresponding obligation to fulfill the transaction—that is to sell or buy—if the buyer (owner) "exercises" the option. The buyer pays a premium to the seller for this right. An option that conveys to the owner the right to buy something at a certain price is a "call option"; an option that conveys the right of the owner to sell something at a certain price is a "put option". Both are commonly traded, but for clarity, the call option is more frequently discussed.
Options valuation is a topic of ongoing research in academic and practical finance. In basic terms, the value of an option is commonly decomposed into two parts:

Although options valuation has been studied since the 19th century, the contemporary approach is based on the Black–Scholes model, which was first published in 1973.

Options contracts have been known for many centuries. However, both trading activity and academic interest increased when, as from 1973, options were issued with standardized terms and traded through a guaranteed clearing house at the Chicago Board Options Exchange. Today, many options are created in a standardized form and traded through clearing houses on regulated options exchanges, while other over-the-counter options are written as bilateral, customized contracts between a single buyer and seller, one or both of which may be a dealer or market-maker. Options are part of a larger class of financial instruments known as derivative products or simply derivatives.

A swap is a derivative in which two counterparties exchange cash flows of one party's financial instrument for those of the other party's financial instrument. The benefits in question depend on the type of financial instruments involved. For example, in the case of a swap involving two bonds, the benefits in question can be the periodic interest (coupon) payments associated with such bonds. Specifically, two counterparties agree to the exchange one stream of cash flows against another stream. These streams are called the swap's "legs". The swap agreement defines the dates when the cash flows are to be paid and the way they are accrued and calculated. Usually at the time when the contract is initiated, at least one of these series of cash flows is determined by an uncertain variable such as a floating interest rate, foreign exchange rate, equity price, or commodity price.

The cash flows are calculated over a notional principal amount. Contrary to a future, a forward or an option, the notional amount is usually not exchanged between counterparties. Consequently, swaps can be in cash or collateral.
Swaps can be used to hedge certain risks such as interest rate risk, or to speculate on changes in the expected direction of underlying prices.

Swaps were first introduced to the public in 1981 when IBM and the World Bank entered into a swap agreement. Today, swaps are among the most heavily traded financial contracts in the world: the total amount of interest rates and currency swaps outstanding is more than $348 trillion in 2010, according to the Bank for International Settlements (BIS). The five generic types of swaps, in order of their quantitative importance, are: interest rate swaps, currency swaps, credit swaps, commodity swaps and equity swaps (there are many other types).

Some of the salient economic functions of the derivative market include:
In a nutshell, there is a substantial increase in savings and investment in the long run due to augmented activities by derivative market participant.

Two common measures of value are:

For exchange-traded derivatives, market price is usually transparent (often published in real time by the exchange, based on all the current bids and offers placed on that particular contract at any one time). Complications can arise with OTC or floor-traded contracts though, as trading is handled manually, making it difficult to automatically broadcast prices. In particular with OTC contracts, there is no central exchange to collate and disseminate prices.

The arbitrage-free price for a derivatives contract can be complex, and there are many different variables to consider. Arbitrage-free pricing is a central topic of financial mathematics. For futures/forwards the arbitrage free price is relatively straightforward, involving the price of the underlying together with the cost of carry (income received less interest costs), although there can be complexities.

However, for options and more complex derivatives, pricing involves developing a complex pricing model: understanding the stochastic process of the price of the underlying asset is often crucial. A key equation for the theoretical valuation of options is the Black–Scholes formula, which is based on the assumption that the cash flows from a European stock option can be replicated by a continuous buying and selling strategy using only the stock. A simplified version of this valuation technique is the binomial options model.

OTC represents the biggest challenge in using models to price derivatives. Since these contracts are not publicly traded, no market price is available to validate the theoretical valuation. Most of the model's results are input-dependent (meaning the final price depends heavily on how we derive the pricing inputs).
Therefore, it is common that OTC derivatives are priced by Independent Agents that both counterparties involved in the deal designate upfront (when signing the contract).

Derivatives are often subject to the following criticisms; particularly since the Financial crisis of 2007–2008, the discipline of Risk management has developed attempting to address the below and other risks - see .

According to Raghuram Rajan, a former chief economist of the International Monetary Fund (IMF), "... it may well be that the managers of these firms [investment funds] have figured out the correlations between the various instruments they hold and believe they are hedged. Yet as Chan and others (2005) point out, the lessons of summer 1998 following the default on Russian government debt is that correlations that are zero or negative in normal times can turn overnight to one – a phenomenon they term "phase lock-in". A hedged position "can become unhedged at the worst times, inflicting substantial losses on those who mistakenly believe they are protected".
See the FRTB framework, which seeks to address this to some extent.

The use of derivatives can result in large losses because of the use of leverage, or borrowing. Derivatives allow investors to earn large returns from small movements in the underlying asset's price. However, investors could lose large amounts if the price of the underlying moves against them significantly. There have been several instances of massive losses in derivative markets, such as the following:

Derivatives typically have a large notional value. As such, there is the danger that their use could result in losses for which the investor would be unable to compensate. The possibility that this could lead to a chain reaction ensuing in an economic crisis was pointed out by famed investor Warren Buffett in Berkshire Hathaway's 2002 annual report. Buffett called them 'financial weapons of mass destruction.' A potential problem with derivatives is that they comprise an increasingly larger notional amount of assets which may lead to distortions in the underlying capital and equities markets themselves. Investors begin to look at the derivatives markets to make a decision to buy or sell securities and so what was originally meant to be a market to transfer risk now becomes a leading indicator.(See Berkshire Hathaway Annual Report for 2002)

Some derivatives (especially swaps) expose investors to counterparty risk, or risk arising from the other party in a financial transaction. Counterparty risk results from the differences in the current price versus the expected future settlement price. Different types of derivatives have different levels of counter party risk. For example, standardized stock options by law require the party at risk to have a certain amount deposited with the exchange, showing that they can pay for any losses; banks that help businesses swap variable for fixed rates on loans may do credit checks on both parties. However, in private agreements between two companies, for example, there may not be benchmarks for performing due diligence and risk analysis.

Under US law and the laws of most other developed countries, derivatives have special legal exemptions that make them a particularly attractive legal form to extend credit. The strong creditor protections afforded to derivatives counterparties, in combination with their complexity and lack of transparency however, can cause capital markets to underprice credit risk. This can contribute to credit booms, and increase systemic risks. Indeed, the use of derivatives to conceal credit risk from third parties while protecting derivative counterparties contributed to the financial crisis of 2008 in the United States.

In the context of a 2010 examination of the ICE Trust, an industry self-regulatory body, Gary Gensler, the chairman of the Commodity Futures Trading Commission which regulates most derivatives, was quoted saying that the derivatives marketplace as it functions now "adds up to higher costs to all Americans". More oversight of the banks in this market is needed, he also said. Additionally, the report said, "[t]he Department of Justice is looking into derivatives, too. The department's antitrust unit is actively investigating 'the possibility of anticompetitive practices in the credit derivatives clearing, trading and information services industries', according to a department spokeswoman."

For legislators and committees responsible for financial reform related to derivatives in the United States and elsewhere, distinguishing between hedging and speculative derivatives activities has been a nontrivial challenge. The distinction is critical because regulation should help to isolate and curtail speculation with derivatives, especially for "systemically significant" institutions whose default could be large enough to threaten the entire financial system. At the same time, the legislation should allow for responsible parties to hedge risk without unduly tying up working capital as collateral that firms may better employ elsewhere in their operations and investment. 
In this regard, it is important to distinguish between financial (e.g. banks) and non-financial end-users of derivatives (e.g. real estate development companies) because these firms' derivatives usage is inherently different. More importantly, the reasonable collateral that secures these different counterparties can be very different. The distinction between these firms is not always straight forward (e.g. hedge funds or even some private equity firms do not neatly fit either category). Finally, even financial users must be differentiated, as 'large' banks may classified as "systemically significant" whose derivatives activities must be more tightly monitored and restricted than those of smaller, local and regional banks.

Over-the-counter dealing will be less common as the Dodd–Frank Wall Street Reform and Consumer Protection Act comes into effect. The law mandated the clearing of certain swaps at registered exchanges and imposed various restrictions on derivatives. To implement Dodd-Frank, the CFTC developed new rules in at least 30 areas. The Commission determines which swaps are subject to mandatory clearing and whether a derivatives exchange is eligible to clear a certain type of swap contract.

Nonetheless, the above and other challenges of the rule-making process have delayed full enactment of aspects of the legislation relating to derivatives. The challenges are further complicated by the necessity to orchestrate globalized financial reform among the nations that comprise the world's major financial markets, a primary responsibility of the Financial Stability Board whose progress is ongoing.

In the U.S., by February 2012 the combined effort of the SEC and CFTC had produced over 70 proposed and final derivatives rules. However, both of them had delayed adoption of a number of derivatives regulations because of the burden of other rulemaking, litigation and opposition to the rules, and many core definitions (such as the terms "swap", "security-based swap", "swap dealer", "security-based swap dealer", "major swap participant" and "major security-based swap participant") had still not been adopted. SEC Chairman Mary Schapiro opined: "At the end of the day, it probably does not make sense to harmonize everything [between the SEC and CFTC rules] because some of these products are quite different and certainly the market structures are quite different." On February 11, 2015, the Securities and Exchange Commission (SEC) released two final rules toward establishing a reporting and public disclosure framework for security-based swap transaction data. The two rules are not completely harmonized with the requirements with CFTC requirements.
In November 2012, the SEC and regulators from Australia, Brazil, the European Union, Hong Kong, Japan, Ontario, Quebec, Singapore, and Switzerland met to discuss reforming the OTC derivatives market, as had been agreed by leaders at the 2009 G-20 Pittsburgh summit in September 2009. In December 2012, they released a joint statement to the effect that they recognized that the market is a global one and "firmly support the adoption and enforcement of robust and consistent standards in and across jurisdictions", with the goals of mitigating risk, improving transparency, protecting against market abuse, preventing regulatory gaps, reducing the potential for arbitrage opportunities, and fostering a level playing field for market participants. They also agreed on the need to reduce regulatory uncertainty and provide market participants with sufficient clarity on laws and regulations by avoiding, to the extent possible, the application of conflicting rules to the same entities and transactions, and minimizing the application of inconsistent and duplicative rules. At the same time, they noted that "complete harmonization – perfect alignment of rules across jurisdictions" would be difficult, because of jurisdictions' differences in law, policy, markets, implementation timing, and legislative and regulatory processes.

On December 20, 2013 the CFTC provided information on its swaps regulation "comparability" determinations. The release addressed the CFTC's cross-border compliance exceptions. Specifically it addressed which entity level and in some cases transaction-level requirements in six jurisdictions (Australia, Canada, the European Union, Hong Kong, Japan, and Switzerland) it found comparable to its own rules, thus permitting non-US swap dealers, major swap participants, and the foreign branches of US Swap Dealers and major swap participants in these jurisdictions to comply with local rules in lieu of Commission rules.

Mandatory reporting regulations are being finalized in a number of countries, such as Dodd Frank Act in the US, the European Market Infrastructure Regulations (EMIR) in Europe, as well as regulations in Hong Kong, Japan, Singapore, Canada, and other countries. The OTC Derivatives Regulators Forum (ODRF), a group of over 40 worldwide regulators, provided trade repositories with a set of guidelines regarding data access to regulators, and the Financial Stability Board and CPSS IOSCO also made recommendations in with regard to reporting.

DTCC, through its "Global Trade Repository" (GTR) service, manages global trade repositories for interest rates, and commodities, foreign exchange, credit, and equity derivatives. It makes global trade reports to the CFTC in the U.S., and plans to do the same for ESMA in Europe and for regulators in Hong Kong, Japan, and Singapore. It covers cleared and uncleared OTC derivatives products, whether or not a trade is electronically processed or bespoke.





Disney (disambiguation)

Disney is another name for The Walt Disney Company, an American diversified multinational mass media and entertainment conglomerate

Disney may also refer to:







Divine right of kings

In European Christianity, the divine right of kings, divine right, or God's mandation, is a political and religious doctrine of political legitimacy of a monarchy. It is also known as the divine-right theory of kingship.

The doctrine asserts that a monarch is not accountable to any earthly authority (such as a parliament or pope) because their right to rule is derived from divine authority. Thus, the monarch is not subject to the will of the people, of the aristocracy, or of any other estate of the realm. It follows that only divine authority can judge a monarch, and that any attempt to depose, dethrone, resist or restrict their powers runs contrary to God's will and may constitute a sacrilegious act. It does not imply that their power is absolute.

In its full-fledged form, the Divine Right of Kings is associated with Henry VIII of England (and the Acts of Supremacy), James VI and I of Scotland and England, Louis XIV of France, and their successors. 

In contrast, the conception of human rights started being developed during the Middle Ages by scholars such as St. Thomas Aquinas (see Natural Law) and were systematised by the thinkers of the Age of Enlightenment, e.g. John Locke. This concept is grounded in Christian thought, especially the idea that reason is a spark of the divine that allows the creature to know the Creator, making each rational creature sacred. Liberty, dignity, freedom and equality are examples of important human rights.

Divine right has been a key element of the self-legitimisation of many absolute monarchies, connected with their authority and right to rule. Related but distinct notions include Caesaropapism (the complete subordination of bishops etc. to the secular power), Supremacy (the legal sovereignty of the civil laws over the laws of the Church), Absolutism (a form of monarchical or despotic power that is unrestrained by all other institutions, such as churches, legislatures, or social elites) or Tyranny (an absolute ruler who is unrestrained even by moral law). 

Historically, many notions of rights have been authoritarian and hierarchical, with different people granted different rights and some having more rights than others. For instance, the right of a father to receive respect from his son did not indicate a right for the son to receive a return from that respect. Analogously, the divine right of kings, which permitted absolute power over subjects, provided few rights for the subjects themselves.

It is sometimes signified by the phrase "by the Grace of God" or its Latin equivalent, "Dei Gratia", which has historically been attached to the titles of certain reigning monarchs. Note, however, that such accountability only to God does not "per se" make the monarch a sacred king.

Khvarenah (also spelled "khwarenah" or "xwarra(h)": ""; ) is an Iranian and Zoroastrian concept, which literally means "glory", about divine right of the kings. This may stem from early Mesopotamian culture, where kings were often regarded as deities after their death. Shulgi of Ur was among the first Mesopotamian rulers to declare himself to be divine. In the Iranian view, kings would never rule, unless Khvarenah is with them, and they will never fall unless Khvarenah leaves them. For example, according to the "Kar-namag of Ardashir," when Ardashir I of Persia and Artabanus V of Parthia fought for the throne of Iran, on the road Artabanus and his contingent are overtaken by an enormous ram, which is also following Ardashir. Artabanus's religious advisors explain to him that the ram is the manifestation of the "khwarrah" of the ancient Iranian kings, which is leaving Artabanus to join Ardashir.

The Imperial cult of ancient Rome identified Roman emperors and some members of their families with the "divinely sanctioned" authority ("auctoritas") of the Roman State. The official offer of "cultus" to a living emperor acknowledged his office and rule as divinely approved and constitutional: his Principate should therefore demonstrate pious respect for traditional Republican deities and mores. Many of the rites, practices and status distinctions that characterized the cult to emperors were perpetuated in the theology and politics of the Christianised Empire.

While the earliest references to kingship in Israel proclaim that "14 "When you come to the land that the Lord your God is giving you, and you possess it and dwell in it and then say, 'I will set a king over me, like all the nations that are around me,' 15 you may indeed set a king over you whom the Lord your God will choose. One from among your brothers you shall set as king over you. You may not put a foreigner over you, who is not your brother." (Deut 17:14-15), significant debate on the legitimacy of kingship has persisted in Rabbinical Judaism until Maimonides, though many mainstream currents continue to reject the notion. 

The controversy is highlighted by the instructions to the Israelites in the above-quoted passage, as well as the passages in 1 Samuel 8 and 12, concerning the dispute over kingship; and "Perashat Shoftim." It is from 1 Samuel 8 that the Jews receive "mishpat ha-melech," the "ius regium", or the law of kingship, and from this passage that Maimonides finally concludes that Judaism supports the institution of monarchy, stating that the Israelites had been given three commandments upon entering the land of Israel - to designate a king for themselves, to wipe out the memory of Amalek, and to build the Temple. 

The debate has primarily centered around the problem of being told to "designate" a king, which some rabbinical sources have argued is an invocation "against" a divine right of kings, and a call to elect a leader, in opposition to a notion of a divine right. Other rabbinical arguments have put forward an idea that it is through the collective decision of the people that God's will is made manifest, and that the king does therefore have a divine right - once appointed by the nation, he is God's emissary. 

Jewish law requires one to recite a special blessing upon seeing a monarch: "Blessed are You, L‑rd our G‑d, King of the universe, Who has given from His glory to flesh and blood".

With the rise of firearms, nation-states and the Protestant Reformation in the late 16th century, the theory of divine right justified the king's absolute authority in both political and spiritual matters. Henry VIII of England declared himself the Supreme Head of the Church of England and exerted the power of the throne more than any of his predecessors. 

As a political theory, it was further developed by James VI of Scotland (1567–1625) and came to the fore in England under his reign as James I of England (1603–1625). Louis XIV of France (1643–1715) strongly promoted the theory as well.

Historian J.P. Sommerville stresses the theory was polemic: "Absolutists magnified royal power. They did this to protect the state against anarchy and to refute the ideas of resistance theorists", those being in Britain Catholic and Presbyterian theorists.

The concept of divine right incorporates, but exaggerates, the ancient Christian concept of "royal God-given rights", which teach that "the right to rule is anointed by God", although this idea is found in many other cultures, including Aryan and Egyptian traditions. 

In pagan religions, the king was often seen as a "God incarnate" and so was an unchallengeable despot. The ancient Roman Catholic tradition overcame this idea with the doctrine of the two swords and so achieved, for the very first time, a balanced constitution for states. The advent of Protestantism saw something of a return to the idea of a mere unchallengeable despot.

The Christian notion of a divine right of kings is traced to a story found in 1 Samuel, where the prophet Samuel anoints Saul and then David as "Messiah" ("anointed one")—king over Israel. In the Jewish traditions, the lack of a divine leadership represented by an anointed king, beginning shortly after the death of Joshua, left the people of Israel vulnerable, and the promise of the "promised land" was not fully fulfilled until a king was anointed by a prophet on behalf of God.

The effect of anointing was seen to be that the monarch became inviolable, so that even when Saul sought to kill David, David would not raise his hand against him because "he was the Lord's anointed". Raising a hand to a king was therefore considered to be as sacrilegious as raising a hand against God and stood on equal footing as blasphemy. In essence, the king stood in place of God and was never to be challenged "without the challenger being accused of blasphemy" - except by a prophet, which under Christianity was replaced by the church.

Outside of Christianity, kings were often seen as ruling with the backing of heavenly powers. 

Although the later Roman Empire had developed the European concept of a divine regent in Late Antiquity, Adomnan of Iona provides one of the earliest written examples of a Western medieval concept of kings ruling with divine right. He wrote of the Irish King Diarmait mac Cerbaill's assassination and claimed that divine punishment fell on his assassin for the act of violating the monarch. 

Adomnan also recorded a story about Saint Columba supposedly being visited by an angel carrying a glass book, who told him to ordain Aedan mac Gabrain as King of Dal Riata. Columba initially refused, and the angel answered by whipping him and demanding that he perform the ordination because God had commanded it. The same angel visited Columba on three successive nights. Columba finally agreed, and Aedan came to receive ordination. At the ordination, Columba told Aedan that so long as he obeyed God's laws, then none of his enemies would prevail against him, but the moment he broke them, this protection would end, and the same whip with which Columba had been struck would be turned against the king. 

Adomnan's writings most likely influenced other Irish writers, who in turn influenced continental ideas as well. Pepin the Short's coronation may have also come from the same influence. The Byzantine Empire can be seen as the progenitor of this concept (which began with Constantine I). This in turn inspired the Carolingian dynasty and the Holy Roman Emperors, whose lasting impact on Western and Central Europe further inspired all subsequent Western ideas of kingship.

In the Middle Ages, the idea that God had granted certain earthly powers to the monarch, just as he had given spiritual authority and power to the church, especially to the Pope, was already a well-known concept long before later writers coined the term "divine right of kings" and employed it as a theory in political science. 

However, the dividing line for the authority and power was a subject of frequent contention: notably in England with the murder of Archbishop Thomas Beckett (1170). For example, Richard I of England declared at his trial during the diet at Speyer in 1193: "", and it was Richard who first used the motto "" ("God and my right") which is still the motto of the Monarch of the United Kingdom.

Thomas Aquinas condoned extra-legal tyrannicide in the worst of circumstances:
On the other hand, Aquinas forbade the overthrow of any morally, Christianly and spiritually legitimate king by his subjects. The only human power capable of deposing the king was the pope. The reasoning was that if a subject may overthrow his superior for some bad law, who was to be the judge of whether the law was bad? If the subject could so judge his own superior, then all lawful superior authority could lawfully be overthrown by the arbitrary judgement of an inferior, and thus all law was under constant threat.

According to John of Paris, kings had their jurisdictions and bishops (and the pope) had theirs, but kings derived their supreme, non-absolute temporal jurisdiction from popular consent.

Towards the end of the Middle Ages, many philosophers, such as Nicholas of Cusa and Francisco Suárez, propounded similar theories. 

The Church was the final guarantor that Christian kings would follow the laws and constitutional traditions of their ancestors and the laws of God and of justice.

Radical English theologian John Wycliffe's theory of Dominium meant that injuries inflicted on someone personally by a king should be born by them submissively, a conventional idea, but that injuries by a king against God should be patiently resisted even to death; gravely sinful kings and popes forfeited their (divine) right to obedience and ownership, though the political order should be maintained. More aggressive versions of this were taken up by Lollards and Hussites.

For Erasmus of Rotterdam it was the consent of the people which gives and takes away "the purple", not an unchangeable divine mandate.

Roman Catholic jurisprudence, the monarch is always subject to natural and divine law, which are regarded as superior to the monarch. 

The possibility of monarchy declining morally, overturning natural law, and degenerating into a tyranny oppressive of the general welfare was answered theologically with the Catholic concept of the spiritual superiority of the Pope (there is no "Catholic concept of extra-legal tyrannicide", as some falsely suppose, the same being expressly condemned by St Thomas Aquinas in chapter 7 of his "De Regno"). 

Catholic thought justified limited submission to the monarchy by reference to the following:

The divine right of kings, or divine-right theory of kingship, is a political and religious doctrine of royal and political legitimacy. It asserts that a monarch is subject to no earthly authority, deriving his right to rule directly from the will of God. The king is thus not subject to the will of his people, the aristocracy, or any other estate of the realm, including (in the view of some, especially in Protestant countries) the church.

A weaker or more moderate form of this political theory does hold, however, that the king is subject to the church and the pope, although completely irreproachable in other ways; but according to this doctrine in its strong form, only God can judge an unjust king. 

The doctrine implies that any attempt to depose the king or to restrict his powers runs contrary to the will of God and may constitute a sacrilegious act.

The Scots textbooks of the divine right of kings were written in 1597–1598 by James VI of Scotland. His "Basilikon Doron", a manual on the powers of a king, was written to edify his four-year-old son Henry Frederick that a king "acknowledgeth himself ordained for his people, having received from God a burden of government, whereof he must be countable". 

The conception of ordination brought with it largely unspoken parallels with the Anglican and Catholic priesthood, but the overriding metaphor in James VI's 'Basilikon Doron' was that of a father's relation to his children. "Just as no misconduct on the part of a father can free his children from obedience to the fifth commandment."

James, after becoming James I of England, also had printed his "Defense of the Right of Kings" in the face of English theories of inalienable popular and clerical rights. 

He based his theories in part on his understanding of the Bible, as noted by the following quote from a speech to parliament delivered in 1610 as James I of England:

James's reference to "God's lieutenants" is apparently a reference to the text in Romans 13 where Paul refers to "God's ministers".

Some of the symbolism within the coronation ceremony for British monarchs, in which they are anointed with holy oils by the Archbishop of Canterbury, thereby "ordaining" them to monarchy, perpetuates the ancient Roman Catholic monarchical ideas and ceremonial (although few Protestants realize this, the ceremony is nearly entirely based upon that of the Coronation of the Holy Roman Emperor). However, in the UK, the symbolism ends there since the real governing authority of the monarch was all but extinguished by the Whig revolution of 1688–89 (see Glorious Revolution). The king or queen of the United Kingdom is one of the last monarchs still to be crowned in the traditional Christian ceremonial, which in most other countries has been replaced by an inauguration or other declaration.

In England, it is not without significance that the sacerdotal vestments, generally discarded by the clergy – dalmatic, alb and stole – continued to be among the insignia of the sovereign (see Coronation of the British monarch). Moreover, this sacrosanct character he acquired not by virtue of his "sacring", but by hereditary right; the coronation, anointing and vesting were but the outward and visible symbol of a divine grace adherent in the sovereign by virtue of his title. Even Roman Catholic monarchs, like Louis XIV, would never have admitted that their coronation by the archbishop constituted any part of their title to reign; it was no more than the consecration of their title.

The French prelate Jacques-Bénigne Bossuet made a classic statement of the doctrine of divine right in a sermon preached before King Louis XIV:

The French Huguenot nobles and clergy, having rejected the pope and the Catholic Church, were left only with the supreme power of the king who, they taught, could not be gainsaid or judged by anyone. Since there was no longer the countervailing power of the papacy and since the Church of England was a creature of the state and had become subservient to it, this meant that there was nothing to regulate the powers of the king, and he became an absolute power. In theory, divine, natural, customary, and constitutional law still held sway over the king, but, absent a superior spiritual power, it was difficult to see how they could be enforced since the king could not be tried by any of his own courts.

One passage in scripture supporting the idea of the divine right of kings was used by Martin Luther, when urging the secular authorities to crush the Peasant Rebellion of 1525 in Germany in his "Against the Murderous, Thieving Hordes of Peasants", basing his argument on Paul's Epistle to the Romans.

It is related to the ancient Catholic philosophies regarding monarchy, in which the monarch is God's vicegerent upon the earth and therefore subject to no inferior power.

Before the Reformation the anointed king was, within his realm, the accredited vicar of God for secular purposes (see the Investiture Controversy); after the Reformation he (or she if queen regnant) became this in Protestant states for religious purposes also.

In the sixteenth century, both Catholic and Protestant political thinkers alike challenged the idea of a monarch's "divine right".

The Spanish Catholic historian Juan de Mariana put forward the argument in his book "De rege et regis institutione" (1598) that since society was formed by a "pact" among all its members, "there can be no doubt that they are able to call a king to account". Mariana thus challenged divine right theories by stating in certain circumstances, tyrannicide could be justified. 

Cardinal Robert Bellarmine also "did not believe that the institute of monarchy had any divine sanction" and shared Mariana's belief that there were times where Catholics could lawfully remove a monarch.

Among groups of English Protestant exiles fleeing from Queen Mary I, some of the earliest anti-monarchist publications emerged. "Weaned off uncritical royalism by the actions of Queen Mary ... The political thinking of men like Ponet, Knox, Goodman and Hales."

In 1553, Mary I, a Roman Catholic, succeeded her Protestant half-brother, Edward VI, to the English throne. Mary set about trying to restore Roman Catholicism by making sure that: Edward's religious laws were abolished in the Statute of Repeal Act (1553); the Protestant religious laws passed in the time of Henry VIII were repealed; and the Revival of the Heresy Acts were passed in late 1554. 

When Thomas Wyatt the Younger instigated what became known as Wyatt's rebellion in early 1554, John Ponet, the highest-ranking ecclesiastic among the exiles, allegedly participated in the uprising. He escaped to Strasbourg after the Rebellion's defeat and, the following year, he published "A Shorte Treatise of Politike Power", in which he put forward a theory of justified opposition to secular rulers.

Ponet's pamphlet was republished on the eve of King Charles I's execution.

According to U.S. President John Adams, Ponet's work contained "all the essential principles of liberty, which were afterward dilated on by Sidney and Locke", including the idea of a three-branched government.

Over time, opposition to the divine right of kings came from a number of sources, including poet John Milton in his pamphlet "The Tenure of Kings and Magistrates", and Thomas Paine in his pamphlet "Common Sense". By 1700 an Anglican 
Archbishop was prepared to assert that Kings hold their Crowns by 
law alone, and the law may forfeit them. 

Probably the two most famous declarations of a right to revolution against tyranny in the English language are John Locke's "Essay concerning The True Original, Extent, and End of Civil-Government" and Thomas Jefferson's formulation in the United States Declaration of Independence that "all men are created equal".

In England the doctrine of the divine right of kings was developed to its most extreme logical conclusions during the political controversies of the 17th century; its most famous exponent was Sir Robert Filmer. It was the main issue to be decided by the English Civil War, the Royalists holding that "all Christian kings, princes and governors" derive their authority direct from God, the Parliamentarians that this authority is the outcome of a contract, actual or implied, between sovereign and people.

In one case the king's power would be unlimited, according to the famous saying misattributed to Louis XIV: ""L' état, c'est moi"", or limited only by his own free act; in the other his actions would be governed by the advice and consent of the people, to whom he would be ultimately responsible. The victory of this latter principle was proclaimed to all the world by the execution of Charles I. 

The doctrine of divine right, indeed, for a while drew nourishment from the blood of the royal "martyr"; it was the guiding principle of the Anglican Church of the Restoration; but it suffered a rude blow when James II of England made it impossible for the clergy to obey both their conscience and their king. 

The Glorious Revolution of 1688 made an end of it as a great political force. This has led to the constitutional development of the Crown in Britain, as held by descent modified and modifiable by parliamentary action.



Davros

Davros () is a fictional character from the long-running British science fiction television series "Doctor Who". He was created by screenwriter Terry Nation, originally for the 1975 serial "Genesis of the Daleks". Davros is a major enemy of the series' protagonist, the Doctor, and is the creator of the Doctor's deadliest enemies, the Daleks. Davros is a genius who has mastered many areas of science, but also a megalomaniac who believes that through his creations he can become the supreme being and ruler of the Universe. The character has been compared to the infamous dictator Adolf Hitler several times, including by the actor Terry Molloy, while Julian Bleach defined him as a cross between Hitler and the renowned scientist Stephen Hawking.

Davros is from the planet Skaro, whose people, the Kaleds, were engaged in a bitter thousand-year war of attrition with their enemies, the Thals. He is horribly scarred and disabled, a condition that various spin-off media attribute to his laboratory being attacked by a Thal shell. He has one functioning hand and one cybernetic eye mounted on his forehead to take the place of his real eyes, which he is not able to open for long; for much of his existence he depends completely upon a self-designed mobile life-support chair in place of his lower body. It would become an obvious inspiration for his eventual design of the Dalek. The lower half of his body is absent and he is physically incapable of leaving the chair for more than a few minutes without dying. Davros' voice, like those of the Daleks, is electronically distorted. His manner of speech is generally soft and contemplative, but when angered or excited he is prone to ranting outbursts that resemble the hysterical, staccatissimo speech of the Daleks.

Davros first appeared in the 1975 serial "Genesis of the Daleks", written by Terry Nation. Nation, creator of the Dalek concept, had deliberately modelled elements of the Daleks' character on Nazi ideology, and conceived of their creator as a scientist with strong fascist tendencies. The physical appearance of Davros was developed by visual effects designer Peter Day and sculptor John Friedlander, who based Davros' chair on the lower half of a Dalek. Producer Philip Hinchcliffe told Friedlander to consider a design similar to the Mekon from the "Eagle" comic "Dan Dare", with a large dome-like head and a withered body.

Cast in the role of Davros was Michael Wisher, who had previously appeared in several different roles on "Doctor Who" and had provided Dalek voices in the serials "Frontier in Space", "Planet of the Daleks" and "Death to the Daleks". Wisher based his performance as Davros on the philosopher Bertrand Russell. In order to prepare for filming under the heavy mask, Wisher rehearsed wearing a paper bag over his head. Friedlander's mask was cast in hard latex, with only the mouth revealing Wisher's features; make-up artist Sylvia James shaded the mask's tones and blackened Wisher's lips and teeth to hide the transition.

In the serial "Destiny of the Daleks", Davros is played by David Gooderson using the mask Friedlander made for Wisher after it was split into intersecting sections to get as good a fit as possible. When Terry Molloy took over the role in "Resurrection of the Daleks", a new mask was designed by Stan Mitchell.

In 2023, Bleach reprised the role of Davros for a minisode aired during "Children in Need", informally titled "Destination: Skaro". For the first time on television, Davros is depicted as non-disabled. In an interview for "", executive producer Russell T. Davies said that this is how Davros will be depicted in future appearances, to avoid contributing to harmful tropes of disabled villains in media.

The decision to portray Davros without his chair received a divisive reception from fans.

The Fourth Doctor (Tom Baker) first encountered Davros (Michael Wisher) in "Genesis of the Daleks" when he and his companions were sent to Skaro to avert the creation of the Daleks. As chief scientist of the Kaleds and leader of their elite scientific division, Davros devised new military strategies in order to win his people's thousand-year war against the Thal race that also occupies Skaro. When Davros learned his people were evolving from exposure to nuclear weapons, chemical weapons and biological weapons used in the war, he artificially accelerates the process to his design and stores the resulting tentacled creatures in tank-like "Mark III travel machines" partly based on the design of his wheelchair. He later names these creatures "Daleks", an anagram of Kaleds.

Davros quickly becomes obsessed with his creations, considering them to be the ultimate form of life compared to others. When other Kaleds attempted to thwart his project, Davros arranges the extinction of his own people by using the Thals, whom he mostly killed with the Daleks later. Davros then weeds out those in elite scientific division who are loyal to him so he can have the Daleks eliminate the rest. However, the Daleks ultimately turn on Davros, killing his supporters before shooting him when he tries to halt the Dalek production line.

In "Destiny of the Daleks", it is revealed that Davros (now played by David Gooderson) was not killed, but placed in suspended animation and buried underground in the destruction of his bunker. The Daleks unearth their creator to help them break a logical impasse in their war against the android Movellans. However, the Dalek force is destroyed by the Doctor, and Davros is captured and imprisoned in suspended animation by the humans, before being taken to Earth to face trial.

In the Fifth Doctor story "Resurrection of the Daleks", Davros (Terry Molloy) is released from his space station prison by a small Dalek force aided by human mercenaries and Dalek duplicates. The Daleks require Davros to find an antidote for a Movellan-created virus that has all but wiped them out. Believing his creations to be treacherous, Davros begins using a syringe-like mind control device hidden in a secret compartment in his wheelchair on Daleks and humans; he ultimately releases a sample of the virus to kill off the Daleks before they can exterminate him. Davros expresses a desire to build a new and improved race of Daleks, but he apparently succumbs to the virus himself, his physiology being close enough to that of the Daleks for the virus to affect him.

In the Sixth Doctor story "Revelation of the Daleks", it is revealed that Davros managed to escape at the end of "Resurrection" and has gone into hiding as "The Great Healer" of the funeral and cryogenic preservation centre Tranquil Repose on the planet Necros. There, creating a clone of his head to serve as a decoy while modifying his body so that it can fire electric bolts and his chair is able to hover, Davros uses the more intelligent frozen bodies to engineer a new variety of white armoured Daleks loyal to him (while using the lesser intellects as food for the galaxy, ending a galaxy-wide famine), but he is captured by the original Daleks and taken to Skaro to face trial.

Davros' final classic appearance is as the Emperor Dalek in "Remembrance of the Daleks", with his white and gold Daleks now based on Skaro and termed "Imperial Daleks", fighting against the grey "Renegade Dalek" faction, who answer to the Dalek Supreme. By this time, Davros has been physically transplanted into a customised Dalek casing. He is only revealed to be the Emperor in the final episode. Both Skaro and the Imperial Dalek mothership are apparently destroyed (in the future) when the Seventh Doctor tricks Davros into using the Time Lord artefact known as the Hand of Omega, which makes Skaro's Sun go supernova, before homing in on their mothership. However, a Dalek on the bridge of Davros' ship reports that the Emperor's escape pod is being launched and a white light is seen speeding away from the ship moments before its destruction, leaving a clear route to bring Davros back in the future.

During the revived series, Davros was referred to in the episode "Dalek" (2005) by the Ninth Doctor (Christopher Eccleston), who explains to Henry Van Statten that the Daleks were created by "a genius... a man who was king of his own little world", and again by the Tenth Doctor (David Tennant) in the episode "Evolution of the Daleks" (2007), where he refers to the Daleks' creator as believing that "removing emotions makes you stronger". Davros makes his first physical appearance in the episode "The Stolen Earth" (2008), portrayed by Julian Bleach. The episode reveals that Davros was thought to have died during the first year of the Time War, when his command ship "flew into the jaws of the Nightmare Child" at the Gates of Elysium, despite the Doctor's failed efforts to save him. But Davros was pulled out of the time lock of the war by Dalek Caan (voiced by Nicholas Briggs), using his own flesh to create a "new empire" of Daleks who place him in the Vault as their prisoner to make use of his knowledge. Under Davros' guidance, the Daleks steal 27 planets, including Earth, and hide them in the Medusa Cascade, one second out of sync with the rest of the universe.

In the follow-up episode "Journey's End" (2008), it is revealed that the stolen planets are required as a power source for Davros' ideal final solution: the Reality Bomb, which produces a wavelength that would cancel out the electrical field binding atoms to reduce all life outside the Crucible into nothingness in both his universe and countless other realities. But Davros learns too late that Dalek Caan, who came to the realisation of his race's atrocities as a consequence of saving his creator, used his prophecies and influence to ensure the Daleks' destruction while manipulating events to bring the Tenth Doctor and Donna Noble (Catherine Tate) together for the role the latter would play. Though the Doctor attempts to save him, having earlier taunted the Doctor for turning his companions into killers and being the cause of the deaths of countless people during his travels, Davros furiously refuses the Doctor's help and accuses him of being responsible for the destruction while screaming: "Never forget, Doctor, you did this! I name you forever: "You" are the Destroyer of Worlds!" Thus the Doctor is forced to leave Davros to his supposed fate as the Crucible self-destructs.

Davros returns in the two-part Series 9 opening "The Magician's Apprentice" and "The Witch's Familiar" (2015), having escaped the Crucible's destruction and ending up on a restored Skaro with his life being prolonged by the Daleks. But when the aged Davros' health begins to fail, he remembers his childhood self, played by Joey Price, meeting the Twelfth Doctor (Peter Capaldi) during the Kaleds' thousand-year war prior to "Genesis of the Daleks". The young Davros finds himself lost on the battlefield and surrounded by handmines, with the Doctor throwing his sonic screwdriver to the boy with the intent to save him before learning his name and leaving the child to his fate. Davros, seeking a final revenge on the Doctor, employs the snake-like Colony Sarff (Jami Reid-Quarrell) to bring him to Skaro. When it appears that the Doctor has lost his companion Clara Oswald (Jenna Coleman) to the Daleks, Davros manages to trick the Doctor into using his regeneration energy to heal him, extending his own life while infusing every Dalek on Skaro with the energy. But the Doctor reveals Davros' scheme has also revitalised the decomposing-yet-still-alive Daleks left to rot in Skaro's sewers, causing them to revolt and destroy the city. The Doctor then discovers the Daleks have a concept of mercy and are allowed to have the word in their vocabulary when he encounters Clara, having been placed in a Dalek casing by Missy (Michelle Gomez). The Doctor and Clara escape, the former having an epiphany as to how Davros somehow put a sliver of compassion into the Daleks. He then returns to the battlefield in Davros' childhood, using a Dalek gun to destroy the handmines with the one bit of compassion in Davros' life instilled in the Daleks' design to ensure Clara being saved.

In the "Children in Need" sketch "Destination: Skaro" (2023) (which takes place during an earlier time in the Kaled-Thal war), Davros (Julian Bleach) (who has not yet become disabled nor has the cybernetic eye) is seen presenting a Dalek prototype featuring a robotic claw to his assistant, Castavillian. When he briefly departs to attend to an urgent matter, the Fourteenth Doctor lands in the TARDIS, accidentally destroying the robotic claw. He inadvertently suggests the name "Dalek" for the prototype, and gives Castavillian a plunger-tipped arm as a replacement for the broken claw. Once he realises that he has accidentally assisted with the creation of his greatest enemy, he quickly departs saying that he was "never here". Davros returns and approves of the new plunger arm.

"Doctor Who Magazine" printed several comics stories involving Davros. The first, "Nemesis of the Daleks" (#152–155), with the Seventh Doctor, features an appearance of a Dalek Emperor. Speaking with the Emperor, the Doctor addresses him as Davros, but the Emperor responds "Who is Davros?" The Doctor initially assumes Davros' personality has been totally subsumed, but in the later strip "Emperor of the Daleks" (#197–202) this Emperor is shown as a different entity from Davros. Set prior to "Remembrance of the Daleks" in Davros' timeline, but after in the timeline of the Doctor, the latter, accompanied by Bernice Summerfield, together with help from the Sixth Doctor, ensures that Davros will survive the wrath of the Daleks so that he can assume the title of Emperor, allowing history to take its course. "Up Above the Gods" (#227), a vignette following up on this, features the Sixth Doctor and Davros having a conversation in the TARDIS.

Terry Molloy has reprised his role as Davros in the spin-off audio plays produced by Big Finish Productions, mostly notably "Davros" (taking place during the Sixth Doctor's era), which, through flashbacks, explored the scientist's life prior to his crippling injury, which is attributed to a Thal nuclear attack (an idea that first appeared in Terrance Dicks' novelisation of "Genesis of the Daleks").

"Davros", which does not feature the Daleks, apparently fills in the gaps between "Resurrection of the Daleks" and "Revelation of the Daleks", and has the scientist trying to manipulate the galaxy's economy into a war footing similar to Skaro's. The Sixth Doctor manages to defeat his plans, and Davros is last heard when his ship explodes, an event obliquely mentioned in "Revelation". However the Doctor thinks he has survived. Davros also mentions he will work on a plan to combat famine, tying into "Revelation of the Daleks".

"The Davros Mission" is an original audio adventure (without the Doctor) available on "The Complete Davros Collection" DVD box set. It takes place directly after the television story "Revelation", while leaving the planet Necros and beginning Davros' trial. At the end of "Davros Mission", he turns the tables on the Daleks, forcing them to do his bidding. The Big Finish miniseries "I, Davros", also features trial scenes, but mostly explores his early life. In those four stories, his journey is seen from his boyhood, to just before "Genesis of the Daleks".

"The Curse of Davros" begins with Davros and the Daleks working together to try and alter the outcome of the Battle of Waterloo using technology that Davros has created that allows him to swap peoples' minds, allowing him to switch various soldiers in Napoleon's army with his own Daleks, ultimately intending to replace Napoleon with a Dalek after Waterloo is won so that he can change history and lead humanity in a direction where they may ally with the Daleks. The plan is complicated when the Sixth Doctor arrives and uses the device to swap bodies with Davros in an attempt to subvert the Daleks' plans from the inside, but Davros-in-the-Doctor is eventually able to convince the Daleks of his true identity, planning to remain in the Doctor's healthy body while leaving the Doctor trapped in his original form. At the end, Davros and the Doctor are returned to their original bodies with the aid of the Doctor's new companion Flip Jackson, the Doctor exposes Davros's true agenda to Napoleon, and Davros is left with an army of Daleks who have had their minds wiped. These Daleks presumably become the "Imperial Daleks", first seen in "Remembrance of the Daleks".

In "The Juggernauts", Davros is on the run from the original Daleks. He hatches a plan to add human tissue to robotic Mechanoids, using them, along with his own Daleks, to destroy the originals, but the Doctor learns the truth about this plan, and his companion Mel Bush—who unwittingly assisted in the programming of the new Mechanoids—uses a backdoor she installed in their programming to turn them against Davros. At the end of the story, the self-destruct mechanism of Davros' life-support chair explodes after he is attacked by the Mechanoids, destroying an entire human colony. It is not clear how Davros survives to become the Dalek Emperor as seen in "Remembrance". However, in the DVD documentary "Davros Connections", director Gary Russell points out that the explosion of Davros' life-support chair leaves the listener to believe there is little of Davros left. This fits chronologically the fact that "Remembrance" depicts Davros as just a head inside the Emperor Dalek.

In "Daleks Among Us", set after "Remembrance", Davros returns to Azimuth, a planet that was invaded by the Daleks long ago, presenting himself as a victim of Dalek enslavement to infiltrate an underground movement against the repressive government- so desperate to prevent riots about individual actions during the Dalek occupation that official policy is now that the Dalek invasion never happened- seeking the remnants of an old experiment he carried out on the planet. This experiment is revealed to be Falkus, a clone of Davros's original body that was intended to be a new host for his mind, with Falkus having evolved an independent personality since the Daleks left Azimuth. Falkus attempts to acquire the Persuasion Machine, a dangerous device that the Seventh Doctor has been tracking with his companions Elizabeth Elizabeth Klein and Will Arrowsmith, but the Doctor is able to trick Falkus into using the reprogrammed Persuasion Machine to destroy himself and his Daleks, while Davros flees in an escape pod. Davros is last shown trapped on the planet Lamuria, faced with the spectral former residents of the planet who sought to punish all criminals in the universe.

By the time of the Eighth Doctor audio play "Terror Firma" (set after "Remembrance"), Davros is commanding a Dalek army which has successfully conquered the Earth. His mental instability has grown to the point where "Davros" and "the Emperor" exist within him as different personalities. His Daleks recognise this instability and rebel against Davros. By the story's end the Emperor personality is dominant, and the Daleks agree to follow him and leave Earth.

In the fourth volume of the "" series, looking at the Eighth Doctor's role in the Time War, after The Valeyard uses a Dalek weapon to erase the Daleks from history, the Dalek Time Strategist escapes the erasure by travelling into a parallel universe where the Kaleds and Thals have been at peace for centuries, with Davros still fully human and married to a Thal woman. The Dalek Time Strategist manipulates this alternate Davros into using his dimensional portal technology to merge various alternate Skaros together to recreate the Daleks in the prime universe, convincing Davros that the Doctor is an enemy of the "Kaleds" rather than the Thals. Reference is made to the 'prime' Davros having been killed in the first year of the War (as mentioned in "The Stolen Earth"). The process of merging with his alternate selves causes the alternate Davros to gain the injuries and memories of his counterparts, to the extent that he forgets his wife and the peace with the Thals. Eventually his presence restores the Daleks in the prime universe, but the Dalek Emperor has Davros put into stasis to prevent his influence causing another civil war by causing the Daleks to become divided between loyalty to the Emperor and Davros.

"Terror Firma" may contradict the events of the Eighth Doctor Adventures novel "War of the Daleks" by John Peel, in which an unmerged Davros is placed on trial by the Dalek Prime, a combination of the Dalek Emperor and the Dalek Supreme. In the novel the Dalek Prime claimed that the planet Antalin had been terraformed to resemble Skaro and was destroyed in its place. A subterfuge to destroy Daleks aligned to Davros; both on Skaro (Antalin) and those that remained hidden within Dalek ranks on Skaro (original). Despite finding evidence of threat to Skaro via evidence found on 22nd century earth of Davros' mission to 1960s Earth and seeing the event via time-tracking equipment, the Dalek Prime allowed the destruction of Skaro to destroy Daleks allied to Davros. Dalek Prime also claimed that the Dalek/Movellan war (and indeed most of Dalek history before the destruction of "Skaro") was actually faked for Davros' benefit; in fact another ruse designed to bait Davros into giving evidence against himself (as he does in his trial.) Skaro is later seen to be intact and undamaged, and one character notes that it is quite possible the Dalek Prime is lying in order to weaken Davros' claim to leadership of the Daleks, while using foreknowledge of events to destroy and entrap Davros and his allies.

At the conclusion of "War", Davros was seemingly disintegrated by a Spider Dalek on the order of the Dalek Prime. However, Davros had previously recruited one of the Spider Daleks as a sleeper agent for just such an eventuality, and even he was not certain in the end if he was being disintegrated or being teleported away to safety, leaving the possibility open for his return.

Paul Cornell's dark vignette in the "Doctor Who Magazine" Brief Encounters series, "An Incident Concerning the Bombardment of the Phobos Colony" occurs sometime between "Resurrection of the Daleks" and his assumption of the role of Emperor.

In 1993, Michael Wisher, the original Davros, with Peter Miles, who had played his confederate, Nyder, reprised the role in an unlicensed one-off amateur stage production, "The Trial of Davros". The plot of the play involved the Time Lords putting Davros on trial, with Nyder as a witness.

Terry Molloy played Davros in the remounting of the play, again with Miles, for another one-off production in 2005. During the production, specially shot footage portrayed Dalek atrocities.

In 2008, Julian Bleach appeared live as Davros at the Doctor Who Prom, announcing that the Royal Albert Hall would become his new palace, and the audience his "obedient slaves".

BBC staff have traditionally created parodies of its own programming to be shown to colleagues at Christmas events and parties. The BBC's 1993 Christmas tape parodied the allegedly robotic, dictatorial and ruthless management style of its then Director-General, John Birt, by portraying him as Davros taking over the BBC, carrying out bizarre mergers of departments, awarding himself a bonus and singing a song to the tune of "I Wan'na Be Like You (The Monkey Song)" describing his plans.




Played by Terry Molloy, except when noted.





On 26 November 2007, a DVD box set was released featuring all of the Davros stories from the shows original run, including "Genesis of the Daleks", "Destiny of the Daleks", "Resurrection of the Daleks", "Revelation of the Daleks", and "Remembrance of the Daleks".

Davros' portrayal as a character in what could be seen as a wheelchair has caused controversy. Showrunner Russell T Davies explained that disability has in the past been associated with villainy, an association which is no longer appropriate. Consequently, Davros appeared standing upright in the 2023 Children In Need special, "Destination: Skaro".



