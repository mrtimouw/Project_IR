Celibacy

Celibacy (from Latin "caelibatus") is the state of voluntarily being unmarried, sexually abstinent, or both, usually for religious reasons. It is often in association with the role of a religious official or devotee. In its narrow sense, the term "celibacy" is applied only to those for whom the unmarried state is the result of a sacred vow, act of renunciation, or religious conviction. In a wider sense, it is commonly understood to only mean abstinence from sexual activity. 

Celibacy has existed in one form or another throughout history, in virtually all the major religions of the world, and views on it have varied.

Classical Hindu culture encouraged asceticism and celibacy in the later stages of life, after one has met one's societal obligations. Jainism, on the other hand, preached complete celibacy even for young monks and considered celibacy to be an essential behavior to attain moksha. Buddhism is similar to Jainism in this respect. There were, however, significant cultural differences in the various areas where Buddhism spread, which affected the local attitudes toward celibacy. A somewhat similar situation existed in Japan, where the Shinto tradition also opposed celibacy. In most native African and Native American religious traditions, celibacy has been viewed negatively as well, although there were exceptions like periodic celibacy practiced by some Mesoamerican warriors.

The Romans viewed celibacy as an aberration and legislated fiscal penalties against it, with the exception of the Vestal Virgins, who took a 30-year vow of chastity in order to devote themselves to the study and correct observance of state rituals.

In Christianity, celibacy means the promise to live either virginal or celibate in the future. Such a "vow of celibacy" has been normal for some centuries for Catholic priests, Catholic and Eastern Orthodox monks, and nuns. In addition, a promise or vow of celibacy may be made in the Anglican Communion and some Protestant churches or communities­— such as the Shakers­–, for members of religious orders and religious congregations; for hermits, consecrated virgins, and deaconesses.

Judaism and Islam have denounced celibacy, as both religions emphasize marriage and family life. However, the priests of the Essenes, a Jewish sect during the Second Temple period, practised celibacy. Several hadiths indicate that the Islamic prophet Muhammad denounced celibacy.

The English word "celibacy" derives from the Latin "caelibatus", "state of being unmarried", from Latin , meaning "unmarried". This word derives from two Proto-Indo-European stems, * "alone" and * "living".

The words "abstinence" and "celibacy" are often used interchangeably, but are not necessarily the same thing. Sexual abstinence, also known as "continence", is abstaining from some or all aspects of sexual activity, often for some limited period of time, while celibacy may be defined as a voluntary religious vow not to marry or engage in sexual activity. Asexuality is commonly conflated with celibacy and sexual abstinence, but it is considered distinct from the two, as celibacy and sexual abstinence are behavioral and those who use those terms for themselves are generally motivated by factors such as an individual's personal or religious beliefs.

A. W. Richard Sipe, while focusing on the topic of celibacy in Catholicism, states that "the most commonly assumed definition of "celibate" is simply an unmarried or single person, and celibacy is perceived as synonymous with sexual abstinence or restraint." Sipe adds that even in the relatively uniform milieu of Catholic priests in the United States there seems to be "simply no clear operational definition of celibacy". Elizabeth Abbott commented on the terminology in her "A History of Celibacy" (2001) writing that she "drafted a definition of celibacy that discarded the rigidly pedantic and unhelpful distinctions between celibacy, chastity, and virginity..."

The concept of "new" celibacy was introduced by Gabrielle Brown in her 1980 book "The New Celibacy". In a revised version (1989) of her book, she claims abstinence to be "a response on the outside to what's going on, and celibacy is a response from the inside". According to her definition, celibacy (even short-term celibacy that is pursued for non-religious reasons) is much more than not having sex. It is more intentional than abstinence, and its goal is personal growth and empowerment. Although Brown repeatedly states that celibacy is a matter of choice, she clearly suggests that those who do not choose this route are somehow missing out. This new perspective on celibacy is echoed by several authors including Elizabeth Abbott, Wendy Keller, and Wendy Shalit.

The rule of celibacy in the Buddhist religion, whether Mahayana or Theravada, has a long history. Celibacy was advocated as an ideal rule of life for all monks and nuns by Gautama Buddha, except in Japan where it is not strictly followed due to historical and political developments following the Meiji Restoration. In Japan, celibacy was an ideal among Buddhist clerics for hundreds of years. But violations of clerical celibacy were so common for so long that finally, in 1872, state laws made marriage legal for Buddhist clerics. Subsequently, ninety percent of Buddhist monks/clerics married. An example is Higashifushimi Kunihide, a prominent Buddhist priest of Japanese royal ancestry who was married and a father whilst serving as a monk for most of his lifetime.

Gautama, later known as the Buddha, is known for his renunciation of his wife, Princess Yasodharā, and son, Rahula. In order to pursue an ascetic life, he needed to renounce aspects of the impermanent world, including his wife and son. Later on both his wife and son joined the ascetic community and are mentioned in the Buddhist texts to have become enlightened. In another sense, a buddhavacana recorded the zen patriarch Vimalakirti as being an advocate of marital continence instead of monastic renunciation. This sutra became somewhat popular due to its brash humour as well as its integration of the role of women in lay and spiritual life.
In the religious movement of Brahma Kumaris, celibacy is also promoted for peace and to defeat power of lust.

There is no commandment in the New Testament that Jesus Christ's disciples have to live in celibacy. However, it is a general view that Christ himself lived a life of perfect chastity; thus, "Voluntary chastity is the imitation of him who was the virgin Son of a virgin Mother". One of his invocations is "King of virgins and lover of stainless chastity" "(Rex virginum, amator castitatis)". Furthermore, Christ says the following in Matthew 19, verse 12: "There are those who choose to live like eunuchs for the sake of the kingdom of heaven. The one who can accept this should accept it." Many supporters of priestly celibacy rely on this passage.

While eunuchs were not generally celibate, over subsequent centuries this statement has come to be interpreted as referring to celibacy.
Paul the Apostle emphasized the importance of overcoming the desires of the flesh and saw the state of celibacy being superior to that of marriage. Paul made parallels between the relations between spouses and God's relationship with the church. "Husbands, love your wives even as Christ loved the church. Husbands should love their wives as their own bodies" (Ephesians 5:25–28). Paul himself was celibate and said that his wish was "that all of you were as I am" (1 Corinthians 7:7). In fact, this entire chapter is a defense of and a call to celibacy.

The early Christians lived in the belief that the end of the world would soon come upon them, and saw no point in planning new families and having children. According to Chadwick, this was why Paul encouraged both celibate and marital lifestyles among the members of the Corinthian congregation, regarding celibacy as the preferable of the two.

In the counsels of perfection (evangelical counsels), which include chastity alongside poverty and obedience, Jesus is said to have "[given] the rule of the higher life, founded upon his own most perfect life", for those who seek "the highest perfection" and feel "called to follow Christ in this way"—i.e. through such "exceptional sacrifices".

A number of early Christian martyrs were women or girls who had given themselves to Christ in perpetual virginity, such as Saint Agnes and Saint Lucy. According to most Christian thought, the first sacred virgin was Mary, the mother of Jesus, who was consecrated by the Holy Spirit during the Annunciation. Tradition also has it that the Apostle Matthew consecrated virgins. In the Catholic Church and the Orthodox churches, a consecrated virgin is a woman who has been consecrated by the church to a life of perpetual virginity in the service of the church.

The Desert Fathers were Christian hermits and ascetics who had a major influence on the development of Christianity and celibacy. Paul of Thebes is often credited with being the first hermit or anchorite to go to the desert, but it was Anthony the Great who launched the movement that became the Desert Fathers. Sometime around AD 270, Anthony heard a Sunday sermon stating that perfection could be achieved by selling all of one's possessions, giving the proceeds to the poor, and following Christ (Matthew 19:21). He followed the advice and made the further step of moving deep into the desert to seek complete solitude.

Over time, the model of Anthony and other hermits attracted many followers, who lived alone in the desert or in small groups. They chose a life of extreme asceticism, renouncing all the pleasures of the senses, rich food, baths, rest, and anything that made them comfortable. Thousands joined them in the desert, mostly men but also a handful of women. Religious seekers also began going to the desert seeking advice and counsel from the early Desert Fathers. By the time of Anthony's death, there were so many men and women living in the desert in celibacy that it was described as "a city" by Anthony's biographer.

The first Conciliar document on clerical celibacy of the Western Church (Synod of Elvira, can. xxxiii) states that the discipline of celibacy is to refrain from the use of marriage, i.e. refrain from having carnal contact with one's spouse.

According to the later St. Jerome (420), celibacy is a moral virtue, consisting of living in the flesh, but outside the flesh, and so being not corrupted by it ("vivere in carne praeter carnem"). Celibacy excludes not only libidinous acts, but also sinful thoughts or desires of the flesh. Jerome referred to marriage prohibition for priests when he claimed in "Against Jovinianus" that Peter and the other apostles had been married before they were called, but subsequently gave up their marital relations.

In the Catholic, Orthodox and Oriental Orthodox traditions, bishops are required to be celibate. In the Eastern Catholic and Orthodox traditions, priests and deacons are allowed to be married, yet have to remain celibate if they are unmarried at the time of ordination.

In the early Church, higher clerics lived in marriages. Augustine taught that the original sin of Adam and Eve was either an act of foolishness "(insipientia)" followed by pride and disobedience to God, or else inspired by pride. The first couple disobeyed God, who had told them not to eat of the tree of the knowledge of good and evil (Gen 2:17). The tree was a symbol of the order of creation. Self-centeredness made Adam and Eve eat of it, thus failing to acknowledge and respect the world as it was created by God, with its hierarchy of beings and values. They would not have fallen into pride and lack of wisdom, if Satan had not sown into their senses "the root of evil" "(radix mali)". Their nature was wounded by concupiscence or libido, which affected human intelligence and will, as well as affections and desires, including sexual desire.
The sin of Adam is inherited by all human beings. Already in his pre-Pelagian writings, Augustine taught that original sin was transmitted by concupiscence, which he regarded as the passion of both soul and body, making humanity a "massa damnata" (mass of perdition, condemned crowd) and much enfeebling, though not destroying, the freedom of the will.

In the early 3rd century, the Canons of the Apostolic Constitutions decreed that only lower clerics might still marry after their ordination, but marriage of bishops, priests, and deacons were not allowed.

One explanation for the origin of obligatory celibacy is that it is based on the writings of Saint Paul, who wrote of the advantages of celibacy allowed a man in serving the Lord. Celibacy was popularised by the early Christian theologians like Saint Augustine of Hippo and Origen. Another possible explanation for the origins of obligatory celibacy revolves around more practical reason, "the need to avoid claims on church property by priests' offspring". It remains a matter of Canon Law (and often a criterion for certain religious orders, especially Franciscans) that priests may not own land and therefore cannot pass it on to legitimate or illegitimate children. The land belongs to the Church through the local diocese as administered by the Local Ordinary (usually a bishop), who is often an "ex officio" corporation sole. Celibacy is viewed differently by the Catholic Church and the various Protestant communities. It includes clerical celibacy, celibacy of the consecrated life, voluntary lay celibacy, and celibacy outside of marriage.

The Protestant Reformation rejected celibate life and sexual continence for preachers. Protestant celibate communities have emerged, especially from Anglican and Lutheran backgrounds. A few minor Christian sects advocate celibacy as a better way of life. These groups included the Shakers, the Harmony Society and the Ephrata Cloister.

Many evangelicals prefer the term "abstinence" to "celibacy". Assuming everyone will marry, they focus their discussion on refraining from premarital sex and focusing on the joys of a future marriage. But some evangelicals, particularly older singles, desire a positive message of celibacy that moves beyond the "wait until marriage" message of abstinence campaigns. They seek a new understanding of celibacy that is focused on God rather than a future marriage or a lifelong vow to the Church.

There are also many Pentecostal churches which practice celibate ministry. For instance, the full-time ministers of the Pentecostal Mission are celibate and generally single. Married couples who enter full-time ministry may become celibate and could be sent to different locations.

During the first three or four centuries, no law was promulgated prohibiting clerical marriage. Celibacy was a matter of choice for bishops, priests, and deacons.
Statutes forbidding clergy from having wives were written beginning with the Council of Elvira (306) but these early statutes were not universal and were often defied by clerics and then retracted by hierarchy. The Synod of Gangra (345) condemned a false asceticism whereby worshipers boycotted celebrations presided over by married clergy. The Apostolic Constitutions () excommunicated a priest or bishop who left his wife "under the pretense of piety" (Mansi, 1:51).

"A famous letter of Synesius of Cyrene () is evidence both for the respecting of personal decision in the matter and for contemporary appreciation of celibacy. For priests and deacons clerical marriage continued to be in vogue".

"The Second Lateran Council (1139) seems to have enacted the first written law making sacred orders a direct impediment to marriage for the universal Church." Celibacy was first required of some clerics in 1123 at the First Lateran Council. Because clerics resisted it, the celibacy mandate was restated at the Second Lateran Council (1139) and the Council of Trent (1545–64). In places, coercion and enslavement of clerical wives and children was apparently involved in the enforcement of the law. "The earliest decree in which the children [of clerics] were declared to be slaves and never to be enfranchised [freed] seems to have been a canon of the Synod of Pavia in 1018. Similar penalties were promulgated against wives and concubines (see the Synod of Melfi, 1189 can. xii), who by the very fact of their unlawful connexion with a subdeacon or clerk of higher rank became liable to be seized by the over-lord".

In the Roman Catholic Church, the Twelve Apostles are considered to have been the first priests and bishops of the Church. Some say the call to be eunuchs for the sake of Heaven in Matthew 19 was a call to be sexually continent and that this developed into celibacy for priests as the successors of the apostles. Others see the call to be sexually continent in Matthew 19 to be a caution for men who were too readily divorcing and remarrying.

The view of the Church is that celibacy is a reflection of life in Heaven, a source of detachment from the material world which aids in one's relationship with God. Celibacy is designed to "consecrate themselves with undivided heart to the Lord and to "the affairs of the Lord, they give themselves entirely to God and to men. It is a sign of this new life to the service of which the Church's minister is consecrated; accepted with a joyous heart celibacy radiantly proclaims the Reign of God." In contrast, Saint Peter, whom the Church considers its first Pope, was married given that he had a mother-in-law whom Christ healed (Matthew 8). But some argue that Peter was a widower, due to the fact that this passage does not mention his wife, and that his mother-in-law is the one who serves Christ and the apostles after she is healed. Furthermore, Peter himself states: "Then Peter spoke up, 'We have left everything to follow you!' 'Truly I tell you', Jesus replied, 'no one who has left home or brothers or sisters or mother or father or children or fields for me and the gospel will fail to receive a hundred times as much'" (Mark 10,28–30).

Usually, only celibate men are ordained as priests in the Latin Church. Married clergy who have converted from other Christian denominations can be ordained Roman Catholic priests without becoming celibate. Priestly celibacy is not "doctrine" of the Church (such as the belief in the Assumption of Mary) but a matter of discipline, like the use of the vernacular (local) language in Mass or Lenten fasting and abstinence. As such, it can theoretically change at any time though it still must be obeyed by Catholics until the change were to take place. The Eastern Catholic Churches ordain both celibate and married men. However, in both the East and the West, bishops are chosen from among those who are celibate. In Ireland, several priests have fathered children, the two most prominent being bishop Eamonn Casey and Michael Cleary.
The classical heritage flourished throughout the Middle Ages in both the Byzantine Greek East and the Latin West. When discerning the population of Christendom in Medieval Europe during the Middle Ages, Will Durant, referring to Plato's ideal community, stated on the "oratores" (clergy):

"The clergy, like Plato's guardians, were placed in authority not by the suffrages of the people, but by their talent as shown in ecclesiastical studies and administration, by their disposition to a life of meditation and simplicity, and (perhaps it should be added) by the influence of their relatives with the powers of state and church. In the latter half of the period in which they ruled [AD 800 onwards], the clergy were as free from family cares as even Plato could desire; and in some cases it would seem they enjoyed no little of the reproductive freedom accorded to the guardians. Celibacy was part of the psychological structure of the power of the clergy; for on the one hand they were unimpeded by the narrowing egoism of the family, and on the other their apparent superiority to the call of the flesh added to the awe in which lay sinners held them …"

With respect to clerical celibacy, Richard P. O'Brien stated in 1995, that in his opinion, "greater understanding of human psychology has led to questions regarding the impact of celibacy on the human development of the clergy. The realization that many non-European countries view celibacy negatively has prompted questions concerning the value of retaining celibacy as an absolute and universal requirement for ordained ministry in the Roman Catholic Church".

Some homosexual Christians choose to be celibate following their denomination's teachings on homosexuality.

In 2014, the American Association of Christian Counselors amended its code of ethics to eliminate the promotion of conversion therapy for homosexuals and encouraged them to be celibate instead.

In Hinduism, celibacy is usually associated with the "sadhus" ("holy men"), ascetics who withdraw from society and renounce all worldly ties. Celibacy, termed "brahmacharya" in Vedic scripture, is the fourth of the "yamas" and the word literally translated means "dedicated to the Divinity of Life". The word is often used in yogic practice to refer to celibacy or denying pleasure, but this is only a small part of what "brahmacharya" represents. The purpose of practicing "brahmacharya" is to keep a person focused on the purpose in life, the things that instill a feeling of peace and contentment. It is also used to cultivate occult powers and many supernatural feats, called siddhi.

Islamic attitudes toward celibacy have been complex, Muhammad denounced it, however some Sufi orders embrace it. Islam does not promote celibacy; rather it condemns premarital sex and extramarital sex. In fact, according to Islam, marriage enables one to attain the highest form of righteousness within this sacred spiritual bond but the Qur'an does not state it as an obligation. The Qur'an () states, "But the Monasticism which they (who followed Jesus) invented for themselves, We did not prescribe for them but only to please God therewith, but that they did not observe it with the right observance." Therefore, religion is clearly not a reason to stay unmarried although people are allowed to live their lives however they are comfortable; but relationships and sex outside of marriage, let alone forced marriage, is definitely a sin, "Oh you who believe! You are forbidden to inherit women against their will" (). In addition, marriage partners can be distractions from practicing religion at the same time, "Your mates and children are only a trial for you" () however that still does not mean Islam does not encourage people who have sexual desires and are willing to marry. Anyone who does not (intend to) get married in this life can always do it in the Hereafter instead.

Celibacy appears as a peculiarity among some Sufis.

Celibacy was practiced by women saints in Sufism. Celibacy was debated along with women's roles in Sufism in medieval times.

Celibacy, poverty, meditation, and mysticism within an ascetic context along with worship centered around saints' tombs were promoted by the Qadiri Sufi order among Hui Muslims in China. In China, unlike other Muslim sects, the leaders (Shaikhs) of the Qadiriyya Sufi order are celibate. Unlike other Sufi orders in China, the leadership within the order is not a hereditary position, rather, one of the disciples of the celibate Shaikh is chosen by the Shaikh to succeed him. The 92-year-old celibate Shaikh Yang Shijun was the leader of the Qadiriya order in China as of 1998.

Celibacy is practiced by Haydariya Sufi dervishes.

The spiritual teacher Meher Baba stated that "[F]or the [spiritual] aspirant a life of strict celibacy is preferable to married life, if restraint comes to him easily without undue sense of self-repression. Such restraint is difficult for most persons and sometimes impossible, and for them married life is decidedly more helpful than a life of celibacy. For ordinary persons, married life is undoubtedly advisable unless they have a special aptitude for celibacy". Baba also asserted that "The value of celibacy lies in the habit of restraint and the sense of detachment and independence which it gives" and that "The aspirant must choose one of the two courses which are open to him. He must take to the life of celibacy or to the married life, and he must avoid at all costs a cheap compromise between the two. Promiscuity in sex gratification is bound to land the aspirant in a most pitiful and dangerous chaos of ungovernable lust."

In Sparta and many other Greek cities, failure to marry was grounds for loss of citizenship, and could be prosecuted as a crime. Both Cicero and Dionysius of Halicarnassus stated that Roman law forbade celibacy. There are no records of such a prosecution, nor is the Roman punishment for refusing to marry known.

Pythagoreanism was the system of esoteric and metaphysical beliefs held by Pythagoras and his followers. Pythagorean thinking was dominated by a profoundly mystical view of the world. The Pythagorean code further restricted his members from eating meat, fish, and beans which they practised for religious, ethical and ascetic reasons, in particular the idea of metempsychosis – the transmigration of souls into the bodies of other animals.
"Pythagoras himself established a small community that set a premium on study, vegetarianism, and sexual restraint or abstinence. Later philosophers believed that celibacy would be conducive to the detachment and equilibrium required by the philosopher's calling."

The tradition of sworn virgins developed out of the "Kanuni i Lekë Dukagjinit" (, or simply the "Kanun"). The "Kanun" is not a religious document – many groups follow this code, including Roman Catholics, the Albanian Orthodox, and Muslims.

Women who become sworn virgins make a vow of celibacy, and are allowed to take on the social role of men: inheriting land, wearing male clothing, etc.




Coalition government

A coalition government is a government where political parties enter a power-sharing arrangement of the executive. Coalition governments usually occur when no single party has achieved an absolute majority after an election. A party not having majority is common under proportional representation, but not in nations with majoritarian electoral systems.

A coalition government might also be created in a time of national difficulty or crisis (for example, during wartime or economic crisis) to give a government the high degree of perceived political legitimacy or collective identity, it can also play a role in diminishing internal political strife. 

In such times, parties have formed all-party coalitions (national unity governments, grand coalitions). If a coalition collapses, the Prime Minister and cabinet may be ousted by a vote of no confidence, call snap elections, form a new majority coalition, or continue as a minority government.

In multi-party states, a coalition agreement is an agreement negotiated between the parties that form a coalition government. It codifies the most important shared goals and objectives of the cabinet. It is often written by the leaders of the parliamentary groups. Coalitions that have a written agreement are more productive than those that do not.

Countries which often operate with coalition cabinets include: the Nordic countries, the Benelux countries, Australia, Austria, Brazil, Chile, Cyprus, France, Germany, Greece, India, Indonesia, Ireland, Israel, Italy, Japan, Kenya, Kosovo, Latvia, Lebanon, Lesotho Lithuania, Malaysia, Nepal, New Zealand, Pakistan, Thailand, Spain, Trinidad and Tobago, Turkey, and Ukraine. Switzerland has been ruled by a consensus government with a coalition of the four strongest parties in parliament since 1959, called the "Magic Formula". Between 2010 and 2015, the United Kingdom also operated a formal coalition between the Conservative and the Liberal Democrat parties, but this was unusual: the UK usually has a single-party majority government. Not every parliament forms a coalition government, for example the European Parliament.

Armenia became an independent state in 1991, following the collapse of the Soviet Union. Since then, many political parties were formed in it, who mainly work with each other to form coalition governments. The country was governed by the My Step Alliance coalition after successfully gaining a majority in the National Assembly of Armenia following the 2018 Armenian parliamentary election.

In federal Australian politics, the conservative Liberal, National, Country Liberal and Liberal National parties are united in a coalition, known simply as the Coalition.

While nominally two parties, the Coalition has become so stable, at least at the federal level, that in practice the lower house of Parliament has become a two-party system, with the Coalition and the Labor Party being the major parties. This coalition is also found in the states of New South Wales and Victoria. In South Australia and Western Australia the Liberal and National parties compete separately, while in the Northern Territory and Queensland the two parties have merged, forming the Country Liberal Party, in 1978, and the Liberal National Party, in 2008, respectively.

Coalition governments involving the Labor Party and the Australian Greens have occurred at state and territory level, for example following the 2010 Tasmanian state election and the 2016 and 2020 Australian Capital Territory elections.

In Belgium, a nation internally divided along linguistic lines (primarily between Dutch-speaking Flanders in the north and French-speaking Wallonia in the south, with Brussels also being by and large Francophone), each main political disposition (Social democracy, liberalism, right-wing populism, etc.) is, with the exception of the far-left Workers' Party of Belgium, split between Francophone and Dutch-speaking parties (e.g. the Dutch-speaking Vooruit and French-speaking Socialist Party being the two social-democratic parties). In the 2019 federal election, no party got more than 17% of the vote. Thus, forming a coalition government is an expected and necessary part of Belgian politics. In Belgium, coalition governments containing ministers from six or more parties are not uncommon; consequently, government formation can take an exceptionally long time. Between 2007 and 2011, Belgium operated under a caretaker government as no coalition could be formed.

In Canada, the Great Coalition was formed in 1864 by the Clear Grits, , and Liberal-Conservative Party. During the First World War, Prime Minister Robert Borden attempted to form a coalition with the opposition Liberals to broaden support for controversial conscription legislation. The Liberal Party refused the offer but some of their members did cross the floor and join the government. Although sometimes referred to as a coalition government, according to the definition above, it was not. It was disbanded after the end of the war.

During the 2008–09 Canadian parliamentary dispute, two of Canada's opposition parties signed an agreement to form what would become the country's second federal coalition government since Confederation if the minority Conservative government was defeated on a vote of non-confidence, unseating Stephen Harper as Prime Minister. The agreement outlined a formal coalition consisting of two opposition parties, the Liberal Party and the New Democratic Party. The Bloc Québécois agreed to support the proposed coalition on confidence matters for 18 months. In the end, parliament was prorogued by the Governor General, and the coalition dispersed before parliament was reconvened.

According to historian Christopher Moore, coalition governments in Canada became much less possible in 1919, when the leaders of parties were no longer chosen by elected MPs but instead began to be chosen by party members. Such a manner of leadership election had never been tried in any parliamentary system before. According to Moore, as long as that kind of leadership selection process remains in place and concentrates power in the hands of the leader, as opposed to backbenchers, then coalition governments will be very difficult to form. Moore shows that the diffusion of power within a party tends to also lead to a diffusion of power in the parliament in which that party operates, thereby making coalitions more likely.

Several coalition governments have been formed within provincial politics. As a result of the 1919 Ontario election, the United Farmers of Ontario and the Labour Party, together with three independent MLAs, formed a coalition that governed Ontario until 1923.

In British Columbia, the governing Liberals formed a coalition with the opposition Conservatives in order to prevent the surging, left-wing Cooperative Commonwealth Federation from taking power in the 1941 British Columbia general election. Liberal premier Duff Pattullo refused to form a coalition with the third-place Conservatives, so his party removed him. The Liberal–Conservative coalition introduced a winner-take-all preferential voting system (the "Alternative Vote") in the hopes that their supporters would rank the other party as their second preference; however, this strategy backfired in the subsequent 1952 British Columbia general election where, to the surprise of many, the right-wing populist BC Social Credit Party won a minority. They were able to win a majority in the subsequent election as Liberal and Conservative supporters shifted their anti-CCF vote to Social Credit.

Manitoba has had more formal coalition governments than any other province. Following gains by the United Farmer's/Progressive movement elsewhere in the country, the United Farmers of Manitoba unexpectedly won the 1921 election. Like their counterparts in Ontario, they had not expected to win and did not have a leader. They asked John Bracken, a professor in animal husbandry, to become leader and premier. Bracken changed the party's name to the Progressive Party of Manitoba. During the Great Depression, Bracken survived at a time when other premiers were being defeated by forming a coalition government with the Manitoba Liberals (eventually, the two parties would merge into the , and decades later, the party would change its name to the Manitoba Liberal Party). In 1940, Bracken formed a wartime coalition government with almost every party in the Manitoba Legislature (the Conservatives, CCF, and Social Credit; however, the CCF broke with the coalition after a few years over policy differences). The only party not included was the small, communist Labor-Progressive Party, which had a handful of seats.

In Saskatchewan, NDP premier Roy Romanow formed a formal coalition with the Saskatchewan Liberals in 1999 after being reduced to a minority. After two years, the newly elected Liberal leader David Karwacki ordered the coalition be disbanded, the Liberal caucus disagreed with him and left the Liberals to run as New Democrats in the upcoming election. The Saskatchewan NDP was re-elected with a majority under its new leader Lorne Calvert, while the Saskatchewan Liberals lost their remaining seats and have not been competitive in the province since.

From the creation of the Folketing in 1849 through the introduction of proportional representation in 1918, there were only single-party governments in Denmark. Thorvald Stauning formed his second government and Denmark's first coalition government in 1929. Since then, the norm has been coalition governments, though there have been periods where single-party governments were frequent, such as the decade after the end of World War II, during the 1970s, and in the late 2010s. Every government from 1982 until the 2015 elections were coalitions. While Mette Frederiksen's first government only consisted of her own Social Democrats, her second government is a coalition of the Social Democrats, Venstre, and the Moderates.

When the Social Democrats under Stauning won 46% of the votes in the 1935 election, this was the closest any party has gotten to winning an outright majority in parliament since 1918. One party has thus never held a majority alone, and even one-party governments have needed to have confidence agreements with at least one other party to govern. For example, though Frederiksen's first government only consisted of the Social Democrats, it also relied on the support of the Social Liberal Party, the Socialist People's Party, and the Red–Green Alliance.

In Finland, no party has had an absolute majority in the parliament since independence, and multi-party coalitions have been the norm. Finland experienced its most stable government (Lipponen I and II) since independence with a five-party governing coalition, a so-called "rainbow government". The Lipponen cabinets set the stability record and were unusual in the respect that both the centre-left (SDP) and radical left-wing (Left Alliance) parties sat in the government with the major centre-right party (National Coalition). The Katainen cabinet was also a rainbow coalition of a total of five parties.

In Germany, coalition governments are the norm, as it is rare for any single party to win a majority in parliament. The German political system makes extensive use of the constructive vote of no confidence, which requires governments to control an absolute majority of seats. Every government since the foundation of the Federal Republic in 1949 has involved at least two political parties. Typically, governments involve one of the two major parties forming a coalition with a smaller party. For example, from 1982 to 1998, the country was governed by a coalition of the CDU/CSU with the minor Free Democratic Party (FDP); from 1998 to 2005, a coalition of the Social Democratic Party of Germany (SPD) and the minor Greens held power. The CDU/CSU comprises an alliance of the Christian Democratic Union of Germany and Christian Social Union in Bavaria, described as "sister parties" which form a joint parliamentary group, and for this purpose are always considered a single party. Coalition arrangements are often given names based on the colours of the parties involved, such as "red-green" for the SPD and Greens. Coalitions of three parties are often named after countries whose flags contain those colours, such as the black-yellow-green Jamaica coalition.

Grand coalitions of the two major parties also occur, but these are relatively rare, as they typically prefer to associate with smaller ones. However, if the major parties are unable to assemble a majority, a grand coalition may be the only practical option. This was the case following the 2005 federal election, in which the incumbent SPD–Green government was defeated but the opposition CDU/CSU–FDP coalition also fell short of a majority. A grand coalition government was subsequently formed between the CDU/CSU and the SPD. Partnerships like these typically involve carefully structured cabinets: Angela Merkel of the CDU/CSU became Chancellor while the SPD was granted the majority of cabinet posts.

Coalition formation has become increasingly complex as voters increasingly migrate away from the major parties during the 2000s and 2010s. While coalitions of more than two parties were extremely rare in preceding decades, they have become common on the state level. These often include the liberal FDP and the Greens alongside one of the major parties, or "red–red–green" coalitions of the SPD, Greens, and The Left. In the eastern states, dwindling support for moderate parties has seen the rise of new forms of grand coalitions such as the Kenya coalition. The rise of populist parties also increases the time that it takes for a successful coalition to form. By 2016, the Greens were participating eleven governing coalitions on the state level in seven different constellations. During campaigns, parties often declare which coalitions or partners they prefer or reject. This tendency toward fragmentation also spread to the federal level, particularly during the 2021 federal election, which saw the CDU/CSU and SPD fall short of a combined majority of votes for the first time in history.

After India's Independence on 15 August 1947, the Indian National Congress, the major political party instrumental in the Indian independence movement, ruled the nation. The first Prime Minister, Jawaharlal Nehru, his successor Lal Bahadur Shastri, and the third Prime Minister, Indira Gandhi, were all members of the Congress party. However, Raj Narain, who had unsuccessfully contested an election against Indira from the constituency of Rae Bareilly in 1971, lodged a case alleging electoral malpractice. In June 1975, Indira was found guilty and barred by the High Court from holding public office for six years. In response, a state of emergency was declared under the pretext of national security. The next election resulted in the formation of India's first ever national coalition government under the prime ministership of Morarji Desai, which was also the first non-Congress national government. It existed from 24 March 1977 to 15 July 1979, headed by the Janata Party, an amalgam of political parties opposed to the emergency imposed between 1975 and 1977. As the popularity of the Janata Party dwindled, Desai had to resign, and Chaudhary Charan Singh, a rival of his, became the fifth Prime Minister. However, due to lack of support, this coalition government did not complete its five-year term.

Congress returned to power in 1980 under Indira Gandhi, and later under Rajiv Gandhi as the sixth Prime Minister. However, the general election of 1989 once again brought a coalition government under National Front, which lasted until 1991, with two Prime Ministers, the second one being supported by Congress. The 1991 election resulted in a Congress-led stable minority government for five years. The eleventh parliament produced three Prime Ministers in two years and forced the country back to the polls in 1998. The first successful coalition government in India which completed a whole five-year term was the Bharatiya Janata Party (BJP)-led National Democratic Alliance with Atal Bihari Vajpayee as Prime Minister from 1999 to 2004. Then another coalition, the Congress-led United Progressive Alliance, consisting of 13 separate parties, ruled India for two terms from 2004 to 2014 with Manmohan Singh as PM. However, in the 16th general election in May 2014, the BJP secured a majority on its own (becoming the first party to do so since the 1984 election), and the National Democratic Alliance came into power, with Narendra Modi as Prime Minister. In 2019, Narendra Modi was re-elected as Prime Minister as the National Democratic Alliance again secured a majority in the 17th general election.

As a result of the toppling of Suharto, political freedom is significantly increased. Compared to only three parties allowed to exist in the New Order era, a total of 48 political parties participated in the 1999 election and always a total of more than 10 parties in next elections. There are no majority winner of those elections and coalition governments are inevitable. The current government is a coalition of seven parties led by the major centre-left PDIP to let governing big tent Onward Indonesia Coalition

In Ireland, coalition governments are common; not since 1977 has a single party formed a majority government. Coalition governments to date have been led by either Fianna Fáil or Fine Gael. They have been joined in government by one or more smaller parties or independent members of parliament (TDs).

Ireland's first coalition government was formed after the 1948 general election, with five parties and independents represented at cabinet. Before 1989, Fianna Fáil had opposed participation in coalition governments, preferring single-party minority government instead. It formed a coalition government with the Progressive Democrats in that year.

The Labour Party has been in government on eight occasions. On all but one of those occasions, it was as a junior coalition party to Fine Gael. The exception was a government with Fianna Fáil from 1993 to 1994. The 29th Government of Ireland (2011–16), was a grand coalition of the two largest parties, as Fianna Fáil had fallen to third place in the Dáil.

The current government is a Fianna Fáil, Fine Gael and the Green Party. It is the first time Fianna Fáil and Fine Gael have served in government together, having derived from opposing sides in the Irish Civil War (1922–23).

A similar situation exists in Israel, which typically has at least 10 parties holding representation in the Knesset. The only faction to ever gain the majority of Knesset seats was Alignment, an alliance of the Labor Party and Mapam that held an absolute majority for a brief period from 1968 to 1969. Historically, control of the Israeli government has alternated between periods of rule by the right-wing Likud in coalition with several right-wing and religious parties and periods of rule by the center-left Labor in coalition with several left-wing parties. Ariel Sharon's formation of the centrist Kadima party in 2006 drew support from former Labor and Likud members, and Kadima ruled in coalition with several other parties.

Israel also formed a national unity government from 1984–1988. The premiership and foreign ministry portfolio were held by the head of each party for two years, and they switched roles in 1986.

In Japan, controlling a majority in the House of Representatives is enough to decide the election of the prime minister (=recorded, two-round votes in both houses of the National Diet, yet the vote of the House of Representatives decision eventually overrides a dissenting House of Councillors vote automatically after the mandatory conference committee procedure fails which, by precedent, it does without real attempt to reconcile the different votes). Therefore, a party that controls the lower house can form a government on its own. It can also pass a budget on its own. But passing any law (including important budget-related laws) requires either majorities in both houses of the legislature or, with the drawback of longer legislative proceedings, a two-thirds majority in the House of Representatives.

In recent decades, single-party full legislative control is rare, and coalition governments are the norm: Most governments of Japan since the 1990s and, as of 2020, all since 1999 have been coalition governments, some of them still fell short of a legislative majority. The Liberal Democratic Party (LDP) held a legislative majority of its own in the National Diet until 1989 (when it initially continued to govern alone), and between the 2016 and 2019 elections (when it remained in its previous ruling coalition). The Democratic Party of Japan (through accessions in the House of Councillors) briefly controlled a single-party legislative majority for a few weeks before it lost the 2010 election (it, too, continued to govern as part of its previous ruling coalition).

From the constitutional establishment of parliamentary cabinets and the introduction of the new, now directly elected upper house of parliament in 1947 until the formation of the LDP and the reunification of the Japanese Socialist Party in 1955, no single party formally controlled a legislative majority on its own. Only few formal coalition governments (46th, 47th, initially 49th cabinet) interchanged with technical minority governments and cabinets without technical control of the House of Councillors (later called "twisted Diets", "nejire kokkai", when they were not only technically, but actually divided). But during most of that period, the centrist Ryokufūkai was the strongest overall or decisive cross-bench group in the House of Councillors, and it was willing to cooperate with both centre-left and centre-right governments even when it was not formally part of the cabinet; and in the House of Representatives, minority governments of Liberals or Democrats (or their precursors; loose, indirect successors to the two major pre-war parties) could usually count on support from some members of the other major conservative party or from smaller conservative parties and independents. Finally in 1955, when Hatoyama Ichirō's Democratic Party minority government called early House of Representatives elections and, while gaining seats substantially, remained in the minority, the Liberal Party refused to cooperate until negotiations on a long-debated "conservative merger" of the two parties were agreed upon, and eventually successful.

After it was founded in 1955, the Liberal Democratic Party dominated Japan's governments for a long period: The new party governed alone without interruption until 1983, again from 1986 to 1993 and most recently between 1996 and 1999. The first time the LDP entered a coalition government followed its third loss of its House of Representatives majority in the 1983 House of Representatives general election. The LDP-New Liberal Club coalition government lasted until 1986 when the LDP won landslide victories in simultaneous double elections to both houses of parliament.

There have been coalition cabinets where the post of prime minister was given to a junior coalition partner: the JSP-DP-Cooperativist coalition government in 1948 of prime minister Ashida Hitoshi (DP) who took over after his JSP predecessor Tetsu Katayama had been toppled by the left wing of his own party, the JSP-Renewal-Kōmei-DSP-JNP-Sakigake-SDF-DRP coalition in 1993 with Morihiro Hosokawa (JNP) as compromise PM for the Ichirō Ozawa-negotiated rainbow coalition that removed the LDP from power for the first time to break up in less than a year, and the LDP-JSP-Sakigake government that was formed in 1994 when the LDP had agreed, if under internal turmoil and with some defections, to bury the main post-war partisan rivalry and support the election of JSP prime minister Tomiichi Murayama in exchange for the return to government.

Ever since Malaysia gained independence in 1957, none of its federal governments have ever been controlled by a single political party. Due to the social nature of the country, the first federal government was formed by a three-party Alliance coalition, composed of the United Malays National Organisations (UMNO), the Malaysian Chinese Association (MCA), and the Malaysian Indian Congress (MIC). It was later expanded and rebranded as Barisan Nasional (BN), which includes parties representing the Malaysian states of Sabah and Sarawak.

The 2018 Malaysian general election saw the first non-BN coalition federal government in the country's electoral history, formed through an alliance between the Pakatan Harapan (PH) coalition and the Sabah Heritage Party (WARISAN). The federal government formed after the 2020–2022 Malaysian political crisis was the first to be established through coordination between multiple political coalitions. This occurred when the newly formed Perikatan Nasional (PN) coalition partnered with BN and Gabungan Parti Sarawak (GPS). In 2022 after its registration, Sabah-based Gabungan Rakyat Sabah (GRS) formally joined the government (though it had been a part of an informal coalition since 2020). The current government led by Prime Minister Anwar Ibrahim is composed of four political coalitions and 19 parties.

MMP was introduced in New Zealand in the 1996 election. 
In order to get into power, parties need to get a total of 50% of the approximately (there can be more if an Overhang seat exists) 120 seats in parliament – 61. Since it is rare for a party to win a full majority, they must form coalitions with other parties. For example, during the 2017 general election, Labour won 46 seats and New Zealand First won nine. The two formed a Coalition Government with confidence and supply from the Green Party who won eight seats.

Since 2015, there are many more coalition governments than previously in municipalities, autonomous regions and, since 2020 (coming from the November 2019 Spanish general election), in the Spanish Government. There are two ways of conforming them: all of them based on a program and its institutional architecture, one consists on distributing the different areas of government between the parties conforming the coalition and the other one is, like in the Valencian Community, where the ministries are structured with members of all the political parties being represented, so that conflicts that may occur are regarding competences and not fights between parties.

Coalition governments in Spain had already existed during the 2nd Republic, and have been common in some specific Autonomous Communities since the 1980s. Nonetheless, the prevalence of two big parties overall has been eroded and the need for coalitions appears to be the new normal since around 2015.

Turkey's first coalition government was formed after the 1961 general election, with two political parties and independents represented at cabinet. It was also Turkey's first grand coalition as the two largest political parties of opposing political ideologies (Republican People's Party and Justice Party) united. Between 1960 and 2002, 17 coalition governments were formed in Turkey. The media and the general public view coalition governments as unfavorable and unstable due to their lack of effectiveness and short lifespan. Following Turkey's transition to a presidential system in 2017, political parties focussed more on forming electoral alliances. Due to separation of powers, the government doesn't have to be formed by parliamentarians and therefore not obliged to result in a coalition government. However, the parliament can dissolve the cabinet if the parliamentary opposition is in majority.

In the United Kingdom, coalition governments (sometimes known as "national governments") usually have only been formed at times of national crisis. The most prominent was the National Government of 1931 to 1940. There were multi-party coalitions during both world wars. Apart from this, when no party has had a majority, minority governments normally have been formed with one or more opposition parties agreeing to vote in favour of the legislation which governments need to function: for instance the Labour government of James Callaghan formed a pact with the Liberals from March 1977 until July 1978, following a series of by-election defeats had eroded Labour's majority of three seats which had been gained at the October 1974 election. However, in the run-up to the 1997 general election, Labour opposition leader Tony Blair was in talks with Liberal Democrat leader Paddy Ashdown about forming a coalition government if Labour failed to win a majority at the election; but there proved to be no need for a coalition as Labour won the election by a landslide. The 2010 general election resulted in a hung parliament (Britain's first for 36 years), and the Conservatives, led by David Cameron, which had won the largest number of seats, formed a coalition with the Liberal Democrats in order to gain a parliamentary majority, ending 13 years of Labour government. This was the first time that the Conservatives and Lib Dems had made a power-sharing deal at Westminster. It was also the first full coalition in Britain since 1945, having been formed 70 years virtually to the day after the establishment of Winston Churchill's wartime coalition,
Labour and the Liberal Democrats have entered into a coalition twice in the Scottish Parliament, as well as twice in the Welsh Assembly.

Since the 1989 election, there have been 4 coalition governments, all including at least both the conservative National Party and the liberal Colorado Party. The first one was after the election of the blanco Luis Alberto Lacalle and lasted until 1992 due to policy disagreements, the longest lasting coalition was the Colorado-led coalition under the second government of Julio María Sanguinetti, in which the national leader Alberto Volonté was frequently described as a "Prime Minister", the next coalition (under president Jorge Batlle) was also Colorado-led, but it lasted only until after the 2002 Uruguay banking crisis, when the blancos abandoned the government. Following the 2019 Uruguayan general election, the blanco Luis Lacalle Pou formed the coalición multicolor, composed of his own National Party, the liberal Colorado Party, the eclectic Open Cabildo and the center left Independent Party.

Advocates of proportional representation suggest that a coalition government leads to more consensus-based politics, as a government comprising differing parties (often based on different ideologies) need to compromise about governmental policy. Another stated advantage is that a coalition government better reflects the popular opinion of the electorate within a country; this means, for instance, that the political system contains just one majority-based mechanism. Contrast this with district voting in which the majority mechanism occurs twice: first, the majority of voters pick the representative and, second, the body of representatives make a subsequent majority decision. The doubled majority decision undermines voter support for that decision. The benefit of proportional representation is that it contains that majority mechanism just once. Additionally, coalition partnership may play an important role in moderating the level of affective polarization over parties, that is, the animosity and hostility against the opponent party identifiers/supporters.

Those who disapprove of coalition governments believe that such governments have a tendency to be fractious and prone to disharmony, as their component parties hold differing beliefs and thus may not always agree on policy. Sometimes the results of an election mean that the coalitions which are mathematically most probable are ideologically infeasible, for example in Flanders or Northern Ireland. A second difficulty might be the ability of minor parties to play "kingmaker" and, particularly in close elections, gain far more power in exchange for their support than the size of their vote would otherwise justify.

Germany is the largest nation ever to have had proportional representation during the interbellum. After WW II, the German system, district based but then proportionally adjusted afterward, contains a threshold that keeps the number of parties limited. The threshold is set at five percent, resulting in empowered parties with at least a minimum amount of political gravity.

Coalition governments have also been criticized for sustaining a consensus on issues when disagreement and the consequent discussion would be more fruitful. To forge a consensus, the leaders of ruling coalition parties can agree to silence their disagreements on an issue to unify the coalition against the opposition. The coalition partners, if they control the parliamentary majority, can collude to make the parliamentary discussion on the issue irrelevant by consistently disregarding the arguments of the opposition and voting against the opposition's proposals — even if there is disagreement within the ruling parties about the issue. However, in winner-take-all this seems always to be the case.

Powerful parties can also act in an oligocratic way to form an alliance to stifle the growth of emerging parties. Of course, such an event is rare in coalition governments when compared to two-party systems, which typically exist because of stifling of the growth of emerging parties, often through discriminatory nomination rules regulations and plurality voting systems, and so on.

A single, more powerful party can shape the policies of the coalition disproportionately. Smaller or less powerful parties can be intimidated to not openly disagree. In order to maintain the coalition, they would have to vote against their own party's platform in the parliament. If they do not, the party has to leave the government and loses executive power. However, this is contradicted by the "kingmaker" factor mentioned above.

Finally, a strength that can also be seen as a weakness is that proportional representation puts the emphasis on collaboration. All parties involved are looking at the other parties in the best light possible, since they may be (future) coalition partners. The pendulum may therefore show less of a swing between political extremes. Still, facing external issues may then also be approached from a collaborative perspective, even when the outside force is not benevolent.

A legislative coalition or voting coalition is when political parties in a legislature align on voting to push forward specific policies or legislation, but do not engage in power-sharing of the executive branch like in coalition governments. 

In a parliamentary system, political parties may form a confidence and supply arrangement, pledging to support the governing party on legislative bills and motions that carry a vote of confidence. Unlike a coalition government, which is a more formalised partnership characterised by the sharing of the executive branch, a confidence and supply arrangement does not entail executive "power-sharing". Instead, it involves the governing party supporting specific proposals and priorities of the other parties in the arrangement, in return for their continued support on motions of confidence. 

In the United States, political parties have formed legislative coalitions in the past in order to push forward specific policies or legislation in the United States Congress. In 1855, a coalition was formed between members of the American party, Opposition Party and Republican Party to elect Nathaniel P. Banks speaker of the House. The most recent legislative coalition took place in 1917, a coalition was formed between members of the Democratic Party, Progressive Party and Socialist Party of America to elect Champ Clark speaker.

A coalition government, in which "power-sharing" of executive offices is performed, has not occurred in the United States. The norms that allow coalition governments to form and persist do not exist in the United States.

Chemical engineering

Chemical engineering is an engineering field which deals with the study of operation and design of chemical plants as well as methods of improving production. Chemical engineers develop economical commercial processes to convert raw materials into useful products. Chemical engineering uses principles of chemistry, physics, mathematics, biology, and economics to efficiently use, produce, design, transport and transform energy and materials. The work of chemical engineers can range from the utilization of nanotechnology and nanomaterials in the laboratory to large-scale industrial processes that convert chemicals, raw materials, living cells, microorganisms, and energy into useful forms and products. Chemical engineers are involved in many aspects of plant design and operation, including safety and hazard assessments, process design and analysis, modeling, control engineering, chemical reaction engineering, nuclear engineering, biological engineering, construction specification, and operating instructions.

Chemical engineers typically hold a degree in Chemical Engineering or Process Engineering. Practicing engineers may have professional certification and be accredited members of a professional body. Such bodies include the Institution of Chemical Engineers (IChemE) or the American Institute of Chemical Engineers (AIChE). A degree in chemical engineering is directly linked with all of the other engineering disciplines, to various extents.

A 1996 article cites James F. Donnelly for mentioning an 1839 reference to chemical engineering in relation to the production of sulfuric acid. In the same paper, however, George E. Davis, an English consultant, was credited with having coined the term. Davis also tried to found a Society of Chemical Engineering, but instead, it was named the Society of Chemical Industry (1881), with Davis as its first secretary. The "History of Science in United States: An Encyclopedia" puts the use of the term around 1890. "Chemical engineering", describing the use of mechanical equipment in the chemical industry, became common vocabulary in England after 1850. By 1910, the profession, "chemical engineer," was already in common use in Britain and the United States.

In the 1940s, it became clear that unit operations alone were insufficient in developing chemical reactors. While the predominance of unit operations in chemical engineering courses in Britain and the United States continued until the 1960s, transport phenomena started to receive greater focus. Along with other novel concepts, such as process systems engineering (PSE), a "second paradigm" was defined. Transport phenomena gave an analytical approach to chemical engineering while PSE focused on its synthetic elements, such as those of a control system and process design. Developments in chemical engineering before and after World War II were mainly incited by the petrochemical industry; however, advances in other fields were made as well. Advancements in biochemical engineering in the 1940s, for example, found application in the pharmaceutical industry, and allowed for the mass production of various antibiotics, including penicillin and streptomycin. Meanwhile, progress in polymer science in the 1950s paved way for the "age of plastics".

Concerns regarding large-scale chemical manufacturing facilities' safety and environmental impact were also raised during this period. "Silent Spring", published in 1962, alerted its readers to the harmful effects of DDT, a potent insecticide. The 1974 Flixborough disaster in the United Kingdom resulted in 28 deaths, as well as damage to a chemical plant and three nearby villages. 1984 Bhopal disaster in India resulted in almost 4,000 deaths. These incidents, along with other incidents, affected the reputation of the trade as industrial safety and environmental protection were given more focus. In response, the IChemE required safety to be part of every degree course that it accredited after 1982. By the 1970s, legislation and monitoring agencies were instituted in various countries, such as France, Germany, and the United States. In time, the systematic application of safety principles to chemical and other process plants began to be considered a specific discipline, known as process safety.

Advancements in computer science found applications for designing and managing plants, simplifying calculations and drawings that previously had to be done manually. The completion of the Human Genome Project is also seen as a major development, not only advancing chemical engineering but genetic engineering and genomics as well. Chemical engineering principles were used to produce DNA sequences in large quantities.

Chemical engineering involves the application of several principles. Key concepts are presented below.

Chemical engineering design concerns the creation of plans, specifications, and economic analyses for pilot plants, new plants, or plant modifications. Design engineers often work in a consulting role, designing plants to meet clients' needs. Design is limited by several factors, including funding, government regulations, and safety standards. These constraints dictate a plant's choice of process, materials, and equipment.

Plant construction is coordinated by project engineers and project managers, depending on the size of the investment. A chemical engineer may do the job of project engineer full-time or part of the time, which requires additional training and job skills or act as a consultant to the project group. In the USA the education of chemical engineering graduates from the Baccalaureate programs accredited by ABET do not usually stress project engineering education, which can be obtained by specialized training, as electives, or from graduate programs. Project engineering jobs are some of the largest employers for chemical engineers.

A unit operation is a physical step in an individual chemical engineering process. Unit operations (such as crystallization, filtration, drying and evaporation) are used to prepare reactants, purifying and separating its products, recycling unspent reactants, and controlling energy transfer in reactors. On the other hand, a unit process is the chemical equivalent of a unit operation. Along with unit operations, unit processes constitute a process operation. Unit processes (such as nitration, hydrogenation, and oxidation involve the conversion of materials by biochemical, thermochemical and other means. Chemical engineers responsible for these are called process engineers.

Process design requires the definition of equipment types and sizes as well as how they are connected and the materials of construction. Details are often printed on a Process Flow Diagram which is used to control the capacity and reliability of a new or existing chemical factory.

Education for chemical engineers in the first college degree 3 or 4 years of study stresses the principles and practices of process design. The same skills are used in existing chemical plants to evaluate the efficiency and make recommendations for improvements.

Modeling and analysis of transport phenomena is essential for many industrial applications. Transport phenomena involve fluid dynamics, heat transfer and mass transfer, which are governed mainly by momentum transfer, energy transfer and transport of chemical species, respectively. Models often involve separate considerations for macroscopic, microscopic and molecular level phenomena. Modeling of transport phenomena, therefore, requires an understanding of applied mathematics.

Chemical engineers "develop economic ways of using materials and energy". Chemical engineers use chemistry and engineering to turn raw materials into usable products, such as medicine, petrochemicals, and plastics on a large-scale, industrial setting. They are also involved in waste management and research. Both applied and research facets could make extensive use of computers.

Chemical engineers may be involved in industry or university research where they are tasked with designing and performing experiments, by scaling up theoretical chemical reactions, to create better and safer methods for production, pollution control, and resource conservation. They may be involved in designing and constructing plants as a project engineer. Chemical engineers serving as project engineers use their knowledge in selecting optimal production methods and plant equipment to minimize costs and maximize safety and profitability. After plant construction, chemical engineering project managers may be involved in equipment upgrades, troubleshooting, and daily operations in either full-time or consulting roles. 


List of comedians

A comedian is one who entertains through comedy, such as jokes and other forms of humour. Following is a list of comedians, comedy groups, and comedy writers.

"(sorted alphabetically by surname)"





"(sorted alphabetically by surname)"

Lists of comedians by nationality


Other related lists

Compact space

In mathematics, specifically general topology, compactness is a property that seeks to generalize the notion of a closed and bounded subset of Euclidean space. The idea is that a compact space has no "punctures" or "missing endpoints", i.e., it includes all "limiting values" of points. For example, the open interval (0,1) would not be compact because it excludes the limiting values of 0 and 1, whereas the closed interval [0,1] would be compact. Similarly, the space of rational numbers formula_1 is not compact, because it has infinitely many "punctures" corresponding to the irrational numbers, and the space of real numbers formula_2 is not compact either, because it excludes the two limiting values formula_3 and formula_4. However, the "extended" real number line "would" be compact, since it contains both infinities. There are many ways to make this heuristic notion precise. These ways usually agree in a metric space, but may not be equivalent in other topological spaces.

One such generalization is that a topological space is "sequentially" compact if every infinite sequence of points sampled from the space has an infinite subsequence that converges to some point of the space. The Bolzano–Weierstrass theorem states that a subset of Euclidean space is compact in this sequential sense if and only if it is closed and bounded. Thus, if one chooses an infinite number of points in the closed unit interval , some of those points will get arbitrarily close to some real number in that space. 
For instance, some of the numbers in the sequence accumulate to 0 (while others accumulate to 1). 
Since neither 0 nor 1 are members of the open unit interval , those same sets of points would not accumulate to any point of it, so the open unit interval is not compact. Although subsets (subspaces) of Euclidean space can be compact, the entire space itself is not compact, since it is not bounded. For example, considering formula_5 (the real number line), the sequence of points has no subsequence that converges to any real number.

Compactness was formally introduced by Maurice Fréchet in 1906 to generalize the Bolzano–Weierstrass theorem from spaces of geometrical points to spaces of functions. The Arzelà–Ascoli theorem and the Peano existence theorem exemplify applications of this notion of compactness to classical analysis. Following its initial introduction, various equivalent notions of compactness, including sequential compactness and limit point compactness, were developed in general metric spaces. In general topological spaces, however, these notions of compactness are not necessarily equivalent. The most useful notion — and the standard definition of the unqualified term "compactness" — is phrased in terms of the existence of finite families of open sets that "cover" the space in the sense that each point of the space lies in some set contained in the family. This more subtle notion, introduced by Pavel Alexandrov and Pavel Urysohn in 1929, exhibits compact spaces as generalizations of finite sets. In spaces that are compact in this sense, it is often possible to patch together information that holds locally – that is, in a neighborhood of each point – into corresponding statements that hold throughout the space, and many theorems are of this character.

The term compact set is sometimes used as a synonym for compact space, but also often refers to a compact subspace of a topological space.

In the 19th century, several disparate mathematical properties were understood that would later be seen as consequences of compactness. On the one hand, Bernard Bolzano (1817) had been aware that any bounded sequence of points (in the line or plane, for instance) has a subsequence that must eventually get arbitrarily close to some other point, called a limit point. 
Bolzano's proof relied on the method of bisection: the sequence was placed into an interval that was then divided into two equal parts, and a part containing infinitely many terms of the sequence was selected. 
The process could then be repeated by dividing the resulting smaller interval into smaller and smaller parts – until it closes down on the desired limit point. The full significance of Bolzano's theorem, and its method of proof, would not emerge until almost 50 years later when it was rediscovered by Karl Weierstrass.

In the 1880s, it became clear that results similar to the Bolzano–Weierstrass theorem could be formulated for spaces of functions rather than just numbers or geometrical points. 
The idea of regarding functions as themselves points of a generalized space dates back to the investigations of Giulio Ascoli and Cesare Arzelà. 
The culmination of their investigations, the Arzelà–Ascoli theorem, was a generalization of the Bolzano–Weierstrass theorem to families of continuous functions, the precise conclusion of which was that it was possible to extract a uniformly convergent sequence of functions from a suitable family of functions. The uniform limit of this sequence then played precisely the same role as Bolzano's "limit point". Towards the beginning of the twentieth century, results similar to that of Arzelà and Ascoli began to accumulate in the area of integral equations, as investigated by David Hilbert and Erhard Schmidt. 
For a certain class of Green's functions coming from solutions of integral equations, Schmidt had shown that a property analogous to the Arzelà–Ascoli theorem held in the sense of mean convergence – or convergence in what would later be dubbed a Hilbert space. This ultimately led to the notion of a compact operator as an offshoot of the general notion of a compact space. 
It was Maurice Fréchet who, in 1906, had distilled the essence of the Bolzano–Weierstrass property and coined the term "compactness" to refer to this general phenomenon (he used the term already in his 1904 paper which led to the famous 1906 thesis).

However, a different notion of compactness altogether had also slowly emerged at the end of the 19th century from the study of the continuum, which was seen as fundamental for the rigorous formulation of analysis. 
In 1870, Eduard Heine showed that a continuous function defined on a closed and bounded interval was in fact uniformly continuous. In the course of the proof, he made use of a lemma that from any countable cover of the interval by smaller open intervals, it was possible to select a finite number of these that also covered it. 
The significance of this lemma was recognized by Émile Borel (1895), and it was generalized to arbitrary collections of intervals by Pierre Cousin (1895) and Henri Lebesgue (1904). The Heine–Borel theorem, as the result is now known, is another special property possessed by closed and bounded sets of real numbers.

This property was significant because it allowed for the passage from local information about a set (such as the continuity of a function) to global information about the set (such as the uniform continuity of a function). This sentiment was expressed by , who also exploited it in the development of the integral now bearing his name. Ultimately, the Russian school of point-set topology, under the direction of Pavel Alexandrov and Pavel Urysohn, formulated Heine–Borel compactness in a way that could be applied to the modern notion of a topological space. showed that the earlier version of compactness due to Fréchet, now called (relative) sequential compactness, under appropriate conditions followed from the version of compactness that was formulated in terms of the existence of finite subcovers. It was this notion of compactness that became the dominant one, because it was not only a stronger property, but it could be formulated in a more general setting with a minimum of additional technical machinery, as it relied only on the structure of the open sets in a space.

Any finite space is compact; a finite subcover can be obtained by selecting, for each point, an open set containing it. A nontrivial example of a compact space is the (closed) unit interval of real numbers. If one chooses an infinite number of distinct points in the unit interval, then there must be some accumulation point among these points in that interval. For instance, the odd-numbered terms of the sequence get arbitrarily close to 0, while the even-numbered ones get arbitrarily close to 1. The given example sequence shows the importance of including the boundary points of the interval, since the limit points must be in the space itself — an open (or half-open) interval of the real numbers is not compact. It is also crucial that the interval be bounded, since in the interval , one could choose the sequence of points , of which no sub-sequence ultimately gets arbitrarily close to any given real number.

In two dimensions, closed disks are compact since for any infinite number of points sampled from a disk, some subset of those points must get arbitrarily close either to a point within the disc, or to a point on the boundary. However, an open disk is not compact, because a sequence of points can tend to the boundary – without getting arbitrarily close to any point in the interior. Likewise, spheres are compact, but a sphere missing a point is not since a sequence of points can still tend to the missing point, thereby not getting arbitrarily close to any point "within" the space. Lines and planes are not compact, since one can take a set of equally-spaced points in any given direction without approaching any point.

Various definitions of compactness may apply, depending on the level of generality. 
A subset of Euclidean space in particular is called compact if it is closed and bounded. This implies, by the Bolzano–Weierstrass theorem, that any infinite sequence from the set has a subsequence that converges to a point in the set. Various equivalent notions of compactness, such as sequential compactness and limit point compactness, can be developed in general metric spaces.

In contrast, the different notions of compactness are not equivalent in general topological spaces, and the most useful notion of compactness – originally called "bicompactness" – is defined using covers consisting of open sets (see "Open cover definition" below). 
That this form of compactness holds for closed and bounded subsets of Euclidean space is known as the Heine–Borel theorem. Compactness, when defined in this manner, often allows one to take information that is known locally – in a neighbourhood of each point of the space – and to extend it to information that holds globally throughout the space. An example of this phenomenon is Dirichlet's theorem, to which it was originally applied by Heine, that a continuous function on a compact interval is uniformly continuous; here, continuity is a local property of the function, and uniform continuity the corresponding global property.

Formally, a topological space is called "compact" if every open cover of has a finite subcover. That is, is compact if for every collection of open subsets of such that

formula_6

there is a finite subcollection ⊆ such that

formula_7

Some branches of mathematics such as algebraic geometry, typically influenced by the French school of Bourbaki, use the term "quasi-compact" for the general notion, and reserve the term "compact" for topological spaces that are both Hausdorff and "quasi-compact". A compact set is sometimes referred to as a "compactum", plural "compacta".

A subset of a topological space is said to be compact if it is compact as a subspace (in the subspace topology). That is, is compact if for every arbitrary collection of open subsets of such that

formula_8

there is a finite subcollection ⊆ such that

formula_9

Compactness is a topological property. That is, if formula_10, with subset equipped with the subspace topology, then is compact in if and only if is compact in .

If is a topological space then the following are equivalent:

Bourbaki defines a compact space (quasi-compact space) as a topological space where each filter has a cluster point (i.e., 8. in the above).

For any subset of Euclidean space, is compact if and only if it is closed and bounded; this is the Heine–Borel theorem.

As a Euclidean space is a metric space, the conditions in the next subsection also apply to all of its subsets. Of all of the equivalent conditions, it is in practice easiest to verify that a subset is closed and bounded, for example, for a closed interval or closed -ball.

For any metric space , the following are equivalent (assuming countable choice):

A compact metric space also satisfies the following properties:

For an ordered space (i.e. a totally ordered set equipped with the order topology), the following are equivalent:

An ordered space satisfying (any one of) these conditions is called a complete lattice.

In addition, the following are equivalent for all ordered spaces , and (assuming countable choice) are true whenever is compact. (The converse in general fails if is not also metrizable.):

Let be a topological space and the ring of real continuous functions on . 
For each , the evaluation map formula_12
given by is a ring homomorphism. 
The kernel of is a maximal ideal, since the residue field is the field of real numbers, by the first isomorphism theorem. A topological space is pseudocompact if and only if every maximal ideal in has residue field the real numbers. For completely regular spaces, this is equivalent to every maximal ideal being the kernel of an evaluation homomorphism. There are pseudocompact spaces that are not compact, though.

In general, for non-pseudocompact spaces there are always maximal ideals in such that the residue field is a (non-Archimedean) hyperreal field. The framework of non-standard analysis allows for the following alternative characterization of compactness: a topological space is compact if and only if every point of the natural extension is infinitely close to a point of (more precisely, is contained in the monad of ).

A space is compact if its hyperreal extension (constructed, for example, by the ultrapower construction) has the property that every point of is infinitely close to some point of . For example, an open real interval is not compact because its hyperreal extension contains infinitesimals, which are infinitely close to 0, which is not a point of .



Since a continuous image of a compact space is compact, the extreme value theorem holds for such spaces: a continuous real-valued function on a nonempty compact space is bounded above and attains its supremum. 
(Slightly more generally, this is true for an upper semicontinuous function.) As a sort of converse to the above statements, the pre-image of a compact space under a proper map is compact.

Every topological space is an open dense subspace of a compact space having at most one point more than , by the Alexandroff one-point compactification. 
By the same construction, every locally compact Hausdorff space is an open dense subspace of a compact Hausdorff space having at most one point more than .

A nonempty compact subset of the real numbers has a greatest element and a least element.

Let be a simply ordered set endowed with the order topology. 
Then is compact if and only if is a complete lattice (i.e. all subsets have suprema and infima).




Clodius

Clodius is an alternate form of the Roman "nomen" Claudius, a patrician "gens" that was traditionally regarded as Sabine in origin. The alternation of "o" and "au" is characteristic of the Sabine dialect. The feminine form is Clodia.

During the Late Republic, the spelling "Clodius" is most prominently associated with Publius Clodius Pulcher, a popularis politician who gave up his patrician status through an order in order to qualify for the office of tribune of the "plebs". Clodius positioned himself as a champion of the urban "plebs", supporting free grain for the poor and the right of association in guilds ("collegia"); because of this individual's ideology, "Clodius" has often been taken as a more "plebeian" spelling and a gesture of political solidarity. Clodius's two elder brothers, the Appius Claudius Pulcher who was consul in 54 BC and the C. Claudius Pulcher who was praetor in 56 BC, conducted more conventional political careers and are referred to in contemporary sources with the traditional spelling.

The view that "Clodius" represents a plebeian or politicized form has been questioned by Clodius's chief modern-era biographer. In "The Patrician Tribune", W. Jeffrey Tatum points out that the spelling is also associated with Clodius's sisters and that "the political explanation … is almost certainly wrong." A plebeian branch of the "gens", the Claudii Marcelli, retained the supposedly patrician spelling, while there is some inscriptional evidence that the "-o-" form may also have been used on occasion by close male relatives of the "patrician tribune" Clodius. Tatum argues that the use of "-o-" by the "chic" Clodia was a fashionable affectation, and that Clodius, whose perhaps inordinately loving relationship with his sister was the subject of much gossip and insinuation, was imitating his stylish sibling. The linguistic variation of "o" for "au" was characteristic of the Umbrian language, of which Sabine was a branch. Forms using "o" were considered archaic or rustic in the 50s BC, and the use of "Clodius" would have been either a whimsical gesture of pastoral fantasy, or a trendy assertion of antiquarian authenticity.

In addition to Clodius, Clodii from the Republican era include:


Women of the Claudii Marcelli branch were often called "Clodia" in the late Republic.

People using the name "Clodius" during the period of the Roman Empire include:

The Clodii Celsini continued to practice the traditional religions of antiquity in the face of Christian hegemony through at least the 4th century, when Clodius Celsinus Adelphius (see below) converted. Members of this branch include:




Cicero

Marcus Tullius Cicero ( ; ; 3 January 106 BC – 7 December 43 BC) was a Roman statesman, lawyer, scholar, philosopher, writer and Academic skeptic, who tried to uphold optimate principles during the political crises that led to the establishment of the Roman Empire. His extensive writings include treatises on rhetoric, philosophy and politics. He is considered one of Rome's greatest orators and prose stylists and the innovator of what became known as "Ciceronian rhetoric". Cicero was educated in Rome and in Greece. He came from a wealthy municipal family of the Roman equestrian order, and served as consul in 63 BC.

His influence on the Latin language was immense. He wrote more than three-quarters of extant Latin literature that is known to have existed in his lifetime, and it has been said that subsequent prose was either a reaction against or a return to his style, not only in Latin but in European languages up to the 19th century. Cicero introduced into Latin the arguments of the chief schools of Hellenistic philosophy and created a large amount of Latin philosophical vocabulary via lexical innovation (e.g. neologisms such as , "generator", , "infinitio", , ), almost 150 of which had been introduced from the translation of Greek philosophical terms, demonstrating himself as both an adept scholar of philosophy as well as a skilled translator.

Though he was an accomplished orator and successful lawyer, Cicero believed his political career was his most important achievement. It was during his consulship that the Catiline conspiracy attempted to overthrow the government through an attack on the city by outside forces, and Cicero suppressed the revolt by summarily and controversially executing five conspirators without trial, with the support of the Senate. During the chaotic middle period of the first century BC, marked by civil wars and the dictatorship of Julius Caesar, Cicero championed a return to the traditional republican government. Following Caesar's death, Cicero became an enemy of Mark Antony in the ensuing power struggle, attacking him in a series of speeches. He was proscribed as an enemy of the state by the Second Triumvirate and consequently executed by soldiers operating on their behalf in 43 BC, having been intercepted during an attempted flight from the Italian peninsula. His severed hands and head were then, as a final revenge of Mark Antony, displayed on the Rostra.

Petrarch's rediscovery of Cicero's letters is often credited for initiating the 14th-century Renaissance in public affairs, humanism, and classical Roman culture. According to Polish historian Tadeusz Zieliński, "the Renaissance was above all things a revival of Cicero, and only after him and through him of the rest of Classical antiquity." The peak of Cicero's authority and prestige came during the 18th-century Enlightenment, and his impact on leading Enlightenment thinkers and political theorists such as John Locke, David Hume, Montesquieu, and Edmund Burke was substantial. His works rank among the most influential in global culture, and today still constitute one of the most important bodies of primary material for the writing and revision of Roman history, especially the last days of the Roman Republic.

Marcus Tullius Cicero was born on 3 January 106 BC in Arpinum, a hill town southeast of Rome. He belonged to the "tribus" Cornelia. His father was a well-to-do member of the equestrian order and possessed good connections in Rome. However, being a semi-invalid, he could not enter public life and studied extensively to compensate. Although little is known about Cicero's mother, Helvia, it was common for the wives of important Roman citizens to be responsible for the management of the household. Cicero's brother Quintus wrote in a letter that she was a thrifty housewife.

Cicero's cognomen, a hereditary nickname, comes from the Latin for chickpea, . Plutarch explains that the name was originally given to one of Cicero's ancestors who had a cleft in the tip of his nose resembling a chickpea. Romans often chose down-to-earth personal surnames. The famous family names of Fabius, Lentulus, and Piso come from the Latin names of beans, lentils, and peas, respectively. Plutarch writes that Cicero was urged to change this deprecatory name when he entered politics, but refused, saying that he would make "Cicero" more glorious than "Scaurus" ("Swollen-ankled") and "Catulus" ("Puppy").

At the age of 15, in 90 BC, Cicero started serving under Pompey Strabo and later Sulla in the Social war between Rome and its Italian allies. When in Rome during the turbulent plebeian tribunate of Publius Sulpicius Rufus in 88 BC which saw a short bout of fighting between the Sulpicius and Sulla, who had been elected consul for that year, Cicero found himself greatly impressed by Sulpicius' oratory even if he disagreed with his politics. He continued his studies at Rome, writing a pamphlet titled "On Invention" relating to rhetorical argumentation and studying philosophy with Greek academics who had fled the ongoing First Mithridatic War.

During this period in Roman history, "cultured" meant being able to speak both Latin and Greek. Cicero was therefore educated in the teachings of the ancient Greek philosophers, poets and historians; as he obtained much of his understanding of the theory and practice of rhetoric from the Greek poet Archias. Cicero used his knowledge of Greek to translate many of the theoretical concepts of Greek philosophy into Latin, thus translating Greek philosophical works for a larger audience. It was precisely his broad education that tied him to the traditional Roman elite.

Cicero's interest in philosophy figured heavily in his later career and led to him providing a comprehensive account of Greek philosophy for a Roman audience, including creating a philosophical vocabulary in Latin. In 87 BC, Philo of Larissa, the head of the Platonic Academy that had been founded by Plato in Athens about 300 years earlier, arrived in Rome. Cicero, "inspired by an extraordinary zeal for philosophy", sat enthusiastically at his feet and absorbed Carneades' Academic Skeptic philosophy.

Cicero said of Plato's Dialogues, that if Zeus were to speak, he would use their language. He would, in due course, honor them with his own convivial dialogues.

According to Plutarch, Cicero was an extremely talented student, whose learning attracted attention from all over Rome, affording him the opportunity to study Roman law under Quintus Mucius Scaevola. Cicero's fellow students were Gaius Marius Minor, Servius Sulpicius Rufus (who became a famous lawyer, one of the few whom Cicero considered superior to himself in legal matters), and Titus Pomponius. The latter two became Cicero's friends for life, and Pomponius (who later received the nickname "Atticus", and whose sister married Cicero's brother) would become, in Cicero's own words, "as a second brother", with both maintaining a lifelong correspondence.

In 79 BC, Cicero left for Greece, Asia Minor and Rhodes. This was perhaps to avoid the potential wrath of Sulla, as Plutarch claims, though Cicero himself says it was to hone his skills and improve his physical fitness. In Athens he studied philosophy with Antiochus of Ascalon, the 'Old Academic' and initiator of Middle Platonism. In Asia Minor, he met the leading orators of the region and continued to study with them. Cicero then journeyed to Rhodes to meet his former teacher, Apollonius Molon, who had taught him in Rome. Molon helped Cicero hone the excesses in his style, as well as train his body and lungs for the demands of public speaking. Charting a middle path between the competing Attic and Asiatic styles, Cicero would ultimately become considered second only to Demosthenes among history's orators.

While Cicero had feared that the law courts would be closed forever, they were reopened in the aftermath of Sulla's civil war and the purging of Sulla's political opponents in the proscriptions. Many of the orators which Cicero admired in his youth were now dead from age or political violence. His first major appearance in the courts was in 81 BC at the age of 26 when he delivered, "Pro Quinctio", a speech defending certain commercial transactions which Cicero had recorded and disseminated.

His more famous speech defending Sextus Roscius of Ameria – – on charges of parricide in 80 BC was his first appearance in criminal court. In this high-profile case, Cicero accused a freedman of the dictator Sulla, Chrysogonus, of fabricating Roscius' father's proscription to obtain Roscius' family's property. Successful in his defence, Cicero tactfully avoided incriminating Sulla of any wrongdoing and developed a positive oratorical reputation for himself.

While Plutarch claims that Cicero left Rome shortly thereafter out of fear of Sulla's response, "most scholarly now dismiss this suggestion" because Cicero left Rome after Sulla resigned his dictatorship. Cicero, for his part, later claimed that he left Rome, headed for Asia, to develop his physique and develop his oratory. After marrying his wife, Terentia, in 80 BC, he eventually left for Asia Minor with his brother Quintus, his friend Titus Atticus, and others on a long trip spanning most of 79 through 77 BC. Returning to Rome in 77 BC, Cicero again busied himself with legal defence.

In 76 BC, at the quaestorian elections, Cicero was elected at the minimum age required – 30 years – in the first returns from the "comitia tributa", to the post of quaestor. Ex officio, he also became a member of the Senate. In the quaestorian lot, he was assigned to Sicily for 75 BC. The post, which was largely one related to financial administration in support of the state or provincial governors, proved for Cicero an important place where he could gain clients in the provinces. His time in Sicily saw him balance his duties – largely in terms of sending more grain back to Rome – with his support for the provincials, Roman businessmen in the area, and local potentates. Adeptly balancing those responsibilities, he won their gratitude. He was also appreciated by local Syracusans for the rediscovery of the lost tomb of Archimedes, which he personally financed.

Promising to lend the Sicilians his oratorical voice, he was called on a few years after his quaestorship to prosecute the Roman province's governor Gaius Verres, for abuse of power and corruption. In 70 BC, at the age of 36, Cicero launched his first high-profile prosecution against Verres, an emblem of the corrupt Sullan supporters who had risen in the chaos of the civil war. 

The prosecution of Gaius Verres was a great forensic success for Cicero. While Verres hired the prominent lawyer, Quintus Hortensius, after a lengthy period in Sicily collecting testimonials and evidence and persuading witnesses to come forward, Cicero returned to Rome and won the case in a series of dramatic court battles. His unique style of oratory set him apart from the flamboyant Hortensius. On the conclusion of this case, Cicero came to be considered the greatest orator in Rome. The view that Cicero may have taken the case for reasons of his own is viable. Hortensius was, at this point, known as the best lawyer in Rome; to beat him would guarantee much success and the prestige that Cicero needed to start his career. Cicero's oratorical ability is shown in his character assassination of Verres and various other techniques of persuasion used on the jury. One such example is found in the speech "In Verrem", where he states "with you on this bench, gentlemen, with Marcus Acilius Glabrio as your president, I do not understand what Verres can hope to achieve". Oratory was considered a great art in ancient Rome and an important tool for disseminating knowledge and promoting oneself in elections, in part because there were no regular newspapers or mass media. Cicero was neither a patrician nor a plebeian noble; his rise to political office despite his relatively humble origins has traditionally been attributed to his brilliance as an orator.

Cicero grew up in a time of civil unrest and war. Sulla's victory in the first of a series of civil wars led to a new constitutional framework that undermined (liberty), the fundamental value of the Roman Republic. Nonetheless, Sulla's reforms strengthened the position of the equestrian class, contributing to that class's growing political power. Cicero was both an Italian and a , but more importantly he was a Roman constitutionalist. His social class and loyalty to the Republic ensured that he would "command the support and confidence of the people as well as the Italian middle classes". The optimates faction never truly accepted Cicero, and this undermined his efforts to reform the Republic while preserving the constitution. Nevertheless, he successfully ascended the cursus honorum, holding each magistracy at or near the youngest possible age: quaestor in 75 BC (age 30), aedile in 69 BC (age 36), and praetor in 66 BC (age 39), when he served as president of the "Reclamation" (or extortion) Court. He was then elected consul at age 42.

Cicero, seizing the opportunity offered by optimate fear of reform, was elected consul for the year 63 BC; he was elected with the support of every unit of the centuriate assembly, rival members of the post-Sullan establishment, and the leaders of municipalities throughout post-Social War Italy. His co-consul for the year, Gaius Antonius Hybrida, played a minor role.

He began his consular year by opposing a land bill proposed by a plebeian tribune which would have appointed commissioners with semi-permanent authority over land reform. Cicero was also active in the courts, defending Gaius Rabirius from accusations of participating in the unlawful killing of plebeian tribune Lucius Appuleius Saturninus in 100 BC. The prosecution occurred before the and threatened to reopen conflict between the Marian and Sullan factions at Rome. Cicero defended the use of force as being authorised by a , which would prove similar to his own use of force under such conditions.

Most famouslyin part because of his own publicityhe thwarted a conspiracy led by Lucius Sergius Catilina to overthrow the Roman Republic with the help of foreign armed forces. Cicero procured a "senatus consultum ultimum" (a recommendation from the senate attempting to legitimise the use of force) and drove Catiline from the city with four vehement speeches (the Catilinarian orations), which remain outstanding examples of his rhetorical style. The Orations listed Catiline and his followers' debaucheries, and denounced Catiline's senatorial sympathizers as roguish and dissolute debtors clinging to Catiline as a final and desperate hope. Cicero demanded that Catiline and his followers leave the city. At the conclusion of Cicero's first speech (which was made in the Temple of Jupiter Stator), Catiline hurriedly left the Senate. In his following speeches, Cicero did not directly address Catiline. He delivered the second and third orations before the people, and the last one again before the Senate. By these speeches, Cicero wanted to prepare the Senate for the worst possible case; he also delivered more evidence, against Catiline.

Catiline fled and left behind his followers to start the revolution from within while he himself assaulted the city with an army of "moral and financial bankrupts, or of honest fanatics and adventurers". It is alleged that Catiline had attempted to involve the Allobroges, a tribe of Transalpine Gaul, in their plot, but Cicero, working with the Gauls, was able to seize letters that incriminated the five conspirators and forced them to confess in front of the Senate. The senate then deliberated upon the conspirators' punishment. As it was the dominant advisory body to the various legislative assemblies rather than a judicial body, there were limits to its power; however, martial law was in effect, and it was feared that simple house arrest or exile – the standard options – would not remove the threat to the state. At first Decimus Junius Silanus spoke for the "extreme penalty"; but during the debate many were swayed by Julius Caesar, who decried the precedent it would set and argued in favor of life imprisonment in various Italian towns. Cato the Younger then rose in defense of the death penalty and the Senate finally agreed on the matter, and came down in support of the death penalty. Cicero had the conspirators taken to the Tullianum, the notorious Roman prison, where they were strangled. Cicero himself accompanied the former consul Publius Cornelius Lentulus Sura, one of the conspirators, to the Tullianum.

Cicero received the honorific ""pater patriae"" for his efforts to suppress the conspiracy, but lived thereafter in fear of trial or exile for having put Roman citizens to death without trial. While the "senatus consultum ultimum" gave some legitimacy to the use of force against the conspirators, Cicero also argued that Catiline's conspiracy, by virtue of its treason, made the conspirators enemies of the state and forfeited the protections intrinsically possessed by Roman citizens. The consuls moved decisively. Antonius Hybrida was dispatched to defeat Catiline in battle that year, preventing Crassus or Pompey from exploiting the situation for their own political aims.

After the suppression of the conspiracy, Cicero was proud of his accomplishment. Some of his political enemies argued that though the act gained Cicero popularity, he exaggerated the extent of his success. He overestimated his popularity again several years later after being exiled from Italy and then allowed back from exile. At this time, he claimed that the republic would be restored along with him.

Shortly after completing his consulship, in late 62 BC, Cicero arranged the purchase of a large townhouse on the Palatine Hill previously owned by Rome's richest citizen, Marcus Licinius Crassus. To finance the purchase, Cicero borrowed some two million sesterces from Publius Cornelius Sulla, whom he had previously defended from court. Cicero boasted his house was ""in conspectu prope totius urbis"" ("in sight of nearly the whole city"), only a short walk from the Roman Forum.

In 60 BC, Julius Caesar invited Cicero to be the fourth member of his existing partnership with Pompey and Marcus Licinius Crassus, an assembly that would eventually be called the First Triumvirate. Cicero refused the invitation because he suspected it would undermine the Republic, and was strongly opposed to anything unconsitutional that limited the powers of the consuls, and replaced them with non-elected officials.

During Caesar's consulship of 59 BC, the triumvirate had achieved many of their goals of land reform, publicani debt forgiveness, ratification of Pompeian conquests, etc. With Caesar leaving for his provinces, they wished to maintain their hold on politics. They engineered the adoption of patrician Publius Clodius Pulcher into a plebeian family and had him elected as one of the ten tribunes of the plebs for 58 BC. Clodius used the triumvirate's backing to push through legislation that benefited them. He introduced several laws (the "leges Clodiae") that made him popular with the people, strengthening his power base, then he turned on Cicero. Clodius passed a law which made it illegal to offer "fire and water" (i.e shelter or food) to anyone who executed a Roman citizen without a trial. 
Cicero, having executed members of the Catiline conspiracy four years previously without formal trial, was clearly the intended target. Furthermore, many believed that Clodius acted in concert with the triumvirate who feared that Cicero would seek to abolish many of Caesar's accomplishments while consul the year before. Cicero argued that the "senatus consultum ultimum" indemnified him from punishment, and he attempted to gain the support of the senators and consuls, especially of Pompey.

Cicero grew out his hair, dressed in mourning and toured the streets. Clodius' gangs dogged him, hurling abuse, stones and even excrement. Hortensius, trying to rally to his old rival's support, was almost lynched. The Senate and the consuls were cowed. Caesar, who was still encamped near Rome, was apologetic but said he could do nothing when Cicero brought himself to grovel in the proconsul's tent. Everyone seemed to have abandoned Cicero.

After Clodius passed a law to deny to Cicero fire and water (i.e. shelter) within four hundred miles of Rome, Cicero went into exile. He arrived at Thessalonica, on 23 May 58 BC. In his absence, Clodius, who lived next door to Cicero on the Palatine, arranged for Cicero's house to be confiscated by the state, and was even able to purchase a part of the property in order to extend his own house. After demolishing Cicero's house, Clodius had the land consecrated and symbolically erected a temple of Liberty ("aedes Libertatis") on the vacant land.

Cicero's exile caused him to fall into depression. He wrote to Atticus: "Your pleas have prevented me from committing suicide. But what is there to live for? Don't blame me for complaining. My afflictions surpass any you ever heard of earlier". After the intervention of recently elected tribune Titus Annius Milo, acting on the behalf of Pompey who wanted Cicero as a client, the Senate voted in favor of recalling Cicero from exile. Clodius cast the single vote against the decree. Cicero returned to Italy on 5 August 57 BC, landing at Brundisium. He was greeted by a cheering crowd, and, to his delight, his beloved daughter Tullia. In his "Oratio De Domo Sua Ad Pontifices", Cicero convinced the College of Pontiffs 
to rule that the consecration of his land was invalid, thereby allowing him to regain his property and rebuild his house on the Palatine.

Cicero tried to re-enter politics as an independent operator, but his attempts to attack portions of Caesar's legislation were unsuccessful and encouraged Caesar to re-solidify his political alliance with Pompey and Crassus. The conference at Luca in 56 BC left the three-man alliance in domination of the republic's politics; this forced Cicero to recant and support the triumvirate out of fear from being entirely excluded from public life. After the conference Cicero lavishly praised Caesar's achievements, got the Senate to vote a thanksgiving for Caesar's victories and grant money to pay his troops. He also delivered a speech 'On the consular provinces' () which checked an attempt by Caesar's enemies to strip him of his provinces in Gaul. After this, a cowed Cicero concentrated on his literary works. It is uncertain whether he was directly involved in politics for the following few years.

In 51 BC he reluctantly accepted a promagistracy (as proconsul) in Cilicia for the year; there were few other former consuls eligible as a result of a legislative requirement enacted by Pompey in 52 BC specifying an interval of five years between a consulship or praetorship and a provincial command. He served as proconsul of Cilicia from May 51 BC, arriving in the provinces three months later around August. 

In 53 BC Marcus Licinius Crassus had been defeated by the Parthians at the Battle of Carrhae. This opened the Roman East for a Parthian invasion, causing unrest in Syria and Cilicia. Cicero restored calm by his mild system of government. He discovered that a great amount of public property had been embezzled by corrupt previous governors and members of their staff, and did his utmost to restore it. Thus he greatly improved the condition of the cities. He retained the civil rights of, and exempted from penalties, the men who gave the property back. Besides this, he was extremely frugal in his outlays for staff and private expenses during his governorship, and this made him highly popular among the natives.

Besides his activity in ameliorating the hard pecuniary situation of the province, Cicero was also creditably active in the military sphere. Early in his governorship he received information that prince Pacorus, son of Orodes II the king of the Parthians, had crossed the Euphrates, and was ravaging the Syrian countryside and had even besieged Cassius (the interim Roman commander in Syria) in Antioch. Cicero eventually marched with two understrength legions and a large contingent of auxiliary cavalry to Cassius's relief. Pacorus and his army had already given up on besieging Antioch and were heading south through Syria, ravaging the countryside again. Cassius and his legions followed them, harrying them wherever they went, eventually ambushing and defeating them near Antigonea.

Another large troop of Parthian horsemen was defeated by Cicero's cavalry who happened to run into them while scouting ahead of the main army. Cicero next defeated some robbers who were based on Mount Amanus and was hailed as imperator by his troops. Afterwards he led his army against the independent Cilician mountain tribes, besieging their fortress of Pindenissum. It took him 47 days to reduce the place, which fell in December. On 30 July 50 BC Cicero left the province to his brother Quintus, who had accompanied him on his governorship as his legate. On his way back to Rome he stopped in Rhodes and then went to Athens, where he caught up with his old friend Titus Pomponius Atticus and met men of great learning.

Cicero arrived in Rome on 4 January 49 BC. He stayed outside the pomerium, to retain his promagisterial powers: either in expectation of a triumph or to retain his independent command authority in the coming civil war. The struggle between Pompey and Julius Caesar grew more intense in 50 BC. Cicero favored Pompey, seeing him as a defender of the senate and Republican tradition, but at that time avoided openly alienating Caesar. When Caesar invaded Italy in 49 BC, Cicero fled Rome. Caesar, seeking an endorsement by a senior senator, courted Cicero's favor, but even so Cicero slipped out of Italy and traveled to Dyrrhachium where Pompey's staff was situated. Cicero traveled with the Pompeian forces to Pharsalus in Macedonia in 48 BC, though he was quickly losing faith in the competence and righteousness of the Pompeian side. Eventually, he provoked the hostility of his fellow senator Cato, who told him that he would have been of more use to the cause of the "optimates" if he had stayed in Rome. After Caesar's victory at the Battle of Pharsalus on 9 August, Cicero refused to take command of the Pompeian forces and continue the war. He returned to Rome, still as a promagistrate with his lictors, in 47 BC, and dismissed them upon his crossing the pomerium and renouncing his command. 

In a letter to Varro on , Cicero outlined his strategy under Caesar's dictatorship. Cicero, however, was taken by surprise when the "Liberatores" assassinated Caesar on the ides of March, 44 BC. Cicero was not included in the conspiracy, even though the conspirators were sure of his sympathy. Marcus Junius Brutus called out Cicero's name, asking him to restore the republic when he lifted his bloodstained dagger after the assassination. A letter Cicero wrote in February 43 BC to Trebonius, one of the conspirators, began, "How I could wish that you had invited me to that most glorious banquet on the Ides of March!" Cicero became a popular leader during the period of instability following the assassination. He had no respect for Mark Antony, who was scheming to take revenge upon Caesar's murderers. In exchange for amnesty for the assassins, he arranged for the Senate to agree not to declare Caesar to have been a tyrant, which allowed the Caesarians to have lawful support and kept Caesar's reforms and policies intact.

In April 43 BC, "diehard republicans" may have revived the ancient position of "princeps senatus" (leader of the senate) for Cicero. This position had been very prestigious until the constitutional reforms of Sulla in 82–80 BC, which removed most of its importance.

On the other side, Antony was consul and leader of the Caesarian faction, and unofficial executor of Caesar's public will. Relations between the two were never friendly and worsened after Cicero claimed that Antony was taking liberties in interpreting Caesar's wishes and intentions. Octavian was Caesar's adopted son and heir. After he returned to Italy, Cicero began to play him against Antony. He praised Octavian, declaring he would not make the same mistakes as his father. He attacked Antony in a series of speeches he called the "Philippics", named after Demosthenes's denunciations of Philip II of Macedon. At the time, Cicero's popularity as a public figure was unrivalled.

Cicero supported Decimus Junius Brutus Albinus as governor of Cisalpine Gaul ("Gallia Cisalpina") and urged the Senate to name Antony an enemy of the state. The speech of Lucius Piso, Caesar's father-in-law, delayed proceedings against Antony. Antony was later declared an enemy of the state when he refused to lift the siege of Mutina, which was in the hands of Decimus Brutus. Cicero's plan to drive out Antony failed. Antony and Octavian reconciled and allied with Lepidus to form the Second Triumvirate after the successive battles of Forum Gallorum and Mutina. The alliance came into official existence with the "lex Titia", passed on 27 November 43 BC, which gave each triumvir a consular "imperium" for five years. The Triumvirate immediately began a proscription of their enemies, modeled after that of Sulla in 82 BC. Cicero and all of his contacts and supporters were numbered among the enemies of the state, even though Octavian argued for two days against Cicero being added to the list.

Cicero was one of the most viciously and doggedly hunted among the proscribed. He was viewed with sympathy by a large segment of the public and many people refused to report that they had seen him. He was caught on 7 December 43 BC leaving his villa in Formiae in a litter heading to the seaside, where he hoped to embark on a ship destined for Macedonia. When his killers – Herennius (a Centurion) and Popilius (a Tribune) – arrived, Cicero's own slaves said they had not seen him, but he was given away by Philologus, a freedman of his brother Quintus Cicero.

As reported by Seneca the Elder, according to the historian Aufidius Bassus, Cicero's last words are said to have been:

He bowed to his captors, leaning his head out of the litter in a gladiatorial gesture to ease the task. By baring his neck and throat to the soldiers, he was indicating that he would not resist. According to Plutarch, Herennius first slew him, then cut off his head. On Antony's instructions his hands, which had penned the Philippics against Antony, were cut off as well; these were nailed along with his head on the Rostra in the Forum Romanum according to the tradition of Marius and Sulla, both of whom had displayed the heads of their enemies in the Forum. Cicero was the only victim of the proscriptions who was displayed in that manner. According to Cassius Dio, in a story often mistakenly attributed to Plutarch, Antony's wife Fulvia took Cicero's head, pulled out his tongue, and jabbed it repeatedly with her hairpin in final revenge against Cicero's power of speech.

Cicero's son, Marcus Tullius Cicero Minor, during his year as a consul in 30 BC, avenged his father's death, to a certain extent, when he announced to the Senate Mark Antony's naval defeat at Actium in 31 BC by Octavian.

Octavian is reported to have praised Cicero as a patriot and a scholar of meaning in later times, within the circle of his family. However, it was Octavian's acquiescence that had allowed Cicero to be killed, as Cicero was condemned by the new triumvirate.

Cicero's career as a statesman was marked by inconsistencies and a tendency to shift his position in response to changes in the political climate. His indecision may be attributed to his sensitive and impressionable personality; he was prone to overreaction in the face of political and private change.

"Would that he had been able to endure prosperity with greater self-control, and adversity with more fortitude!" wrote C. Asinius Pollio, a contemporary Roman statesman and historian.

Cicero married Terentia probably at the age of 27, in 79 BC. According to the upper-class mores of the day it was a marriage of convenience but lasted harmoniously for nearly 30 years. Terentia's family was wealthy, probably the plebeian noble house of Terenti Varrones, thus meeting the needs of Cicero's political ambitions in both economic and social terms. She had a half-sister named Fabia, who as a child had become a Vestal Virgin, a great honour. Terentia was a strong-willed woman and (citing Plutarch) "took more interest in her husband's political career than she allowed him to take in household affairs".

In the 50s BC, Cicero's letters to Terentia became shorter and colder. He complained to his friends that Terentia had betrayed him but did not specify in which sense. Perhaps the marriage could not outlast the strain of the political upheaval in Rome, Cicero's involvement in it, and various other disputes between the two. The divorce appears to have taken place in 51 BC or shortly before. In 46 or 45 BC, Cicero married a young girl, Publilia, who had been his ward. It is thought that Cicero needed her money, particularly after having to repay the dowry of Terentia, who came from a wealthy family. 

Although his marriage to Terentia was one of convenience, it is commonly known that Cicero held great love for his daughter Tullia. When she suddenly became ill in February 45 BC and died after having seemingly recovered from giving birth to a son in January, Cicero was stunned. "I have lost the one thing that bound me to life," he wrote to Atticus. Atticus told him to come for a visit during the first weeks of his bereavement, so that he could comfort him when his pain was at its greatest. In Atticus's large library, Cicero read everything that the Greek philosophers had written about overcoming grief, "but my sorrow defeats all consolation." Caesar and Brutus, as well as Servius Sulpicius Rufus, sent him letters of condolence.

Cicero hoped that his son Marcus would become a philosopher like him, but Marcus himself wished for a military career. He joined the army of Pompey in 49 BC, and after Pompey's defeat at Pharsalus 48 BC, he was pardoned by Caesar. Cicero sent him to Athens to study as a disciple of the peripatetic philosopher Kratippos in 48 BC, but he used this absence from "his father's vigilant eye" to "eat, drink, and be merry." After Cicero's death, he joined the army of the "Liberatores" but was later pardoned by Augustus. Augustus's bad conscience for not having objected to Cicero's being put on the proscription list during the Second Triumvirate led him to aid considerably Marcus Minor's career. He became an augur and was nominated consul in 30 BC together with Augustus. As such, he was responsible for revoking the honors of Mark Antony, who was responsible for the proscription and could in this way take revenge. Later he was appointed proconsul of Syria and the province of Asia.

Cicero has been traditionally considered the master of Latin prose, with Quintilian declaring that Cicero was "not the name of a man, but of eloquence itself." The English words "Ciceronian" (meaning "eloquent") and "cicerone" (meaning "local guide") derive from his name. He is credited with transforming Latin from a modest utilitarian language into a versatile literary medium capable of expressing abstract and complicated thoughts with clarity. Julius Caesar praised Cicero's achievement by saying "it is more important to have greatly extended the frontiers of the Roman spirit than the frontiers of the Roman empire". According to John William Mackail, "Cicero's unique and imperishable glory is that he created the language of the civilized world, and used that language to create a style which nineteen centuries have not replaced, and in some respects have hardly altered."

Cicero was also an energetic writer with an interest in a wide variety of subjects, in keeping with the Hellenistic philosophical and rhetorical traditions in which he was trained. The quality and ready accessibility of Ciceronian texts favored very wide distribution and inclusion in teaching curricula, as suggested by a graffito at Pompeii, admonishing: "You will like Cicero, or you will be whipped".

Cicero was greatly admired by influential Church Fathers such as Augustine of Hippo, who credited Cicero's lost "Hortensius" for his eventual conversion to Christianity, and St. Jerome, who had a feverish vision in which he was accused of being "follower of Cicero and not of Christ" before the judgment seat.

This influence further increased after the Early Middle Ages in Europe, where more of his writings survived than any other Latin author. Medieval philosophers were influenced by Cicero's writings on natural law and innate rights.

Petrarch's rediscovery of Cicero's letters provided the impetus for searches for ancient Greek and Latin writings scattered throughout European monasteries, and the subsequent rediscovery of classical antiquity led to the Renaissance. Subsequently, Cicero became synonymous with classical Latin to such an extent that a number of humanist scholars began to assert that no Latin word or phrase should be used unless it appeared in Cicero's works, a stance criticised by Erasmus.

His voluminous correspondence, much of it addressed to his friend Atticus, has been especially influential, introducing the art of refined letter writing to European culture. Cornelius Nepos, the first century BC biographer of Atticus, remarked that Cicero's letters contained such a wealth of detail "concerning the inclinations of leading men, the faults of the generals, and the revolutions in the government" that their reader had little need for a history of the period.

Among Cicero's admirers were Desiderius Erasmus, Martin Luther, and John Locke. Following the invention of Johannes Gutenberg's printing press, "De Officiis" was the second book printed in Europe, after the Gutenberg Bible. Scholars note Cicero's influence on the rebirth of religious toleration in the 17th century.

Cicero was especially popular with the Philosophes of the 18th century, including Edward Gibbon, Diderot, David Hume, Montesquieu, and Voltaire. Gibbon wrote of his first experience reading the author's collective works thus: "I tasted the beauty of the language; I breathed the spirit of freedom; and I imbibed from his precepts and examples the public and private sense of a man...after finishing the great author, a library of eloquence and reason, I formed a more extensive plan of reviewing the Latin classics..."

Voltaire called Cicero "the greatest as well as the most elegant of Roman philosophers" and even staged a play based on Cicero's role in the Catilinarian conspiracy, called "Rome Sauvée, ou Catilina", to "make young people who go to the theatre acquainted with Cicero." Voltaire was spurred to pen the drama as a rebuff to his rival Claude Prosper Jolyot de Crébillon's own play "Catilina", which had portrayed Cicero as a coward and villain who hypocritically married his own daughter to Catiline.

Montesquieu produced his "Discourse on Cicero" in 1717, in which he heaped praise on the author because he rescued "philosophy from the hands of scholars, and freed it from the confusion of a foreign language". Montesquieu went on to declare that Cicero was "of all the ancients, the one who had the most personal merit, and whom I would prefer to resemble."

Internationally, Cicero the republican inspired the Founding Fathers of the United States and the revolutionaries of the French Revolution. John Adams said, "As all the ages of the world have not produced a greater statesman and philosopher united than Cicero, his authority should have great weight." Thomas Jefferson names Cicero as one of a handful of major figures who contributed to a tradition "of public right" that informed his draft of the Declaration of Independence and shaped American understandings of "the common sense" basis for the right of revolution. Camille Desmoulins said of the French republicans in 1789 that they were "mostly young people who, nourished by the reading of Cicero at school, had become passionate enthusiasts for liberty".

Jim Powell starts his book on the history of liberty with the sentence: "Marcus Tullius Cicero expressed principles that became the bedrock of liberty in the modern world."

Likewise, no other ancient personality has inspired as much venomous dislike as Cicero, especially in more modern times. His commitment to the values of the Republic accommodated a hatred of the poor and persistent opposition to the advocates and mechanisms of popular representation. Friedrich Engels referred to him as "the most contemptible scoundrel in history" for upholding republican "democracy" while at the same time denouncing land and class reforms. Cicero has faced criticism for exaggerating the democratic qualities of republican Rome, and for defending the Roman oligarchy against the popular reforms of Caesar. Michael Parenti admits Cicero's abilities as an orator, but finds him a vain, pompous and hypocritical personality who, when it suited him, could show public support for popular causes that he privately despised. Parenti presents Cicero's prosecution of the Catiline conspiracy as legally flawed at least, and possibly unlawful.

Cicero also had an influence on modern astronomy. Nicolaus Copernicus, searching for ancient views on earth motion, said that he "first ... found in Cicero that Hicetas supposed the earth to move."

Notably, "Cicero" was the name attributed to size 12 font in typesetting table drawers. For ease of reference, type sizes 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, and 20 were all given different names.

Cicero was declared a righteous pagan by the Early Church, and therefore many of his works were deemed worthy of preservation. Subsequent Roman and medieval Christian writers quoted liberally from his works "De re publica" ("On the Commonwealth") and "De Legibus" ("On the Laws"), and much of his work has been recreated from these surviving fragments. Cicero also articulated an early, abstract conceptualization of rights, based on ancient law and custom. Of Cicero's books, six on rhetoric have survived, as well as parts of seven on philosophy. Of his speeches, 88 were recorded, but only 52 survive.

Cicero's great repute in Italy has led to numerous ruins being identified as having belonged to him, though none have been substantiated with absolute certainty. In Formia, two Roman-era ruins are popularly believed to be Cicero's mausoleum, the "Tomba di Cicerone", and the villa where he was assassinated in 43 BC. The latter building is centered around a central hall with Doric columns and a coffered vault, with a separate nymphaeum, on five acres of land near Formia. A modern villa was built on the site after the Rubino family purchased the land from Ferdinand II of the Two Sicilies in 1868. Cicero's supposed tomb is a 24-meter (79 feet) tall tower on an "opus quadratum" base on the ancient Via Appia outside of Formia. Some suggest that it is not in fact Cicero's tomb, but a monument built on the spot where Cicero was intercepted and assassinated while trying to reach the sea.

In Pompeii, a large villa excavated in the mid 18th century just outside the Herculaneum Gate was widely believed to have been Cicero's, who was known to have owned a holiday villa in Pompeii he called his "Pompeianum". The villa was stripped of its fine frescoes and mosaics and then re-buried after 1763 – it has yet to be re-excavated. However, contemporaneous descriptions of the building from the excavators combined with Cicero's own references to his "Pompeianum" differ, making it unlikely that it is Cicero's villa.

In Rome, the location of Cicero's house has been roughly identified from excavations of the Republican-era stratum on the northwestern slope of the Palatine Hill. Cicero's "domus" has long been known to have stood in the area, according to his own descriptions and those of later authors, but there is some debate about whether it stood near the base of the hill, very close to the Roman Forum, or nearer to the summit. During his life the area was the most desirable in Rome, densely occupied with Patrician houses including the "Domus Publica" of Julius Caesar and the home of Cicero's mortal enemy Clodius.

In Dante's 1320 poem the "Divine Comedy", the author encounters Cicero, among other philosophers, in Limbo. Ben Jonson dramatised the conspiracy of Catiline in his play "Catiline His Conspiracy", featuring Cicero as a character. Cicero also appears as a minor character in William Shakespeare's play "Julius Caesar".

Cicero was portrayed on the motion picture screen by British actor Alan Napier in the 1953 film "Julius Caesar", based on Shakespeare's play. He has also been played by such noted actors as Michael Hordern (in "Cleopatra"), and André Morell (in the 1970 "Julius Caesar"). Most recently, Cicero was portrayed by David Bamber in the HBO series "Rome" (2005–2007) and appeared in both seasons.

In the historical novel series "Masters of Rome", Colleen McCullough presents a not-so-flattering depiction of Cicero's career, showing him struggling with an inferiority complex and vanity, morally flexible and fatally indiscreet, while his rival Julius Caesar is shown in a more approving light. Cicero is portrayed as a hero in the novel "A Pillar of Iron" by Taylor Caldwell (1965). Robert Harris' novels "Imperium", "Lustrum" (published under the name "Conspirata" in the United States) and "Dictator" comprise a three-part series based on the life of Cicero. In these novels Cicero's character is depicted in a more favorable way than in those of McCullough, with his positive traits equaling or outweighing his weaknesses (while conversely Caesar is depicted as more sinister than in McCullough). Cicero is a major recurring character in the "Roma Sub Rosa" series of mystery novels by Steven Saylor. He also appears several times as a peripheral character in John Maddox Roberts' "SPQR" series.

Samuel Barnett portrays Cicero in a 2017 audio drama series pilot produced by Big Finish Productions. A full series was released the following year. All episodes are written by David Llewellyn and directed and produced by Scott Handcock.



Works by Cicero
Biographies and descriptions of Cicero's time

Plutarch's biography of Cicero contained in the 

Consul

Consul (abbrev. "cos."; Latin plural "consules") was the title of one of the two chief magistrates of the Roman Republic, and subsequently also an important title under the Roman Empire. The title was used in other European city-states through antiquity and the Middle Ages, in particular in the Republics of Genoa and Pisa, then revived in modern states, notably in the First French Republic. The related adjective is consular, from the Latin "consularis".

This usage contrasts with modern terminology, where a consul is a type of diplomat.

A consul held the highest elected political office of the Roman Republic (509 to 27 BC), and ancient Romans considered the consulship the highest level of the "cursus honorum" (an ascending sequence of public offices to which politicians aspired). Consuls were elected to office and held power for one year. There were always two consuls in power at any time.

It was not uncommon for an organization under Roman private law to copy the terminology of state and city institutions for its own statutory agents. The founding statute, or contract, of such an organisation was called "lex", 'law'. The people elected each year were patricians, members of the upper class.

While many cities, including the Gallic states and the Carthaginian Republic, had a double-headed chief magistracy, another title was often used, such as the Punic "sufet", "Duumvir", or native styles like "Meddix".

The city-state of Genoa, unlike ancient Rome, bestowed the title of "consul" on various state officials, not necessarily restricted to the highest. Among these were Genoese officials stationed in various Mediterranean ports, whose role included helping Genoese merchants and sailors in difficulties with the local authorities. Great Britain reciprocated by appointing consuls to Genoa from 1722. This institution, with its name, was later emulated by other powers and is reflected in the modern usage of the word (see Consul (representative)).

In addition to the Genoese Republic, the Republic of Pisa also took the form of "Consul" in the early stages of its government. The Consulate of the Republic of Pisa was the major government institution present in Pisa between the 11th and 12th centuries. Despite losing space within the government since 1190 in favor of the Podestà, for some periods of the 13th century some citizens were again elected as consuls.

Throughout most of southern France, a consul ( or "") was an office equivalent to the of the north and roughly similar with English aldermen. The most prominent were those of Bordeaux and Toulouse, which came to be known as jurats and capitouls, respectively. The capitouls of Toulouse were granted transmittable nobility. In many other smaller towns the first consul was the equivalent of a mayor today, assisted by a variable number of secondary consuls and jurats. His main task was to levy and collect tax.

The Dukes of Gaeta often used also the title of "consul" in its Greek form "Hypatos" (see List of Hypati and Dukes of Gaeta).

After Napoleon Bonaparte staged a coup against the Directory government in November 1799, the French Republic adopted a constitution which conferred executive powers upon three consuls, elected for a period of ten years. In reality, the first consul, Bonaparte, dominated his two colleagues and held supreme power, soon making himself consul for life (1802) and eventually, in 1804, emperor.

The office was held by:


The short-lived Bolognese Republic, proclaimed in 1796 as a French client republic in the Central Italian city of Bologna, had a government consisting of nine consuls and its head of state was the "Presidente del Magistrato", i.e., chief magistrate, a presiding office held for four months by one of the consuls. Bologna already had consuls at some parts of its Medieval history.

The French-sponsored Roman Republic (15 February 1798 – 23 June 1800) was headed by multiple consuls:

Consular rule was interrupted by the Neapolitan occupation (27 November – 12 December 1798), which installed a Provisional Government:

Rome was occupied by France (11 July – 28 September 1799) and again by Naples (30 September 1799 – 23 June 1800), bringing an end to the Roman Republic.

Among the many petty local republics that were formed during the first year of the Greek Revolution, prior to the creation of a unified Provisional Government at the First National Assembly at Epidaurus, were:
"Note: in Greek, the term for "consul" is "hypatos" (ὕπατος), which translates as "supreme one", and hence does not necessarily imply a joint office."

In between a series of juntas and various other short-lived regimes, the young republic was governed by "consuls of the republic", with two consuls alternating in power every 4 months:

After a few presidents of the Provisional Junta, there were again consuls of the republic, 14 March 1841 – 13 March 1844 (ruling jointly, but occasionally styled "first consul", "second consul"): Carlos Antonio López Ynsfrán (b. 1792 – d. 1862) + Mariano Roque Alonzo Romero (d. 1853) (the lasts of the aforementioned juntistas, Commandant-General of the Army)
Thereafter all republican rulers were styled "president".

In modern terminology, a consul is a type of diplomat. The "American Heritage Dictionary" defines consul as "an official appointed by a government to reside in a foreign country and represent its interests there." "The Devil's Dictionary" defines Consul as "in American politics, a person who having failed to secure an office from the people is given one by the Administration on condition that he leave the country".

In most governments, the consul is the head of the consular section of an embassy, and is responsible for all consular services such as immigrant and non-immigrant visas, passports, and citizen services for expatriates living or traveling in the host country.
A less common modern usage is when the consul of one country takes a governing role in the host country.

Differently named, but same function

Modern UN System 


Specific

List of equations in classical mechanics

Classical mechanics is the branch of physics used to describe the motion of macroscopic objects. It is the most familiar of the theories of physics. The concepts it covers, such as mass, acceleration, and force, are commonly used and known. The subject is based upon a three-dimensional Euclidean space with fixed axes, called a frame of reference. The point of concurrency of the three axes is known as the origin of the particular space.

Classical mechanics utilises many equations—as well as other mathematical concepts—which relate various physical quantities to one another. These include differential equations, manifolds, Lie groups, and ergodic theory. This article gives a summary of the most important of these.

This article lists equations from Newtonian mechanics, see analytical mechanics for the more general formulation of classical mechanics (which includes Lagrangian and Hamiltonian mechanics).

Every conservative force has a potential energy. By following two principles one can consistently assign a non-relative value to "U":


In the following rotational definitions, the angle can be any angle about the specified axis of rotation. It is customary to use "θ", but this does not have to be the polar angle used in polar coordinate systems. The unit axial vector

formula_1

defines the axis of rotation, formula_2 = unit vector in direction of , formula_3 = unit vector tangential to the angle.


Cursus honorum

The , or more colloquially 'ladder of offices'; ) was the sequential order of public offices held by aspiring politicians in the Roman Republic and the early Roman Empire. It was designed for men of senatorial rank. The "cursus honorum" comprised a mixture of military and political administration posts; the ultimate prize for winning election to each "rung" in the sequence was to become one of the two consuls in a given year.

These rules were altered and flagrantly ignored in the course of the last century of the Republic. For example, Gaius Marius held consulships for five years in a row between 104 BC and 100 BC. He was consul seven times in all, also serving in 107 and 86. Officially presented as opportunities for public service, the offices often became mere opportunities for self-aggrandizement. The constitutional reforms of Sulla between 82 and 79 BC required a ten-year interval before holding the same office again for another term.

To have held each office at the youngest possible age ("suo anno", 'in his year') was considered a great political success. For instance, to miss out on a praetorship at 39 meant that one could not become consul at 42. Cicero expressed extreme pride not only in being a "novus homo" ('new man'; comparable to a "self-made man") who became consul even though none of his ancestors had ever served as a consul, but also in having become consul "in his year".

Prior to entering political life and the "cursus honorum", a young man of senatorial rank was expected to serve around ten years of military duty. The years of service were intended to be mandatory in order to qualify for political office.

Advancement and honors would improve his political prospects, and a successful military career might culminate in the office of military tribune, to which 24 men were elected by the Tribal Assembly each year. The rank of military tribune is sometimes described as the first office of the "cursus honorum".

The first official post was that of quaestor. Ever since the reforms of Sulla, candidates had to be at least 30 years old to hold the office. From the time of Augustus onwards, twenty quaestors served in the financial administration at Rome or as second-in-command to a governor in the provinces. They could also serve as the paymaster for a legion.

At 36 years of age, a promagistrate could stand for election to one of the aediles (pronounced , from "aedes", "temple edifice") positions. Of these aediles, two were plebeian and two were patrician, with the patrician aediles called curule aediles. The plebeian aediles were elected by the Plebeian Council and the curule aediles were either elected by the Tribal Assembly or appointed by the reigning consul. The aediles had administrative responsibilities in Rome. They had to take care of the temples (whence their title, from the Latin "aedes", "temple"), organize games, and be responsible for the maintenance of the public buildings in Rome. Moreover, they took charge of Rome's water and food supplies; in their capacity as market superintendents, they served sometimes as judges in mercantile affairs.

The aedile was the supervisor of public works; the words "edifice" and "edification" stem from the same root. He oversaw the public works, temples and markets. Therefore, the aediles would have been in some cooperation with the current censors, who had similar or related duties. Also, they oversaw the organization of festivals and games ("ludi"), which made this a very sought-after office for a career minded politician of the late Republic, as it was a good means of gaining popularity by staging spectacles.

Curule aediles were added at a later date in the 4th century BC; their duties do not differ substantially from plebeian aediles. However, unlike plebeian aediles, curule aediles were allowed certain symbols of rank—the "sella curulis" or curule chair, for example—and only patricians could stand for election to curule aedile. This later changed, and both plebeians and patricians could stand for curule aedileship.

The elections for curule aedile were at first alternated between patricians and plebeians, until late in the 2nd century BC, when the practice was abandoned and both classes became free to run during all years.

While part of the "cursus honorum", this step was optional and not required to hold future offices. Though the office was usually held after the quaestorship and before the praetorship, there are some cases with former praetors serving as aediles.

After serving either as quaestor or as aedile, a man of 39 years could run for praetor. During the reign of Augustus this requirement was lowered to 30, at the request of Gaius Maecenas. The number of praetors elected varied through history, generally increasing with time. During the republic, six or eight were generally elected each year to serve judicial functions throughout Rome and other governmental responsibilities. In the absence of the consuls, a praetor would be given command of the garrison in Rome or in Italy. Also, a praetor could exercise the functions of the consuls throughout Rome, but their main function was that of a judge. They would preside over trials involving criminal acts, grant court orders and validate "illegal" acts as acts of administering justice. A praetor was escorted by six lictors, and wielded "imperium". After a term as praetor, the magistrate could serve as a provincial governor with the title of propraetor, wielding "propraetor imperium", commanding the province's legions, and possessing ultimate authority within his province(s).

Two of the praetors were more prestigious than the others. The first was the Praetor Peregrinus, who was the chief judge in trials involving one or more foreigners. The other was the Praetor Urbanus, the chief judicial office in Rome. He had the power to overturn any verdict by any other courts, and served as judge in cases involving criminal charges against provincial governors. The Praetor Urbanus was not allowed to leave the city for more than ten days. If one of these two praetors was absent from Rome, the other would perform the duties of both.

The office of consul was the most prestigious of all of the offices on the "cursus honorum", and represented the summit of a successful career. The minimum age was 42. Years were identified by the names of the two consuls elected for a particular year; for instance, "M. Messalla et M. Pisone consulibus", "in the consulship of Messalla and Piso", dates an event to 61 BC. Consuls were responsible for the city's political agenda, commanded large-scale armies and controlled important provinces. The consuls served for only a year (a restriction intended to limit the amassing of power by individuals) and could only rule when they agreed, because each consul could veto the other's decision.

The consuls would alternate monthly as the chairman of the Senate. They also were the supreme commanders in the Roman army, with each being granted two legions during their consular year. Consuls also exercised the highest juridical power in the Republic, being the only office with the power to override the decisions of the Praetor Urbanus. Only laws and the decrees of the Senate or the People's assembly limited their powers, and only the veto of a fellow consul or a tribune of the plebs could supersede their decisions.

A consul was escorted by twelve lictors, held "imperium" and wore the toga "praetexta". Because the consul was the highest executive office within the Republic, they had the power to veto any action or proposal by any other magistrate, save that of the Tribune of the Plebs. After a consulship, a consul was assigned one of the more important provinces and acted as the governor in the same way that a propraetor did, only owning proconsular "imperium". A second consulship could only be attempted after an interval of 10 years to prevent one man holding too much power.

Although not part of the "cursus honorum", upon completing a term as either praetor or consul, an officer was required to serve a term as propraetor and proconsul, respectively, in one of Rome's many provinces. These propraetors and proconsuls held near autocratic authority within their selected province or provinces. Because each governor held equal "imperium" to the equivalent magistrate, they were escorted by the same number of lictors (12) and could only be vetoed by a reigning consul or praetor. Their abilities to govern were only limited by the decrees of the Senate or the people's assemblies, and the Tribune of the Plebs was unable to veto their acts as long as the governor remained at least a mile outside of Rome.

After a term as consul, the final step in the "cursus honorum" was the office of "censor". This was the only office in the Roman Republic whose term was a period of eighteen months instead of the usual twelve. Censors were elected every five years and although the office held no military "imperium", it was considered a great honour. The censors took a regular census of the people and then apportioned the citizens into voting classes on the basis of income and tribal affiliation. The censors enrolled new citizens in tribes and voting classes as well. The censors were also in charge of the membership roll of the Senate, every five years adding new senators who had been elected to the requisite offices. Censors could also remove unworthy members from the Senate. This ability was lost during the dictatorship of Sulla. Censors were also responsible for construction of public buildings and the moral status of the city.

Censors also had financial duties, in that they had to put out to tender projects that were to be financed by the state. Also, the censors were in charge of the leasing out of conquered land for public use and auction. Though this office owned no "imperium", meaning no lictors for protection, they were allowed to wear the toga "praetexta".

The office of Tribune of the Plebs was an important step in the political career of plebeians. Patricians could not hold the office. They were not an official step in the "cursus honorum". The Tribune was an office first created to protect the right of the common man in Roman politics and served as the head of the Plebeian Council. In the mid-to-late Republic, however, plebeians were often just as, and sometimes more, wealthy and powerful than patricians. Those who held the office were granted sacrosanctity (the right to be legally protected from any physical harm), the power to rescue any plebeian from the hands of a patrician magistrate, and the right to veto any act or proposal of any magistrate, including another tribune of the people and the consuls. The tribune also had the power to exercise capital punishment against any person who interfered in the performance of his duties. The tribunes could even convene a Senate meeting and lay legislation before it and arrest magistrates. Their houses had to remain open for visitors even during the night, and they were not allowed to be more than a day's journey from Rome. Due to their unique power of sacrosanctity, the Tribune had no need for lictors for protection and owned no "imperium", nor could they wear the toga "praetexta". For a period after Sulla's reforms, a person who had held the office of Tribune of the Plebs could no longer qualify for any other office, and the powers of the tribunes were more limited, but these restrictions were subsequently lifted.

Another office not officially a step in the "cursus honorum" was the "princeps senatus", an extremely prestigious office for a patrician. The "princeps senatus" served as the leader of the Senate and was chosen to serve a five-year term by each pair of Censors every five years. Censors could, however, confirm a "princeps senatus" for a period of another five years. The "princeps senatus" was chosen from all Patricians who had served as a Consul, with former Censors usually holding the office. The office originally granted the holder the ability to speak first at session on the topic presented by the presiding magistrate, but eventually gained the power to open and close the senate sessions, decide the agenda, decide where the session should take place, impose order and other rules of the session, meet in the name of the senate with embassies of foreign countries, and write in the name of the senate letters and dispatches. This office, like the Tribune, did not own "imperium", was not escorted by lictors, and could not wear the "toga praetexta".

Of all the offices within the Roman Republic, none granted as much power and authority as the position of dictator, known as the Master of the People. In times of emergency, the Senate would declare that a dictator was required, and the current consuls would appoint a dictator. This was the only decision that could not be vetoed by the Tribune of the Plebs. The dictator was the sole exception to the Roman legal principles of having multiple magistrates in the same office and being legally able to be held to answer for actions in office. Essentially by definition, only one dictator could serve at a time, and no dictator could ever be held legally responsible for any action during his time in office for any reason.

The dictator was the highest magistrate in degree of "imperium" and was attended by twenty-four lictors (as were the former Kings of Rome). Although his term lasted only six months instead of twelve (except for the Dictatorships of Sulla and Caesar), all other magistrates reported to the dictator (except for the tribunes of the plebs – although they could not veto any of the dictator's acts), granting the dictator absolute authority in both civil and military matters throughout the Republic. The dictator was free from the control of the Senate in all that he did, could execute anyone without a trial for any reason, and could ignore any law in the performance of his duties. The dictator was the sole magistrate under the Republic that was truly independent in discharging his duties. All of the other offices were extensions of the Senate's executive authority and thus answerable to the Senate. Since the dictator exercised his own authority, he did not suffer this limitation, which was the cornerstone of the office's power.

When a dictator entered office, he appointed to serve as his second-in-command a "magister equitum", the Master of the Horse, whose office ceased to exist once the dictator left office. The "magister equitum" held "praetorian imperium", was attended by six lictors, and was charged with assisting the dictator in managing the State. When the dictator was away from Rome, the "magister equitum" usually remained behind to administer the city. The "magister equitum", like the dictator, had unchallengeable authority in all civil and military affairs, with his decisions only being overturned by the dictator himself.

The dictatorship was definitively abolished in 44 BC after the assassination of Gaius Julius Caesar ("Lex Antonia").



Continental drift

Continental drift is the hypothesis, originating in the early 20th century, that Earth's continents move or drift relative to each other over geologic time. The hypothesis of continental drift has since been validated and incorporated into the science of plate tectonics, which studies the movement of the continents as they ride on plates of the Earth's lithosphere.

The speculation that continents might have "drifted" was first put forward by Abraham Ortelius in 1596. A pioneer of the modern view of mobilism was the Austrian geologist Otto Ampferer. The concept was independently and more fully developed by Alfred Wegener in his 1915 publication, "The Origin of Continents and Oceans". However, at that time the hypothesis was rejected by many for lack of any motive mechanism. The English geologist Arthur Holmes later proposed mantle convection for that mechanism.

Abraham Ortelius , Theodor Christoph Lilienthal (1756), Alexander von Humboldt (1801 and 1845), Antonio Snider-Pellegrini , and others had noted earlier that the shapes of continents on opposite sides of the Atlantic Ocean (most notably, Africa and South America) seem to fit together. W. J. Kious described Ortelius' thoughts in this way:
In 1889, Alfred Russel Wallace remarked, "It was formerly a very general belief, even amongst geologists, that the great features of the earth's surface, no less than the smaller ones, were subject to continual mutations, and that during the course of known geological time the continents and great oceans had, again and again, changed places with each other." He quotes Charles Lyell as saying, "Continents, therefore, although permanent for whole geological epochs, shift their positions entirely in the course of ages." and claims that the first to throw doubt on this was James Dwight Dana in 1849.

In his "Manual of Geology" (1863), Dana wrote, "The continents and oceans had their general outline or form defined in earliest time. This has been proved with regard to North America from the position and distribution of the first beds of the Lower Silurian, – those of the Potsdam epoch. The facts indicate that the continent of North America had its surface near tide-level, part above and part below it (p.196); and this will probably be proved to be the condition in Primordial time of the other continents also. And, if the outlines of the continents were marked out, it follows that the outlines of the oceans were no less so". Dana was enormously influential in America—his "Manual of Mineralogy" is still in print in revised form—and the theory became known as the "Permanence theory".

This appeared to be confirmed by the exploration of the deep sea beds conducted by the "Challenger" expedition, 1872–1876, which showed that contrary to expectation, land debris brought down by rivers to the ocean is deposited comparatively close to the shore on what is now known as the continental shelf. This suggested that the oceans were a permanent feature of the Earth's surface, rather than them having "changed places" with the continents.

Eduard Suess had proposed a supercontinent Gondwana in 1885 and the Tethys Ocean in 1893, assuming a land-bridge between the present continents submerged in the form of a geosyncline, and John Perry had written an 1895 paper proposing that the Earth's interior was fluid, and disagreeing with Lord Kelvin on the age of the Earth.

Apart from the earlier speculations mentioned above, the idea that the American continents had once formed a single landmass with Eurasia and Africa was postulated by several scientists before Alfred Wegener's 1912 paper. Although Wegener's theory was formed independently and was more complete than those of his predecessors, Wegener later credited a number of past authors with similar ideas: Franklin Coxworthy (between 1848 and 1890), Roberto Mantovani (between 1889 and 1909), William Henry Pickering (1907) and Frank Bursley Taylor (1908).

The similarity of southern continent geological formations had led Roberto Mantovani to conjecture in 1889 and 1909 that all the continents had once been joined into a supercontinent; Wegener noted the similarity of Mantovani's and his own maps of the former positions of the southern continents. In Mantovani's conjecture, this continent broke due to volcanic activity caused by thermal expansion, and the new continents drifted away from each other because of further expansion of the rip-zones, where the oceans now lie. This led Mantovani to propose a now-discredited Expanding Earth theory.

Continental drift without expansion was proposed by Frank Bursley Taylor, who suggested in 1908 (published in 1910) that the continents were moved into their present positions by a process of "continental creep", later proposing a mechanism of increased tidal forces during the Cretaceous dragging the crust towards the equator. He was the first to realize that one of the effects of continental motion would be the formation of mountains, attributing the formation of the Himalayas to the collision between the Indian subcontinent with Asia. Wegener said that of all those theories, Taylor's had the most similarities to his own. For a time in the mid-20th century, the theory of continental drift was referred to as the "Taylor-Wegener hypothesis".

Alfred Wegener first presented his hypothesis to the German Geological Society on 6 January 1912. His hypothesis was that the continents had once formed a single landmass, called Pangaea, before breaking apart and drifting to their present locations.

Wegener was the first to use the phrase "continental drift" (1912, 1915) (in German "die Verschiebung der Kontinente" – translated into English in 1922) and formally publish the hypothesis that the continents had somehow "drifted" apart. Although he presented much evidence for continental drift, he was unable to provide a convincing explanation for the physical processes which might have caused this drift. He suggested that the continents had been pulled apart by the centrifugal pseudoforce ("Polflucht") of the Earth's rotation or by a small component of astronomical precession, but calculations showed that the force was not sufficient. The Polflucht hypothesis was also studied by Paul Sophus Epstein in 1920 and found to be implausible.

Although now accepted, the theory of continental drift was rejected for many years, with evidence in its favor considered insufficient. One problem was that a plausible driving force was missing. A second problem was that Wegener's estimate of the speed of continental motion, 250 cm/year, was implausibly high. (The currently accepted rate for the separation of the Americas from Europe and Africa is about 2.5 cm/year). Furthermore, Wegener was treated less seriously because he was not a geologist. Even today, the details of the forces propelling the plates are poorly understood.

The English geologist Arthur Holmes championed the theory of continental drift at a time when it was deeply unfashionable. He proposed in 1931 that the Earth's mantle contained convection cells which dissipated heat produced by radioactive decay and moved the crust at the surface. His "Principles of Physical Geology", ending with a chapter on continental drift, was published in 1944.

Geological maps of the time showed huge land bridges spanning the Atlantic and Indian oceans to account for the similarities of fauna and flora and the divisions of the Asian continent in the Permian period, but failing to account for glaciation in India, Australia and South Africa.

Hans Stille and Leopold Kober opposed the idea of continental drift and worked on a "fixist" geosyncline model with Earth contraction playing a key role in the formation of orogens. Other geologists who opposed continental drift were Bailey Willis, Charles Schuchert, Rollin Chamberlin, Walther Bucher and Walther Penck. In 1939 an international geological conference was held in Frankfurt. This conference came to be dominated by the fixists, especially as those geologists specializing in tectonics were all fixists except Willem van der Gracht. Criticism of continental drift and mobilism was abundant at the conference not only from tectonicists but also from sedimentological (Nölke), paleontological (Nölke), mechanical (Lehmann) and oceanographic (Troll, Wüst) perspectives. Hans Cloos, the organizer of the conference, was also a fixist who together with Troll held the view that excepting the Pacific Ocean continents were not radically different from oceans in their behaviour. The mobilist theory of Émile Argand for the Alpine orogeny was criticized by Kurt Leuchs. The few drifters and mobilists at the conference appealed to biogeography (Kirsch, Wittmann), paleoclimatology (Wegener, K), paleontology (Gerth) and geodetic measurements (Wegener, K). F. Bernauer correctly equated Reykjanes in south-west Iceland with the Mid-Atlantic Ridge, arguing with this that the floor of the Atlantic Ocean was undergoing extension just like Reykjanes. Bernauer thought this extension had drifted the continents only 100–200 km apart, the approximate width of the volcanic zone in Iceland.

David Attenborough, who attended university in the second half of the 1940s, recounted an incident illustrating its lack of acceptance then: "I once asked one of my lecturers why he was not talking to us about continental drift and I was told, sneeringly, that if I could prove there was a force that could move continents, then he might think about it. The idea was moonshine, I was informed."

As late as 1953—just five years before Carey introduced the theory of plate tectonics—the theory of continental drift was rejected by the physicist Scheidegger on the following grounds.

From the 1930s to the late 1950s, works by Vening-Meinesz, Holmes, Umbgrove, and numerous others outlined concepts that were close or nearly identical to modern plate tectonics theory. In particular, the English geologist Arthur Holmes proposed in 1920 that plate junctions might lie beneath the sea, and in 1928 that convection currents within the mantle might be the driving force. Holmes' views were particularly influential: in his bestselling textbook, "Principles of Physical Geology," he included a chapter on continental drift, proposing that Earth's mantle contained convection cells which dissipated radioactive heat and moved the crust at the surface.  Holmes' proposal resolved the phase disequilibrium objection (the underlying fluid was kept from solidifying by radioactive heating from the core). However, scientific communication in the 1930s and 1940s was inhibited by World War II, and the theory still required work to avoid foundering on the orogeny and isostasy objections. Worse, the most viable forms of the theory predicted the existence of convection cell boundaries reaching deep into the Earth, that had yet to be observed.

In 1947, a team of scientists led by Maurice Ewing confirmed the existence of a rise in the central Atlantic Ocean, and found that the floor of the seabed beneath the sediments was chemically and physically different from continental crust.  As oceanographers continued to bathymeter the ocean basins, a system of mid-oceanic ridges was detected.  An important conclusion was that along this system, new ocean floor was being created, which led to the concept of the "Great Global Rift".

Meanwhile, scientists began recognizing odd magnetic variations across the ocean floor using devices developed during World War II to detect submarines.  Over the next decade, it became increasingly clear that the magnetization patterns were not anomalies, as had been originally supposed. In a series of papers in 1959–1963, Heezen, Dietz, Hess, Mason, Vine, Matthews, and Morley collectively realized that the magnetization of the ocean floor formed extensive, zebra-like patterns: one stripe would exhibit normal polarity and the adjoining stripes reversed polarity.  The best explanation was the "conveyor belt" or Vine–Matthews–Morley hypothesis.  New magma from deep within the Earth rises easily through these weak zones and eventually erupts along the crest of the ridges to create new oceanic crust.  The new crust is magnetized by the Earth's magnetic field, which undergoes occasional reversals.  Formation of new crust then displaces the magnetized crust apart, akin to a conveyor belt – hence the name.

Without workable alternatives to explain the stripes, geophysicists were forced to conclude that Holmes had been right: ocean rifts were sites of perpetual orogeny at the boundaries of convection cells. By 1967, barely two decades after discovery of the mid-oceanic rifts, and a decade after discovery of the striping, plate tectonics had become axiomatic to modern geophysics.

In addition, Marie Tharp, in collaboration with Bruce Heezen, who was initially sceptical of Tharp's observations that her maps confirmed continental drift theory, provided essential corroboration, using her skills in cartography and seismographic data, to confirm the theory.

Geophysicist Jack Oliver is credited with providing seismologic evidence supporting plate tectonics which encompassed and superseded continental drift with the article "Seismology and the New Global Tectonics", published in 1968, using data collected from seismologic stations, including those he set up in the South Pacific. The modern theory of plate tectonics, refining Wegener, explains that there are two kinds of crust of different composition: continental crust and oceanic crust, both floating above a much deeper "plastic" mantle. Continental crust is inherently lighter. Oceanic crust is created at spreading centers, and this, along with subduction, drives the system of plates in a chaotic manner, resulting in continuous orogeny and areas of isostatic imbalance.

Evidence for the movement of continents on tectonic plates is now extensive. Similar plant and animal fossils are found around the shores of different continents, suggesting that they were once joined. The fossils of "Mesosaurus", a freshwater reptile rather like a small crocodile, found both in Brazil and South Africa, are one example; another is the discovery of fossils of the land reptile "Lystrosaurus" in rocks of the same age at locations in Africa, India, and Antarctica. There is also living evidence, with the same animals being found on two continents. Some earthworm families (such as Ocnerodrilidae, Acanthodrilidae, Octochaetidae) are found in South America and Africa.

The complementary arrangement of the facing sides of South America and Africa is obvious but a temporary coincidence. In millions of years, slab pull, ridge-push, and other forces of tectonophysics will further separate and rotate those two continents. It was that temporary feature that inspired Wegener to study what he defined as continental drift although he did not live to see his hypothesis generally accepted.

The widespread distribution of Permo-Carboniferous glacial sediments in South America, Africa, Madagascar, Arabia, India, Antarctica and Australia was one of the major pieces of evidence for the theory of continental drift. The continuity of glaciers, inferred from oriented glacial striations and deposits called tillites, suggested the existence of the supercontinent of Gondwana, which became a central element of the concept of continental drift. Striations indicated glacial flow away from the equator and toward the poles, based on continents' current positions and orientations, and supported the idea that the southern continents had previously been in dramatically different locations that were contiguous with one another.




Commodores

Commodores, often billed as the Commodores, are an American funk and soul group. The group's most successful period was in the late 1970s and early 1980s when Lionel Richie was the co-lead singer.

The members of the group met as mostly freshmen at Tuskegee Institute (now Tuskegee University) in 1968, and signed with Motown in November 1972, having first caught the public eye opening for the Jackson 5 while on tour.

The band's biggest hit singles are ballads such as "Easy", "Three Times a Lady", and "Nightshift"; and funk-influenced dance songs, including "Brick House", "Fancy Dancer", "Lady (You Bring Me Up)", and "Too Hot ta Trot". 

Commodores were inducted into the Alabama Music Hall of Fame and Vocal Group Hall of Fame. The band has also won one Grammy Award out of nine nominations. The Commodores have sold over 70 million albums worldwide.

Commodores were formed from two former student groups, the Mystics and the Jays. Richie described some members of the Mystics as "jazz buffs". The new six-man band featured Lionel Richie, Thomas McClary, and William King from the Mystics, and Andre Callahan, Michael Gilbert, and Milan Williams from the Jays. To choose their name, William King opened a dictionary and randomly picked a word. "We lucked in," he remarked with a laugh when telling this story to "People" magazine. "We almost became 'The Commodes.'"

The bandmembers attended Tuskegee University in Alabama. After winning the university's annual freshman talent contest, they played at fraternity parties as well as a weekend gig at the Black Forest Inn, one of a few clubs in Tuskegee that catered to college students. They performed cover tunes and some original songs with their first singer, James Ingram (not the famous solo artist). Ingram, older than the rest of the band, left to serve in Vietnam, and was later replaced by drummer Walter "Clyde" Orange, who wrote or co-wrote many of their hits. Lionel Richie and Orange alternated as lead singers. Orange was the lead singer on the Top 10 hits "Brick House" (1977) and "Nightshift" (1985).

The early band was managed by Benny Ashburn, who brought them to his family's vacation lodge on Martha's Vineyard in 1971 and 1972. There, Ashburn test-marketed the group by having them play in parking lots and summer festivals.

"Machine Gun" (1974), the instrumental title track from the band's debut album, became a staple at American sporting events, and is also heard in many films, including "Boogie Nights" and "Looking for Mr. Goodbar". It reached No. 22 on the "Billboard" Hot 100 in 1974. Another 1974 song "I Feel Sanctified" has been called a "prototype" of Wild Cherry's 1976 big hit "Play That Funky Music". Three albums released in 1975 and 1976, "Caught in the Act" was funk album, but "Movin' On" and "Hot on the Tracks" were pop albums. After those recordings the group developed the mellower sound hinted at in their 1976 top-ten hits, "Sweet Love" and "Just to Be Close to You". In 1977, the Commodores released "Easy", which became the group's biggest hit yet, reaching No. 4 in the US, followed by funky single "Brick House", also top 5, both from their album "Commodores", as was "Zoom". The group reached No. 1 in 1978 with "Three Times a Lady". In 1979, the Commodores scored another top-five ballad, "Sail On", before reaching the top of the charts once again with another ballad, "Still". In 1981 they released two top-ten hits with "Oh No" (No. 4) and their first upbeat single in almost five years, "Lady (You Bring Me Up)" (No. 8).

Commodores made a brief appearance in the 1978 film, "Thank God It's Friday". They performed the song "Too Hot ta Trot" during the dance contest; the songs "Brick House" and "Easy" were also played in the movie

In 1982, the group decided to take a hiatus from touring and recording, during which time Lionel Richie recorded a solo album at the suggestion of Motown and the other group members. Its success encouraged Richie to pursue a solo career, and Skyler Jett replaced him as co-lead singer. Also in 1982, Ashburn died of a heart attack at the age of 54.

Founding member McClary left in 1984 (shortly after Richie) to pursue a solo career, and to develop a gospel music company. McClary was replaced by guitarist-vocalist Sheldon Reynolds. Then LaPread left in 1986 and moved to Auckland, New Zealand. Reynolds departed for Earth, Wind & Fire in 1987, which prompted trumpeter William "WAK" King to take over primary guitar duties for live performances. Keyboardist Milan Williams exited the band in 1989 after allegedly refusing to tour South Africa.

The group gradually abandoned its funk roots and moved into the more commercial pop arena. In 1984, former Heatwave singer James Dean "J.D." Nicholas assumed co-lead vocal duties with drummer Walter Orange. That line-up was hitless until 1985 when their final Motown album "Nightshift", produced by Dennis Lambert (prior albums were produced by James Anthony Carmichael), delivered the title track "Nightshift", a loving tribute to Marvin Gaye and Jackie Wilson, both of whom had died the previous year. "Nightshift" hit no. 3 in the US and won the Commodores their first Grammy for Best R&B Performance by a Duo or Group With Vocals in 1985.

In 2010 a new version was recorded, dedicated to Michael Jackson. The Commodores were on a European tour performing at Wembley Arena, London, on June 25, 2009, when they walked off the stage after they were told that Michael Jackson had died. Initially the band thought it was a hoax. However, back in their dressing rooms they received confirmation and broke down in tears. The next night at Birmingham's NIA Arena, J.D. Nicholas added Jackson's name to the lyrics of the song, and henceforth the Commodores have mentioned Jackson and other deceased R&B singers. Thus came the inspiration upon the one-year anniversary of Jackson's death to re-record, with new lyrics, the hit song "Nightshift" as a tribute.

In 1990, they formed Commodores Records and re-recorded their 20 greatest hits as "Commodores Hits Vol. I & II". They have recorded a live album, "Commodores Live", along with a DVD of the same name, and a Christmas album titled "Commodores Christmas". In 2012, the band was working on new material, with some contributions written by current and former members.

Commodores as of 2020 consist of Walter "Clyde" Orange, James Dean "J.D." Nicholas, and William "WAK" King, along with their five-piece band The Mean Machine.They continue to perform, playing at arenas, theaters, and festivals around the world.




The Commodores have won one Grammy Award out of ten nominations.

During 1995 the Commodores were inducted into the Alabama Music Hall of Fame.

During 2003 the Commodores were also inducted into the Vocal Group Hall of Fame.


Collagen

Collagen () is the main structural protein in the extracellular matrix found in the body's various connective tissues. As the main component of connective tissue, it is the most abundant protein in mammals, making up from 25% to 35% of the whole-body protein content. Collagen consists of amino acids bound together to form a triple helix of elongated fibril known as a collagen helix. It is mostly found in connective tissue such as cartilage, bones, tendons, ligaments, and skin. Vitamin C is vital for collagen synthesis, and Vitamin E improves the production of collagen.

Depending upon the degree of mineralization, collagen tissues may be rigid (bone) or compliant (tendon) or have a gradient from rigid to compliant (cartilage). Collagen is also abundant in corneas, blood vessels, the gut, intervertebral discs, and the dentin in teeth. In muscle tissue, it serves as a major component of the endomysium. Collagen constitutes one to two percent of muscle tissue and accounts for 6% of the weight of the skeletal muscle tissue. The fibroblast is the most common cell that creates collagen. Gelatin, which is used in food and industry, is collagen that has been irreversibly hydrolyzed using heat, basic solutions or weak acids.

The name "collagen" comes from the Greek κόλλα ("kólla"), meaning "glue", and suffix -γέν, "-gen", denoting "producing".

Over 90% of the collagen in the human body is type I collagen. However, as of 2011, 28 types of human collagen have been identified, described, and divided into several groups according to the structure they form. All of the types contain at least one triple helix. The number of types shows collagen's diverse functionality.

The five most common types are:

The collagenous cardiac skeleton which includes the four heart valve rings, is histologically, elastically and uniquely bound to cardiac muscle. The cardiac skeleton also includes the separating septa of the heart chambers – the interventricular septum and the atrioventricular septum. Collagen contribution to the measure of cardiac performance summarily represents a continuous torsional force opposed to the fluid mechanics of blood pressure emitted from the heart. The collagenous structure that divides the upper chambers of the heart from the lower chambers is an impermeable membrane that excludes both blood and electrical impulses through typical physiological means. With support from collagen, atrial fibrillation never deteriorates to ventricular fibrillation. Collagen is layered in variable densities with smooth muscle mass. The mass, distribution, age, and density of collagen all contribute to the compliance required to move blood back and forth. Individual cardiac valvular leaflets are folded into shape by specialized collagen under variable pressure. Gradual calcium deposition within collagen occurs as a natural function of aging. Calcified points within collagen matrices show contrast in a moving display of blood and muscle, enabling methods of cardiac imaging technology to arrive at ratios essentially stating blood in (cardiac input) and blood out (cardiac output). Pathology of the collagen underpinning of the heart is understood within the category of connective tissue disease.

As the skeleton forms the structure of the body, it is vital that it maintains its strength, even after breaks and injuries. Collagen is used in bone grafting as it has a triple helical structure, making it a very strong molecule. It is ideal for use in bones, as it does not compromise the structural integrity of the skeleton. The triple helical structure of collagen prevents it from being broken down by enzymes, it enables adhesiveness of cells and it is important for the proper assembly of the extracellular matrix.

Collagen scaffolds are used in tissue regeneration, whether in sponges, thin sheets, gels, or fibers. Collagen has favorable properties for tissue regeneration, such as pore structure, permeability, hydrophilicity, and stability in vivo. Collagen scaffolds also support deposition of cells, such as osteoblasts and fibroblasts, and once inserted, facilitate growth to proceed normally.

Collagens are widely employed in the construction of artificial skin substitutes used in the management of severe burns and wounds. These collagens may be derived from bovine, equine, porcine, or even human sources; and are sometimes used in combination with silicones, glycosaminoglycans, fibroblasts, growth factors and other substances.

Collagen is one of the body's key natural resources and a component of skin tissue that can benefit all stages of wound healing. When collagen is made available to the wound bed, closure can occur. Wound deterioration, followed sometimes by procedures such as amputation, can thus be avoided.

Collagen is a natural product and is thus used as a natural wound dressing and has properties that artificial wound dressings do not have. It is resistant against bacteria, which is of vital importance in a wound dressing. It helps to keep the wound sterile, because of its natural ability to fight infection. When collagen is used as a burn dressing, healthy granulation tissue is able to form very quickly over the burn, helping it to heal rapidly.

Throughout the four phases of wound healing, collagen performs the following functions:

Collagen is used in laboratory studies for cell culture, studying cell behavior and cellular interactions with the extracellular environment. Collagen is also widely used as a bioink for 3D bioprinting and biofabrication of 3D tissue models.

The collagen protein is composed of a triple helix, which generally consists of two identical chains (α1) and an additional chain that differs slightly in its chemical composition (α2). The amino acid composition of collagen is atypical for proteins, particularly with respect to its high hydroxyproline content. The most common motifs in the amino acid sequence of collagen are glycine-proline-X and glycine-X-hydroxyproline, where X is any amino acid other than glycine, proline or hydroxyproline. The average amino acid composition for fish and mammal skin is given.

First, a three-dimensional stranded structure is assembled, with the amino acids glycine and proline as its principal components. This is not yet collagen but its precursor, procollagen. Procollagen is then modified by the addition of hydroxyl groups to the amino acids proline and lysine. This step is important for later glycosylation and the formation of the triple helix structure of collagen. Because the hydroxylase enzymes that perform these reactions require vitamin C as a cofactor, a long-term deficiency in this vitamin results in impaired collagen synthesis and scurvy. These hydroxylation reactions are catalyzed by two different enzymes: prolyl 4-hydroxylase and lysyl hydroxylase. The reaction consumes one ascorbate molecule per hydroxylation.

The synthesis of collagen occurs inside and outside of the cell. The formation of collagen which results in fibrillary collagen (most common form) is discussed here. Meshwork collagen, which is often involved in the formation of filtration systems, is the other form of collagen. All types of collagens are triple helices, and the differences lie in the make-up of the alpha peptides created in step 2.

Collagen has an unusual amino acid composition and sequence:

Cortisol stimulates degradation of (skin) collagen into amino acids.

Most collagen forms in a similar manner, but the following process is typical for type I:


Vitamin C deficiency causes scurvy, a serious and painful disease in which defective collagen prevents the formation of strong connective tissue. Gums deteriorate and bleed, with loss of teeth; skin discolors, and wounds do not heal. Prior to the 18th century, this condition was notorious among long-duration military, particularly naval, expeditions during which participants were deprived of foods containing vitamin C.

An autoimmune disease such as lupus erythematosus or rheumatoid arthritis may attack healthy collagen fibers.

Many bacteria and viruses secrete virulence factors, such as the enzyme collagenase, which destroys collagen or interferes with its production.

A single collagen molecule, tropocollagen, is used to make up larger collagen aggregates, such as fibrils. It is approximately 300 nm long and 1.5 nm in diameter, and it is made up of three polypeptide strands (called alpha peptides, see step 2), each of which has the conformation of a left-handed helix – this should not be confused with the right-handed alpha helix. These three left-handed helices are twisted together into a right-handed triple helix or "super helix", a cooperative quaternary structure stabilized by many hydrogen bonds. With type I collagen and possibly all fibrillar collagens, if not all collagens, each triple-helix associates into a right-handed super-super-coil referred to as the collagen microfibril. Each microfibril is interdigitated with its neighboring microfibrils to a degree that might suggest they are individually unstable, although within collagen fibrils, they are so well ordered as to be crystalline.

A distinctive feature of collagen is the regular arrangement of amino acids in each of the three chains of these collagen subunits. The sequence often follows the pattern Gly-Pro-X or Gly-X-Hyp, where X may be any of various other amino acid residues. Proline or hydroxyproline constitute about 1/6 of the total sequence. With glycine accounting for the 1/3 of the sequence, this means approximately half of the collagen sequence is not glycine, proline or hydroxyproline, a fact often missed due to the distraction of the unusual GXX character of collagen alpha-peptides. The high glycine content of collagen is important with respect to stabilization of the collagen helix as this allows the very close association of the collagen fibers within the molecule, facilitating hydrogen bonding and the formation of intermolecular cross-links. This kind of regular repetition and high glycine content is found in only a few other fibrous proteins, such as silk fibroin.

Collagen is not only a structural protein. Due to its key role in the determination of cell phenotype, cell adhesion, tissue regulation, and infrastructure, many sections of its non-proline-rich regions have cell or matrix association/regulation roles. The relatively high content of proline and hydroxyproline rings, with their geometrically constrained carboxyl and (secondary) amino groups, along with the rich abundance of glycine, accounts for the tendency of the individual polypeptide strands to form left-handed helices spontaneously, without any intrachain hydrogen bonding.

Because glycine is the smallest amino acid with no side chain, it plays a unique role in fibrous structural proteins. In collagen, Gly is required at every third position because the assembly of the triple helix puts this residue at the interior (axis) of the helix, where there is no space for a larger side group than glycine's single hydrogen atom. For the same reason, the rings of the Pro and Hyp must point outward. These two amino acids help stabilize the triple helix – Hyp even more so than Pro; a lower concentration of them is required in animals such as fish, whose body temperatures are lower than most warm-blooded animals. Lower proline and hydroxyproline contents are characteristic of cold-water, but not warm-water fish; the latter tend to have similar proline and hydroxyproline contents to mammals. The lower proline and hydroxyproline contents of cold-water fish and other poikilotherm animals leads to their collagen having a lower thermal stability than mammalian collagen. This lower thermal stability means that gelatin derived from fish collagen is not suitable for many food and industrial applications.

The tropocollagen subunits spontaneously self-assemble, with regularly staggered ends, into even larger arrays in the extracellular spaces of tissues. Additional assembly of fibrils is guided by fibroblasts, which deposit fully formed fibrils from fibripositors. In the fibrillar collagens, molecules are staggered to adjacent molecules by about 67 nm (a unit that is referred to as 'D' and changes depending upon the hydration state of the aggregate). In each D-period repeat of the microfibril, there is a part containing five molecules in cross-section, called the "overlap", and a part containing only four molecules, called the "gap". These overlap and gap regions are retained as microfibrils assemble into fibrils, and are thus viewable using electron microscopy. The triple helical tropocollagens in the microfibrils are arranged in a quasihexagonal packing pattern.

There is some covalent crosslinking within the triple helices and a variable amount of covalent crosslinking between tropocollagen helices forming well-organized aggregates (such as fibrils). Larger fibrillar bundles are formed with the aid of several different classes of proteins (including different collagen types), glycoproteins, and proteoglycans to form the different types of mature tissues from alternate combinations of the same key players. Collagen's insolubility was a barrier to the study of monomeric collagen until it was found that tropocollagen from young animals can be extracted because it is not yet fully crosslinked. However, advances in microscopy techniques (i.e. electron microscopy (EM) and atomic force microscopy (AFM)) and X-ray diffraction have enabled researchers to obtain increasingly detailed images of collagen structure "in situ". These later advances are particularly important to better understanding the way in which collagen structure affects cell–cell and cell–matrix communication and how tissues are constructed in growth and repair and changed in development and disease. For example, using AFM–based nanoindentation it has been shown that a single collagen fibril is a heterogeneous material along its axial direction with significantly different mechanical properties in its gap and overlap regions, correlating with its different molecular organizations in these two regions.

Collagen fibrils/aggregates are arranged in different combinations and concentrations in various tissues to provide varying tissue properties. In bone, entire collagen triple helices lie in a parallel, staggered array. 40 nm gaps between the ends of the tropocollagen subunits (approximately equal to the gap region) probably serve as nucleation sites for the deposition of long, hard, fine crystals of the mineral component, which is hydroxylapatite (approximately) Ca(OH)(PO). Type I collagen gives bone its tensile strength.

Collagen-related diseases most commonly arise from genetic defects or nutritional deficiencies that affect the biosynthesis, assembly, posttranslational modification, secretion, or other processes involved in normal collagen production.

In addition to the above-mentioned disorders, excessive deposition of collagen occurs in scleroderma.

One thousand mutations have been identified in 12 out of more than 20 types of collagen. These mutations can lead to various diseases at the tissue level.

Osteogenesis imperfecta – Caused by a mutation in "type 1 collagen", dominant autosomal disorder, results in weak bones and irregular connective tissue, some cases can be mild while others can be lethal. Mild cases have lowered levels of collagen type 1 while severe cases have structural defects in collagen.

Chondrodysplasias – Skeletal disorder believed to be caused by a mutation in "type 2 collagen", further research is being conducted to confirm this.

Ehlers–Danlos syndrome – Thirteen different types of this disorder, which lead to deformities in connective tissue, are known. Some of the rarer types can be lethal, leading to the rupture of arteries. Each syndrome is caused by a different mutation. For example, the vascular type (vEDS) of this disorder is caused by a mutation in "collagen type 3".

Alport syndrome – Can be passed on genetically, usually as X-linked dominant, but also as both an autosomal dominant and autosomal recessive disorder, those with the condition have problems with their kidneys and eyes, loss of hearing can also develop during the childhood or adolescent years.

Knobloch syndrome – Caused by a mutation in the COL18A1 gene that codes for the production of collagen XVIII. Patients present with protrusion of the brain tissue and degeneration of the retina; an individual who has family members with the disorder is at an increased risk of developing it themselves since there is a hereditary link.

Collagen is one of the long, fibrous structural proteins whose functions are quite different from those of globular proteins, such as enzymes. Tough bundles of collagen called "collagen fibers" are a major component of the extracellular matrix that supports most tissues and gives cells structure from the outside, but collagen is also found inside certain cells. Collagen has great tensile strength, and is the main component of fascia, cartilage, ligaments, tendons, bone and skin. Along with elastin and soft keratin, it is responsible for skin strength and elasticity, and its degradation leads to wrinkles that accompany aging. It strengthens blood vessels and plays a role in tissue development. It is present in the cornea and lens of the eye in crystalline form. It may be one of the most abundant proteins in the fossil record, given that it appears to fossilize frequently, even in bones from the Mesozoic and Paleozoic.

Collagen has a wide variety of applications, from food to medical. In the medical industry, it is used in cosmetic surgery and burn surgery. In the food sector, one use example is in casings for sausages.

If collagen is subject to sufficient denaturation, such as by heating, the three tropocollagen strands separate partially or completely into globular domains, containing a different secondary structure to the normal collagen polyproline II (PPII) of random coils. This process describes the formation of gelatin, which is used in many foods, including flavored gelatin desserts. Besides food, gelatin has been used in pharmaceutical, cosmetic, and photography industries. It is also used as a dietary supplement, and has been advertised as a potential remedy against the ageing process.

From the Greek for glue, "kolla", the word collagen means "glue producer" and refers to the early process of boiling the skin and sinews of horses and other animals to obtain glue. Collagen adhesive was used by Egyptians about 4,000 years ago, and Native Americans used it in bows about 1,500 years ago. The oldest glue in the world, carbon-dated as more than 8,000 years old, was found to be collagen – used as a protective lining on rope baskets and embroidered fabrics, to hold utensils together, and in crisscross decorations on human skulls. Collagen normally converts to gelatin, but survived due to dry conditions. Animal glues are thermoplastic, softening again upon reheating, so they are still used in making musical instruments such as fine violins and guitars, which may have to be reopened for repairs – an application incompatible with tough, synthetic plastic adhesives, which are permanent. Animal sinews and skins, including leather, have been used to make useful articles for millennia.

Gelatin-resorcinol-formaldehyde glue (and with formaldehyde replaced by less-toxic pentanedial and ethanedial) has been used to repair experimental incisions in rabbit lungs.

Bovine collagen is widely used in dermal fillers for aesthetic correction of wrinkles and skin aging. Collagen cremes are also widely sold even though collagen cannot penetrate the skin because its fibers are too large. Most research on collagen supplements has been funded by industries that could benefit from a positive study result.

The molecular and packing structures of collagen eluded scientists over decades of research. The first evidence that it possesses a regular structure at the molecular level was presented in the mid-1930s. Research then concentrated on the conformation of the collagen monomer, producing several competing models, although correctly dealing with the conformation of each individual peptide chain. The triple-helical "Madras" model, proposed by G. N. Ramachandran in 1955, provided an accurate model of quaternary structure in collagen. This model was supported by further studies of higher resolution in the late 20th century.

The packing structure of collagen has not been defined to the same degree outside of the fibrillar collagen types, although it has been long known to be hexagonal. As with its monomeric structure, several conflicting models propose either that the packing arrangement of collagen molecules is 'sheet-like', or is microfibrillar. The microfibrillar structure of collagen fibrils in tendon, cornea and cartilage was imaged directly by electron microscopy in the late 20th century and early 21st century. The microfibrillar structure of rat tail tendon was modeled as being closest to the observed structure, although it oversimplified the topological progression of neighboring collagen molecules, and so did not predict the correct conformation of the discontinuous D-periodic pentameric arrangement termed "microfibril".

Calvin and Hobbes

Calvin and Hobbes is a daily American comic strip created by cartoonist Bill Watterson that was syndicated from November 18, 1985, to December 31, 1995. Commonly described as "the last great newspaper comic", "Calvin and Hobbes" has enjoyed broad and enduring popularity, influence, and academic and philosophical interest.

"Calvin and Hobbes" follows the humorous antics of the title characters: Calvin, a precocious, mischievous, and adventurous six-year-old boy; and his friend Hobbes, a sardonic tiger. Set in the suburban United States of the 1980s and 1990s, the strip depicts Calvin's frequent flights of fancy and friendship with Hobbes. It also examines Calvin's relationships with his long-suffering parents and with his classmates, especially his neighbor Susie Derkins. Hobbes's dual nature is a defining motif for the strip: to Calvin, Hobbes is a living anthropomorphic tiger, while all the other characters seem to see Hobbes as an inanimate stuffed toy, though Watterson has not clarified exactly how Hobbes is perceived by others, or whether he is real or an imaginary friend. Though the series does not frequently mention specific political figures or ongoing events, it does explore broad issues like environmentalism, public education, and philosophical quandaries.

At the height of its popularity, "Calvin and Hobbes" was featured in over 2,400 newspapers worldwide. In 2010, reruns of the strip appeared in more than 50 countries, and nearly 45 million copies of the "Calvin and Hobbes" books had been sold worldwide.

"Calvin and Hobbes" was conceived when Bill Watterson, while working in an advertising job he detested, began devoting his spare time to developing a newspaper comic for potential syndication. He explored various strip ideas but all were rejected by the syndicates. United Feature Syndicate finally responded positively to one strip called "The Doghouse", which featured a side character (the main character's little brother) who had a stuffed tiger. United identified these characters as the strongest and encouraged Watterson to develop them as the center of their own strip. Though United Feature ultimately rejected the new strip as lacking in marketing potential, Universal Press Syndicate took it up.

The first "Calvin and Hobbes" strip was published on November 18, 1985 in 35 newspapers. The strip quickly became popular. Within a year of syndication, the strip was published in roughly 250 newspapers and proved to have international appeal with translation and wide circulation outside the United States.

Although "Calvin and Hobbes" underwent continual artistic development and creative innovation over the period of syndication, the earliest strips demonstrated a remarkable consistency with the latest. Watterson introduced all the major characters within the first three weeks and made no changes to the central cast over the strip's 10-year history. 

By April 5, 1987, Watterson was featured in an article in the "Los Angeles Times". "Calvin and Hobbes" earned Watterson the Reuben Award from the National Cartoonists Society in the Outstanding Cartoonist of the Year category, first in 1986 and again in 1988. He was nominated another time in 1992. The Society awarded him the Humor Comic Strip Award for 1988. "Calvin and Hobbes" has also won several more awards.

As his creation grew in popularity, there was strong interest from the syndicate to merchandise the characters and expand into other forms of media. Watterson's contract with the syndicate allowed the characters to be licensed without the creator's consent, as was standard at the time. Nevertheless, Watterson had leverage by threatening to simply walk away from the comic strip.

This dynamic played out in a long and emotionally draining battle between Watterson and his syndicate editors. By 1991, Watterson had achieved his goal of securing a new contract that granted him legal control over his creation and all future licensing arrangements.

Having achieved his objective of creative control, Watterson's desire for privacy subsequently reasserted itself and he ceased all media interviews, relocated to New Mexico, and largely disappeared from public engagements, refusing to attend the ceremonies of any of the cartooning awards he won. The pressures of the battle over merchandising led to Watterson taking an extended break from May 5, 1991, to February 1, 1992, a move that was virtually unprecedented in the world of syndicated cartoonists.
During Watterson's first sabbatical from the strip, Universal Press Syndicate continued to charge newspapers full price to re-run old "Calvin and Hobbes" strips. Few editors approved of the move, but the strip was so popular that they had no choice but to continue to run it for fear that competing newspapers might pick it up and draw its fans away. Watterson returned to the strip in 1992 with plans to produce his Sunday strip as an unbreakable half of a newspaper or tabloid page. This made him only the second cartoonist since Garry Trudeau to have sufficient popularity to demand more space and control over the presentation of his work.

Watterson took a second sabbatical from April 3 through December 31, 1994. His return came with an announcement that "Calvin and Hobbes" would be concluding at the end of 1995. Stating his belief that he had achieved everything that he wanted to within the medium, he announced his intention to work on future projects at a slower pace with fewer artistic compromises.

The final strip ran on Sunday, December 31, 1995, depicting Calvin and Hobbes sledding down a snowy hill after a fresh snowfall with Calvin exclaiming "Let's go exploring!"

Speaking to NPR in 2005, animation critic Charles Solomon opined that the final strip "left behind a hole in the comics page that no strip has been able to fill."

Syndicated comics were typically published six times a week in black and white, with a Sunday supplement version in a larger, full color format. This larger format version of the strip was constrained by mandatory layout requirements that made it possible for newspaper editors to format the strip for different page sizes and layouts.

Watterson grew increasingly frustrated by the shrinking of the available space for comics in the newspapers and the mandatory panel divisions that restricted his ability to produce better artwork and more creative storytelling. He lamented that without space for anything more than simple dialogue or sparse artwork, comics as an art form were becoming dilute, bland, and unoriginal.

Watterson longed for the artistic freedom allotted to classic strips such as "Little Nemo" and "Krazy Kat", and in 1989 he gave a sample of what could be accomplished with such liberty in the opening pages of the Sunday strip compilation, "The Calvin and Hobbes Lazy Sunday Book—"an 8-page previously unpublished Calvin story fully illustrated in watercolor. The same book contained an afterword from the artist himself, reflecting on a time when comic strips were allocated a whole page of the newspaper and every comic was like a "color poster".

Within two years, Watterson was ultimately successful in negotiating a deal that provided him more space and creative freedom. Following his 1991 sabbatical, Universal Press announced that Watterson had decided to sell his Sunday strip as an unbreakable half of a newspaper or tabloid page. Many editors and even a few cartoonists including Bil Keane ("The Family Circus") and Bruce Beattie ("Snafu") criticized him for what they perceived as arrogance and an unwillingness to abide by the normal practices of the cartoon business. Others, including Bill Amend ("Foxtrot"), Johnny Hart ("BC", "Wizard of Id") and Barbara Brandon ("Where I'm Coming From") supported him. The American Association of Sunday and Feature Editors even formally requested that Universal reconsider the changes. Watterson's own comments on the matter was that "editors will have to judge for themselves whether or not Calvin and Hobbes deserves the extra space. If they don't think the strip carries its own weight, they don't have to run it." Ultimately only 15 newspapers cancelled the strip in response to the layout changes.

Bill Watterson took two sabbaticals from the daily requirements of producing the strip. The first took place from May 5, 1991, to February 1, 1992, and the second from April 3 through December 31, 1994. These sabbaticals were included in the new contract Watterson managed to negotiate with Universal Features in 1990. The sabbaticals were proposed by the syndicate themselves, who, fearing Watterson's complete burnout, endeavored to get another five years of work from their star artist.

Watterson remains only the third cartoonist with sufficient popularity and stature to receive a sabbatical from their syndicate, the first two being Garry Trudeau ("Doonesbury") in 1983 and Gary Larson ("The Far Side") in 1989. Typically, cartoonists are expected to produce sufficient strips to cover any period that they may wish to take off. Watterson's lengthy sabbaticals received some mild criticism from his fellow cartoonists including Greg Evans ("Luann"); and Charles Schulz ("Peanuts"), one of Watterson's major artistic influences, even called it a "puzzle". Some cartoonists resented the idea that Watterson worked harder than others, while others supported it. At least one newspaper editor noted that the strip was the most popular in the country and stated that he "earned it".

Despite the popularity of "Calvin and Hobbes", the strip remains notable for the almost complete lack of official product merchandising. Watterson held that comic strips should stand on their own as an art form and although he did not start out completely opposed to merchandising in all forms (or even for all comic strips), he did reject an early syndication deal that involved incorporating a more marketable, licensed character into his strip. In spite of being an unproven cartoonist, and having been flown all the way to New York to discuss the proposal, Watterson reflexively resented the idea of "cartooning by committee" and turned it down.

When "Calvin and Hobbes" was accepted by Universal Syndicate, and began to grow in popularity, Watterson found himself at odds with the syndicate, which urged him to begin merchandising the characters and touring the country to promote the first collections of comic strips. Watterson refused, believing that the integrity of the strip and its artist would be undermined by commercialization, which he saw as a major negative influence in the world of cartoon art, and that licensing his character would only violate the spirit of his work. He gave an example of this in discussing his opposition to a Hobbes plush toy: that if the essence of Hobbes' nature in the strip is that it remain unresolved whether he is a real tiger or a stuffed toy, then creating a real stuffed toy would only destroy the magic. However, having initially signed away control over merchandising in his initial contract with the syndicate, Watterson commenced a lengthy and emotionally draining battle with Universal to gain control over his work. Ultimately Universal did not approve any products against Watterson's wishes, understanding that, unlike other comic strips, it would be nearly impossible to separate the creator from the strip if Watterson chose to walk away.

One estimate places the value of licensing revenue forgone by Watterson at $300–$400 million. Almost no legitimate "Calvin and Hobbes" merchandise exists. Exceptions produced during the strip's original run include two 16-month calendars (1988–89 and 1989–90), a t-shirt for the Smithsonian Exhibit, "Great American Comics: 100 Years of Cartoon Art" (1990) and the textbook "Teaching with Calvin and Hobbes", which has been described as "perhaps the most difficult piece of official "Calvin and Hobbes" memorabilia to find." In 2010, Watterson did allow his characters to be included in a series of United States Postal Service stamps honoring five classic American comics. Licensed prints of "Calvin and Hobbes" were made available and have also been included in various academic works.

The strip's immense popularity has led to the appearance of various counterfeit items such as window decals and T-shirts that often feature crude humor, binge drinking and other themes that are not found in Watterson's work. Images from one strip in which Calvin and Hobbes dance to loud music at night were commonly used for copyright violations. After threat of a lawsuit alleging infringement of copyright and trademark, some sticker makers replaced Calvin with a different boy, while other makers made no changes. Watterson wryly commented, "I clearly miscalculated how popular it would be to show Calvin urinating on a Ford logo," but later added, "long after the strip is forgotten, [they] are my ticket to immortality".

Watterson has expressed admiration for animation as an artform. In a 1989 interview in "The Comics Journal" he described the appeal of being able to do things with a moving image that cannot be done by a simple drawing: the distortion, the exaggeration and the control over the length of time an event is viewed. However, although the visual possibilities of animation appealed to Watterson, the idea of finding a voice for Calvin made him uncomfortable, as did the idea of working with a team of animators. Ultimately, "Calvin and Hobbes" was never made into an animated series. Watterson later stated in "The Calvin and Hobbes Tenth Anniversary Book" that he liked the fact that his strip was a "low-tech, one-man operation," and that he took great pride in the fact that he drew every line and wrote every word on his own. Calls from major Hollywood figures interested in an adaptation of his work, including Jim Henson, George Lucas and Steven Spielberg, were never returned and in a 2013 interview Watterson stated that he had "zero interest" in an animated adaptation as there was really no upside for him in doing so.

The strip borrows several elements and themes from three major influences: Walt Kelly's "Pogo", George Herriman's "Krazy Kat" and Charles M. Schulz's "Peanuts". Schulz and Kelly particularly influenced Watterson's outlook on comics during his formative years.

Notable elements of Watterson's artistic style are his characters' diverse and often exaggerated expressions (particularly those of Calvin), elaborate and bizarre backgrounds for Calvin's flights of imagination, expressions of motion and frequent visual jokes and metaphors. In the later years of the strip, with more panel space available for his use, Watterson experimented more freely with different panel layouts, art styles, stories without dialogue and greater use of white space. He also experimented with his tools, once inking a strip with a stick from his yard in order to achieve a particular look. He also makes a point of not showing certain things explicitly: the "Noodle Incident" and the children's book "Hamster Huey and the Gooey Kablooie" are left to the reader's imagination, where Watterson was sure they would be "more outrageous" than he could portray.

Watterson's technique started with minimalist pencil sketches drawn with a light pencil (though the larger Sunday strips often required more elaborate work) on a piece of Bristol board, with his brand of choice being Strathmore because he felt it held the drawings better on the page as opposed to the cheaper brands (Watterson said he initially used any cheap pad of Bristol board his local supply store had but switched to Strathmore after he found himself growing more and more displeased with the results). He would then use a small sable brush and India ink to fill in the rest of the drawing, saying that he did not want to simply trace over his penciling and thus make the inking more spontaneous. He lettered dialogue with a Rapidograph fountain pen, and he used a crowquill pen for odds and ends. Mistakes were covered with various forms of correction fluid, including the type used on typewriters. Watterson was careful in his use of color, often spending a great deal of time in choosing the right colors to employ for the weekly Sunday strip; his technique was to cut the color tabs the syndicate sent him into individual squares, lay out the colors, and then paint a watercolor approximation of the strip on tracing paper over the Bristol board and then mark the strip accordingly before sending it on. When "Calvin and Hobbes" began there were 64 colors available for the Sunday strips. For the later Sunday strips Watterson had 125 colors as well as the ability to fade the colors into each other.

Calvin, named after the 16th-century theologian John Calvin, is a six-year-old boy with spiky blond hair and a distinctive red-and-black striped shirt, black pants and sneakers. Despite his poor grades in school, Calvin demonstrates his intelligence through a sophisticated vocabulary, philosophical mind and creative/artistic talent. Watterson described Calvin as having "not much of a filter between his brain and his mouth", a "little too intelligent for his age", lacking in restraint and not yet having the experience to "know the things that you shouldn't do." The comic strip largely revolves around Calvin's inner world and his largely antagonistic experiences with those outside of it (fellow students, authority figures and his parents).

From Calvin's point of view, Hobbes is an anthropomorphic tiger much larger than Calvin and full of independent attitudes and ideas. When a scene includes any other human, Hobbes appears as a stuffed animal, usually seated at an off-kilter angle with a blank facial expression. The true nature of the character is never resolved, instead as Watterson describes, a 'grown-up' version of reality is juxtaposed against Calvin's, with the reader left to "decide which is truer". Hobbes is based on a cat Watterson owned, a grey tabby named Sprite. Sprite inspired the length of Hobbes' body as well as his personality. Although Hobbes' humor stems from acting like a human, Watterson maintained Sprite's feline attitude.

Hobbes is named after 17th-century philosopher Thomas Hobbes, who held what Watterson describes as "a dim view of human nature." He typically exhibits a greater understanding of consequences than Calvin, but rarely intervenes in Calvin's activities beyond a few oblique warnings. He often likes to sneak up and pounce on Calvin, especially at the front door when Calvin is returning home from school. The friendship between the two characters provides the core dynamic of the strip.

Calvin's mother and father are typical middle-class parents who are relatively down to earth and whose sensible attitudes serve as a foil for Calvin's outlandish behavior. Calvin's father is a patent attorney (like Watterson's own father), while his mother is a stay-at-home mom. Both parents are unnamed throughout the entire strip, as Watterson insists, "As far as the strip is concerned, they are important only as Calvin's mom and dad."

Watterson recounts that some fans are angered by the sometimes sardonic way that Calvin's parents respond to him. In response, Watterson defends what Calvin's parents do, remarking that in the case of parenting a kid like Calvin, "I think they do a better job than I would." Calvin's father is overly concerned with "character building" activities in a number of strips, either in the things he makes Calvin do or in the austere eccentricities of his own lifestyle.

Susie Derkins, who first appears early in the strip and is the only important character with both a first and last name, lives on Calvin's street and is one of his classmates. Her last name apparently derives from the pet beagle owned by Watterson's wife's family.

Susie is studious and polite (though she can be aggressive if sufficiently provoked), and she likes to play house or host tea parties with her stuffed animals. She also plays imaginary games with Calvin in which she acts as a high-powered lawyer or politician and wants Calvin to pretend to be her househusband. Though both of them are typically loath to admit it, Calvin and Susie exhibit many common traits and inclinations. For example, the reader occasionally sees Susie with a stuffed rabbit named "Mr. Bun." Much like Calvin, Susie has a mischievous (and sometimes aggressive) streak as well, which the reader witnesses whenever she subverts Calvin's attempts to cheat on school tests by feeding him incorrect answers, or whenever she fights back after Calvin attacks her with snowballs or water balloons.

Hobbes often openly expresses romantic feelings for Susie, to Calvin's disgust. In contrast, Calvin started a club (of which he and Hobbes are the only members) that he calls G.R.O.S.S. (Get Rid Of Slimy GirlS) and, while holding "meetings" in Calvin's tree house or in the "box of secrecy" in Calvin's room, they usually come up with some plot against Susie. In one instance, Calvin steals one of Susie's dolls and holds it for ransom, only to have Susie retaliate by nabbing Hobbes. Watterson admits that Calvin and Susie have a nascent crush on each other and that Susie is a reference to the type of woman whom Watterson himself found attractive and eventually married.

Susie features as a main character in two of the five storylines that appear in "Teaching with Calvin and Hobbes".

 Calvin also interacts with a handful of secondary characters. Several of these, including Rosalyn, his babysitter; Miss Wormwood, his teacher; and Moe, the school bully, recur regularly through the duration of the strip.

Watterson used the strip to poke fun at the art world, principally through Calvin's unconventional creations of snowmen but also through other expressions of childhood art. When Miss Wormwood complains that he is wasting class time drawing impossible things (a "Stegosaurus" in a rocket ship, for example), Calvin proclaims himself "on the cutting edge of the "avant-garde"." He begins exploring the medium of snow when a warm day melts his snowman. His next sculpture "speaks to the horror of our own mortality, inviting the viewer to contemplate the evanescence of life." In later strips, Calvin's creative instincts diversify to include sidewalk drawings (or, as he terms them, examples of "suburban postmodernism").

Watterson also lampooned the academic world. In one example, Calvin carefully crafts an "artist's statement", claiming that such essays convey more messages than artworks themselves ever do (Hobbes blandly notes, "You misspelled "Weltanschauung""). He indulges in what Watterson calls "pop psychobabble" to justify his destructive rampages and shift blame to his parents, citing "toxic codependency." In one instance, he pens a book report based on the theory that the purpose of academic writing is to "inflate weak ideas, obscure poor reasoning and inhibit clarity," entitled "The Dynamics of Interbeing and Monological Imperatives in Dick and Jane: A Study in Psychic Transrelational Gender Modes". Displaying his creation to Hobbes, he remarks, "Academia, here I come!" Watterson explains that he adapted this jargon (and similar examples from several other strips) from an actual book of art criticism.

Overall, Watterson's satirical essays serve to attack both sides, criticizing both the commercial mainstream and the artists who are supposed to be "outside" it. The strip on Sunday, June 21, 1992, criticized the naming of The Big Bang theory as not evocative of the wonders behind it and coined the term "Horrendous Space Kablooie", an alternative that achieved some informal popularity among scientists and was often shortened to "the HSK." The term has also been referred to in newspapers, books and university courses.

Calvin imagines himself as many great creatures and other people, including dinosaurs, elephants, jungle-farers and superheroes. Three of his alter egos are well-defined and recurrent:


Calvin also has several adventures involving corrugated cardboard boxes, which he adapts for many imaginative and elaborate uses. In one strip, when Calvin shows off his Transmogrifier, a device that transforms its user into any desired creature or item, Hobbes remarks, "It's amazing what they do with corrugated cardboard these days." Calvin is able to change the function of the boxes by rewriting the label and flipping the box onto another side. In this way, a box can be used not only for its conventional purposes (a storage container for water balloons, for example), but also as a flying time machine, a duplicator, a transmogrifier or, with the attachment of a few wires and a colander, a "Cerebral Enhance-o-tron."

In the real world, Calvin's antics with his box have had varying effects. When he transmogrified into a tiger, he still appeared as a regular human child to his parents. However, in a story where he made several duplicates of himself, his parents are seen interacting with what does seem like multiple Calvins, including in a strip where two of him are seen in the same panel as his father. It is ultimately unknown what his parents do or do not see, as Calvin tries to hide most of his creations (or conceal their effects) so as not to traumatize them.

In addition, Calvin uses a cardboard box as a sidewalk kiosk to sell things. Often, Calvin offers merchandise no one would want, such as "suicide drink", "a swift kick in the butt" for one dollar or a "frank appraisal of your looks" for fifty cents. In one strip, he sells "happiness" for ten cents, hitting the customer in the face with a water balloon and explaining that he meant his own happiness. In another strip, he sold "insurance", firing a slingshot at those who refused to buy it. In some strips, he tried to sell "great ideas" and, in one earlier strip, he attempted to sell the family car to obtain money for a grenade launcher. In yet another strip, he sells "life" for five cents, where the customer receives nothing in return, which, in Calvin's opinion, is life.

The box has also functioned as an alternate secret meeting place for G.R.O.S.S., as the "Box of Secrecy".

Calvinball is an improvisational sport/game introduced in a 1990 storyline that involved Calvin's negative experience of joining the school baseball team. Calvinball is a nomic or self-modifying game, a contest of wits, skill and creativity rather than stamina or athletic skill. The game is portrayed as a rebellion against conventional team sports and became a staple of the final five years of the comic. The only consistent rules of the game are that Calvinball may never be played with the same rules twice and that each participant must wear a mask.

When asked how to play, Watterson stated: "It's pretty simple: you make up the rules as you go." In most appearances of the game, a comical array of conventional and non-conventional sporting equipment is involved, including a croquet set, a badminton set, assorted flags, bags, signs, a hobby horse, water buckets and balloons, with humorous allusions to unseen elements such as "time-fracture wickets". Scoring is portrayed as arbitrary and nonsensical ("Q to 12" and "oogy to boogy") and the lack of fixed rules leads to lengthy argument between the participants as to who scored, where the boundaries are, and when the game is finished. Usually, the contest results in Calvin being outsmarted by Hobbes. The game has been described in one academic work not as a new game based on fragments of an older one, but as the "constant connecting and disconnecting of parts, the constant evasion of rules or guidelines based on collective creativity."

Calvin often creates horrendous/dark humor scenes with his snowmen and other snow sculptures. He uses the snowman for social commentary, revenge or pure enjoyment. Examples include Snowman Calvin being yelled at by Snowman Dad to shovel the snow; one snowman eating snow cones scooped out of a second snowman, who is lying on the ground with an ice-cream scoop in his back; a "snowman house of horror"; and snowmen representing people he hates. "The ones I "really" hate are small, so they'll melt faster," he says. There was even an occasion on which Calvin accidentally brought a snowman to life and it made itself and a small army into "deranged mutant killer monster snow goons."

Calvin's snow art is often used as a commentary on art in general. For example, Calvin has complained more than once about the lack of originality in other people's snow art and compared it with his own grotesque snow sculptures. In one of these instances, Calvin and Hobbes claim to be the sole guardians of high culture; in another, Hobbes admires Calvin's willingness to put artistic integrity above marketability, causing Calvin to reconsider and make an ordinary snowman.

Calvin and Hobbes frequently ride downhill in a wagon or sled (depending on the season), as a device to add some physical comedy to the strip and because, according to Watterson, "it's a lot more interesting ... than talking heads." While the ride is sometimes the focus of the strip, it also frequently serves as a counterpoint or visual metaphor while Calvin ponders the meaning of life, death, God, philosophy or a variety of other weighty subjects. Many of their rides end in spectacular crashes which leave them battered, beaten up and broken, a fact which convinces Hobbes to sometimes hop off before a ride even begins. In the final strip, Calvin and Hobbes depart on their sled to go exploring. This theme is similar (perhaps even an homage) to scenes in Walt Kelly's "Pogo". Calvin and Hobbes' sled has been described as the most famous sled in American arts since "Citizen Kane".

G.R.O.S.S. (which is a backronym for Get Rid Of Slimy GirlS, "otherwise it doesn't spell anything") is a club in which Calvin and Hobbes are the only members. The club was founded in the garage of their house, but to clear space for its activities, Calvin and (purportedly) Hobbes push Calvin's parents' car, causing it to roll into a ditch (but not suffer damage); the incident prompts the duo to change the club's location to Calvin's treehouse. They hold meetings that involve finding ways to annoy and discomfort Susie Derkins, a girl and enemy of their club. Notable actions include planting a fake secret tape near her in attempt to draw her in to a trap, trapping her in a closet at their house and creating elaborate water balloon traps. Calvin gave himself and Hobbes important positions in the club, Calvin being "Dictator-for-Life" and Hobbes being "President-and-First-Tiger". They go into Calvin's treehouse for their club meetings and often get into fights during them. The password to get into the treehouse is intentionally long and difficult, which has on at least one occasion ruined Calvin's plans. As Hobbes is able to climb the tree without the rope, he is usually the one who comes up with the password, which often involves heaping praise upon tigers. An example of this can be seen in the comic strip where Calvin, rushing to get into the treehouse to throw things at a passing Susie Derkins, insults Hobbes, who is in the treehouse and thus has to let down the rope. Hobbes forces Calvin to say the password for insulting him. By the time Susie arrives, in time to hear Calvin saying some of the password, causing him to stumble, Calvin is on ""Verse Seven:" Tigers are perfect!/The E-pit-o-me/of good looks and grace/and quiet..uh..um..dignity". The opportunity to pelt Susie with something having passed, Calvin threatens to turn Hobbes into a rug.

There are 18 "Calvin and Hobbes" books, published from 1987 to 1997. These include 11 collections, which form a complete archive of the newspaper strips, except for a single daily strip from November 28, 1985. (The collections "do" contain a strip for this date, but it is not the same strip that appeared in some newspapers.) Treasuries usually combine the two preceding collections with bonus material and include color reprints of Sunday comics.

Watterson included some new material in the treasuries. In "The Essential Calvin and Hobbes", which includes cartoons from the collections "Calvin and Hobbes" and "Something Under the Bed Is Drooling", the back cover features a scene of a giant Calvin rampaging through a town. The scene is based on Watterson's home town of Chagrin Falls, Ohio, and Calvin is holding the Chagrin Falls Popcorn Shop, an iconic candy and ice cream shop overlooking the town's namesake falls. Several of the treasuries incorporate additional poetry; "The Indispensable Calvin and Hobbes" book features a set of poems, ranging from just a few lines to an entire page, that cover topics such as Calvin's mother's "hindsight" and exploring the woods. In "The Essential Calvin and Hobbes", Watterson presents a long poem explaining a night's battle against a monster from Calvin's perspective. "The Authoritative Calvin and Hobbes" includes a story based on Calvin's use of the Transmogrifier to finish his reading homework.

A complete collection of "Calvin and Hobbes" strips, in three hardcover volumes totaling 1440 pages, was released on October 4, 2005, by Andrews McMeel Publishing. It includes color prints of the art used on paperback covers, the treasuries' extra illustrated stories and poems and a new introduction by Bill Watterson in which he talks about his inspirations and his story leading up to the publication of the strip. The alternate 1985 strip is still omitted, and three other strips (January 7 and November 24, 1987, and November 25, 1988) have altered dialogue. A four-volume paperback version was released November 13, 2012.

To celebrate the release (which coincided with the strip's 20th anniversary and the tenth anniversary of its absence from newspapers), Bill Watterson answered 15 questions submitted by readers.

Early books were printed in smaller format in black and white. These were later reproduced in twos in color in the "Treasuries" ("Essential", "Authoritative" and "Indispensable"), except for the contents of "Attack of the Deranged Mutant Killer Monster Snow Goons". Those Sunday strips were not reprinted in color until the "Complete" collection was finally published in 2005.

Watterson claims he named the books the ""Essential", "Authoritative" and "Indispensable"" because, as he says in "The Calvin and Hobbes Tenth Anniversary Book", the books are "obviously none of these things."

An officially licensed children's textbook entitled "Teaching with Calvin and Hobbes" was published in a single print run in Fargo, North Dakota, in 1993. The book is composed of "Calvin and Hobbes" strips that form story arcs, including "The Binoculars" and "The Bug Collection", followed by lessons based on the stories.

The book is rare and highly sought. It has been called the "Holy Grail" for "Calvin and Hobbes" collectors.

Reviewing "Calvin and Hobbes" in 1990, "Entertainment Weekly" Ken Tucker gave the strip an A+ rating, writing "Watterson summons up the pain and confusion of childhood as much as he does its innocence and fun."

In 1993, paleontologist and paleoartist Gregory S. Paul praised Bill Watterson for the scientific accuracy of the dinosaurs appearing in "Calvin and Hobbes".

In her 1994 book "When Toys Come Alive", Lois Rostow Kuznets theorizes that Hobbes serves both as a figure of Calvin's childish fantasy life and as an outlet for the expression of libidinous desires more associated with adults. Kuznets also analyzes Calvin's other fantasies, suggesting that they are a second tier of fantasies utilized in places like school where transitional objects such as Hobbes would not be socially acceptable.

Political scientist James Q. Wilson, in a paean to "Calvin and Hobbes" upon Watterson's decision to end the strip in 1995, characterized it as "our only popular explication of the moral philosophy of Aristotle."

Alisa White Coleman analyzed the strip's underlying messages concerning ethics and values in "'Calvin and Hobbes': A Critique of Society's Values," published in the "Journal of Mass Media Ethics" in 2000.

A collection of original Sunday strips was exhibited at Ohio State University's Billy Ireland Cartoon Library & Museum in 2001. Watterson himself selected the strips and provided his own commentary for the exhibition catalog, which was later published by Andrews McMeel as "Calvin and Hobbes: Sunday Pages 1985–1995".

Since the discontinuation of "Calvin and Hobbes", individual strips have been licensed for reprint in schoolbooks, including the Christian homeschooling book "The Fallacy Detective" in 2002, and the university-level philosophy reader "Open Questions: Readings for Critical Thinking and Writing" in 2005; in the latter, the ethical views of Watterson and his characters Calvin and Hobbes are discussed in relation to the views of professional philosophers. 
In a 2009 evaluation of the entire body of "Calvin and Hobbes" strips using grounded theory methodology, Christijan D. Draper found that: "Overall, "Calvin and Hobbes" suggests that meaningful time use is a key attribute of a life well lived," and that "the strip suggests one way to assess the meaning associated with time use is through preemptive retrospection by which a person looks at current experiences through the lens of an anticipated future..."

Jamey Heit's "Imagination and Meaning in Calvin and Hobbes", a critical and academic analysis of the strip, was published in 2012.

"Calvin and Hobbes" strips were again exhibited at the Billy Ireland Cartoon Library & Museum at Ohio State University in 2014, in an exhibition entitled "Exploring Calvin and Hobbes". An exhibition catalog by the same title, which also contained an interview with Watterson conducted by Jenny Robb, the curator of the museum, was published by Andrews McMeel in 2015.

Years after its original newspaper run, "Calvin and Hobbes" has continued to exert influence in entertainment, art, and fandom.

In television, Calvin and Hobbes have been satirically depicted in stop motion animation in the 2006 "Robot Chicken" episode "Lust for Puppets," and in traditional animation in the 2009 "Family Guy" episode "Not All Dogs Go to Heaven." In the 2013 "Community" episode "Paranormal Parentage," the characters Abed Nadir (Danny Pudi) and Troy Barnes (Donald Glover) dress as Calvin and Hobbes, respectively, for Halloween.

British artists, merchandisers, booksellers, and philosophers were interviewed for a 2009 BBC Radio 4 half-hour programme about the abiding popularity of the comic strip, narrated by Phill Jupitus.

The first book-length study of the strip, "Looking for Calvin and Hobbes: The Unconventional Story of Bill Watterson and His Revolutionary Comic Strip" by Nevin Martell, was first published in 2009; an expanded edition was published in 2010. The book chronicles Martell's quest to tell the story of "Calvin and Hobbes" and Watterson through research and interviews with people connected to the cartoonist and his work. The director of the later documentary "Dear Mr. Watterson" referenced "Looking for Calvin and Hobbes" in discussing the production of the movie, and Martell appears in the film.

The American documentary film "Dear Mr. Watterson", released in 2013, explores the impact and legacy of "Calvin and Hobbes" through interviews with authors, curators, historians, and numerous professional cartoonists.

The enduring significance of "Calvin and Hobbes" to international cartooning was recognized by the jury of the Angoulême International Comics Festival in 2014 by the awarding of its Grand Prix to Watterson, only the fourth American to ever receive the honor (after Will Eisner, Robert Crumb, and Art Spiegelman).

From 2016 to 2021, author Berkeley Breathed included "Calvin and Hobbes" in various "Bloom County" cartoons. He launched the first cartoon on April Fool's Day 2016 and jokingly issued a statement suggesting that he had acquired "Calvin and Hobbes" from Bill Watterson, who was "out of the Arizona facility, continent and looking forward to some well-earned financial security." While bearing Watterson's signature and drawing style as well as featuring characters from both "Calvin and Hobbes" and Breathed's "Bloom County", it is unclear whether Watterson had any input into these cartoons or not.

"Calvin and Hobbes" remains the most viewed comic on GoComics, which cycles through old strips with an approximately 30-year delay.

Portraying Calvin as a teenager/adult has inspired writers.

In 2011, a comic strip appeared by cartoonists Dan and Tom Heyerman called "Hobbes and Bacon". The strip depicts Calvin as an adult, married to Susie Derkins with a young daughter named after philosopher Francis Bacon, to whom Calvin gives Hobbes. Though consisting of only four strips originally, "Hobbes and Bacon" received considerable attention when it appeared and was continued by other cartoonists and artists.

A novel titled "Calvin" by CLA Young Adult Book Award–winning author Martine Leavitt was published in 2015. The story tells of seventeen-year-old Calvin—who was born on the day that "Calvin and Hobbes" ended, and who has now been diagnosed with schizophrenia—and his hallucination of Hobbes, his childhood stuffed tiger. With his friend Susie, who might also be a hallucination, Calvin sets off to find Bill Watterson in the hope that the cartoonist can provide aid for Calvin's condition.

The titular character of the comic strip "Frazz" has been noted for his similar appearance and personality to a grown-up Calvin. Creator Jef Mallett has stated that although Watterson is an inspiration to him, the similarities are unintentional.



Campaign for Real Ale

The Campaign for Real Ale (CAMRA) is an independent voluntary consumer organisation headquartered in St Albans, England, which promotes real ale, cider and perry and traditional British pubs and clubs. With just under 150,000 members, it is the largest single-issue consumer group in the UK, and is a founding member of the European Beer Consumers Union (EBCU).

The organisation was founded on 16 March 1971 in Kruger's Bar, Dunquin, County Kerry, Ireland, by Michael Hardman, Graham Lees, Jim Makin, and Bill Mellor, who were opposed to the growing mass production of beer and the homogenisation of the British brewing industry. The original name was the Campaign for the Revitalisation of Ale. Following the formation of the Campaign, the first annual general meeting took place in 1972, at the Rose Inn in Coton Road, Nuneaton. 

Early membership consisted of the four founders and their friends. Interest in CAMRA and its objectives spread rapidly, with 5,000 members signed up by 1973. Other early influential members included Christopher Hutt, author of "Death of the English Pub", who succeeded Hardman as chairman, Frank Baillie, author of "The Beer Drinker's Companion", and later the many times "Good Beer Guide" editor, Roger Protz.

In 1991, CAMRA reached 30,000 members across the UK and abroad and, a year later, helped to launch the European Beer Consumers Union. CAMRA remains EBCU's largest contributor, despite the UK's exit from the European Union.

CAMRA published a history book on its 50th birthday, 16 March 2021, written by Laura Hadland "50 Years of CAMRA".

CAMRA's stated aims are:

CAMRA's campaigns include promoting small brewing and pub businesses, reforming licensing laws, reducing tax on beer, and stopping continued consolidation among local British brewers. It also makes an effort to promote less common varieties of beer, including stout, porter, and mild, as well as traditional cider and perry.

CAMRA's states that real ale should be served without the use of additional carbonation. This means that "any beer brand which is produced in both cask and keg versions" is not admitted to CAMRA festivals if the brewery's marketing is deemed to imply an equivalence of quality or character between the two versions.

CAMRA is organised on a federal basis, over 200 local branches, each covering a particular geographical area of the UK, that contribute to the central body of the organisation based in St Albans. It is governed by a National Executive, made up of 12 voluntary unpaid directors elected by the membership. The local branches are grouped into 16 regions across the UK, such as the West Midlands or Wessex.

In 2009, CAMRA's membership reached 100,000, and 150,000 members in 2013.

CAMRA publishes the "Good Beer Guide", an annually compiled directory of the best 4,500 real ale outlets and listing of real ale brewers.
CAMRA members received a monthly newspaper called "What's Brewing" until its April 2021 issue and there is a quarterly colour magazine called "Beer". It also maintains a National Inventory of Historic Pub Interiors to help bring greater recognition and protection to Britain's most historic pubs.

CAMRA supports and promotes beer and cider festivals around the country, which are organised by local CAMRA branches. Generally, each festival charges an entry fee which either covers entry only or also includes a commemorative glass showing the details of the festival. A festival programme is usually also provided, with a list and description of the drinks available. Members may get discounted entrance to CAMRA festivals.

The Campaign also organises the annual Great British Beer Festival in August. It is now held in the Great, National & West Halls at the Olympia Exhibition Centre, in Kensington, London, having been held for a few years at Earl's Court as well as regionally in the past at venues such as Brighton and Leeds. This is the UK's largest beer festival, with over 900 beers, ciders and perries available over the week long event.

For many years, CAMRA also organised the National Winter Ales Festival. However, in 2017 this was re-branded as the Great British Beer Festival Winter where they award the Champion Winter Beer of Britain. Unlike the Great British Beer Festival, the Winter event does not have a permanent venue and is rotated throughout the country every three years. Recent hosts have been Derby and Norwich, with the event currently held each February in Birmingham. In 2020 CAMRA also launched the Great Welsh Beer Festival, to be held in Cardiff in April.

CAMRA presents awards for beers and pubs, such as the National Pub of the Year. The competition begins in the preceding year with branches choosing their local pub of the year through either a ballot or a panel of judges. The branch winners are entered into 16 regional competitions which are then visited by several individuals who agree the best using a scoring system that looks at beer quality, aesthetic, and welcome. The four finalists are announced each year before a ceremony to crown the winner in the spring. There are also the Pub Design Awards, which are held in association with English Heritage and the Victorian Society. These comprise several categories, including new build, refurbished and converted pubs.

The best known CAMRA award is the Champion Beer of Britain, which is selected at the Great British Beer Festival. Other awards include the Champion Beer of Scotland and the Champion Beer of Wales.

CAMRA developed the National Beer Scoring Scheme (NBSS) as an easy to use scheme for judging beer quality in pubs, to assist CAMRA branches in selecting pubs for the "Good Beer Guide". CAMRA members input their beer scores online via WhatPub or through the Good Beer Guide app.

The CAMRA Pub Heritage Group identifies, records and helps to protect pub interiors of historic and/or architectural importance, and seeks to get them listed.

The group maintains two inventories of Heritage pubs, the National Inventory (NI), which contains only those pubs that have been maintained in their original condition (or have been modified very little) for at least thirty years, but usually since at least World War II. The second, larger, inventory is the Regional Inventory (RI), which is broken down by county and contains both those pubs listed in the NI and other pubs that are not eligible for the NI, for reasons such as having been overly modified, but are still considered historically important, or have particular architectural value.

The LocAle scheme was launched in 2007 to promote locally brewed beers. The scheme functions slightly differently in each area, and is managed by each branch, but each is similar: if the beer is to be promoted as a LocAle it must come from a brewery within a predetermined number of miles set by each CAMRA branch, generally around 20, although the North London branch has set it at 30 miles from brewery to pub, even if it comes from a distribution centre further away; in addition, each participating pub must keep at least one LocAle for sale at all times.

CAMRA members may join the CAMRA Members' Investment Club which, since 1989, has invested in real ale breweries and pub chains. As of January 2021 the club had over 3,000 members and owned investments worth over £17 million. Although all investors must be CAMRA members, the CAMRA Members' Investment Club is not part of CAMRA Ltd.



CNO cycle

The CNO cycle (for carbon–nitrogen–oxygen; sometimes called Bethe–Weizsäcker cycle after Hans Albrecht Bethe and Carl Friedrich von Weizsäcker) is one of the two known sets of fusion reactions by which stars convert hydrogen to helium, the other being the proton–proton chain reaction (p–p cycle), which is more efficient at the Sun's core temperature. The CNO cycle is hypothesized to be dominant in stars that are more than 1.3 times as massive as the Sun.

Unlike the proton-proton reaction, which consumes all its constituents, the CNO cycle is a catalytic cycle. In the CNO cycle, four protons fuse, using carbon, nitrogen, and oxygen isotopes as catalysts, each of which is consumed at one step of the CNO cycle, but re-generated in a later step. The end product is one alpha particle (a stable helium nucleus), two positrons, and two electron neutrinos.

There are various alternative paths and catalysts involved in the CNO cycles, but all these cycles have the same net result:

The positrons will almost instantly annihilate with electrons, releasing energy in the form of gamma rays. The neutrinos escape from the star carrying away some energy. One nucleus goes on to become carbon, nitrogen, and oxygen isotopes through a number of transformations in a repeating cycle.
The proton–proton chain is more prominent in stars the mass of the Sun or less. This difference stems from temperature dependency differences between the two reactions; pp-chain reaction starts at temperatures around (4 megakelvin), making it the dominant energy source in smaller stars. A self-maintaining CNO chain starts at approximately , but its energy output rises much more rapidly with increasing temperatures so that it becomes the dominant source of energy at approximately .

The Sun has a core temperature of around , and only of nuclei produced in the Sun are
born in the CNO cycle.

The CNO-I process was independently proposed by Carl von Weizsäcker and Hans Bethe in the late 1930s.

The first reports of the experimental detection of the neutrinos produced by the CNO cycle in the Sun were published in 2020 by the BOREXINO collaboration. This was also the first experimental confirmation that the Sun had a CNO cycle, that the proposed magnitude of the cycle was accurate, and that von Weizsäcker and Bethe were correct.

Under typical conditions found in stars, catalytic hydrogen burning by the CNO cycles is limited by proton captures. Specifically, the timescale for beta decay of the radioactive nuclei produced is faster than the timescale for fusion. Because of the long timescales involved, the cold CNO cycles convert hydrogen to helium slowly, allowing them to power stars in quiescent equilibrium for many years.

The first proposed catalytic cycle for the conversion of hydrogen into helium was initially called the carbon–nitrogen cycle (CN-cycle), also referred to as the Bethe–Weizsäcker cycle in honor of the independent work of Carl Friedrich von Weizsäcker in 1937–38 and Hans Bethe. Bethe's 1939 papers on the CN-cycle drew on three earlier papers written in collaboration with Robert Bacher and Milton Stanley Livingston and which came to be known informally as ""Bethe's Bible"". It was considered the standard work on nuclear physics for many years and was a significant factor in his being awarded the 1967 Nobel Prize in Physics. Bethe's original calculations suggested the CN-cycle was the Sun's primary source of energy. This conclusion arose from a belief that is now known to be mistaken, that the abundance of nitrogen in the sun is approximately 10%; it is actually less than half a percent. The CN-cycle, named as it contains no stable isotope of oxygen, involves the following cycle of transformations:

This cycle is now understood as being the first part of a larger process, the CNO-cycle, and the main reactions in this part of the cycle (CNO-I) are: 
where the carbon-12 nucleus used in the first reaction is regenerated in the last reaction. After the two positrons emitted annihilate with two ambient electrons producing an additional , the total energy released in one cycle is 26.73 MeV; in some texts, authors are erroneously including the positron annihilation energy in with the beta-decay Q-value and then neglecting the equal amount of energy released by annihilation, leading to possible confusion. All values are calculated with reference to the Atomic Mass Evaluation 2003.

The limiting (slowest) reaction in the CNO-I cycle is the proton capture on . In 2006 it was experimentally measured down to stellar energies, revising the calculated age of globular clusters by around 1 billion years.

The neutrinos emitted in beta decay will have a spectrum of energy ranges, because although momentum is conserved, the momentum can be shared in any way between the positron and neutrino, with either emitted at rest and the other taking away the full energy, or anything in between, so long as all the energy from the Q-value is used. The total momentum received by the positron and the neutrino is not great enough to cause a significant recoil of the much heavier daughter nucleus and hence, its contribution to kinetic energy of the products, for the precision of values given here, can be neglected. Thus the neutrino emitted during the decay of nitrogen-13 can have an energy from zero up to , and the neutrino emitted during the decay of oxygen-15 can have an energy from zero up to . On average, about 1.7 MeV of the total energy output is taken away by neutrinos for each loop of the cycle, leaving about available for producing luminosity.

In a minor branch of the above reaction, occurring in the Sun's core 0.04% of the time, the final reaction involving shown above does not produce carbon-12 and an alpha particle, but instead produces oxygen-16 and a photon and continues

In detail:

Like the carbon, nitrogen, and oxygen involved in the main branch, the fluorine produced in the minor branch is merely an intermediate product; at steady state, it does not accumulate in the star.

This subdominant branch is significant only for massive stars. The reactions are started when one of the reactions in CNO-II results in fluorine-18 and a photon instead of nitrogen-14 and an alpha particle, and continues

In detail:

Like the CNO-III, this branch is also only significant in massive stars. The reactions are started when one of the reactions in CNO-III results in fluorine-19 and a photon instead of nitrogen-15 and an alpha particle, and continues

In detail:

In some instances can combine with a helium nucleus to start a sodium-neon cycle.

Under conditions of higher temperature and pressure, such as those found in novae and X-ray bursts, the rate of proton captures exceeds the rate of beta-decay, pushing the burning to the proton drip line. The essential idea is that a radioactive species will capture a proton before it can beta decay, opening new nuclear burning pathways that are otherwise inaccessible. Because of the higher temperatures involved, these catalytic cycles are typically referred to as the hot CNO cycles; because the timescales are limited by beta decays instead of proton captures, they are also called the beta-limited CNO cycles.

The difference between the CNO-I cycle and the HCNO-I cycle is that captures a proton instead of decaying, leading to the total sequence

In detail:

The notable difference between the CNO-II cycle and the HCNO-II cycle is that captures a proton instead of decaying, and neon is produced in a subsequent reaction on , leading to the total sequence

In detail:

An alternative to the HCNO-II cycle is that captures a proton moving towards higher mass and using the same helium production mechanism as the CNO-IV cycle as

In detail:

While the total number of "catalytic" nuclei are conserved in the cycle, in stellar evolution the relative proportions of the nuclei are altered. When the cycle is run to equilibrium, the ratio of the carbon-12/carbon-13 nuclei is driven to 3.5, and nitrogen-14 becomes the most numerous nucleus, regardless of initial composition. During a star's evolution, convective mixing episodes moves material, within which the CNO cycle has operated, from the star's interior to the surface, altering the observed composition of the star. Red giant stars are observed to have lower carbon-12/carbon-13 and carbon-12/nitrogen-14 ratios than do main sequence stars, which is considered to be convincing evidence for the operation of the CNO cycle.



Craps

Craps is a dice game in which players bet on the outcomes of the roll of a pair of dice. Players can wager money against each other (playing "street craps") or against a bank ("casino craps"). Because it requires little equipment, "street craps" can be played in informal settings. While shooting craps, players may use slang terminology to place bets and actions.

In 1788, "Krabs" (later spelled crabs) was an English variation on the dice game hazard (also spelled hasard).

Craps developed in the United States from a simplification of the western European game of hazard. The origins of hazard are obscure and may date to the Crusades. Hazard was brought from London to New Orleans in approximately 1805 by the returning Bernard Xavier Philippe de Marigny de Mandeville, the young gambler and scion of a family of wealthy landowners in colonial Louisiana. Although in hazard the dice shooter may choose any number from five to nine to be his main number, de Marigny simplified the game such that the main number is always seven, which is the mathematically optimal choice (choice with the lowest disadvantage for the shooter). Both hazard and its simpler derivative were unfamiliar to and rejected by Americans of his social class, leading de Marigny to introduce his novelty to the local underclass. Field hands taught their friends and deckhands, who carried the new game up the Mississippi River and its tributaries. Celebrating the popular success of his novelty, de Marigny gave the name Rue de Craps to a street in his new subdivision in New Orleans.

The central game, called pass from the French word "pas" (meaning "pace" or "step"), has been gradually supplemented over the decades by many companion games which can be played simultaneously with pass. Now applied to the entire collection of games, the name craps derives from an underclass Louisiana mispronunciation of the word "crabs", which in aristocratic London had been the epithet for the numbers two and three. In hazard, both "crabs" are always instant-losing numbers for the first dice roll regardless of the shooter's selected main number. Also in hazard, if the main number is seven then the number twelve is added to the crabs as a losing number on the first dice roll. This structure is retained in the simplified game called pass. All three losing numbers on the first roll of pass are jointly called the craps numbers.

For a century after its invention, casinos used unfair dice. In approximately 1907, a dicemaker named John H. Winn in Philadelphia introduced a layout which featured bets on Don't Pass as well as Pass. Virtually all modern casinos use his innovation, which incentivizes casinos to use fair dice.

Craps exploded in popularity during World War II, which brought most young American men of every social class into the military. The street version of craps was popular among service members who often played it using a blanket as a shooting surface. Their military memories led to craps becoming the dominant casino game in postwar Las Vegas and the Caribbean. After 1960, a few casinos in Europe, Australia, and Macau began offering craps, and, after 2004, online casinos extended the game's spread globally.

Bank craps or casino craps is played by one or more players betting against the casino rather than each other. Both the players and the dealers stand around a large rectangular craps table. Sitting is discouraged by most casinos unless a player has medical reasons for requiring a seat.

Players use casino chips rather than cash to bet on the Craps "layout", a fabric surface which displays the various bets. The bets vary somewhat among casinos in availability, locations, and payouts. The tables roughly resemble bathtubs and come in various sizes. In some locations, chips may be called checks, tokens, or plaques.

Against one long side is the casino's table bank: as many as two thousand casino chips in stacks of 20. The opposite long side is usually a long mirror. The U-shaped ends of the table have duplicate layouts and standing room for approximately eight players. In the center of the layout is an additional group of bets which are used by players from both ends. The vertical walls at each end are usually covered with a rubberized target surface covered with small pyramid shapes to randomize the dice which strike them. The top edges of the table walls have one or two horizontal grooves in which players may store their reserve chips.

The table is run by up to four casino employees: a boxman seated (usually the only seated employee) behind the casino's bank, who manages the chips, supervises the dealers, and handles "coloring up" players (exchanging small chip denominations for larger denominations in order to preserve the chips at a table); two base dealers who stand to either side of the boxman and collect and pay bets to players around their half of the table; and a stickman who stands directly across the table from the boxman, takes and pays (or directs the base dealers to do so) the bets in the center of the table, announces the results of each roll (usually with a distinctive patter), and moves the dice across the layout with an elongated wooden stick.

Each employee also watches for mistakes by the others because of the sometimes large number of bets and frantic pace of the game. In smaller casinos or at quiet times of day, one or more of these employees may be missing, and have their job covered by another, or cause player capacity to be reduced.

Some smaller casinos have introduced "mini-craps" tables which are operated with only two dealers; rather than being two essentially identical sides and the center area, a single set of major bets is presented, split by the center bets. Responsibility of the dealers is adjusted: while the stickman continues to handle the center bets, it is the base dealer who handles all other bets (as well as cash and chip exchanges).

By contrast, in "street craps", there is no marked table and often the game is played with no back-stop against which the dice are to hit. (Despite the name "street craps", this game is often played in houses, usually on an un-carpeted garage or kitchen floor.) The wagers are made in cash, never in chips, and are usually thrown down onto the ground or floor by the players. There are no attendants, and so the progress of the game, fairness of the throws, and the way that the payouts are made for winning bets are self-policed by the players.

Each casino may set which bets are offered and different payouts for them, though a core set of bets and payouts is typical. Players take turns rolling two dice and whoever is throwing the dice is called the "shooter". Players can bet on the various options by placing chips directly on the appropriately-marked sections of the layout, or asking the base dealer or stickman to do so, depending on which bet is being made.

While acting as the shooter, a player must have a bet on the "Pass" line and/or the "Don't Pass" line. "Pass" and "Don't Pass" are sometimes called "Win" and "Don't Win" or "Right" and "Wrong" bets. The game is played in rounds and these "Pass" and "Don't Pass" bets are betting on the outcome of a round. The shooter is presented with multiple dice (typically five) by the "stickman", and must choose two for the round. The remaining dice are returned to the stickman's bowl and are not used.
Each round has two phases: "come-out" and "point". Dice are passed to the left. To start a round, the shooter makes one or more "come-out" rolls. The shooter must shoot toward the farther back wall and is generally required to hit the farther back wall with both dice. Casinos may allow a few warnings before enforcing the dice to hit the back wall and are generally lenient if at least one die hits the back wall. Both dice must be tossed in one throw. If only one die is thrown the shot is invalid. A come-out roll of 2, 3, or 12 is called "craps" or "crapping out", and anyone betting the Pass line loses. On the other hand, anyone betting the Don't Pass line on come out wins with a roll of 2 or 3 and ties (pushes) if a 12 is rolled. Shooters may keep rolling after crapping out; the dice are only required to be passed if a shooter sevens out (rolls a seven after a point has been established). A come-out roll of 7 or 11 is a "natural"; the Pass line wins and Don't Pass loses. The other possible numbers are the point numbers: 4, 5, 6, 8, 9, and 10. If the shooter rolls one of these numbers on the come-out roll, this establishes the "point" – to "pass" or "win", the point number must be rolled again before a seven.

The dealer flips a button to the "On" side and moves it to the point number signifying the second phase of the round. If the shooter "hits" the point value again (any value of the dice that sum to the point will do; the shooter does not have to exactly repeat the exact combination of the come-out roll) before rolling a seven, the Pass line wins and a new round starts. If the shooter rolls any seven before repeating the point number (a "seven-out"), the Pass line loses, the Don't Pass line wins, and the dice pass clockwise to the next new shooter for the next round. Once a point has been established any multi-roll bet (including Pass and/or Don't Pass line bets and odds) are unaffected by the 2, 3, 11, or 12; the only numbers which affect the round are the established point, any specific bet on a number, or any 7. Any single roll bet is always affected (win or lose) by the outcome of any roll.

While the come-out roll may specifically refer to the first roll of a new shooter, any roll where no point is established may be referred to as a come-out. By this definition the start of any new round regardless if it is the shooter's first toss can be referred to as a come-out roll.

Any player can make a bet on Pass or Don't Pass as long as a point has not been established, or Come or Don't Come as long as a point is established. All other bets, including an increase in odds behind the Pass and Don't Pass lines, may be made at any time. All bets other than Pass line and Come may be removed or reduced any time before the bet loses. This is known as "taking it down" in craps.

The maximum bet for Place, Buy, Lay, Pass, and Come bets are generally equal to table maximum. Lay bet maximum are equal to the table maximum win, so players wishing to lay the 4 or 10 may bet twice at amount of the table maximum for the win to be table maximum. Odds behind Pass, Come, Don't Pass, and Don't Come may be however larger than the odds offered allows and can be greater than the table maximum in some casinos. Don't odds are capped on the maximum allowed win some casino allow the odds bet itself to be larger than the maximum bet allowed as long as the win is capped at maximum odds. Single rolls bets can be lower than the table minimum, but the maximum bet allowed is also lower than the table maximum. The maximum allowed single roll bet is based on the maximum allowed win from a single roll.

In all the above scenarios, whenever the Pass line wins, the Don't Pass line loses, and vice versa, with one exception: on the come-out roll, a roll of 12 will cause Pass Line bets to lose, but Don't Pass bets are pushed (or "barred"), neither winning nor losing. (The same applies to "Come" and "Don't Come" bets, discussed below.)

A player wishing to play craps without being the shooter should approach the craps table and first check to see if the dealer's "On" button is on any of the point numbers.


In either case, all single or multi-roll proposition bets may be placed in either of the two rounds.

Between dice rolls there is a period for dealers to make payouts and collect losing bets, after which players can place new bets. The stickman monitors the action at a table and decides when to give the shooter the dice, after which no more betting is allowed.

When joining the game, one should place money on the table rather than passing it directly to a dealer. The dealer's exaggerated movements during the process of "making change" or "change only" (converting currency to an equivalent in casino cheques) are required so that any disputes can be later reviewed against security camera footage.

The dealers will insist that the shooter roll with one hand and that the dice bounce off the far wall surrounding the table. These requirements are meant to keep the game fair (preventing switching the dice or making a "controlled shot"). If a die leaves the table, the shooter will usually be asked to select another die from the remaining three but can request permission to use the same die if it passes the boxman's inspection. This requirement exists to keep the game fair and reduce the chance of loaded dice.

There are many local variants of the calls made by the stickman for rolls during a craps game. These frequently incorporate a reminder to the dealers as to which bets to pay or collect.


Rolls of 4, 6, 8, and 10 are called "hard" or "easy" (e.g. "six the hard way", "easy eight", "hard ten") depending on whether they were rolled as a "double" or as any other combination of values, because of their significance in center table bets known as the "hard ways". Hard way rolls are so named because there is only one way to roll them (i.e., the value on each die is the same when the number is rolled). Consequently, it is more likely to roll the number in combinations (easy) rather than as a double (hard).

The shooter is required to make either a Pass line bet or a Don't Pass bet if he wants to shoot. On the come out roll each player may only make one bet on the Pass or Don't Pass, but may bet both if desired. The Pass Line and Don't Pass bet is optional for any player not shooting. In rare cases, some casinos require all players to make a minimum Pass Line or Don't Pass bet (if they want to make any other bet), whether they are currently shooting or not.

The fundamental bet in craps is the Pass line bet, which is a bet for the shooter to win. This bet must be at least the table minimum and at most the table maximum.
The Pass line bet pays even money.

The Pass line bet is a contract bet. Once a Pass line bet is made, it is always working and cannot be turned "Off", taken down, or reduced until a decision is reached – the point is made, or the shooter sevens out. A player may increase any corresponding odds (up to the table limit) behind the Pass line at any time after a point is established. Players may only bet the Pass line on the come out roll when no point has been established, unless the casino allows put betting where the player can bet Pass line or increase an existing Pass line bet whenever desired and may take odds immediately if the point is already on.

A Don't Pass bet is a bet for the shooter to lose ("seven out, line away") and is almost the opposite of the Pass line bet. Like the Pass bet, this bet must be at least the table minimum and at most the table maximum.
The Don't Pass bet pays even money.

The Don't Pass bet is a no-contract bet. After a point is established, a player may take down or reduce a Don't Pass bet and any corresponding odds at any time because odds of rolling a 7 before the point is in the player's favor. Once taken down or reduced, however, the Don't Pass bet may not be restored or increased. Because the shooter must have a line bet the shooter generally may not reduce a Don't Pass bet below the table minimum. In Las Vegas, a majority of casinos will allow the shooter to move the bet to the Pass line in lieu of taking it down; however, in other areas such as Pennsylvania and Atlantic City, this is not allowed. Even though players are allowed to remove the Don't Pass line bet after a point has been established, the bet cannot be turned "Off" without being removed. If a player chooses to remove the Don't Pass line bet, he or she can no longer lay odds behind the Don't Pass line. The player can, however, still make standard lay bets on any of the point numbers (4, 5, 6, 8, 9, 10).

There are two different ways to calculate the odds and house edge of this bet. The table below gives the numbers considering that the game ends in a push when a 12 is rolled, rather than being undetermined. Betting on Don't Pass is often called "playing the dark side", and it is considered by some players to be in poor taste, or even taboo, because it goes directly against conventional play, winning when most of the players lose.

If a 4, 5, 6, 8, 9, or 10 is thrown on the come-out roll (i.e., if a point is established), most casinos allow Pass line players to take odds by placing up to some predetermined multiple of the Pass line bet, behind the Pass line. This additional bet wins if the point is rolled again before a 7 is rolled (the point is made) and pays at the true odds of 2-to-1 if 4 or 10 is the point, 3-to-2 if 5 or 9 is the point, or 6-to-5 if 6 or 8 is the point. Unlike the Pass line bet itself, the Pass line odds bet can be turned "Off" (not working), removed or reduced anytime before it loses. In Las Vegas, generally odds bets are required to be the table minimum. In Atlantic City and Pennsylvania, the combine odds and Pass bet must be table minimum so players can bet the minimum single unit on odds depending on the point. If the point is a 4 or 10 players can bet as little as $1 on odds if the table minimum is low such as is $5, $10 or $15. If the player requests the Pass odds be not working ("Off") and the shooter sevens-out or hits the point, the Pass line bet will be lost or doubled and the Pass odds returned.

Individual casinos (and sometimes tables within a casino) vary greatly in the maximum odds they offer, from single or double odds (one or two times the Pass line bet) up to 100x or even unlimited odds. A variation often seen is "3-4-5X Odds", where the maximum allowed odds bet depends on the point: three times if the point is 4 or 10; four times on points of 5 or 9; or five times on points of 6 or 8. This rule simplifies the calculation of winnings: a maximum Pass odds bet on a 3–4–5× table will always be paid at six times the Pass line bet regardless of the point.

As odds bets are paid at true odds, in contrast with the Pass line which is always even money, taking odds on a minimum Pass line bet lessens the house advantage compared with betting the same total amount on the Pass line only. A maximum odds bet on a minimum Pass line bet often gives the lowest house edge available in any game in the casino. However, the odds bet cannot be made independently, so the house retains an edge on the Pass line bet itself.

If a player is playing Don't Pass instead of pass, they may also lay odds by placing chips behind the Don't Pass line. If a 7 comes before the point is rolled, the odds pay at true odds of 1-to-2 if 4 or 10 is the point, 2-to-3 if 5 or 9 is the point, or 5-to-6 if 6 or 8 is the point. Typically the maximum lay bet will be expressed such that a player may win up to an amount equal to the maximum odds multiple at the table. If a player lays maximum odds with a point of 4 or 10 on a table offering five-times odds, he would be able to lay a maximum of ten times the amount of his Don't Pass bet. At 5x odds table, the maximum amount the combined bet can win will always be 6x the amount of the Don't Pass bet. Players can bet table minimum odds if desired and win less than table minimum. Like the Don't Pass bet the odds can be removed or reduced. Unlike the Don't Pass bet itself, the Don't Pass odds can be turned "Off" (not working). In Las Vegas generally odds bets are required to be the table minimum. In Atlantic City and Pennsylvania, the combine lay odds and Don't Pass bet must be table minimum so players may bet as little as the minimum two units on odds depending on the point. If the point is a 4 or 10 players can bet as little as $2 if the table minimum is low such as $5, $10 or $15 tables. If the player requests the Don't Pass odds to be not working ("Off") and the shooter hits the point or sevens-out, the Don't Pass bet will be lost or doubled and the Don't Pass odds returned. Unlike a standard lay bet on a point, lay odds behind the Don't Pass line does not charge commission (vig).

A Come bet can be visualized as starting an entirely new Pass line bet, unique to that player. Like the Pass Line each player may only make one Come bet per roll, this does not exclude a player from betting odds on an already established Come point. This bet must be at least the table minimum and at most the table maximum. Players may bet both the Come and Don't Come on the same roll if desired. Come bets can only be made after a point has been established since, on the come-out roll, a Come bet would be the same thing as a Pass line bet. A player making a Come bet will bet on the first point number that "comes" from the shooter's next roll, regardless of the table's round. If a 7 or 11 is rolled on the first round, it wins. If a 2, 3, or 12 is rolled, it loses. If instead the roll is 4, 5, 6, 8, 9, or 10, the Come bet will be moved by the base dealer onto a box representing the number the shooter threw. This number becomes the "come-bet point" and the player is allowed to take odds, just like a Pass line bet. Also like a Pass line bet, the come bet is a contract bet and is always working, and cannot be turned "Off", removed or reduced until it wins or loses. However, the odds taken behind a Come bet can be turned "Off" (not working), removed or reduced anytime before the bet loses. In Las Vegas generally odds bets are required to be the table minimum. In Atlantic City and Pennsylvania, the combine odds and Pass bet must be table minimum so players can bet the minimum single unit depending on the point. If the point is a 4 or 10, players can bet as little as $1 if the table minimum is low such as $5, $10, or $15 minimums. If the player requests the Come odds to be not working ("Off") and the shooter sevens-out or hits the Come bet point, the Come bet will be lost or doubled and the Come odds returned. If the casino allows put betting a player may increase a Come bet after a point has been established and bet larger odds behind if desired. Put betting also allows a player to bet on a Come and take odds immediately on a point number without a Come bet point being established.

The dealer will place the odds on top of the come bet, but slightly off center in order to differentiate between the original bet and the odds. The second round wins if the shooter rolls the come bet point again before a seven. Winning come bets are paid the same as winning Pass line bets: even money for the original bet and true odds for the odds bet. If, instead, the seven is rolled before the come-bet point, the come bet (and any odds bet) loses.

Because of the come bet, if the shooter makes their point, a player can find themselves in the situation where they still have a come bet (possibly with odds on it) and the next roll is a come-out roll. In this situation, odds bets on the come wagers are usually presumed to be not working for the come-out roll. That means that if the shooter rolls a 7 on the come-out roll, any players with active come bets waiting for a come-bet point lose their initial wager but will have their odds bets returned to them.

If the come-bet point is rolled on the come-out roll, the odds do not win but the come bet does and the odds bet is returned (along with the come bet and its payoff). The player can tell the dealer that they want their odds working, such that if the shooter rolls a number that matches the come point, the odds bet will win along with the come bet, and if a seven is rolled, both lose.

Many players will use a come bet as "insurance" against sevening out: if the shooter rolls a seven, the come bet pays 1:1, offsetting the loss of the Pass line bet. The risk in this strategy is the situation where the shooter does not hit a seven for several rolls, leading to multiple come bets that will be lost if the shooter eventually sevens out.

In the same way that a come bet is similar to a Pass line bet, a Don't Come bet is similar to a Don't Pass bet. Like the come, the Don't Come can only be bet after a point has already been established as it is the same as a Don't Pass line bet when no point is established. This bet must be at least the table minimum and at most the table maximum. A Don't Come bet is played in two rounds. If a 2 or 3 is rolled in the first round, it wins. If a 7 or 11 is rolled, it loses. If a 12 is rolled, it is a push (subject to the same 2/12 switch described above for the Don't Pass bet). If, instead, the roll is 4, 5, 6, 8, 9, or 10, the Don't Come bet will be moved by the base dealer onto a box representing the number the shooter threw. The second round wins if the shooter rolls a seven before the Don't Come point. Like the Don't Pass each player may only make one Don't Come bet per roll, this does not exclude a player from laying odds on an already established Don't Come points. Players may bet both the Don't Come and Come on the same roll if desired.

The player may lay odds on a Don't Come bet, just like a Don't Pass bet; in this case, the dealer (not the player) places the odds bet on top of the bet in the box, because of limited space, slightly offset to signify that it is an odds bet and not part of the original Don't Come bet. Lay odds behind a Don't Come are subject to the same rules as Don't Pass lay odds. Unlike a standard lay bet on a point, lay odds behind a Don't Come point does not charge commission (vig) and gives the player true odds. Like the Don't Pass line bet, Don't Come bets are no-contract, and can be removed or reduced after a Don't Come point has been established, but cannot be turned off ("not working") without being removed. A player may also call, "No Action" when a point is established, and the bet will not be moved to its point. This play is not to the player's advantage. If the bet is removed, the player can no longer lay odds behind the Don't Come point and cannot restore or increase the same Don't Come bet. Players must wait until next roll as long as a Pass line point has been established (players cannot bet Don't Come on come out rolls) before they can make a new Don't Come bet. Las Vegas casinos which allow put betting allows players to move the Don't Come directly to any Come point as a put; however, this is not allowed in Atlantic City or Pennsylvania. Unlike the Don't Come bet itself, the Don't Come odds can be turned "Off" (not working), removed, or reduced if desired. In Las Vegas, players generally must lay at least table minimum on odds if desired and win less than table minimum; in Atlantic City and Pennsylvania a player's combined bet must be at least table minimum, so depending on the point number players may lay as little as 2 minimum units (e.g. if the point is 4 or 10). If the player requests the Don't Come odds be not working ("Off") and the shooter hits the Don't Come point or sevens-out, the Don't Come bet will be lost or doubled and the Don't Come odds returned.

Winning Don't Come bets are paid the same as winning Don't Pass bets: even money for the original bet and true odds for the odds lay. Unlike come bets, the odds laid behind points established by Don't Come bets are always working including come out rolls unless the player specifies otherwise.

These are bets that may not be settled on the first roll and may need any number of subsequent rolls before an outcome is determined.
Most multi-roll bets may fall into the situation where a point is made by the shooter before the outcome of the multi-roll bet is decided. These bets are often considered "not working" on the new come-out roll until the next point is established, unless the player calls the bet as "working."

Casino rules vary on this; some of these bets may not be callable, while others may be considered "working" during the come-out. Dealers will usually announce if bets are working unless otherwise called off. If a non-working point number placed, bought or laid becomes the new point as the result of a come-out, the bet is usually refunded, or can be moved to another number for free.

Players can bet any point number (4, 5, 6, 8, 9, 10) by placing their wager in the come area and telling the dealer how much and on what number(s), "30 on the 6", "5 on the 5", or "25 on the 10". These are typically "Place Bets to Win". These are bets that the number bet on will be rolled before a 7 is rolled. These bets are considered working bets, and will continue to be paid out each time a shooter rolls the number bet. On a come-out roll, a place bet is considered to be not in effect unless the player who made it specifies otherwise. This bet may be removed or reduced at any time until it loses; in the latter case, the player must abide by any table minimums.

Place bets to win pay out at slightly worse than the true odds: 9-to-5 on points 4 or 10, 7-to-5 on points 5 or 9, and 7-to-6 on points 6 or 8. The place bets on the outside numbers (4,5,9,10) should be made in units of $5, (on a $5 minimum table), in order to receive the correct exact payout of $5 paying $7 or $5 paying $9. The place bets on the 6 & 8 should be made in units of $6, (on a $5 minimum table), in order to receive the correct exact payout of $6 paying $7. For the 4 and 10, it is to the player's advantage to 'buy' the bet (see below).

An alternative form, rarely offered by casinos, is the "place bet to lose." This bet is the opposite of the place bet to win and pays off if a 7 is rolled before the specific point number. The place bet to lose typically carries a lower house edge than a place bet to win. Payouts are 4–5 on points 6 or 8, 5–8 on 5 or 9, and 5–11 on 4 or 10.

Players can also buy a bet which are paid at true odds, but a 5% commission is charged on the amount of the bet. Buy bets are placed with the shooter betting at a specific number will come out before a player sevens out. The buy bet must be at least table minimum excluding commission; however, some casinos require the minimum buy bet amount to be at least $20 to match the $1 charged on the 5% commission. Traditionally, the buy bet commission is paid no matter what, but in recent years a number of casinos have changed their policy to charge the commission only when the buy bet wins. Some casinos charge the commission as a one-time fee to buy the number; payouts are then always at true odds. Most casinos usually charge only $1 for a $25 green-chip bet (4% commission), or $2 for $50 (two green chips), reducing the house advantage a bit more. Players may remove or reduce this bet (bet must be at least table minimum excluding vig) anytime before it loses. Buy bets like place bets are not working when no point has been established unless the player specifies otherwise.

Where commission is charged only on wins, the commission is often deducted from the winning payoff—a winning $25 buy bet on the 10 would pay $49, for instance. The house edges stated in the table assume the commission is charged on all bets. They are reduced by at least a factor of two if commission is charged on winning bets only.

A lay bet is the opposite of a buy bet, where a player bets on a 7 to roll before the number that is laid. Players may only lay the 4, 5, 6, 8, 9, or 10 and may lay multiple numbers if desired. Just like the buy bet lay bets pay true odds, but because the lay bet is the opposite of the buy bet, the payout is reversed. Therefore, players get 1 to 2 for the numbers 4 and 10, 2 to 3 for the numbers 5 and 9, and 5 to 6 for the numbers 6 and 8. A 5% commission (vigorish, vig, juice) is charged up front on the possible winning amount. For example: A $40 Lay Bet on the 4 would pay $20 on a win. The 5% vig would be $1 based on the $20 win. (not $2 based on the $40 bet as the way buy bet commissions are figured.) Like the buy bet the commission is adjusted to suit the betting unit such that fraction of a dollar payouts are not needed. Casinos may charge the vig up front thereby requiring the player to pay a vig win or lose, other casinos may only take the vig if the bet wins. Taking vig only on wins lowers house edge. Players may removed or reduce this bet (bet must be at least table minimum) anytime before it loses. Some casinos in Las Vegas allow players to lay table minimum plus vig if desired and win less than table minimum. Lay bet maximums are equal to the table maximum win, so if a player wishes to lay the 4 or 10, he or she may bet twice at amount of the table maximum for the win to be table maximum. Other casinos require the minimum bet to win at $20 even at the lowest minimum tables in order to match the $1 vig, this requires a $40 bet. Similar to buy betting, some casinos only take commission on win reducing house edge. Unlike place and buy bets, lay bets are always working even when no point has been established. The player must specify otherwise if he or she wishes to have the bet not working.

If a player is unsure of whether a bet is a single or multi-roll bet, it can be noted that all single-roll bets will be displayed on the playing surface in one color (usually red), while all multi-roll bets will be displayed in a different color (usually yellow).

A put bet is a bet which allows players to increase or make a Pass line bet after a point has been established (after come-out roll). Players may make a put bet on the Pass line and take odds immediately or increase odds behind if a player decides to add money to an already existing Pass line bet. Put betting also allows players to increase an existing come bet for additional odds after a come point has been established or make a new come bet and take odds immediately behind if desired without a come bet point being established. If increased or added put bets on the Pass line and Come cannot be turned "Off", removed or reduced, but odds bet behind can be turned "Off", removed or reduced. The odds bet is generally required to be the table minimum. Player cannot put bet the Don't Pass or Don't Come. Put betting may give a larger house edge over place betting unless the casino offers high odds.

Put bets are generally allowed in Las Vegas, but not allowed in Atlantic City and Pennsylvania.

Put bets are better than place bets (to win) when betting more than 5-times odds over the flat bet portion of the put bet. For example, a player wants a $30 bet on the six. Looking at two possible bets: 1) Place the six, or 2) Put the six with odds. A $30 place bet on the six pays $35 if it wins. A $30 put bet would be a $5 flat line bet plus $25 (5-times) in odds, and also would pay $35 if it wins. Now, with a $60 bet on the six, the place bet wins $70, where the put bet ($5 + $55 in odds) would pay $71. The player needs to be at a table which not only allows put bets, but also high-times odds, to take this advantage.

This bet can only be placed on the numbers 4, 6, 8, and 10. In order for this bet to win, the chosen number must be rolled the "hard way" (as doubles) before a 7 or any other non-double combination ("easy way") totaling that number is rolled. For example, a player who bets a hard 6 can only win by seeing a 3–3 roll come up before any 7 or any easy roll totaling 6 (4–2 or 5–1); otherwise, the player loses.

In Las Vegas casinos, this bet is generally working, including when no point has been established, unless the player specifies otherwise. In other casinos such as those in Atlantic City, hard ways are not working when the point is off unless the player requests to have it working on the come out roll.

Like single-roll bets, hard way bets can be lower than the table minimum; however, the maximum bet allowed is also lower than the table maximum. The minimum hard way bet can be a minimum one unit. For example, lower stake table minimums of $5 or $10, generally allow minimum hard ways bets of $1. The maximum bet is based on the maximum allowed win from a single roll.

Easy way is not a specific bet offered in standard casinos, but a term used to define any number combination which has two ways to roll. For example, (6–4, 4–6) would be a "10 easy". The 4, 6, 8 or 10 can be made both hard and easy ways. Betting point numbers (which pays off on easy or hard rolls of that number) or single-roll ("hop") bets (e.g., "hop the 2–4" is a bet for the next roll to be an easy six rolled as a two and four) are methods of betting easy ways.

A player can choose either the 6 or 8 being rolled before the shooter throws a seven. These wagers are usually avoided by experienced craps players since they pay even money (1:1) while a player can make place bets on the 6 or the 8, which pay more (7:6). Some casinos (especially all those in Atlantic City) do not even offer the Big 6 & 8. The bets are located in the corners behind the Pass line, and bets may be placed directly by players.

The only real advantage offered by the Big 6 & 8 is that they can be bet for the table minimum, whereas a place bet minimum may sometimes be greater than the table minimum (e.g. $6 place bet on a $3 minimum game.) In addition place bets are usually not working, except by agreement, when the shooter is "coming out" i.e. shooting for a point, and Big 6 and 8 bets always work. Some modern layouts no longer show the Big 6/Big 8 bet.

Single-roll (proposition) bets are resolved in one dice roll by the shooter. Most of these are called "service bets", and they are located at the center of most craps tables. Only the stickman or a dealer can place a service bet. Single-roll bets can be lower than the table minimum, but the maximum bet allowed is also lower than the table maximum. The maximum bet is based on the maximum allowed win from a single roll. The lowest single-roll bet can be a minimum one unit bet. For example, tables with minimums of $5 or $10 generally allow minimum single-roll bets of $1. Single bets are always working by default unless the player specifies otherwise. The bets include:


Fire Bet: Before the shooter begins, some casinos will allow a bet known as a fire bet to be placed. A fire bet is a bet of as little as $1 and generally up to a maximum of $5 to $10 sometimes higher, depending on casino, made in the hope that the next shooter will have a hot streak of setting and getting many points of different values. As different individual points are made by the shooter, they will be marked on the craps layout with a fire symbol.

The first three points will not pay out on the fire bet, but the fourth, fifth, and sixth will pay out at increasing odds. The fourth point pays at 24-to-1, the fifth point pays at 249-to-1, and the 6th point pays at 999-to-1. (The points must all be different numbers for them to count toward the fire bet.) For example, a shooter who successfully hits a point of 10 twice will only garner credit for the first one on the fire bet. Players must hit the established point in order for it to count toward the fire bet. The payout is determine by the number of points which have been established and hit after the shooter sevens out.

Bonus Craps: Prior to the initial "come out roll", players may place an optional wager (usually a $1 minimum to a maximum $25) on one or more of the three Bonus Craps wagers, "All Small", "All Tall", or "All or Nothing at All." For players to win the "All Small" wager, the shooter must hit all five small numbers (2, 3, 4, 5, 6) before a seven is rolled; similarly, "All Tall" wins if all five high numbers (8, 9, 10, 11, 12) are hit before a seven is rolled.

These bets pay 35-for-1, for a house advantage of 7.76%. "All or Nothing at All" wins if the shooter hits all 10 numbers before a seven is rolled. This pays 176-for-1, for a house edge of 7.46%. For all three wagers, the order in which the numbers are hit does not matter. Whenever a seven is hit, including on the come out roll, all bonus bets lose, the bonus board is reset, and new bonus bets may be placed.

A player may wish to make multiple different bets. For example, a player may be wish to bet $1 on all hard ways and the horn. If one of the bets win the dealer may automatically replenish the losing bet with profits from the winning bet. In this example, if the shooter rolls a hard 8 (pays 9:1), the horn loses. The dealer may return $5 to the player and place the other $4 on the horn bet which lost. If the player does not want the bet replenished, he or she should request any or all bets be taken down.

A working bet is a live bet. Bets may also be on the board, but not in play and therefore not working. Pass line and come bets are always working meaning the chips are in play and the player is therefore wagering live money. Other bets may be working or not working depending whether a point has been established or player's choice. Place and buy bets are working by default when a point is established and not working when the point is off unless the player specifies otherwise. Lay bets are always working even if a point has not been established unless the player requests otherwise. At any time, a player may wish to take any bet or bets out of play. The dealer will put an "Off" button on the player's specific bet or bets; this allows the player to keep his chips on the board without a live wager. For example, if a player decides not to wager a place bet mid-roll but wishes to keep the chips on the number, he or she may request the bet be "not working" or "Off". The chips remain on the table, but the player cannot win from or lose chips which are not working.

The opposite is also allowed. By default place and buy bets are not working without an established point; a player may wish to wager chips before a point has been established. In this case, the player would request the bet be working in which the dealer will place an "On" button on the specified chips.

The probability of dice combinations determine the odds of the payout. The following chart shows the dice combinations needed to roll each number. The two and twelve are the hardest to roll since only one combination of dice is possible. The game of craps is built around the dice roll of seven, since it is the most easily rolled dice combination.

Viewed another way:

The expected value of all bets is usually negative, such that the average player will always lose money. This is because the house always sets the paid odds to below the actual odds. The only exception is the "odds" bet that the player is allowed to make after a point is established on a pass/come Don't Pass/Don't Come bet (the odds portion of the bet has a long-term expected value of 0). However, this "free odds" bet cannot be made independently, so the expected value of the entire bet, including odds, is still negative. Since there is no correlation between die rolls, there is normally no possible long-term winning strategy in craps.

There are occasional promotional variants that provide either no house edge or even a player edge. One example is a field bet that pays 3:1 on 12 and 2:1 on either 3 or 11. Overall, given the 5:4 true odds of this bet, and the weighted average paid odds of approximately 7:5, the player has a 5% advantage on this bet. This is sometimes seen at casinos running limited-time incentives, in jurisdictions or gaming houses that require the game to be fair, or in layouts for use in informal settings using play money. No casino currently runs a craps table with a bet that yields a player edge full-time.

Maximizing the size of the odds bet in relation to the line bet will reduce, but never eliminate the house edge, and will increase variance. Most casinos have a limit on how large the odds bet can be in relation to the line bet, with single, double, and five times odds common. Some casinos offer 3–4–5 odds, referring to the maximum multiple of the line bet a player can place in odds for the points of 4 and 10, 5 and 9, and 6 and 8, respectively. During promotional periods, a casino may even offer 100x odds bets, which reduces the house edge to almost nothing, but dramatically increases variance, as the player will be betting in large betting units.

Since several of the multiple roll bets pay off in ratios of fractions on the dollar, it is important that the player bets in multiples that will allow a correct payoff in complete dollars. Normally, payoffs will be rounded down to the nearest dollar, resulting in a higher house advantage. These bets include all place bets, taking odds, and buying on numbers 6, 8, 5, and 9, as well as laying all numbers.

These variants depend on the casino and the table, and sometimes a casino will have different tables that use or omit these variants and others.


When craps is played in a casino, all bets have a house advantage. That is, it can be shown mathematically that a player will (with 100% probability) lose all his or her money to the casino in the long run, while in the short run the player is more likely to lose money than make money. There may be players who are lucky and get ahead for a period of time, but in the long run these winning streaks are eroded away. One can slow, but not eliminate, one's average losses by only placing bets with the smallest house advantage.

The Pass/Don't Pass line, Come/Don't Come line, place 6, place 8, buy 4 and buy 10 (only under the casino rules where commission is charged only on wins) have the lowest house edge in the casino, and all other bets will, on average, lose money between three and twelve times faster because of the difference in house edges.

The place bets and buy bets differ from the Pass line and come line, in that place bets and buy bets can be removed at any time, since, while they are multi-roll bets, their odds of winning do not change from roll to roll, whereas Pass line bets and come line bets are a combination of different odds on their first roll and subsequent rolls. The first roll of a Pass line bet is 2:1 advantage for the player (8 wins, 4 losses), but it is "paid for" by subsequent rolls that are at the same disadvantage to the player as the Don't Pass bets were at an advantage. As such, they cannot profitably let the player take down the bet after the first roll. Players can bet or lay odds behind an established point depending on whether it was a Pass/Come or Don't Pass/Don't Come to lower house edge by receiving true odds on the point. Casinos which allow put betting allows players to increase or make new pass/come bets after the come-out roll. This bet generally has a higher house edge than place betting, unless the casino offers high odds.

Conversely, a player can take back (pick up) a Don't Pass or Don't Come bet after the first roll, but this cannot be recommended, because they already endured the disadvantaged part of the combination – the first roll. On that come-out roll, they win just 3 times (2 and 3), while losing 8 of them (7 and 11) and pushing one (12) out of the 36 possible rolls. On the other 24 rolls that become a point, their Don't Pass bet is now to their advantage by 6:3 (4 and 10), 6:4 (5 and 9) and 6:5 (6 and 8). If a player chooses to remove the initial Don't Come and/or Don't Pass line bet, he or she can no longer lay odds behind the bet and cannot re-bet the same Don't Pass and/or Don't Come number (players must make a new Don't Pass or come bets if desired). However, players can still make standard lay bets odds on any of the point numbers (4,5,6,8,9,10).

Among these, and the remaining numbers and possible bets, there are a myriad of systems and progressions that can be used with many combinations of numbers.

An important alternative metric is house advantage per roll (rather than per bet), which may be expressed in loss per hour. The typical pace of rolls varies depending on the number of players, but 102 rolls per hour is a cited rate for a nearly full table. This same reference states that only "29.6% of total rolls are come out rolls, on average", so for this alternative metric, needing extra rolls to resolve the Pass line bet, for example, is factored. This number then permits calculation of rate of loss per hour, and per the 4 day/5 hour per day gambling trip:


Besides the rules of the game itself, a number of formal and informal rules are commonly applied in the table form of Craps, especially when played in a casino.

To reduce the potential opportunity for switching dice by sleight-of-hand, players are not supposed to handle the dice with more than one hand (such as shaking them in cupped hands before rolling) nor take the dice past the edge of the table. If a player wishes to change shooting hands, they may set the dice on the table, let go, then take them with the other hand.

When throwing the dice, the player is expected to hit the farthest wall at the opposite end of the table (these walls are typically augmented with pyramidal structures to ensure highly unpredictable bouncing after impact). Casinos will sometimes allow a roll that does not hit the opposite wall as long as the dice are thrown past the middle of the table; a very short roll will be nullified as a "no roll". The dice may not be slid across the table and must be tossed. These rules are intended to prevent dexterous players from physically influencing the outcome of the roll.

Players are generally asked not to throw the dice above a certain height (such as the eye level of the dealers). This is both for the safety of those around the table, and to eliminate the potential use of such a throw as a distraction device in order to cheat.

Dice are still considered "in play" if they land on players' bets on the table, the dealer's working stacks, on the marker puck, or with one die resting on top of the other. The roll is invalid if either or both dice land in the boxman's bank, the stickman's bowl (where the extra three dice are kept between rolls), or in the rails around the top of the table where players chips are kept. If one or both dice hits a player or dealer and rolls back onto the table, the roll counts as long as the person being hit did not intentionally interfere with either of the dice, though some casinos will rule "no roll" for this situation. If one or both leave the table, it is also a "no roll", and the dice may either be replaced or examined by the boxman and returned to play.

Shooters may wish to "set" the dice to a particular starting configuration before throwing (such as showing a particular number or combination, stacking the dice, or spacing them to be picked up between different fingers), but if they do, they are often asked to be quick about it so as not to delay the game. Some casinos disallow such rituals to speed up the pace of the game. Some may also discourage or disallow unsanitary practices such as kissing or spitting on the dice.

In most casinos, players are not allowed to hand anything directly to dealers, and vice versa. Items such as cash, checks, and chips are exchanged by laying them down on the table; for example, when "buying in" (paying cash for chips), players are expected to place the cash on the layout: the dealer will take it and then place the chips in front of the player. This rule is enforced in order to allow the casino to easily monitor and record all transfers via overhead surveillance cameras, and to reduce the opportunity for cheating via sleight-of-hand.

Most casinos prohibit "call bets", and may have a warning such as "No Call Bets" printed on the layout to make this clear. This means a player may not call out a bet without also placing the corresponding chips on the table. Such a rule reduces the potential for misunderstanding in loud environments, as well as disputes over the amount that the player intended to bet after the outcome has been decided. Some casinos choose to allow call bets once players have bought-in. When allowed, they are usually made when a player wishes to bet at the last second, immediately before the dice are thrown, to avoid the risk of obstructing the roll.

Craps is among the most social and most superstitious of all gambling games, which leads to an enormous variety of informal rules of etiquette that players may be expected to follow. An exhaustive list of these is beyond the scope of this article, but the guidelines below are most commonly given.

Tipping the dealers is universal and expected in Craps. As in most other casino games, a player may simply place (or toss) chips onto the table and say, "For the dealers", "For the crew", "etc." In craps, it is also common to place a bet for the dealers. This is usually done one of three ways: by placing an ordinary bet and simply declaring it for the dealers, as a "two-way", or "on top". A "Two-Way" is a bet for both parties: for example, a player may toss in two chips and say "Two Way Hard Eight", which will be understood to mean one chip for the player and one chip for the dealers. Players may also place a stack of chips for a bet as usual, but leave the top chip off-center and announce "on top for the dealers". The dealer's portion is often called a "toke" bet, which comes from the practice of using $1 slot machine tokens to place dealer bets in some casinos.

In some cases, players may also tip each other, for example as a show of gratitude to the thrower for a roll on which they win a substantial bet.

Craps players routinely practice a wide range of superstitious behaviors, and may expect or demand these from other players as well.

Most prominently, it is universally considered bad luck to say the word "seven" (after the "come-out", a roll of 7 is a loss for "pass" bets). Dealers themselves often make significant efforts to avoid calling out the number. When necessary, participants may refer to seven with a "nickname" such as "Big Red" (or just "Red"), "the S-word", etc.

Although no wagering system can consistently beat casino games based on independent trials such as craps, that does not stop gamblers from believing in them. One of the best known systems is the Martingale System. In this strategy, the gambler doubles his bet after every loss. After a win, the bet is reset to the original bet. The theory is that the first win would recover all previous losses plus win a profit equal to the original stake.

Other systems depend on the gambler's fallacy, which in craps terms is the belief that past dice rolls influence the probabilities of future dice rolls. For example, the gambler's fallacy indicates that a craps player should bet on eleven if an eleven has not appeared or has appeared too often in the last 20 rolls. In practice this can be observed as players respond to a roll such as a Hard Six with an immediate wager on the Hard Six.

In reality, each roll of the dice is an independent event, so the probability of rolling eleven is exactly 1/18 on every roll, regardless of the number of times eleven has come up in the last x rolls. Even if the dice are actually biased toward particular results ("loaded"), each roll is still independent of all the previous ones. The common term to describe this is "dice have no memory".

Another approach is to "set" the dice in a particular orientation, and then throw them in such a manner that they do not tumble randomly. The theory is that given exactly the same throw from exactly the same starting configuration, the dice will tumble in the same way and therefore show the same or similar values every time.

Casinos take steps to prevent this. The dice are usually required to hit the back wall of the table, which is normally faced with a jagged angular texture such as pyramids, making controlled spins more difficult. There has been no independent evidence that such methods can be successfully applied in a real casino.

Bank craps is a variation of the original craps game and is sometimes known as Las Vegas Craps. This variant is quite popular in Nevada gambling houses, and its availability online has now made it a globally played game. Bank craps uses a special table layout and all bets must be made against the house. In Bank Craps, the dice are thrown over a wire or a string that is normally stretched a few inches from the table's surface. The lowest house edge (for the Pass/Don't Pass) in this variation is around 1.4%. Generally, if the word "craps" is used without any modifier, it can be inferred to mean this version of the game, to which most of this article refers.

Crapless craps, also known as bastard craps, is a simple version of the original craps game, and is normally played as an online private game. The biggest difference between crapless craps and original craps is that the shooter (person throwing the dice) is at a far greater disadvantage and has a house edge of 5.38%. Another difference is that this is one of the craps games in which a player can bet on rolling a 2, 3, 11 or 12 before a 7 is thrown. In crapless craps, 2 and 12 have odds of 11:2 and have a house edge of 7.143% while 3 and 11 have odds of 11:4 with a house edge of 6.25%.

New York Craps is one of the variations of craps played mostly in the Eastern coast of the US, true to its name. History states that this game was actually found and played in casinos in Yugoslavia, the UK and the Bahamas. In this craps variant, the house edge is greater than Las Vegas Craps or Bank craps. The table layout is also different, and is called a double-end-dealer table. This variation is different from the original craps game in several ways, but the primary difference is that New York craps does not allow Come or Don't Come bets. New York Craps Players bet on box numbers like 4, 5, 6, 8, 9, or 10. The overall house edge in New York craps is 5%.

In order to get around Californian laws barring the payout of a game being directly related to the roll of dice, Indian reservations have adapted the game to substitute cards for dice.

To replicate the original dice odds exactly without dice or possibility of card-counting, one scheme uses two shuffle machines each with just one deck of Ace through 6 each. Each machine selects one of the 6 cards at random and this is the roll. The selected cards are replaced and the decks are reshuffled for the next roll.

In one variation, two shoes are used, each containing some number of regular card decks that have been stripped down to just the Aces and deuces through sixes. The boxman simply deals one card from each shoe and that is the roll on which bets are settled. Since a card-counting scheme is easily devised to make use of the information of cards that have already been dealt, a relatively small portion (less than 50%) of each shoe is usually dealt in order to protect the house.

In a similar variation, cards representing dice are dealt directly from a continuous shuffling machine (CSM). Typically, the CSM will hold approximately 264 cards, or 44 sets of 1 through 6 spot cards. Two cards are dealt from the CSM for each roll. The game is played exactly as regular craps, but the roll distribution of the remaining cards in the CSM is slightly skewed from the normal symmetric distribution of dice.

Even if the dealer were to shuffle each roll back into the CSM, the effect of buffering a number of cards in the chute of the CSM provides information about the skew of the next roll. Analysis shows this type of game is biased towards the Don't Pass and Don't Come bets. A player betting Don't Pass and Don't Come every roll and laying 10x odds receives a 2% profit on the initial Don't Pass / Don't Come bet each roll. Using a counting system allows the player to attain a similar return at lower variance.

In this game variation, one red deck and one blue deck of six cards each (A through 6), and a red die and a blue die are used. Each deck is shuffled separately, usually by machine. Each card is then dealt onto the layout, into the 6 red and 6 blue numbered boxes. The shooter then shoots the dice. The red card in the red-numbered box corresponding to the red die, and the blue card in the blue-numbered box corresponding to the blue die are then turned over to form the roll on which bets are settled.

Another variation uses a red and a blue deck of 36 custom playing cards each. Each card has a picture of a two-die roll on it – from 1–1 to 6–6. The shooter shoots what looks like a red and a blue die, called "cubes". They are numbered such that they can never throw a pair, and that the blue one will show a higher value than the red one exactly half the time. One such scheme could be 222555 on the red die and 333444 on the blue die.

One card is dealt from the red deck and one is dealt from the blue deck. The shooter throws the "cubes" and the color of the cube that is higher selects the color of the card to be used to settle bets. On one such table, an additional one-roll prop bet was offered: If the card that was turned over for the "roll" was either 1–1 or 6–6, the other card was also turned over. If the other card was the "opposite" (6–6 or 1–1, respectively) of the first card, the bet paid 500:1 for this 647:1 proposition.

And additional variation uses a single set of 6 cards, and regular dice. The roll of the dice maps to the card in that position, and if a pair is rolled, then the mapped card is used twice, as a pair.

Recreational or informal playing of craps outside of a casino is referred to as street craps or private craps. The most notable difference between playing street craps and bank craps is that there is no bank or house to cover bets in street craps. Players must bet against each other by covering or fading each other's bets for the game to be played. If money is used instead of chips and depending on the laws of where it is being played, street craps can be an illegal form of gambling.

There are many variations of street craps. The simplest way is to either agree on or roll a number as the point, then roll the point again before rolling a seven. Unlike more complex proposition bets offered by casinos, street craps has more simplified betting options. The shooter is required to make either a Pass or a Don't Pass bet if he wants to roll the dice. Another player must choose to cover the shooter to create a stake for the game to continue.

If there are several players, the rotation of the player who must cover the shooter may change with the shooter (comparable to a blind in poker). The person covering the shooter will always bet against the shooter. For example, if the shooter made a "Pass" bet, the person covering the shooter would make a "Don't Pass" bet to win. Once the shooter is covered, other players may make Pass/Don't Pass bets, or any other proposition bets, as long as there is another player willing to cover.

Due to the random nature of the game, in popular culture a "crapshoot" is often used to describe an action with an unpredictable outcome.

The prayer or invocation "Baby needs a new pair of shoes!" is associated with shooting craps.

Floating craps is an illegal operation of craps. The term "floating" refers to the practice of the game's operators using portable tables and equipment to quickly move the game from location to location to stay ahead of the law enforcement authorities. The term may have originated in the 1930s when Benny Binion (later known for founding the downtown Las Vegas hotel Binion's) set up an illegal craps game utilizing tables created from portable crates for the Texas Centennial Exposition.

The 1950 Broadway musical "Guys and Dolls" features a major plot point revolving around a floating craps game.

In the 1950s and 1960s The Sands Hotel in Las Vegas had a craps table that floated in the swimming pool, as a joke reference to the notoriety of the term.

A Golden Arm is a craps player who rolls the dice for longer than one hour without losing. Likely the first known Golden Arm was Oahu native Stanley Fujitake, who rolled 118 times without sevening out in 3 hours and 6 minutes at the California Hotel and Casino on May 28, 1989.

The current record for length of a "hand" (successive rounds won by the same shooter) is 154 rolls including 25 passes by Patricia DeMauro of New Jersey, lasting 4 hours and 18 minutes, at the Borgata in Atlantic City, New Jersey, on May 23–24, 2009. She bested by over an hour the record held for almost 20 years – that of Fujitake.


Carl von Clausewitz

Carl Philipp Gottfried (or Gottlieb) von Clausewitz (; 1 July 1780 – 16 November 1831) was a Prussian general and military theorist who stressed the "moral" (in modern terms meaning psychological) and political aspects of waging war. His most notable work, (""On War""), though unfinished at his death, is considered a seminal treatise on military strategy and science.

Clausewitz was a realist in many different senses, including "realpolitik", and while in some respects a romantic, he also drew heavily on the rationalist ideas of the European Enlightenment.

Clausewitz stressed the dialectical interaction of diverse factors, noting how unexpected developments unfolding under the "fog of war" (i.e., in the face of incomplete, dubious, and often erroneous information and great fear, doubt, and excitement) call for rapid decisions by alert commanders. He saw history as a vital check on erudite abstractions that did not accord with experience. In contrast to the early work of Antoine-Henri Jomini, he argued that war could not be quantified or reduced to mapwork, geometry, and graphs. Clausewitz had many aphorisms, of which the most famous is "War is the continuation of policy with other means." (often misquoted as "... by other means").

Clausewitz's Christian names are sometimes given in non-German sources as "Karl", "Carl Philipp Gottlieb", or "Carl Maria". He spelled his own given name with a "C" in order to identify with the classical Western tradition; writers who use "Karl" are often seeking to emphasize their German (rather than European) identity. "Carl Philipp Gottfried" appears on Clausewitz's tombstone. Nonetheless, sources such as military historian Peter Paret and "Encyclopædia Britannica" continue to use Gottlieb instead of Gottfried.

Clausewitz was born on 1 July 1780 in Burg bei Magdeburg in the Prussian Duchy of Magdeburg as the fourth and youngest son of a family that made claims to a noble status which Carl accepted. Clausewitz's family claimed descent from the Barons of Clausewitz in Upper Silesia, though scholars question the connection. His grandfather, the son of a Lutheran pastor, had been a professor of theology. Clausewitz's father, once a lieutenant in the army of Frederick the Great, King of Prussia, held a minor post in the Prussian internal-revenue service. Clausewitz entered the Prussian military service at the age of twelve as a lance corporal, eventually attaining the rank of major general.

Clausewitz served in the Rhine campaigns (1793–1794) including the siege of Mainz, when the Prussian Army invaded France during the French Revolution, and fought in the Napoleonic Wars from 1806 to 1815. He entered the "Kriegsakademie" (also cited as "The German War School", the "Military Academy in Berlin", and the "Prussian Military Academy," later the "War College") in Berlin in 1801 (aged 21), probably studied the writings of the philosophers Immanuel Kant and/or Johann Gottlieb Fichte and Friedrich Schleiermacher and won the regard of General Gerhard von Scharnhorst, the future first chief-of-staff of the newly reformed Prussian Army (appointed 1809). Clausewitz, Hermann von Boyen (1771–1848) and Karl von Grolman (1777–1843) were among Scharnhorst's primary allies in his efforts to reform the Prussian army between 1807 and 1814.

Clausewitz served during the Jena Campaign as aide-de-camp to Prince August. At the Battle of Jena-Auerstedt on 14 October 1806—when Napoleon invaded Prussia and defeated the Prussian-Saxon army commanded by Karl Wilhelm Ferdinand, Duke of Brunswick—he was captured, one of the 25,000 prisoners taken that day as the Prussian army disintegrated. He was 26. Clausewitz was held prisoner with his prince in France from 1807 to 1808. Returning to Prussia, he assisted in the reform of the Prussian army and state. Johann Gottlieb Fichte wrote "On Machiavelli, as an Author, and Passages from His Writings" in June 1807. (""Über Machiavell, als Schriftsteller, und Stellen aus seinen Schriften"" ). Carl Clausewitz wrote an interesting and anonymous Letter to Fichte (1809) about his book on "Machiavelli." The letter was published in Fichte's "Verstreute kleine Schriften" 157–166. For an English translation of the letter see "Carl von Clausewitz Historical and Political Writings" Edited by: Peter Paret and D. Moran (1992).
On 10 December 1810, he married the socially prominent Countess Marie von Brühl, whom he had first met in 1803. She was a member of the noble German Brühl family originating in Thuringia. The couple moved in the highest circles, socialising with Berlin's political, literary, and intellectual élite. Marie was well-educated and politically well-connected—she played an important role in her husband's career progress and intellectual evolution. She also edited, published, and introduced his collected works.

Opposed to Prussia's enforced alliance with Napoleon, Clausewitz left the Prussian army and served in the Imperial Russian Army from 1812 to 1813 during the Russian campaign, taking part in the Battle of Borodino (1812). Like many Prussian officers serving in Russia, he joined the Russian–German Legion in 1813. In the service of the Russian Empire, Clausewitz helped negotiate the Convention of Tauroggen (1812), which prepared the way for the coalition of Prussia, Russia, and the United Kingdom that ultimately defeated Napoleon and his allies.

In 1815 the Russian-German Legion became integrated into the Prussian Army and Clausewitz re-entered Prussian service as a colonel. He was soon appointed chief-of-staff of Johann von Thielmann's III Corps. In that capacity he served at the Battle of Ligny and the Battle of Wavre during the Waterloo campaign in 1815. An army led personally by Napoleon defeated the Prussians at Ligny (south of Mont-Saint-Jean and the village of Waterloo) on 16 June 1815, but they withdrew in good order. Napoleon's failure to destroy the Prussian forces led to his defeat a few days later at the Battle of Waterloo (18 June 1815), when the Prussian forces arrived on his right flank late in the afternoon to support the Anglo-Dutch-Belgian forces pressing his front. Napoleon had convinced his troops that the field grey uniforms were those of Marshal Grouchy's grenadiers. Clausewitz's unit fought heavily outnumbered at Wavre (18–19 June 1815), preventing large reinforcements from reaching Napoleon at Waterloo. After the war, Clausewitz served as the director of the "Kriegsakademie", where he served until 1830. In that year he returned to active duty with the army. Soon afterward, the outbreak of several revolutions around Europe and a crisis in Poland appeared to presage another major European war. Clausewitz was appointed chief of staff of the only army Prussia was able to mobilise in this emergency, which was sent to the Polish border. Its commander, Gneisenau, died of cholera (August 1831), and Clausewitz took command of the Prussian army's efforts to construct a to contain the great cholera outbreak (the first time cholera had appeared in modern heartland Europe, causing a continent-wide panic). Clausewitz himself died of the same disease shortly afterwards, on 16 November 1831.

His widow edited, published, and wrote the introduction to his "magnum opus" on the philosophy of war in 1832. (He had started working on the text in 1816 but had not completed it.) She wrote the preface for "On War" and had published most of his collected works by 1835. She died in January 1836.

Clausewitz was a professional combat soldier who was involved in numerous military campaigns, but he is famous primarily as a military theorist interested in the examination of war, utilising the campaigns of Frederick the Great and Napoleon as frames of reference for his work. He wrote a careful, systematic, philosophical examination of war in all its aspects. The result was his principal book, "On War", a major work on the philosophy of war. It was unfinished when Clausewitz died and contains material written at different stages in his intellectual evolution, producing some significant contradictions between different sections. The sequence and precise character of that evolution is a source of much debate as to the exact meaning behind some seemingly contradictory observations in discussions pertinent to the tactical, operational and strategic levels of war, for example (though many of these apparent contradictions are simply the result of his dialectical method). Clausewitz constantly sought to revise the text, particularly between 1827 and his departure on his last field assignments, to include more material on "people's war" and forms of war other than high-intensity warfare between states, but relatively little of this material was included in the book. Soldiers before this time had written treatises on various military subjects, but none had undertaken a great philosophical examination of war on the scale of those written by Clausewitz and Leo Tolstoy, both of whom were inspired by the events of the Napoleonic Era.

Clausewitz's work is still studied today, demonstrating its continued relevance. More than sixteen major English-language books that focused specifically on his work were published between 2005 and 2014, whereas his 19th-century rival Jomini has faded from influence. The historian Lynn Montross said that this outcome "may be explained by the fact that Jomini produced a system of war, Clausewitz a philosophy. The one has been outdated by new weapons, the other still influences the strategy behind those weapons." Jomini did not attempt to define war but Clausewitz did, providing (and dialectically comparing) a number of definitions. The first is his dialectical thesis: "War is thus an act of force to compel our enemy to do our will." The second, often treated as Clausewitz's 'bottom line,' is in fact merely his dialectical antithesis: "War is merely the continuation of policy with other means." The synthesis of his dialectical examination of the nature of war is his famous "trinity," saying that war is "a fascinating trinity—composed of primordial violence, hatred, and enmity, which are to be regarded as a blind natural force; the play of chance and probability, within which the creative spirit is free to roam; and its element of subordination, as an instrument of policy, which makes it subject to pure reason." Christopher Bassford says the best shorthand for Clausewitz's trinity should be something like "violent emotion/chance/rational calculation." However, it is frequently presented as "people/army/government," a misunderstanding based on a later paragraph in the same section. This misrepresentation was popularised by U.S. Army Colonel Harry Summers' Vietnam-era interpretation, facilitated by weaknesses in the 1976 Howard/Paret translation.

The degree to which Clausewitz managed to revise his manuscript to reflect that synthesis is the subject of much debate. His final reference to war and "Politik", however, goes beyond his widely quoted antithesis: "War is simply the continuation of political intercourse with the addition of other means. We deliberately use the phrase 'with the addition of other means' because we also want to make it clear that war in itself does not suspend political intercourse or change it into something entirely different. In essentials that intercourse continues, irrespective of the means it employs. The main lines along which military events progress, and to which they are restricted, are political lines that continue throughout the war into the subsequent peace."

Clausewitz introduced systematic philosophical contemplation into Western military thinking, with powerful implications not only for historical and analytical writing but also for practical policy, military instruction, and operational planning. He relied on his own experiences, contemporary writings about Napoleon, and on deep historical research. His historiographical approach is evident in his first extended study, written when he was 25, of the Thirty Years' War. He rejects the Enlightenment's view of the war as a chaotic muddle and instead explains its drawn-out operations by the economy and technology of the age, the social characteristics of the troops, and the commanders' politics and psychology. In "On War", Clausewitz sees all wars as the sum of decisions, actions, and reactions in an uncertain and dangerous context, and also as a socio-political phenomenon. He also stressed the complex nature of war, which encompasses both the socio-political and the operational and stresses the primacy of state policy. (One should be careful not to limit his observations on war to war between states, however, as he certainly discusses other kinds of protagonists).

The word "strategy" had only recently come into usage in modern Europe, and Clausewitz's definition is quite narrow: "the use of engagements for the object of war" (which many today would call "the operational level" of war). Clausewitz conceived of war as a political, social, and military phenomenon which might—depending on circumstances—involve the entire population of a political entity at war. In any case, Clausewitz saw military force as an instrument that states and other political actors use to pursue the ends of their policy, in a dialectic between opposing wills, each with the aim of imposing his policies and will upon his enemy.

Clausewitz's emphasis on the inherent superiority of the defense suggests that habitual aggressors are likely to end up as failures. The inherent superiority of the defense obviously does not mean that the defender will always win, however: there are other asymmetries to be considered. He was interested in co-operation between the regular army and militia or partisan forces, or citizen soldiers, as one possible—sometimes the only—method of defense. In the circumstances of the Wars of the French Revolution and those with Napoleon, which were energised by a rising spirit of nationalism, he emphasised the need for states to involve their entire populations in the conduct of war. This point is especially important, as these wars demonstrated that such energies could be of decisive importance and for a time led to a democratisation of the armed forces much as universal suffrage democratised politics.

While Clausewitz was intensely aware of the value of intelligence at all levels, he was also very skeptical of the accuracy of much military intelligence: "Many intelligence reports in war are contradictory; even more are false, and most are uncertain... In short, most intelligence is false." This circumstance is generally described as part of the fog of war. Such skeptical comments apply only to intelligence at the tactical and operational levels; at the strategic and political levels he constantly stressed the requirement for the best possible understanding of what today would be called strategic and political intelligence. His conclusions were influenced by his experiences in the Prussian Army, which was often in an intelligence fog due partly to the superior abilities of Napoleon's system but even more simply to the nature of war. Clausewitz acknowledges that friction creates enormous difficulties for the realization of any plan, and the "fog of war" hinders commanders from knowing what is happening. It is precisely in the context of this challenge that he develops the concept of military genius, whose capabilities are seen above all in the execution of operations. 'Military genius' is not simply a matter of intellect, but a combination of qualities of intellect, experience, personality, and temperament (and there are many possible such combinations) that create a very highly developed mental aptitude for the waging of war.

Key ideas discussed in "On War" include:

Clausewitz used a dialectical method to construct his argument, leading to frequent misinterpretation of his ideas. British military theorist B. H. Liddell Hart contends that the enthusiastic acceptance by the Prussian military establishment—especially Moltke the Elder, a former student of Clausewitz —of what they believed to be Clausewitz's ideas, and the subsequent widespread adoption of the Prussian military system worldwide, had a deleterious effect on military theory and practice, due to their egregious misinterpretation of his ideas:

As described by Christopher Bassford, then-professor of strategy at the National War College of the United States:

Another example of this confusion is the idea that Clausewitz was a proponent of total war as used in the Third Reich's propaganda in the 1940s. In fact, Clausewitz never used the term "total war": rather, he discussed "absolute war," a concept which evolved into the much more abstract notion of "ideal war" discussed at the very beginning of —the purely "logical" result of the forces underlying a "pure," Platonic "ideal" of war. In what he called a "logical fantasy," war cannot be waged in a limited way: the rules of competition will force participants to use all means at their disposal to achieve victory. But in the "real world," he said, such rigid logic is unrealistic and dangerous. As a practical matter, the military objectives in "real" war that support political objectives generally fall into two broad types: limited aims or the effective "disarming" of the enemy "to render [him] politically helpless or militarily impotent. Thus, the complete defeat of the enemy may not be necessary, desirable, or even possible.

In modern times the reconstruction of Clausewitzian theory has been a matter of much dispute. One analysis was that of Panagiotis Kondylis, a Greek writer and philosopher, who opposed the interpretations of Raymond Aron in "Penser la Guerre, Clausewitz," and other liberal writers. According to Aron, Clausewitz was one of the first writers to condemn the militarism of the Prussian general staff and its war-proneness, based on Clausewitz's argument that "war is a continuation of policy by other means." In "Theory of War," Kondylis claims that this is inconsistent with Clausewitzian thought. He claims that Clausewitz was morally indifferent to war (though this probably reflects a lack of familiarity with personal letters from Clausewitz, which demonstrate an acute awareness of war's tragic aspects) and that his advice regarding politics' dominance over the conduct of war has nothing to do with pacifist ideas.

Other notable writers who have studied Clausewitz's texts and translated them into English are historians Peter Paret of the Institute for Advanced Study and Sir Michael Howard. Howard and Paret edited the most widely used edition of "On War" (Princeton University Press, 1976/1984) and have produced comparative studies of Clausewitz and other theorists, such as Tolstoy. Bernard Brodie's "A Guide to the Reading of "On War,"" in the 1976 Princeton translation, expressed his interpretations of the Prussian's theories and provided students with an influential synopsis of this vital work. The 1873 translation by Colonel James John Graham was heavily—and controversially—edited by the philosopher, musician, and game theorist Anatol Rapoport.

The British military historian John Keegan attacked Clausewitz's theory in his book "A History of Warfare". Keegan argued that Clausewitz assumed the existence of states, yet 'war antedates the state, diplomacy and strategy by many millennia.'

Clausewitz died without completing "Vom Kriege," but despite this his ideas have been widely influential in military theory and have had a strong influence on German military thought specifically. Later Prussian and German generals, such as Helmuth Graf von Moltke, were clearly influenced by Clausewitz: Moltke's widely quoted statement that "No operational plan extends with high certainty beyond the first encounter with the main enemy force" is a classic reflection of Clausewitz's insistence on the roles of chance, friction, "fog," uncertainty, and interactivity in war.

Clausewitz's influence spread to British thinking as well, though at first more as a historian and analyst than as a theorist. See for example Wellington's extended essay discussing Clausewitz's study of the Campaign of 1815—Wellington's only serious written discussion of the battle, which was widely discussed in 19th-century Britain. Clausewitz's broader thinking came to the fore following Britain's military embarrassments in the Boer War (1899–1902). One example of a heavy Clausewitzian influence in that era is Spenser Wilkinson, journalist, the first Chichele Professor of Military History at Oxford University, and perhaps the most prominent military analyst in Britain from until well into the interwar period. Another is naval historian Julian Corbett (1854–1922), whose work reflected a deep if idiosyncratic adherence to Clausewitz's concepts and frequently an emphasis on Clausewitz's ideas about 'limited objectives' and the inherent strengths of the defensive form of war. Corbett's practical strategic views were often in prominent public conflict with Wilkinson's—see, for example, Wilkinson's article "Strategy at Sea", "The Morning Post", 12 February 1912. Following the First World War, however, the influential British military commentator B. H. Liddell Hart in the 1920s erroneously attributed to him the doctrine of "total war" that during the First World War had been embraced by many European general staffs and emulated by the British. More recent scholars typically see that war as so confused in terms of political rationale that it in fact contradicts much of "On War." That view assumes, however, a set of values as to what constitutes "rational" political objectives—in this case, values not shaped by the fervid Social Darwinism that was rife in 1914 Europe. One of the most influential British Clausewitzians today is Colin S. Gray; historian Hew Strachan (like Wilkinson also the Chichele Professor of Military History at Oxford University, since 2001) has been an energetic proponent of the "study" of Clausewitz, but his own views on Clausewitz's ideas are somewhat ambivalent.

With some interesting exceptions (e.g., John McAuley Palmer, Robert M. Johnston, Hoffman Nickerson), Clausewitz had little influence on American military thought before 1945 other than via British writers, though Generals Eisenhower and Patton were avid readers of English translations. He did influence Karl Marx, Friedrich Engels, Vladimir Lenin, Leon Trotsky, Võ Nguyên Giáp, Ferdinand Foch, and Mao Zedong, and thus the Communist Soviet and Chinese traditions, as Lenin emphasized the inevitability of wars among capitalist states in the age of imperialism and presented the armed struggle of the working class as the only path toward the eventual elimination of war. Because Lenin was an admirer of Clausewitz and called him "one of the great military writers," his influence on the Red Army was immense. The Russian historian A.N. Mertsalov commented that "It was an irony of fate that the view in the USSR was that it was Lenin who shaped the attitude towards Clausewitz, and that Lenin's dictum that war is a continuation of politics is taken from the work of this [allegedly] anti-humanist anti-revolutionary." The American mathematician Anatol Rapoport wrote in 1968 that Clausewitz as interpreted by Lenin formed the basis of all Soviet military thinking since 1917, and quoted the remarks by Marshal V.D. Sokolovsky:

Henry A. Kissinger, however, described Lenin's approach as being that politics is a continuation of war by other means, thus turning Clausewitz's argument "on its head."

Rapoport argued that:

Clausewitz directly influenced Mao Zedong, who read "On War" in 1938 and organised a seminar on Clausewitz for the Party leadership in Yan'an. Thus the "Clausewitzian" content in many of Mao's writings is not merely a regurgitation of Lenin but reflects Mao's own study. The idea that war involves inherent "friction" that distorts, to a greater or lesser degree, all prior arrangements, has become common currency in fields such as business strategy and sport. The phrase "fog of war" derives from Clausewitz's stress on how confused warfare can seem while one is immersed within it. The term center of gravity, used in a military context derives from Clausewitz's usage, which he took from Newtonian mechanics. In U.S. military doctrine, "center of gravity" refers to the basis of an opponent's power at the operational, strategic, or political level, though this is only one aspect of Clausewitz's use of the term.

The deterrence strategy of the United States in the 1950s was closely inspired by President Dwight Eisenhower's reading of Clausewitz as a young officer in the 1920s. Eisenhower was greatly impressed by Clausewitz's example of a theoretical, idealized "absolute war" in "Vom Kriege" as a way of demonstrating how absurd it would be to attempt such a strategy in practice. For Eisenhower, the age of nuclear weapons had made what was for Clausewitz in the early-19th century only a theoretical vision an all too real possibility in the mid-20th century. From Eisenhower's viewpoint, the best deterrent to war was to show the world just how appalling and horrific a nuclear "absolute war" would be if it should ever occur, hence a series of much-publicized nuclear tests in the Pacific, giving first priority in the defense budget to nuclear weapons and to their delivery-systems over conventional weapons, and making repeated statements in public that the United States was able and willing at all times to use nuclear weapons. In this way, through the massive retaliation doctrine and the closely related foreign-policy concept of brinkmanship, Eisenhower hoped to hold out a credible vision of Clausewitzian nuclear "absolute war" in order to deter the Soviet Union and/or China from ever risking a war or even conditions that might lead to a war with the United States.

After 1970, some theorists claimed that nuclear proliferation made Clausewitzian concepts obsolete after the 20th-century period in which they dominated the world. John E. Sheppard, Jr., argues that by developing nuclear weapons, state-based conventional armies simultaneously both perfected their original purpose, to destroy a mirror image of themselves, and made themselves obsolete. No two powers have used nuclear weapons against each other, instead using diplomacy, conventional means, or proxy wars to settle disputes. If such a conflict did occur, presumably both combatants would be annihilated. Heavily influenced by the war in Vietnam and by antipathy to American strategist Henry Kissinger, the American biologist, musician, and game-theorist Anatol Rapoport argued in 1968 that a Clausewitzian view of war was not only obsolete in the age of nuclear weapons, but also highly dangerous as it promoted a "zero-sum paradigm" to international relations and a "dissolution of rationality" amongst decision-makers.

The end of the 20th century and the beginning of the 21st century have seen many instances of state armies attempting to suppress insurgencies and terrorism, and engaging in other forms of asymmetrical warfare. Clausewitz did not focus solely on wars between countries with well-defined armies. The era of the French Revolution and Napoleon was full of revolutions, rebellions, and violence by "non-state actors" - witness the wars in the French Vendée and in Spain. Clausewitz wrote a series of "Lectures on Small War" and studied the rebellion in the Vendée (1793–1796) and the Tyrolean uprising of 1809. In his famous "Bekenntnisdenkschrift" of 1812 he called for a "Spanish war in Germany" and laid out a comprehensive guerrilla strategy to be waged against Napoleon. In "On War" he included a famous chapter on "The People in Arms".

One prominent critic of Clausewitz is the Israeli military historian Martin van Creveld. In his 1991 book "The Transformation of War", Creveld argued that Clausewitz's famous "Trinity" of people, army, and government was an obsolete socio-political construct based on the state, which was rapidly passing from the scene as the key player in war, and that he (Creveld) had constructed a new "non-trinitarian" model for modern warfare. Creveld's work has had great influence. Daniel Moran replied, 'The most egregious misrepresentation of Clausewitz's famous metaphor must be that of Martin van Creveld, who has declared Clausewitz to be an apostle of Trinitarian War, by which he means, incomprehensibly, a war of 'state against state and army against army,' from which the influence of the people is entirely excluded." Christopher Bassford went further, noting that one need only "read" the paragraph in which Clausewitz defined his Trinity to see "that the words 'people,' 'army,' and 'government' appear nowhere at all in the list of the Trinity's components... Creveld's and Keegan's assault on Clausewitz's Trinity is not only a classic 'blow into the air,' i.e., an assault on a position Clausewitz doesn't occupy. It is also a pointless attack on a concept that is quite useful in its own right. In any case, their failure to read the actual wording of the theory they so vociferously attack, and to grasp its deep relevance to the phenomena they describe, is hard to credit."

Some have gone further and suggested that Clausewitz's best-known aphorism, that war is a continuation of policy with other means, is not only irrelevant today but also inapplicable historically. For an opposing view see the sixteen essays presented in "Clausewitz in the Twenty-First Century" edited by Hew Strachan and Andreas Herberg-Rothe.

In military academies, schools, and universities worldwide, Clausewitz's "Vom Kriege" is often (usually in translation) mandatory reading.

Some theorists of management look to Clausewitz - just as some look to Sun Tzu - to bolster ideas on the concept of leadership.

August Otto Rühle von Lilienstern – Prussian officer from whom Clausewitz allegedly took, without acknowledgement, several important ideas (including that about war as pursuing political aims) made famous in "On War". However, substantial basis for assuming common influences exist, most prominently Scharnhorst, who was Clausewitz's "second father" and professional mentor. This provokes skepticism of the claim the ideas were plagiarized from Lilienstern.
Informational notes
Citations



Common Lisp

Common Lisp (CL) is a dialect of the Lisp programming language, published in American National Standards Institute (ANSI) standard document "ANSI INCITS 226-1994 (S2018)" (formerly "X3.226-1994 (R1999)"). The Common Lisp HyperSpec, a hyperlinked HTML version, has been derived from the ANSI Common Lisp standard.

The Common Lisp language was developed as a standardized and improved successor of Maclisp. By the early 1980s several groups were already at work on diverse successors to MacLisp: Lisp Machine Lisp (aka ZetaLisp), Spice Lisp, NIL and S-1 Lisp. Common Lisp sought to unify, standardise, and extend the features of these MacLisp dialects. Common Lisp is not an implementation, but rather a language specification. Several implementations of the Common Lisp standard are available, including free and open-source software and proprietary products.
Common Lisp is a general-purpose, multi-paradigm programming language. It supports a combination of procedural, functional, and object-oriented programming paradigms. As a dynamic programming language, it facilitates evolutionary and incremental software development, with iterative compilation into efficient run-time programs. This incremental development is often done interactively without interrupting the running application.

It also supports optional type annotation and casting, which can be added as necessary at the later profiling and optimization stages, to permit the compiler to generate more efficient code. For instance, codice_1 can hold an unboxed integer in a range supported by the hardware and implementation, permitting more efficient arithmetic than on big integers or arbitrary precision types. Similarly, the compiler can be told on a per-module or per-function basis which type of safety level is wanted, using "optimize" declarations.

Common Lisp includes CLOS, an object system that supports multimethods and method combinations. It is often implemented with a Metaobject Protocol.

Common Lisp is extensible through standard features such as "Lisp macros" (code transformations) and "reader macros" (input parsers for characters).

Common Lisp provides partial backwards compatibility with Maclisp and John McCarthy's original Lisp. This allows older Lisp software to be ported to Common Lisp.

Work on Common Lisp started in 1981 after an initiative by ARPA manager Bob Engelmore to develop a single community standard Lisp dialect. Much of the initial language design was done via electronic mail. In 1982, Guy L. Steele Jr. gave the first overview of Common Lisp at the 1982 ACM Symposium on LISP and functional programming.

The first language documentation was published in 1984 as Common Lisp the Language (known as CLtL1), first edition. A second edition (known as CLtL2), published in 1990, incorporated many changes to the language, made during the ANSI Common Lisp standardization process: extended LOOP syntax, the Common Lisp Object System, the Condition System for error handling, an interface to the pretty printer and much more. But CLtL2 does not describe the final ANSI Common Lisp standard and thus is not a documentation of ANSI Common Lisp. The final ANSI Common Lisp standard then was published in 1994. Since then no update to the standard has been published. Various extensions and improvements to Common Lisp (examples are Unicode, Concurrency, CLOS-based IO) have been provided by implementations and libraries.

Common Lisp is a dialect of Lisp. It uses S-expressions to denote both code and data structure. Function calls, macro forms and special forms are written as lists, with the name of the operator first, as in these examples:

Common Lisp has many data types.

"Number" types include integers, ratios, floating-point numbers, and complex numbers. Common Lisp uses bignums to represent numerical values of arbitrary size and precision. The ratio type represents fractions exactly, a facility not available in many languages. Common Lisp automatically coerces numeric values among these types as appropriate.

The Common Lisp "character" type is not limited to ASCII characters. Most modern implementations allow Unicode characters.

The "symbol" type is common to Lisp languages, but largely unknown outside them. A symbol is a unique, named data object with several parts: name, value, function, property list, and package. Of these, "value cell" and "function cell" are the most important. Symbols in Lisp are often used similarly to identifiers in other languages: to hold the value of a variable; however there are many other uses. Normally, when a symbol is evaluated, its value is returned. Some symbols evaluate to themselves, for example, all symbols in the keyword package are self-evaluating. Boolean values in Common Lisp are represented by the self-evaluating symbols T and NIL. Common Lisp has namespaces for symbols, called 'packages'.

A number of functions are available for rounding scalar numeric values in various ways. The function codice_2 rounds the argument to the nearest integer, with halfway cases rounded to the even integer. The functions codice_3, codice_4, and codice_5 round towards zero, down, or up respectively. All these functions return the discarded fractional part as a secondary value. For example, codice_6 yields −3, 0.5; codice_7 yields −2, −0.5; codice_8 yields 2, 0.5; and codice_9 yields 4, −0.5.

"Sequence" types in Common Lisp include lists, vectors, bit-vectors, and strings. There are many operations that can work on any sequence type.

As in almost all other Lisp dialects, "lists" in Common Lisp are composed of "conses", sometimes called "cons cells" or "pairs". A cons is a data structure with two slots, called its "car" and "cdr". A list is a linked chain of conses or the empty list. Each cons's car refers to a member of the list (possibly another list). Each cons's cdr refers to the next cons—except for the last cons in a list, whose cdr refers to the codice_10 value. Conses can also easily be used to implement trees and other complex data structures; though it is usually advised to use structure or class instances instead. It is also possible to create circular data structures with conses.

Common Lisp supports multidimensional "arrays", and can dynamically resize "adjustable" arrays if required. Multidimensional arrays can be used for matrix mathematics. A "vector" is a one-dimensional array. Arrays can carry any type as members (even mixed types in the same array) or can be specialized to contain a specific type of members, as in a vector of bits. Usually, only a few types are supported. Many implementations can optimize array functions when the array used is type-specialized. Two type-specialized array types are standard: a "string" is a vector of characters, while a "bit-vector" is a vector of bits.

"Hash tables" store associations between data objects. Any object may be used as key or value. Hash tables are automatically resized as needed.

"Packages" are collections of symbols, used chiefly to separate the parts of a program into namespaces. A package may "export" some symbols, marking them as part of a public interface. Packages can use other packages.

"Structures", similar in use to C structs and Pascal records, represent arbitrary complex data structures with any number and type of fields (called "slots"). Structures allow single-inheritance.

"Classes" are similar to structures, but offer more dynamic features and multiple-inheritance. (See CLOS). Classes have been added late to Common Lisp and there is some conceptual overlap with structures. Objects created of classes are called "Instances". A special case is Generic Functions. Generic Functions are both functions and instances.

Common Lisp supports first-class functions. For instance, it is possible to write functions that take other functions as arguments or return functions as well. This makes it possible to describe very general operations.

The Common Lisp library relies heavily on such higher-order functions. For example, the codice_11 function takes a relational operator as an argument and key function as an optional keyword argument. This can be used not only to sort any type of data, but also to sort data structures according to a key.
The evaluation model for functions is very simple. When the evaluator encounters a form codice_12 then it presumes that the symbol named f is one of the following:


If f is the name of a function, then the arguments a1, a2, ..., an are evaluated in left-to-right order, and the function is found and invoked with those values supplied as parameters.

The macro codice_14 defines functions where a function definition gives the name of the function, the names of any arguments, and a function body:
Function definitions may include compiler directives, known as "declarations", which provide hints to the compiler about optimization settings or the data types of arguments. They may also include "documentation strings" (docstrings), which the Lisp system may use to provide interactive documentation:
Anonymous functions (function literals) are defined using codice_13 expressions, e.g. codice_16 for a function that squares its argument. Lisp programming style frequently uses higher-order functions for which it is useful to provide anonymous functions as arguments.

Local functions can be defined with codice_17 and codice_18.
There are several other operators related to the definition and manipulation of functions. For instance, a function may be compiled with the codice_19 operator. (Some Lisp systems run functions using an interpreter by default unless instructed to compile; others compile every function).

The macro codice_20 defines generic functions. Generic functions are a collection of methods.
The macro codice_21 defines methods.

Methods can specialize their parameters over CLOS "standard classes", "system classes", "structure classes" or individual objects. For many types, there are corresponding "system classes".

When a generic function is called, multiple-dispatch will determine the effective method to use.

Generic Functions are also a first class data type. There are many more features to Generic Functions and Methods than described above.

The namespace for function names is separate from the namespace for data variables. This is a key difference between Common Lisp and Scheme. For Common Lisp, operators that define names in the function namespace include codice_14, codice_17, codice_18, codice_21 and codice_20.

To pass a function by name as an argument to another function, one must use the codice_27 special operator, commonly abbreviated as codice_28. The first codice_11 example above refers to the function named by the symbol codice_30 in the function namespace, with the code codice_31. Conversely, to call a function passed in such a way, one would use the codice_32 operator on the argument.

Scheme's evaluation model is simpler: there is only one namespace, and all positions in the form are evaluated (in any order) – not just the arguments. Code written in one dialect is therefore sometimes confusing to programmers more experienced in the other. For instance, many Common Lisp programmers like to use descriptive variable names such as "list" or "string" which could cause problems in Scheme, as they would locally shadow function names.

Whether a separate namespace for functions is an advantage is a source of contention in the Lisp community. It is usually referred to as the "Lisp-1 vs. Lisp-2 debate". Lisp-1 refers to Scheme's model and Lisp-2 refers to Common Lisp's model. These names were coined in a 1988 paper by Richard P. Gabriel and Kent Pitman, which extensively compares the two approaches.

Common Lisp supports the concept of "multiple values", where any expression always has a single "primary value", but it might also have any number of "secondary values", which might be received and inspected by interested callers. This concept is distinct from returning a list value, as the secondary values are fully optional, and passed via a dedicated side channel. This means that callers may remain entirely unaware of the secondary values being there if they have no need for them, and it makes it convenient to use the mechanism for communicating information that is sometimes useful, but not always necessary. For example,




Multiple values are supported by a handful of standard forms, most common of which are the codice_35 special form for accessing secondary values and codice_36 for returning multiple values:

Other data types in Common Lisp include:


Like programs in many other programming languages, Common Lisp programs make use of names to refer to variables, functions, and many other kinds of entities. Named references are subject to scope.

The association between a name and the entity which the name refers to is called a binding.

Scope refers to the set of circumstances in which a name is determined to have a particular binding.

The circumstances which determine scope in Common Lisp include:


To understand what a symbol refers to, the Common Lisp programmer must know what kind of reference is being expressed, what kind of scope it uses if it is a variable reference (dynamic versus lexical scope), and also the run-time situation: in what environment is the reference resolved, where was the binding introduced into the environment, et cetera.

Some environments in Lisp are globally pervasive. For instance, if a new type is defined, it is known everywhere thereafter. References to that type look it up in this global environment.

One type of environment in Common Lisp is the dynamic environment. Bindings established in this environment have dynamic extent, which means that a binding is established at the start of the execution of some construct, such as a codice_51 block, and disappears when that construct finishes executing: its lifetime is tied to the dynamic activation and deactivation of a block. However, a dynamic binding is not just visible within that block; it is also visible to all functions invoked from that block. This type of visibility is known as indefinite scope. Bindings which exhibit dynamic extent (lifetime tied to the activation and deactivation of a block) and indefinite scope (visible to all functions which are called from that block) are said to have dynamic scope.

Common Lisp has support for dynamically scoped variables, which are also called special variables. Certain other kinds of bindings are necessarily dynamically scoped also, such as restarts and catch tags. Function bindings cannot be dynamically scoped using codice_17 (which only provides lexically scoped function bindings), but function objects (a first-level object in Common Lisp) can be assigned to dynamically scoped variables, bound using codice_51 in dynamic scope, then called using codice_32 or codice_57.

Dynamic scope is extremely useful because it adds referential clarity and discipline to global variables. Global variables are frowned upon in computer science as potential sources of error, because they can give rise to ad-hoc, covert channels of communication among modules that lead to unwanted, surprising interactions.

In Common Lisp, a special variable which has only a top-level binding behaves just like a global variable in other programming languages. A new value can be stored into it, and that value simply replaces what is in the top-level binding. Careless replacement of the value of a global variable is at the heart of bugs caused by the use of global variables. However, another way to work with a special variable is to give it a new, local binding within an expression. This is sometimes referred to as "rebinding" the variable. Binding a dynamically scoped variable temporarily creates a new memory location for that variable, and associates the name with that location. While that binding is in effect, all references to that variable refer to the new binding; the previous binding is hidden. When execution of the binding expression terminates, the temporary memory location is gone, and the old binding is revealed, with the original value intact. Of course, multiple dynamic bindings for the same variable can be nested.

In Common Lisp implementations which support multithreading, dynamic scopes are specific to each thread of execution. Thus special variables serve as an abstraction for thread local storage. If one thread rebinds a special variable, this rebinding has no effect on that variable in other threads. The value stored in a binding can only be retrieved by the thread which created that binding. If each thread binds some special variable codice_58, then codice_58 behaves like thread-local storage. Among threads which do not rebind codice_58, it behaves like an ordinary global: all of these threads refer to the same top-level binding of codice_58.

Dynamic variables can be used to extend the execution context with additional context information which is implicitly passed from function to function without having to appear as an extra function parameter. This is especially useful when the control transfer has to pass through layers of unrelated code, which simply cannot be extended with extra parameters to pass the additional data. A situation like this usually calls for a global variable. That global variable must be saved and restored, so that the scheme doesn't break under recursion: dynamic variable rebinding takes care of this. And that variable must be made thread-local (or else a big mutex must be used) so the scheme doesn't break under threads: dynamic scope implementations can take care of this also.

In the Common Lisp library, there are many standard special variables. For instance, all standard I/O streams are stored in the top-level bindings of well-known special variables. The standard output stream is stored in *standard-output*.

Suppose a function foo writes to standard output:
To capture its output in a character string, *standard-output* can be bound to a string stream and called:

Common Lisp supports lexical environments. Formally, the bindings in a lexical environment have lexical scope and may have either an indefinite extent or dynamic extent, depending on the type of namespace. Lexical scope means that visibility is physically restricted to the block in which the binding is established. References which are not textually (i.e. lexically) embedded in that block simply do not see that binding.

The tags in a TAGBODY have lexical scope. The expression (GO X) is erroneous if it is not embedded in a TAGBODY which contains a label X. However, the label bindings disappear when the TAGBODY terminates its execution, because they have dynamic extent. If that block of code is re-entered by the invocation of a lexical closure, it is invalid for the body of that closure to try to transfer control to a tag via GO:

When the TAGBODY is executed, it first evaluates the setf form which stores a function in the special variable *stashed*. Then the (go end-label) transfers control to end-label, skipping the code (print "Hello"). Since end-label is at the end of the tagbody, the tagbody terminates, yielding NIL. Suppose that the previously remembered function is now called:
This situation is erroneous. One implementation's response is an error condition containing the message, "GO: tagbody for tag SOME-LABEL has already been left". The function tried to evaluate (go some-label), which is lexically embedded in the tagbody, and resolves to the label. However, the tagbody isn't executing (its extent has ended), and so the control transfer cannot take place.

Local function bindings in Lisp have lexical scope, and variable bindings also have lexical scope by default. By contrast with GO labels, both of these have indefinite extent. When a lexical function or variable binding is established, that binding continues to exist for as long as references to it are possible, even after the construct which established that binding has terminated. References to lexical variables and functions after the termination of their establishing construct are possible thanks to lexical closures.

Lexical binding is the default binding mode for Common Lisp variables. For an individual symbol, it can be switched to dynamic scope, either by a local declaration, by a global declaration. The latter may occur implicitly through the use of a construct like DEFVAR or DEFPARAMETER. It is an important convention in Common Lisp programming that special (i.e. dynamically scoped) variables have names which begin and end with an asterisk sigil codice_62 in what is called the "earmuff convention". If adhered to, this convention effectively creates a separate namespace for special variables, so that variables intended to be lexical are not accidentally made special.

Lexical scope is useful for several reasons.

Firstly, references to variables and functions can be compiled to efficient machine code, because the run-time environment structure is relatively simple. In many cases it can be optimized to stack storage, so opening and closing lexical scopes has minimal overhead. Even in cases where full closures must be generated, access to the closure's environment is still efficient; typically each variable becomes an offset into a vector of bindings, and so a variable reference becomes a simple load or store instruction with a base-plus-offset addressing mode.

Secondly, lexical scope (combined with indefinite extent) gives rise to the lexical closure, which in turn creates a whole paradigm of programming centered around the use of functions being first-class objects, which is at the root of functional programming.

Thirdly, perhaps most importantly, even if lexical closures are not exploited, the use of lexical scope isolates program modules from unwanted interactions. Due to their restricted visibility, lexical variables are private. If one module A binds a lexical variable X, and calls another module B, references to X in B will not accidentally resolve to the X bound in A. B simply has no access to X. For situations in which disciplined interactions through a variable are desirable, Common Lisp provides special variables. Special variables allow for a module A to set up a binding for a variable X which is visible to another module B, called from A. Being able to do this is an advantage, and being able to prevent it from happening is also an advantage; consequently, Common Lisp supports both lexical and dynamic scope.

A "macro" in Lisp superficially resembles a function in usage. However, rather than representing an expression which is evaluated, it represents a transformation of the program source code. The macro gets the source it surrounds as arguments, binds them to its parameters and computes a new source form. This new form can also use a macro. The macro expansion is repeated until the new source form does not use a macro. The final computed form is the source code executed at runtime.

Typical uses of macros in Lisp:


Various standard Common Lisp features also need to be implemented as macros, such as:


Macros are defined by the "defmacro" macro. The special operator "macrolet" allows the definition of local (lexically scoped) macros. It is also possible to define macros for symbols using "define-symbol-macro" and "symbol-macrolet".

Paul Graham's book On Lisp describes the use of macros in Common Lisp in detail. Doug Hoyte's book Let Over Lambda extends the discussion on macros, claiming "Macros are the single greatest advantage that lisp has as a programming language and the single greatest advantage of any programming language." Hoyte provides several examples of iterative development of macros.

Macros allow Lisp programmers to create new syntactic forms in the language. One typical use is to create new control structures. The example macro provides an codice_73 looping construct. The syntax is:
The macro definition for "until":

"tagbody" is a primitive Common Lisp special operator which provides the ability to name tags and use the "go" form to jump to those tags. The backquote "`" provides a notation that provides code templates, where the value of forms preceded with a comma are filled in. Forms preceded with comma and at-sign are "spliced" in. The tagbody form tests the end condition. If the condition is true, it jumps to the end tag. Otherwise, the provided body code is executed and then it jumps to the start tag.

An example of using the above "until" macro:

The code can be expanded using the function "macroexpand-1". The expansion for the above example looks like this:

(TAGBODY
During macro expansion the value of the variable "test" is "(= (random 10) 0)" and the value of the variable "body" is "((write-line "Hello"))". The body is a list of forms.

Symbols are usually automatically upcased. The expansion uses the TAGBODY with two labels. The symbols for these labels are computed by GENSYM and are not interned in any package. Two "go" forms use these tags to jump to. Since "tagbody" is a primitive operator in Common Lisp (and not a macro), it will not be expanded into something else. The expanded form uses the "when" macro, which also will be expanded. Fully expanding a source form is called "code walking".

In the fully expanded ("walked") form, the "when" form is replaced by the primitive "if":

(TAGBODY
All macros must be expanded before the source code containing them can be evaluated or compiled normally. Macros can be considered functions that accept and return S-expressions – similar to abstract syntax trees, but not limited to those. These functions are invoked before the evaluator or compiler to produce the final source code. Macros are written in normal Common Lisp, and may use any Common Lisp (or third-party) operator available.

Common Lisp macros are capable of what is commonly called "variable capture", where symbols in the macro-expansion body coincide with those in the calling context, allowing the programmer to create macros wherein various symbols have special meaning. The term "variable capture" is somewhat misleading, because all namespaces are vulnerable to unwanted capture, including the operator and function namespace, the tagbody label namespace, catch tag, condition handler and restart namespaces.

"Variable capture" can introduce software defects. This happens in one of the following two ways:


The Scheme dialect of Lisp provides a macro-writing system which provides the referential transparency that eliminates both types of capture problem. This type of macro system is sometimes called "hygienic", in particular by its proponents (who regard macro systems which do not automatically solve this problem as unhygienic). 

In Common Lisp, macro hygiene is ensured one of two different ways.

One approach is to use gensyms: guaranteed-unique symbols which can be used in a macro-expansion without threat of capture. The use of gensyms in a macro definition is a manual chore, but macros can be written which simplify the instantiation and use of gensyms. Gensyms solve type 2 capture easily, but they are not applicable to type 1 capture in the same way, because the macro expansion cannot rename the interfering symbols in the surrounding code which capture its references. Gensyms could be used to provide stable aliases for the global symbols which the macro expansion needs. The macro expansion would use these secret aliases rather than the well-known names, so redefinition of the well-known names would have no ill effect on the macro.

Another approach is to use packages. A macro defined in its own package can simply use internal symbols in that package in its expansion. The use of packages deals with type 1 and type 2 capture.

However, packages don't solve the type 1 capture of references to standard Common Lisp functions and operators. The reason is that the use of packages to solve capture problems revolves around the use of private symbols (symbols in one package, which are not imported into, or otherwise made visible in other packages). Whereas the Common Lisp library symbols are external, and frequently imported into or made visible in user-defined packages.

The following is an example of unwanted capture in the operator namespace, occurring in the expansion of a macro:

The codice_73 macro will expand into a form which calls codice_75 which is intended to refer to the standard Common Lisp macro codice_75. However, in this context, codice_75 may have a completely different meaning, so codice_73 may not work properly.

Common Lisp solves the problem of the shadowing of standard operators and functions by forbidding their redefinition. Because it redefines the standard operator codice_75, the preceding is actually a fragment of non-conforming Common Lisp, which allows implementations to diagnose and reject it.

The "condition system" is responsible for exception handling in Common Lisp. It provides "conditions", "handler"s and "restart"s. "Condition"s are objects describing an exceptional situation (for example an error). If a "condition" is signaled, the Common Lisp system searches for a "handler" for this condition type and calls the handler. The "handler" can now search for restarts and use one of these restarts to automatically repair the current problem, using information such as the condition type and any relevant information provided as part of the condition object, and call the appropriate restart function.

These restarts, if unhandled by code, can be presented to users (as part of a user interface, that of a debugger for example), so that the user can select and invoke one of the available restarts. Since the condition handler is called in the context of the error (without unwinding the stack), full error recovery is possible in many cases, where other exception handling systems would have already terminated the current routine. The debugger itself can also be customized or replaced using the codice_80 dynamic variable. Code found within "unwind-protect" forms such as finalizers will also be executed as appropriate despite the exception.

In the following example (using Symbolics Genera) the user tries to open a file in a Lisp function "test" called from the Read-Eval-Print-LOOP (REPL), when the file does not exist. The Lisp system presents four restarts. The user selects the "Retry OPEN using a different pathname" restart and enters a different pathname (lispm-init.lisp instead of lispm-int.lisp). The user code does not contain any error handling code. The whole error handling and restart code is provided by the Lisp system, which can handle and repair the error without terminating the user code.
Command: (test ">zippy>lispm-int.lisp")

Error: The file was not found.

LMFS:OPEN-LOCAL-LMFS-1

s-A, <Resume>: Retry OPEN of lispm:>zippy>lispm-int.lisp.newest
s-B: Retry OPEN using a different pathname
s-C, <Abort>: Return to Lisp Top Level in a TELNET server
s-D: Restart process TELNET terminal

-> Retry OPEN using a different pathname
Use what pathname instead [default lispm:>zippy>lispm-int.lisp.newest]:

...the program continues

Common Lisp includes a toolkit for object-oriented programming, the Common Lisp Object System or CLOS. Peter Norvig explains how many Design Patterns are simpler to implement in a dynamic language with the features of CLOS (Multiple Inheritance, Mixins, Multimethods, Metaclasses, Method combinations, etc.).
Several extensions to Common Lisp for object-oriented programming have been proposed to be included into the ANSI Common Lisp standard, but eventually CLOS was adopted as the standard object-system for Common Lisp. CLOS is a dynamic object system with multiple dispatch and multiple inheritance, and differs radically from the OOP facilities found in static languages such as C++ or Java. As a dynamic object system, CLOS allows changes at runtime to generic functions and classes. Methods can be added and removed, classes can be added and redefined, objects can be updated for class changes and the class of objects can be changed.

CLOS has been integrated into ANSI Common Lisp. Generic functions can be used like normal functions and are a first-class data type. Every CLOS class is integrated into the Common Lisp type system. Many Common Lisp types have a corresponding class. There is more potential use of CLOS for Common Lisp. The specification does not say whether conditions are implemented with CLOS. Pathnames and streams could be implemented with CLOS. These further usage possibilities of CLOS for ANSI Common Lisp are not part of the standard. Actual Common Lisp implementations use CLOS for pathnames, streams, input–output, conditions, the implementation of CLOS itself and more.

A Lisp interpreter directly executes Lisp source code provided as Lisp objects (lists, symbols, numbers, ...) read from s-expressions. A Lisp compiler generates bytecode or machine code from Lisp source code. Common Lisp allows both individual Lisp functions to be compiled in memory and the compilation of whole files to externally stored compiled code ("fasl" files).

Several implementations of earlier Lisp dialects provided both an interpreter and a compiler. Unfortunately often the semantics were different. These earlier Lisps implemented lexical scoping in the compiler and dynamic scoping in the interpreter. Common Lisp requires that both the interpreter and compiler use lexical scoping by default. The Common Lisp standard describes both the semantics of the interpreter and a compiler. The compiler can be called using the function "compile" for individual functions and using the function "compile-file" for files. Common Lisp allows type declarations and provides ways to influence the compiler code generation policy. For the latter various optimization qualities can be given values between 0 (not important) and 3 (most important): "speed", "space", "safety", "debug" and "compilation-speed".

There is also a function to evaluate Lisp code: codice_81. codice_81 takes code as pre-parsed s-expressions and not, like in some other languages, as text strings. This way code can be constructed with the usual Lisp functions for constructing lists and symbols and then this code can be evaluated with the function codice_81. Several Common Lisp implementations (like Clozure CL and SBCL) are implementing codice_81 using their compiler. This way code is compiled, even though it is evaluated using the function codice_81.

The file compiler is invoked using the function "compile-file". The generated file with compiled code is called a "fasl" (from "fast load") file. These "fasl" files and also source code files can be loaded with the function "load" into a running Common Lisp system. Depending on the implementation, the file compiler generates byte-code (for example for the Java Virtual Machine), C language code (which then is compiled with a C compiler) or, directly, native code.

Common Lisp implementations can be used interactively, even though the code gets fully compiled. The idea of an Interpreted language thus does not apply for interactive Common Lisp.

The language makes a distinction between read-time, compile-time, load-time, and run-time, and allows user code to also make this distinction to perform the wanted type of processing at the wanted step.

Some special operators are provided to especially suit interactive development; for instance, codice_86 will only assign a value to its provided variable if it wasn't already bound, while codice_87 will always perform the assignment. This distinction is useful when interactively evaluating, compiling and loading code in a live image.

Some features are also provided to help writing compilers and interpreters. Symbols consist of first-level objects and are directly manipulable by user code. The codice_88 special operator allows to create lexical bindings programmatically, while packages are also manipulable. The Lisp compiler is available at runtime to compile files or individual functions. These make it easy to use Lisp as an intermediate compiler or interpreter for another language.

The following program calculates the smallest number of people in a room for whom the probability of unique birthdays is less than 50% (the birthday paradox, where for 1 person the probability is obviously 100%, for 2 it is 364/365, etc.). The answer is 23.

In Common Lisp, by convention, constants are enclosed with + characters.

Calling the example function using the REPL (Read Eval Print Loop):

CL-USER > (birthday-paradox 1.0 1)
23

We define a class codice_89 and a method for displaying the name and age of a person.
Next we define a group of persons as a list of codice_89 objects.
Then we iterate over the sorted list.

(defparameter *group*

It prints the three names with descending age.

Bob (33)
Ash (23)
Chris (16)

Use of the LOOP macro is demonstrated:
Example use:
CL-USER > (power 2 200)
1606938044258990275541962092341162602522202993782792835301376
Compare with the built in exponentiation:
CL-USER > (= (expt 2 200) (power 2 200))
T

WITH-OPEN-FILE is a macro that opens a file and provides a stream. When the form is returning, the file is automatically closed. FUNCALL calls a function object. The LOOP collects all lines that match the predicate.
The function AVAILABLE-SHELLS calls the above function LIST-MATCHING-LINES with a pathname and an anonymous function as the predicate. The predicate returns the pathname of a shell or NIL (if the string is not the filename of a shell).
Example results (on Mac OS X 10.6):
CL-USER > (available-shells)

Common Lisp is most frequently compared with, and contrasted to, Scheme—if only because they are the two most popular Lisp dialects. Scheme predates CL, and comes not only from the same Lisp tradition but from some of the same engineers—Guy Steele, with whom Gerald Jay Sussman designed Scheme, chaired the standards committee for Common Lisp.

Common Lisp is a general-purpose programming language, in contrast to Lisp variants such as Emacs Lisp and AutoLISP which are extension languages embedded in particular products (GNU Emacs and AutoCAD, respectively). Unlike many earlier Lisps, Common Lisp (like Scheme) uses lexical variable scope by default for both interpreted and compiled code.

Most of the Lisp systems whose designs contributed to Common Lisp—such as ZetaLisp and Franz Lisp—used dynamically scoped variables in their interpreters and lexically scoped variables in their compilers. Scheme introduced the sole use of lexically scoped variables to Lisp; an inspiration from ALGOL 68. CL supports dynamically scoped variables as well, but they must be explicitly declared as "special". There are no differences in scoping between ANSI CL interpreters and compilers.

Common Lisp is sometimes termed a "Lisp-2" and Scheme a "Lisp-1", referring to CL's use of separate namespaces for functions and variables. (In fact, CL has "many" namespaces, such as those for go tags, block names, and codice_72 keywords). There is a long-standing controversy between CL and Scheme advocates over the tradeoffs involved in multiple namespaces. In Scheme, it is (broadly) necessary to avoid giving variables names which clash with functions; Scheme functions frequently have arguments named codice_92, codice_93, or codice_94 so as not to conflict with the system function codice_95. However, in CL it is necessary to explicitly refer to the function namespace when passing a function as an argument—which is also a common occurrence, as in the codice_11 example above.

CL also differs from Scheme in its handling of boolean values. Scheme uses the special values #t and #f to represent truth and falsity. CL follows the older Lisp convention of using the symbols T and NIL, with NIL standing also for the empty list. In CL, "any" non-NIL value is treated as true by conditionals, such as codice_68, whereas in Scheme all non-#f values are treated as true. These conventions allow some operators in both languages to serve both as predicates (answering a boolean-valued question) and as returning a useful value for further computation, but in Scheme the value '() which is equivalent to NIL in Common Lisp evaluates to true in a boolean expression.

Lastly, the Scheme standards documents require tail-call optimization, which the CL standard does not. Most CL implementations do offer tail-call optimization, although often only when the programmer uses an optimization directive. Nonetheless, common CL coding style does not favor the ubiquitous use of recursion that Scheme style prefers—what a Scheme programmer would express with tail recursion, a CL user would usually express with an iterative expression in codice_75, codice_99, codice_72, or (more recently) with the codice_101 package.

See the Category .

Common Lisp is defined by a specification (like Ada and C) rather than by one implementation (like Perl). There are many implementations, and the standard details areas in which they may validly differ.

In addition, implementations tend to come with extensions, which provide functionality not covered in the standard:


Free and open-source software libraries have been created to support extensions to Common Lisp in a portable way, and are most notably found in the repositories of the Common-Lisp.net and CLOCC (Common Lisp Open Code Collection) projects.

Common Lisp implementations may use any mix of native code compilation, byte code compilation or interpretation. Common Lisp has been designed to support incremental compilers, file compilers and block compilers. Standard declarations to optimize compilation (such as function inlining or type specialization) are proposed in the language specification. Most Common Lisp implementations compile source code to native machine code. Some implementations can create (optimized) stand-alone applications. Others compile to interpreted bytecode, which is less efficient than native code, but eases binary-code portability. Some compilers compile Common Lisp code to C code. The misconception that Lisp is a purely interpreted language is most likely because Lisp environments provide an interactive prompt and that code is compiled one-by-one, in an incremental way. With Common Lisp incremental compilation is widely used.

Some Unix-based implementations (CLISP, SBCL) can be used as a scripting language; that is, invoked by the system transparently in the way that a Perl or Unix shell interpreter is.




Common Lisp is used to develop research applications (often in Artificial Intelligence), for rapid development of prototypes or for deployed applications.

Common Lisp is used in many commercial applications, including the Yahoo! Store web-commerce site, which originally involved Paul Graham and was later rewritten in C++ and Perl. Other notable examples include:


There also exist open-source applications written in Common Lisp, such as:


A chronological list of books published (or about to be published) about Common Lisp (the language) or about programming with Common Lisp (especially AI programming).


Color code

A color code is a system for encoding and representing non-color information with colors to facilitate communication. This information tends to be categorical (representing unordered/qualitative categories) though may also be sequential (representing an ordered/quantitative variable).

The earliest examples of color codes in use are for long-distance communication by use of flags, as in semaphore communication. The United Kingdom adopted a color code scheme for such communication wherein red signified danger and white signified safety, with other colors having similar assignments of meaning.

As chemistry and other technologies advanced, it became expedient to use coloration as a signal for telling apart things that would otherwise be confusingly similar, such as wiring in electrical and electronic devices, and pharmaceutical pills.

A color code encodes a variable, which may have different representations, where the color code type should match the variable type:

The types of color code are:

When color is the only varied attribute, the color code is "unidimensional". When other attributes are varied (e.g. shape, size), the code is "multidimensional", where the dimensions can be "independent" (each encoding separate variables) or "redundant" (encoding the same variable). Partial redundancy sees one variable as a subset of another. For example, playing card suits are multidimensional with color (black, red) and shape (club, diamond, heart, spade), which are partially redundant since clubs and spades are always black and diamonds and hearts are always red. Tasks using categorical color codes can be classified as identification tasks, where a single stimulus is shown and must be identified (connotatively or denotatively), versus search tasks, where a color stimulus must be found within a field of heterogenous stimuli. Performance in these tasks is measured by speed and/or accuracy.

The ideal color scheme for a categorical color code depends on whether speed or accuracy is more important. Despite humans being able to distinguish 150 distinct colors along the hue dimension during comparative task, evidence supports that color schemes where colors differ only by hue (equal luminosity and colorfulness) should have a maximum of 8 categories with optimized stimulus spacing along the hue dimension, though this would not be color blind accessible. The IALA recommends categorical color codes in 7 colors: red, orange, yellow, green, blue, white & black. Adding redundant coding of luminosity and colorfulness adds information and increases speed and accuracy of color decoding tasks. Color codes are superior to others (encoding to letters, shape, size, etc.) in certain types of tasks. Adding color as a redundant attribute to a numeral or letter encoding in search tasks decreased time by 50-75%, but in unidimensional identification tasks, using alphanumeric or line inclination codes caused less errors than color codes.

Several studies demonstrate a subjective preference for color codes over achromatic codes (e.g. shapes), even in studies where color coding did not increase performance over achromatic coding. Subjects reported the tasks as less monotonous and less inducing of eye strain and fatigue.

The ability to discriminate color differences decreases rapidly as the visual angle subtends less than 12' (0.2° or ~2mm at a viewing distance of 50cm), so color stimulus of at least 3mm in diameter or thickness is recommended when the color is on paper or on a screen. Under normal conditions, colored backgrounds do not affect the interpretation of color codes, but chromatic (and/or low) illumination of surface color code can degrade performance.

Color codes present some potential problems. On forms and signage, the use of color can distract from black and white text.

Color codes are often designed without consideration for accessibility to color blind and blind people, and may even be inaccessible for those with normal color vision, since use of many colors to code many variables can lead to use of confusingly similar colors. Only 15-40% of the colorblind can correctly name surface color codes with 8-10 color categories, most of which test as mildly colorblind. This finding uses ideal illumination; when dimmer illumination is used, performance drops sharply.

Systems incorporating color-coding include:



Cortex

Cortex or cortical may refer to:





Collection

Collection or Collections may refer to:

Collection may also refer to:




Cauchy sequence

In mathematics, a Cauchy sequence is a sequence whose elements become arbitrarily close to each other as the sequence progresses. More precisely, given any small positive distance, all excluding a finite number of elements of the sequence are less than that given distance from each other. Cauchy sequences are named after Augustin-Louis Cauchy; they may occasionally be known as fundamental sequences.

It is not sufficient for each term to become arbitrarily close to the term. For instance, in the sequence of square roots of natural numbers:
formula_1
the consecutive terms become arbitrarily close to each other – their differences
formula_2
tend to zero as the index grows. However, with growing values of , the terms formula_3 become arbitrarily large. So, for any index and distance , there exists an index big enough such that formula_4 As a result, no matter how far one goes, the remaining terms of the sequence never get close to ; hence the sequence is not Cauchy.

The utility of Cauchy sequences lies in the fact that in a complete metric space (one where all such sequences are known to converge to a limit), the criterion for convergence depends only on the terms of the sequence itself, as opposed to the definition of convergence, which uses the limit value as well as the terms. This is often exploited in algorithms, both theoretical and applied, where an iterative process can be shown relatively easily to produce a Cauchy sequence, consisting of the iterates, thus fulfilling a logical condition, such as termination. 

Generalizations of Cauchy sequences in more abstract uniform spaces exist in the form of Cauchy filters and Cauchy nets.

A sequence
formula_5
of real numbers is called a Cauchy sequence if for every positive real number formula_6 there is a positive integer "N" such that for all natural numbers formula_7
formula_8
where the vertical bars denote the absolute value. In a similar way one can define Cauchy sequences of rational or complex numbers. Cauchy formulated such a condition by requiring formula_9 to be infinitesimal for every pair of infinite "m", "n".

For any real number "r", the sequence of truncated decimal expansions of "r" forms a Cauchy sequence. For example, when formula_10 this sequence is (3, 3.1, 3.14, 3.141, ...). The "m"th and "n"th terms differ by at most formula_11 when "m" < "n", and as "m" grows this becomes smaller than any fixed positive number formula_12

If formula_13 is a sequence in the set formula_14 then a "modulus of Cauchy convergence" for the sequence is a function formula_15 from the set of natural numbers to itself, such that for all natural numbers formula_16 and natural numbers formula_17 formula_18

Any sequence with a modulus of Cauchy convergence is a Cauchy sequence. The existence of a modulus for a Cauchy sequence follows from the well-ordering property of the natural numbers (let formula_19 be the smallest possible formula_20 in the definition of Cauchy sequence, taking formula_21 to be formula_22). The existence of a modulus also follows from the principle of countable choice. "Regular Cauchy sequences" are sequences with a given modulus of Cauchy convergence (usually formula_23 or formula_24). Any Cauchy sequence with a modulus of Cauchy convergence is equivalent to a regular Cauchy sequence; this can be proven without using any form of the axiom of choice.

Moduli of Cauchy convergence are used by constructive mathematicians who do not wish to use any form of choice. Using a modulus of Cauchy convergence can simplify both definitions and theorems in constructive analysis. Regular Cauchy sequences were used by and by in constructive mathematics textbooks.

Since the definition of a Cauchy sequence only involves metric concepts, it is straightforward to generalize it to any metric space "X". 
To do so, the absolute value formula_25 is replaced by the distance formula_26 (where "d" denotes a metric) between formula_27 and formula_28

Formally, given a metric space formula_29 a sequence
formula_5
is Cauchy, if for every positive real number formula_31 there is a positive integer formula_20 such that for all positive integers formula_7 the distance
formula_34

Roughly speaking, the terms of the sequence are getting closer and closer together in a way that suggests that the sequence ought to have a limit in "X". 
Nonetheless, such a limit does not always exist within "X": the property of a space that every Cauchy sequence converges in the space is called "completeness", and is detailed below.

A metric space ("X", "d") in which every Cauchy sequence converges to an element of "X" is called complete.

The real numbers are complete under the metric induced by the usual absolute value, and one of the standard constructions of the real numbers involves Cauchy sequences of rational numbers. In this construction, each equivalence class of Cauchy sequences of rational numbers with a certain tail behavior—that is, each class of sequences that get arbitrarily close to one another— is a real number.

A rather different type of example is afforded by a metric space "X" which has the discrete metric (where any two distinct points are at distance 1 from each other). Any Cauchy sequence of elements of "X" must be constant beyond some fixed point, and converges to the eventually repeating term.

The rational numbers formula_35 are not complete (for the usual distance):
There are sequences of rationals that converge (in formula_36) to irrational numbers; these are Cauchy sequences having no limit in formula_37 In fact, if a real number "x" is irrational, then the sequence ("x"), whose "n"-th term is the truncation to "n" decimal places of the decimal expansion of "x", gives a Cauchy sequence of rational numbers with irrational limit "x". Irrational numbers certainly exist in formula_38 for example:


The open interval formula_45 in the set of real numbers with an ordinary distance in formula_36 is not a complete space: there is a sequence formula_47 in it, which is Cauchy (for arbitrarily small distance bound formula_48 all terms formula_49 of formula_50 fit in the formula_51 interval), however does not converge in formula_52 — its 'limit', number 0, does not belong to the space formula_53


These last two properties, together with the Bolzano–Weierstrass theorem, yield one standard proof of the completeness of the real numbers, closely related to both the Bolzano–Weierstrass theorem and the Heine–Borel theorem. Every Cauchy sequence of real numbers is bounded, hence by Bolzano–Weierstrass has a convergent subsequence, hence is itself convergent. This proof of the completeness of the real numbers implicitly makes use of the least upper bound axiom. The alternative approach, mentioned above, of the real numbers as the completion of the rational numbers, makes the completeness of the real numbers tautological.

One of the standard illustrations of the advantage of being able to work with Cauchy sequences and make use of completeness is provided by consideration of the summation of an infinite series of real numbers
(or, more generally, of elements of any complete normed linear space, or Banach space). Such a series 
formula_61 is considered to be convergent if and only if the sequence of partial sums formula_62 is convergent, where formula_63 It is a routine matter to determine whether the sequence of partial sums is Cauchy or not, since for positive integers formula_64
formula_65

If formula_66 is a uniformly continuous map between the metric spaces "M" and "N" and ("x") is a Cauchy sequence in "M", then formula_67 is a Cauchy sequence in "N". If formula_68 and formula_69 are two Cauchy sequences in the rational, real or complex numbers, then the sum formula_70 and the product formula_71 are also Cauchy sequences.

There is also a concept of Cauchy sequence for a topological vector space formula_52: Pick a local base formula_73 for formula_52 about 0; then (formula_75) is a Cauchy sequence if for each member formula_76 there is some number formula_20 such that whenever 
formula_78 is an element of formula_79 If the topology of formula_52 is compatible with a translation-invariant metric formula_81 the two definitions agree.

Since the topological vector space definition of Cauchy sequence requires only that there be a continuous "subtraction" operation, it can just as well be stated in the context of a topological group: A sequence formula_82 in a topological group formula_83 is a Cauchy sequence if for every open neighbourhood formula_84 of the identity in formula_83 there exists some number formula_20 such that whenever formula_87 it follows that formula_88 As above, it is sufficient to check this for the neighbourhoods in any local base of the identity in formula_89

As in the construction of the completion of a metric space, one can furthermore define the binary relation on Cauchy sequences in formula_83 that formula_82 and formula_92 are equivalent if for every open neighbourhood formula_84 of the identity in formula_83 there exists some number formula_20 such that whenever formula_87 it follows that formula_97 This relation is an equivalence relation: It is reflexive since the sequences are Cauchy sequences. It is symmetric since formula_98 which by continuity of the inverse is another open neighbourhood of the identity. It is transitive since formula_99 where formula_100 and formula_101 are open neighbourhoods of the identity such that formula_102; such pairs exist by the continuity of the group operation.

There is also a concept of Cauchy sequence in a group formula_83:
Let formula_104 be a decreasing sequence of normal subgroups of formula_83 of finite index.
Then a sequence formula_68 in formula_83 is said to be Cauchy (with respect to formula_108) if and only if for any formula_109 there is formula_20 such that for all formula_111

Technically, this is the same thing as a topological group Cauchy sequence for a particular choice of topology on formula_112 namely that for which formula_108 is a local base.

The set formula_114 of such Cauchy sequences forms a group (for the componentwise product), and the set formula_115 of null sequences (sequences such that formula_116) is a normal subgroup of formula_117 The factor group formula_118 is called the completion of formula_83 with respect to formula_120

One can then show that this completion is isomorphic to the inverse limit of the sequence formula_121

An example of this construction familiar in number theory and algebraic geometry is the construction of the formula_122-adic completion of the integers with respect to a prime formula_123 In this case, formula_83 is the integers under addition, and formula_125 is the additive subgroup consisting of integer multiples of formula_126 

If formula_108 is a cofinal sequence (that is, any normal subgroup of finite index contains some formula_125), then this completion is canonical in the sense that it is isomorphic to the inverse limit of formula_129 where formula_108 varies over normal subgroups of finite index. For further details, see Ch. I.10 in Lang's "Algebra".

A real sequence formula_131 has a natural hyperreal extension, defined for hypernatural values "H" of the index "n" in addition to the usual natural "n". The sequence is Cauchy if and only if for every infinite "H" and "K", the values formula_132 and formula_133 are infinitely close, or adequal, that is,
where "st" is the standard part function.

 introduced a notion of Cauchy completion of a category. Applied to formula_35 (the category whose objects are rational numbers, and there is a morphism from "x" to "y" if and only if formula_136), this Cauchy completion yields formula_137 (again interpreted as a category using its natural ordering).



Common Era

Common Era (CE) and Before the Common Era (BCE) are year notations for the Gregorian calendar (and its predecessor, the Julian calendar), the world's most widely used calendar era. Common Era and Before the Common Era are alternatives to the original Anno Domini (AD) and Before Christ (BC) notations used for the same calendar era. The two notation systems are numerically equivalent: "2024 CE" and "AD 2024" each describe the current year; "400 BCE" and "400 BC" are the same year.

The expression can be traced back to 1615, when it first appears in a book by Johannes Kepler as the (), and to 1635 in English as "Vulgar Era". The term "Common Era" can be found in English as early as 1708, and became more widely used in the mid-19th century by Jewish religious scholars. Since the late 20th century, BCE and CE have become popular in academic and scientific publications on the grounds that BCE and CE are religiously neutral terms. They have been promoted as more sensitive to non-Christians by not referring to Jesus, the central figure of Christianity, especially via the religious terms "Christ" and ("Lord") utilized by the other abbreviations. 

The idea of numbering years beginning from the date he believed to be the date of birth of Jesus, was conceived around the year 525 by the Christian monk Dionysius Exiguus. He did this to replace the then dominant Era of Martyrs system, because he did not wish to continue the memory of a tyrant who persecuted Christians. He numbered years from an initial reference date ("epoch"), an event he referred to as the Incarnation of Jesus. Dionysius labeled the column of the table in which he introduced the new era as ""Anni Domini Nostri Jesu Christi"" [Year of our Lord Jesus Christ].

This way of numbering years became more widespread in Europe with its use by Bede in England in 731. Bede also introduced the practice of dating years before what he supposed was the year of birth of Jesus, without a year zero. In 1422, Portugal became the last Western European country to switch to the system begun by Dionysius.

The term "Common Era" is traced back in English to its appearance as "Vulgar Era" to distinguish dates on the Gregorian calendar which was in popular use from dates of the regnal year (the year of the reign of a sovereign) typically used in national law. (The word 'vulgar' originally meant 'of the ordinary people', with no derogatory associations.)

The first use of the Latin term may be that in a 1615 book by Johannes Kepler. Kepler uses it again, as , in a 1616 table of ephemerides, and again, as , in 1617. A 1635 English edition of that book has the title page in English that may be the earliest-found use of "Vulgar Era" in English. A 1701 book edited by John Le Clerc includes the phrase "Before Christ according to the Vulgar Æra,6".

The Merriam Webster Dictionary gives 1716 as being the date of first use of the term "vulgar era" (to mean Christian era). 

The first published use of "Christian Era" may be the Latin phrase on the title page of a 1584 theology book, . In 1649, the Latin phrase appeared in the title of an English almanac. A 1652 ephemeris may be the first instance found so far of the English use of "Christian Era".

The English phrase "Common Era" appears at least as early as 1708, 
and in a 1715 book on astronomy it is used interchangeably with "Christian Era" and "Vulgar Era". A 1759 history book uses "common æra" in a generic sense, to refer to "the common era of the Jews". The first use of the phrase "before the common era" may be that in a 1770 work that also uses "common era" and "vulgar era" as synonyms, in a translation of a book originally written in German. The 1797 edition of the Encyclopædia Britannica uses the terms "vulgar era" and "common era" synonymously. 
In 1835, in his book "Living Oracles", Alexander Campbell, wrote: "The vulgar Era, or Anno Domini; the fourth year of Jesus Christ, the first of which was but eight days", 
and also refers to the "common era" as a synonym for "vulgar era" with "the fact that our Lord was born on the 4th year before the vulgar era, called Anno Domini, thus making (for example) the 42d year from his birth to correspond with the 38th of the common era". The "Catholic Encyclopedia" (1909) in at least one article reports all three terms (Christian, Vulgar, Common Era) being commonly understood by the early 20th century.

The phrase "common era", in lower case, also appeared in the 19th century in a 'generic' sense, not necessarily to refer to the Christian Era, but to any system of dates in common use throughout a civilization. Thus, "the common era of the Jews", "the common era of the Mahometans", "common era of the world", "the common era of the foundation of Rome". 
When it did refer to the Christian Era, it was sometimes qualified, e.g., "common era of the Incarnation", "common era of the Nativity", or "common era of the birth of Christ".

An adapted translation of "Common Era" into Latin as was adopted in the 20th century by some followers of Aleister Crowley, and thus the abbreviation "e.v." or "EV" may sometimes be seen as a replacement for AD.

Although Jews have their own Hebrew calendar, they often use the Gregorian calendar without the AD prefix. As early as 1825, the abbreviation VE (for Vulgar Era) was in use among Jews to denote years in the Western calendar. , Common Era notation has also been in use for Hebrew lessons for more than a century. Jews have also used the term Current Era.

Some academics in the fields of theology, education, archaeology and history have adopted CE and BCE notation despite some disagreement. Several style guides now prefer or mandate its use. A study conducted in 2014 found that the BCE/CE notation is not growing at the expense of BC and AD notation in the scholarly literature, and that both notations are used in a relatively stable fashion. 

In 2002, an advisory panel for the religious education syllabus for England and Wales recommended introducing BCE/CE dates to schools, and by 2018 some local education authorities were using them. 

In 2018, the National Trust said it would continue to use BC/AD as its house style. English Heritage explains its era policy thus: "It might seem strange to use a Christian calendar system when referring to British prehistory, but the BC/AD labels are widely used and understood." Some parts of the BBC use BCE/CE, but some presenters have said they will not. As of October 2019, the BBC News style guide has entries for AD and BC, but not for CE or BCE. The style guide for "The Guardian" says, under the entry for CE/BCE: "some people prefer CE (common era, current era, or Christian era) and BCE (before common era, etc.) to AD and BC, which, however, remain our style".

In the United States, the use of the BCE/CE notation in textbooks was reported in 2005 to be growing. Some publications have transitioned to using it exclusively. For example, the 2007 World Almanac was the first edition to switch to BCE/CE, ending a period of 138 years in which the traditional BC/AD dating notation was used. BCE/CE is used by the College Board in its history tests, and by the Norton Anthology of English Literature. Others have taken a different approach. The US-based History Channel uses BCE/CE notation in articles on non-Christian religious topics such as Jerusalem and Judaism. The 2006 style guide for the Episcopal Diocese "Maryland Church News" says that BCE and CE should be used.

In June 2006, in the United States, the Kentucky State School Board reversed its decision to use BCE and CE in the state's new Program of Studies, leaving education of students about these concepts a matter of local discretion.

In 2011, media reports suggested that the BC/AD notation in Australian school textbooks would be replaced by BCE/CE notation. The change drew opposition from some politicians and church leaders. Weeks after the story broke, the Australian Curriculum, Assessment and Reporting Authority denied the rumours and stated that the BC/AD notation would remain, with CE and BCE as an optional suggested learning activity.

In 2013, the Canadian Museum of Civilization (now the Canadian Museum of History) in Gatineau (opposite Ottawa), which had previously switched to BCE/CE, decided to change back to BC/AD in material intended for the public while retaining BCE/CE in academic content.

The use of CE in Jewish scholarship was historically motivated by the desire to avoid the implicit "Our Lord" in the abbreviation "AD". Although other aspects of dating systems are based in Christian origins, AD is a direct reference to Jesus as Lord.

Proponents of the Common Era notation assert that the use of BCE/CE shows sensitivity to those who use the same year numbering system as the one that originated with and is currently used by Christians, but who are not themselves Christian.

Former United Nations Secretary-General Kofi Annan has argued:

Adena K. Berkowitz, in her application to argue before the United States Supreme Court, opted to use BCE and CE because "Given the multicultural society that we live in, the traditional Jewish designationsB.C.E. and C.E. cast a wider net of inclusion".

"Non-Christian scholars, especially, embraced [CE and BCE] because they could now communicate more easily with the Christian community. Jewish, Islamic, Hindu and Buddhist scholars could retain their [own] calendar but refer to events using the Gregorian Calendar as BCE and CE without compromising their own beliefs about the divinity of Jesus of Nazareth".

Some critics often note the fact that there is no difference in the epoch of the two systems, a moment about four to seven years after the date of birth of Jesus of Nazareth. BCE and CE are still aligned with BC and AD, which denote the periods before and after Jesus was born.

Some Christians are offended by the removal of the reference to Jesus in the Common Era notation. The Southern Baptist Convention supports retaining the BC/AD abbreviations.

Roman Catholic priest and writer on interfaith issues Raimon Panikkar argued that the BCE/CE usage is the less inclusive option, since they are still using the Christian calendar numbers, forcing it on other nations. In 1993, the English-language expert Kenneth G. Wilson speculated a slippery slope scenario in his style guide that "if we do end by casting aside the AD/BC convention, almost certainly some will argue that we ought to cast aside as well the conventional numbering system [that is, the method of numbering years] itself, given its Christian basis."

The abbreviation BCE, just as with BC, always follows the year number. Unlike AD, which still often precedes the year number, CE always follows the year number (if context requires that it be written at all). Thus, the current year is written as in both notations (or, if further clarity is needed, as CE, or as AD ), and the year that Socrates died is represented as 399 BCE (the same year that is represented by 399 BC in the BC/AD notation). The abbreviations are sometimes written with small capital letters, or with periods (e.g., "B.C.E." or "C.E."). The US-based Society of Biblical Literature style guide for academic texts on religion prefers BCE/CE to BC/AD.




Charles Robert Malden

Charles Robert Malden (9 August 1797 – 23 May 1855), was a nineteenth-century British naval officer, surveyor and educator. He is the discoverer of Malden Island in the central Pacific, which is named in his honour. He also founded Windlesham House School at Brighton, England.

Malden was born in Putney, Surrey, son of Jonas Malden, a surgeon. He entered British naval service at the age of 11 on 22 June 1809. He served nine years as a volunteer 1st class, midshipman, and shipmate, including one year in the English Channel and Bay of Biscay (1809), four years at the Cape of Good Hope and in the East Indies (1809–14), two and a half years on the North American and West Indian stations (1814–16), and a year and a half in the Mediterranean (1817–18). He was present at the capture of Mauritius and Java, and at the battles of Baltimore and New Orleans.

He passed the examination in the elements of mathematics and the theory of navigation at the Royal Naval Academy on 2–4 September 1816, and became a 1st Lieutenant on 1 September 1818. In eight years of active service as an officer, he served two and a half years in a surveying ship in the Mediterranean (1818–21), one and a half years in a surveying sloop in the English Channel and off the coast of Ireland (1823–24), and one and a half years as Surveyor of the frigate during a voyage (1824–26) to and from the Hawaiian Islands (then known as the "Sandwich islands").
In Hawaii he surveyed harbours which, he noted, were "said not to exist by Captains Cook and Vancouver." On the return voyage he discovered and explored uninhabited Malden Island in the central Pacific on 30 July 1825. After his return he left active service but remained at half pay. He served for several years as hydrographer to King William IV.

He married Frances Cole, daughter of Rev. William Hodgson Cole, rector of West Clandon and Vicar of Wonersh, near Guildford, Surrey, on 8 April 1828. Malden became the father of seven sons and a daughter.

From 1830 to 1836 he took pupils for the Royal Navy at Ryde, Isle of Wight. He purchased the school of Henry Worsley at Newport, Isle of Wight, in December 1836, reopened it as a preparatory school on 20 February 1837, and moved it to Montpelier Road in Brighton in December 1837. He built the Windlesham House School at Brighton in 1844, and conducted the school until his death there in 1855. He was succeeded as headmaster by his son Henry Charles Malden.

Chechnya

Chechnya, officially the Chechen Republic, is a republic of Russia. It is situated in the North Caucasus of Eastern Europe, between the Caspian Sea and Black Sea. The republic forms a part of the North Caucasian Federal District, and shares land borders with the country of Georgia to its south; with the Russian republics of Dagestan, Ingushetia, and North Ossetia-Alania to its east, north, and west; and with Stavropol Krai to its northwest.

After the dissolution of the Soviet Union in 1991, the Checheno-Ingush ASSR split into two parts: the Republic of Ingushetia and the Chechen Republic. The latter proclaimed the Chechen Republic of Ichkeria, which declared independence, while the former sided with Russia. Following the First Chechen War of 1994–1996 with Russia, Chechnya gained "de facto" independence as the Chechen Republic of Ichkeria, although "de jure" it remained a part of Russia. Russian federal control was restored in the Second Chechen War of 1999–2009, with Chechen politics being dominated by the former Ichkerian Mufti Akhmad Kadyrov, and later his son Ramzan Kadyrov.

The republic covers an area of , with a population of over 1.5 million residents .
It is home to the indigenous Chechens, part of the Nakh peoples, and of primarily Muslim faith. Grozny is the capital and largest city.

According to Leonti Mroveli, the 11th-century Georgian chronicler, the word Caucasian is derived from the Nakh ancestor Kavkas.
According to George Anchabadze of Ilia State University:

American linguist Johanna Nichols "has used language to connect the modern people of the Caucasus region to the ancient farmers of the Fertile Crescent" and her research suggests that "farmers of the region were proto-Nakh-Daghestanians". Nichols stated: "The Nakh–Dagestanian languages are the closest thing we have to a direct continuation of the cultural and linguistic community that gave rise to Western civilisation."

Traces of human settlement dating back to 40,000 BCE were found near Lake Kezanoi. Cave paintings, artifacts, and other archaeological evidence indicate continuous habitation for some 8,000 years. People living in these settlements used tools, fire, and clothing made of animal skins.

The Caucasian Epipaleolithic and early Caucasian Neolithic era saw the introduction of agriculture, irrigation, and the domestication of animals in the region. Settlements near Ali-Yurt and Magas, discovered in modern times, revealed tools made out of stone: stone axes, polished stones, stone knives, stones with holes drilled in them, clay dishes etc. Settlements made out of clay bricks were discovered in the plains. In the mountains there were settlements made from stone and surrounded by walls; some of them dated back to 8000 BCE. This period also saw the appearance of the wheel (3000 BCE), horseback riding, metal works (copper, gold, silver, iron), dishes, armor, daggers, knives and arrow tips in the region. The artifacts were found near Nasare-Cort, Muzhichi, Ja-E-Bortz (alternatively known as Surkha-khi), Abbey-Gove (also known as Nazran or Nasare).

The German scientist Peter Simon Pallas believed that the Vainakh people (Chechens and Ingush) were the direct descendants from Alania. In 1239, the Alania capital of Maghas and the Alan confederacy of the Northern Caucasian highlanders, nations, and tribes was destroyed by Batu Khan (a Mongol leader and a grandson of Genghis Khan).

According to the missionary Pian de Carpine, a part of the Alans had successfully resisted a Mongol siege on a mountain for 12 years:

This twelve year old siege is not found in any other report, however the Russian historian A. I. Krasnov connected this battle with two Chechen folktales he recorded in 1967 that spoke of an old hunter named Idig who with his companions defended the Dakuoh mountain for 12 years against Tatar-Mongols. He also reported to have found several arrowheads and spears from the 13th century near the very mountain at which the battle took place:

In the 14th and 15th centuries, there was frequent warfare between the Chechens, Tamerlane and Tokhtamysh, culminating in the Battle of the Terek River (see Tokhtamysh–Timur war). The Chechen tribes built fortresses, castles, and defensive walls, protecting the mountains from the invaders. Part of the lowland tribes were occupied by Mongols. However, during the mid-14th century a strong Chechen Princedom called Simsim emerged under Khour II, a Chechen king that led the Chechen politics and wars. He was in charge of an army of Chechens against the rogue warlord Mamai and defeated him in the Battle of Tatar-tup in 1362. The kingdom of Simsim was almost destroyed during the Timurid invasion of the Caucasus, when Khour II allied himself with the Golden Horde Khan Tokhtamysh in the Battle of the Terek River. Timur sought to punish the highlanders for their allegiance to Tokhtamysh and as a consequence invaded Simsim in 1395.

The 16th century saw the first Russian involvement in the Caucasus. In 1558, Temryuk of Kabarda sent his emissaries to Moscow requesting help from Ivan the Terrible against the Vainakh tribes. Ivan the Terrible married Temryuk's daughter Maria Temryukovna. An alliance was formed to gain the ground in the central Caucasus for the expanding Tsardom of Russia against stubborn Vainakh defenders. Chechnya was a nation in the Northern Caucasus that fought against foreign rule continually since the 15th century. Several Chechen leaders such as the 17th century Mehk-Da Aldaman Gheza led the Chechen politics and fought off encroachments of foreign powers. He defended the borders of Chechnya from invasions of Kabardinians and Avars during the Battle of Khachara in 1667.
The Chechens converted over the next few centuries to Sunni Islam, as Islam was associated with resistance to Russian encroachment.

Peter the Great first sought to increase Russia's political influence in the Caucasus and the Caspian Sea at the expense of Safavid Persia when he launched the Russo-Persian War of 1722–1723. Russian forces succeeded in taking much of the Caucasian territories from Iran for several years.

As the Russians took control of the Caspian corridor and moved into Persian-ruled Dagestan, Peter's forces ran into mountain tribes. Peter sent a cavalry force to subdue them, but the Chechens routed them. In 1732, after Russia already ceded back most of the Caucasus to Persia, now led by Nader Shah, following the Treaty of Resht, Russian troops clashed again with Chechens in a village called Chechen-aul along the Argun River. The Russians were defeated again and withdrew, but this battle is responsible for the apocryphal story about how the Nokchi came to be known as "Chechens" – the people ostensibly named for the place the battle had taken place. The name Chechen was however already used since as early as 1692.

Under intermittent Persian rule since 1555, in 1783 the eastern Georgians of Kartl-Kakheti led by Erekle II and Russia signed the Treaty of Georgievsk. According to this treaty, Kartl-Kakheti received protection from Russia, and Georgia abjured any dependence on Iran. In order to increase its influence in the Caucasus and to secure communications with Kartli and other Christian regions of the Transcaucasia which it considered useful in its wars against Persia and Turkey, the Russian Empire began conquering the Northern Caucasus mountains. The Russian Empire used Christianity to justify its conquests, allowing Islam to spread widely because it positioned itself as the religion of liberation from tsardom, which viewed Nakh tribes as "bandits". The rebellion was led by Mansur Ushurma, a Chechen Naqshbandi (Sufi) sheikh—with wavering military support from other North Caucasian tribes. Mansur hoped to establish a Transcaucasus Islamic state under sharia law. He was unable to fully achieve this because in the course of the war he was betrayed by the Ottomans, handed over to Russians, and executed in 1794.

Following the forced ceding of the current territories of Dagestan, most of Azerbaijan, and Georgia by Persia to Russia, following the Russo-Persian War of 1804–1813 and its resultant Treaty of Gulistan, Russia significantly widened its foothold in the Caucasus at the expense of Persia. Another successful Caucasus war against Persia several years later, starting in 1826 and ending in 1828 with the Treaty of Turkmenchay, and a successful war against Ottoman Turkey in 1828 and 1829, enabled Russia to use a much larger portion of its army in subduing the natives of the North Caucasus.

The resistance of the Nakh tribes never ended and was a fertile ground for a new Muslim-Avar commander, Imam Shamil, who fought against the Russians from 1834 to 1859 (see Murid War). In 1859, Shamil was captured by Russians at aul Gunib. Shamil left Baysangur of Benoa, a Chechen with one arm, one eye, and one leg, in charge of command at Gunib. Baysangur broke through the siege and continued to fight Russia for another two years until he was captured and killed by Russians. The Russian tsar hoped that by sparing the life of Shamil, the resistance in the North Caucasus would stop, but it did not. Russia began to use a colonization tactic by destroying Nakh settlements and building Cossack defense lines in the lowlands. The Cossacks suffered defeat after defeat and were constantly attacked by mountaineers, who were robbing them of food and weaponry.

The tsarists' regime used a different approach at the end of the 1860s. They offered Chechens and Ingush to leave the Caucasus for the Ottoman Empire (see Muhajir (Caucasus)). It is estimated that about 80% of Chechens and Ingush left the Caucasus during the deportation. It weakened the resistance which went from open warfare to insurgent warfare. One of the notable Chechen resistance fighters at the end of the 19th century was a Chechen abrek Zelimkhan Gushmazukaev and his comrade-in-arms Ingush abrek Sulom-Beck Sagopshinski. Together they built up small units which constantly harassed Russian military convoys, government mints, and government post-service, mainly in Ingushetia and Chechnya. Ingush aul Kek was completely burned when the Ingush refused to hand over Zelimkhan. Zelimkhan was killed at the beginning of the 20th century. The war between Nakh tribes and Russia resurfaced during the times of the Russian Revolution, which saw the Nakh struggle against Anton Denikin and later against the Soviet Union.

On 21 December 1917, Ingushetia, Chechnya, and Dagestan declared independence from Russia and formed a single state: "United Mountain Dwellers of the North Caucasus" (also known as the Mountainous Republic of the Northern Caucasus) which was recognized by major world powers. The capital of the new state was moved to Temir-Khan-Shura (Dagestan). Tapa Tchermoeff, a prominent Chechen statesman, was elected the first prime minister of the state. The second prime minister elected was Vassan-Girey Dzhabagiev, an Ingush statesman, who also was the author of the constitution of the republic in 1917, and in 1920 he was re-elected for the third term. In 1921 the Russians attacked and occupied the country and forcibly absorbed it into the Soviet state. The Caucasian war for independence restarted, and the government went into exile.

During Soviet rule, Chechnya and Ingushetia were combined to form the Checheno-Ingush Autonomous Soviet Socialist Republic. In the 1930s, Chechnya was flooded with many Ukrainians fleeing a famine. As a result, many of the Ukrainians settled in Chechen-Ingush ASSR permanently and survived the famine.
Although over 50,000 Chechens and over 12,000 Ingush were fighting against Nazi Germany on the front line (including Heroes of the USSR: Abukhadzhi Idrisov, Khanpasha Nuradilov, Movlid Visaitov), and although Nazi German troops advanced as far as the Ossetian ASSR city of Ordzhonikidze and the Chechen-Ingush ASSR city of Malgobek after capturing half of the Caucasus in less than a month, Chechens and Ingush were falsely accused as Nazi supporters and entire nations were deported during Operation Lentil to the Kazakh SSR (later Kazakhstan) in 1944 near the end of World War II where over 60% of Chechen and Ingush populations perished. American historian Norman Naimark writes:

The deportation was justified by the materials prepared by NKVD officer Bogdan Kobulov accusing Chechens and Ingush in a mass conspiracy preparing rebellion and providing assistance to the German forces. Many of the materials were later proven to be fabricated. Even distinguished Red Army officers who fought bravely against Germans (e.g. the commander of 255th Separate Chechen-Ingush regiment Movlid Visaitov, the first to contact American forces at Elbe river) were deported. There is a theory that the real reason why Chechens and Ingush were deported was the desire of Russia to attack Turkey, an anti-communist country, as Chechens and Ingush could impede such plans. In 2004, the European Parliament recognized the deportation of Chechens and Ingush as an act of genocide.

The territory of the Chechen-Ingush Autonomous Soviet Socialist Republic was divided between Stavropol Krai (where Grozny Okrug was formed), the Dagestan ASSR, the North Ossetian ASSR, and the Georgian SSR.

The Chechens and Ingush were allowed to return to their land after 1956 during de-Stalinisation under Nikita Khrushchev when the Chechen-Ingush ASSR was restored but with both the boundaries and ethnic composition of the territory significantly changed. There were many (predominantly Russian) migrants from other parts of the Soviet Union, who often settled in the abandoned family homes of Chechens and Ingushes. The republic lost its Prigorodny District which transferred to North Ossetian ASSR but gained predominantly Russian Naursky District and Shelkovskoy District that is considered the homeland for Terek Cossacks.

The Russification policies towards Chechens continued after 1956, with Russian language proficiency required in many aspects of life to provide Chechens better opportunities for advancement in the Soviet system.

On 26 November 1990, the Supreme Council of Chechen-Ingush ASSR adopted the "Declaration of State Sovereignty of the Chechen-Ingush Republic". This declaration was part of the reorganisation of the Soviet Union. This new treaty was to be signed 22 August 1991, which would have transformed 15 republic states into more than 80. The 19–21 August 1991 Soviet coup d'état attempt led to the abandonment of this reorganisation.

With the impending dissolution of the Soviet Union in 1991, an independence movement, the Chechen National Congress, was formed, led by ex-Soviet Air Force general and new Chechen President Dzhokhar Dudayev. It campaigned for the recognition of Chechnya as a separate nation. This movement was opposed by Boris Yeltsin's Russian Federation, which argued that Chechnya had not been an independent entity within the Soviet Union—as the Baltic, Central Asian, and other Caucasian states such as Georgia had—but was part of the Russian Soviet Federative Socialist Republic and hence did not have a right under the Soviet constitution to secede. It also argued that other republics of Russia, such as Tatarstan, would consider seceding from the Russian Federation if Chechnya were granted that right. Finally, it argued that Chechnya was a major hub in the oil infrastructure of Russia and hence its secession would hurt the country's economy and energy access.

During the Chechen Revolution, the Soviet Chechen leader Doku Zavgayev was overthrown and Dzhokhar Dudayev seized power. On 1 November 1991, Dudaev's Chechnya issued a unilateral declaration of independence. In the ensuing decade, the territory was locked in an ongoing struggle between various factions, usually fighting unconventionally.

The First Chechen War took place from 1994 to 1996, when Russian forces attempted to regain control over Chechnya. Despite overwhelming numerical superiority in men, weaponry, and air support, the Russian forces were unable to establish effective permanent control over the mountainous area due to numerous successful full-scale battles and insurgency raids. The Budyonnovsk hospital hostage crisis in 1995 shocked the Russian public.

In April 1996, the first democratically elected president of Chechnya, Dzhokhar Dudayev, was killed by Russian forces using a booby trap bomb and a missile fired from a warplane after he was located by triangulating the position of a satellite phone he was using.

The widespread demoralisation of the Russian forces in the area and a successful offensive to re-take Grozny by Chechen rebel forces led by Aslan Maskhadov prompted Russian President Boris Yeltsin to declare a ceasefire in 1996, and sign a peace treaty a year later that saw a withdrawal of Russian forces.

After the war, parliamentary and presidential elections took place in January 1997 in Chechnya and brought to power new President Aslan Maskhadov, chief of staff and prime minister in the Chechen coalition government, for a five-year term. Maskhadov sought to maintain Chechen sovereignty while pressing the Russian government to help rebuild the republic, whose formal economy and infrastructure were virtually destroyed. Russia continued to send money for the rehabilitation of the republic; it also provided pensions and funds for schools and hospitals. Nearly half a million people (40% of Chechnya's prewar population) had been internally displaced and lived in refugee camps or overcrowded villages. There was an economic downturn. Two Russian brigades were permanently stationed in Chechnya.

In light of the devastated economic structure, kidnapping emerged as the principal source of income countrywide, procuring over US$200 million during the three-year independence of the chaotic fledgling state, although victims were rarely killed. In 1998, 176 people were kidnapped, 90 of whom were released, according to official accounts. President Maskhadov started a major campaign against hostage-takers, and on 25 October 1998, Shadid Bargishev, Chechnya's top anti-kidnapping official, was killed in a remote-controlled car bombing. Bargishev's colleagues then insisted they would not be intimidated by the attack and would go ahead with their offensive. Political violence and religious extremism, blamed on "Wahhabism", was rife. In 1998, Grozny authorities declared a state of emergency. Tensions led to open clashes between the Chechen National Guard and Islamist militants, such as the July 1998 confrontation in Gudermes.

The War of Dagestan began on 7 August 1999, during which the Islamic International Peacekeeping Brigade (IIPB) began an unsuccessful incursion into the neighboring Russian republic of Dagestan in favor of the Shura of Dagestan which sought independence from Russia. In September, a series of apartment bombs that killed around 300 people in several Russian cities, including Moscow, were blamed on the Chechen separatists. Some journalists contested the official explanation, instead blaming the Russian Secret Service for blowing up the buildings to initiate a new military campaign against Chechnya. In response to the bombings, a prolonged air campaign of retaliatory strikes against the Ichkerian regime and a ground offensive that began in October 1999 marked the beginning of the Second Chechen War. Much better organized and planned than the First Chechen War, the Russian armed forces took control of most regions. The Russian forces used brutal force, killing 60 Chechen civilians during a mop-up operation in Aldy, Chechnya on 5 February 2000. After the re-capture of Grozny in February 2000, the Ichkerian regime fell apart.

Chechen rebels continued to fight Russian troops and conduct terrorist attacks. In October 2002, 40–50 Chechen rebels seized a Moscow theater and took about 900 civilians hostage. The crisis ended with 117 hostages and up to 50 rebels dead, mostly due to an unknown aerosol pumped into the building by Russian special forces to incapacitate the people inside.

In response to the increasing terrorism, Russia tightened its grip on Chechnya and expanded its anti-terrorist operations throughout the region. Russia installed a pro-Russian Chechen regime. In 2003, a referendum was held on a constitution that reintegrated Chechnya within Russia but provided limited autonomy. According to the Chechen government, the referendum passed with 95.5% of the votes and almost 80% turnout. "The Economist" was skeptical of the results, arguing that "few outside the Kremlin regard the referendum as fair".

In September 2004, separatist rebels occupied a school in the town of Beslan, North Ossetia, demanding recognition of the independence of Chechnya and a Russian withdrawal. 1,100 people (including 777 children) were taken hostage. The attack lasted three days, resulting in the deaths of over 331 people, including 186 children. After the 2004 school siege, Russian president Vladimir Putin announced sweeping security and political reforms, sealing borders in the Caucasus region and revealing plans to give the central government more power. He also vowed to take tougher action against domestic terrorism, including preemptive strikes against Chechen separatists. In 2005 and 2006, separatist leaders Aslan Maskhadov and Shamil Basayev were killed.

Since 2007, Chechnya has been governed by Ramzan Kadyrov. Kadyrov's rule has been characterized by high-level corruption, a poor human rights record, widespread use of torture, and a growing cult of personality. Allegations of anti-gay purges in Chechnya were initially reported on 1 April 2017.

In April 2009, Russia ended its counter-terrorism operation and pulled out the bulk of its army. The insurgency in the North Caucasus continued even after this date. The Caucasus Emirate had fully adopted the tenets of a Salafist jihadist group through its strict adherence to the Sunni Hanbali obedience to the literal interpretation of the Quran and the Sunnah.

The Chechen government has been outspoken in its support for the 2022 Russian invasion of Ukraine, where a Chechen military force, the Kadyrovtsy, which is under Kadyrov's personal command, has played a leading role, notably in the Siege of Mariupol. Meanwhile, a substantial number of Chechen separatists have allied themselves to the Ukrainian cause and are fighting a mutual Russian enemy in the Donbas. In June 2022, the US State Department advised citizens not to travel to Chechnya, due to terrorism, kidnapping, and risk of civil unrest.

Situated in the eastern part of the North Caucasus in Eastern Europe, Chechnya is surrounded on nearly all sides by Russian Federal territory. In the west, it borders North Ossetia and Ingushetia, in the north, Stavropol Krai, in the east, Dagestan, and to the south, Georgia. Its capital is Grozny. Chechnya is well known for being mountainous, but it is in fact split between the more flat areas north of the Terek, and the highlands south of the Terek.

Rivers:

Despite a relatively small territory, Chechnya is characterized by a variety of climate conditions. The average temperature in Grozny is 11.2 °C (52.1 °F).


The Chechen Republic is divided into 15 districts and 3 cities of republican significance.

According to the 2021 Census, the population of the republic is 1,510,824, up from 1,268,989 in the 2010 Census.
As of the 2021 Census, Chechens at 1,456,792 make up 96.4% of the republic's population. Other groups include Russians (18,225, or 1.2%), Kumyks (12,184, or 0.8%) and a host of other small groups, each accounting for less than 0.5% of the total population The birth rate was 25.41 in 2004. (25.7 in Achkhoi Martan, 19.8 in Groznyy, 17.5 in Kurchaloi, 28.3 in Urus Martan and 11.1 in Vedeno).

The languages used in the Republic are Chechen and Russian. Chechen belongs to the Vaynakh or North-central Caucasian language family, which also includes Ingush and Batsb. Some scholars place it in a wider North Caucasian languages.

Despite its difficult past, Chechnya has a high life expectancy, one of the highest in Russia. But the pattern of life expectancy is unusual, and in according to numerous statistics, Chechnya stands out from the overall picture. In 2020, Chechnya had the deepest fall in life expectancy, but in 2021 it had the biggest rise. Chechnya has the highest excess of life expectancy in rural areas over cities.

Sunni Islam is the predominant religion in Chechnya, practiced by 95% of those polled in Grozny in 2010. Most of the population is Sunni and follows either the Shafi'i or the Hanafi schools of fiqh (Islamic jurisprudence). The Shafi'i school of jurisprudence has a long tradition among the Chechens, and thus it remains the most practiced. Many Chechens are also Sufis, of either the Qadiri or Naqshbandi orders.

Following the end of the Soviet Union, there has been an Islamic revival in Chechnya, and in 2011 it was estimated that there were 465 mosques, including the Akhmad Kadyrov Mosque in Grozny accommodating 10,000 worshippers, as well 31 madrasas, including an Islamic university named Kunta-haji, the Kurchaloy Islamic Institute named Akhmad Kadyrov, and a Center of Islamic Medicine in Grozny which is the largest such institution in Europe. A supreme Islamic administrative territorial organisation in Chechnya is the Spiritual Administration of the Muslims of the Chechen Republic or the Muftiate of the Chechen Republic.

From the 11th to 13th centuries (i.e. before Mongol invasions of Durdzuketia), there was a mission of Georgian Orthodox missionaries to the Nakh peoples. Their success was limited, though a couple of highland teips did convert (conversion was largely by teips). However, during the Mongol invasions, these Christianized teips gradually reverted to paganism, perhaps due to the loss of trans-Caucasian contacts as the Georgians fought the Mongols and briefly fell under their dominion.

The once-strong Russian minority in Chechnya, mostly Terek Cossacks and estimated as numbering approximately 25,000 in 2012, are predominantly Russian Orthodox, although currently only one church exists in Grozny. In August 2011, Archbishop Zosima of Vladikavkaz and Makhachkala performed the first mass baptism ceremony in the history of the Chechen Republic in the Terek River of Naursky District in which 35 citizens of Naursky and Shelkovsky districts were converted to Orthodoxy. As of 2020, there are eight Orthodox churches in Chechnya, the largest is the temple of the Archangel Michael in Grozny.

Since 1990, the Chechen Republic has had many legal, military, and civil conflicts involving separatist movements and pro-Russian authorities. Today, Chechnya is a relatively stable federal republic, although there is still some separatist movement activity. Its regional constitution entered into effect on 2 April 2003, after an all-Chechen referendum was held on 23 March 2003. Some Chechens were controlled by regional teips, or clans, despite the existence of pro- and anti-Russian political structures.

The former separatist religious leader (mufti) Akhmad Kadyrov, looked upon as a traitor by many separatists, was elected president with 83% of the vote in an internationally monitored election on 5th of October 2003. Incidents of ballot stuffing and voter intimidation by Russian soldiers and the exclusion of separatist parties from the polls were subsequently reported by Organization for Security and Co-operation in Europe (OSCE) monitors. On 9 May 2004, Kadyrov was assassinated in Grozny football stadium by a landmine explosion that was planted beneath a VIP stage and detonated during a parade, and Sergey Abramov was appointed acting prime minister after the incident. However, since 2005 Ramzan Kadyrov (son of Akhmad Kadyrov) has been the caretaker prime minister, and in 2007 was appointed as the new president. Many allege he is the wealthiest and most powerful man in the republic, with control over a large private militia (the Kadyrovites). The militia, which began as his father's security force, has been accused of killings and kidnappings by human rights organisations such as Human Rights Watch.

Ichkeria was a member of the Unrepresented Nations and Peoples Organisation between 1991 and 2010. Former president of Georgia Zviad Gamsakhurdia deposed in a military coup of 1991 and a participant of the Georgian Civil War, recognized the independence of the Chechen Republic of Ichkeria in 1993. Diplomatic relations with Ichkeria were also established by the partially recognised Islamic Emirate of Afghanistan under the Taliban government on 16 January 2000. This recognition ceased with the fall of the Taliban in 2001. However, despite Taliban recognition, there were no friendly relations between the Taliban and Ichkeria—Maskhadov rejected their recognition, stating that the Taliban were illegitimate. Ichkeria also received vocal support from the Baltic countries, a group of Ukrainian nationalists, and Poland; Estonia once voted to recognize, but the act never was followed through due to pressure applied by both Russia and the EU.

The president of this government was Aslan Maskhadov, and the foreign minister was Ilyas Akhmadov, who was the spokesman for the president. Maskhadov had been elected for four years in an internationally monitored election in 1997, which took place after signing a peace agreement with Russia. In 2001, he issued a decree prolonging his office for one additional year; he was unable to participate in the 2003 presidential election since separatist parties were barred by the Russian government, and Maskhadov faced accusations of terrorist offenses in Russia. Maskhadov left Grozny and moved to the separatist-controlled areas of the south at the onset of the Second Chechen War. Maskhadov was unable to influence a number of warlords who retain effective control over Chechen territory, and his power was diminished as a result. Russian forces killed Maskhadov on 8 March 2005, and the assassination was widely criticized since it left no legitimate Chechen separatist leader with whom to conduct peace talks. Akhmed Zakayev, deputy prime minister and a foreign minister under Maskhadov, was appointed shortly after the 1997 election and is currently living under asylum in England. He and others chose Abdul Khalim Saidullayev, a relatively unknown Islamic judge who was previously the host of an Islamic program on Chechen television, to replace Maskhadov following his death. On 17 June 2006, it was reported that Russian special forces killed Abdul Khalim Saidullayev in a raid in the Chechen town of Argun. On 10 July 2006, Shamil Basayev, a leader of the Chechen rebel movement, was killed in a truck explosion during an arms deal.

The successor of Saidullayev became Doku Umarov. On 31 October 2007, Umarov abolished the Chechen Republic of Ichkeria and its presidency and in its place proclaimed the Caucasus Emirate with himself as its Emir. This change of status has been rejected by many Chechen politicians and military leaders who continue to support the existence of the republic.

During the 2022 Russian invasion of Ukraine, the Ukrainian parliament voted to recognize the "Chechen Republic of Ichkeria as territory temporarily occupied by the Russian Federation".

Тhe Internal Displacement Monitoring Center reports that after hundreds of thousands of ethnic Russians and Chechens fled their homes following inter-ethnic and separatist conflicts in Chechnya in 1994 and 1999, more than 150,000 people still remain displaced in Russia today.

Нuman rights groups criticized the conduct of the 2005 parliamentary elections as unfairly influenced by the central Russian government and military.

In 2006, Human Rights Watch reported that pro-Russian Chechen forces under the command of Ramzan Kadyrov, as well as federal police personnel, used torture to get information about separatist forces. "If you are detained in Chechnya, you face a real and immediate risk of torture. And there is little chance that your torturer will be held accountable", said Holly Cartner, Director of the Europe and Central Asia division of the Human Rights Watch.

In 2009, the US government financed American organization Freedom House included Chechnya in the "Worst of the Worst" list of most repressive societies in the world, together with Burma, North Korea, Tibet, and others. Memorial considers Chechnya under Kadyrov to be a totalitarian regime.

On 1 February 2009, "The New York Times" released extensive evidence to support allegations of consistent torture and executions under the Kadyrov government. The accusations were sparked by the assassination in Austria of a former Chechen rebel who had gained access to Kadyrov's inner circle, 27-year-old Umar Israilov.

On 1 July 2009, Amnesty International released a detailed report covering the human rights violations committed by the Russian Federation against Chechen citizens. Among the most prominent features was that those abused had no method of redress against assaults, ranging from kidnapping to torture, while those responsible were never held accountable. This led to the conclusion that Chechnya was being ruled without law, being run into further devastating destabilization.

On 10 March 2011, Human Rights Watch reported that since Chechenization, the government has pushed for enforced Islamic dress code. The president Ramzan Kadyrov is quoted as saying "I have the right to criticize my wife. She doesn't [have the right to criticize me]. With us [in Chechen society], a wife is a housewife. A woman should know her place. A woman should give her love to us [men]... She would be [man's] property. And the man is the owner. Here, if a woman does not behave properly, her husband, father, and brother are responsible. According to our tradition, if a woman fools around, her family members kill her... That's how it happens, a brother kills his sister or a husband kills his wife... As a president, I cannot allow for them to kill. So, let women not wear shorts...". He has also openly defended honor killings on several occasions.

On 9 July 2017, Russian newspaper reported that a number of people were subject to an extrajudicial execution on the night of 26 January 2017. It published 27 names of the people known to be dead, but stressed that the list is "not all [of those killed]"; the newspaper asserted that 50 people may have been killed in the execution. Some of the dead were gay, but not all; the deaths appeared to have been triggered by the death of a policeman, and according to the author of the report, Elena Milashina, were executed for alleged terrorism.

In December 2021, up to 50 family members of critics of the Kadyrov government were abducted in a wave of mass kidnappings beginning on 22 December.

In a case study published in 2021, Freedom House reported that Kadyrov also conducts a total transnational repression campaign against Chechen exiles outside of Russia, including assassinations of critics and digital intimidation. 

Although homosexuality is officially legal in Chechnya per Russian law, it is "de facto" illegal. Chechen authorities have reportedly arrested, imprisoned and killed persons based on their perceived sexual orientation.

In 2017, it was reported by and human rights groups that Chechen authorities had set up concentration camps, one of which is in Argun, where gay men are interrogated and subjected to physical violence. On 27 June 2018, the Parliamentary Assembly of the Council of Europe noted "cases of abduction, arbitrary detention and torture ... with the direct involvement of Chechen law enforcement officials and on the orders of top-level Chechen authorities" and expressed dismay "at the statements of Chechen and Russian public officials denying the existence of LGBTI people in the Chechen Republic". Kadyrov's spokesman Alvi Karimov told Interfax that gay people "simply do not exist in the republic" and made an approving reference to honor killings by family members "if there were such people in Chechnya". In a 2021 Council of Europe report into anti-LGBTI hate crimes, rapporteur Foura ben Chikha described the "state-sponsored attacks carried out against LGBTI people in Chechnya in 2017" as "the single most egregious example of violence against LGBTI people in Europe that has occurred in decades".

On 11 January 2019, it was reported that another 'gay purge' had begun in the country in December 2018, with several gay men being detained. The Russian LGBT Network believes that around 40 people were detained and two killed.

During the First Chechen War, the Chechen economy fell apart. In 1994, the separatists planned to introduce a new currency, but the change did not occur due to the re-taking of Chechnya by Russian troops in the Second Chechen War.

The economic situation in Chechnya has improved considerably since 2000. According to the "New York Times", major efforts to rebuild Grozny have been made, and improvements in the political situation have led some officials to consider setting up a tourism industry, though there are claims that construction workers are being irregularly paid and that poor people have been displaced.

Chechnya's unemployment was 67% in 2006 and fell to 21.5% in 2014.

Total revenue of the budget of Chechnya for 2017 was 59.2 billion rubles. Of these, 48.5 billion rubles were grants from the federal budget of the Russian Federation.

In late 1970s, Chechnya produced up to 20 million tons of oil annually, production declined sharply to approximately 3 million tons in the late 1980s, and to below 2 million tons before 1994, first (1994–1996) second Russian invasion of Chechnya (1999) inflicted material damage on the oil-sector infrastructure, oil production decreased to 750,000 tons in 2001 only to increase to 2 million tons in 2006, by 2012 production was 1 million tons.

The culture of Chechnya is based on the native traditions of Chechen people. Chechen mythology along with art have helped shape the culture for over 1,000 years.



Canonization

Canonization is the declaration of a deceased person as an officially recognized saint, specifically, the official act of a Christian communion declaring a person worthy of public veneration and entering their name in the canon catalogue of saints, or authorized list of that communion's recognized saints.

Canonization is a papal declaration that the Catholic faithful may venerate a particular deceased member of the church. Popes began making such decrees in the tenth century. Up to that point, the local bishops governed the veneration of holy men and women within their own dioceses; and there may have been, for any particular saint, no formal decree at all. In subsequent centuries, the procedures became increasingly regularized and the Popes began restricting to themselves the right to declare someone a Catholic saint. In contemporary usage, the term is understood to refer to the act by which any Christian church declares that a person who has died is a saint, upon which declaration the person is included in the list of recognized saints, called the "canon".

In the Roman Martyrology, the following entry is given for the Penitent Thief: "At Jerusalem, the commemoration of the good Thief, who confessed Christ on the cross, and deserved to hear from Him these words: 'This day thou shalt be with Me in paradise.'

The Roman Rite's Canon of the Mass contains only the names of apostles and martyrs, along with that of the Blessed Virgin Mary and, since 1962, that of Saint Joseph her spouse.

By the fourth century, however, "confessors"—people who had confessed their faith not by dying but by word and life—began to be venerated publicly. Examples of such people are Saint Hilarion and Saint Ephrem the Syrian in the East, and Saint Martin of Tours and Saint Hilary of Poitiers in the West. Their names were inserted in the diptychs, the lists of saints explicitly venerated in the liturgy, and their tombs were honoured in like manner as those of the martyrs. Since the witness of their lives was not as unequivocal as that of the martyrs, they were venerated publicly only with the approval by the local bishop. This process is often referred to as "local canonization".

This approval was required even for veneration of a reputed martyr. In his history of the Donatist heresy, Saint Optatus recounts that at Carthage a Catholic matron, named Lucilla, incurred the censures of the Church for having kissed the relics of a reputed martyr whose claims to martyrdom had not been juridically proved. And Saint Cyprian (died 258) recommended that the utmost diligence be observed in investigating the claims of those who were said to have died for the faith. All the circumstances accompanying the martyrdom were to be inquired into; the faith of those who suffered, and the motives that animated them were to be rigorously examined, in order to prevent the recognition of undeserving persons. Evidence was sought from the court records of the trials or from people who had been present at the trials.

Augustine of Hippo (died 430) tells of the procedure which was followed in his day for the recognition of a martyr. The bishop of the diocese in which the martyrdom took place set up a canonical process for conducting the inquiry with the utmost severity. The acts of the process were sent either to the metropolitan or primate, who carefully examined the cause, and, after consultation with the suffragan bishops, declared whether the deceased was worthy of the name of "martyr" and public veneration.

Though not "canonizations" in the narrow sense, acts of formal recognition, such as the erection of an altar over the saint's tomb or transferring the saint's relics to a church, were preceded by formal inquiries into the sanctity of the person's life and the miracles attributed to that person's intercession.

Such acts of recognition of a saint were authoritative, in the strict sense, only for the diocese or ecclesiastical province for which they were issued, but with the spread of the fame of a saint, were often accepted elsewhere also.

In the Catholic Church, both in the Latin and the constituent Eastern churches, the act of canonization is reserved to the Apostolic See and occurs at the conclusion of a long process requiring extensive proof that the candidate for canonization lived and died in such an exemplary and holy way that they are worthy to be recognized as a saint. The Church's official recognition of sanctity implies that the person is now in Heaven and that they may be publicly invoked and mentioned officially in the liturgy of the Church, including in the Litany of the Saints.

In the Catholic Church, canonization is a decree that allows universal veneration of the saint. For permission to venerate merely locally, only beatification is needed.

For several centuries the bishops, or in some places only the primates and patriarchs, could grant martyrs and confessors public ecclesiastical honor; such honor, however, was always decreed only for the local territory of which the grantors had jurisdiction. Only acceptance of the "cultus" by the Pope made the "cultus" universal, because he alone can rule the universal Catholic Church. Abuses, however, crept into this discipline, due as well to indiscretions of popular fervor as to the negligence of some bishops in inquiring into the lives of those whom they permitted to be honoured as saints.

In the Medieval West, the Apostolic See was asked to intervene in the question of canonizations so as to ensure more authoritative decisions. The canonization of Saint Udalric, Bishop of Augsburg by Pope John XV in 993 was the first undoubted example of papal canonization of a saint from outside of Rome being declared worthy of liturgical veneration for the entire church. 

Thereafter, recourse to the judgment of the Pope occurred more frequently. Toward the end of the 11th century, the Popes began asserting their exclusive right to authorize the veneration of a saint against the older rights of bishops to do so for their dioceses and regions. Popes therefore decreed that the virtues and miracles of persons proposed for public veneration should be examined in councils, more specifically in general councils. Pope Urban II, Pope Calixtus II, and Pope Eugene III conformed to this discipline.

Hugh de Boves, Archbishop of Rouen, canonized Walter of Pontoise, or St. Gaultier, in 1153, the final saint in Western Europe to be canonized by an authority other than the Pope: "The last case of canonization by a metropolitan is said to have been that of St. Gaultier, or Gaucher, [A]bbot of Pontoise, by the Archbishop of Rouen. A decree of Pope Alexander III [in] 1170 gave the prerogative to the [P]ope thenceforth, so far as the Western Church was concerned." In a decretal of 1173, Pope Alexander III reprimanded some bishops for permitting veneration of a man who was merely killed while intoxicated, prohibited veneration of the man, and most significantly decreed that "you shall not therefore presume to honor him in the future; for, even if miracles were worked through him, it is not lawful for you to venerate him as a saint without the authority of the Catholic Church." Theologians disagree as to the full import of the decretal of Pope Alexander III: either a new law was instituted, in which case the Pope then for the first time reserved the right of beatification to himself, or an existing law was confirmed.

However, the procedure initiated by the decretal of Pope Alexander III was confirmed by a bull of Pope Innocent III issued on the occasion of the canonization of Cunigunde of Luxembourg in 1200. The bull of Pope Innocent III resulted in increasingly elaborate inquiries to the Apostolic See concerning canonizations. Because the decretal of Pope Alexander III did not end all controversy and some bishops did not obey it in so far as it regarded beatification, the right of which they had certainly possessed hitherto, Pope Urban VIII issued the Apostolic letter "Caelestis Hierusalem cives" of 5 July 1634 that exclusively reserved to the Apostolic See both its immemorial right of canonization and that of beatification. He further regulated both of these acts by issuing his "Decreta servanda in beatificatione et canonizatione Sanctorum" on 12 March 1642.

In his "De Servorum Dei beatificatione et de Beatorum canonizatione" of five volumes the eminent canonist Prospero Lambertini (1675–1758), who later became Pope Benedict XIV, elaborated on the procedural norms of Pope Urban VIII's Apostolic letter "Caelestis Hierusalem cives" of 1634 and "Decreta servanda in beatificatione et canonizatione Sanctorum" of 1642, and on the conventional practice of the time. His work published from 1734 to 1738 governed the proceedings until 1917. The article "Beatification and canonization process in 1914" describes the procedures followed until the promulgation of the "Codex" of 1917. The substance of "De Servorum Dei beatifιcatione et de Beatorum canonizatione" was incorporated into the "Codex Iuris Canonici" ("Code of Canon Law") of 1917, which governed until the promulgation of the revised "Codex Iuris Canonici" in 1983 by Pope John Paul II. Prior to promulgation of the revised "Codex" in 1983, Pope Paul VI initiated a simplification of the procedures.

The Apostolic constitution "Divinus Perfectionis Magister" of Pope John Paul II of 25 January 1983 and the norms issued by the Congregation for the Causes of Saints on 7 February 1983 to implement the constitution in dioceses, continued the simplification of the process initiated by Pope Paul VI. Contrary to popular belief, the reforms did not eliminate the office of the Promoter of the Faith (Latin: "Promotor Fidei"), popularly known as the Devil's advocate, whose office is to question the material presented in favor of canonization. The reforms were intended to reduce the adversarial nature of the process. In November 2012 Pope Benedict XVI appointed Monsignor Carmello Pellegrino as Promoter of the Faith.

Candidates for canonization undergo the following process:
Canonization is a statement of the Church that the person certainly enjoys the beatific vision of Heaven. The title of "Saint" (Latin: "Sanctus" or "Sancta") is then proper, reflecting that the saint is a refulgence of the holiness ("sanctitas") of God himself, which alone comes from God's gift. The saint is assigned a feast day which may be celebrated anywhere in the universal Church, although it is not necessarily added to the General Roman Calendar or local calendars as an "obligatory" feast; parish churches may be erected in their honor; and the faithful may freely celebrate and honor the saint.

Although recognition of sainthood by the Pope does not directly concern a fact of Divine revelation, nonetheless it must be "definitively held" by the faithful as "infallible" pursuant to, at the least, the Universal Magisterium of the Church, because it is a truth related to revelation by historical necessity.

Popes have several times permitted to the universal Church, without executing the ordinary judicial process of canonization described above, the veneration as a saint, the ""cultus"" of one long venerated as such locally. This act of a Pope is denominated "equipollent" or "equivalent canonization" and "confirmation of "cultus"". In such cases, there is no need to have a miracle attributed to the saint to allow their canonization. According to the rules Pope Benedict XIV ("regnat" 17 August 1740 – 3 May 1758) instituted, there are three conditions for an equipollent canonization: (1) existence of an ancient "cultus" of the person, (2) a general and constant attestation to the virtues or martyrdom of the person by credible historians, and (3) uninterrupted fame of the person as a worker of miracles.

The majority of Protestant denominations do not formally recognize saints because the Bible uses the term in a way that suggests all Christians are saints. However, some denominations do, as shown below.

The Church of England, the Mother Church of the Anglican Communion, canonized Charles I as a saint, in the Convocations of Canterbury and York of 1660.

The General Conference of the United Methodist Church has formally declared individuals "martyrs", including Dietrich Bonhoeffer (in 2008) and Martin Luther King Jr. (in 2012).

Various terms are used for canonization by the autocephalous Eastern Orthodox Churches: канонизация ("canonization") or прославление ("glorification", in the Russian Orthodox Church), კანონიზაცია ("kanonizats’ia", Georgian Orthodox Church), канонизација (Serbian Orthodox Church), "canonizare" (Romanian Orthodox Church), and Канонизация (Bulgarian Orthodox Church). Additional terms are used for canonization by other autocephalous Eastern Orthodox Churches: (Katharevousa: ) "agiokatataxi/agiokatataxis", "ranking among saints" (Ecumenical Patriarchate of Constantinople, Church of Cyprus, Church of Greece), "kanonizim" (Albanian Orthodox Church), "kanonizacja" (Polish Orthodox Church), and "kanonizace/kanonizácia" (Czech and Slovak Orthodox Church).

The Orthodox Church in America, an Eastern Orthodox Church partly recognized as autocephalous, uses the term "glorification" for the official recognition of a person as a saint.

Within the Armenian Apostolic Church, part of Oriental Orthodoxy, there had been discussions since the 1980s about canonizing the victims of the Armenian genocide. On 23 April 2015, all of the victims of the genocide were canonized.



Carboxylic acid

In organic chemistry, a carboxylic acid is an organic acid that contains a carboxyl group () attached to an R-group. The general formula of a carboxylic acid is often written as ' or ', sometimes as with R referring to the alkyl, alkenyl, aryl, or other group. Carboxylic acids occur widely. Important examples include the amino acids and fatty acids. Deprotonation of a carboxylic acid gives a carboxylate anion.

Carboxylic acids are commonly identified by their trivial names. They often have the suffix "-ic acid". IUPAC-recommended names also exist; in this system, carboxylic acids have an "-oic acid" suffix. For example, butyric acid () is butanoic acid by IUPAC guidelines. For nomenclature of complex molecules containing a carboxylic acid, the carboxyl can be considered position one of the parent chain even if there are other substituents, such as 3-chloropropanoic acid. Alternately, it can be named as a "carboxy" or "carboxylic acid" substituent on another parent structure, such as 2-carboxyfuran.

The carboxylate anion ( or ) of a carboxylic acid is usually named with the suffix "-ate", in keeping with the general pattern of "-ic acid" and "-ate" for a conjugate acid and its conjugate base, respectively. For example, the conjugate base of acetic acid is acetate.

Carbonic acid, which occurs in bicarbonate buffer systems in nature, is not generally classed as one of the carboxylic acids, despite that it has a moiety that looks like a COOH group. 

Carboxylic acids are polar. Because they are both hydrogen-bond acceptors (the carbonyl ) and hydrogen-bond donors (the hydroxyl ), they also participate in hydrogen bonding. Together, the hydroxyl and carbonyl group form the functional group carboxyl. Carboxylic acids usually exist as dimers in nonpolar media due to their tendency to "self-associate". Smaller carboxylic acids (1 to 5 carbons) are soluble in water, whereas bigger carboxylic acids have limited solubility due to the increasing hydrophobic nature of the alkyl chain. These longer chain acids tend to be soluble in less-polar solvents such as ethers and alcohols. Aqueous sodium hydroxide and carboxylic acids, even hydrophobic ones, react to yield water-soluble sodium salts. For example, enanthic acid has a low solubility in water (0.2 g/L), but its sodium salt is very soluble in water.

Carboxylic acids tend to have higher boiling points than water, because of their greater surface areas and their tendency to form stabilized dimers through hydrogen bonds. For boiling to occur, either the dimer bonds must be broken or the entire dimer arrangement must be vaporized, increasing the enthalpy of vaporization requirements significantly.

Carboxylic acids are Brønsted–Lowry acids because they are proton (H) donors. They are the most common type of organic acid.

Carboxylic acids are typically weak acids, meaning that they only partially dissociate into cations and anions in neutral aqueous solution. For example, at room temperature, in a 1-molar solution of acetic acid, only 0.001% of the acid are dissociated (i.e. 10 moles out of 1 mol). Electron-withdrawing substituents, such as -CF group, give stronger acids (the p"K" of acetic acid is 4.76 whereas trifluoroacetic acid, with a trifluoromethyl substituent, has a p"K" of 0.23). Electron-donating substituents give weaker acids (the p"K" of formic acid is 3.75 whereas acetic acid, with a methyl substituent, has a p"K" of 4.76)

Deprotonation of carboxylic acids gives carboxylate anions; these are resonance stabilized, because the negative charge is delocalized over the two oxygen atoms, increasing the stability of the anion. Each of the carbon–oxygen bonds in the carboxylate anion has a partial double-bond character. The carbonyl carbon's partial positive charge is also weakened by the -/ negative charges on the 2 oxygen atoms.

Carboxylic acids often have strong sour odours. Esters of carboxylic acids tend to have fruity, pleasant odours, and many are used in perfume.

Carboxylic acids are readily identified as such by infrared spectroscopy. They exhibit a sharp band associated with vibration of the C=O carbonyl bond ("ν") between 1680 and 1725 cm. A characteristic "ν" band appears as a broad peak in the 2500 to 3000 cm region. By H NMR spectrometry, the hydroxyl hydrogen appears in the 10–13 ppm region, although it is often either broadened or not observed owing to exchange with traces of water.

Many carboxylic acids are produced industrially on a large scale. They are also frequently found in nature. Esters of fatty acids are the main components of lipids and polyamides of aminocarboxylic acids are the main components of proteins.

Carboxylic acids are used in the production of polymers, pharmaceuticals, solvents, and food additives. Industrially important carboxylic acids include acetic acid (component of vinegar, precursor to solvents and coatings), acrylic and methacrylic acids (precursors to polymers, adhesives), adipic acid (polymers), citric acid (a flavor and preservative in food and beverages), ethylenediaminetetraacetic acid (chelating agent), fatty acids (coatings), maleic acid (polymers), propionic acid (food preservative), terephthalic acid (polymers). Important carboxylate salts are soaps.

In general, industrial routes to carboxylic acids differ from those used on a smaller scale because they require specialized equipment.


Preparative methods for small scale reactions for research or for production of fine chemicals often employ expensive consumable reagents.

Many reactions produce carboxylic acids but are used only in specific cases or are mainly of academic interest.

The most widely practiced reactions convert carboxylic acids into esters, amides, carboxylate salts, acid chlorides, and alcohols. Carboxylic acids react with bases to form carboxylate salts, in which the hydrogen of the hydroxyl (–OH) group is replaced with a metal cation. For example, acetic acid found in vinegar reacts with sodium bicarbonate (baking soda) to form sodium acetate, carbon dioxide, and water:

Carboxylic acids also react with alcohols to give esters. This process is widely used, e.g. in the production of polyesters. Likewise, carboxylic acids are converted into amides, but this conversion typically does not occur by direct reaction of the carboxylic acid and the amine. Instead esters are typical precursors to amides. The conversion of amino acids into peptides is a significant biochemical process that requires ATP.

The hydroxyl group on carboxylic acids may be replaced with a chlorine atom using thionyl chloride to give acyl chlorides. In nature, carboxylic acids are converted to thioesters.

Like esters, most carboxylic acids can be reduced to alcohols by hydrogenation, or using hydride transferring agents such as lithium aluminium hydride. Strong alkyl transferring agents, such as organolithium compounds but not Grignard reagents, will reduce carboxylic acids to ketones along with transfer of the alkyl group.

Vilsmaier reagent ("N","N"-Dimethyl(chloromethylene)ammonium chloride [ClHC\dN+(CH3)2]Cl−) is a highly chemoselective agent for carboxylic acid reduction. It selectively activates the carboxylic acid to give the carboxymethyleneammonium salt, which can be reduced by a mild reductant like lithium tris("t"-butoxy)aluminum hydride to afford an aldehyde in a one pot procedure. This procedure is known to tolerate reactive carbonyl functionalities such as ketone as well as moderately reactive ester, olefin, nitrile, and halide moieties.


The carboxyl radical, •COOH, only exists briefly. The acid dissociation constant of •COOH has been measured using electron paramagnetic resonance spectroscopy. The carboxyl group tends to dimerise to form oxalic acid.



Chernobyl

Chernobyl ( , ; , ) or Chornobyl (, ) is a partially abandoned city in the Chernobyl Exclusion Zone, situated in the Vyshhorod Raion of northern Kyiv Oblast, Ukraine. Chernobyl is about north of Kyiv, and southwest of the Belarusian city of Gomel. Before its evacuation, the city had about 14,000 residents (considerably less than neighboring Pripyat). While living anywhere within the Chernobyl Exclusion Zone is technically illegal today, authorities tolerate those who choose to live within some of the less irradiated areas, and around 1,000 people live in Chernobyl today.

First mentioned as a ducal hunting lodge in 1193, the city has changed hands multiple times over the course of history. Jews moved into the city in the 16th century, and a now-defunct monastery was established in the area in 1626. By the end of the 18th century, Chernobyl was a major centre of Hasidic Judaism under the Twersky Dynasty, which left Chernobyl after the city was subjected to pogroms in the early 20th century. The Jewish community was later murdered during the Holocaust. Chernobyl was chosen as the site of Ukraine's first nuclear power plant in 1972, located north of the city, which opened in 1977. Chernobyl was evacuated on 5 May 1986, nine days after a catastrophic nuclear disaster at the plant, which was the largest nuclear disaster in history. Along with the residents of the nearby city of Pripyat, which was built as a home for the plant's workers, the population was relocated to the newly built city of Slavutych, and most have never returned.
The city was the administrative centre of Chernobyl Raion (district) from 1923. After the disaster, in 1988, the raion was dissolved and administration was transferred to the neighbouring Ivankiv Raion. The raion was abolished on 18 July 2020 as part of the administrative reform of Ukraine, which reduced the number of raions of Kyiv Oblast to seven. The area of Ivankiv Raion was merged into Vyshhorod Raion.

Although Chernobyl is primarily a ghost town today, a small number of people still live there, in houses marked with signs that read, "Owner of this house lives here", and a small number of animals live there as well. Workers on watch and administrative personnel of the Chernobyl Exclusion Zone are also stationed in the city. The city has two general stores and a hotel.

During the 2022 Russian invasion of Ukraine, Chernobyl was temporarily captured and occupied by Russian forces between 24 February and 2 April. After its capture, it was reported that radiation levels temporarily rose, due to human activities, including earthworks, which disturbed the dust.

The city's name is the same as one of the Ukrainian names for "Artemisia vulgaris", mugwort or common wormwood: (or more commonly , 'common artemisia'). The name is inherited from or , a compound of + , the parts related to and , 'stalk', so named in distinction to the lighter-stemmed wormwood "A. absinthium".

The name in languages used nearby is:

The name in languages formerly used in the area is:
In English, the Russian-derived spelling "Chernobyl" has been commonly used, but some style guides recommend the spelling "Chornobyl", or the use of romanized Ukrainian names for Ukrainian places generally.

The Polish Geographical Dictionary of the Kingdom of Poland of 1880–1902 states that the time the city was founded is not known.

Some older geographical dictionaries and descriptions of modern Eastern Europe mention "Czernobol" (Chernobyl) with reference to Ptolemy's world map (2nd century AD). Czernobol is identified as "oppidium Sarmatiae" (Lat., "a city in Sarmatia"), by the 1605 "Lexicon geographicum" of Filippo Ferrari and the 1677 "Lexicon Universale" of Johann Jakob Hofmann. According to the "Dictionary of Ancient Geography" of Alexander Macbean (London, 1773), Azagarium is "a town of Sarmatia Europaea, on the Borysthenes" (Dnieper), 36° East longitude and 50°40' latitude. The city is "now supposed to be "Czernobol", a town of Poland, in Red Russia [Red Ruthenia], in the Palatinate of Kiow [see Kiev Voivodeship], not far from the Borysthenes."

Whether Azagarium is indeed Czernobol is debatable. The question of Azagarium's correct location was raised in 1842 by Habsburg-Slovak historian, Pavel Jozef Šafárik, who published a book titled "Slavic Ancient History" ("Sławiańskie starożytności"), where he claimed Azagarium to be the hill of Zaguryna, which he found on an old Russian map "Bolzoj czertez" (Big drawing) near the city of Pereiaslav, now in central Ukraine.

In 2019, Ukrainian architect Boris Yerofalov-Pylypchak published a book, "Roman Kyiv or Castrum Azagarium at Kyiv-Podil".

The archaeological excavations that were conducted in 2005–2008 found a cultural layer from the 10–12th centuries AD, which predates the first documentary mention of Chernobyl.

Around the 12th century Chernobyl was part of the land of Kievan Rus′. The first known mention of the settlement as Chernobyl is from an 1193 charter, which describes it as a hunting lodge of Knyaz Rurik Rostislavich. In 1362 it was a crown village of the Grand Duchy of Lithuania. Around that time the town had own castle which was ruined at least on two occasions in 1473 and 1482. The Chernobyl castle was rebuilt in the first quarter of the 16th century being located nearby the settlement in a hard to reach area. With revival of the castle, Chernobyl became a county seat. In 1552 it accounted for 196 buildings with 1,372 residents, out of which over 1,160 were considered city dwellers. In the city were developing various crafts professions such as blacksmith, cooper among others. Near Chernobyl has been excavated bog iron, out of which was produced iron. The village was granted to Filon Kmita, a captain of the royal cavalry, as a fiefdom in 1566. Following the Union of Lublin, the province where Chernobyl is located was transferred to the Crown of the Kingdom of Poland in 1569. Under the Polish Crown, Chernobyl became a seat of eldership (starostwo). During that period Chernobyl was inhabited by Ukrainian peasants, some Polish people and a relatively large number of Jews. Jews were brought to Chernobyl by Filon Kmita, during the Polish campaign of colonization. The first mentioning of Jewish community in Chernobyl is in the 17th century. In 1600 the first Roman Catholic church was built in the town. Local population was persecuted for holding Eastern Orthodox rite services. The traditionally Eastern Orthodox Ukrainian peasantry around the town were forcibly converted, by Poland, to the Ruthenian Uniate Church. In 1626, during the Counter-reformation, a Dominican church and monastery were founded by Lukasz Sapieha. A group of Old Catholics opposed the decrees of the Council of Trent. The Chernobyl residents actively supported the Khmelnytsky Uprising (1648–1657).

With the signing of the Truce of Andrusovo in 1667, Chernobyl was secured after the Sapieha family. Sometime in the 18th century, the place was passed on to the Chodkiewicz family. In the mid-18th century the area around Chernobyl was engulfed in a number of peasant riots, which caused Prince Riepnin to write from Warsaw to Major General Krechetnikov, requesting hussars to be sent from Kharkiv to deal with the uprising near Chernobyl in 1768. The 8th Lithuanian Infantry Regiment was stationed in the town in 1791. By the end of the 18th century, the town accounted for 2,865 residents and had 642 buildings.

Following the Second Partition of Poland, in 1793 Chernobyl was annexed by the Russian Empire and became part of Radomyshl county ("uezd") as a supernumerary town ("zashtatny gorod"). Many of the Uniate Church converts returned to Eastern Orthodoxy.

In 1832, following the failed Polish November Uprising, the Dominican monastery was sequestrated. The church of the Old Catholics was disbanded in 1852.

Until the end of the 19th century, Chernobyl was a privately owned city that belonged to the Chodkiewicz family. In 1896 they sold the city to the state, but until 1910 they owned a castle and a house in the city.

In the second half of the 18th century, Chernobyl became a major centre of Hasidic Judaism. The Chernobyl Hasidic dynasty had been founded by Rabbi Menachem Nachum Twersky. The Jewish population suffered greatly from pogroms in October 1905 and in March–April 1919; many Jews were killed or robbed at the instigation of the Russian nationalist Black Hundreds. When the Twersky Dynasty left Chernobyl in 1920, it ceased to exist as a center of Hasidism.

Chernobyl had a population of 10,800 in 1898, including 7,200 Jews. In the beginning of March 1918 Chernobyl was occupied in World War I by German forces (see Treaty of Brest-Litovsk).

Ukrainians and Bolsheviks fought over the city in the ensuing Civil War. In the Polish–Soviet War of 1919–20, Chernobyl was taken first by the Polish Army and then by the cavalry of the Red Army. From 1921 onwards, it was officially incorporated into the Ukrainian SSR.

Between 1929 and 1933, Chernobyl suffered from killings during Stalin's collectivization campaign. It was also affected by the famine that resulted from Stalin's policies. The Polish and German community of Chernobyl was deported to Kazakhstan in 1936, during the Frontier Clearances.

During World War II, Chernobyl was occupied by the German Army from 25 August 1941 to 17 November 1943. When the Germans arrived, only 400 Jews remained in Chernobyl; they were murdered during the Holocaust.

In 1972, the Duga-1 radio receiver, part of the larger Duga over-the-horizon radar array, began construction west-northwest of Chernobyl. It was the origin of the Russian Woodpecker and was designed as part of an anti-ballistic missile early warning radar network.

On 15 August 1972, the Chernobyl Nuclear Power Plant (officially the Vladimir Ilyich Lenin Nuclear Power Plant) began construction about northwest of Chernobyl. The plant was built alongside Pripyat, an "atomograd" city founded on 4 February 1970 that was intended to serve the nuclear power plant. The decision to build the power plant was adopted by the Central Committee of the Communist Party of the Soviet Union and the Council of Ministers of the Soviet Union on recommendations of the State Planning Committee that the Ukrainian SSR be its location. It was the first nuclear power plant to be built in Ukraine.

With the dissolution of the Soviet Union in 1991, Chernobyl remained part of Ukraine within the Chernobyl Exclusion Zone which Ukraine inherited from the Soviet Union.

During the 2022 Russian invasion of Ukraine, Russian forces captured the city on 24 February. After its capture, Ukrainian officials reported that the radiation levels started to rise due to recent military activity causing radioactive dust to ascend into the air. Hundreds of Russian soldiers were suffering from radiation poisoning after digging trenches in a contaminated area, and one died. On 31 March it was reported that Russian forces had left the exclusion zone. Ukrainian authorities reasserted control over the area on 2 April.

Chernobyl is located about north of Kyiv, and southwest of the Belarusian city of Gomel.

Chernobyl has a humid continental climate (Dfb) with very warm, wet summers with cool nights and long, cold, and snowy winters.

On 26 April 1986, one of the reactors at the Chernobyl Nuclear Power Plant exploded after unsanctioned experiments on the reactor by plant operators were done improperly. The resulting loss of control was due to design flaws of the RBMK reactor, which made it unstable when operated at low power, and prone to thermal runaway where increases in temperature increase reactor power output.

Chernobyl city was evacuated nine days after the disaster. The level of contamination with caesium-137 was around 555 kBq/m (surface ground deposition in 1986).

Later analyses concluded that, even with very conservative estimates, relocation of the city (or of any area below 1500 kBq/m) could not be justified on the grounds of radiological health.
This however does not account for the uncertainty in the first few days of the accident about further depositions and weather patterns.
Moreover, an earlier short-term evacuation could have averted more significant doses from short-lived isotope radiation (specifically iodine-131, which has a half-life of about eight days).
Estimates of health effects are a subject of some controversy, see Effects of the Chernobyl disaster.

In 1998, average caesium-137 doses from the accident (estimated at 1–2 mSv per year) did not exceed those from other sources of exposure. Current effective caesium-137 dose rates as of 2019 are 200–250 nSv/h, or roughly 1.7–2.2 mSv per year,
which is comparable to the worldwide average background radiation from natural sources.

The base of operations for the administration and monitoring of the Chernobyl Exclusion Zone was moved from Pripyat to Chernobyl. Chernobyl currently contains offices for the State Agency of Ukraine on the Exclusion Zone Management and accommodations for visitors. Apartment blocks have been repurposed as accommodations for employees of the State Agency. The length of time that workers may spend within the Chernobyl Exclusion Zone is restricted by regulations that have been implemented to limit radiation exposure. Today, visits are allowed to Chernobyl but limited by strict rules.

In 2003, the United Nations Development Programme launched a project, called the Chernobyl Recovery and Development Programme (CRDP), for the recovery of the affected areas. The main goal of the CRDP's activities is supporting the efforts of the Government of Ukraine to mitigate the long-term social, economic, and ecological consequences of the Chernobyl disaster.

The city has become overgrown and many types of animals live there. According to census information collected over an extended period of time, it is estimated that more mammals live there now than before the disaster.

Notably, Mikhail Gorbachev, the final leader of the Soviet Union, stated in respect to the Chernobyl disaster that, "More than anything else, (Chernobyl) opened the possibility of much greater freedom of expression, to the point that the (Soviet) system as we knew it could no longer continue."




Cyan

Cyan () is the color between blue and green on the visible spectrum of light. It is evoked by light with a predominant wavelength between 490 and 520 nm, between the wavelengths of green and blue.

In the subtractive color system, or CMYK color model, which can be overlaid to produce all colors in paint and color printing, cyan is one of the primary colors, along with magenta and yellow. In the additive color system, or RGB color model, used to create all the colors on a computer or television display, cyan is made by mixing equal amounts of green and blue light. Cyan is the complement of red; it can be made by the removal of red from white. Mixing red light and cyan light at the right intensity will make white light.

Different shades of cyan can vary in terms of hue, chroma (also known as saturation, intensity, or colorfulness), or lightness (or value, tone, or brightness), or any combination of these characteristics. Differences in value can also be referred to as tints and shades, with a tint being a cyan mixed with white, and a shade being mixed with black.

Color nomenclature is subjective. Many shades of cyan with a bluish hue are called blue. Similarly, those with a greenish hue are referred to as green. A cyan with a dark shade is commonly known as teal. A teal blue shade leans toward the blue end of the spectrum. Variations of teal with a greener tint are commonly referred to as teal green. 

Turquoise, reminiscent of the stone with the same name, is a shade in the green spectrum of cyan hues. Celeste is a lightly tinted cyan that represents the color a clear sky. Other colors in the cyan color range are electric blue, aquamarine, and others described as blue-green.

Cyan boasts a rich and diverse history, holding cultural significance for millennia. In ancient civilizations, turquoise, valued for its aesthetic appeal, served as a highly regarded precious gem. Turquoise comes in a variety of shades from green to blue, but cyan hues are particularly prevalent. Approximately 3,700 years ago, an intricately crafted dragon-shaped treasure made from over 2,000 pieces of turquoise and jade was created. This artifact is widely recognized as the oldest Chinese dragon totem by many Chinese scholars.

Turquoise jewelry also held significant importance among the Aztecs, who often featured this precious gemstone in vibrant frescoes for both symbolic and decorative purposes. The Aztecs revered turquoise, associating its color with the heavens and sacredness. Additionally, ancient Egyptians interpreted cyan hues as representing faith and truth, while Tibetans viewed them as a symbol of infinity.

After earlier uses in various contexts, cyan hues found increased use in diverse cultures due to their appealing aesthetic qualities in religious structures and art pieces. For example, the prominent dome of the Goharshad Mosque in Iran, built in 1418, showcases this trend. Additionally, Jacopo da Pontormo's use of a teal shade for Mary's robe in the 1528 painting "Carmignano Visitation" demonstrates the allure for these hues. During the 16th century, speakers of the English language began using the term "turquoise" to describe the cyan color of objects that resembled the color of the stone.

In the 1870s, the French sculptor Frédéric Bartholdi began the construction of what would later become the Statue of Liberty. Over time, exposure to the elements caused the copper structure to develop its distinctive patina, now recognized as iconic cyan. Following this, there was a significant advancement in the use of cyan during the late 19th and early 20th centuries. 

Impressionist artists, such as Claude Monet in his renowned "Water Lilies", effectively incorporated cyan hues into their works. Deviating from traditional interpretations of local color under neutral lighting conditions, the focus of artists was on accurately depicting perceived color and the influence of light on altering object hues. Specifically, daylight plays a significant role in shifting the perceived color of objects toward cyan hues. In 1917, the color term "teal" was introduced to describe deeper shades of cyan.

In the late 19th century, while "traditional" nomenclature of red, yellow, and blue persisted, the printing industry initiated a shift towards utilizing magenta and cyan inks for red and blue hues, respectively. This transition aimed to establish a more versatile color gamut achievable with only three primary colors. In 1949, a document in the printing industry stated: “The four-color set comprises Yellow, Red (magenta), Blue (cyan), Black”. This practice of labeling magenta, yellow, and cyan as red, yellow, and blue persisted until 1961. As the hues evolved, the printing industry maintained the use of the "traditional" terms red, yellow, and blue. Consequently, pinpointing the exact date of origin for CMYK, in which cyan serves as a primary color, proves "challenging".

Its name is derived from the Ancient Greek word "kyanos" (κύανος), meaning "dark blue enamel, Lapis lazuli". It was formerly known as "cyan blue" or cyan-blue, and its first recorded use as a color name in English was in 1879. Further origins of the color name can be traced back to a dye produced from the cornflower ("Centaurea cyanus").

In most languages, 'cyan' is not a basic color term and it phenomenologically appears as a greenish vibrant hue of blue to most English speakers. Other English terms for this "borderline" hue region include "blue green", "aqua", "turquoise", "teal", and "grue".

The web color cyan shown at right is a secondary color in the RGB color model, which uses combinations of red, green and blue light to create all the colors on computer and television displays. In X11 colors, this color is called both cyan and aqua. In the HTML color list, this same color is called aqua.

The web colors are more vivid than the cyan used in the CMYK color system, and the web colors cannot be accurately reproduced on a printed page. To reproduce the web color cyan in inks, it is necessary to add some white ink to the printer's cyan below, so when it is reproduced in printing, it is not a primary subtractive color. It is called "aqua" (a name in use since 1598) because it is a color commonly associated with water, such as the appearance of the water at a tropical beach.

Cyan is also one of the common inks used in four-color printing, along with magenta, yellow, and black; this set of colors is referred to as CMYK. In printing, the cyan ink is sometimes known as printer's cyan, process cyan, or process blue.

While both the additive secondary and the subtractive primary are called "cyan", they can be substantially different from one another. Cyan printing ink is typically more saturated than the RGB secondary cyan, depending on what RGB color space and ink are considered. That is, process cyan is usually outside the RGB gamut, and there is no fixed conversion from CMYK primaries to RGB. Different formulations are used for printer's ink, so there can be variations in the printed color that is pure cyan ink. This is because real-world subtractive (unlike additive) color mixing does not consistently produce the same result when mixing apparently identical colors, since the specific frequencies filtered out to produce that color affect how it interacts with other colors. Phthalocyanine blue is one such commonly used pigment. A typical formulation of "process cyan" is shown in the color box on the right.









Conventional insulin therapy

Conventional insulin therapy is a therapeutic regimen for treatment of diabetes mellitus which contrasts with the newer intensive insulin therapy.

This older method (prior to the development home blood glucose monitoring) is still in use in a proportion of cases.

Conventional insulin therapy is characterized by:

The down side of this method is that it is difficult to achieve as good results of glycemic control as with intensive insulin therapy. The advantage is that, for diabetics with a regular lifestyle, the regime is less intrusive than the intensive therapy.

Cream

Cream is a dairy product composed of the higher-fat layer skimmed from the top of milk before homogenization. In un-homogenized milk, the fat, which is less dense, eventually rises to the top. In the industrial production of cream, this process is accelerated by using centrifuges called "separators". In many countries, it is sold in several grades depending on the total butterfat content. It can be dried to a powder for shipment to distant markets, and contains high levels of saturated fat.

Cream skimmed from milk may be called "sweet cream" to distinguish it from cream skimmed from whey, a by-product of cheese-making. Whey cream has a lower fat content and tastes more salty, tangy, and "cheesy". In many countries partially fermented cream is also sold: sour cream, crème fraîche, and so on. Both forms have many culinary uses in both sweet and savoury dishes.

Cream produced by cattle (particularly Jersey cattle) grazing on natural pasture often contains some carotenoid pigments derived from the plants they eat; traces of these intensely colored pigments give milk a slightly yellow tone, hence the name of the yellowish-white color: cream. Carotenoids are also the origin of butter's yellow color. Cream from goat's milk, water buffalo milk, or from cows fed indoors on grain or grain-based pellets, is white.

Cream is used as an ingredient in many foods, including ice cream, many sauces, soups, stews, puddings, and some custard bases, and is also used for cakes. Whipped cream is served as a topping on ice cream sundaes, milkshakes, lassi, eggnog, sweet pies, strawberries, blueberries, or peaches. Cream is also used in Indian curries such as masala dishes.

Cream (usually light/single cream or half and half) may be added to coffee.

Both single and double cream (see Types for definitions) can be used in cooking. Double cream or full-fat crème fraîche is often used when the cream is added to a hot sauce, to prevent it separating or "splitting". Double cream can be thinned with milk to make an approximation of single cream.

The French word denotes not only dairy cream but also other thick liquids such as sweet and savory custards, which are normally made with milk, not cream.

Different grades of cream are distinguished by their fat content, whether they have been heat-treated, whipped, and so on. In many jurisdictions, there are regulations for each type.

The Australia New Zealand Food Standards Code – Standard 2.5.2 – Defines cream as a milk product comparatively rich in fat, in the form of an emulsion of fat-in-skim milk, which can be obtained by separation from milk. Cream sold without further specification must contain no less than 350 g/kg (35%) milk fat.

Manufacturers labels may distinguish between different fat contents, a general guideline is as follows:

Canadian cream definitions are similar to those used in the United States, except for "light cream", which is very low-fat cream, usually with 5 or 6 percent butterfat. Specific product characteristics are generally uniform throughout Canada, but names vary by both geographic and linguistic area and by manufacturer: "coffee cream" may be 10 or 18 percent cream and "half-and-half" () may be 3, 5, 6 or 10 percent, all depending on location and brand.

Regulations allow cream to contain acidity regulators and stabilizers. For whipping cream, allowed additives include skim milk powder (≤ 0.25%), glucose solids (≤ 0.1%), calcium sulphate (≤ 0.005%), and xanthan gum (≤ 0.02%). The content of milk fat in canned cream must be displayed as a percentage followed by "milk fat", "B.F", or "M.F".

In France, the use of the term "cream" for food products is defined by the decree 80-313 of April 23, 1980. It specifies the minimum rate of milk fat (12%) as well as the rules for pasteurisation or UHT sterilisation. The mention "crème fraîche" (fresh cream) can only be used for pasteurised creams conditioned on production site within 24h after pasteurisation. Even if food additives complying with French and European laws are allowed, usually, none will be found in plain "crèmes" and "crèmes fraîches" apart from lactic ferments (some low cost creams (or close to creams) can contain thickening agents, but rarely). Fat content is commonly shown as "XX% M.G." ("matière grasse").
Russia, as well as other EAC countries, legally separates cream into two classes: normal (10–34% butterfat) and heavy (35–58%), but the industry has pretty much standardized around the following types:
In Sweden, cream is usually sold as:

Mellangrädde (27%) is, nowadays, a less common variant. 
Gräddfil (usually 12%) and Creme Fraiche (usually around 35%) are two common sour cream products.

In Switzerland, the types of cream are legally defined as follows:

Sour cream and crème fraîche (German: Sauerrahm, Crème fraîche; French: crème acidulée, crème fraîche; Italian: panna acidula, crème fraîche) are defined as cream soured by bacterial cultures.

Thick cream (German: ; French: ; Italian: ) is defined as cream thickened using thickening agents.

In the United Kingdom, these types of cream are produced. Fat content must meet the Food Labelling Regulations 1996.

In the United States, cream is usually sold as:

Not all grades are defined by all jurisdictions, and the exact fat content ranges vary. The above figures, except for "manufacturer's cream", are based on the Code of Federal Regulations, Title 21, Part 131.

Cream may have thickening agents and stabilizers added. Thickeners include sodium alginate, carrageenan, gelatine, sodium bicarbonate, tetrasodium pyrophosphate, and alginic acid.

Other processing may be carried out. For example, cream has a tendency to produce oily globules (called "feathering") when added to coffee. The stability of the cream may be increased by increasing the non-fat solids content, which can be done by partial demineralisation and addition of sodium caseinate, although this is expensive.

 by churning cream to separate the butterfat and buttermilk. This can be done by hand or by machine.

Whipped cream is made by whisking or mixing air into cream with more than 30% fat, to turn the liquid cream into a soft solid. Nitrous oxide, from whipped-cream chargers may also be used to make whipped cream.

Sour cream, produced in many countries, is cream (12 to 16% or more milk fat) that has been subjected to a bacterial culture that produces lactic acid (0.5%+), which sours and thickens it.

Crème fraîche (28% milk fat) is slightly soured with bacterial culture, but not as sour or as thick as sour cream. Mexican crema (or cream espesa) is similar to crème fraîche.

Smetana is a heavy cream-derived (15–40% milk fat) Central and Eastern European sweet or sour cream.

Rjome or rømme is Norwegian sour cream containing 35% milk fat, similar to Icelandic sýrður rjómi.

Clotted cream in the United Kingdom is made through a process that starts by slowly heating whole milk to produce a very high-fat (55%) product, similar to Indian malai.

Reduced cream is a cream product in New Zealand, often used to make Kiwi dip.

Some non-edible substances are called creams due to their consistency: shoe cream is runny, unlike regular waxy shoe polish; hand/body "creme" or "skin cream" is meant for moisturizing the skin.

Regulations in many jurisdictions restrict the use of the word "cream" for foods. Words such as "creme", "kreme", "creame", or "whipped topping" (e.g., Cool Whip) are often used for products which cannot legally be called cream, though in some jurisdictions even these spellings may be disallowed, for example under the doctrine of "idem sonans". Oreo and Hydrox cookies are a type of sandwich cookie in which two biscuits have a soft, sweet filling between them that is called "crème filling." In some cases, foods can be described as cream although they do not contain predominantly milk fats; for example, in Britain, "ice cream" can contain non-milk fat (declared on the label) in addition to or instead of cream, and salad cream is the customary name for a non-dairy condiment that has been produced since the 1920s.

In other languages, cognates of "cream" are also sometimes used for non-food products, such as fogkrém (Hungarian for toothpaste), or Sonnencreme (German for sunscreen).

Some products are described as "cream alternatives". For example, "Elmlea Double", etc. are blends of buttermilk or lentils and vegetable oil with other additives sold by Upfield in the United Kingdom packaged and shelved in the same way as cream, labelled as having "a creamy taste".



Chemical vapor deposition

Chemical vapor deposition (CVD) is a vacuum deposition method used to produce high-quality, and high-performance, solid materials. The process is often used in the semiconductor industry to produce thin films.

In typical CVD, the wafer (substrate) is exposed to one or more volatile precursors, which react and/or decompose on the substrate surface to produce the desired deposit. Frequently, volatile by-products are also produced, which are removed by gas flow through the reaction chamber.

Microfabrication processes widely use CVD to deposit materials in various forms, including: monocrystalline, polycrystalline, amorphous, and epitaxial. These materials include: silicon (dioxide, carbide, nitride, oxynitride), carbon (fiber, nanofibers, nanotubes, diamond and graphene), fluorocarbons, filaments, tungsten, titanium nitride and various high-κ dielectrics.

The term "chemical vapour deposition" was coined in 1960 by "John M. Blocher, Jr." who intended to differentiate "chemical" from "physical vapour deposition" (PVD).

CVD is practiced in a variety of formats. These processes generally differ in the means by which chemical reactions are initiated.

Most modern CVD is either LPCVD or UHVCVD.

CVD is commonly used to deposit conformal films and augment substrate surfaces in ways that more traditional surface modification techniques are not capable of. CVD is extremely useful in the process of atomic layer deposition at depositing extremely thin layers of material. A variety of applications for such films exist. Gallium arsenide is used in some integrated circuits (ICs) and photovoltaic devices. Amorphous polysilicon is used in photovoltaic devices. Certain carbides and nitrides confer wear-resistance. Polymerization by CVD, perhaps the most versatile of all applications, allows for super-thin coatings which possess some very desirable qualities, such as lubricity, hydrophobicity and weather-resistance to name a few. The CVD of metal-organic frameworks, a class of crystalline nanoporous materials, has recently been demonstrated. Recently scaled up as an integrated cleanroom process depositing large-area substrates, the applications for these films are anticipated in gas sensing and low-κ dielectrics. CVD techniques are advantageous for membrane coatings as well, such as those in desalination or water treatment, as these coatings can be sufficiently uniform (conformal) and thin that they do not clog membrane pores.

Polycrystalline silicon is deposited from trichlorosilane (SiHCl) or silane (SiH), using the following reactions:

This reaction is usually performed in LPCVD systems, with either pure silane feedstock, or a solution of silane with 70–80% nitrogen. Temperatures between 600 and 650 °C and pressures between 25 and 150 Pa yield a growth rate between 10 and 20 nm per minute. An alternative process uses a hydrogen-based solution. The hydrogen reduces the growth rate, but the temperature is raised to 850 or even 1050 °C to compensate. Polysilicon may be grown directly with doping, if gases such as phosphine, arsine or diborane are added to the CVD chamber. Diborane increases the growth rate, but arsine and phosphine decrease it.

Silicon dioxide (usually called simply "oxide" in the semiconductor industry) may be deposited by several different processes. Common source gases include silane and oxygen, dichlorosilane (SiClH) and nitrous oxide (NO), or tetraethylorthosilicate (TEOS; Si(OCH)). The reactions are as follows:

The choice of source gas depends on the thermal stability of the substrate; for instance, aluminium is sensitive to high temperature. Silane deposits between 300 and 500 °C, dichlorosilane at around 900 °C, and TEOS between 650 and 750 °C, resulting in a layer of "low- temperature oxide" (LTO). However, silane produces a lower-quality oxide than the other methods (lower dielectric strength, for instance), and it deposits nonconformally. Any of these reactions may be used in LPCVD, but the silane reaction is also done in APCVD. CVD oxide invariably has lower quality than thermal oxide, but thermal oxidation can only be used in the earliest stages of IC manufacturing.

Oxide may also be grown with impurities (alloying or "doping"). This may have two purposes. During further process steps that occur at high temperature, the impurities may diffuse from the oxide into adjacent layers (most notably silicon) and dope them. Oxides containing 5–15% impurities by mass are often used for this purpose. In addition, silicon dioxide alloyed with phosphorus pentoxide ("P-glass") can be used to smooth out uneven surfaces. P-glass softens and reflows at temperatures above 1000 °C. This process requires a phosphorus concentration of at least 6%, but concentrations above 8% can corrode aluminium. Phosphorus is deposited from phosphine gas and oxygen:

Glasses containing both boron and phosphorus (borophosphosilicate glass, BPSG) undergo viscous flow at lower temperatures; around 850 °C is achievable with glasses containing around 5 weight % of both constituents, but stability in air can be difficult to achieve. Phosphorus oxide in high concentrations interacts with ambient moisture to produce phosphoric acid. Crystals of BPO can also precipitate from the flowing glass on cooling; these crystals are not readily etched in the standard reactive plasmas used to pattern oxides, and will result in circuit defects in integrated circuit manufacturing.

Besides these intentional impurities, CVD oxide may contain byproducts of the deposition. TEOS produces a relatively pure oxide, whereas silane introduces hydrogen impurities, and dichlorosilane introduces chlorine.

Lower temperature deposition of silicon dioxide and doped glasses from TEOS using ozone rather than oxygen has also been explored (350 to 500 °C). Ozone glasses have excellent conformality but tend to be hygroscopic – that is, they absorb water from the air due to the incorporation of silanol (Si-OH) in the glass. Infrared spectroscopy and mechanical strain as a function of temperature are valuable diagnostic tools for diagnosing such problems.

Silicon nitride is often used as an insulator and chemical barrier in manufacturing ICs. The following two reactions deposit silicon nitride from the gas phase:

Silicon nitride deposited by LPCVD contains up to 8% hydrogen. It also experiences strong tensile stress, which may crack films thicker than 200 nm. However, it has higher resistivity and dielectric strength than most insulators commonly available in microfabrication (10 Ω·cm and 10 MV/cm, respectively).

Another two reactions may be used in plasma to deposit SiNH:

These films have much less tensile stress, but worse electrical properties (resistivity 10 to 10 Ω·cm, and dielectric strength 1 to 5 MV/cm).

Tungsten CVD, used for forming conductive contacts, vias, and plugs on a semiconductor device, is achieved from tungsten hexafluoride (WF), which may be deposited in two ways:

Other metals, notably aluminium and copper, can be deposited by CVD. , commercially cost-effective CVD for copper did not exist, although volatile sources exist, such as Cu(hfac). Copper is typically deposited by electroplating. Aluminium can be deposited from triisobutylaluminium (TIBAL) and related organoaluminium compounds.

CVD for molybdenum, tantalum, titanium, nickel is widely used. These metals can form useful silicides when deposited onto silicon. Mo, Ta and Ti are deposited by LPCVD, from their pentachlorides. Nickel, molybdenum, and tungsten can be deposited at low temperatures from their carbonyl precursors. In general, for an arbitrary metal "M", the chloride deposition reaction is as follows:

whereas the carbonyl decomposition reaction can happen spontaneously under thermal treatment or acoustic cavitation and is as follows:

the decomposition of metal carbonyls is often violently precipitated by moisture or air, where oxygen reacts with the metal precursor to form metal or metal oxide along with carbon dioxide.

Niobium(V) oxide layers can be produced by the thermal decomposition of niobium(V) ethoxide with the loss of diethyl ether according to the equation:

Many variations of CVD can be utilized to synthesize graphene. Although many advancements have been made, the processes listed below are not commercially viable yet.

The most popular carbon source that is used to produce graphene is methane gas. One of the less popular choices is petroleum asphalt, notable for being inexpensive but more difficult to work with.

Although methane is the most popular carbon source, hydrogen is required during the preparation process to promote carbon deposition on the substrate. If the flow ratio of methane and hydrogen are not appropriate, it will cause undesirable results. During the growth of graphene, the role of methane is to provide a carbon source, the role of hydrogen is to provide H atoms to corrode amorphous C, and improve the quality of graphene. But excessive H atoms can also corrode graphene. As a result, the integrity of the crystal lattice is destroyed, and the quality of graphene is deteriorated. Therefore, by optimizing the flow rate of methane and hydrogen gases in the growth process, the quality of graphene can be improved.
The use of catalyst is viable in changing the physical process of graphene production. Notable examples include iron nanoparticles, nickel foam, and gallium vapor. These catalysts can either be used in situ during graphene buildup, or situated at some distance away at the deposition area. Some catalysts require another step to remove them from the sample material.

The direct growth of high-quality, large single-crystalline domains of graphene on a dielectric substrate is of vital importance for applications in electronics and optoelectronics. Combining the advantages of both catalytic CVD and the ultra-flat dielectric substrate, gaseous catalyst-assisted CVD paves the way for synthesizing high-quality graphene for device applications while avoiding the transfer process.
Physical conditions such as surrounding pressure, temperature, carrier gas, and chamber material play a big role in production of graphene.

Most systems use LPCVD with pressures ranging from 1 to 1500 Pa. However, some still use APCVD. Low pressures are used more commonly as they help prevent unwanted reactions and produce more uniform thickness of deposition on the substrate.

On the other hand, temperatures used range from 800 to 1050 °C. High temperatures translate to an increase of the rate of reaction. Caution has to be exercised as high temperatures do pose higher danger levels in addition to greater energy costs.
Hydrogen gas and inert gases such as argon are flowed into the system. These gases act as a carrier, enhancing surface reaction and improving reaction rate, thereby increasing deposition of graphene onto the substrate.
Standard quartz tubing and chambers are used in CVD of graphene. Quartz is chosen because it has a very high melting point and is chemically inert. In other words, quartz does not interfere with any physical or chemical reactions regardless of the conditions.
Raman spectroscopy, X-ray spectroscopy, transmission electron microscopy (TEM), and scanning electron microscopy (SEM) are used to examine and characterize the graphene samples.

Raman spectroscopy is used to characterize and identify the graphene particles; X-ray spectroscopy is used to characterize chemical states; TEM is used to provide fine details regarding the internal composition of graphene; SEM is used to examine the surface and topography.

Sometimes, atomic force microscopy (AFM) is used to measure local properties such as friction and magnetism.

Cold wall CVD technique can be used to study the underlying surface science involved in graphene nucleation and growth as it allows unprecedented control of process parameters like gas flow rates, temperature and pressure as demonstrated in a recent study. The study was carried out in a home-built vertical cold wall system utilizing resistive heating by passing direct current through the substrate. It provided conclusive insight into a typical surface-mediated nucleation and growth mechanism involved in two-dimensional materials grown using catalytic CVD under conditions sought out in the semiconductor industry.

In spite of graphene's exciting electronic and thermal properties, it is unsuitable as a transistor for future digital devices, due to the absence of a bandgap between the conduction and valence bands. This makes it impossible to switch between on and off states with respect to electron flow. Scaling things down, graphene nanoribbons of less than 10 nm in width do exhibit electronic bandgaps and are therefore potential candidates for digital devices. Precise control over their dimensions, and hence electronic properties, however, represents a challenging goal, and the ribbons typically possess rough edges that are detrimental to their performance.

CVD can be used to produce a synthetic diamond by creating the circumstances necessary for carbon atoms in a gas to settle on a substrate in crystalline form. CVD of diamonds has received much attention in the materials sciences because it allows many new applications that had previously been considered too expensive. CVD diamond growth typically occurs under low pressure (1–27 kPa; 0.145–3.926 psi; 7.5–203 Torr) and involves feeding varying amounts of gases into a chamber, energizing them and providing conditions for diamond growth on the substrate. The gases always include a carbon source, and typically include hydrogen as well, though the amounts used vary greatly depending on the type of diamond being grown. Energy sources include hot filament, microwave power, and arc discharges, among others. The energy source is intended to generate a plasma in which the gases are broken down and more complex chemistries occur. The actual chemical process for diamond growth is still under study and is complicated by the very wide variety of diamond growth processes used.

Using CVD, films of diamond can be grown over large areas of substrate with control over the properties of the diamond produced. In the past, when high pressure high temperature (HPHT) techniques were used to produce a diamond, the result was typically very small free-standing diamonds of varying sizes. With CVD diamond, growth areas of greater than fifteen centimeters (six inches) in diameter have been achieved, and much larger areas are likely to be successfully coated with diamond in the future. Improving this process is key to enabling several important applications.

The growth of diamond directly on a substrate allows the addition of many of diamond's important qualities to other materials. Since diamond has the highest thermal conductivity of any bulk material, layering diamond onto high heat-producing electronics (such as optics and transistors) allows the diamond to be used as a heat sink. Diamond films are being grown on valve rings, cutting tools, and other objects that benefit from diamond's hardness and exceedingly low wear rate. In each case the diamond growth must be carefully done to achieve the necessary adhesion onto the substrate. Diamond's very high scratch resistance and thermal conductivity, combined with a lower coefficient of thermal expansion than Pyrex glass, a coefficient of friction close to that of Teflon (polytetrafluoroethylene) and strong lipophilicity would make it a nearly ideal non-stick coating for cookware if large substrate areas could be coated economically.

CVD growth allows one to control the properties of the diamond produced. In the area of diamond growth, the word "diamond" is used as a description of any material primarily made up of sp3-bonded carbon, and there are many different types of diamond included in this. By regulating the processing parameters—especially the gases introduced, but also including the pressure the system is operated under, the temperature of the diamond, and the method of generating plasma—many different materials that can be considered diamond can be made. Single-crystal diamond can be made containing various dopants. Polycrystalline diamond consisting of grain sizes from several nanometers to several micrometers can be grown. Some polycrystalline diamond grains are surrounded by thin, non-diamond carbon, while others are not. These different factors affect the diamond's hardness, smoothness, conductivity, optical properties and more.

Commercially, mercury cadmium telluride is of continuing interest for detection of infrared radiation. Consisting of an alloy of CdTe and HgTe, this material can be prepared from the dimethyl derivatives of the respective elements.



CN Tower

The CN Tower () is a concrete communications and observation tower in Toronto, Ontario, Canada. Completed in 1976, it is located in downtown Toronto, built on the former Railway Lands. Its name "CN" referred to Canadian National, the railway company that built the tower. Following the railway's decision to divest non-core freight railway assets prior to the company's privatization in 1995, it transferred the tower to the Canada Lands Company, a federal Crown corporation responsible for the government's real estate portfolio.

The CN Tower held the record for the world's tallest free-standing structure for 32 years, from 1975 until 2007, when it was surpassed by the Burj Khalifa, and was the world's tallest tower until 2009 when it was surpassed by the Canton Tower. It is currently the tenth-tallest free-standing structure in the world and remains the tallest free-standing structure on land in the Western Hemisphere. In 1995, the CN Tower was declared one of the modern Seven Wonders of the World by the American Society of Civil Engineers. It also belongs to the World Federation of Great Towers.

It is a signature icon of Toronto's skyline and attracts more than two million international visitors annually. It houses several observation decks, a revolving restaurant at some , and an entertainment complex.

The original concept of the CN Tower was first conceived in 1968 when the Canadian National Railway wanted to build a large television and radio communication platform to serve the Toronto area, and to demonstrate the strength of Canadian industry and CN in particular. These plans evolved over the next few years, and the project became official in 1972.

The tower would have been part of Metro Centre (see CityPlace), a large development south of Front Street on the Railway Lands, a large railway switching yard that was being made redundant after the opening of the MacMillan Yard north of the city in 1965 (then known as Toronto Yard). Key project team members were NCK Engineering as structural engineer; John Andrews Architects; Webb, Zerafa, Menkes, Housden Architects; Foundation Building Construction; and Canron (Eastern Structural Division).

As Toronto grew rapidly during the late 1960s and early 1970s, multiple skyscrapers were constructed in the downtown core, most notably First Canadian Place, which has Bank of Montreal's head offices. The reflective nature of the new buildings reduced the quality of broadcast signals, requiring new, higher antennas that were at least tall. The radio wire is estimated to be long in 44 pieces, the heaviest of which weighs around .

At the time, most data communications took place over point-to-point microwave links, whose dish antennas covered the roofs of large buildings. As each new skyscraper was added to the downtown, former line-of-sight links were no longer possible. CN intended to rent "hub" space for microwave links, visible from almost any building in the Toronto area.

The original plan for the tower envisioned a tripod consisting of three independent cylindrical "pillars" linked at various heights by structural bridges. Had it been built, this design would have been considerably shorter, with the metal antenna located roughly where the concrete section between the main level and the SkyPod lies today. As the design effort continued, it evolved into the current design with a single continuous hexagonal core to the SkyPod, with three support legs blended into the hexagon below the main level, forming a large Y-shape structure at the ground level.

The idea for the main level in its current form evolved around this time, but the Space Deck (later renamed SkyPod) was not part of the plans until later. One engineer in particular felt that visitors would feel the higher observation deck would be worth paying extra for, and the costs in terms of construction were not prohibitive. Also around this time, it was realized that the tower could become the world's tallest free-standing structure to improve signal quality and attract tourists, and plans were changed to incorporate subtle modifications throughout the structure to this end.

The CN Tower was built by Canada Cement Company (also known as the Cement Foundation Company of Canada at the time), a subsidiary of Sweden's Skanska, a global project-development and construction group.

Construction began on February 6, 1973, with massive excavations at the tower base for the foundation. By the time the foundation was complete, of earth and shale were removed to a depth of in the centre, and a base incorporating of concrete with of rebar and of steel cable had been built to a thickness of . This portion of the construction was fairly rapid, with only four months needed between the start and the foundation being ready for construction on top.

To create the main support pillar, workers constructed a hydraulically raised slipform at the base. This was a fairly unprecedented engineering feat on its own, consisting of a large metal platform that raised itself on jacks at about per day as the concrete below set. Concrete was poured Monday to Friday (not continuously) by a small team of people until February 22, 1974, at which time it had already become the tallest structure in Canada, surpassing the recently built Inco Superstack in Sudbury, built using similar methods.

The tower contains of concrete, all of which was mixed on-site in order to ensure batch consistency. Through the pour, the vertical accuracy of the tower was maintained by comparing the slip form's location to massive plumb bobs hanging from it, observed by small telescopes from the ground. Over the height of the tower, it varies from true vertical accuracy by only .

In August 1974, construction of the main level commenced. Using 45 hydraulic jacks attached to cables strung from a temporary steel crown anchored to the top of the tower, twelve giant steel and wooden bracket forms were slowly raised, ultimately taking about a week to crawl up to their final position. These forms were used to create the brackets that support the main level, as well as a base for the construction of the main level itself. The Space Deck (currently named SkyPod) was built of concrete poured into a wooden frame attached to rebar at the lower level deck, and then reinforced with a large steel compression band around the outside.

While still under construction, the CN Tower officially became the world's tallest free-standing structure on March 31, 1975.

The antenna was originally to be raised by crane as well, but, during construction, the Sikorsky S-64 Skycrane helicopter became available when the United States Army sold one to civilian operators. The helicopter, named "Olga", was first used to remove the crane, and then flew the antenna up in 36 sections.

The flights of the antenna pieces were a minor tourist attraction of their own, and the schedule was printed in local newspapers. Use of the helicopter saved months of construction time, with this phase taking only three and a half weeks instead of the planned six months. The tower was topped-off on April 2, 1975, after 26 months of construction, officially capturing the height record from Moscow's Ostankino Tower, and bringing the total mass to .

Two years into the construction, plans for Metro Centre were scrapped, leaving the tower isolated on the Railway Lands in what was then a largely abandoned light-industrial space. This caused serious problems for tourists to access the tower. Ned Baldwin, project architect with John Andrews, wrote at the time that "All of the logic which dictated the design of the lower accommodation has been upset," and that "Under such ludicrous circumstances Canadian National would hardly have chosen this location to build."

The CN Tower opened on June 26, 1976. The construction costs of approximately ($ in dollars) were repaid in fifteen years.

From the mid-1970s to the mid-1980s, the CN Tower was practically the only development along Front Street West; it was still possible to see Lake Ontario from the foot of the CN Tower due to the expansive parking lots and lack of development in the area at the time. As the area around the tower was developed, particularly with the completion of the Metro Toronto Convention Centre (north building) in 1984 and SkyDome in 1989 (renamed Rogers Centre in 2005), the former Railway Lands were redeveloped and the tower became the centre of a newly developing entertainment area. Access was greatly improved with the construction of the SkyWalk in 1989, which connected the tower and SkyDome to the nearby Union Station railway and subway station, and, in turn, to the city's Path underground pedestrian system. By the mid-1990s, it was the centre of a thriving tourist district. The entire area continues to be an area of intense building, notably a boom in condominium construction in the first quarter of the 21st century, as well as the 2013 opening of the Ripley's Aquarium by the base of the tower.

When the CN Tower opened in 1976, there were three public observation points: the SkyPod (then known as the Space Deck) that stands at , the Indoor Observation Level (later named Indoor Lookout Level) at , and the Outdoor Observation Terrace (at the same level as the Glass Floor) at . One floor above the Indoor Observation Level was the Top of Toronto Restaurant, which completed a revolution once every 72 minutes.

The tower would garner worldwide media attention when stuntman Dar Robinson jumped off the CN Tower on two occasions in 1979 and 1980. The first was for a scene from the movie "Highpoint", in which Robinson received ($ in dollars) for the stunt. The second was for a personal documentary. The first stunt had him use a parachute which he deployed three seconds before impact with the ground, while the second one used a wire decelerator attached to his back.

On June 26, 1986, the tenth anniversary of the tower's opening, high-rise firefighting and rescue advocate Dan Goodwin, in a sponsored publicity event, used his hands and feet to climb the outside of the tower, a feat he performed twice on the same day. Following both ascents, he used multiple rappels to descend to the ground.

From 1985 to 1992, the CN Tower basement level hosted the world's first flight simulator ride, Tour of the Universe. The ride was replaced in 1992 with a similar attraction entitled "Space Race." It was later dismantled and replaced by two other rides in 1998 and 1999.

A glass floor at an elevation of was installed in 1994. Canadian National Railway sold the tower to Canada Lands Company prior to privatizing the company in 1995, when it divested all operations not directly related to its core freight shipping businesses. The tower's name and wordmark were adjusted to remove the CN railways logo, and the tower was renamed Canada's National Tower (from Canadian National Tower), though the tower is commonly called the CN Tower.

Further changes were made from 1997 to January 2004: TrizecHahn Corporation managed the tower and instituted several expansion projects including a entertainment expansion, the 1997 addition of two new elevators (to a total of six) and the consequential relocation of the staircase from the north side leg to inside the core of the building, a conversion that also added nine stairs to the climb. TrizecHahn also owned the Willis Tower (Sears Tower at the time) in Chicago approximately at the same time.

In 2007, light-emitting diode (LED) lights replaced the incandescent lights that lit the CN Tower at night. This was done to take advantage of the cost savings of LED lights over incandescent lights. The colour of the LED lights can change, compared to the constant white colour of the incandescent lights. On September 12, 2007, Burj Khalifa, then under construction and known as Burj Dubai, surpassed the CN Tower as the world's tallest free-standing structure on land. In 2008, glass panels were installed in one of the CN Tower elevators, which established a world record (346 m) for highest glass floor panelled elevator in the world.

On August 1, 2011, the CN Tower opened the EdgeWalk, an amusement in which thrill-seekers can walk on and around the roof of the main pod of the tower at , which is directly above the 360 Restaurant. It is the world's highest full-circle, hands-free walk. Visitors are tethered to an overhead rail system and walk around the edge of the CN Tower's main pod above the 360 Restaurant on a metal floor. The attraction is closed throughout the winter and during periods of electrical storms and high winds.

One of the notable guests who visited EdgeWalk was Canadian comedian Rick Mercer, featured as the first episode of the ninth season of his CBC Television news satire show, "Rick Mercer Report". There, he was accompanied by Canadian pop singer Jann Arden. The episode first aired on April 10, 2013.

The tower and surrounding areas were prominent in the 2015 Pan American Games production. In the opening ceremony, a pre-recorded segment featured track-and-field athlete Bruny Surin passing the flame to sprinter Donovan Bailey on the EdgeWalk and parachuting into Rogers Centre. A fireworks display off the tower concluded both the opening and closing ceremonies.

On July 1, 2017, as part of the nationwide celebrations for Canada 150, which celebrated the 150th anniversary of Canadian Confederation, fireworks were once again shot from the tower in a five-minute display coordinated with the tower lights and music broadcast on a local radio station.


The CN Tower consists of several substructures. The main portion of the tower is a hollow concrete hexagonal pillar containing the stairwells and power and plumbing connections. The tower's six elevators are located in the three inverted angles created by the Tower's hexagonal shape (two elevators per angle). Each of the three elevator shafts is lined with glass, allowing for views of the city as the glass-windowed elevators make their way through the tower. The stairwell was originally located in one of these angles (the one facing north), but was moved into the central hollow of the tower; the tower's new fifth and sixth elevators were placed in the hexagonal angle that once contained the stairwell. On top of the main concrete portion of the tower is a tall metal broadcast antenna, carrying television and radio signals. There are three visitor areas: the Glass Floor and Outdoor Observation Terrace, which are both located at an elevation of , the Indoor Lookout Level (formerly known as "Indoor Observation Level") located at , and the higher SkyPod (formerly known as "Space Deck") at , just below the metal antenna. The hexagonal shape is visible between the two highest areas; however, below the main deck, three large supporting legs give the tower the appearance of a large tripod.

The main deck level has seven storeys, some of which are open to the public. Below the public areas—at —is a large white donut-shaped radome containing the structure's UHF transmitters. The glass floor and outdoor observation deck are at . The glass floor has an area of and can withstand a pressure of . The floor's thermal glass units are thick, consisting of a pane of laminated glass, airspace and a pane of laminated glass. In 2008, one elevator was upgraded to add a glass floor panel, believed to have the highest vertical rise of any elevator equipped with this feature. The Horizons Cafe and the lookout level are at . The 360 Restaurant, a revolving restaurant that completes a full rotation once every 72 minutes, is at . When the tower first opened, it also featured a disco named Sparkles (at the Indoor Observation Level), billed as the highest disco and dance floor in the world.

The SkyPod was once the highest public observation deck in the world until it was surpassed by the Shanghai World Financial Center in 2008.

A metal staircase reaches the main deck level after 1,776 steps, and the SkyPod above after 2,579 steps; it is the tallest metal staircase on Earth. These stairs are intended for emergency use only except for charity stair-climb events two times during the year. The average climber takes approximately 30 minutes to climb to the base of the radome, but the fastest climb on record is 7 minutes and 52 seconds in 1989 by Brendan Keenoy, an Ontario Provincial Police officer. In 2002, Canadian Olympian and Paralympic champion Jeff Adams climbed the stairs of the tower in a specially designed wheelchair. The stairs were originally on one of the three sides of the tower (facing north), with a glass view, but these were later replaced with the third elevator pair and the stairs were moved to the inside of the core. Top climbs on the new, windowless stairwell used since around 2003 have generally been over ten minutes.


A freezing rain storm on March 2, 2007, resulted in a layer of ice several centimetres thick forming on the side of the tower and other downtown buildings. The sun thawed the ice, then winds of up to blew some of it away from the structure. There were fears that cars and windows of nearby buildings would be smashed by large chunks of ice. In response, police closed some streets surrounding the tower. During morning rush hour on March 5 of the same year, police expanded the area of closed streets to include the Gardiner Expressway away from the tower as increased winds blew the ice farther, as far north as King Street West, away, where a taxicab window was shattered. Subsequently, on March 6, 2007, the Gardiner Expressway reopened after winds abated.

On April 16, 2018, falling ice from the CN Tower punctured the roof of the nearby Rogers Centre stadium, causing the Toronto Blue Jays to postpone the game that day to the following day as a doubleheader; this was the third doubleheader held at the Rogers Centre. On April 20 of the same year, the CN Tower reopened.

In August 2000, a fire broke out at the Ostankino Tower in Moscow, killing three people and causing extensive damage. The fire was blamed on poor maintenance and outdated equipment. The failure of the fire-suppression systems and the lack of proper equipment for firefighters allowed the fire to destroy most of the interior and sparked fears the tower might even collapse.

The Ostankino Tower was completed nine years before the CN Tower and is only shorter. The parallels between the towers led to some concern that the CN Tower could be at risk of a similar tragedy. However, Canadian officials subsequently stated that it is "highly unlikely" that a similar disaster could occur at the CN Tower, as it has important safeguards that were not present in the Ostankino Tower. Specifically, officials cited:


Officials also noted that the CN Tower has an excellent safety record, although there was an electrical fire in the antennas on August 16, 2017 — the tower's first fire. Moreover, other supertall structures built between 1967 and 1976 — such as the Willis Tower (formerly the Sears Tower), the World Trade Center (until its destruction on September 11, 2001), the Fernsehturm Berlin, the Aon Center, 875 North Michigan Avenue (formerly the John Hancock Center), and First Canadian Place — also have excellent safety records, which suggests that the Ostankino Tower accident was a rare safety failure, and that the likelihood of similar events occurring at other supertall structures is extremely low.

The CN Tower was originally lit at night with incandescent lights, which were removed in 1997 because they were inefficient and expensive to repair. In June 2007, the tower was outfitted with 1,330 super-bright LED lights inside the elevator shafts, shooting over the main pod and upward to the top of the tower's mast to light the tower from dusk until 2 a.m. The official opening ceremony took place on June 28, 2007, before the Canada Day holiday weekend.

The tower changes its lighting scheme on holidays and to commemorate major events. After the 95th Grey Cup in Toronto, the tower was lit in green and white to represent the colours of the Grey Cup champion Saskatchewan Roughriders. From sundown on August 27, 2011, to sunrise the following day, the tower was lit in orange, the official colour of the New Democratic Party (NDP), to commemorate the death of federal NDP leader and leader of the official opposition Jack Layton. When former South African president Nelson Mandela died, the tower was lit in the colours of the South African flag. When former federal finance minister under Stephen Harper's Conservatives Jim Flaherty died, the tower was lit in green to reflect his Irish Canadian heritage. On the night of the attacks on Paris on November 13, 2015, the tower displayed the colours of the French flag. On June 8, 2021, the tower displayed the colours of the Toronto Maple Leafs' archrivals Montreal Canadiens after they advanced to the semifinals of 2021 Stanley Cup playoffs. The CN Tower was lit in the colours of the Ukrainian flag during the beginning of the Russian invasion of Ukraine in late February 2022.

Programmed remotely from a desktop computer with a wireless network interface controller in Burlington, Ontario, the LEDs use less energy to light than the previous incandescent lights (10% less energy than the dimly lit version and 60% less than the brightly lit version). The estimated cost to use the LEDs is $1,000 per month.

During the spring and autumn bird migration seasons, the lights are turned off to comply with the voluntary Fatal Light Awareness Program, which "encourages buildings to dim unnecessary exterior lighting to mitigate bird mortality during spring and summer migration."

The CN Tower is the tallest freestanding structure in the Western Hemisphere. As of 2013, there were two other freestanding structures in the Western Hemisphere exceeding in height: the Willis Tower in Chicago, which stands at when measured to its pinnacle, and One World Trade Center in New York City, which has a pinnacle height of , or approximately shorter than the CN Tower. Due to the symbolism of the number 1776 (the year of the signing of the United States Declaration of Independence), the height of One World Trade Center is unlikely to be increased. The proposed Chicago Spire was expected to exceed the height of the CN Tower, but its construction was halted early due to financial difficulties amid the Great Recession, and was eventually cancelled in 2010.

"Guinness World Records" has called the CN Tower "the world's tallest self-supporting tower" and "the world's tallest free-standing tower". Although Guinness did list this description of the CN Tower under the heading "tallest building" at least once, it has also listed it under "tallest tower", omitting it from its list of "tallest buildings." In 1996, Guinness changed the tower's classification to "World's Tallest Building and Freestanding Structure". Emporis and the Council on Tall Buildings and Urban Habitat both listed the CN Tower as the world's tallest free-standing structure on land, and specifically state that the CN Tower is not a true building, thereby awarding the title of world's tallest building to Taipei 101, which is shorter than the CN Tower. The issue of what was tallest became moot when Burj Khalifa, then under construction, exceeded the height of the CN Tower in 2007 (see below).

Although the CN Tower contains a restaurant, a gift shop and multiple observation levels, it does not have floors continuously from the ground, and therefore it is not considered a building by the Council on Tall Buildings and Urban Habitat (CTBUH) or Emporis. CTBUH defines a building as "a structure that is designed for residential, business, or manufacturing purposes. An essential characteristic of a building is that it has floors." The CN Tower and other similar structures—such as the Ostankino Tower in Moscow, Russia; the Oriental Pearl Tower in Shanghai, China; The Strat in Las Vegas, Nevada, United States; and the Eiffel Tower in Paris, France—are categorized as "towers", which are free-standing structures that may have observation decks and a few other habitable levels, but do not have floors from the ground up. The CN Tower was the tallest tower by this definition until 2010 (see below).

Taller than the CN Tower are numerous radio masts and towers, which are held in place by guy-wires, the tallest being the KVLY-TV mast in Blanchard, North Dakota, in the United States at tall, leading to a distinction between these and "free-standing" structures. Additionally, the Petronius Platform stands above its base on the bottom of the Gulf of Mexico near the Mississippi River Delta, but only the top of this oil and natural gas platform are above water, and the structure is thus partially supported by its buoyancy. Like the CN Tower, none of these taller structures are commonly considered buildings.

On September 12, 2007, Burj Khalifa, which is a hotel, residential and commercial building in Dubai, United Arab Emirates (formerly known as Burj Dubai before opening), passed the CN Tower's 553.33-m height. The CN Tower held the record of the tallest freestanding structure on land for over 30 years.

After Burj Khalifa had been formally recognized by the Guinness World Records as the world's tallest freestanding structure, Guinness re-certified CN Tower as the world's tallest freestanding tower. The tower definition used by Guinness was defined by the Council on Tall Buildings and Urban Habitat as 'a building in which less than 50% of the construction is usable floor space'. "Guinness World Records" editor-in-chief Craig Glenday announced that Burj Khalifa was not classified as a tower because it has too much usable floor space to be considered to be a tower. CN Tower still held world records for highest above ground wine cellar (in 360 Restaurant) at 351 m, highest above ground restaurant at 346 m (Horizons Restaurant), and tallest free-standing concrete tower during Guinness's recertification. The CN Tower was surpassed in 2009 by the Canton Tower in Guangzhou, China, which stands at tall, as the world's tallest tower; which in turn was surpassed by the Tokyo Skytree in 2011, which currently is the tallest tower at in height. The CN Tower, as of 2022, stands as the tenth-tallest free-standing structure on land, remains the tallest free-standing structure in the Western Hemisphere, and is the third-tallest tower.

Since its construction, the tower has gained the following world height records:

The CN Tower has been and continues to be used as a communications tower for a number of different media and by numerous companies.

Source: Vividcomm

There is no AM broadcasting from the CN Tower. The FM transmitters are situated in a metal broadcast antenna, on top of the main concrete portion of the tower at an elevation above .
Source: Vividcomm


The CN Tower has been featured in numerous films, television shows, music recording covers, and video games. The tower also has its own official mascot, which resembles the tower itself.



Chain rule

In calculus, the chain rule is a formula that expresses the derivative of the composition of two differentiable functions and in terms of the derivatives of and . More precisely, if formula_1 is the function such that formula_2 for every , then the chain rule is, in Lagrange's notation,
or, equivalently,

The chain rule may also be expressed in Leibniz's notation. If a variable depends on the variable , which itself depends on the variable (that is, and are dependent variables), then depends on as well, via the intermediate variable . In this case, the chain rule is expressed as
and
for indicating at which points the derivatives have to be evaluated.

In integration, the counterpart to the chain rule is the substitution rule.

Intuitively, the chain rule states that knowing the instantaneous rate of change of relative to and that of relative to allows one to calculate the instantaneous rate of change of relative to as the product of the two rates of change. 

As put by George F. Simmons: "If a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2 × 4 = 8 times as fast as the man." 

The relationship between this example and the chain rule is as follows. Let , and be the (variable) positions of the car, the bicycle, and the walking man, respectively. The rate of change of relative positions of the car and the bicycle is formula_7 Similarly, formula_8 So, the rate of change of the relative positions of the car and the walking man is

The rate of change of positions is the ratio of the speeds, and the speed is the derivative of the position with respect to the time; that is,
or, equivalently,
which is also an application of the chain rule.

The chain rule seems to have first been used by Gottfried Wilhelm Leibniz. He used it to calculate the derivative of formula_12 as the composite of the square root function and the function formula_13. He first mentioned it in a 1676 memoir (with a sign error in the calculation). The common notation of the chain rule is due to Leibniz. Guillaume de l'Hôpital used the chain rule implicitly in his "Analyse des infiniment petits". The chain rule does not appear in any of Leonhard Euler's analysis books, even though they were written over a hundred years after Leibniz's discovery.. It is believed that the first "modern" version of the chain rule appears in Lagrange’s 1797 "Théorie des fonctions analytiques"; it also appears in Cauchy’s 1823 "Résumé des Leçons données a L’École Royale Polytechnique sur Le Calcul Infinitesimal".

The simplest form of the chain rule is for real-valued functions of one real variable. It states that if ' is a function that is differentiable at a point ' (i.e. the derivative exists) and ' is a function that is differentiable at , then the composite function formula_14 is differentiable at ', and the derivative is

The rule is sometimes abbreviated as

If and , then this abbreviated form is written in Leibniz notation as:

The points where the derivatives are evaluated may also be stated explicitly:

Carrying the same reasoning further, given " functions formula_19 with the composite function formula_20, if each function formula_21 is differentiable at its immediate input, then the composite function is also differentiable by the repeated application of Chain Rule, where the derivative is (in Leibniz's notation):

The chain rule can be applied to composites of more than two functions. To take the derivative of a composite of more than two functions, notice that the composite of , , and ' (in that order) is the composite of with . The chain rule states that to compute the derivative of , it is sufficient to compute the derivative of ' and the derivative of . The derivative of " can be calculated directly, and the derivative of can be calculated by applying the chain rule again.

For concreteness, consider the function
This can be decomposed as the composite of three functions:
So that formula_25.

Their derivatives are:

The chain rule states that the derivative of their composite at the point is:

In Leibniz's notation, this is:
or for short,
The derivative function is therefore:

Another way of computing this derivative is to view the composite function as the composite of and "h". Applying the chain rule in this manner would yield:

This is the same as what was computed above. This should be expected because .

Sometimes, it is necessary to differentiate an arbitrarily long composition of the form formula_32. In this case, define
where formula_34 and formula_35 when formula_36. Then the chain rule takes the form
or, in the Lagrange notation,

The chain rule can be used to derive some well-known differentiation rules. For example, the quotient rule is a consequence of the chain rule and the product rule. To see this, write the function as the product . First apply the product rule:

To compute the derivative of , notice that it is the composite of with the reciprocal function, that is, the function that sends to . The derivative of the reciprocal function is formula_40. By applying the chain rule, the last expression becomes:

which is the usual formula for the quotient rule.

Suppose that has an inverse function. Call its inverse function so that we have . There is a formula for the derivative of in terms of the derivative of . To see this, note that and satisfy the formula

And because the functions formula_43 and are equal, their derivatives must be equal. The derivative of is the constant function with value 1, and the derivative of formula_43 is determined by the chain rule. Therefore, we have that:

To express as a function of an independent variable , we substitute formula_46 for wherever it appears. Then we can solve for .

For example, consider the function . It has an inverse . Because , the above formula says that

This formula is true whenever is differentiable and its inverse is also differentiable. This formula can fail when one of these conditions is not true. For example, consider . Its inverse is , which is not differentiable at zero. If we attempt to use the above formula to compute the derivative of at zero, then we must evaluate . Since and , we must evaluate 1/0, which is undefined. Therefore, the formula fails in this case. This is not surprising because is not differentiable at zero.

Faà di Bruno's formula generalizes the chain rule to higher derivatives. Assuming that and , then the first few derivatives are:

One proof of the chain rule begins by defining the derivative of the composite function , where we take the limit of the difference quotient for as approaches :

Assume for the moment that formula_51 does not equal formula_52 for any formula_53 near formula_54. Then the previous expression is equal to the product of two factors:

If formula_56 oscillates near , then it might happen that no matter how close one gets to , there is always an even closer such that . For example, this happens near for the continuous function defined by for and otherwise. Whenever this happens, the above expression is undefined because it involves division by zero. To work around this, introduce a function formula_57 as follows:

We will show that the difference quotient for is always equal to:

Whenever is not equal to , this is clear because the factors of cancel. When equals , then the difference quotient for is zero because equals , and the above product is zero because it equals times zero. So the above product is always equal to the difference quotient, and to show that the derivative of at exists and to determine its value, we need only show that the limit as goes to of the above product exists and determine its value.

To do this, recall that the limit of a product exists if the limits of its factors exist. When this happens, the limit of the product of these two factors will equal the product of the limits of the factors. The two factors are and . The latter is the difference quotient for at , and because is differentiable at by assumption, its limit as tends to exists and equals .

As for , notice that is defined wherever ' is. Furthermore, ' is differentiable at by assumption, so is continuous at , by definition of the derivative. The function is continuous at because it is differentiable at , and therefore is continuous at . So its limit as ' goes to ' exists and equals , which is .

This shows that the limits of both factors exist and that they equal and , respectively. Therefore, the derivative of at "a" exists and equals .

Another way of proving the chain rule is to measure the error in the linear approximation determined by the derivative. This proof has the advantage that it generalizes to several variables. It relies on the following equivalent definition of differentiability at a point: A function "g" is differentiable at "a" if there exists a real number "g"′("a") and a function "ε"("h") that tends to zero as "h" tends to zero, and furthermore
Here the left-hand side represents the true difference between the value of "g" at "a" and at , whereas the right-hand side represents the approximation determined by the derivative plus an error term.

In the situation of the chain rule, such a function "ε" exists because "g" is assumed to be differentiable at "a". Again by assumption, a similar function also exists for "f" at "g"("a"). Calling this function "η", we have
The above definition imposes no constraints on "η"(0), even though it is assumed that "η"("k") tends to zero as "k" tends to zero. If we set , then "η" is continuous at 0.

Proving the theorem requires studying the difference as "h" tends to zero. The first step is to substitute for using the definition of differentiability of "g" at "a":
The next step is to use the definition of differentiability of "f" at "g"("a"). This requires a term of the form for some "k". In the above equation, the correct "k" varies with "h". Set and the right hand side becomes . Applying the definition of the derivative gives:
To study the behavior of this expression as "h" tends to zero, expand "k". After regrouping the terms, the right-hand side becomes:
Because "ε"("h") and "η"("k") tend to zero as "h" tends to zero, the first two bracketed terms tend to zero as "h" tends to zero. Applying the same theorem on products of limits as in the first proof, the third bracketed term also tends zero. Because the above expression is equal to the difference , by the definition of the derivative is differentiable at "a" and its derivative is 

The role of "Q" in the first proof is played by "η" in this proof. They are related by the equation:
The need to define "Q" at "g"("a") is analogous to the need to define "η" at zero.

Constantin Carathéodory's alternative definition of the differentiability of a function can be used to give an elegant proof of the chain rule.

Under this definition, a function is differentiable at a point if and only if there is a function , continuous at and such that . There is at most one such function, and if is differentiable at then .

Given the assumptions of the chain rule and the fact that differentiable functions and compositions of continuous functions are continuous, we have that there exist functions , continuous at , and , continuous at , and such that,
and
Therefore,
but the function given by is continuous at , and we get, for this 
A similar approach works for continuously differentiable (vector-)functions of many variables. This method of factoring also allows a unified approach to stronger forms of differentiability, when the derivative is required to be Lipschitz continuous, Hölder continuous, etc. Differentiation itself can be viewed as the polynomial remainder theorem (the little Bézout theorem, or factor theorem), generalized to an appropriate class of functions. 

If formula_70 and formula_71 then choosing infinitesimal formula_72 we compute the corresponding formula_73 and then the corresponding formula_74, so that
and applying the standard part we obtain
which is the chain rule.

The full generalization of the chain rule to multi-variable functions (such as formula_77) is rather technical. However, it is simpler to write in the case of functions of the form 
formula_78
where formula_79, and formula_80 for each formula_81

As this case occurs often in the study of functions of a single variable, it is worth describing it separately.

Let formula_79, and formula_80 for each formula_81
To write the chain rule for the composition of functions 
formula_85 
one needs the partial derivatives of with respect to its arguments. The usual notations for partial derivatives involve names for the arguments of the function. As these arguments are not named in the above formula, it is simpler and clearer to use "D"-Notation, and to denote by 
the partial derivative of with respect to its th argument, and by 
the value of this derivative at .

With this notation, the chain rule is

If the function is addition, that is, if 
then formula_90 and formula_91. Thus, the chain rule gives 

For multiplication
the partials are formula_94 and formula_95. Thus, 

The case of exponentiation
is slightly more complicated, as 
and, as formula_99
It follows that 

The simplest way for writing the chain rule in the general case is to use the total derivative, which is a linear transformation that captures all directional derivatives in a single formula. Consider differentiable functions and , and a point in . Let denote the total derivative of at and denote the total derivative of at . These two derivatives are linear transformations and , respectively, so they can be composed. The chain rule for total derivatives is that their composite is the total derivative of at :
or for short,
The higher-dimensional chain rule can be proved using a technique similar to the second proof given above.

Because the total derivative is a linear transformation, the functions appearing in the formula can be rewritten as matrices. The matrix corresponding to a total derivative is called a Jacobian matrix, and the composite of two derivatives corresponds to the product of their Jacobian matrices. From this perspective the chain rule therefore says:
or for short,

That is, the Jacobian of a composite function is the product of the Jacobians of the composed functions (evaluated at the appropriate points).

The higher-dimensional chain rule is a generalization of the one-dimensional chain rule. If "k", "m", and "n" are 1, so that and , then the Jacobian matrices of "f" and "g" are . Specifically, they are:
The Jacobian of "f" ∘ "g" is the product of these matrices, so it is , as expected from the one-dimensional chain rule. In the language of linear transformations, "D"("g") is the function which scales a vector by a factor of "g"′("a") and "D"("f") is the function which scales a vector by a factor of "f"′("g"("a")). The chain rule says that the composite of these two linear transformations is the linear transformation , and therefore it is the function that scales a vector by "f"′("g"("a"))⋅"g"′("a").

Another way of writing the chain rule is used when "f" and "g" are expressed in terms of their components as and . In this case, the above rule for Jacobian matrices is usually written as:

The chain rule for total derivatives implies a chain rule for partial derivatives. Recall that when the total derivative exists, the partial derivative in the "i"th coordinate direction is found by multiplying the Jacobian matrix by the "i"th basis vector. By doing this to the formula above, we find:
Since the entries of the Jacobian matrix are partial derivatives, we may simplify the above formula to get:
More conceptually, this rule expresses the fact that a change in the "x" direction may change all of "g" through "g", and any of these changes may affect "f".

In the special case where , so that "f" is a real-valued function, then this formula simplifies even further:
This can be rewritten as a dot product. Recalling that , the partial derivative is also a vector, and the chain rule says that:

Given where and , determine the value of and using the chain rule.
and

Faà di Bruno's formula for higher-order derivatives of single-variable functions generalizes to the multivariable case. If is a function of as above, then the second derivative of is:

All extensions of calculus have a chain rule. In most of these, the formula remains the same, though the meaning of that formula may be vastly different.

One generalization is to manifolds. In this situation, the chain rule represents the fact that the derivative of is the composite of the derivative of "f" and the derivative of "g". This theorem is an immediate consequence of the higher dimensional chain rule given above, and it has exactly the same formula.

The chain rule is also valid for Fréchet derivatives in Banach spaces. The same formula holds as before. This case and the previous one admit a simultaneous generalization to Banach manifolds.

In differential algebra, the derivative is interpreted as a morphism of modules of Kähler differentials. A ring homomorphism of commutative rings determines a morphism of Kähler differentials which sends an element "dr" to "d"("f"("r")), the exterior differential of "f"("r"). The formula holds in this context as well.

The common feature of these examples is that they are expressions of the idea that the derivative is part of a functor. A functor is an operation on spaces and functions between them. It associates to each space a new space and to each function between two spaces a new function between the corresponding new spaces. In each of the above cases, the functor sends each space to its tangent bundle and it sends each function to its derivative. For example, in the manifold case, the derivative sends a "C"-manifold to a "C"-manifold (its tangent bundle) and a "C"-function to its total derivative. There is one requirement for this to be a functor, namely that the derivative of a composite must be the composite of the derivatives. This is exactly the formula .

There are also chain rules in stochastic calculus. One of these, Itō's lemma, expresses the composite of an Itō process (or more generally a semimartingale) "dX" with a twice-differentiable function "f". In Itō's lemma, the derivative of the composite function depends not only on "dX" and the derivative of "f" but also on the second derivative of "f". The dependence on the second derivative is a consequence of the non-zero quadratic variation of the stochastic process, which broadly speaking means that the process can move up and down in a very rough way. This variant of the chain rule is not an example of a functor because the two functions being composed are of different types.



P versus NP problem

The P versus NP problem is a major unsolved problem in theoretical computer science. In informal terms, it asks whether every problem whose solution can be quickly verified can also be quickly solved.

Here "quickly", means an algorithm exists that solves the task and runs in polynomial time, meaning the task completion time varies as a polynomial function on the size of the input to the algorithm (as opposed to, say, exponential time). The general class of questions that some algorithm can answer in polynomial time is "P" or "class P". For some questions, there is no known way to find an answer quickly, but if provided with an answer, it can be verified quickly. The class of questions where an answer can be "verified" in polynomial time is NP, standing for "nondeterministic polynomial time".

An answer to the P versus NP question would determine whether problems that can be verified in polynomial time can also be solved in polynomial time. If P ≠ NP, which is widely believed, it would mean that there are problems in NP that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time.

The problem has been called the most important open problem in computer science. Aside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, economics and many other fields.

It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute, each of which carries a US$1,000,000 prize for the first correct solution.

In the game Sudoku, the player begins with a partially filled-in grid of numbers and attempts to complete the grid following certain rules. Given an incomplete Sudoku grid, of any size, is there at least one legal solution? Proposed solutions are easily verified, and the time to check a solution grows slowly (polynomially) as the grid gets bigger. However, all known algorithms for finding solutions take, for difficult examples, time that grows exponentially as the grid gets bigger. So, Sudoku is in NP (quickly checkable) but does not seem to be in P (quickly solvable). Thousands of other problems seem similarly fast to check but slow to solve. Researchers have shown that many of the problems in NP have the extra property that a fast solution to any one of them could be used to build a quick solution to any other problem in NP, a property called NP-completeness. Decades of searching have not produced a fast solution to any of these problems, so most scientists suspect that these problems cannot be solved quickly, however this is unproven.

The precise statement of the P versus NP problem was introduced in 1971 by Stephen Cook in his seminal paper "The complexity of theorem proving procedures" (and independently by Leonid Levin in 1973).

Although the P versus NP problem was formally defined in 1971, there were previous inklings of the problems involved, the difficulty of proof, and the potential consequences. In 1955, mathematician John Nash wrote a letter to the NSA, speculating that cracking a sufficiently complex code would require time exponential in the length of the key. If proved (and Nash was suitably skeptical), this would imply what is now called P ≠ NP, since a proposed key can be verified in polynomial time. Another mention of the underlying problem occurred in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether theorem-proving (now known to be co-NP-complete) could be solved in quadratic or linear time, and pointed out one of the most important consequences—that if so, then the discovery of mathematical proofs could be automated.

The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem).

In such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is "deterministic" (given the computer's present state and any inputs, there is only one possible action that the computer might take) and "sequential" (it performs actions one after the other).

In this theory, the class P consists of all "decision problems" (defined below) solvable on a deterministic sequential machine in a durationpolynomial in the size of the input; the class NP consists of all decision problems whose positive solutions are verifiable in polynomial time given the right information, or equivalently, whose solution can be found in polynomial time on a non-deterministic machine. Clearly, P ⊆ NP. Arguably, the biggest open question in theoretical computer science concerns the relationship between those two classes:

Since 2002, William Gasarch has conducted three polls of researchers concerning this and related questions. Confidence that P ≠ NP has been increasing – in 2019, 88% believed P ≠ NP, as opposed to 83% in 2012 and 61% in 2002. When restricted to experts, the 2019 answers became 99% believed P ≠ NP. These polls do not imply anything about the truth of P = NP, as stated by Gasarch himself: "This does not bring us any closer to solving P=?NP or to knowing when it will be solved, but it attempts to be an objective report on the subjective opinion of this era."

To attack the P = NP question, the concept of NP-completeness is very useful. NP-complete problems are problems that any other NP problem is reducible to in polynomial time and whose solution is still verifiable in polynomial time. That is, any NP problem can be transformed into any NP-complete problem. Informally, an NP-complete problem is an NP problem that is at least as "tough" as any other problem in NP.

NP-hard problems are those at least as hard as NP problems; i.e., all NP problems can be reduced (in polynomial time) to them. NP-hard problems need not be in NP; i.e., they need not have solutions verifiable in polynomial time.

For instance, the Boolean satisfiability problem is NP-complete by the Cook–Levin theorem, so "any" instance of "any" problem in NP can be transformed mechanically into a Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many NP-complete problems. If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems are NP-complete, and no fast algorithm for any of them is known.

From the definition alone it is unintuitive that NP-complete problems exist; however, a trivial NP-complete problem can be formulated as follows: given a Turing machine "M" guaranteed to halt in polynomial time, does a polynomial-size input that "M" will accept exist? It is in NP because (given an input) it is simple to check whether "M" accepts the input by simulating "M"; it is NP-complete because the verifier for any particular instance of a problem in NP can be encoded as a polynomial-time machine "M" that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists.

The first natural problem proven to be NP-complete was the Boolean satisfiability problem, also known as SAT. As noted above, this is the Cook–Levin theorem; its proof that satisfiability is NP-complete contains technical details about Turing machines as they relate to the definition of NP. However, after this problem was proved to be NP-complete, proof by reduction provided a simpler way to show that many other problems are also NP-complete, including the game Sudoku discussed earlier. In this case, the proof shows that a solution of Sudoku in polynomial time could also be used to complete Latin squares in polynomial time. This in turn gives a solution to the problem of partitioning tri-partite graphs into triangles, which could then be used to find solutions for the special case of SAT known as 3-SAT, which then provides a solution for general Boolean satisfiability. So a polynomial-time solution to Sudoku leads, by a series of mechanical transformations, to a polynomial time solution of satisfiability, which in turn can be used to solve any other NP-problem in polynomial time. Using transformations like this, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense "the same problem".

Although it is unknown whether P = NP, problems outside of P are known. Just as the class P is defined in terms of polynomial running time, the class EXPTIME is the set of all decision problems that have "exponential" running time. In other words, any problem in EXPTIME is solvable by a deterministic Turing machine in O(2) time, where "p"("n") is a polynomial function of "n". A decision problem is EXPTIME-complete if it is in EXPTIME, and every problem in EXPTIME has a polynomial-time many-one reduction to it. A number of problems are known to be EXPTIME-complete. Because it can be shown that P ≠ EXPTIME, these problems are outside P, and so require more than polynomial time. In fact, by the time hierarchy theorem, they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for chess positions on an "N" × "N" board and similar problems for other board games.

The problem of deciding the truth of a statement in Presburger arithmetic requires even more time. Fischer and Rabin proved in 1974 that every algorithm that decides the truth of Presburger statements of length "n" has a runtime of at least formula_1 for some constant "c". Hence, the problem is known to need more than exponential run time. Even more difficult are the undecidable problems, such as the halting problem. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all.

It is also possible to consider questions other than decision problems. One such class, consisting of counting problems, is called #P: whereas an NP problem asks "Are there any solutions?", the corresponding #P problem asks "How many solutions are there?". Clearly, a #P problem must be at least as hard as the corresponding NP problem, since a count of solutions immediately tells if at least one solution exists, if the count is greater than zero. Surprisingly, some #P problems that are believed to be difficult correspond to easy (for example linear-time) P problems. For these problems, it is very easy to tell whether solutions exist, but thought to be very hard to tell how many. Many of these problems are #P-complete, and hence among the hardest problems in #P, since a polynomial time solution to any of them would allow a polynomial time solution to all other #P problems.

In 1975, Richard E. Ladner showed that if P ≠ NP, then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem, and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete.

The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to László Babai, runs in quasi-polynomial time.

The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than "k". No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP = co-NP). The most efficient known algorithm for integer factorization is the general number field sieve, which takes expected time

to factor an "n"-bit integer. The best known quantum algorithm for this problem, Shor's algorithm, runs in polynomial time, although this does not indicate where the problem lies with respect to non-quantum complexity classes.

All of the above discussion has assumed that P means "easy" and "not in P" means "difficult", an assumption known as "Cobham's thesis". It is a common and reasonably accurate assumption in complexity theory; but there are caveats.

First, it can be false in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents, rendering it impractical. For example, the problem of deciding whether a graph "G" contains "H" as a minor, where "H" is fixed, can be solved in a running time of "O"("n"), where "n" is the number of vertices in "G". However, the big O notation hides a constant that depends superexponentially on "H". The constant is greater than formula_3 (using Knuth's up-arrow notation), and where "h" is the number of vertices in "H".

On the other hand, even if a problem is shown to be NP-complete, and even if P ≠ NP, there may still be effective approaches to the problem in practice. There are algorithms for many NP-complete problems, such as the knapsack problem, the traveling salesman problem, and the Boolean satisfiability problem, that can solve to optimality many real-world instances in reasonable time. The empirical average-case complexity (time vs. problem size) of such algorithms can be surprisingly low. An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity, it runs on par with the best known polynomial-time algorithms.

Finally, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms.

Cook provides a restatement of the problem in "The P Versus NP Problem" as "Does P = NP?" According to polls, most computer scientists believe that P ≠ NP. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems (see List of NP-complete problems). These algorithms were sought long before the concept of NP-completeness was even defined (Karp's 21 NP-complete problems, among the first found, were all well-known existing problems at the time they were shown to be NP-complete). Furthermore, the result P = NP would imply many other startling results that are currently believed to be false, such as NP = co-NP and P = PH.

It is also intuitively argued that the existence of problems that are hard to solve but for which the solutions are easy to verify matches real-world experience.
On the other hand, some researchers believe that there is overconfidence in believing P ≠ NP and that researchers should explore proofs of P = NP as well. For example, in 2002 these statements were made:

When one substitutes "linear time on a multitape Turing machine" for "polynomial time" in the definitions of P and NP, one obtains the classes DLIN and NLIN.
It is known that DLIN≠NLIN.

One of the reasons the problem attracts so much attention is the consequences of the possible answers. Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well.

A proof that P = NP could have stunning practical consequences if the proof leads to efficient methods for solving some of the important problems in NP. The potential consequences, both positive and negative, arise since various NP-complete problems are fundamental in many fields.

It is also very possible that a proof would "not" lead to practical algorithms for NP-complete problems. The formulation of the problem does not require that the bounding polynomial be small or even specifically known. A non-constructive proof might show a solution exists without specifying either an algorithm to obtain it or a specific bound. Even if the proof is constructive, showing an explicit bounding polynomial and algorithmic details, if the polynomial is not very low-order the algorithm might not be sufficiently efficient in practice. In this case the initial proof would be mainly of interest to theoreticians, but the knowledge that polynomial time solutions are possible would surely spur research into better (and possibly practical) methods to achieve them.

An example of a field that could be upended by a solution showing P = NP is cryptography, which relies on certain problems being difficult. A constructive and efficient solution to an NP-complete problem such as 3-SAT would break most existing cryptosystems including:
These would need to be modified or replaced by information-theoretically secure solutions not inherently based on P–NP inequivalence.

On the other hand, there are enormous positive consequences that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in operations research are NP-complete, such as some types of integer programming and the travelling salesman problem. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in protein structure prediction, are also NP-complete; if these problems were efficiently solvable, it could spur considerable advances in life sciences and biotechnology.

But such changes may pale in significance compared to the revolution an efficient method for solving NP-complete problems would cause in mathematics itself. Gödel, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics:

Similarly, Stephen Cook (assuming not only a proof, but a practically efficient algorithm) says:
Research mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated—for instance, Fermat's Last Theorem took over three centuries to prove. A method that is guaranteed to find proofs to theorems, should one exist of a "reasonable" size, would essentially end this struggle.

Donald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof:

A proof showing that P ≠ NP would lack the practical computational benefits of a proof that P = NP, but would nevertheless represent a very significant advance in computational complexity theory and provide guidance for future research. It would allow one to show in a formal way that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in P ≠ NP, much of this focusing of research has already taken place.

Also, P ≠ NP still leaves open the average-case complexity of hard problems in NP. For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. Russell Impagliazzo has described five hypothetical "worlds" that could result from different possible resolutions to the average-case complexity question. These range from "Algorithmica", where P = NP and problems like SAT can be solved efficiently in all instances, to "Cryptomania", where P ≠ NP and generating hard instances of problems outside P is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of NP-hard problems. The "world" where P ≠ NP but all problems in NP are tractable in the average case is called "Heuristica" in the paper. A Princeton University workshop in 2009 studied the status of the five worlds.

Although the P = NP problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques. In particular, some of the most fruitful research related to the P = NP problem has been in showing that existing proof techniques are not powerful enough to answer the question, thus suggesting that novel technical approaches are required.

As additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, each of which is known to be insufficient to prove that P ≠ NP:
These barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results.

These barriers have also led some computer scientists to suggest that the P versus NP problem may be independent of standard axiom systems like ZFC (cannot be proved or disproved within them). The interpretation of an independence result could be that either no polynomial-time algorithm exists for any NP-complete problem, and such a proof cannot be constructed in (e.g.) ZFC, or that polynomial-time algorithms for NP-complete problems may exist, but it is impossible to prove in ZFC that such algorithms are correct. However, if it can be shown, using techniques of the sort that are currently known to be applicable, that the problem cannot be decided even with much weaker assumptions extending the Peano axioms (PA) for integer arithmetic, then there would necessarily exist nearly polynomial-time algorithms for every problem in NP. Therefore, if one believes (as most complexity theorists do) that not all problems in NP have efficient algorithms, it would follow that proofs of independence using those techniques cannot be possible. Additionally, this result implies that proving independence from PA or ZFC using currently known techniques is no easier than proving the existence of efficient algorithms for all problems in NP.

The P = NP problem can be restated in terms of expressible certain classes of logical statements, as a result of work in descriptive complexity.

Consider all languages of finite structures with a fixed signature including a linear order relation. Then, all such languages in P can be expressed in first-order logic with the addition of a suitable least fixed-point combinator. Effectively, this, in combination with the order, allows the definition of recursive functions. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P.

Similarly, NP is the set of languages expressible in existential second-order logic—that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets. The languages in the polynomial hierarchy, PH, correspond to all of second-order logic. Thus, the question "is P a proper subset of NP" can be reformulated as "is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?". The word "existential" can even be dropped from the previous characterization, since P = NP if and only if P = PH (as the former would establish that NP = co-NP, which in turn implies that NP = PH).

No algorithm for any NP-complete problem is known to run in polynomial time. However, there are algorithms known for NP-complete problems with the property that if P = NP, then the algorithm runs in polynomial time on accepting instances (although with enormous constants, making the algorithm impractical). However, these algorithms do not qualify as polynomial time because their running time on rejecting instances are not polynomial. The following algorithm, due to Levin (without any citation), is such an example below. It correctly accepts the NP-complete language SUBSET-SUM. It runs in polynomial time on inputs that are in SUBSET-SUM if and only if P = NP:

If, and only if, P = NP, then this is a polynomial-time algorithm accepting an NP-complete language. "Accepting" means it gives "yes" answers in polynomial time, but is allowed to run forever when the answer is "no" (also known as a "semi-algorithm").

This algorithm is enormously impractical, even if P = NP. If the shortest program that can solve SUBSET-SUM in polynomial time is "b" bits long, the above algorithm will try at least other programs first.

Conceptually speaking, a "decision problem" is a problem that takes as input some string "w" over an alphabet Σ, and outputs "yes" or "no". If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that can produce the correct answer for any input string of length "n" in at most "cn" steps, where "k" and "c" are constants independent of the input string, then we say that the problem can be solved in "polynomial time" and we place it in the class P. Formally, P is defined as the set of all languages that can be decided by a deterministic polynomial-time Turing machine. That is,
where
and a deterministic polynomial-time Turing machine is a deterministic Turing machine "M" that satisfies the following two conditions:


NP can be defined similarly using nondeterministic Turing machines (the traditional way). However, a modern approach to define NP is to use the concept of "certificate" and "verifier". Formally, NP is defined as the set of languages over a finite alphabet that have a verifier that runs in polynomial time, where the notion of "verifier" is defined as follows.

Let "L" be a language over a finite alphabet, Σ.

"L" ∈ NP if, and only if, there exists a binary relation formula_10 and a positive integer "k" such that the following two conditions are satisfied:


A Turing machine that decides "L" is called a "verifier" for "L" and a "y" such that ("x", "y") ∈ "R" is called a "certificate of membership" of "x" in "L".

In general, a verifier does not have to be polynomial-time. However, for "L" to be in NP, there must be a verifier that runs in polynomial time.

Let
Clearly, the question of whether a given "x" is a composite is equivalent to the question of whether "x" is a member of COMPOSITE. It can be shown that COMPOSITE ∈ NP by verifying that it satisfies the above definition (if we identify natural numbers with their binary representations).

COMPOSITE also happens to be in P, a fact demonstrated by the invention of the AKS primality test.

There are many equivalent ways of describing NP-completeness.

Let "L" be a language over a finite alphabet Σ.

"L" is NP-complete if, and only if, the following two conditions are satisfied:


Alternatively, if "L" ∈ NP, and there is another NP-complete problem that can be polynomial-time reduced to "L", then "L" is NP-complete. This is a common way of proving some new problem is NP-complete.

While the P versus NP problem is generally considered unsolved, many amateur and some professional researchers have claimed solutions. Gerhard J. Woeginger compiled a list of 62 purported proofs of P = NP from 1986 to 2016, of which 50 were proofs of P ≠ NP, 2 were proofs the problem is unprovable, and one was a proof that it is undecidable. Some attempts at resolving P versus NP have received brief media attention, though these attempts have since been refuted.

The film "Travelling Salesman", by director Timothy Lanzone, is the story of four mathematicians hired by the US government to solve the P versus NP problem.

In the sixth episode of "The Simpsons" seventh season "Treehouse of Horror VI", the equation P = NP is seen shortly after Homer accidentally stumbles into the "third dimension".

In the second episode of season 2 of "Elementary", "Solve for X" revolves around Sherlock and Watson investigating the murders of mathematicians who were attempting to solve P versus NP.





Charles Sanders Peirce

Charles Sanders Peirce ( ; September 10, 1839 – April 19, 1914) was an American scientist, mathematician, logician, and philosopher who is sometimes known as "the father of pragmatism". According to philosopher Paul Weiss, Peirce was "the most original and versatile of America's philosophers and America's greatest logician". Bertrand Russell wrote "he was one of the most original minds of the later nineteenth century and certainly the greatest American thinker ever". 

Educated as a chemist and employed as a scientist for thirty years, Peirce meanwhile made major contributions to logic, such as theories of relations and quantification. C. I. Lewis wrote, "The contributions of C.S. Peirce to symbolic logic are more numerous and varied than those of any other writer—at least in the nineteenth century." For Peirce, logic also encompassed much of what is now called epistemology and the philosophy of science. He saw logic as the formal branch of semiotics or study of signs, of which he is a founder, which foreshadowed the debate among logical positivists and proponents of philosophy of language that dominated 20th-century Western philosophy. Peirce's study of signs also included a tripartite theory of predication. 

Additionally, he defined the concept of abductive reasoning, as well as rigorously formulating mathematical induction and deductive reasoning. He was one of the founders of statistics. As early as 1886, he saw that logical operations could be carried out by electrical switching circuits. The same idea was used decades later to produce digital computers.

For metaphysics, Peirce was an "objective idealist" in the tradition of German philosopher Immanuel Kant as well as a scholastic realist about universals. He also held a commitment to the ideas of continuity and chance as real features of the universe, views he labeled synechism and tychism respectively. Peirce believed an epistemic fallibilism and anti-skepticism went along with these views. 

Peirce was born at 3 Phillips Place in Cambridge, Massachusetts. He was the son of Sarah Hunt Mills and Benjamin Peirce, himself a professor of mathematics and astronomy at Harvard University. At age 12, Charles read his older brother's copy of Richard Whately's "Elements of Logic", then the leading English-language text on the subject. So began his lifelong fascination with logic and reasoning. 

He suffered from his late teens onward from a nervous condition then known as "facial neuralgia", which would today be diagnosed as trigeminal neuralgia. His biographer, Joseph Brent, says that when in the throes of its pain "he was, at first, almost stupefied, and then aloof, cold, depressed, extremely suspicious, impatient of the slightest crossing, and subject to violent outbursts of temper". Its consequences may have led to the social isolation of his later life.

Peirce went on to earn a Bachelor of Arts degree and a Master of Arts degree (1862) from Harvard. In 1863 the Lawrence Scientific School awarded him a Bachelor of Science degree, Harvard's first "summa cum laude" chemistry degree. His academic record was otherwise undistinguished. At Harvard, he began lifelong friendships with Francis Ellingwood Abbot, Chauncey Wright, and William James. One of his Harvard instructors, Charles William Eliot, formed an unfavorable opinion of Peirce. This proved fateful, because Eliot, while President of Harvard (1869–1909—a period encompassing nearly all of Peirce's working life), repeatedly vetoed Peirce's employment at the university.

Between 1859 and 1891, Peirce was intermittently employed in various scientific capacities by the United States Coast Survey, which in 1878 was renamed the United States Coast and Geodetic Survey, where he enjoyed his highly influential father's protection until the latter's death in 1880. At the Survey, he worked mainly in geodesy and gravimetry, refining the use of pendulums to determine small local variations in the Earth's gravity.

This employment exempted Peirce from having to take part in the American Civil War; it would have been very awkward for him to do so, as the Boston Brahmin Peirces sympathized with the Confederacy. No members of the Peirce family volunteered or enlisted. Peirce grew up in a home where white supremacy was taken for granted, and slavery was considered natural. Peirce's father had described himself as a secessionist until the outbreak of the war, after which he became a Union partisan, providing donations to the Sanitary Commission, the leading Northern war charity. 

Peirce liked to use the following syllogism to illustrate the unreliability of traditional forms of logic (for the first premise arguably assumes the conclusion):<poem>
All Men are equal in their political rights.
Negroes are Men.
Therefore, negroes are equal in political rights to whites.</poem>

He was elected a resident fellow of the American Academy of Arts and Sciences in January 1867. The Survey sent him to Europe five times, first in 1871 as part of a group sent to observe a solar eclipse. There, he sought out Augustus De Morgan, William Stanley Jevons, and William Kingdon Clifford, British mathematicians and logicians whose turn of mind resembled his own. 

From 1869 to 1872, he was employed as an assistant in Harvard's astronomical observatory, doing important work on determining the brightness of stars and the shape of the Milky Way. In 1872 he founded the Metaphysical Club, a conversational philosophical club that Peirce, the future Supreme Court Justice Oliver Wendell Holmes Jr., the philosopher and psychologist William James, amongst others, formed in January 1872 in Cambridge, Massachusetts, and dissolved in December 1872. Other members of the club included Chauncey Wright, John Fiske, Francis Ellingwood Abbot, Nicholas St. John Green, and Joseph Bangs Warner. The discussions eventually birthed Peirce's notion of pragmatism.

On April 20, 1877, he was elected a member of the National Academy of Sciences. Also in 1877, he proposed measuring the meter as so many wavelengths of light of a certain frequency, the kind of definition employed from 1960 to 1983.

In 1879 Peirce developed Peirce quincuncial projection, having been inspired by H. A. Schwarz's 1869 conformal transformation of a circle onto a polygon of "n" sides (known as the Schwarz–Christoffel mapping). 

During the 1880s, Peirce's indifference to bureaucratic detail waxed while his Survey work's quality and timeliness waned. Peirce took years to write reports that he should have completed in months. Meanwhile, he wrote entries, ultimately thousands, during 1883–1909 on philosophy, logic, science, and other subjects for the encyclopedic "Century Dictionary". In 1885, an investigation by the Allison Commission exonerated Peirce, but led to the dismissal of Superintendent Julius Hilgard and several other Coast Survey employees for misuse of public funds. In 1891, Peirce resigned from the Coast Survey at Superintendent Thomas Corwin Mendenhall's request.

In 1879, Peirce was appointed lecturer in logic at Johns Hopkins University, which had strong departments in areas that interested him, such as philosophy (Royce and Dewey completed their PhDs at Hopkins), psychology (taught by G. Stanley Hall and studied by Joseph Jastrow, who coauthored a landmark empirical study with Peirce), and mathematics (taught by J. J. Sylvester, who came to admire Peirce's work on mathematics and logic). His "Studies in Logic by Members of the Johns Hopkins University" (1883) contained works by himself and Allan Marquand, Christine Ladd, Benjamin Ives Gilman, and Oscar Howard Mitchell, several of whom were his graduate students. Peirce's nontenured position at Hopkins was the only academic appointment he ever held.

Brent documents something Peirce never suspected, namely that his efforts to obtain academic employment, grants, and scientific respectability were repeatedly frustrated by the covert opposition of a major Canadian-American scientist of the day, Simon Newcomb. Newcomb had been a favourite student of Peirce's father; although "no doubt quite bright", "like Salieri in Peter Shaffer’s Amadeus he also had just enough talent to recognize he was not a genius and just enough pettiness to resent someone who was". Additionally "an intensely devout and literal-minded Christian of rigid moral standards", he was appalled by what he considered Peirce's personal shortcomings. Peirce's efforts may also have been hampered by what Brent characterizes as "his difficult personality". In contrast, Keith Devlin believes that Peirce's work was too far ahead of his time to be appreciated by the academic establishment of the day and that this played a large role in his inability to obtain a tenured position.

Peirce's personal life undoubtedly worked against his professional success. After his first wife, Harriet Melusina Fay ("Zina"), left him in 1875, Peirce, while still legally married, became involved with Juliette, whose last name, given variously as Froissy and Pourtalai, and nationality (she spoke French) remains uncertain. When his divorce from Zina became final in 1883, he married Juliette. That year, Newcomb pointed out to a Johns Hopkins trustee that Peirce, while a Hopkins employee, had lived and traveled with a woman to whom he was not married; the ensuing scandal led to his dismissal in January 1884. Over the years Peirce sought academic employment at various universities without success. He had no children by either marriage.

In 1887, Peirce spent part of his inheritance from his parents to buy of rural land near Milford, Pennsylvania, which never yielded an economic return. There he had an 1854 farmhouse remodeled to his design. The Peirces named the property "Arisbe". There they lived with few interruptions for the rest of their lives, Charles writing prolifically, with much of his work remaining unpublished to this day (see Works). Living beyond their means soon led to grave financial and legal difficulties. Charles spent much of his last two decades unable to afford heat in winter and subsisting on old bread donated by the local baker. Unable to afford new stationery, he wrote on the verso side of old manuscripts. An outstanding warrant for assault and unpaid debts led to his being a fugitive in New York City for a while. Several people, including his brother James Mills Peirce and his neighbors, relatives of Gifford Pinchot, settled his debts and paid his property taxes and mortgage.

Peirce did some scientific and engineering consulting and wrote much for meager pay, mainly encyclopedic dictionary entries, and reviews for "The Nation" (with whose editor, Wendell Phillips Garrison, he became friendly). He did translations for the Smithsonian Institution, at its director Samuel Langley's instigation. Peirce also did substantial mathematical calculations for Langley's research on powered flight. Hoping to make money, Peirce tried inventing. He began but did not complete several books. In 1888, President Grover Cleveland appointed him to the Assay Commission.

From 1890 on, he had a friend and admirer in Judge Francis C. Russell of Chicago, who introduced Peirce to editor Paul Carus and owner Edward C. Hegeler of the pioneering American philosophy journal "The Monist", which eventually published at least 14 articles by Peirce. He wrote many texts in James Mark Baldwin's "Dictionary of Philosophy and Psychology" (1901–1905); half of those credited to him appear to have been written actually by Christine Ladd-Franklin under his supervision. He applied in 1902 to the newly formed Carnegie Institution for a grant to write a systematic book describing his life's work. The application was doomed; his nemesis, Newcomb, served on the Carnegie Institution executive committee, and its president had been president of Johns Hopkins at the time of Peirce's dismissal.

The one who did the most to help Peirce in these desperate times was his old friend William James, dedicating his "Will to Believe" (1897) to Peirce, and arranging for Peirce to be paid to give two series of lectures at or near Harvard (1898 and 1903). Most important, each year from 1907 until James's death in 1910, James wrote to his friends in the Boston intelligentsia to request financial aid for Peirce; the fund continued even after James died. Peirce reciprocated by designating James's eldest son as his heir should Juliette predecease him. It has been believed that this was also why Peirce used "Santiago" ("St. James" in English) as a middle name, but he appeared in print as early as 1890 as Charles Santiago Peirce. (See Charles Santiago Sanders Peirce for discussion and references).

Peirce died destitute in Milford, Pennsylvania, twenty years before his widow. Juliette Peirce kept the urn with Peirce's ashes at Arisbe. In 1934, Pennsylvania Governor Gifford Pinchot arranged for Juliette's burial in Milford Cemetery. The urn with Peirce's ashes was interred with Juliette.

Bertrand Russell (1959) wrote "Beyond doubt [...] he was one of the most original minds of the later nineteenth century and certainly the greatest American thinker ever". Russell and Whitehead's "Principia Mathematica", published from 1910 to 1913, does not mention Peirce (Peirce's work was not widely known until later). A. N. Whitehead, while reading some of Peirce's unpublished manuscripts soon after arriving at Harvard in 1924, was struck by how Peirce had anticipated his own "process" thinking. (On Peirce and process metaphysics, see Lowe 1964.) Karl Popper viewed Peirce as "one of the greatest philosophers of all times". Yet Peirce's achievements were not immediately recognized. His imposing contemporaries William James and Josiah Royce admired him and Cassius Jackson Keyser, at Columbia and C. K. Ogden, wrote about Peirce with respect but to no immediate effect.

The first scholar to give Peirce his considered professional attention was Royce's student Morris Raphael Cohen, the editor of an anthology of Peirce's writings entitled "Chance, Love, and Logic" (1923), and the author of the first bibliography of Peirce's scattered writings. John Dewey studied under Peirce at Johns Hopkins. From 1916 onward, Dewey's writings repeatedly mention Peirce with deference. His 1938 "Logic: The Theory of Inquiry" is much influenced by Peirce. The publication of the first six volumes of "Collected Papers" (1931–1935), the most important event to date in Peirce studies and one that Cohen made possible by raising the needed funds, did not prompt an outpouring of secondary studies. The editors of those volumes, Charles Hartshorne and Paul Weiss, did not become Peirce specialists. Early landmarks of the secondary literature include the monographs by Buchler (1939), Feibleman (1946), and Goudge (1950), the 1941 PhD thesis by Arthur W. Burks (who went on to edit volumes 7 and 8), and the studies edited by Wiener and Young (1952). The Charles S. Peirce Society was founded in 1946. Its "Transactions", an academic quarterly specializing in Peirce's pragmatism and American philosophy has appeared since 1965. (See Phillips 2014, 62 for discussion of Peirce and Dewey relative to transactionalism.)

By 1943 such was Peirce's reputation, in the US at least, that "Webster's Biographical Dictionary" said that Peirce was "now regarded as the most original thinker and greatest logician of his time".

In 1949, while doing unrelated archival work, the historian of mathematics Carolyn Eisele (1902–2000) chanced on an autograph letter by Peirce. So began her forty years of research on Peirce, “the mathematician and scientist,” culminating in Eisele (1976, 1979, 1985). Beginning around 1960, the philosopher and historian of ideas Max Fisch (1900–1995) emerged as an authority on Peirce (Fisch, 1986). He includes many of his relevant articles in a survey (Fisch 1986: 422–448) of the impact of Peirce's thought through 1983.

Peirce has gained an international following, marked by university research centers devoted to Peirce studies and pragmatism in Brazil (CeneP/CIEP), Finland (HPRC and ), Germany (Wirth's group, Hoffman's and Otte's group, and Deuser's and Härle's group), France (L'I.R.S.C.E.), Spain (GEP), and Italy (CSP). His writings have been translated into several languages, including German, French, Finnish, Spanish, and Swedish. Since 1950, there have been French, Italian, Spanish, British, and Brazilian Peirce scholars of note. For many years, the North American philosophy department most devoted to Peirce was the University of Toronto, thanks in part to the leadership of Thomas Goudge and David Savan. In recent years, U.S. Peirce scholars have clustered at Indiana University – Purdue University Indianapolis, home of the Peirce Edition Project (PEP) –, and Pennsylvania State University.

In recent years, Peirce's trichotomy of signs is exploited by a growing number of practitioners for marketing and design tasks.

John Deely writes that Peirce was the last of the "moderns" and "first of the postmoderns". He lauds Peirce's doctrine of signs as a contribution to the dawn of the Postmodern epoch. Deely additionally comments that "Peirce stands...in a position analogous to the position occupied by Augustine as last of the Western Fathers and first of the medievals".

Peirce's reputation rests largely on academic papers published in American scientific and scholarly journals such as "Proceedings of the American Academy of Arts and Sciences", the "Journal of Speculative Philosophy", "The Monist", "Popular Science Monthly", the "American Journal of Mathematics", "Memoirs of the National Academy of Sciences", "The Nation", and others. See Articles by Peirce, published in his lifetime for an extensive list with links to them online. The only full-length book (neither extract nor pamphlet) that Peirce authored and saw published in his lifetime was "Photometric Researches" (1878), a 181-page monograph on the applications of spectrographic methods to astronomy. While at Johns Hopkins, he edited "Studies in Logic" (1883), containing chapters by himself and his graduate students. Besides lectures during his years (1879–1884) as lecturer in Logic at Johns Hopkins, he gave at least nine series of lectures, many now published; see Lectures by Peirce.

After Peirce's death, Harvard University obtained from Peirce's widow the papers found in his study, but did not microfilm them until 1964. Only after Richard Robin (1967) catalogued this "Nachlass" did it become clear that Peirce had left approximately 1,650 unpublished manuscripts, totaling over 100,000 pages, mostly still unpublished except on microfilm. On the vicissitudes of Peirce's papers, see Houser (1989). Reportedly the papers remain in unsatisfactory condition.

The first published anthology of Peirce's articles was the one-volume "Chance, Love and Logic: Philosophical Essays", edited by Morris Raphael Cohen, 1923, still in print. Other one-volume anthologies were published in 1940, 1957, 1958, 1972, 1994, and 2009, most still in print. The main posthumous editions of Peirce's works in their long trek to light, often multi-volume, and some still in print, have included:

1931–1958: "Collected Papers of Charles Sanders Peirce" (CP), 8 volumes, includes many published works, along with a selection of previously unpublished work and a smattering of his correspondence. This long-time standard edition drawn from Peirce's work from the 1860s to 1913 remains the most comprehensive survey of his prolific output from 1893 to 1913. It is organized thematically, but texts (including lecture series) are often split up across volumes, while texts from various stages in Peirce's development are often combined, requiring frequent visits to editors' notes. Edited (1–6) by Charles Hartshorne and Paul Weiss and (7–8) by Arthur Burks, in print and online.

1975–1987: "Charles Sanders Peirce: Contributions to" The Nation, 4 volumes, includes Peirce's more than 300 reviews and articles published 1869–1908 in "The Nation". Edited by Kenneth Laine Ketner and James Edward Cook, online.

1976: "The New Elements of Mathematics by Charles S. Peirce", 4 volumes in 5, included many previously unpublished Peirce manuscripts on mathematical subjects, along with Peirce's important published mathematical articles. Edited by Carolyn Eisele, back in print.

1977: "Semiotic and Significs: The Correspondence between C. S. Peirce and Victoria Lady Welby" (2nd edition 2001), included Peirce's entire correspondence (1903–1912) with Victoria, Lady Welby. Peirce's other published correspondence is largely limited to the 14 letters included in volume 8 of the "Collected Papers", and the 20-odd pre-1890 items included so far in the "Writings". Edited by Charles S. Hardwick with James Cook, out of print.

1982–now: "Writings of Charles S. Peirce, A Chronological Edition" (W), Volumes 1–6 & 8, of a projected 30. The limited coverage, and defective editing and organization, of the "Collected Papers" led Max Fisch and others in the 1970s to found the Peirce Edition Project (PEP), whose mission is to prepare a more complete critical chronological edition. Only seven volumes have appeared to date, but they cover the period from 1859 to 1892, when Peirce carried out much of his best-known work. "Writings of Charles S. Peirce", 8 was published in November 2010; and work continues on "Writings of Charles S. Peirce", 7, 9, and 11. In print and online.

1985: "Historical Perspectives on Peirce's Logic of Science: A History of Science", 2 volumes. Auspitz has said, "The extent of Peirce's immersion in the science of his day is evident in his reviews in the "Nation" [...] and in his papers, grant applications, and publishers' prospectuses in the history and practice of science", referring latterly to "Historical Perspectives". Edited by Carolyn Eisele, back in print.

1992: "Reasoning and the Logic of Things" collects in one place Peirce's 1898 series of lectures invited by William James. Edited by Kenneth Laine Ketner, with commentary by Hilary Putnam, in print.

1992–1998: "The Essential Peirce" (EP), 2 volumes, is an important recent sampler of Peirce's philosophical writings. Edited (1) by Nathan Hauser and Christian Kloesel and (2) by "Peirce Edition Project" editors, in print.

1997: "Pragmatism as a Principle and Method of Right Thinking" collects Peirce's 1903 Harvard "Lectures on Pragmatism" in a study edition, including drafts, of Peirce's lecture manuscripts, which had been previously published in abridged form; the lectures now also appear in "The Essential Peirce", 2. Edited by Patricia Ann Turisi, in print.

2010: "Philosophy of Mathematics: Selected Writings" collects important writings by Peirce on the subject, many not previously in print. Edited by Matthew E. Moore, in print.

Peirce's most important work in pure mathematics was in logical and foundational areas. He also worked on linear algebra, matrices, various geometries, topology and Listing numbers, Bell numbers, graphs, the four-color problem, and the nature of continuity.

He worked on applied mathematics in economics, engineering, and map projections, and was especially active in probability and statistics.


Peirce made a number of striking discoveries in formal logic and foundational mathematics, nearly all of which came to be appreciated only long after he died:

In 1860 he suggested a cardinal arithmetic for infinite numbers, years before any work by Georg Cantor (who completed his dissertation in 1867) and without access to Bernard Bolzano's 1851 (posthumous) "Paradoxien des Unendlichen".

In 1880–1881 he showed how Boolean algebra could be done via a repeated sufficient single binary operation (logical NOR), anticipating Henry M. Sheffer by 33 years. (See also De Morgan's Laws.)

In 1881 he set out the axiomatization of natural number arithmetic, a few years before Richard Dedekind and Giuseppe Peano. In the same paper Peirce gave, years before Dedekind, the first purely cardinal definition of a finite set in the sense now known as "Dedekind-finite", and implied by the same stroke an important formal definition of an infinite set (Dedekind-infinite), as a set that can be put into a one-to-one correspondence with one of its proper subsets.

In 1885 he distinguished between first-order and second-order quantification. In the same paper he set out what can be read as the first (primitive) axiomatic set theory, anticipating Zermelo by about two decades (Brady 2000, pp. 132–133).

In 1886, he saw that Boolean calculations could be carried out via electrical switches, anticipating Claude Shannon by more than 50 years. 
By the later 1890s he was devising existential graphs, a diagrammatic notation for the predicate calculus. Based on them are John F. Sowa's conceptual graphs and Sun-Joo Shin's diagrammatic reasoning.


Peirce wrote drafts for an introductory textbook, with the working title "The New Elements of Mathematics", that presented mathematics from an original standpoint. Those drafts and many other of his previously unpublished mathematical manuscripts finally appeared in "The New Elements of Mathematics by Charles S. Peirce" (1976), edited by mathematician Carolyn Eisele.


Peirce agreed with Auguste Comte in regarding mathematics as more basic than philosophy and the special sciences (of nature and mind). Peirce classified mathematics into three subareas: (1) mathematics of logic, (2) discrete series, and (3) pseudo-continua (as he called them, including the real numbers) and continua. Influenced by his father Benjamin, Peirce argued that mathematics studies purely hypothetical objects and is not just the science of quantity but is more broadly the science which draws necessary conclusions; that mathematics aids logic, not vice versa; and that logic itself is part of philosophy and is the science "about" drawing conclusions necessary and otherwise.

Peirce held that science achieves statistical probabilities, not certainties, and that spontaneity (absolute chance) is real (see Tychism on his view). Most of his statistical writings promote the frequency interpretation of probability (objective ratios of cases), and many of his writings express skepticism about (and criticize the use of) probability when such models are not based on objective randomization. Though Peirce was largely a frequentist, his possible world semantics introduced the "propensity" theory of probability before Karl Popper. Peirce (sometimes with Joseph Jastrow) investigated the probability judgments of experimental subjects, "perhaps the very first" elicitation and estimation of subjective probabilities in experimental psychology and (what came to be called) Bayesian statistics.

Peirce was one of the founders of statistics. He formulated modern statistics in "Illustrations of the Logic of Science" (1877–1878) and "A Theory of Probable Inference" (1883). With a repeated measures design, Charles Sanders Peirce and Joseph Jastrow introduced blinded, controlled randomized experiments in 1884 (Hacking 1990:205) (before Ronald A. Fisher). He invented optimal design for experiments on gravity, in which he "corrected the means". He used correlation and smoothing. Peirce extended the work on outliers by Benjamin Peirce, his father. He introduced terms "confidence" and "likelihood" (before Jerzy Neyman and Fisher). (See Stephen Stigler's historical books and Ian Hacking 1990.)

Peirce was a working scientist for 30 years, and arguably was a professional philosopher only during the five years he lectured at Johns Hopkins. He learned philosophy mainly by reading, each day, a few pages of Immanuel Kant's "Critique of Pure Reason", in the original German, while a Harvard undergraduate. His writings bear on a wide array of disciplines, including mathematics, logic, philosophy, statistics, astronomy, metrology, geodesy, experimental psychology, economics, linguistics, and the history and philosophy of science. This work has enjoyed renewed interest and approval, a revival inspired not only by his anticipations of recent scientific developments but also by his demonstration of how philosophy can be applied effectively to human problems.

Peirce's philosophy includes (see below in related sections) a pervasive three-category system: belief that truth is immutable and is both independent from actual opinion (fallibilism) and discoverable (no radical skepticism), logic as formal semiotic on signs, on arguments, and on inquiry's ways—including philosophical pragmatism (which he founded), critical common-sensism, and scientific method—and, in metaphysics: Scholastic realism, e.g. John Duns Scotus, belief in God, freedom, and at least an attenuated immortality, objective idealism, and belief in the reality of continuity and of absolute chance, mechanical necessity, and creative love. In his work, fallibilism and pragmatism may seem to work somewhat like skepticism and positivism, respectively, in others' work. However, for Peirce, fallibilism is balanced by an anti-skepticism and is a basis for belief in the reality of absolute chance and of continuity, and pragmatism commits one to anti-nominalist belief in the reality of the general (CP 5.453–457).

For Peirce, First Philosophy, which he also called cenoscopy, is less basic than mathematics and more basic than the special sciences (of nature and mind). It studies positive phenomena in general, phenomena available to any person at any waking moment, and does not settle questions by resorting to special experiences. He divided such philosophy into (1) phenomenology (which he also called phaneroscopy or categorics), (2) normative sciences (esthetics, ethics, and logic), and (3) metaphysics; his views on them are discussed in order below.

 Peirce's recipe for pragmatic thinking, which he called "pragmatism" and, later, "pragmaticism", is recapitulated in several versions of the so-called "pragmatic maxim". Here is one of his more emphatic reiterations of it:

As a movement, pragmatism began in the early 1870s in discussions among Peirce, William James, and others in the Metaphysical Club. James among others regarded some articles by Peirce such as "" (1877) and especially "" (1878) as foundational to pragmatism. Peirce (CP 5.11–12), like James ("", 1907), saw pragmatism as embodying familiar attitudes, in philosophy and elsewhere, elaborated into a new deliberate method for fruitful thinking about problems. Peirce differed from James and the early John Dewey, in some of their tangential enthusiasms, in being decidedly more rationalistic and realistic, in several senses of those terms, throughout the preponderance of his own philosophical moods.

In 1905 Peirce coined the new name pragmaticism "for the precise purpose of expressing the original definition", saying that "all went happily" with James's and F.C.S. Schiller's variant uses of the old name "pragmatism" and that he coined the new name because of the old name's growing use in "literary journals, where it gets abused". Yet he cited as causes, in a 1906 manuscript, his differences with James and Schiller and, in a 1908 publication, his differences with James as well as literary author Giovanni Papini's declaration of pragmatism's indefinability. Peirce in any case regarded his views that truth is immutable and infinity is real, as being opposed by the other pragmatists, but he remained allied with them on other issues.

Pragmatism begins with the idea that belief is that on which one is prepared to act. Peirce's pragmatism is a method of clarification of conceptions of objects. It equates any conception of an object to a conception of that object's effects to a general extent of the effects' conceivable implications for informed practice. It is a method of sorting out conceptual confusions occasioned, for example, by distinctions that make (sometimes needed) formal yet not practical differences. He formulated both pragmatism and statistical principles as aspects of scientific logic, in his "Illustrations of the Logic of Science" series of articles. In the second one, "", Peirce discussed three grades of clearness of conception:


By way of example of how to clarify conceptions, he addressed conceptions about truth and the real as questions of the presuppositions of reasoning in general. In clearness's second grade (the "nominal" grade), he defined truth as a sign's correspondence to its object, and the real as the object of such correspondence, such that truth and the real are independent of that which you or I or any actual, definite community of inquirers think. After that needful but confined step, next in clearness's third grade (the pragmatic, practice-oriented grade) he defined truth as that opinion which "would" be reached, sooner or later but still inevitably, by research taken far enough, such that the real does depend on that ideal final opinion—a dependence to which he appeals in theoretical arguments elsewhere, for instance for the long-run validity of the rule of induction. Peirce argued that even to argue against the independence and discoverability of truth and the real is to presuppose that there is, about that very question under argument, a truth with just such independence and discoverability.

Peirce said that a conception's meaning consists in "all general modes of rational conduct" implied by "acceptance" of the conception—that is, if one were to accept, first of all, the conception as true, then what could one conceive to be consequent general modes of rational conduct by all who accept the conception as true?—the whole of such consequent general modes is the whole meaning. His pragmatism does not equate a conception's meaning, its intellectual purport, with the conceived benefit or cost of the conception itself, like a meme (or, say, propaganda), outside the perspective of its being true, nor, since a conception is general, is its meaning equated with any definite set of actual consequences or upshots corroborating or undermining the conception or its worth. His pragmatism also bears no resemblance to "vulgar" pragmatism, which misleadingly connotes a ruthless and Machiavellian search for mercenary or political advantage. Instead the pragmatic maxim is the heart of his pragmatism as a method of experimentational mental reflection arriving at conceptions in terms of conceivable confirmatory and disconfirmatory circumstances—a method hospitable to the formation of explanatory hypotheses, and conducive to the use and improvement of verification.

Peirce's pragmatism, as method and theory of definitions and conceptual clearness, is part of his theory of inquiry, which he variously called speculative, general, formal or universal rhetoric or simply methodeutic. He applied his pragmatism as a method throughout his work.

In "" (1877), Peirce gives his take on the psychological origin and aim of inquiry. On his view, individuals are motivated to inquiry by desire to escape the feelings of anxiety and unease which Peirce takes to be characteristic of the state of doubt. Doubt is described by Peirce as an "uneasy and dissatisfied state from which we struggle to free ourselves and pass into the state of belief." Peirce uses words like "irritation" to describe the experience of being in doubt and to explain why he thinks we find such experiences to be motivating. The irritating feeling of doubt is appeased, Peirce says, through our efforts to achieve a settled state of satisfaction with what we land on as our answer to the question which led to that doubt in the first place. This settled state, namely, belief, is described by Peirce as "a calm and satisfactory state which we do not wish to avoid." Our efforts to achieve the satisfaction of belief, by whichever methods we may pursue, are what Peirce calls "inquiry". Four methods which Peirce describes as having been actually pursued throughout the history of thought are summarized below in the section after next. 

Critical common-sensism, treated by Peirce as a consequence of his pragmatism, is his combination of Thomas Reid's common-sense philosophy with a fallibilism that recognizes that propositions of our more or less vague common sense now indubitable may later come into question, for example because of transformations of our world through science. It includes efforts to work up in tests genuine doubts for a core group of common indubitables that vary slowly if at all.

In "" (1877), Peirce described inquiry in general not as the pursuit of truth "per se" but as the struggle to move from irritating, inhibitory doubt born of surprise, disagreement, and the like, and to reach a secure belief, belief being that on which one is prepared to act. That let Peirce frame scientific inquiry as part of a broader spectrum and as spurred, like inquiry generally, by actual doubt, not mere verbal, quarrelsome, or hyperbolic doubt, which he held to be fruitless. Peirce sketched four methods of settling opinion, ordered from least to most successful:


Peirce held that, in practical affairs, slow and stumbling ratiocination is often dangerously inferior to instinct and traditional sentiment, and that the scientific method is best suited to theoretical research, which in turn should not be trammeled by the other methods and practical ends; reason's "first rule" is that, in order to learn, one must desire to learn and, as a corollary, must not block the way of inquiry. Scientific method excels over the others finally by being deliberately designed to arrive—eventually—at the most secure beliefs, upon which the most successful practices can be based. Starting from the idea that people seek not truth "per se" but instead to subdue irritating, inhibitory doubt, Peirce showed how, through the struggle, some can come to submit to truth for the sake of belief's integrity, seek as truth the guidance of potential conduct correctly to its given goal, and wed themselves to the scientific method.

Insofar as clarification by pragmatic reflection suits explanatory hypotheses and fosters predictions and testing, pragmatism points beyond the usual duo of foundational alternatives: deduction from self-evident truths, or "rationalism"; and induction from experiential phenomena, or "empiricism".

Based on his critique of three modes of argument and different from either foundationalism or coherentism, Peirce's approach seeks to justify claims by a three-phase dynamic of inquiry:


Thereby, Peirce devised an approach to inquiry far more solid than the flatter image of inductive generalization "simpliciter", which is a mere re-labeling of phenomenological patterns. Peirce's pragmatism was the first time the scientific method was proposed as an epistemology for philosophical questions.

A theory that succeeds better than its rivals in predicting and controlling our world is said to be nearer the truth. This is an operational notion of truth used by scientists.

Peirce extracted the pragmatic model or theory of inquiry from its raw materials in classical logic and refined it in parallel with the early development of symbolic logic to address problems about the nature of scientific reasoning.

Abduction, deduction, and induction make incomplete sense in isolation from one another but comprise a cycle understandable as a whole insofar as they collaborate toward the common end of inquiry. In the pragmatic way of thinking about conceivable practical implications, every thing has a purpose, and, as possible, its purpose should first be denoted. Abduction hypothesizes an explanation for deduction to clarify into implications to be tested so that induction can evaluate the hypothesis, in the struggle to move from troublesome uncertainty to more secure belief. No matter how traditional and needful it is to study the modes of inference in abstraction from one another, the integrity of inquiry strongly limits the effective modularity of its principal components.

Peirce's outline of the scientific method in §III–IV of "A Neglected Argument" is summarized below (except as otherwise noted). There he also reviewed plausibility and inductive precision (issues of critique of arguments).

1. (or retroductive) phase. Guessing, inference to explanatory hypotheses for selection of those best worth trying. From abduction, Peirce distinguishes induction as inferring, on the basis of tests, the proportion of truth in the hypothesis. Every inquiry, whether into ideas, brute facts, or norms and laws, arises from surprising observations in one or more of those realms (and for example at any stage of an inquiry already underway). All explanatory content of theories comes from abduction, which guesses a new or outside idea so as to account in a simple, economical way for a surprising or complicated phenomenon. The modicum of success in our guesses far exceeds that of random luck, and seems born of attunement to nature by developed or inherent instincts, especially insofar as best guesses are optimally plausible and simple in the sense of the "facile and natural", as by Galileo's natural light of reason and as distinct from "logical simplicity". Abduction is the most fertile but least secure mode of inference. Its general rationale is inductive: it succeeds often enough and it has no substitute in expediting us toward new truths. In 1903, Peirce called pragmatism "the logic of abduction". Coordinative method leads from abducting a plausible hypothesis to judging it for its testability and for how its trial would economize inquiry itself. The hypothesis, being insecure, needs to have practical implications leading at least to mental tests and, in science, lending themselves to scientific tests. A simple but unlikely guess, if not costly to test for falsity, may belong first in line for testing. A guess is intrinsically worth testing if it has plausibility or reasoned objective probability, while subjective likelihood, though reasoned, can be misleadingly seductive. Guesses can be selected for trial strategically, for their caution (for which Peirce gave as example the game of Twenty Questions), breadth, or incomplexity. One can discover only that which would be revealed through their sufficient experience anyway, and so the point is to expedite it; economy of research demands the leap, so to speak, of abduction and governs its art.

2. phase. Two stages:

3. phase. Evaluation of the hypothesis, inferring from observational or experimental tests of its deduced consequences. The long-run validity of the rule of induction is deducible from the principle (presuppositional to reasoning in general) that the real "is only the object of the final opinion to which sufficient investigation would lead"; in other words, anything excluding such a process would never be real. Induction involving the ongoing accumulation of evidence follows "a method which, sufficiently persisted in", will "diminish the error below any predesignate degree". Three stages:

Peirce drew on the methodological implications of the four incapacities—no genuine introspection, no intuition in the sense of non-inferential cognition, no thought but in signs, and no conception of the absolutely incognizable—to attack philosophical Cartesianism, of which he said that:


On May 14, 1867, the 27-year-old Peirce presented a paper entitled "On a New List of Categories" to the American Academy of Arts and Sciences, which published it the following year. The paper outlined a theory of predication, involving three universal categories that Peirce developed in response to reading Aristotle, Immanuel Kant, and G. W. F. Hegel, categories that Peirce applied throughout his work for the rest of his life. Peirce scholars generally regard the "New List" as foundational or breaking the ground for Peirce's "architectonic", his blueprint for a pragmatic philosophy. In the categories one will discern, concentrated, the pattern that one finds formed by the three grades of clearness in "" (1878 paper foundational to pragmatism), and in numerous other trichotomies in his work.

In 1918 the logician C. I. Lewis wrote, "The contributions of C.S. Peirce to symbolic logic are more numerous and varied than those of any other writer—at least in the nineteenth century." 

Beginning with his first paper on the "Logic of Relatives" (1870), Peirce extended the theory of relations pioneered by Augustus De Morgan. Beginning in 1940, Alfred Tarski and his students rediscovered aspects of Peirce's larger vision of relational logic, developing the perspective of relation algebra.

Relational logic gained applications. In mathematics, it influenced the abstract analysis of E. H. Moore and the lattice theory of Garrett Birkhoff. In computer science, the relational model for databases was developed with Peircean ideas in work of Edgar F. Codd, who was a doctoral student of Arthur W. Burks, a Peirce scholar. In economics, relational logic was used by Frank P. Ramsey, John von Neumann, and Paul Samuelson to study preferences and utility and by Kenneth J. Arrow in "Social Choice and Individual Values", following Arrow's association with Tarski at City College of New York.

On Peirce and his contemporaries Ernst Schröder and Gottlob Frege, Hilary Putnam (1982) documented that Frege's work on the logic of quantifiers had little influence on his contemporaries, although it was published four years before the work of Peirce and his student Oscar Howard Mitchell. Putnam found that mathematicians and logicians learned about the logic of quantifiers through the independent work of Peirce and Mitchell, particularly through Peirce's "On the Algebra of Logic: A Contribution to the Philosophy of Notation" (1885), published in the premier American mathematical journal of the day, and cited by Peano and Schröder, among others, who ignored Frege. They also adopted and modified Peirce's notations, typographical variants of those now used. Peirce apparently was ignorant of Frege's work, despite their overlapping achievements in logic, philosophy of language, and the foundations of mathematics.

Peirce's work on formal logic had admirers besides Ernst Schröder:

A philosophy of logic, grounded in his categories and semiotic, can be extracted from Peirce's writings and, along with Peirce's logical work more generally, is exposited and defended in Hilary Putnam (1982); the Introduction in Nathan Houser "et al." (1997); and Randall Dipert's chapter in Cheryl Misak (2004).

Peirce regarded logic "per se" as a division of philosophy, as a normative science based on esthetics and ethics, as more basic than metaphysics, and as "the art of devising methods of research". More generally, as inference, "logic is rooted in the social principle", since inference depends on a standpoint that, in a sense, is unlimited. Peirce called (with no sense of deprecation) "mathematics of logic" much of the kind of thing which, in current research and applications, is called simply "logic". He was productive in both (philosophical) logic and logic's mathematics, which were connected deeply in his work and thought.

Peirce argued that logic is formal semiotic: the formal study of signs in the broadest sense, not only signs that are artificial, linguistic, or symbolic, but also signs that are semblances or are indexical such as reactions. Peirce held that "all this universe is perfused with signs, if it is not composed exclusively of signs", along with their representational and inferential relations. He argued that, since all thought takes time, all thought is in signs and sign processes ("semiosis") such as the inquiry process. He divided logic into: (1) speculative grammar, or stechiology, on how signs can be meaningful and, in relation to that, what kinds of signs there are, how they combine, and how some embody or incorporate others; (2) logical critic, or logic proper, on the modes of inference; and (3) speculative or universal rhetoric, or methodeutic, the philosophical theory of inquiry, including pragmatism.

In his "F.R.L." [First Rule of Logic] (1899), Peirce states that the first, and "in one sense, the sole", rule of reason is that, "to learn, one needs to desire to learn" and desire it without resting satisfied with that which one is inclined to think. So, the first rule is, "to wonder". Peirce proceeds to a critical theme in research practices and the shaping of theories:

<poem>...there follows one corollary which itself deserves to be inscribed upon every wall of the city of philosophy:

Peirce adds, that method and economy are best in research but no outright sin inheres in trying any theory in the sense that the investigation via its trial adoption can proceed unimpeded and undiscouraged, and that "the one unpardonable offence" is a philosophical barricade against truth's advance, an offense to which "metaphysicians in all ages have shown themselves the most addicted". Peirce in many writings holds that logic precedes metaphysics (ontological, religious, and physical).

Peirce goes on to list four common barriers to inquiry: (1) Assertion of absolute certainty; (2) maintaining that something is absolutely unknowable; (3) maintaining that something is absolutely inexplicable because absolutely basic or ultimate; (4) holding that perfect exactitude is possible, especially such as to quite preclude unusual and anomalous phenomena. To refuse absolute theoretical certainty is the heart of "fallibilism", which Peirce unfolds into refusals to set up any of the listed barriers. Peirce elsewhere argues (1897) that logic's presupposition of fallibilism leads at length to the view that chance and continuity are very real (tychism and synechism).

The First Rule of Logic pertains to the mind's presuppositions in undertaking reason and logic; presuppositions, for instance, that truth and the real do not depend on yours or my opinion of them but do depend on representational relation and consist in the destined end in investigation taken far enough (see below). He describes such ideas as, collectively, hopes which, in particular cases, one is unable seriously to doubt.

 In three articles in 1868–1869, Peirce rejected mere verbal or hyperbolic doubt and first or ultimate principles, and argued that we have (as he numbered them):
(The above sense of the term "intuition" is almost Kant's, said Peirce. It differs from the current looser sense that encompasses instinctive or anyway half-conscious inference.)

Peirce argued that those incapacities imply the reality of the general and of the continuous, the validity of the modes of reasoning, and the falsity of philosophical Cartesianism (see below).

Peirce rejected the conception (usually ascribed to Kant) of the unknowable thing-in-itself and later said that to "dismiss make-believes" is a prerequisite for pragmatism.

Peirce sought, through his wide-ranging studies through the decades, formal philosophical ways to articulate thought's processes, and also to explain the workings of science. These inextricably entangled questions of a dynamics of inquiry rooted in nature and nurture led him to develop his semiotic with very broadened conceptions of signs and inference, and, as its culmination, a theory of inquiry for the task of saying 'how science works' and devising research methods. This would be logic by the medieval definition taught for centuries: art of arts, science of sciences, having the way to the principles of all methods. Influences radiate from points on parallel lines of inquiry in Aristotle's work, in such "loci" as: the basic terminology of psychology in "On the Soul"; the founding description of sign relations in "On Interpretation"; and the differentiation of inference into three modes that are commonly translated into English as "abduction", "deduction", and "induction", in the "Prior Analytics", as well as inference by analogy (called "paradeigma" by Aristotle), which Peirce regarded as involving the other three modes.

Peirce began writing on semiotic in the 1860s, around the time when he devised his system of three categories. He called it both "semiotic" and "semeiotic". Both are current in singular and plural. He based it on the conception of a triadic sign relation, and defined "semiosis" as "action, or influence, which is, or involves, a cooperation of "three" subjects, such as a sign, its object, and its interpretant, this tri-relative influence not being in any way resolvable into actions between pairs". As to signs in thought, Peirce emphasized the reverse: "To say, therefore, that thought cannot happen in an instant, but requires a time, is but another way of saying that every thought must be interpreted in another, or that all thought is in signs."

Peirce held that all thought is in signs, issuing in and from interpretation, where "sign" is the word for the broadest variety of conceivable semblances, diagrams, metaphors, symptoms, signals, designations, symbols, texts, even mental concepts and ideas, all as determinations of a mind or "quasi-mind", that which at least functions like a mind, as in the work of crystals or bees—the focus is on sign action in general rather than on psychology, linguistics, or social studies (fields which he also pursued).

Inquiry is a kind of inference process, a manner of thinking and semiosis. Global divisions of ways for phenomena to stand as signs, and the subsumption of inquiry and thinking within inference as a sign process, enable the study of inquiry on semiotics' three levels:


Peirce uses examples often from common experience, but defines and discusses such things as assertion and interpretation in terms of philosophical logic. In a formal vein, Peirce said:

Peirce's theory of signs is known to be one of the most complex semiotic theories due to its generalistic claim. Anything is a sign—not absolutely as itself, but instead in some relation or other. The "sign relation" is the key. It defines three roles encompassing (1) the sign, (2) the sign's subject matter, called its "object", and (3) the sign's meaning or ramification as formed into a kind of effect called its "interpretant" (a further sign, for example a translation). It is an irreducible "triadic relation", according to Peirce. The roles are distinct even when the things that fill those roles are not. The roles are but three; a sign of an object leads to one or more interpretants, and, as signs, they lead to further interpretants.

"Extension × intension = information." Two traditional approaches to sign relation, necessary though insufficient, are the way of "extension" (a sign's objects, also called breadth, denotation, or application) and the way of "intension" (the objects' characteristics, qualities, attributes referenced by the sign, also called depth, comprehension, significance, or connotation). Peirce adds a third, the way of "information", including change of information, to integrate the other two approaches into a unified whole. For example, because of the equation above, if a term's total amount of information stays the same, then the more that the term 'intends' or signifies about objects, the fewer are the objects to which the term 'extends' or applies.

"Determination." A sign depends on its object in such a way as to represent its object—the object enables and, in a sense, determines the sign. A physically causal sense of this stands out when a sign consists in an indicative reaction. The interpretant depends likewise on both the sign and the object—an object determines a sign to determine an interpretant. But this determination is not a succession of dyadic events, like a row of toppling dominoes; sign determination is triadic. For example, an interpretant does not merely represent something which represented an object; instead an interpretant represents something "as" a sign representing the object. The object (be it a quality or fact or law or even fictional) determines the sign to an interpretant through one's collateral experience with the object, in which the object is found or from which it is recalled, as when a sign consists in a chance semblance of an absent object. Peirce used the word "determine" not in a strictly deterministic sense, but in a sense of "specializes", "bestimmt", involving variable amount, like an influence. Peirce came to define representation and interpretation in terms of (triadic) determination. The object determines the sign to determine another sign—the interpretant—to be related to the object "as the sign is related to the object", hence the interpretant, fulfilling its function as sign of the object, determines a further interpretant sign. The process is logically structured to perpetuate itself, and is definitive of sign, object, and interpretant in general.

Peirce held there are exactly three basic elements in semiosis (sign action):

Some of the understanding needed by the mind depends on familiarity with the object. To know what a given sign denotes, the mind needs some experience of that sign's object, experience outside of, and collateral to, that sign or sign system. In that context Peirce speaks of collateral experience, collateral observation, collateral acquaintance, all in much the same terms.

Among Peirce's many sign typologies, three stand out, interlocked. The first typology depends on the sign itself, the second on how the sign stands for its denoted object, and the third on how the sign stands for its object to its interpretant. Also, each of the three typologies is a three-way division, a trichotomy, via Peirce's three phenomenological categories: (1) quality of feeling, (2) reaction, resistance, and (3) representation, mediation.

I. "Qualisign, sinsign, legisign" (also called" tone, token, type," and also called "potisign, actisign, famisign"): This typology classifies every sign according to the sign's own phenomenological category—the qualisign is a quality, a possibility, a "First"; the sinsign is a reaction or resistance, a singular object, an actual event or fact, a "Second"; and the legisign is a habit, a rule, a representational relation, a "Third".

II. "Icon, index, symbol": This typology, the best known one, classifies every sign according to the category of the sign's way of denoting its object—the icon (also called semblance or likeness) by a quality of its own, the index by factual connection to its object, and the symbol by a habit or rule for its interpretant.

III. "Rheme, dicisign, argument" (also called "sumisign, dicisign, suadisign," also "seme, pheme, delome," and regarded as very broadened versions of the traditional "term, proposition, argument"): This typology classifies every sign according to the category which the interpretant attributes to the sign's way of denoting its object—the rheme, for example a term, is a sign interpreted to represent its object in respect of quality; the dicisign, for example a proposition, is a sign interpreted to represent its object in respect of fact; and the argument is a sign interpreted to represent its object in respect of habit or law. This is the culminating typology of the three, where the sign is understood as a structural element of inference.

Every sign belongs to one class or another within (I) "and" within (II) "and" within (III). Thus each of the three typologies is a three-valued parameter for every sign. The three parameters are not independent of each other; many co-classifications are absent, for reasons pertaining to the lack of either habit-taking or singular reaction in a quality, and the lack of habit-taking in a singular reaction. The result is not 27 but instead ten classes of signs fully specified at this level of analysis.

Borrowing a brace of concepts from Aristotle, Peirce examined three basic modes of inference—"abduction", "deduction", and "induction"—in his "critique of arguments" or "logic proper". Peirce also called abduction "retroduction", "presumption", and, earliest of all, "hypothesis". He characterized it as guessing and as inference to an explanatory hypothesis. He sometimes expounded the modes of inference by transformations of the categorical syllogism Barbara (AAA), for example in "Deduction, Induction, and Hypothesis" (1878). He does this by rearranging the "rule" (Barbara's major premise), the "case" (Barbara's minor premise), and the "result" (Barbara's conclusion):

Deduction.

"Rule:" All the beans from this bag are white. <br>
"Case:" These beans are beans from this bag. <br>
formula_1 "Result:" These beans are white.

Induction.

"Case:" These beans are [randomly selected] from this bag.<br>
"Result:" These beans are white.<br>
formula_1 "Rule:" All the beans from this bag are white.

Hypothesis (Abduction).

"Rule:" All the beans from this bag are white.<br>
"Result:" These beans [oddly] are white.<br>
formula_1 "Case:" These beans are from this bag.
Peirce 1883 in "A Theory of Probable Inference" ("Studies in Logic") equated hypothetical inference with the induction of characters of objects (as he had done in effect before). Eventually dissatisfied, by 1900 he distinguished them once and for all and also wrote that he now took the syllogistic forms and the doctrine of logical extension and comprehension as being less basic than he had thought. In 1903 he presented the following logical form for abductive inference:

The logical form does not also cover induction, since induction neither depends on surprise nor proposes a new idea for its conclusion. Induction seeks facts to test a hypothesis; abduction seeks a hypothesis to account for facts. "Deduction proves that something "must" be; Induction shows that something "actually is" operative; Abduction merely suggests that something "may be"." Peirce did not remain quite convinced that one logical form covers all abduction. In his methodeutic or theory of inquiry (see below), he portrayed abduction as an economic initiative to further inference and study, and portrayed all three modes as clarified by their coordination in essential roles in inquiry: hypothetical explanation, deductive prediction, inductive testing

Peirce did not write extensively in aesthetics and ethics, but came by 1902 to hold that aesthetics, ethics, and logic, in that order, comprise the normative sciences. He characterized aesthetics as the study of the good (grasped as the admirable), and thus of the ends governing all conduct and thought.

Peirce divided metaphysics into (1) ontology or general metaphysics, (2) psychical or religious metaphysics, and (3) physical metaphysics.

On the issue of universals, Peirce was a scholastic realist, declaring the reality of generals as early as 1868. According to Peirce, his category he called "thirdness", the more general facts about the world, are extra-mental realities. Regarding modalities (possibility, necessity, etc.), he came in later years to regard himself as having wavered earlier as to just how positively real the modalities are. In his 1897 "The Logic of Relatives" he wrote:

Peirce retained, as useful for some purposes, the definitions in terms of information states, but insisted that the pragmaticist is committed to a strong modal realism by conceiving of objects in terms of predictive general conditional propositions about how they "would" behave under certain circumstances.

Continuity and synechism are central in Peirce's philosophy: "I did not at first suppose that it was, as I gradually came to find it, the master-Key of philosophy".

From a mathematical point of view, he embraced infinitesimals and worked long on the mathematics of continua. He long held that the real numbers constitute a pseudo-continuum; that a true continuum is the real subject matter of "analysis situs" (topology); and that a true continuum of instants exceeds—and within any lapse of time has room for—any Aleph number (any infinite "multitude" as he called it) of instants.

In 1908 Peirce wrote that he found that a true continuum might have or lack such room. Jérôme Havenel (2008): "It is on 26 May 1908, that Peirce finally gave up his idea that in every continuum there is room for whatever collection of any multitude. From now on, there are different kinds of continua, which have different properties."

Peirce believed in God, and characterized such belief as founded in an instinct explorable in musing over the worlds of ideas, brute facts, and evolving habits—and it is a belief in God not as an "actual" or "existent" being (in Peirce's sense of those words), but all the same as a "real" being. In "" (1908), Peirce sketches, for God's reality, an argument to a hypothesis of God as the Necessary Being, a hypothesis which he describes in terms of how it would tend to develop and become compelling in musement and inquiry by a normal person who is led, by the hypothesis, to consider as being purposed the features of the worlds of ideas, brute facts, and evolving habits (for example scientific progress), such that the thought of such purposefulness will "stand or fall with the hypothesis"; meanwhile, according to Peirce, the hypothesis, in supposing an "infinitely incomprehensible" being, starts off at odds with its own nature as a purportively true conception, and so, no matter how much the hypothesis grows, it both (A) inevitably regards itself as partly true, partly vague, and as continuing to define itself without limit, and (B) inevitably has God appearing likewise vague but growing, though God as the Necessary Being is not vague or growing; but the hypothesis will hold it to be "more" false to say the opposite, that God is purposeless. Peirce also argued that the will is free and (see Synechism) that there is at least an attenuated kind of immortality.

Peirce held the view, which he called objective idealism, that "matter is effete mind, inveterate habits becoming physical laws". Peirce observed that "Berkeley's metaphysical theories have at first sight an air of paradox and levity very unbecoming to a bishop". 

Peirce asserted the reality of (1) absolute chance (his tychist view), (2) mechanical necessity (anancist view), and (3) that which he called the law of love (agapist view), echoing his categories Firstness, Secondness, and Thirdness, respectively. He held that fortuitous variation (which he also called "sporting"), mechanical necessity, and creative love are the three modes of evolution (modes called "tychasm", "anancasm", and "agapasm") of the cosmos and its parts. He found his conception of agapasm embodied in Lamarckian evolution; the overall idea in any case is that of evolution tending toward an end or goal, and it could also be the evolution of a mind or a society; it is the kind of evolution which manifests workings of mind in some general sense. He said that overall he was a synechist, holding with reality of continuity, especially of space, time, and law.

Peirce outlined two fields, "Cenoscopy" and "Science of Review", both of which he called philosophy. Both included philosophy about science. In 1903 he arranged them, from more to less theoretically basic, thus: 


Peirce placed, within Science of Review, the work and theory of classifying the sciences (including mathematics and philosophy). His classifications, on which he worked for many years, draw on argument and wide knowledge, and are of interest both as a map for navigating his philosophy and as an accomplished polymath's survey of research in his time.

Umberto Eco described Peirce as "undoubtedly the greatest unpublished writer of our generation" and by Karl Popper as "one of the greatest philosophers of all time". The Internet Encyclopedia of Philosophy says of Peirce that although "long considered an eccentric figure whose contribution to pragmatism was to provide its name and whose importance was as an influence upon James and Dewey, Peirce’s significance in his own right is now largely accepted."


Carnot heat engine

A Carnot heat engine is a theoretical heat engine that operates on the Carnot cycle. The basic model for this engine was developed by Nicolas Léonard Sadi Carnot in 1824. The Carnot engine model was graphically expanded by Benoît Paul Émile Clapeyron in 1834 and mathematically explored by Rudolf Clausius in 1857, work that led to the fundamental thermodynamic concept of entropy. The Carnot engine is the most efficient heat engine which is theoretically possible. The efficiency depends only upon the absolute temperatures of the hot and cold heat reservoirs between which it operates.

A heat engine acts by transferring energy from a warm region to a cool region of space and, in the process, converting some of that energy to mechanical work. The cycle may also be reversed. The system may be worked upon by an external force, and in the process, it can transfer thermal energy from a cooler system to a warmer one, thereby acting as a refrigerator or heat pump rather than a heat engine.

Every thermodynamic system exists in a particular state. A thermodynamic cycle occurs when a system is taken through a series of different states, and finally returned to its initial state. In the process of going through this cycle, the system may perform work on its surroundings, thereby acting as a heat engine.

The Carnot engine is a theoretical construct, useful for exploring the efficiency limits of other heat engines. An actual Carnot engine, however, would be completely impractical to build.

In the adjacent diagram, from Carnot's 1824 work, "Reflections on the Motive Power of Fire", there are "two bodies "A" and "B", kept each at a constant temperature, that of "A" being higher than that of "B". These two bodies to which we can give, or from which we can remove the heat without causing their temperatures to vary, exercise the functions of two unlimited reservoirs of caloric. We will call the first the furnace and the second the refrigerator." Carnot then explains how we can obtain motive power, i.e., "work", by carrying a certain quantity of heat from body "A" to body "B".
It also acts as a cooler and hence can also act as a refrigerator.

The previous image shows the original piston-and-cylinder diagram used by Carnot in discussing his ideal engine. The figure at right shows a block diagram of a generic heat engine, such as the Carnot engine. In the diagram, the "working body" (system), a term introduced by Clausius in 1850, can be any fluid or vapor body through which heat "Q" can be introduced or transmitted to produce work. Carnot had postulated that the fluid body could be any substance capable of expansion, such as vapor of water, vapor of alcohol, vapor of mercury, a permanent gas, air, etc. Although in those early years, engines came in a number of configurations, typically "Q" was supplied by a boiler, wherein water was boiled over a furnace; "Q" was typically removed by a stream of cold flowing water in the form of a condenser located on a separate part of the engine. The output work, "W", is transmitted by the movement of the piston as it is used to turn a crank-arm, which in turn was typically used to power a pulley so as to lift water out of flooded salt mines. Carnot defined work as "weight lifted through a height".

The Carnot cycle when acting as a heat engine consists of the following steps:


Carnot's theorem is a formal statement of this fact: "No engine operating between two heat reservoirs can be more efficient than a Carnot engine operating between the same reservoirs."

formula_1

This maximum efficiency is defined as above:

A corollary to Carnot's theorem states that: All reversible engines operating between the same heat reservoirs are equally efficient.

It is easily shown that the efficiency is maximum when the entire cyclic process is a reversible process. This means the total entropy of system and surroundings (the entropies of the hot furnace, the "working fluid" of the heat engine, and the cold sink) remains constant when the "working fluid" completes one cycle and returns to its original state. (In the general and more realistic case of an irreversible process, the total entropy of this combined system would increase.)

Since the "working fluid" comes back to the same state after one cycle, and entropy of the system is a state function, the change in entropy of the "working fluid" system is 0. Thus, it implies that the total entropy change of the furnace and sink is zero, for the process to be reversible and the efficiency of the engine to be maximum. This derivation is carried out in the next section.

The coefficient of performance (COP) of the heat engine is the reciprocal of its efficiency.

For a real heat engine, the total thermodynamic process is generally irreversible. The working fluid is brought back to its initial state after one cycle, and thus the change of entropy of the fluid system is 0, but the sum of the entropy changes in the hot and cold reservoir in this one cyclical process is greater than 0.

The internal energy of the fluid is also a state variable, so its total change in one cycle is 0. So the total work done by the system is equal to the net heat put into the system, the sum of formula_2 > 0 taken up and the waste heat formula_3 < 0 given off:

For real engines, stages 1 and 3 of the Carnot cycle, in which heat is absorbed by the "working fluid" from the hot reservoir, and released by it to the cold reservoir, respectively, no longer remain ideally reversible, and there is a temperature differential between the temperature of the reservoir and the temperature of the fluid while heat exchange takes place.

During heat transfer from the hot reservoir at formula_4 to the fluid, the fluid would have a slightly lower temperature than formula_4, and the process for the fluid may not necessarily remain isothermal. 
Let formula_6 be the total entropy change of the fluid in the process of intake of heat.

where the temperature of the fluid is always slightly lesser than formula_4, in this process.

So, one would get:

Similarly, at the time of heat injection from the fluid to the cold reservoir one would have, for the magnitude of total entropy change formula_8< 0 of the fluid in the process of expelling heat:

where, during this process of transfer of heat to the cold reservoir, the temperature of the fluid is always slightly greater than formula_9.

We have only considered the magnitude of the entropy change here. Since the total change of entropy of the fluid system for the cyclic process is 0, we must have

The previous three equations, namely (3), (4), (5), substituted into (6) to give:

For [ΔSh ≥ (Qh/Th)] +[ΔSc ≥ (Qc/Tc)] = 0

[ΔSh ≥ (Qh/Th)] = - [ΔSc ≥ (Qc/Tc)]

<nowiki>=</nowiki> [-ΔSc "≤" (-Qc/Tc)]

it is at least (Qh/Th) "≤" (-Qc/Tc)

Equations () and () combine to give

To derive this step needs two adiabatic processes involved to show an isentropic process property for the ratio of the changing volumes of two isothermal processes are equal. 

Most importantly, since the two adiabatic processes are volume works without heat lost, and since the ratio of volume changes for this two processes are the same, so the works for these two adiabatic processes are the same with opposite direction to each other, namely, one direction is work done by the system and the other is work done on the system; therefore, heat efficiency only concerns the amount of work done by the heat absorbed comparing to the amount of heat absorbed by the system.

Therefore, (W/Qh) = (Qh - Qc) / Qh

<nowiki>=</nowiki> 1 - (Qc/Qh)

<nowiki>=</nowiki> 1 - (Tc/Th)

And, from (7)

(Qh/Th) "≤" (-Qc/Tc) here Qc it is less than 0 (release heat) 

-(Tc/Th) ≥ (Qc/Qh)

"1+"[-(Tc/Th)] ≥ "1+"(Qc/Qh) 

1 - (Tc/Th) ≥ (Qh + Qc)/Qh here Qc<0, 

1 - (Tc/Th) ≥ (Qh - Qc)/Qh

1 - (Tc/Th) ≥ W/Qh

Hence,

where formula_10 is the efficiency of the real engine, and formula_11 is the efficiency of the Carnot engine working between the same two reservoirs at the temperatures formula_4 and formula_9. For the Carnot engine, the entire process is 'reversible', and Equation () is an equality. Hence, the efficiency of the real engine is always less than the ideal Carnot engine.

Equation () signifies that the total entropy of system and surroundings (the fluid and the two reservoirs) increases for the real engine, because (in a surroundings-based analysis) the entropy gain of the cold reservoir as formula_14 flows into it at the fixed temperature formula_9, is greater than the entropy loss of the hot reservoir as formula_16 leaves it at its fixed temperature formula_4. The inequality in Equation () is essentially the statement of the Clausius theorem.

According to the second theorem, "The efficiency of the Carnot engine is independent of the nature of the working substance".

In 1892 Rudolf Diesel patented an internal combustion engine inspired by the Carnot engine. Diesel knew a Carnot engine is an ideal that cannot be built, but he thought he had invented a working approximation. His principle was unsound, but in his struggle to implement it he developed the practical engine that bears his name.

The conceptual problem was how to achieve isothermal expansion in an internal combustion engine, since burning fuel at the highest temperature of the cycle would only raise the temperature further. Diesel's patented solution was: having achieved the highest temperature just by compressing the air, to add a small amount of fuel at a controlled rate, such that heating caused by burning the fuel would be counteracted by cooling caused by air expansion as the piston moved. Hence all the heat from the fuel would be transformed into work during the isothermal expansion, as required by Carnot's theorem.

For the idea to work a small mass of fuel would have to be burnt in a huge mass of air. Diesel first proposed a working engine that would compress air to 250 atmospheres at , then cycle to one atmosphere at . However, this was well beyond the technological capabilities of the day, since it implied a compression ratio of 60:1. Such an engine, if it could have been built, would have had an efficiency of 73%. (In contrast, the best steam engines of his day achieved 7%.)

Accordingly, Diesel sought to compromise. He calculated that, were he to reduce the peak pressure to a less ambitious 90 atmospheres, he would sacrifice only 5% of the thermal efficiency. Seeking financial support, he published the "Theory and Construction of a Rational Heat Engine to Take the Place of the Steam Engine and All Presently Known Combustion Engines" (1893). Endorsed by scientific opinion, including Lord Kelvin, he won the backing of Krupp and . He clung to the Carnot cycle as a symbol. But years of practical work failed to achieve an isothermal combustion engine, nor could have done, since it requires such an enormous quantity of air that it cannot develop enough power to compress it. Furthermore, controlled fuel injection turned out to be no easy matter.

Even so, it slowly evolved over 25 years to become a practical high-compression air engine, its fuel injected near the end of the compression stroke and ignited by the heat of compression, the diesel engine. Today its efficiency is 40%.


Context-sensitive

Context-sensitive is an adjective meaning "depending on context" or "depending on circumstances". It may refer to:


Central America

Central America is a subregion of the Americas. Its political boundaries are defined as bordering Mexico to the north, Colombia to the south, the Caribbean Sea to the east, and the Pacific Ocean to the west. Central America is usually defined as consisting of seven countries: Belize, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and Panama. Within Central America is the Mesoamerican biodiversity hotspot, which extends from northern Guatemala to central Panama. Due to the presence of several active geologic faults and the Central America Volcanic Arc, there is a high amount of seismic activity in the region, such as volcanic eruptions and earthquakes, which has resulted in death, injury, and property damage.

In the pre-Columbian era, Central America was inhabited by the Indigenous peoples of Mesoamerica to the north and west and the Isthmo-Colombian peoples to the south and east. Following the Spanish expedition of Christopher Columbus' voyages to the Americas, Spain began to colonize the Americas. From 1609 to 1821, the majority of Central American territories (except for what would become Belize and Panama, and including the modern Mexican state of Chiapas) were governed by the viceroyalty of New Spain from Mexico City as the Captaincy General of Guatemala. On 24 August 1821, Spanish Viceroy Juan de O'Donojú signed the Treaty of Córdoba, which established New Spain's independence from Spain. On 15 September 1821, the Act of Independence of Central America was enacted to announce Central America's separation from the Spanish Empire and provide for the establishment of a new Central American state. Some of New Spain's provinces in the Central American region (i.e. what would become Guatemala, Honduras, El Salvador, Nicaragua and Costa Rica) were annexed to the First Mexican Empire; however in 1823 they seceded from Mexico to form the Federal Republic of Central America until 1838.

In 1838, Costa Rica, Guatemala, Honduras, and Nicaragua became the first of Central America's seven states to become independent countries, followed by El Salvador in 1841, Panama in 1903, and Belize in 1981. Despite the dissolution of the Federal Republic of Central America, countries like Costa Rica, El Salvador, Guatemala, Honduras, and Nicaragua continue to maintain a Central American identity. The Belizeans are usually identified as culturally Caribbean rather than Central American, while the Panamanians identify themselves more broadly with their South American neighbors.

The Spanish-speaking countries officially include both North America and South America as a single continent, , which is split into four subregions: North America (Northern America and Mexico), Central America, South America, and Insular America (the West Indies).

"Central America" may mean different things to various people, based upon different contexts:


Central America was formed more than 3 million years ago, as part of the Isthmus of Panama, when its portion of land connected each side of water.

In the Pre-Columbian era, the northern areas of Central America were inhabited by the indigenous peoples of Mesoamerica. Most notable among these were the Mayans, who had built numerous cities throughout the region, and the Aztecs, who had created a vast empire. The pre-Columbian cultures of eastern El Salvador, eastern Honduras, Caribbean Nicaragua, most of Costa Rica and Panama were predominantly speakers of the Chibchan languages at the time of European contact and are considered by some culturally different and grouped in the Isthmo-Colombian Area.

Following the Spanish expedition of Christopher Columbus's voyages to the Americas, the Spanish sent many expeditions to the region, and they began their conquest of Maya territory in 1523. Soon after the conquest of the Aztec Empire, Spanish conquistador Pedro de Alvarado commenced the conquest of northern Central America for the Spanish Empire. Beginning with his arrival in Soconusco in 1523, Alvarado's forces systematically conquered and subjugated most of the major Maya kingdoms, including the K'iche', Tz'utujil, Pipil, and the Kaqchikel. By 1528, the conquest of Guatemala was nearly complete, with only the Petén Basin remaining outside the Spanish sphere of influence. The last independent Maya kingdoms – the Kowoj and the Itza people – were finally defeated in 1697, as part of the Spanish conquest of Petén.

In 1538, Spain established the Real Audiencia of Panama, which had jurisdiction over all land from the Strait of Magellan to the Gulf of Fonseca. This entity was dissolved in 1543, and most of the territory within Central America then fell under the jurisdiction of the "Audiencia Real de Guatemala". This area included the current territories of Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and the Mexican state of Chiapas, but excluded the lands that would become Belize and Panama. The president of the Audiencia, which had its seat in Antigua Guatemala, was the governor of the entire area. In 1609 the area became a captaincy general and the governor was also granted the title of captain general. The Captaincy General of Guatemala encompassed most of Central America, with the exception of present-day Belize and Panama.

The Captaincy General of Guatemala lasted for more than two centuries, but began to fray after a rebellion in 1811 which began in the Intendancy of San Salvador. The Captaincy General formally ended on 15 September 1821, with the signing of the Act of Independence of Central America. Mexican independence was achieved at virtually the same time with the signing of the Treaty of Córdoba and the Declaration of Independence of the Mexican Empire, and the entire region was finally independent from Spanish authority by 28 September 1821.

From its independence from Spain in 1821 until 1823, the former Captaincy General remained intact as part of the short-lived First Mexican Empire. When the Emperor of Mexico abdicated on 19 March 1823, Central America again became independent. On 1 July 1823, the Congress of Central America peacefully seceded from Mexico and declared absolute independence from all foreign nations, and the region formed the Federal Republic of Central America.

The Federal Republic of Central America was a representative democracy with its capital at Guatemala City. This union consisted of the provinces of Costa Rica, El Salvador, Guatemala, Honduras, Los Altos, Mosquito Coast, and Nicaragua. The lowlands of southwest Chiapas, including Soconusco, initially belonged to the Republic until 1824, when Mexico annexed most of Chiapas and began its claims to Soconusco. The Republic lasted from 1823 to 1838, when it disintegrated as a result of civil wars.

The territory that now makes up Belize was heavily contested in a dispute that continued for decades after Guatemala achieved independence. Spain, and later Guatemala, considered this land a Guatemalan department. In 1862, Britain formally declared it a British colony and named it British Honduras. It became independent as Belize in 1981.

Panama, situated in the southernmost part of Central America on the Isthmus of Panama, has for most of its history been culturally and politically linked to South America. Panama was part of the Province of Tierra Firme from 1510 until 1538 when it came under the jurisdiction of the newly formed "Audiencia Real de Panama". Beginning in 1543, Panama was administered as part of the Viceroyalty of Peru, along with all other Spanish possessions in South America. Panama remained as part of the Viceroyalty of Peru until 1739, when it was transferred to the Viceroyalty of New Granada, the capital of which was located at Santa Fé de Bogotá. Panama remained as part of the Viceroyalty of New Granada until the disestablishment of that viceroyalty in 1819. A series of military and political struggles took place from that time until 1822, the result of which produced the republic of Gran Colombia. After the dissolution of Gran Colombia in 1830, Panama became part of a successor state, the Republic of New Granada. From 1855 until 1886, Panama existed as Panama State, first within the Republic of New Granada, then within the Granadine Confederation, and finally within the United States of Colombia. The United States of Colombia was replaced by the Republic of Colombia in 1886. As part of the Republic of Colombia, Panama State was abolished and it became the Isthmus Department. Despite the many political reorganizations, Colombia was still deeply plagued by conflict, which eventually led to the secession of Panama on 3 November 1903. Only after that time did some begin to regard Panama as a North or Central American entity.

By the 1930s the United Fruit Company owned of land in Central America and the Caribbean and was the single largest land owner in Guatemala. Such holdings gave it great power over the governments of small countries. That was one of the factors that led to the coining of the phrase banana republic.

After more than two hundred years of social unrest, violent conflict, and revolution, Central America today remains in a period of political transformation. Poverty, social injustice, and violence are still widespread. Nicaragua is the second poorest country in the western hemisphere (only Haiti is poorer).

Central America is a part of North America consisting of a tapering isthmus running from the southern extent of Mexico to the northwestern portion of South America. Central America has the Gulf of Mexico, a body of water within the Atlantic Ocean, to the north; the Caribbean Sea, also part of the Atlantic Ocean, to the northeast; and the Pacific Ocean to the southwest. Some physiographists define the Isthmus of Tehuantepec as the northern geographic border of Central America, while others use the northwestern borders of Belize and Guatemala. From there, the Central American land mass extends southeastward to the Atrato River, where it connects to the Pacific Lowlands in northwestern South America.

Of the many mountain ranges within Central America, the longest are the Sierra Madre de Chiapas, the Cordillera Isabelia and the Cordillera de Talamanca. At , Volcán Tajumulco is the highest peak in Central America. Other high points of Central America are as listed in the table below:

Between the mountain ranges lie fertile valleys that are suitable for the raising of livestock and for the production of coffee, tobacco, beans and other crops. Most of the population of Honduras, Costa Rica and Guatemala lives in valleys.

Trade winds have a significant effect upon the climate of Central America. Temperatures in Central America are highest just prior to the summer wet season, and are lowest during the winter dry season, when trade winds contribute to a cooler climate. The highest temperatures occur in April, due to higher levels of sunlight, lower cloud cover and a decrease in trade winds.

Central America is part of the Mesoamerican biodiversity hotspot, boasting 7% of the world's biodiversity. The Pacific Flyway is a major north–south flyway for migratory birds in the Americas, extending from Alaska to Tierra del Fuego. Due to the funnel-like shape of its land mass, migratory birds can be seen in very high concentrations in Central America, especially in the spring and autumn. As a bridge between North America and South America, Central America has many species from the Nearctic and the Neotropical realms. However the southern countries (Costa Rica and Panama) of the region have more biodiversity than the northern countries (Guatemala and Belize), meanwhile the central countries (Honduras, Nicaragua and El Salvador) have the least biodiversity. The table below shows recent statistics:

Over 300 species of the region's flora and fauna are threatened, 107 of which are classified as critically endangered. The underlying problems are deforestation, which is estimated by FAO at 1.2% per year in Central America and Mexico combined, fragmentation of rainforests and the fact that 80% of the vegetation in Central America has already been converted to agriculture.

Efforts to protect fauna and flora in the region are made by creating ecoregions and nature reserves. 36% of Belize's land territory falls under some form of official protected status, giving Belize one of the most extensive systems of terrestrial protected areas in the Americas. In addition, 13% of Belize's marine territory are also protected. A large coral reef extends from Mexico to Honduras: the Mesoamerican Barrier Reef System. The Belize Barrier Reef is part of this. The Belize Barrier Reef is home to a large diversity of plants and animals, and is one of the most diverse ecosystems of the world. It is home to 70 hard coral species, 36 soft coral species, 500 species of fish and hundreds of invertebrate species.
So far only about 10% of the species in the Belize barrier reef have been discovered.

From 2001 to 2010, of forest were lost in the region. In 2010 Belize had 63% of remaining forest cover, Costa Rica 46%, Panama 45%, Honduras 41%, Guatemala 37%, Nicaragua 29%, and El Salvador 21%. Most of the loss occurred in the moist forest biome, with . Woody vegetation loss was partially set off by a gain in the coniferous forest biome with , and a gain in the dry forest biome at . Mangroves and deserts contributed only 1% to the loss in forest vegetation. The bulk of the deforestation was located at the Caribbean slopes of Nicaragua with a loss of of forest in the period from 2001 to 2010. The most significant regrowth of of forest was seen in the coniferous woody vegetation of Honduras.

The Central American pine-oak forests ecoregion, in the tropical and subtropical coniferous forests biome, is found in Central America and southern Mexico. The Central American pine-oak forests occupy an area of , extending along the mountainous spine of Central America, extending from the Sierra Madre de Chiapas in Mexico's Chiapas state through the highlands of Guatemala, El Salvador, and Honduras to central Nicaragua. The pine-oak forests lie between elevation, and are surrounded at lower elevations by tropical moist forests and tropical dry forests. Higher elevations above are usually covered with Central American montane forests. The Central American pine-oak forests are composed of many species characteristic of temperate North America including oak, pine, fir, and cypress.

Laurel forest is the most common type of Central American temperate evergreen cloud forest, found in almost all Central American countries, normally more than above sea level. Tree species include evergreen oaks, members of the laurel family, species of "Weinmannia" and "Magnolia", and "Drimys granadensis". The cloud forest of Sierra de las Minas, Guatemala, is the largest in Central America. In some areas of southeastern Honduras there are cloud forests, the largest located near the border with Nicaragua. In Nicaragua, cloud forests are situated near the border with Honduras, but many were cleared to grow coffee. There are still some temperate evergreen hills in the north. The only cloud forest in the Pacific coastal zone of Central America is on the Mombacho volcano in Nicaragua. In Costa Rica, there are laurel forests in the Cordillera de Tilarán and Volcán Arenal, called Monteverde, also in the Cordillera de Talamanca.

The Central American montane forests are an ecoregion of the tropical and subtropical moist broadleaf forests biome, as defined by the World Wildlife Fund. These forests are of the moist deciduous and the semi-evergreen seasonal subtype of tropical and subtropical moist broadleaf forests and receive high overall rainfall with a warm summer wet season and a cooler winter dry season. Central American montane forests consist of forest patches located at altitudes ranging from , on the summits and slopes of the highest mountains in Central America ranging from Southern Mexico, through Guatemala, El Salvador, and Honduras, to northern Nicaragua. The entire ecoregion covers an area of and has a temperate climate with relatively high precipitation levels.

Ecoregions are not only established to protect the forests themselves but also because they are habitats for an incomparably rich and often endemic fauna. Almost half of the bird population of the Talamancan montane forests in Costa Rica and Panama are endemic to this region. Several birds are listed as threatened, most notably the resplendent quetzal (Pharomacrus mocinno), three-wattled bellbird (Procnias tricarunculata), bare-necked umbrellabird (Cephalopterus glabricollis), and black guan (Chamaepetes unicolor). Many of the amphibians are endemic and depend on the existence of forest. The golden toad that once inhabited a small region in the Monteverde Reserve, which is part of the Talamancan montane forests, has not been seen alive since 1989 and is listed as extinct by IUCN. The exact causes for its extinction are unknown. Global warming may have played a role, because the development of that frog is typical for this area may have been compromised. Seven small mammals are endemic to the Costa Rica-Chiriqui highlands within the Talamancan montane forest region. Jaguars, cougars, spider monkeys, as well as tapirs, and anteaters live in the woods of Central America. The Central American red brocket is a brocket deer found in Central America's tropical forest.

Central America is geologically very active, with volcanic eruptions and earthquakes occurring frequently, and tsunamis occurring occasionally. Many thousands of people have died as a result of these natural disasters.

Most of Central America rests atop the Caribbean Plate. This tectonic plate converges with the Cocos, Nazca, and North American plates to form the Middle America Trench, a major subduction zone. The Middle America Trench is situated some off the Pacific coast of Central America and runs roughly parallel to it. Many large earthquakes have occurred as a result of seismic activity at the Middle America Trench. For example, subduction of the Cocos Plate beneath the North American Plate at the Middle America Trench is believed to have caused the 1985 Mexico City earthquake that killed as many as 40,000 people. Seismic activity at the Middle America Trench is also responsible for earthquakes in 1902, 1942, 1956, 1982, 1992, January 2001, February 2001, 2007, 2012, 2014, and many other earthquakes throughout Central America.

The Middle America Trench is not the only source of seismic activity in Central America. The Motagua Fault is an onshore continuation of the Cayman Trough which forms part of the tectonic boundary between the North American Plate and the Caribbean Plate. This transform fault cuts right across Guatemala and then continues offshore until it merges with the Middle America Trench along the Pacific coast of Mexico, near Acapulco. Seismic activity at the Motagua Fault has been responsible for earthquakes in 1717, 1773, 1902, 1976, 1980, and 2009.

Another onshore continuation of the Cayman Trough is the Chixoy-Polochic Fault, which runs parallel to, and roughly to the north, of the Motagua Fault. Though less active than the Motagua Fault, seismic activity at the Chixoy-Polochic Fault is still thought to be capable of producing very large earthquakes, such as the 1816 earthquake of Guatemala.

Managua, the capital of Nicaragua, was devastated by earthquakes in 1931 and 1972.

Volcanic eruptions are also common in Central America. In 1968 the Arenal Volcano, in Costa Rica, erupted killing 87 people as the 3 villages of Tabacon, Pueblo Nuevo and San Luis were buried under pyroclastic flows and debris. Fertile soils from weathered volcanic lava have made it possible to sustain dense populations in the agriculturally productive highland areas.

List of countries by life expectancy at birth for 2021, according to the World Bank Group. List of Central American countries is expanded by Mexico and Colombia.

The population of Central America is estimated at as of . With an area of , it has a population density of . Human Development Index values are from the estimates for 2017.

The official language majority in all Central American countries is Spanish, except in Belize, where the official language is English. Mayan languages constitute a language family consisting of about 26 related languages. Guatemala formally recognized 21 of these in 1996. Xinca, Miskito, and Garifuna are also present in Central America.

This region of the continent is very rich in terms of ethnic groups. The majority of the population is mestizo, with sizable Mayan and African descendent populations present, along with numerous other indigenous groups such as the Miskito people. The immigration of Arabs, Jews, Chinese, Europeans and others brought additional groups to the area.

The predominant religion in Central America is Christianity (95.6%). Beginning with the Spanish colonization of Central America in the 16th century, Roman Catholicism became the most popular religion in the region until the first half of the 20th century. Since the 1960s, there has been an increase in other Christian groups, particularly Protestantism, as well as other religious organizations, and individuals identifying themselves as having no religion.
Source: Jason Mandrik, Operation World Statistics (2020).




Central America is currently undergoing a process of political, economic and cultural transformation that started in 1907 with the creation of the Central American Court of Justice.

In 1951 the integration process continued with the signature of the San Salvador Treaty, which created the ODECA, the Organization of Central American States. However, the unity of the ODECA was limited by conflicts between several member states.

In 1991, the integration agenda was further advanced by the creation of the Central American Integration System ("Sistema para la Integración Centroamericana", or SICA). SICA provides a clear legal basis to avoid disputes between the member states. SICA membership includes the 7 nations of Central America plus the Dominican Republic, a state that is traditionally considered part of the Caribbean.

On 6 December 2008, SICA announced an agreement to pursue a common currency and common passport for the member nations. No timeline for implementation was discussed.

Central America already has several supranational institutions such as the Central American Parliament, the Central American Bank for Economic Integration and the Central American Common Market.

On 22 July 2011, President Mauricio Funes of El Salvador became the first president "pro tempore" to SICA. El Salvador also became the headquarters of SICA with the inauguration of a new building.

Until recently, all Central American countries maintained diplomatic relations with Taiwan instead of China. President Óscar Arias of Costa Rica, however, established diplomatic relations with China in 2007, severing formal diplomatic ties with Taiwan. After breaking off relations with the Republic of China in 2017, Panama established diplomatic relations with the People's Republic of China. In August 2018, El Salvador also severed ties with Taiwan to formally start recognizing the People's Republic of China as sole China, a move many considered lacked transparency due to its abruptness and reports of the Chinese government's desires to invest in the department of La Union while also promising to fund the ruling party's reelection campaign. The President of El Salvador, Nayib Bukele, broke diplomatic relations with Taiwan and established ties with China. On 9 December 2021, Nicaragua resumed relations with the PRC.

The Central American Parliament (aka PARLACEN) is a political and parliamentary body of SICA. The parliament started around 1980, and its primary goal was to resolve conflicts in Nicaragua, Guatemala, and El Salvador. Although the group was disbanded in 1986, ideas of unity of Central Americans still remained, so a treaty was signed in 1987 to create the Central American Parliament and other political bodies. Its original members were Guatemala, El Salvador, Nicaragua and Honduras. The parliament is the political organ of Central America, and is part of SICA. New members have since then joined including Panama and the Dominican Republic.

Costa Rica is not a member State of the Central American Parliament and its adhesion remains as a very unpopular topic at all levels of the Costa Rican society due to existing strong political criticism towards the regional parliament, since it is regarded by Costa Ricans as a menace to democratic accountability and effectiveness of integration efforts. Excessively high salaries for its members, legal immunity of jurisdiction from any member State, corruption, lack of a binding nature and effectiveness of the regional parliament's decisions, high operative costs and immediate membership of Central American Presidents once they leave their office and presidential terms, are the most common reasons invoked by Costa Ricans against the Central American Parliament.

Signed in 2004, the Central American Free Trade Agreement (CAFTA) is an agreement between the United States, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and the Dominican Republic. The treaty is aimed at promoting free trade among its members.

Guatemala has the largest economy in the region. Its main exports are coffee, sugar, bananas, petroleum, clothing, and cardamom. Of its 10.29 billion dollar annual exports, 40.2% go to the United States, 11.1% to neighboring El Salvador, 8% to Honduras, 5.5% to Mexico, 4.7% to Nicaragua, and 4.3% to Costa Rica.

The region is particularly attractive for companies (especially clothing companies) because of its geographical proximity to the United States, very low wages and considerable tax advantages. In addition, the decline in the prices of coffee and other export products and the structural adjustment measures promoted by the international financial institutions have partly ruined agriculture, favouring the emergence of maquiladoras. This sector accounts for 42 per cent of total exports from El Salvador, 55 per cent from Guatemala, and 65 per cent from Honduras. However, its contribution to the economies of these countries is disputed; raw materials are imported, jobs are precarious and low-paid, and tax exemptions weaken public finances.

They are also criticised for the working conditions of employees: insults and physical violence, abusive dismissals (especially of pregnant workers), working hours, non-payment of overtime. According to Lucrecia Bautista, coordinator of the "maquilas" sector of the audit firm Coverco, "labour law regulations are regularly violated in maquilas and there is no political will to enforce their application. In the case of infringements, the labour inspectorate shows remarkable leniency. It is a question of not discouraging investors." Trade unionists are subject to pressure, and sometimes to kidnapping or murder. In some cases, business leaders have used the services of the maras. Finally, black lists containing the names of trade unionists or political activists are circulating in employers' circles.

Economic growth in Central America is projected to slow slightly in 2014–15, as country-specific domestic factors offset the positive effects from stronger economic activity in the United States.

Tourism in Belize has grown considerably in more recent times, and it is now the second largest industry in the nation. Belizean Prime Minister Dean Barrow has stated his intention to use tourism to combat poverty throughout the country. The growth in tourism has positively affected the agricultural, commercial, and finance industries, as well as the construction industry. The results for Belize's tourism-driven economy have been significant, with the nation welcoming almost one million tourists in a calendar year for the first time in its history in 2012. Belize is also the only country in Central America with English as its official language, making this country a comfortable destination for English-speaking tourists.

Costa Rica is the most visited nation in Central America. Tourism in Costa Rica is one of the fastest growing economic sectors of the country, having become the largest source of foreign revenue by 1995. Since 1999, tourism has earned more foreign exchange than bananas, pineapples and coffee exports combined. The tourism boom began in 1987, with the number of visitors up from 329,000 in 1988, through 1.03 million in 1999, to a historical record of 2.43 million foreign visitors and $1.92-billion in revenue in 2013. In 2012 tourism contributed with 12.5% of the country's GDP and it was responsible for 11.7% of direct and indirect employment.

Tourism in Nicaragua has grown considerably recently, and it is now the second largest industry in the nation. Nicaraguan President Daniel Ortega has stated his intention to use tourism to combat poverty throughout the country. The growth in tourism has positively affected the agricultural, commercial, and finance industries, as well as the construction industry. The results for Nicaragua's tourism-driven economy have been significant, with the nation welcoming one million tourists in a calendar year for the first time in its history in 2010.

The Inter-American Highway is the Central American section of the Pan-American Highway, and spans between Nuevo Laredo, Mexico, and Panama City, Panama. Because of the break in the highway known as the Darién Gap, it is not possible to cross between Central America and South America in an automobile.



Continuous function

In mathematics, a continuous function is a function such that a small variation of the argument induces a small variation of the value of the function. This implies there are no abrupt changes in value, known as "discontinuities". More precisely, a function is continuous if arbitrarily small changes in its value can be assured by restricting to sufficiently small changes of its argument. A discontinuous function is a function that is . Until the 19th century, mathematicians largely relied on intuitive notions of continuity and considered only continuous functions. The epsilon–delta definition of a limit was introduced to formalize the definition of continuity.

Continuity is one of the core concepts of calculus and mathematical analysis, where arguments and values of functions are real and complex numbers. The concept has been generalized to functions between metric spaces and between topological spaces. The latter are the most general continuous functions, and their definition is the basis of topology.

A stronger form of continuity is uniform continuity. In order theory, especially in domain theory, a related concept of continuity is Scott continuity.

As an example, the function denoting the height of a growing flower at time would be considered continuous. In contrast, the function denoting the amount of money in a bank account at time would be considered discontinuous since it "jumps" at each point in time when money is deposited or withdrawn.

A form of the epsilon–delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of formula_1 as follows: an infinitely small increment formula_2 of the independent variable "x" always produces an infinitely small change formula_3 of the dependent variable "y" (see e.g. "Cours d'Analyse", p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s, but the work wasn't published until the 1930s. Like Bolzano, Karl Weierstrass denied continuity of a function at a point "c" unless it was defined at and on both sides of "c", but Édouard Goursat allowed the function to be defined only at and on one side of "c", and Camille Jordan allowed it even if the function was defined only at "c". All three of those nonequivalent definitions of pointwise continuity are still in use. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.

A real function that is a function from real numbers to real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve whose domain is the entire real line. A more mathematically rigorous definition is given below.

Continuity of real functions is usually defined in terms of limits. A function with variable is "continuous at" the real number , if the limit of formula_4 as tends to , is equal to formula_5

There are several different definitions of the (global) continuity of a function, which depend on the nature of its domain. 

A function is continuous on an open interval if the interval is contained in the function's domain and the function is continuous at every interval point. A function that is continuous on the interval formula_6 (the whole real line) is often called simply a continuous function; one also says that such a function is "continuous everywhere". For example, all polynomial functions are continuous everywhere.

A function is continuous on a semi-open or a closed interval; if the interval is contained in the domain of the function, the function is continuous at every interior point of the interval, and the value of the function at each endpoint that belongs to the interval is the limit of the values of the function when the variable tends to the endpoint from the interior of the interval. For example, the function formula_7 is continuous on its whole domain, which is the closed interval formula_8

Many commonly encountered functions are partial functions that have a domain formed by all real numbers, except some isolated points. Examples are the functions formula_9 and formula_10 When they are continuous on their domain, one says, in some contexts, that they are continuous, although they are not continuous everywhere. In other contexts, mainly when one is interested in their behavior near the exceptional points, one says they are discontinuous.

A partial function is "discontinuous" at a point if the point belongs to the topological closure of its domain, and either the point does not belong to the domain of the function or the function is not continuous at the point. For example, the functions formula_11 and formula_12 are discontinuous at , and remain discontinuous whichever value is chosen for defining them at . A point where a function is discontinuous is called a "discontinuity".

Using mathematical notation, several ways exist to define continuous functions in the three senses mentioned above.

Let formula_13 be a function defined on a subset formula_14 of the set formula_15 of real numbers.

This subset formula_14 is the domain of . Some possible choices include 

In the case of the domain formula_14 being defined as an open interval, formula_24 and formula_25 do not belong to formula_14, and the values of formula_27 and formula_28 do not matter for continuity on formula_14.

The function is "continuous at some point" of its domain if the limit of formula_4 as "x" approaches "c" through the domain of "f", exists and is equal to formula_5 In mathematical notation, this is written as
formula_32
In detail this means three conditions: first, has to be defined at (guaranteed by the requirement that is in the domain of ). Second, the limit of that equation has to exist. Third, the value of this limit must equal formula_5

A neighborhood of a point "c" is a set that contains, at least, all points within some fixed distance of "c". Intuitively, a function is continuous at a point "c" if the range of "f" over the neighborhood of "c" shrinks to a single point formula_34 as the width of the neighborhood around "c" shrinks to zero. More precisely, a function "f" is continuous at a point "c" of its domain if, for any neighborhood formula_35 there is a neighborhood formula_36 in its domain such that formula_37 whenever formula_38

As neighborhoods are defined in any topological space, this definition of a continuous function applies not only for real functions but also when the domain and the codomain are topological spaces and is thus the most general definition. It follows that a function is automatically continuous at every isolated point of its domain. For example, every real-valued function on the integers is continuous.

One can instead require that for any sequence formula_39 of points in the domain which converges to "c", the corresponding sequence formula_40 converges to formula_5 In mathematical notation, formula_42

Explicitly including the definition of the limit of a function, we obtain a self-contained definition: Given a function formula_43 as above and an element formula_44 of the domain formula_14, formula_46 is said to be continuous at the point formula_44 when the following holds: For any positive real number formula_48 however small, there exists some positive real number formula_49 such that for all formula_50 in the domain of formula_46 with formula_52 the value of formula_53 satisfies
formula_54

Alternatively written, continuity of formula_43 at formula_56 means that for every formula_48 there exists a formula_49 such that for all formula_59:
formula_60

More intuitively, we can say that if we want to get all the formula_53 values to stay in some small neighborhood around formula_62 we need to choose a small enough neighborhood for the formula_50 values around formula_64 If we can do that no matter how small the formula_65 neighborhood is, then formula_46 is continuous at formula_64

In modern terms, this is generalized by the definition of continuity of a function with respect to a basis for the topology, here the metric topology.

Weierstrass had required that the interval formula_68 be entirely within the domain formula_14, but Jordan removed that restriction.

In proofs and numerical analysis, we often need to know how fast limits are converging, or in other words, control of the remainder. We can formalize this to a definition of continuity. 
A function formula_70 is called a control function if

A function formula_72 is "C"-continuous at formula_44 if there exists such a neighbourhood formula_74 that 
formula_75

A function is continuous in formula_44 if it is "C"-continuous for some control function "C".

This approach leads naturally to refining the notion of continuity by restricting the set of admissible control functions. For a given set of control functions formula_77 a function is if it is for some formula_78 For example, the Lipschitz and Hölder continuous functions of exponent below are defined by the set of control functions 
formula_79 
respectively 
formula_80

Continuity can also be defined in terms of oscillation: a function "f" is continuous at a point formula_44 if and only if its oscillation at that point is zero; in symbols, formula_82 A benefit of this definition is that it discontinuity: the oscillation gives how the function is discontinuous at a point.

This definition is helpful in descriptive set theory to study the set of discontinuities and continuous points – the continuous points are the intersection of the sets where the oscillation is less than formula_83 (hence a formula_84 set) – and gives a rapid proof of one direction of the Lebesgue integrability condition.

The oscillation is equivalent to the formula_85 definition by a simple re-arrangement and by using a limit (lim sup, lim inf) to define oscillation: if (at a given point) for a given formula_86 there is no formula_87 that satisfies the formula_85 definition, then the oscillation is at least formula_89 and conversely if for every formula_83 there is a desired formula_91 the oscillation is 0. The oscillation definition can be naturally generalized to maps from a topological space to a metric space.

Cauchy defined the continuity of a function in the following intuitive terms: an infinitesimal change in the independent variable corresponds to an infinitesimal change of the dependent variable (see "Cours d'analyse", page 34). Non-standard analysis is a way of making this mathematically rigorous. The real line is augmented by adding infinite and infinitesimal numbers to form the hyperreal numbers. In nonstandard analysis, continuity can be defined as follows.

(see microcontinuity). In other words, an infinitesimal increment of the independent variable always produces an infinitesimal change of the dependent variable, giving a modern expression to Augustin-Louis Cauchy's definition of continuity.

Checking the continuity of a given function can be simplified by checking one of the above defining properties for the building blocks of the given function. It is straightforward to show that the sum of two functions, continuous on some domain, is also continuous on this domain. Given
formula_92
then the 
formula_93 
(defined by formula_94 for all formula_95) is continuous in formula_96

The same holds for the ,
formula_97
is continuous in formula_96

Combining the above preservations of continuity and the continuity of constant functions and of the identity function formula_101 one arrives at the continuity of all polynomial functions such as
formula_102
(pictured on the right).

In the same way, it can be shown that the 
formula_103
is continuous in formula_107

This implies that, excluding the roots of formula_108 the 
formula_109
is also continuous on formula_113.

For example, the function (pictured)
formula_114
is defined for all real numbers formula_115 and is continuous at every such point. Thus, it is a continuous function. The question of continuity at formula_116 does not arise since formula_116 is not in the domain of formula_118 There is no continuous function formula_119 that agrees with formula_120 for all formula_121

Since the function sine is continuous on all reals, the sinc function formula_122 is defined and continuous for all real formula_123 However, unlike the previous example, "G" be extended to a continuous function on real numbers, by the value formula_124 to be 1, which is the limit of formula_125 when "x" approaches 0, i.e.,
formula_126

Thus, by setting

the sinc-function becomes a continuous function on all real numbers. The term is used in such cases when (re)defining values of a function to coincide with the appropriate limits make a function continuous at specific points.

A more involved construction of continuous functions is the function composition. Given two continuous functions
formula_128 
their composition, denoted as
formula_129 and defined by formula_130 is continuous.

This construction allows stating, for example, that
formula_131 
is continuous for all formula_132

An example of a discontinuous function is the Heaviside step function formula_133, defined by
formula_134

Pick for instance formula_135. Then there is no around formula_136, i.e. no open interval formula_137 with formula_138 that will force all the formula_139 values to be within the of formula_140, i.e. within formula_141. Intuitively, we can think of this type of discontinuity as a sudden jump in function values.

Similarly, the signum or sign function
formula_142
is discontinuous at formula_136 but continuous everywhere else. Yet another example: the function
formula_144
is continuous everywhere apart from formula_136.
Besides plausible continuities and discontinuities like above, there are also functions with a behavior, often coined pathological, for example, Thomae's function,
formula_146
is continuous at all irrational numbers and discontinuous at all rational numbers. In a similar vein, Dirichlet's function, the indicator function for the set of rational numbers,
formula_147
is nowhere continuous.

Let formula_53 be a function that is continuous at a point formula_149 and formula_150 be a value such formula_151 Then formula_152 throughout some neighbourhood of formula_64

"Proof:" By the definition of continuity, take formula_154 , then there exists formula_155 such that 
formula_156
Suppose there is a point in the neighbourhood formula_157 for which formula_158 then we have the contradiction
formula_159

The intermediate value theorem is an existence theorem, based on the real number property of completeness, and states:

For example, if a child grows from 1 m to 1.5 m between the ages of two and six years, then, at some time between two and six years of age, the child's height must have been 1.25 m.

As a consequence, if "f" is continuous on formula_165 and formula_27 and formula_28 differ in sign, then, at some point formula_163 formula_34 must equal zero.

The extreme value theorem states that if a function "f" is defined on a closed interval formula_165 (or any closed and bounded set) and is continuous there, then the function attains its maximum, i.e. there exists formula_171 with formula_172 for all formula_173 The same is true of the minimum of "f". These statements are not, in general, true if the function is defined on an open interval formula_174 (or any set that is not both closed and bounded), as, for example, the continuous function formula_175 defined on the open interval (0,1), does not attain a maximum, being unbounded above.

Every differentiable function
formula_176
is continuous, as can be shown. The converse does not hold: for example, the absolute value function
is everywhere continuous. However, it is not differentiable at formula_136 (but is so everywhere else). Weierstrass's function is also everywhere continuous but nowhere differentiable.

The derivative "f′"("x") of a differentiable function "f"("x") need not be continuous. If "f′"("x") is continuous, "f"("x") is said to be "continuously differentiable". The set of such functions is denoted formula_179 More generally, the set of functions
formula_180
(from an open interval (or open subset of formula_15) formula_182 to the reals) such that "f" is formula_183 times differentiable and such that the formula_183-th derivative of "f" is continuous is denoted formula_185 See differentiability class. In the field of computer graphics, properties related (but not identical) to formula_186 are sometimes called formula_187 (continuity of position), formula_188 (continuity of tangency), and formula_189 (continuity of curvature); see Smoothness of curves and surfaces.

Every continuous function
formula_190
is integrable (for example in the sense of the Riemann integral). The converse does not hold, as the (integrable but discontinuous) sign function shows.

Given a sequence
formula_191
of functions such that the limit
formula_192
exists for all formula_193, the resulting function formula_53 is referred to as the pointwise limit of the sequence of functions formula_195 The pointwise limit function need not be continuous, even if all functions formula_196 are continuous, as the animation at the right shows. However, "f" is continuous if all functions formula_196 are continuous and the sequence converges uniformly, by the uniform convergence theorem. This theorem can be used to show that the exponential functions, logarithms, square root function, and trigonometric functions are continuous.

Discontinuous functions may be discontinuous in a restricted way, giving rise to the concept of directional continuity (or right and left continuous functions) and semi-continuity. Roughly speaking, a function is if no jump occurs when the limit point is approached from the right. Formally, "f" is said to be right-continuous at the point "c" if the following holds: For any number formula_198 however small, there exists some number formula_49 such that for all "x" in the domain with formula_200 the value of formula_53 will satisfy
formula_202

This is the same condition as continuous functions, except it is required to hold for "x" strictly larger than "c" only. Requiring it instead for all "x" with formula_203 yields the notion of functions. A function is continuous if and only if it is both right-continuous and left-continuous.

A function "f" is if, roughly, any jumps that might occur only go down, but not up. That is, for any formula_48 there exists some number formula_49 such that for all "x" in the domain with formula_206 the value of formula_53 satisfies
formula_208
The reverse condition is .

The concept of continuous real-valued functions can be generalized to functions between metric spaces. A metric space is a set formula_209 equipped with a function (called metric) formula_210 that can be thought of as a measurement of the distance of any two elements in "X". Formally, the metric is a function
formula_211
that satisfies a number of requirements, notably the triangle inequality. Given two metric spaces formula_212 and formula_213 and a function
formula_214
then formula_46 is continuous at the point formula_216 (with respect to the given metrics) if for any positive real number formula_48 there exists a positive real number formula_49 such that all formula_219 satisfying formula_220 will also satisfy formula_221 As in the case of real functions above, this is equivalent to the condition that for every sequence formula_222 in formula_209 with limit formula_224 we have formula_225 The latter condition can be weakened as follows: formula_46 is continuous at the point formula_227 if and only if for every convergent sequence formula_222 in formula_209 with limit formula_227, the sequence formula_231 is a Cauchy sequence, and formula_227 is in the domain of formula_46.

The set of points at which a function between metric spaces is continuous is a formula_84 set – this follows from the formula_85 definition of continuity.

This notion of continuity is applied, for example, in functional analysis. A key statement in this area says that a linear operator
formula_236
between normed vector spaces formula_237 and formula_238 (which are vector spaces equipped with a compatible norm, denoted formula_239) is continuous if and only if it is bounded, that is, there is a constant formula_240 such that
formula_241
for all formula_242

The concept of continuity for functions between metric spaces can be strengthened in various ways by limiting the way formula_87 depends on formula_83 and "c" in the definition above. Intuitively, a function "f" as above is uniformly continuous if the formula_87 does
not depend on the point "c". More precisely, it is required that for every real number formula_198 there exists formula_49 such that for every formula_248 with formula_249 we have that formula_250 Thus, any uniformly continuous function is continuous. The converse does not generally hold but holds when the domain space "X" is compact. Uniformly continuous maps can be defined in the more general situation of uniform spaces.

A function is Hölder continuous with exponent α (a real number) if there is a constant "K" such that for all formula_251 the inequality
formula_252
holds. Any Hölder continuous function is uniformly continuous. The particular case formula_253 is referred to as Lipschitz continuity. That is, a function is Lipschitz continuous if there is a constant "K" such that the inequality
formula_254
holds for any formula_255 The Lipschitz condition occurs, for example, in the Picard–Lindelöf theorem concerning the solutions of ordinary differential equations.

Another, more abstract, notion of continuity is the continuity of functions between topological spaces in which there generally is no formal notion of distance, as there is in the case of metric spaces. A topological space is a set "X" together with a topology on "X", which is a set of subsets of "X" satisfying a few requirements with respect to their unions and intersections that generalize the properties of the open balls in metric spaces while still allowing one to talk about the neighborhoods of a given point. The elements of a topology are called open subsets of "X" (with respect to the topology).

A function
formula_214
between two topological spaces "X" and "Y" is continuous if for every open set formula_257 the inverse image
formula_258
is an open subset of "X". That is, "f" is a function between the sets "X" and "Y" (not on the elements of the topology formula_259), but the continuity of "f" depends on the topologies used on "X" and "Y".

This is equivalent to the condition that the preimages of the closed sets (which are the complements of the open subsets) in "Y" are closed in "X".

An extreme example: if a set "X" is given the discrete topology (in which every subset is open), all functions
formula_260
to any topological space "T" are continuous. On the other hand, if "X" is equipped with the indiscrete topology (in which the only open subsets are the empty set and "X") and the space "T" set is at least T, then the only continuous functions are the constant functions. Conversely, any function whose codomain is indiscrete is continuous.

The translation in the language of neighborhoods of the formula_261-definition of continuity leads to the following definition of the continuity at a point:
This definition is equivalent to the same statement with neighborhoods restricted to open neighborhoods and can be restated in several ways by using preimages rather than images.

Also, as every set that contains a neighborhood is also a neighborhood, and formula_262 is the largest subset of such that formula_263 this definition may be simplified into:
As an open set is a set that is a neighborhood of all its points, a function formula_264 is continuous at every point of if and only if it is a continuous function.

If "X" and "Y" are metric spaces, it is equivalent to consider the neighborhood system of open balls centered at "x" and "f"("x") instead of all neighborhoods. This gives back the above formula_85 definition of continuity in the context of metric spaces. In general topological spaces, there is no notion of nearness or distance. If, however, the target space is a Hausdorff space, it is still true that "f" is continuous at "a" if and only if the limit of "f" as "x" approaches "a" is "f"("a"). At an isolated point, every function is continuous.

Given formula_266 a map formula_264 is continuous at formula_50 if and only if whenever formula_269 is a filter on formula_209 that converges to formula_50 in formula_272 which is expressed by writing formula_273 then necessarily formula_274 in formula_275 
If formula_276 denotes the neighborhood filter at formula_50 then formula_264 is continuous at formula_50 if and only if formula_280 in formula_275 Moreover, this happens if and only if the prefilter formula_282 is a filter base for the neighborhood filter of formula_53 in formula_275

Several equivalent definitions for a topological structure exist; thus, several equivalent ways exist to define a continuous function.

In several contexts, the topology of a space is conveniently specified in terms of limit points. This is often accomplished by specifying when a point is the limit of a sequence. Still, for some spaces that are too large in some sense, one specifies also when a point is the limit of more general sets of points indexed by a directed set, known as nets. A function is (Heine-)continuous only if it takes limits of sequences to limits of sequences. In the former case, preservation of limits is also sufficient; in the latter, a function may preserve all limits of sequences yet still fail to be continuous, and preservation of nets is a necessary and sufficient condition.

In detail, a function formula_264 is sequentially continuous if whenever a sequence formula_222 in formula_209 converges to a limit formula_288 the sequence formula_231 converges to formula_290 Thus, sequentially continuous functions "preserve sequential limits." Every continuous function is sequentially continuous. If formula_209 is a first-countable space and countable choice holds, then the converse also holds: any function preserving sequential limits is continuous. In particular, if formula_209 is a metric space, sequential continuity and continuity are equivalent. For non-first-countable spaces, sequential continuity might be strictly weaker than continuity. (The spaces for which the two properties are equivalent are called sequential spaces.) This motivates the consideration of nets instead of sequences in general topological spaces. Continuous functions preserve the limits of nets, and this property characterizes continuous functions.

For instance, consider the case of real-valued functions of one real variable:

"Proof." Assume that formula_293 is continuous at formula_44 (in the sense of formula_295 continuity). Let formula_296 be a sequence converging at formula_44 (such a sequence always exists, for example, formula_298); since formula_46 is continuous at formula_44
formula_301
For any such formula_302 we can find a natural number formula_303 such that for all formula_304
formula_305
since formula_222 converges at formula_44; combining this with formula_308 we obtain
formula_309
Assume on the contrary that formula_46 is sequentially continuous and proceed by contradiction: suppose formula_46 is not continuous at formula_44
formula_313
then we can take formula_314 and call the corresponding point formula_315: in this way we have defined a sequence formula_316 such that
formula_317
by construction formula_318 but formula_319, which contradicts the hypothesis of sequentially continuity. formula_320

In terms of the interior operator, a function formula_264 between topological spaces is continuous if and only if for every subset formula_322 
formula_323

In terms of the closure operator, formula_264 is continuous if and only if for every subset formula_325 
formula_326
That is to say, given any element formula_219 that belongs to the closure of a subset formula_325 formula_53 necessarily belongs to the closure of formula_330 in formula_275 If we declare that a point formula_50 is a subset formula_333 if formula_334 then this terminology allows for a plain English description of continuity: formula_46 is continuous if and only if for every subset formula_325 formula_46 maps points that are close to formula_338 to points that are close to formula_339 Similarly, formula_46 is continuous at a fixed given point formula_219 if and only if whenever formula_50 is close to a subset formula_325 then formula_53 is close to formula_339

Instead of specifying topological spaces by their open subsets, any topology on formula_209 can alternatively be determined by a closure operator or by an interior operator. 
Specifically, the map that sends a subset formula_338 of a topological space formula_209 to its topological closure formula_349 satisfies the Kuratowski closure axioms. Conversely, for any closure operator formula_350 there exists a unique topology formula_351 on formula_209 (specifically, formula_353) such that for every subset formula_325 formula_355 is equal to the topological closure formula_356 of formula_338 in formula_358 If the sets formula_209 and formula_360 are each associated with closure operators (both denoted by formula_361) then a map formula_264 is continuous if and only if formula_363 for every subset formula_364

Similarly, the map that sends a subset formula_338 of formula_209 to its topological interior formula_367 defines an interior operator. Conversely, any interior operator formula_368 induces a unique topology formula_351 on formula_209 (specifically, formula_371) such that for every formula_325 formula_373 is equal to the topological interior formula_374 of formula_338 in formula_358 If the sets formula_209 and formula_360 are each associated with interior operators (both denoted by formula_379) then a map formula_264 is continuous if and only if formula_381 for every subset formula_382

Continuity can also be characterized in terms of filters. A function formula_264 is continuous if and only if whenever a filter formula_269 on formula_209 converges in formula_209 to a point formula_266 then the prefilter formula_388 converges in formula_360 to formula_290 This characterization remains true if the word "filter" is replaced by "prefilter."

If formula_264 and formula_392 are continuous, then so is the composition formula_393 If formula_264 is continuous and

The possible topologies on a fixed set "X" are partially ordered: a topology formula_395 is said to be coarser than another topology formula_396 (notation: formula_397) if every open subset with respect to formula_395 is also open with respect to formula_399 Then, the identity map
formula_400
is continuous if and only if formula_397 (see also comparison of topologies). More generally, a continuous function
formula_402
stays continuous if the topology formula_403 is replaced by a coarser topology and/or formula_404 is replaced by a finer topology.

Symmetric to the concept of a continuous map is an open map, for which of open sets are open. If an open map "f" has an inverse function, that inverse is continuous, and if a continuous map "g" has an inverse, that inverse is open. Given a bijective function "f" between two topological spaces, the inverse function formula_405 need not be continuous. A bijective continuous function with a continuous inverse function is called a .

If a continuous bijection has as its domain a compact space and its codomain is Hausdorff, then it is a homeomorphism.

Given a function
formula_406
where "X" is a topological space and "S" is a set (without a specified topology), the final topology on "S" is defined by letting the open sets of "S" be those subsets "A" of "S" for which formula_407 is open in "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is coarser than the final topology on "S". Thus, the final topology is the finest topology on "S" that makes "f" continuous. If "f" is surjective, this topology is canonically identified with the quotient topology under the equivalence relation defined by "f".

Dually, for a function "f" from a set "S" to a topological space "X", the initial topology on "S" is defined by designating as an open set every subset "A" of "S" such that formula_408 for some open subset "U" of "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is finer than the initial topology on "S". Thus, the initial topology is the coarsest topology on "S" that makes "f" continuous. If "f" is injective, this topology is canonically identified with the subspace topology of "S", viewed as a subset of "X".

A topology on a set "S" is uniquely determined by the class of all continuous functions formula_409 into all topological spaces "X". Dually, a similar idea can be applied to maps formula_410

If formula_411 is a continuous function from some subset formula_412 of a topological space formula_209 then a of formula_46 to formula_209 is any continuous function formula_416 such that formula_417 for every formula_418 which is a condition that often written as formula_419 In words, it is any continuous function formula_416 that restricts to formula_46 on formula_422 This notion is used, for example, in the Tietze extension theorem and the Hahn–Banach theorem. If formula_411 is not continuous, then it could not possibly have a continuous extension. If formula_360 is a Hausdorff space and formula_412 is a dense subset of formula_209 then a continuous extension of formula_411 to formula_272 if one exists, will be unique. The Blumberg theorem states that if formula_429 is an arbitrary function then there exists a dense subset formula_14 of formula_15 such that the restriction formula_432 is continuous; in other words, every function formula_433 can be restricted to some dense subset on which it is continuous. 

Various other mathematical domains use the concept of continuity in different but related meanings. For example, in order theory, an order-preserving function formula_264 between particular types of partially ordered sets formula_209 and formula_360 is continuous if for each directed subset formula_338 of formula_272 we have formula_439 Here formula_440 is the supremum with respect to the orderings in formula_209 and formula_442 respectively. This notion of continuity is the same as topological continuity when the partially ordered sets are given the Scott topology.

In category theory, a functor
formula_443
between two categories is called if it commutes with small limits. That is to say,
formula_444
for any small (that is, indexed by a set formula_445 as opposed to a class) diagram of objects in formula_446.

A is a generalization of metric spaces and posets, which uses the concept of quantales, and that can be used to unify the notions of metric spaces and domains.



Curl (mathematics)

In vector calculus, the curl, also known as rotor, is a vector operator that describes the infinitesimal circulation of a vector field in three-dimensional Euclidean space. The curl at a point in the field is represented by a vector whose length and direction denote the magnitude and axis of the maximum circulation. The curl of a field is formally defined as the circulation density at each point of the field.

A vector field whose curl is zero is called irrotational. The curl is a form of differentiation for vector fields. The corresponding form of the fundamental theorem of calculus is Stokes' theorem, which relates the surface integral of the curl of a vector field to the line integral of the vector field around the boundary curve.

The notation is more common in North America. In the rest of the world, particularly in 20th century scientific literature, the alternative notation is traditionally used, which comes from the "rate of rotation" that it represents. To avoid confusion, modern authors tend to use the cross product notation with the del (nabla) operator, as in which also reveals the relation between curl (rotor), divergence, and gradient operators.

Unlike the gradient and divergence, curl as formulated in vector calculus does not generalize simply to other dimensions; some generalizations are possible, but only in three dimensions is the geometrically defined curl of a vector field again a vector field. This deficiency is a direct consequence of the limitations of vector calculus; on the other hand, when expressed as an antisymmetric tensor field via the wedge operator of geometric calculus, the curl generalizes to all dimensions. The circumstance is similar to that attending the 3-dimensional cross product, and indeed the connection is reflected in the notation formula_1 for the curl. 

The name "curl" was first suggested by James Clerk Maxwell in 1871 but the concept was apparently first used in the construction of an optical field theory by James MacCullagh in 1839.

</math> and the fingers curl along the orientation of 

The curl of a vector field , denoted by , or formula_2, or , is an operator that maps functions in to functions in , and in particular, it maps continuously differentiable functions to continuous functions . It can be defined in several ways, to be mentioned below:

One way to define the curl of a vector field at a point is implicitly through its projections onto various axes passing through the point: if formula_3 is any unit vector, the projection of the curl of onto formula_3 may be defined to be the limiting value of a closed line integral in a plane orthogonal to formula_3 divided by the area enclosed, as the path of integration is contracted indefinitely around the point.

More specifically, the curl is defined at a point as
formula_6
where the line integral is calculated along the boundary of the area in question, being the magnitude of the area. This equation defines the projection of the curl of onto formula_3. The infinitesimal surfaces bounded by have formula_3 as their normal. is oriented via the right-hand rule.

The above formula means that the projection of the curl of a vector field along a certain axis is the "infinitesimal area density" of the circulation of the field projected onto a plane perpendicular to that axis. This formula does not "a priori" define a legitimate vector field, for the individual circulation densities with respect to various axes "a priori" need not relate to each other in the same way as the components of a vector do; that they "do" indeed relate to each other in this precise manner must be proven separately.

To this definition fits naturally the Kelvin–Stokes theorem, as a global formula corresponding to the definition. It equates the surface integral of the curl of a vector field to the above line integral taken around the boundary of the surface.

Another way one can define the curl vector of a function at a point is explicitly as the limiting value of a vector-valued surface integral around a shell enclosing divided by the volume enclosed, as the shell is contracted indefinitely around .

More specifically, the curl may be defined by the vector formula
formula_9

where the surface integral is calculated along the boundary of the volume , being the magnitude of the volume, and formula_10 pointing outward from the surface perpendicularly at every point in .

In this formula, the cross product in the integrand measures the tangential component of at each point on the surface , together with the orientation of these tangential components with respect to the surface . Thus, the surface integral measures the overall extent to which circulates around , together with the net orientation of this circulation in space. The "curl" of a vector field at a point is then the "infinitesimal volume density" of the net "vector" circulation (i.e., both magnitude and spatial orientation) of the field around the point.

To this definition fits naturally another global formula (similar to the Kelvin-Stokes theorem) which equates the volume integral of the curl of a vector field to the above surface integral taken over the boundary of the volume. 

Whereas the above two definitions of the curl are coordinate free, there is another "easy to memorize" definition of the curl in curvilinear orthogonal coordinates, e.g. in Cartesian coordinates, spherical, cylindrical, or even elliptical or parabolic coordinates: formula_11

The equation for each component can be obtained by exchanging each occurrence of a subscript 1, 2, 3 in cyclic permutation: 1 → 2, 2 → 3, and 3 → 1 (where the subscripts represent the relevant indices).

If are the Cartesian coordinates and are the orthogonal coordinates, then 
formula_12 
is the length of the coordinate vector corresponding to . The remaining two components of curl result from cyclic permutation of indices: 3,1,2 → 1,2,3 → 2,3,1.

In practice, the two coordinate-free definitions described above are rarely used because in virtually all cases, the curl operator can be applied using some set of curvilinear coordinates, for which simpler representations have been derived.

The notation has its origins in the similarities to the 3-dimensional cross product, and it is useful as a mnemonic in Cartesian coordinates if is taken as a vector differential operator del. Such notation involving operators is common in physics and algebra.

Expanded in 3-dimensional Cartesian coordinates (see "Del in cylindrical and spherical coordinates" for spherical and cylindrical coordinate representations), is, for composed of (where the subscripts indicate the components of the vector, not partial derivatives):
formula_13
where , , and are the unit vectors for the -, -, and -axes, respectively. This expands as follows:
formula_14

Although expressed in terms of coordinates, the result is invariant under proper rotations of the coordinate axes but the result inverts under reflection.

In a general coordinate system, the curl is given by
formula_15
where denotes the Levi-Civita tensor, the covariant derivative, formula_16 is the determinant of the metric tensor and the Einstein summation convention implies that repeated indices are summed over. Due to the symmetry of the Christoffel symbols participating in the covariant derivative, this expression reduces to the partial derivative:
formula_17
where are the local basis vectors. Equivalently, using the exterior derivative, the curl can be expressed as:
formula_18

Here and are the musical isomorphisms, and is the Hodge star operator. This formula shows how to calculate the curl of in any coordinate system, and how to extend the curl to any oriented three-dimensional Riemannian manifold. Since this depends on a choice of orientation, curl is a chiral operation. In other words, if the orientation is reversed, then the direction of the curl is also reversed.

Suppose the vector field describes the velocity field of a fluid flow (such as a large tank of liquid or gas) and a small ball is located within the fluid or gas (the center of the ball being fixed at a certain point). If the ball has a rough surface, the fluid flowing past it will make it rotate. The rotation axis (oriented according to the right hand rule) points in the direction of the curl of the field at the center of the ball, and the angular speed of the rotation is half the magnitude of the curl at this point.
The curl of the vector field at any point is given by the rotation of an infinitesimal area in the "xy"-plane (for "z"-axis component of the curl), "zx"-plane (for "y"-axis component of the curl) and "yz"-plane (for "x"-axis component of the curl vector). This can be seen in the examples below.

The vector field
formula_19
can be decomposed as
formula_20

Upon visual inspection, the field can be described as "rotating". If the vectors of the field were to represent a linear force acting on objects present at that point, and an object were to be placed inside the field, the object would start to rotate clockwise around itself. This is true regardless of where the object is placed.

Calculating the curl:
formula_21

The resulting vector field describing the curl would at all points be pointing in the negative direction. The results of this equation align with what could have been predicted using the right-hand rule using a right-handed coordinate system. Being a uniform vector field, the object described before would have the same rotational intensity regardless of where it was placed.
For the vector field
formula_22

the curl is not as obvious from the graph. However, taking the object in the previous example, and placing it anywhere on the line , the force exerted on the right side would be slightly greater than the force exerted on the left, causing it to rotate clockwise. Using the right-hand rule, it can be predicted that the resulting curl would be straight in the negative direction. Inversely, if placed on , the object would rotate counterclockwise and the right-hand rule would result in a positive direction.

Calculating the curl:
formula_23

The curl points in the negative direction when is positive and vice versa. In this field, the intensity of rotation would be greater as the object moves away from the plane .


In general curvilinear coordinates (not only in Cartesian coordinates), the curl of a cross product of vector fields and can be shown to be
formula_24

Interchanging the vector field and operator, we arrive at the cross product of a vector field with curl of a vector field:
formula_25
where is the Feynman subscript notation, which considers only the variation due to the vector field (i.e., in this case, is treated as being constant in space).

Another example is the curl of a curl of a vector field. It can be shown that in general coordinates
formula_26
and this identity defines the vector Laplacian of , symbolized as .

The curl of the gradient of "any" scalar field is always the zero vector field
formula_27
which follows from the antisymmetry in the definition of the curl, and the symmetry of second derivatives.

The divergence of the curl of any vector field is equal to zero: 
formula_28

If is a scalar valued function and is a vector field, then
formula_29

The vector calculus operations of grad, curl, and div are most easily generalized in the context of differential forms, which involves a number of steps. In short, they correspond to the derivatives of 0-forms, 1-forms, and 2-forms, respectively. The geometric interpretation of curl as rotation corresponds to identifying bivectors (2-vectors) in 3 dimensions with the special orthogonal Lie algebra formula_30 of infinitesimal rotations (in coordinates, skew-symmetric 3 × 3 matrices), while representing rotations by vectors corresponds to identifying 1-vectors (equivalently, 2-vectors) and these all being 3-dimensional spaces.

In 3 dimensions, a differential 0-form is a real-valued function ; a differential 1-form is the following expression, where the coefficients are functions:
formula_31
a differential 2-form is the formal sum, again with function coefficients:
formula_32
and a differential 3-form is defined by a single term with one function as coefficient:
formula_33

The exterior derivative of a -form in is defined as the -form from above—and in if, e.g.,
formula_34
then the exterior derivative leads to
formula_35

The exterior derivative of a 1-form is therefore a 2-form, and that of a 2-form is a 3-form. On the other hand, because of the interchangeability of mixed derivatives, 
formula_36
and antisymmetry,
formula_37

the twofold application of the exterior derivative yields formula_38 (the zero formula_39-form).

Thus, denoting the space of -forms by and the exterior derivative by one gets a sequence:
formula_40

Here is the space of sections of the exterior algebra vector bundle over R, whose dimension is the binomial coefficient ; note that for or . Writing only dimensions, one obtains a row of Pascal's triangle:

the 1-dimensional fibers correspond to scalar fields, and the 3-dimensional fibers to vector fields, as described below. Modulo suitable identifications, the three nontrivial occurrences of the exterior derivative correspond to grad, curl, and div.

Differential forms and the differential can be defined on any Euclidean space, or indeed any manifold, without any notion of a Riemannian metric. On a Riemannian manifold, or more generally pseudo-Riemannian manifold, -forms can be identified with -vector fields (-forms are -covector fields, and a pseudo-Riemannian metric gives an isomorphism between vectors and covectors), and on an "oriented" vector space with a nondegenerate form (an isomorphism between vectors and covectors), there is an isomorphism between -vectors and -vectors; in particular on (the tangent space of) an oriented pseudo-Riemannian manifold. Thus on an oriented pseudo-Riemannian manifold, one can interchange -forms, -vector fields, -forms, and -vector fields; this is known as Hodge duality. Concretely, on this is given by:

Thus, identifying 0-forms and 3-forms with scalar fields, and 1-forms and 2-forms with vector fields:

On the other hand, the fact that corresponds to the identities
formula_41
for any scalar field , and
formula_42
for any vector field .

Grad and div generalize to all oriented pseudo-Riemannian manifolds, with the same geometric interpretation, because the spaces of 0-forms and -forms at each point are always 1-dimensional and can be identified with scalar fields, while the spaces of 1-forms and -forms are always fiberwise -dimensional and can be identified with vector fields.

Curl does not generalize in this way to 4 or more dimensions (or down to 2 or fewer dimensions); in 4 dimensions the dimensions are

so the curl of a 1-vector field (fiberwise 4-dimensional) is a "2-vector field", which at each point belongs to 6-dimensional vector space, and so one has
formula_43
which yields a sum of six independent terms, and cannot be identified with a 1-vector field. Nor can one meaningfully go from a 1-vector field to a 2-vector field to a 3-vector field (4 → 6 → 4), as taking the differential twice yields zero (). Thus there is no curl function from vector fields to vector fields in other dimensions arising in this way.

However, one can define a curl of a vector field as a "2-vector field" in general, as described below.

2-vectors correspond to the exterior power ; in the presence of an inner product, in coordinates these are the skew-symmetric matrices, which are geometrically considered as the special orthogonal Lie algebra of infinitesimal rotations. This has dimensions, and allows one to interpret the differential of a 1-vector field as its infinitesimal rotations. Only in 3 dimensions (or trivially in 0 dimensions) we have , which is the most elegant and common case. In 2 dimensions the curl of a vector field is not a vector field but a function, as 2-dimensional rotations are given by an angle (a scalar – an orientation is required to choose whether one counts clockwise or counterclockwise rotations as positive); this is not the div, but is rather perpendicular to it. In 3 dimensions the curl of a vector field is a vector field as is familiar (in 1 and 0 dimensions the curl of a vector field is 0, because there are no non-trivial 2-vectors), while in 4 dimensions the curl of a vector field is, geometrically, at each point an element of the 6-dimensional Lie algebra 

The curl of a 3-dimensional vector field which only depends on 2 coordinates (say and ) is simply a vertical vector field (in the direction) whose magnitude is the curl of the 2-dimensional vector field, as in the examples on this page.

Considering curl as a 2-vector field (an antisymmetric 2-tensor) has been used to generalize vector calculus and associated physics to higher dimensions.

In the case where the divergence of a vector field is zero, a vector field exists such that . This is why the magnetic field, characterized by zero divergence, can be expressed as the curl of a magnetic vector potential.

If is a vector field with , then adding any gradient vector field to will result in another vector field such that as well. This can be summarized by saying that the inverse curl of a three-dimensional vector field can be obtained up to an unknown irrotational field with the Biot–Savart law.



Carl Friedrich Gauss

Johann Carl Friedrich Gauss ( ; ; 30 April 177723 February 1855) was a German mathematician, geodesist, and physicist who made significant contributions to many fields in mathematics and science. Gauss ranks among history's most influential mathematicians and has been referred to as the "Prince of Mathematicians". He was director of the Göttingen Observatory and professor at the university for nearly half a century, from 1807 until his death in 1855.

While still a student at the University of Göttingen, he propounded several mathematical theorems. Gauss completed his masterpieces "Disquisitiones Arithmeticae" and "Theoria motus corporum coelestium" as a private scholar. He published the second and third complete proofs of the fundamental theorem of algebra, made contributions to number theory, developed the theories of binary and ternary quadratic forms, and is credited with inventing the fast Fourier transform algorithm. He is considered one of the discoverers of non-Euclidean geometry alongside Nikolai Lobachevsky and János Bolyai and coined that term.

Gauss was instrumental in the identification of the new newly discovered Ceres as a dwarf planet. His work on the motion of planetoids disturbed by large planets led to the introduction of the Gaussian gravitational constant and the method of least squares, which he discovered before Adrien-Marie Legendre published on the method.

Gauss was in charge of the extensive geodetic survey of the Kingdom of Hanover together with an arc measurement project from 1820 to 1844, did much of the fieldwork, and provided the complete scientific evaluation. Furthermore, he was one of the founders of geophysics while formulating the fundamental principles of magnetism, and did basic practical research in this field. Fruits of his practical works were the inventions of the heliotrope in 1821, a magnetometer in 1833 and, alongside Wilhelm Eduard Weber, the first electromagnetic telegraph in 1833.

Gauss was a careful author and refused to publish incomplete work. Although he published extensively during his life, he left behind several works to be published posthumously. He believed that the act of learning, not possession of knowledge, provided the greatest enjoyment. Gauss was known to dislike teaching, but some of his students became influential mathematicians.

Johann Carl Friedrich Gauss was born on 30 April 1777 in Brunswick (Braunschweig), in the Duchy of Brunswick-Wolfenbüttel (now part of Lower Saxony, Germany), to a family of lower social status. His father Gebhard Dietrich Gauss (1744–1808) worked in several jobs, as butcher, bricklayer, gardener, and as treasurer of a death-benefit fund. Gauss characterized his father as an honourable and respected man, but rough and dominating at home. He was experienced in writing and calculating, whereas his wife Dorothea (1743–1839), Carl Friedrich's mother, was nearly illiterate. Carl Friedrich was christened and confirmed in a church near the school that he attended as a child. He had one elder brother from his father's first marriage.

Gauss was a child prodigy in the field of mathematics. When the elementary teachers noticed his intellectual abilities, they brought him to the attention of the Duke of Brunswick, who sent him to the local "Collegium Carolinum", which he attended from 1792 to 1795 with Eberhard August Wilhelm von Zimmermann as one of his teachers. Thereafter the Duke granted him the resources for studies of mathematics, sciences, and classical languages at the Hanoverian University of Göttingen until 1798. It is not known why Gauss went to Göttingen and not to the University of Helmstedt near his native Brunswick; it is assumed that the large library of Göttingen, where students were allowed to borrow books and take them home, was the decisive reason. One of his professors in mathematics was Abraham Gotthelf Kästner, whom Gauss called "the leading mathematician among poets, and the leading poet among mathematicians" because of his epigrams. Gauss depicted him in a drawing showing a lecture scene where he produced errors in a simple calculation. Astronomy was taught by Karl Felix von Seyffer (1762–1822), with whom Gauss stayed in correspondence after graduation; Olbers and Gauss mocked him in their correspondence. On the other hand, he thought highly of Georg Christoph Lichtenberg, his teacher of physics, and of Christian Gottlob Heyne, whose lectures in classics Gauss attended with pleasure. Fellow students of this time were Johann Friedrich Benzenberg, Farkas Bolyai, and Heinrich Wilhelm Brandes.

Though being a registered student at university, it is evident that he was a self-taught student in mathematics, since he independently rediscovered several theorems. He succeeded with a breakthrough in a geometrical problem that had occupied mathematicians since the days of the Ancient Greeks when he determined in 1796 which regular polygons can be constructed by compass and straightedge. This discovery was the subject of his first publication and ultimately led Gauss to choose mathematics instead of philology as a career. Gauss' mathematical diary shows that, in the same year, he was also productive in number theory. He made advanced discoveries in modular arithmetic, found the first proof of the quadratic reciprocity law, and dealt with the prime number theorem. Many ideas for his mathematical magnum opus "Disquisitiones arithmeticae", published in 1801, date from this time.

Gauss graduated as a Doctor of Philosophy in 1799. He did not graduate from Göttingen, as is sometimes stated, but rather, at the Duke of Brunswick's special request, from the University of Helmstedt, the only state university of the duchy. There, Johann Friedrich Pfaff assessed his doctoral thesis, and Gauss got the degree "in absentia" without the further oral examination that was usually requested. The Duke then granted him his cost of living as a private scholar in Brunswick. Gauss showed his gratitude and loyalty for this bequest when he refused several calls from the Russian Academy of Sciences in St. Peterburg and from Landshut University. Later, the Duke promised him the foundation of an observatory in Brunswick in 1804. Architect Peter Joseph Krahe made preliminary designs, but one of Napoleon's wars cancelled those plans: the Duke was mortally wounded in the battle of Jena in 1806. The duchy was abolished in the following year, and Gauss's financial support stopped. He then followed a call to the University of Göttingen, an institution of the newly founded Kingdom of Westphalia under Jérôme Bonaparte, as full professor and director of the astronomical observatory.

Studying the calculation of asteroid orbits, Gauss established contact with the astronomical community of Bremen and Lilienthal, especially Wilhelm Olbers, Karl Ludwig Harding and Friedrich Wilhelm Bessel, as part of the informal group of astronomers known as the Celestial police. One of their aims was the discovery of further planets, and they assembled data on asteroids and comets as a basis for Gauss's research. Gauss was thereby able to develop new, powerful methods for the determination of orbits, which he later published in his astronomical magnum opus "Theoria motus corporum coelestium" (1809).

Gauss arrived at Göttingen in November 1807, and in the following years he was confronted with the demand for two thousand francs from the Westphalian government as a war contribution. Without having yet received his salary, he could not raise this enormous amount. Both Olbers and Laplace wanted to help him with the payment, but Gauss refused their assistance. Finally, an anonymous person from Frankfurt, later discovered to be Prince-primate Dalberg, paid the sum.

Gauss took on the directorate of the 60-year-old observatory, founded in 1748 by Prince-elector George II and built on a converted fortification tower, with usable, but partly out-of-date instruments. The construction of a new observatory had been approved by Prince-elector George III in principle since 1802, and the Westphalian government continued the planning, but Gauss could not move to his new place of work until October 1816. He got new up-to-date instruments, for instance two meridian circles from Repsold and Reichenbach, and a heliometer from Fraunhofer.

The scientific activity of Gauss, besides pure mathematics, can be roughly divided into three periods: in the first two decades of the 19th century astronomy was the main focus, in the third decade geodesy, and in the fourth decade he occupied himself with physics, mainly magnetism.

Gauss remained mentally active into his old age, even while suffering from gout and general unhappiness. His last observation was the solar eclipse of July 28, 1851. On 23 February 1855, Gauss died of a heart attack in Göttingen; and is interred in the Albani Cemetery there. Heinrich Ewald, Gauss's son-in-law, and Wolfgang Sartorius von Waltershausen, Gauss's close friend and biographer, gave eulogies at his funeral.

The day after Gauss's death his brain was removed, preserved and studied by Rudolf Wagner, who found its mass to be slightly above average, at . The cerebral area was determined by Wagner's son Hermann in his doctoral thesis to be . Highly developed convolutions were also found, which in the early 20th century were suggested as the explanation for his genius. After various previous investigations, a magnetic resonance study of 1998, done at the Max Planck Institute for Biophysical Chemistry in Göttingen, gave no results which could be used to explain his mathematical abilities.

In 2013, a neurobiologist at the same institute discovered that Gauss's brain had been mixed up, due to mislabelling, with that of the physician Conrad Heinrich Fuchs, who died in Göttingen a few months after Gauss. A further investigation showed no remarkable anomalies in the brains of either person. Thus, all investigations on Gauss's brain until 1998, except the first ones of Rudolf and Hermann Wagner, actually refer to the brain of Fuchs.

Gauss married Johanna Osthoff (1780–1809) on 9 October 1805. They had two sons and a daughter: Joseph (1806–1873), Wilhelmina (1808–1840) and Louis (1809–1810). Johanna died on 11 October 1809 one month after the birth of Louis, who himself died a few months later.

Gauss remarried within a year, on 4 August 1810, to Wilhelmine (Minna) Waldeck (1788–1831), a friend of his first wife. They had three more children: Eugen (later Eugene) (1811–1896), Wilhelm (later William) (1813–1879) and (1816–1864). Minna Gauss died on 12 September 1831 after being seriously ill for more than a decade. Therese then took over the household and cared for Gauss for the rest of his life; after her father's death she married the actor Constantin Staufenau. Her sister Wilhelmina married the orientalist Heinrich Ewald. Gauss' mother Dorothea lived in his house from 1817 until her death in 1839.

The eldest son Joseph, whilst still a schoolboy, helped his father as an assistant during his survey campaign in summer 1821. After a short time at university, in 1824 Joseph joined the Hanoverian army and assisted in surveying again in 1829. In the 1830s he was responsible for the enlargement of the survey network to the western parts of the kingdom. With his geodetical qualifications he left the service and engaged in the construction of the railway network as director of the Royal Hanoverian State Railways. In 1836 he studied the railroad system in the US for some months.

Eugen left Göttingen in September 1830 and emigrated to the United States, where he joined the army for five years. He then worked for the American Fur Company in the Midwest, where he learned the Sioux language. Later, he moved to Missouri and became a successful businessman. Wilhelm married a niece of the astronomer Bessel and also moved to Missouri in 1837, starting as a farmer and later becoming wealthy in the shoe business in St. Louis. Eugene and William have numerous descendants in America, but the descendants left in Germany all derive from Joseph, as the Gauss daughters had no children.

At the end of the 18th century, German academic mathematics was in a poor condition: the prolific mathematicians of that time worked in France and other European countries. The mathematical mainstream mainly dealt with solving practical problems in mechanics, astronomy, geodesy, etc. In this scientific environment, Gauss can be seen, following Felix Klein, as typical of both 18th and 19th-century mathematicians. His interest in practical applicability, for example in geodesy and astronomy, qualified Gauss to be taken as a typical applied mathematician of the century of enlightenment. On the other hand, he began research in numerous parts of mathematics without defined links to practical purposes, and thus showed himself as a pioneer of what was later called "pure mathematics". In contrast to earlier mathematicians, such as Leonhard Euler—who let their readers take part in their reasoning as they developed new ideas, and included certain erroneous deviations from the correct path—Gauss developed a new style of direct and complete explanation that did not attempt to show the reader the author's train of thought.

But for himself, he propagated a quite different ideal, given in a letter to Farkas Bolyai as follows:
Gauss refused to publish work which he did not consider complete and above criticism. This perfectionism was in keeping with the motto of his personal seal ("Few, but Ripe"). His personal diary indicates that he had made several mathematical discoveries years or decades before contemporaries published them. 
He put down new ideas in writing to his colleagues, who encouraged him to publish, and sometimes rebuked him if he hesitated too long, in their opinion. Gauss defended himself, claiming that the initial discovery of ideas was easy, but preparing a publishable elaboration was a demanding matter for him, for either lack of time or "serenity of mind". Nevertheless, he published many short communications of urgent content in various journals, but his "Collected Works" contain a considerable literary estate, too. Eric Temple Bell said that if Gauss had published all of his discoveries in a timely manner, he would have advanced mathematics by fifty years. Gauss referred to mathematics as "the queen of sciences" and arithmetics as "the queen of mathematics", and supposedly once espoused a belief in the necessity of immediately understanding Euler's identity as a benchmark pursuant to becoming a first-class mathematician.

On certain occasions, Gauss claimed that a finding published by another scholar had already been in his possession previously. Thus his concept of priority as "the first to discover, not the first to publish" differed from that of his scientific contemporaries. In contrast to his perfectionism in presenting mathematical ideas, he was criticized for his negligent way of quoting. He justified himself with a very special view of correct quoting: if he gave references, then only in a quite complete way, with respect to the previous authors of importance, which no one should ignore; but quoting in this way needed knowledge of the history of science and more time than he wished to spend.
Though Gauss is seen as a master of axiomatic presentation, it became obvious from his posthumously published papers, his diary, and short glosses in his own textbooks, that he worked to a great extent in an empirical way. Gauss was a lifelong busy and enthusiastic calculator, who made his calculations with extraordinary rapidity, mostly without precis controlling, but checked the results by masterly estimation. Nevertheless, his calculations, especially in geodesy and astronomy, were not always free from mistakes. He coped with the enormous workload by using skillful tools. Gauss used a lot of mathematical tables, examined their exactness, and constructed new tables on various matters for personal use. He developed new tools for effective calculation, for example the Gaussian elimination. It has been taken as a curious feature of his working style that he carried out calculations with a high degree of precision, much more than required. Very likely, this method gave him a lot of material which he used in finding theorems in number theory.

It was well known to his close colleagues that Gauss disliked giving academic lectures. He first stated this to Olbers in 1802, so this aversion was not the result of bad experience. Thus he refused to accept any academic position with teaching duties during his years as a private scholar. But from the start of his academic career at Göttingen in 1807, he continuously gave lectures until 1854. He often complained about the burdens of teaching, feeling that it was a waste of his time. On the other hand he occasionally described one or other student as talented. In all these 47 years of teaching he gave only three lectures on subjects of pure mathematics, whereas most of his lectures dealt with astronomy, geodesy, and applied mathematics. Some of Gauss' students went on to become renowned mathematicians, physicists, and astronomers: Moritz Cantor, Dedekind, Dirksen, Encke, Gould, Heine, Klinkerfues, Kupffer, Listing, Möbius, Nicolai, Riemann, Ritter, Schering, Scherk, Schumacher, Seeber, von Staudt, Stern, Ursin; as geoscientists Sartorius von Waltershausen and Wappäus.

Gauss did not write any textbook, and (unlike his friends Bessel, Humboldt, and Olbers) he disliked the popularization of scientific matters. His only attempts at popularization were his works on the date of Easter and the essay "Erdmagnetismus und Magnetometer" of 1836. Gauss published his papers and books exclusively in Latin or in German. He wrote Latin in a merely classical style, but used some customary modifications set by contemporary mathematicians.
At Göttingen University, Gauss was accompanied by a staff of other lecturers in his disciplines, who completed the educational program: for instance the brilliant Thibaut in mathematics, in physics Weber and Mayer, well known for his successful textbooks, and Harding, who took the main part of lectures in astronomy. When the observatory was completed, Gauss took his living accommodation in the western wing of the new observatory and Harding in the eastern one. Once they had been on friendly terms with another, but in the course of time they became alienated, possibly – as some biographers presume – because Gauss had wished the equal-ranked Harding to be no more than his assistant or observer. The years since 1820 were evaluated as a "period of lower astronomical activity". The new, well-equipped observatory did not work as effectively as others; Gauss' astronomical research had the character of a one-man enterprise, and the university established a place for an assistant only after Harding's death in 1834. Nevertheless, Gauss twice refused the opportunity to solve the problem by accepting offers from Berlin in 1810 and 1825 to become a full member of the Prussian Academy, without burdening lecturing duties, as well as from Leipzig University in 1810 and from Vienna University in 1842. Perhaps the reason was the difficult situation of his family. In his later years, Gauss was one of the best-paid professors of the university.

When Gauss was asked for help by his colleague and friend Friedrich Wilhelm Bessel in 1810, who was in trouble at Königsberg University because of his lack of an academic title, Gauss provided a doctorate "honoris causa" for Bessel from the Philosophy Faculty of Göttingen in March 1811. Gauss gave another recommendation for an honorary degree for Sophie Germain, but only shortly before her death, so she never received it. He also gave successful support for the talented mathematician Gotthold Eisenstein in Berlin.

Gauss took part in academic administration: three times he was elected as dean of the Philosophy Faculty. Being entrusted with the widow's pension fund of the university, he dealt with actuarial science and wrote a report on the strategy for stabilizing the benefits. He was appointed director of the Royal Academy of Sciences in Göttingen for nine years, even in his last year of life.

Soon after Gauss' death, his friend Sartorius published the first biography (1856), written in a rather enthusiastic style. Sartorius saw Gauss as a serene and forward-striving man with childlike modesty, but also of "iron character" with an unshakeable strength of mind. He was noted for a sense of justice and religious tolerance. Apart from his closer circle, others regarded him as reserved and unapproachable, "like an Olympian sitting enthroned on the summit of science". His close contemporaries agreed that Gauss was a man of difficult character. He often refused to accept compliments. His visitors were occasionally irritated by grumpy behaviour, but a short time later his mood could change, and he became a charming, open-minded host.
Gauss' life was overshadowed by severe problems in his family. When his first wife Johanna suddenly died shortly after the death of their third child, he plunged into a depression from which he never fully recovered. Soon after her death he wrote a last letter to her in the style of an ancient threnody, the most personal surviving document of Gauss'. The situation worsened when tuberculosis afflicted, and ultimately destroyed the health of, his second wife Minna over 13 years; both his daughters later suffered from the same disease. Both younger sons were educated for some years in Celle far from Göttingen. Gauss himself gave only slight hints of his personal distress: in a letter to Bessel dated December 1831 he described himself as "the victim of the worst domestic sufferings".

Gauss grew to dominate his children and eventually had conflicts with his sons, because he did not want any of them to enter mathematics or science for "fear of lowering the family name", as he believed none of them would surpass his own achievements. The military career of his elder son Joseph ended after more than two decades with the rank of a poorly paid first lieutenant, although he had acquired a considerable knowledge of geodesy. He needed financial support from his father even after he was married. The second son Eugen shared a good measure of Gauss' talent in computation and languages, but had a vivacious and sometimes rebellious character. He wanted to study philology, whereas Gauss wanted him to become a lawyer. Having run up debts and caused a scandal in public, he suddenly left Göttingen under dramatic circumstances in September 1830 and emigrated via Bremen to the United States. He wasted the little money he had taken for starting, after which his father refused further financial support. The youngest son Wilhelm wanted to qualify for agricultural administration, but had difficulties to get an appropriate education, and emigrated as well. Only Gauss' youngest daughter Therese accompanied him in his last years of life.

Collecting numerical data on very different things, useful or useless, became a habit in his later years, for example the number of paths from his home to certain places in Göttingen, or the numbers of living days of persons; he congratulated Humboldt in December 1851, when he had reached the same age as Isaac Newton at his death, calculated in days.

Similar to his excellent knowledge of Latin he was also acquainted with modern languages. At the age of 62, he began to teach himself Russian, very likely to understand scientific writings from Russia, among them those of Lobachevsky on non-Euclidean geometry. Gauss read both classical and modern literature, the English and French in the original languages. His favorite English author was Walter Scott, his favorite German Jean Paul. Gauss liked singing and went to concerts. He was a busy newspaper reader, and in his last years he used to visit an academic press salon of the university every noon. Gauss did not care much for philosophy, and mocked the "splitting hairs of the so-called metaphysicians", by which he meant proponents of the contemporary school of "Naturphilosophie".

Gauss had an "aristocratic and through and through conservative nature", with little respect for people's intelligence and morals, in accordance with the motto "mundus vult decipi". He disliked Napoleon and his system, and all kind of violence and revolution caused horror to him. Thus he condemned the methods of the Revolutions of 1848, though he agreed with some of their aims, such as the idea of a unified Germany. As far as the political system is concerned, he had a low estimation of the constitutional system; he criticized parliamentarians of his time for a lack of knowledge and logical errors.

Gauss was loyal to the House of Hanover. After King William IV's death in 1837, the personal union between the kingdoms of Great Britain and Ireland and Hanover ceased. In the same year, the new Hanoverian King Ernest Augustus annulled the constitution given to the state by his brother in 1833. Seven prominent professors, later known as the "Göttingen Seven", protested against this, among them Gauss' friend and collaborator Wilhelm Weber and Gauss' son-in-law Heinrich Ewald. All of them were dismissed, three of them were expelled, but Ewald and Weber could stay in Göttingen. Ewald took a position the University of Tübingen in 1838, where Gauss' daughter Wilhelmina died soon afterwards in 1840, and Weber went to the University of Leipzig in 1843; both of them returned to their Göttingen positions in 1849 as the only ones of the Göttingen Seven. Gauss was deeply affected by this quarrel, but saw no possibility to help them.

Gauss' religious beliefs have been a subject of speculation by some of his biographers. He sometimes said: "God is calculating." and: "I succeeded - not on account of my hard efforts, but by the grace of the Lord." Gauss was a member of the Lutheran church, like most of the population in northern Germany. It seems that he did not believe all dogmas or understand the Holy Bible to be true quite literally. Sartorius mentioned Gauss' religious tolerance, and estimated his "insatiable thirst for truth" and his sense of justice as motivated by religious convictions.

Gauss was a successful investor and accumulated considerable wealth with stocks and securities, but he disapproved of the idea of paper money. After his death a great sum of money was found hidden in his rooms.

In his doctoral thesis from 1799 Gauss proved the fundamental theorem of algebra which states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. Mathematicians including Jean le Rond d'Alembert had produced false proofs before him, and Gauss' dissertation contains a critique of d'Alembert's work. He subsequently produced three other proofs, the last one in 1849 being generally rigorous. His attempts clarified the concept of complex numbers considerably along the way.

The entries in Gauss' Mathematical diary indicate that he was busy with the subject of number theory at least since 1796. A detailed study of previous researches showed him that some of his findings had been already done by other scholars. In the years 1798 and 1799 Gauss wrote a voluminous compilation of all these results in the famous "Disquisitiones Arithmeticae", published in 1801, that was fundamental in consolidating number theory as a discipline and covered both elementary and algebraic number theory. Therein he introduces, among other things, the triple bar symbol () for congruence and uses it in a clean presentation of modular arithmetic. It deals with the unique factorization theorem and primitive roots modulo n. In the main chapters, Gauss presents the first two proofs of the law of quadratic reciprocity, which allows mathematicians to determine the solvability of any quadratic equation in modular arithmetic, and develops the theories of binary and ternary quadratic forms.

Highlights of these theories include the Gauss composition law for binary quadratic forms, as well as his enumeration of the number of representations of an integer as sum of three squares. As an almost immediate corollary of his theorem on three squares, he proves the triangular case of the Fermat polygonal number theorem for "n" = 3. From several analytic results on class numbers that Gauss gives without proof towards the end of the fifth chapter, it appears that Gauss already knew the class number formula in 1801.

In the last chapter Gauss gives his proof for the constructibility of a regular heptadecagon (17-sided polygon) with straightedge and compass by reducing this geometrical to an algebraic problem. He shows that a regular polygon is constructible if the number of its sides is a product of distinct Fermat primes and a power of 2. In the same chapter, he gives a result on the number of solutions of certain cubic polynomials with coefficients in finite fields, which amounts to counting integral points on an elliptic curve. Some 150 years later, Andre Weil remarked that this particular result, together with some other unpublished results of Gauss, led him to formulate what is now called Weil conjectures.

Gauss intended to include an eighth chapter that would treat the topic of higher congruences modulo a prime number in its full generality, the unfinished chapter was found among his papers only after his death, consisting of work done during the years 1797–1799.

In 1831, Ludwig August Seeber published a book on the theory of reduction of positive ternary quadratic forms, with accordance with the program outlined in Gauss's "Disquisitiones". However, he did not prove a central theorem of his theory, so it remained a mere conjecture. In his review of Seeber's book, Gauss simplified many of Seeber's lengthy arguments, proved this central conjecture, and remarked that this theorem is equivalent to Kepler conjecture for regular arrangements.

Gauss proved Fermat's Last Theorem for "n" = 3 and sketchingly proved it for "n" = 5 in his unpublished writings. The particular case of "n" = 3 was proved much earlier by Leonhard Euler, but Gauss developed a more streamlined proof which made use of Eisenstein integers; though more general, the proof was simpler than in the real integers case.

In his two important papers on biquadratic residues (published in 1828 and 1832) Gauss introduces the ring of Gaussian integers formula_1, and shows that this ring is a unique factorization domain. He generalizes into this ring many key arithmetic concepts, such as Fermat's little theorem and Gauss's lemma. The main objective of introducing this ring was to formulate the law of biquadratic reciprocity – as Gauss discovered, rings of complex integers are the natural setting for such higher reciprocity laws.

In the second paper, he states the general law of biquadratic reciprocity and proves several special cases of it, but proof of the general theorem is lacking, despite Gauss's statements that he found such a proof around 1814. He promised a third paper with a general proof, which has never appeared. In an earlier publication from 1818 containing his fifth and sixth proofs of quadratic reciprocity, he claims the techniques of these proofs (Gauss sums) can be applied to prove higher reciprocity laws.

Gauss's publications on biquadratic residues opened the way for boundless enlargement of the theory of numbers, and are memorable for the wealth of investigations in "higher arithmetic" that they led to.

One of Gauss's first independent discoveries was the notion of the arithmetic-geometric mean (AGM) of two positive real numbers; his systematic investigations on the AGM led him to discover an unusually rich mathematical landscape, and to obtain plenty of new results associated with it. He discovered its relation to elliptic integrals in the years 1798-1799 through the Landen's transformation, and in a diary entry recorded his discovery of the connection of Gauss's constant to lemniscatic elliptic functions, a result that Gauss stated that "will surely open a new area of analysis". He also made early inroads into the more formal issues of the foundations of complex analysis, and from a letter to Bessel in 1811 it is clear that he knew the "fundamental theorem of complex analysis" - Cauchy's integral theorem - and understood the notion of complex residues when integrating around poles.

Another source of inspiration for Gauss's early work in analysis was his acquaintance with Euler's pentagonal numbers theorem. This theorem together with his other researches on the AGM and lemniscatic functions led him to plenty of results on Jacobi theta functions, work which culminated with his discovery in 1808 of the later called Jacobi triple product identity, which includes Euler's theorem as a special case. In his publication from 1811 on the determination of the sign of quadratic Gauss sum, Gauss solved the problem by introducing Gaussian binomial coefficients and by using a line of reasoning that somehow "hides" its origin in theta function theory, as later mathematicians have shown. All this work was done several decades before the publication of Jacobi's "Fundamenta nova" in 1829; however, Gauss never found the time to write and organize all his thoughts and theorems of this kind systematically, and his contemporaries never knew the scope of his work.

Several mathematical fragments in his Nachlass indicate that he knew quite well parts of the modern theory of modular forms of Felix Klein and Robert Fricke. In his work on the multivalued AGM of two complex numbers, he discovered a very deep connection between the infinitely many values of the AGM to its two "simplest values". His unpublished writings include several drawings that show he was quite aware of the geometric side of the theory; in the context of his work on the complex AGM he recognized and made a sketch of the key concept of fundamental domain for the modular group. One of Gauss's sketches of this kind was his drawing of a tessellation of the unit disk by "equilateral" hyperbolic triangles with all angles equal to formula_2.

In his lifetime Gauss published almost nothing about those more modern theories of elliptic functions, but he did publish most of his results on the related theme of the hypergeometric function. In his work "Disquisitiones generales circa series infinitam..." (1812), he provided the first systematic treatment of the general hypergeometric function formula_3, and showed that many of the functions known to science at the time, such as the elementary functions and some special functions, are a special case of the hypergeometric function. This work was the first one with an exact inquiry of convergence of infinite series in the history of mathematics. Furthermore, it dealt with infinite continued fractions arising as ratios of hypergeometric functions.

In 1822 Gauss published his prize winning essay on conformal mappings, which contains several developments that pertain to the field of complex analysis. In this essay, Gauss made explicit the insight that angle-preserving mappings in the complex plane must be complex analytic functions, and used the later called Beltrami equation to prove the existence of isothermal coordinates on analytic surfaces. The essay concludes with examples of conformal mappings into a sphere and an ellipsoid of revolution. In addition, in unpublished fragments from the years 1834-1839 he investigated and solved the more difficult task of explicitly constructing a conformal mapping from the interior of an ellipse to the unit disk. His solution, which combined his early work on elliptic functions and his later ideas on potential theory, reveals his mastery of the theory of logarithmic potential, and his final results corresponded to the formula found by Hermann Schwarz in 1870.

Gauss often deduced theorems inductively from numerical data he had collected in an empirical way. As such, the use of efficient algorithms to facilitate calculations was vital to his researches, and he made many contributions to numeric analysis. In 1815, he published an article on numeric integration, in which he described his method of Gaussian quadrature, that improved existing methods and inspired much of the work made by later mathematicians.

In a private letter to Gerling from 1823, he described a solution of a certain 4X4 system of linear equations by using Gauss-Seidel method – an "indirect" iterative method for the solution of linear systems, that in some cases converges very rapidly to the exact solution. Gauss recommended it over the usual method (what is called "direct elimination") for systems of more than 2 equations, stating that it can be done "while half asleep, or while thinking about other things". As such, it was an early contribution to numerical linear algebra.

Gauss invented an algorithm for calculating what are now called discrete Fourier transforms, sometimes called "the most important numerical algorithm of our lifetime", when calculating the orbits of Pallas and Juno in 1805, 160 years before Cooley and Tukey published their similar Cooley–Tukey FFT algorithm. He developed it as a trigonometric interpolation method, but his paper "Theoria Interpolationis Methodo Nova Tractata" was published only posthumously in 1866, preceded by the first presentation by Joseph Fourier on the subject in 1807.

The first publication following the doctoral thesis dealt with the determination of the date of Easter (1800), a very elementary matter of mathematics. Gauss aimed to present a most convenient algorithm for people without any knowledge in ecclesiastical or even astronomical chronology, and thus avoided the usually required terms of golden number, epact, solar cycle, domenical letter, and any religious connotations. Biographers speculated on the reason why Gauss dealt with this matter, but it is likely comprehensible by the historical background. The replacement of the Julian calendar by the Gregorian calendar had caused confusion to the hundreds of states of the Holy Roman Empire since the 16th century, and was finished in Germany not until the year 1700, when the difference of eleven days was deleted, but the difference in calculating the date of Easter remained between Protestant and Catholic territories. A further agreement of 1776 equalized the confessional way of counting, thus in the Protestant states like the Duchy of Brunswick the Easter of 1777, five weeks before Gauss' birth, was the first one calculated in the new manner. The public difficulties of replacement may be the historical background for the confusion on this matter in the Gauss family (see chapter: Anecdotes). For being connected with the Easter regulations, an essay on the date of Pesach followed soon in 1802.

On 1 January 1801, Italian astronomer Giuseppe Piazzi discovered the dwarf planet Ceres. Piazzi could track Ceres for only somewhat more than a month, following it for three degrees across the night sky, less than 1% of the total orbit, until it disappeared temporarily behind the glare of the Sun. Several months later, when Ceres should have reappeared, Piazzi could not locate it: the mathematical tools of the time were not able to extrapolate a position from such a scant amount of data. Gauss tackled the problem within three months of intense work, and predicted a position for Ceres in December 1801. This turned out to be accurate within a half-degree when it was rediscovered by Franz Xaver von Zach on 7/31 December at Gotha, and independently by Heinrich Olbers on 1/2 January in Bremen. This confirmation eventually led to the classification of Ceres as minor-planet designation 1 Ceres; that was taken as the predicted planet between Mars and Jupiter by the most speculative Titius–Bode law.

Gauss's method involved determining a conic section in space, given one focus (the Sun) and the conic's intersection with three given lines (lines of sight from the Earth, which is itself moving on an ellipse, to the planet) and given the time it takes the planet to traverse the arcs determined by these lines (from which the lengths of the arcs can be calculated by Kepler's Second Law). This problem leads to an equation of the eighth degree, of which one solution, the Earth's orbit, is known. The solution sought is then separated from the remaining six based on physical conditions. In this work, Gauss used comprehensive approximation methods which he created for that purpose. Zach noted that "without the intelligent work and calculations of Doctor Gauss we might not have found Ceres again".

The discovery of Ceres led Gauss to his work on a theory of the motion of planetoids disturbed by large planets, eventually published in 1809 as "Theoria motus corporum coelestium in sectionibus conicis solem ambientum". In the process, he so streamlined the cumbersome mathematics of 18th-century orbital prediction that his work remains a cornerstone of astronomical computation. It introduced the Gaussian gravitational constant.

Since the new asteroids had been discovered, Gauss occupied himself with the perturbations of their orbital elements. Firstly he examined Ceres with analytical methods similar to those of Laplace, but his favorite object was Pallas, because of its great eccentricity and orbital inclination, whereby Laplace's method did not work. Gauss used his own tools : the arithmetic–geometric mean, the hypergeometric function, and his method of interpolation. He found an orbital resonance with Jupiter in proportion 18 : 7 in 1812; Gauss published this result as cipher, and gave the explicit meaning only in letters to Olbers and Bessel. After long years of work, he finished it in 1816 without a result that seemed sufficient to him. This marked the end of his activities in theoretical astronomy, too.

One fruit of Gauss's research on Pallas perturbations was his article "Determinatio Attractionis..." (1818) on a method of theoretical astronomy that later became known as the "elliptic ring method". This method introduced a useful averaging conception in which a planet in orbit is replaced by a fictitious ring with mass density proportional to the time taking the planet to follow the corresponding orbital arcs. Gauss presents his method of evaluating the gravitational attraction of such an elliptic ring, which includes several complicated steps; one such step involves a direct application of the arithmetic-geometric mean (AGM) algorithm to calculate an elliptic integral. In the late 19th century Gauss's method was adapted by American astronomer George William Hill, who applied it directly to the problem of secular perturbation induced by Venus on Mercury orbit.

While Gauss's contributions to theoretical astronomy came to a marked end in 1818, his more practical activities in observational astronomy continued and occupied him during his entire career. Even early in 1799, Gauss dealt with determination of longitude by use oft he lunar parallax, for which he developed more convient formulas than those were in common use. After his appointment as director of observatory he attached importance to the fundamental astronomical constants in correspondance with Bessel. Gauss himself provided tables for nutation and aberration, the solar coordinates, and refraction.

It is likely that Gauss used the method of least squares for calculating the orbit of Ceres to minimize the impact of measurement error. The method was published first by Adrien-Marie Legendre in 1805, but Gauss claimed in "Theoria motus" (1809) that he had been using it since 1794 or 1795. In the history of statistics, this disagreement is called the "priority dispute over the discovery of the method of least squares". Gauss proved the method under the assumption of normally distributed errors (Gauss–Markov theorem) in his paper "Theoria combinationis observationum erroribus minimis obnoxiae" from 1821.

In this paper, which was relatively little known in the English speaking world in the first century after its publication, he stated and proved Gauss's inequality (a Chebyshev-type inequality) for unimodal distributions, and stated without proof another inequality for moments of the fourth order (a special case of Gauss-Winckler inequality). He derived lower and upper bounds for the variance of sample variance. In a supplement to this paper Gauss described recursive least squares methods that went unnoticed until 1950, when his work was rediscovered as a consequence of the growing demand of quick estimation for various new technologies. Gauss's work on the theory of errors was extended in several directions by the geodesist Friedrich Robert Helmert, and the Gauss-Helmert theory is considered today as the "classical" theory of errors.

Gauss made several striking contributions to problems in probability theory that are not directly concerned with the theory of errors, but offer a glimpse into his broad minded view on the applicability of probabilistic thinking. One example appears as a note in his diary and is concerned with a very unusual problem that came to his mind: to describe the asymptotic distribution of entries in the continued fraction expansion of a random number uniformly distributed in "(0,1)". He derived this distribution, now known as the Gauss-Kuzmin distribution, as a by-product of his discovery of the ergodicity of the Gauss map for continued fractions. Gauss's solution is the first ever result in the metrical theory of continued fractions.

Gauss was busy with geodetic problems since 1799, when he helped Karl Ludwig von Lecoq with calculations during his survey in Westphalia. Later since 1804, he taught himself some geodetic practise with a sextant in Brunswick, and Göttingen.

Since 1816, his former student Heinrich Christian Schumacher, then professor in Copenhagen, but living in Altona (Holstein) near Hamburg, made a triangulation of the Jutland peninsula from Skagen in the north to Lauenburg in the south. The aim was not only the foundation of map production, but also the determination of the geodetic arc of that distance. Schumacher asked Gauss to continue this work further to the south and said he could find support for this project directly from the government of Hanover. Finally in May 1820, King George IV gave the order to Gauss.

Gauss and Schumacher had yet determined some angles between Lüneburg, Hamburg, and Lauenburg for the geodetic connection in October 1818. During the summers of 1821 until 1825 Gauss directed the triangulation personally, that reached from Thuringia in the south to the river Elbe in the north. The triangel between Hoher Hagen, Großer Inselsberg in the Thuringian Forest, and Brocken in the Harz mountains was the largest one Gauss had ever measured with a maximum side of . In the thin populated Lüneburg Heath, without significant natural summits or artificial buildings, he had difficulties to find suitable triangulation points, sometimes cutting lanes through the vegetation was necessary or even the erection of signal towers.

For pointing signals, Gauss invented a new instrument with movable mirrors and a small telescope that reflects the sunbeams to the triangulation points, and named it "heliotrope". Another suitable construction for the same purpose was a sextant with an additional mirror which he named "vice heliotrope". Gauss got assistance by soldiers of the Hanoveran army, among them his eldest son Joseph. Gauss took part in the baseline measurement (Braak Base Line) of Schumacher in the village Braake= near Hamburg in 1820, and used the result for the evaluation of his triangulation.

The arc measurement needed a precise astronomical determination of two points in the network. Gauss and Schumacher used the favourite occasion that both observatories in Göttingen and in Altona, in the garden of Schumacher's house, laid nearly in the same longitude. The latitude was measured with both their own instruments and a zenith sector of Ramsden that was transported to both observatories.

An additional result was a better value of flattening of the approximative earth ellipsoid. Gauss developed the universal transverse Mercator projection of the ellipsoidal shaped earth (what he named "conform projection") for representing geodetical data in plane charts.

When the arc measurement was finished, Gauss intended the enlargement of the triangulation to the west to get a survey of the whole Kingdom of Hanover. The practical work was directed by three army officers, among them Lieutenant Joseph Gauss. The complete data evaluation laid in the hands of Carl Friedrich Gauss, who applied his mathematical inventions as the method of least squares and his elimination method to it. The project was finished in 1844, but Gauss did not publish a final report of the project and his method of projection; this work was not done until 1866.

In 1828, when studying differences in latitude, Gauss first defined a physical approximation for the figure of the Earth as the surface everywhere perpendicular to the direction of gravity; later his doctoral student Johann Benedict Listing called this the "geoid".

The geodetic survey of Hanover fueled Gauss' interest in differential geometry and topology, fields of mathematics dealing with curves and surfaces. This led him in 1828 to the publication of a memoir that marks the birth of modern differential geometry of surfaces, as it departed from the traditional ways of treating surfaces as cartesian graphs of functions of two variables, and instead pioneered a revolutionary approach that initiated the exploration of surfaces from the "inner" point of view of a two-dimensional being constrained to move on it. Its crowning result, the Theorema Egregium ("remarkable theorem"), established a property of the notion of Gaussian curvature. Informally, the theorem says that the curvature of a surface can be determined entirely by measuring angles and distances on the surface. That is, curvature does not depend on how the surface might be embedded in 3-dimensional space or 2-dimensional space.

The Theorema Egregium leads to the abstraction of surfaces as doubly-extended manifolds - it makes clear the distinction between the intrinsic properties of the manifold (the metric) and its physical realization (the embedding) in ambient space. A consequence is the impossibility of an isometric transformation between surfaces of different Gaussian curvature. This means practically that a sphere or an ellipsoid cannot be transformed to a plane without distortion, what causes a fundamental problem in designing projections for geographical maps.

An additional significant portion of his essay is dedicated to a profound study of geodesics. In particular, Gauss proves the local Gauss-Bonnet theorem on geodesic triangles, and generalizes Legendre's theorem on spherical triangles to geodesic triangles on arbitrary surfaces with continuous curvature; he found that the angles of a "sufficiently small" geodesic triangle deviate from that of a planar triangle of the same sides in a way that depends only on the values of the surface curvature at the vertices of the triangle - regardless of the behaviour of the surface in the triangle interior.

One key differential geometric conception was lacking from Gauss's memoir, that of geodesic curvature. However, his posthumous papers show that this notion did not escape his mind, and in the years of composing his memoir he also wrote up a manuscript in which he introduced it and referred to it as "side curvature" (in German: "Seitenkrümmung"). More importantly, he proved its invariance under isometric transformations, a result later obtained by Ferdinand Minding. Based on this evidence and the announcement in his memoir of further investigations on the curvature integral, it is very likely that he knew the more general version of the Gauss-Bonnet theorem proved by Pierre Ossian Bonnet in 1848, which is closer in spirit to the global version of this theorem.

In the lifetime of Gauss a vivid discussion on Euclid‘s parallel axiom was going on. Numerous mathematicians made efforts to prove it, whereas some of them discussed the possibility of geometrical systems without it. Gauss himself was only interested in the geometrical aspects of the physical space, but did not care about the philosophical aspects of an enlarged geometry. In 1816, he gave his first short public comment on this matter in a book review, and in the follwing time he occasionally made some remarks in letters to his correspondents. He is the one who coined the term "non-Euclidean geometry".

Not until Lobachevsky (1829) and Janos Bolyai (1832) had published their ideas of a non-Euclidean geometry – for the first time in history of mathematics – , Gauss himself put down his ideas, but avoided any influence to the contemporary scientific discussion, because he did not publish about it. Gauss commended the ideas of Janos Bolyai in a letter to his father, claiming that these were congruent to his own thoughts since some decades. But it is not clear to what extent he preceded Lobachevsky and Bolyai, for he gave only vague and obscure remarks on it in his letters.

Sartorius mentioned it first in 1856, but only the edition of left papers in Volume VIII of his Collected Works (1900) showed Gauss's own progress on that matter, at a time when Non-Euclidean geometry had yet grown out of controversial discussion.

In 1854, Gauss selected the topic for Bernhard Riemann's inaugural lecture from three proposals. On the way home from Riemann's lecture, Weber reported that Gauss was full of praise and excitement.

One of the lesser known aspects of Gauss's work is that he was also an early pioneer of topology, or as it was called in his lifetime, "Geometria Situs". His first proof of the fundamental theorem of the algebra contained an essentially topological argument; fifty years later, he further developed the topological argument in his fourth proof of this theorem (in 1849).

His earliest "serious" encounter with topological notions occurred to him in the course of his astronomical work, and in a small article from 1804 he determined the limits of the region on the celestial sphere in which comets and asteroids might appear, region which he termed "Zodiacus". He determined this region, and observed that if the Earth's and comet's orbits are linked, then by topological reasons the Zodiacus is the entire sphere. In 1848, in the context of the discovery of the asteroid 7 Iris, he published another short article in which he further elaborated the qualitative discussion of the Zodiacus.

From Gauss's letters during the period of 1820–1830, one can learn that he thought intensively on topics with close affinity to Geometria Situs, and became gradually conscious of semantic difficulty in this field. Fragments from this period reveal that he tried to classify "Tractfigurens", which are closed plane curves with a finite number of transverse self-intersections, that may also be planar projections of knots. To do so he devised a symbolical scheme, the Gauss code, that in a sense captured the characteristic features of tract figures.

In a fragment from 1833, Gauss defined the linking number of two space curves by a certain double integral, and in doing so provided for the first time an analytical formulation of a topological phenomenon. In the same note, he lamented on the little progress made in Geometria Situs, and remarked that one of its central problems will be "to count the intertwinings of two closed or infinite curves". His notebooks from that period reveal that he was also thinking about other topological objects such as braids and tangles.

In his later years Gauss held the emerging field of topology in a very high esteem and expected great future developments for it, but since there is so few written material by Gauss from this period, his influence was made mainly through occasional remarks and oral communications. For example, an indirect report by Mobius referred to a surface constructed by Gauss, which Gauss called "double ring" and sayed something about its connectivity properties. This report is consistent with a fragment of Gauss, written around 1840, which sketched a theory of the order of connectivity of surfaces. Listing expressed his indebtness to Gauss's influence in the introduction of his book ""Vorstudien zur Topologie"" (1847).

Gauss's work did not only initiate significant mathematical theories, as he was also the author of many little "gems" in mathematics, especially in elementary geometry and algebra. In his way, he helped spread the new mathematical ideas of his time by demonstrating how they illuminate and shorten the solution of small mathematical problems.

For example, he was a vivid spirit in applying complex numbers to various problems, and used them in his work on perspective and projective geometry: in a short 1836 note on "Projections of the Cube", he stated the fundamental theorem of axonometry, which tells how to represent a 3D cube on a 2D plane with complete accuracy, via complex numbers. In an unpublished 1819 note entitled "the Sphere", he conceived of the complex plane extended by a point at infinity as the stereographic projection of a sphere (the Riemann sphere), and described rotations of this sphere as the action of certain linear fractional transformations on the extended complex plane.

Gauss seems to have in his foresight the algebraic system of quaternions, the later discovery of the William Rowan Hamilton. In 1819, Gauss drafted an unpublished short treatise on "Rotations of Space", in which he elaborated on the use of quadruples of real numbers (of which he called "scales") to describe 3D rotations.

In elementary geometry, he contributed his solution to the problem of constructing the largest-area ellipse that can be inscribed in a given quadrilateral, which was published in 1810 as an addition to Schumacher's translation of Lazare Carnot's treatise "Géométrie de position". He discovered a surprising result about the computation of area of pentagons. He made many contributions to spherical geometry, and in this context solved some practical problems about navigation by stars.

One of his investigations was concerned with John Napier's "Pentagramma mirificum" - a certain spherical pentagram whose properties intrigued and occupied Gauss's mind for several decades. In his studies of the Pentagramma he approached it from various points of view, and gradually gained a full understanding of its geometric, algebraic and analytic aspects. In particular, in 1843 he stated and proved several theorems connecting elliptic functions, Napier spherical pentagons and Poncelet pentagons in the plane.

Gauss' interest in magnetism is obvious since the first decennium of the 19th century. Since 1826, when Alexander von Humboldt visited him in Göttingen, both scientists began intensive research on geomagnetism, partly independent, partly in productive cooperation. In 1828, Gauss was Humboldt's personal guest during the conference of the Society of German Natural Scientists and Physicians in Berlin, where he got acquaintance with the physicist Wilhelm Weber.

When Weber got the chair for physics in Göttingen as successor of Johann Tobias Mayer by Gauss' recommendation in 1831, both of them started a fruitful collaboration, leading to a new knowledge of magnetism with a representation for the unit of magnetism in terms of mass, charge, and time. They founded the "Magnetic Association" (German: "Magnetischer Verein"), an international working group of several observatories, which supported measurements of Earth's magnetic field in many regions of the world with equal methods at arranged dates in the years 1836 to 1841. In 1836, Humboldt was helpful to organize the worldwide spread of observatories including the British dominions with a letter to the Duke of Sussex, then president of the Royal Society, wherein he asked for support for a program of global research based on Gauss' methods. Together with other instigators, this led to a global programm known as "Magnetical crusade" under directory of Edward Sabine. The dates, times, and intervalls of observations were determined in advance, the "Göttingen mean time" was used as standard. Finally 61 stations participated in this global program. Gauss and Weber founded a series for the publication of the results, six volumes were edited between 1837 and 1843. Weber's departure to Leipzig in 1843 as late effect of the Göttingen Seven affair marked the end of Magnetic Assiciation activity.

Following Humboldt's example, Gauss ordered a magnetic observatory to be built in the garden of his observatory, but both scientists differed over instrumental equipment; Gauss preferred stationary instruments, which he thought to give more precise results, whereas Humboldt was accustomed to movable instruments. Gauss was interested in the temporal and spatial variation of magnetic declination, inclination, and intensity, but discriminated Humboldt's concept of magnetic intensity to the terms of "horizontal" and "vertical" intensity. Together with Weber, he developed methods of measuring the components of intensity of the magnetic field, and constructed a suitable magnetometer to measure "absolute values" of the strength of the Earth's magnetic field, not more relative ones that depended on the apparatus. The precision of the magnetometer was about ten times higher than of previous instruments. With this work, Gauss was the first one who derived a non-mechanical quantity by basic mechanical quantities.

Gauss carried out a "General Theory of Terrestrial Magnetism" (1839), in what he believed to describe the nature of magnetic Force; following Felix Klein, this work is actually a presentation of observations by use of spherical harmonics rather than a physical theory. The theory predicted the existence of exactly two magnetic poles on the earth, thus Hansteen's idea of four magnetic poles became obsolete, and the data allowed to determine their location with rather good precision. In his "General theorems concerning the attractive and repulsive forces acting in reciprocal proportions of quadratic distances" (1840) Gauss gave the baseline of a theory of the magnetic potential, based on Lagrange, Laplace, and Poisson; it seems rather unlikely that he had knowledge of the previous works of George Green on this subject. However, Gauss could never give any reasons for magnetism, nor a theory of magnetism similar to Newton's work on gravitation, that enabled scientists to predict geomagnetic effects in the future.

Gauss got influence on the begin of geophysics in Russia, when Adolph Theodor Kupffer, one of his former students, founded a magnetic observatory in St. Petersburg, following the eample of the observatory in Götttingen, and similar Ivan Simonov in Kazan.

The discoveries of Hans Christian Ørsted on electromagnetism and Michael Faraday on electromagnetic induction drew Gauss' attention to these matters. Gauss and Weber found the rules for branched electric circuits, later benamed as Kirchhoff's circuit laws, and made inquiries on electromagnetism. They constructed the first electromechanical telegraph in 1833, and Weber himself connected the observatory with the institute for physics in the town centre of Göttingen, but they did not care for any further development of this invention with regard to commercial purposes.

Gauss's main theoretical interests in electromagnetism were reflected in his attempts to formulate quantitive laws governing electromagnetic induction. In his notebooks from these years, he recorded several innovative formulations; he discovered the idea of vector potential function (independently rediscovered by Franz Ernst Neumann in 1845), and in January 1835 he wrote down an "induction law" equivalent to Faraday's law, which stated that the electromotive force at a given point in space is equal to the instantaneous rate of change (with respect to time) of this function.

In the same year Gauss had an insightful speculative thought, according to which electromagnetic interaction between two electric charges propagates in space in finite speed, in a manner similar to light, and that the magnitude of this interaction might depend on their relative velocity. In this way, he refuted the notion of immediate action at a distance. In unpublished fragments and in an 1845 letter to Weber, Gauss attempted to unite electricity and magnetism by forming a single expression for the interaction between two charges in relative motion, from which both Coulomb's law and the effects of magnetism could be derived.

His unpublished insights in these directions eventually merged into Weber electrodynamics, a theory that became obsolete today due to some essential difficulties to reconcile it with the undisputed Maxwell's theory. Despite its incorrectness, the Gauss-Weber theory contained some of the germs of later ideas, such as the existence of an electromagnetic field that is in some sense independent of its point sources (Faraday's view), as well as the notion of retarded potential.

Instrument maker Johann Georg Repsold in Hamburg asked Gauss in 1807 for help to construct an achromatic lens system. Based on Gauss' calculations, Repsold succeeded with a new objective in 1810. A main problem, among other difficulties, was the non precise knowledge of the refractive index and dispersion of the used glass types. In a short article from 1817 Gauss dealt with the problem of removal of chromatic aberration in double lenses, and made calculations about adjustments of the shape and coefficients of refraction required to minimize it. His work was noted by the optician Carl August von Steinheil, who in 1860 indroduced the achromatic Steinheil doublet, based in part on Gauss's calculations. Many results in geometrical optics are scattered in Gauss's correspondences and handnotes.
In his influential "Dioptrical Investigations" (1840), Gauss gave the first systematic analysis on the formation of images under a paraxial approximation (Gaussian optics). Gauss demonstrated, that under a paraxial approximation an optical system can be characterized by its cardinal points, and he derived the Gaussian lens formula, applicable without restrictions in respect to the thickness of the lenses.

Gauss' first and last business in mechanics concerned the earth's rotation. When his university friend Benzenberg carried out experiments to determine the deviation of falling masses from the perpendicular in 1802, what today is known as an effect of the Coriolis force, he asked Gauss for a theory based calculation of the values for comparison with the experimental ones. Gauss elaborated a system of fundamental equations for the motion, and his results correspondent sufficiently with Benzenberg's data, who published Gauss' considerations as appendix to his book on falling experiments.

After Foucault had demonstrated his pendulum in public in 1851, Gerling questioned Gauss for further explanations. This instigated Gauss to design a new apparatus for demonstration with a much shorter length of pendulum than Foucault's one. The oscillations were observed with a reading telescope, with a vertical scale and a mirror fastened at the pendulum; the time of oscillation was 3.1 seconds. It is described in the Gauss–Gerling correspondence, and Weber made some experiments with this obviously working apparatus in 1853, but no data were published.

Gauss's principle of least constraint of 1829 was established as a general concept to overcome the division of mechanics into statics and dynamics, combining D'Alembert's principle with Lagrange's principle of Virtual Work, and showing analogies to the method of least squares.

In 1828, Gauss was appointed to head of a Board for weights and measures of the Kingdom of Hanover. He provided the creation of standards of length and measures. Gauss himself took care of the time-consuming measures and gave detailed orders for the mechanical preparation. In his correspondence with Schumacher, who was also working on this matter, he described new ideas for scales of high precision. He gave his final reports on the Hanoveran foot and pound to the government in 1841. This work got more than regional importance by the order of a law of 1836, that connected the Hanoveran measures with the English ones.

Several stories of his early genius have been reported. Carl Friedrich Gauss' mother had never recorded the date of his birth, remembering only that he had been born on a Wednesday, eight days before the Feast of the Ascension, which occurs 39 days after Easter. Gauss later solved this puzzle about his birthdate in the context of finding the date of Easter, deriving methods to compute the date in both past and future years. Gauss felt sorry for his new born daughter Wilhelmine, because she was born on the leap day in 1808 and thus would celebrate her birthday only every four years.

In his memorial on Gauss, Wolfgang Sartorius von Waltershausen tells a story about the three-years-aged Gauss, who corrected a math error his father made. The most popular story, also told by Sartorius, tells of a school exercise: the teacher, J.G. Büttner, and his assistant, Martin Bartels, ordered students to add an arithmetic series. Out of about a hundred pupils, Gauss was the first to solve the problem correctly by a significant margin. Although (or because) Sartorius gave no details, in the course of time many versions of this story have been created, with more and more details regarding the nature of the seriesthe most frequent being the classical problem of adding together all the integers from 1 to 100and the circumstances in the classroom.

Gauss' favorite English author was Walter Scott; when he sometimes read the words "the moon rises broad in the nord west", he was very amused.

The first membership of a scientific society was given to Gauss in 1802 by the Russian Academy of Sciences. Further memberships (corresponding, foreign or full) were from the Academy of Sciences in Göttingen (1802/ 1807), the French Academy of Sciences (1804/ 1820), the Royal Society of London (1804), the Royal Prussian Academy in Berlin (1810), the National Academy of Science in Verona (1810), the Royal Society of Edinburgh (1820), the Bavarian Academy of Sciences of Munich (1820), the Royal Danish Academy in Copenhagen (1821), the Royal Astronomical Society in London (1821), the Royal Swedish Academy of Sciences (1821), the American Academy of Arts and Sciences in Boston (1822), the Royal Bohemian Society of Sciences in Prague (1833), the Royal Academy of Science, Letters and Fine Arts of Belgium (1841/ 1845), the Royal Society of Sciences in Uppsala (1843), the Royal Irish Academy in Dublin (1843), the Royal Institute of the Netherlands (1845/ 1851), the Spanish Royal Academy of Sciences in Madrid (1850), the Russian Geographical Society (1851), the Imperial Academy of Sciences in Vienna (1848), the American Philosophical Society (1853), the Cambridge Philosophical Society, and the Royal Hollandish Society of Sciences in Haarlem.

Gauss was an honorary member of the University of Kazan and of the Philosophy Faculty of the University of Prague since 1849.

Gauss received the Lalande Prize from the French Academy of Science in 1809 for the theory of planets and the means of determining their orbits from only three observations, the Danish Academy of Science prize in 1823 for "his study of angle-preserving maps", and the Copley Medal from the Royal Society in 1838 for "his inventions and mathematical researches in magnetism".

Gauss was appointed Knight of the French Legion of Honour in 1837 and was one of the first members of the Prussian Order Pour le Merite (Civil class) when it was established in 1842. He received the Order of the Crown of Westphalia (1810), the Danish Order of the Dannebrog (1817), the Hanoverian Royal Guelphic Order (1815), the Swedish Order of the Polar Star (1844), the Order of Henry the Lion (1849), and the Bavarian Maximilian Order for Science and Art (1853).

The Kings of Hanover appointed him the honorary titles "Hofrath" (1816) and "Geheimer Hofrath" (1845). On the occasion of his golden doctor degree jubilee he got the honorary citizenship of both towns of Brunswick and Göttingen in 1849. Soon after his death a medal was issued by order of King George V of Hanover with the back side inscription : "GEORGIVS V REX HANNOVERAE MATHEMATICORVM PRINCIPI" and the circumscription : "ACADEMIAE SVAE GEORGIAE AVGVSTAE DECORI AETERNO".

The ″Gauss-Gesellschaft Göttingen″ ("Gauss Society") was founded in 1964 for researches on life and work of Carl Friedrich Gauss and related persons and edits the ″Mitteilungen der Gauss-Gesellschaft″ ("Communications of the Gauss Society").





The Göttingen Academy of Sciences and Humanities provides a complete collection of the yet known letters from and to Carl Friedrich Gauss that is accessible online. The literary estate is kept and provided by the Göttingen State and University Library. Written estate from Carl Friedrich Gauss and family members can also be found in the municipal archive of Brunswick.




Cornish language

Cornish (Standard Written Form: or ; ) is a Southwestern Brittonic language of the Celtic language family. It is a revived language, having become extinct as a living community language in Cornwall at the end of the 18th century. However, knowledge of Cornish, including speaking ability to a certain extent, continued to be passed on within families and by individuals, and a revival began in the early 20th century. The language has a growing number of second-language speakers, and a very small number of families now raise children to speak revived Cornish as a first language. Cornish is currently recognised under the European Charter for Regional or Minority Languages, and the language is often described as an important part of Cornish identity, culture and heritage.

Along with Welsh and Breton, Cornish is descended from the Common Brittonic language spoken throughout much of Great Britain before the English language came to dominate. For centuries, until it was pushed westwards by English, it was the main language of Cornwall, maintaining close links with its sister language Breton, with which it was mutually intelligible, perhaps even as long as Cornish continued to be spoken as a vernacular. Cornish continued to function as a common community language in parts of Cornwall until the mid 18th century. There is some evidence of knowledge of the language persisting into the 19th century, possibly almost overlapping the beginning of revival efforts.

A process to revive the language began in the early 20th century, and in 2010, UNESCO announced that its former classification of the language as "extinct" was "no longer accurate." Since the revival of the language, some Cornish textbooks and works of literature have been published, and an increasing number of people are studying the language. Recent developments include Cornish music, independent films, and children's books. A small number of people in Cornwall have been brought up to be bilingual native speakers, and the language is taught in schools and appears on street nameplates. The first Cornish-language day care opened in 2010.

Cornish is a Southwestern Brittonic language, a branch of the Insular Celtic section of the Celtic language family, which is a sub-family of the Indo-European language family. Brittonic also includes Welsh, Breton, Cumbric and possibly Pictish, the last two of which are extinct. Scottish Gaelic, Irish and Manx are part of the separate Goidelic branch of Insular Celtic.

Joseph Loth viewed Cornish and Breton as being two dialects of the same language, claiming that "Middle Cornish is without doubt closer to Breton as a whole than the modern Breton dialect of Quiberon [] is to that of Saint-Pol-de-Léon []." Also, Kenneth Jackson argued that it is almost certain that Cornish and Breton would have been mutually intelligible as long as Cornish was a living language, and that Cornish and Breton are especially closely related to each other and less closely related to Welsh.

Cornish evolved from the Common Brittonic spoken throughout Britain south of the Firth of Forth during the British Iron Age and Roman period. As a result of westward Anglo-Saxon expansion, the Britons of the southwest were separated from those in modern-day Wales and Cumbria, which Jackson links to the defeat of the Britons at the Battle of Deorham in about 577. The western dialects eventually evolved into modern Welsh and the now extinct Cumbric, while Southwestern Brittonic developed into Cornish and Breton, the latter as a result of emigration to parts of the continent, known as Brittany over the following centuries.

The area controlled by the southwestern Britons was progressively reduced by the expansion of Wessex over the next few centuries. During the Old Cornish () period (800–1200), the Cornish-speaking area was largely coterminous with modern-day Cornwall, after the Saxons had taken over Devon in their south-westward advance, which probably was facilitated by a second migration wave to Brittany that resulted in the partial depopulation of Devon.

The earliest written record of the Cornish language comes from this period: a 9th-century gloss in a Latin manuscript of by Boethius, which used the words . The phrase may mean "it [the mind] hated the gloomy places", or alternatively, as Andrew Breeze suggests, "she hated the land". Other sources from this period include the "Saints' List", a list of almost fifty Cornish saints, the Bodmin manumissions, which is a list of manumittors and slaves, the latter with mostly Cornish names, and, more substantially, a Latin-Cornish glossary (the or Cottonian Vocabulary), a Cornish translation of Ælfric of Eynsham's Latin-Old English Glossary, which is thematically arranged into several groups, such as the Genesis creation narrative, anatomy, church hierarchy, the family, names for various kinds of artisans and their tools, flora, fauna, and household items. The manuscript was widely thought to be in Old Welsh until the 18th century when it was identified as Cornish by Edward Lhuyd. Some Brittonic glosses in the 9th-century colloquy were once identified as Old Cornish, but they are more likely Old Welsh, possibly influenced by a Cornish scribe. No single phonological feature distinguishes Cornish from both Welsh and Breton until the beginning of the assibilation of dental stops in Cornish, which is not found before the second half of the eleventh century, and it is not always possible to distinguish Old Cornish, Old Breton, and Old Welsh orthographically.

The Cornish language continued to flourish well through the Middle Cornish () period (1200–1600), reaching a peak of about 39,000 speakers in the 13th century, after which the number started to decline. This period provided the bulk of traditional Cornish literature, and was used to reconstruct the language during its revival. Most important is the , a cycle of three mystery plays, , and . Together these provide about 8,734 lines of text. The three plays exhibit a mixture of English and Brittonic influences, and, like other Cornish literature, may have been written at Glasney College near Penryn. From this period also are the hagiographical dramas ("The Life of Meriasek") and ("The Life of Ke"), both of which feature as an antagonist the villainous and tyrannical King Tewdar (or Teudar), a historical medieval king in Armorica and Cornwall, who, in these plays, has been interpreted as a lampoon of either of the Tudor kings Henry VII or Henry VIII.

Others are the "Charter Fragment", the earliest known continuous text in the Cornish language, apparently part of a play about a medieval marriage, and ("The Passion of Our Lord"), a poem probably intended for personal worship, were written during this period, probably in the second half of the 14th century. Another important text, the , was realized to be Cornish in 1949, having previously been incorrectly classified as Welsh. It is the longest text in the traditional Cornish language, consisting of around 30,000 words of continuous prose. This text is a late 16th century translation of twelve of Bishop Bonner's thirteen homilies by a certain John Tregear, tentatively identified as a vicar of St Allen from Crowan, and has an additional catena, Sacrament an Alter, added later by his fellow priest, Thomas Stephyn. In the reign of Henry VIII, an account was given by Andrew Boorde in his 1542 . He states, ""

When Parliament passed the Act of Uniformity 1549, which established the 1549 edition of the English Book of Common Prayer as the sole legal form of worship in England, including Cornwall, people in many areas of Cornwall did not speak or understand English. The passing of this Act was one of the causes of the Prayer Book Rebellion (which may also have been influenced by the retaliation of the English after the failed Cornish Rebellion of 1497), with "the commoners of Devonshyre and Cornwall" producing a manifesto demanding a return to the old religious services and included an article that concluded, "and so we the Cornyshe men (whereof certen of us understande no Englysh) utterly refuse thys newe Englysh." In response to their articles, the government spokesman (either Philip Nichols or Nicholas Udall) wondered why they did not just ask the king for a version of the liturgy in their own language. Archbishop Thomas Cranmer asked why the Cornishmen should be offended by holding the service in English, when they had before held it in Latin, which even fewer of them could understand. Anthony Fletcher points out that this rebellion was primarily motivated by religious and economic, rather than linguistic, concerns. The rebellion prompted a heavy-handed response from the government, and 5,500 people died during the fighting and the rebellion's aftermath. Government officials then directed troops under the command of Sir Anthony Kingston to carry out pacification operations throughout the West Country. Kingston subsequently ordered the executions of numerous individuals suspected of involvement with the rebellion as part of the post-rebellion reprisals.

The rebellion eventually proved a turning-point for the Cornish language, as the authorities came to associate it with sedition and "backwardness". This proved to be one of the reasons why the Book of Common Prayer was never translated into Cornish (unlike Welsh), as proposals to do so were suppressed in the rebellion's aftermath. The failure to translate the Book of Common Prayer into Cornish led to the language's rapid decline during the 16th and 17th centuries. Peter Berresford Ellis cites the years 1550–1650 as a century of immense damage for the language, and its decline can be traced to this period. In 1680 William Scawen wrote an essay describing 16 reasons for the decline of Cornish, among them the lack of a distinctive Cornish alphabet, the loss of contact between Cornwall and Brittany, the cessation of the miracle plays, loss of records in the Civil War, lack of a Cornish Bible and immigration to Cornwall. Mark Stoyle, however, has argued that the 'glotticide' of the Cornish language was mainly a result of the Cornish gentry adopting English to dissociate themselves from the reputation for disloyalty and rebellion associated with the Cornish language since the 1497 uprising.

By the middle of the 17th century, the language had retreated to Penwith and Kerrier, and transmission of the language to new generations had almost entirely ceased. In his "Survey of Cornwall", published in 1602, Richard Carew writes:[M]ost of the inhabitants can speak no word of Cornish, but very few are ignorant of the English; and yet some so affect their own, as to a stranger they will not speak it; for if meeting them by chance, you inquire the way, or any such matter, your answer shall be, "," "I [will] speak no Saxonage."
The Late Cornish () period from 1600 to about 1800 has a less substantial body of literature than the Middle Cornish period, but the sources are more varied in nature, including songs, poems about fishing and curing pilchards, and various translations of verses from the Bible, the Ten Commandments, the Lord's Prayer and the Creed. Edward Lhuyd's "Archaeologia Britannica", which was mainly recorded in the field from native speakers in the early 1700s, and his unpublished field notebook are seen as important sources of Cornish vocabulary, some of which are not found in any other source. "Archaeologia Britannica" also features a complete version of a traditional folk tale, "John of Chyanhor", a short story about a man from St Levan who goes far to the east seeking work, eventually returning home after three years to find that his wife has borne him a child during his absence.

In 1776, William Bodinar, who describes himself as having learned Cornish from old fishermen when he was a boy, wrote a letter to Daines Barrington in Cornish, with an English translation, which was probably the last prose written in the traditional language. In his letter, he describes the sociolinguistics of the Cornish language at the time, stating that there are no more than four or five old people in his village who can still speak Cornish, concluding with the remark that Cornish is no longer known by young people. However, the last recorded traditional Cornish literature may have been the "Cranken Rhyme", a corrupted version of a verse or song published in the late 19th century by John Hobson Matthews, recorded orally by John Davey (or Davy) of Boswednack, of uncertain date but probably originally composed during the last years of the traditional language. Davey had traditional knowledge of at least some Cornish. John Kelynack (1796–1885), a fisherman of Newlyn, was sought by philologists for old Cornish words and technical phrases in the 19th century.

It is difficult to state with certainty when Cornish ceased to be spoken, due to the fact that its last speakers were of relatively low social class and that the definition of what constitutes "a living language" is not clear cut. Peter Pool argues that by 1800 nobody was using Cornish as a daily language and no evidence exists of anyone capable of conversing in the language at that date. However, passive speakers, semi-speakers and rememberers, who retain some competence in the language despite not being fluent nor using the language in daily life, generally survive even longer.

The traditional view that Dolly Pentreath (1692–1777) was the last native speaker of Cornish has been challenged, and in the 18th and 19th centuries there was academic interest in the language and in attempting to find the last speaker of Cornish. It has been suggested that, whereas Pentreath was probably the last "monolingual" speaker, the last "native" speaker may have been John Davey of Zennor, who died in 1891. However, although it is clear Davey possessed some traditional knowledge in addition to having read books on Cornish, accounts differ of his competence in the language. Some contemporaries stated he was able to converse on certain topics in Cornish whereas others affirmed they had never heard him claim to be able to do so. Robert Morton Nance, who reworked and translated Davey's Cranken Rhyme, remarked, "There can be no doubt, after the evidence of this rhyme, of what there was to lose by neglecting John Davey."

The search for the last speaker is hampered by a lack of transcriptions or audio recordings, so that it is impossible to tell from this distance whether the language these people were reported to be speaking was Cornish, or English with a heavy Cornish substratum, nor what their level of fluency was. Nevertheless this academic interest, along with the beginning of the Celtic Revival in the late 19th century, provided the groundwork for a Cornish language revival movement.

Notwithstanding the uncertainty over who was the last speaker of Cornish, researchers have posited the following numbers for the prevalence of the language between 1050 and 1800.

In 1904, the Celtic language scholar and Cornish cultural activist Henry Jenner published "A Handbook of the Cornish Language". The publication of this book is often considered to be the point at which the revival movement started. Jenner wrote about the Cornish language in 1905, "one may fairly say that most of what there was of it has been preserved, and that it has been continuously preserved, for there has never been a time when there were not some Cornishmen who knew some Cornish."

The revival focused on reconstructing and standardising the language, including coining new words for modern concepts, and creating educational material in order to teach Cornish to others. In 1929 Robert Morton Nance published his Unified Cornish () system, based on the Middle Cornish literature while extending the attested vocabulary with neologisms and forms based on Celtic roots also found in Breton and Welsh, publishing a dictionary in 1938. Nance's work became the basis of revived Cornish () for most of the 20th century. During the 1970s, criticism of Nance's system, including the inconsistent orthography and unpredictable correspondence between spelling and pronunciation, as well as on other grounds such as the archaic basis of Unified and a lack of emphasis on the spoken language, resulted in the creation of several rival systems. In the 1980s, Ken George published a new system, ('Common Cornish'), based on a reconstruction of the phonological system of Middle Cornish, but with an approximately morphophonemic orthography. It was subsequently adopted by the Cornish Language Board and was the written form used by a reported 54.5% of all Cornish language users according to a survey in 2008, but was heavily criticised for a variety of reasons by Jon Mills and Nicholas Williams, including making phonological distinctions that they state were not made in the traditional language 1500, failing to make distinctions that they believe "were" made in the traditional language at this time, and the use of an orthography that deviated too far from the traditional texts and Unified Cornish. Also during this period, Richard Gendall created his Modern Cornish system (also known as Revived Late Cornish), which used Late Cornish as a basis, and Nicholas Williams published a revised version of Unified; however neither of these systems gained the popularity of Unified or Kemmyn.

The revival entered a period of factionalism and public disputes, with each orthography attempting to push the others aside. By the time that Cornish was recognised by the UK government under the European Charter for Regional or Minority Languages in 2002, it had become recognised that the existence of multiple orthographies was unsustainable with regards to using the language in education and public life, as none had achieved a wide consensus. A process of unification was set about which resulted in the creation of the public-body Cornish Language Partnership in 2005 and agreement on a Standard Written Form in 2008. In 2010 a new milestone was reached when UNESCO altered its classification of Cornish, stating that its previous label of "extinct" was no longer accurate.

Speakers of Cornish reside primarily in Cornwall, which has a population of 563,600 (2017 estimate). There are also some speakers living outside Cornwall, particularly in the countries of the Cornish diaspora, as well as in other Celtic nations. Estimates of the number of Cornish speakers vary according to the definition of a speaker, and is difficult to determine accurately due to the individualised nature of language take-up. Nevertheless, there is recognition that the number of Cornish speakers is growing. From before the 1980s to the end of the 20th century there was a sixfold increase in the number of speakers to around 300. One figure for the number of people who know a few basic words, such as knowing that "Kernow" means "Cornwall", was 300,000; the same survey gave the number of people able to have simple conversations as 3,000.

The Cornish Language Strategy project commissioned research to provide quantitative and qualitative evidence for the number of Cornish speakers: due to the success of the revival project it was estimated that 2,000 people were fluent (surveyed in spring 2008), an increase from the estimated 300 people who spoke Cornish fluently suggested in a study by Kenneth MacKinnon in 2000.<ref name="BBC BBC/British Council"></ref>

Jenefer Lowe of the Cornish Language Partnership said in an interview with the BBC in 2010 that there were around 300 fluent speakers. Bert Biscoe, a councillor and bard, in a statement to the "Western Morning News" in 2014 said there were "several hundred fluent speakers". Cornwall Council estimated in 2015 that there were 300–400 fluent speakers who used the language regularly, with 5,000 people having a basic conversational ability in the language.

A report on the 2011 Census published in 2013 by the Office for National Statistics placed the number of speakers at somewhere between 325 and 625. In 2017 the ONS released data based on the 2011 Census that placed the number of speakers at 557 people in England and Wales who declared Cornish to be their main language, 464 of whom lived in Cornwall. The 2021 census listed the number of Cornish speakers at 563.

A study that appeared in 2018 established the number of people in Cornwall with at least minimal skills in Cornish, such as the use of some words and phrases, to be more than 3,000, including around 500 estimated to be fluent.

The Institute of Cornish Studies at the University of Exeter is working with the Cornish Language Partnership to study the Cornish language revival of the 20th century, including the growth in number of speakers.

In 2002, Cornish was recognized by the UK government under Part II of the European Charter for Regional or Minority Languages. UNESCO's "Atlas of World Languages" classifies Cornish as "critically endangered". UNESCO has said that a previous classification of 'extinct' "does not reflect the current situation for Cornish" and is "no longer accurate".

Cornwall Council's policy is to support the language, in line with the European Charter. A motion was passed in November 2009 in which the council promoted the inclusion of Cornish, as appropriate and where possible, in council publications and on signs. This plan has drawn some criticism. In October 2015, Cornwall Council announced that staff would be encouraged to use "basic words and phrases" in Cornish when dealing with the public. In 2021 Cornwall Council prohibited a marriage ceremony from being conducted in Cornish as the Marriage Act 1949 only allowed for marriage ceremonies in English or Welsh.

In 2014, the Cornish people were recognised by the UK Government as a national minority under the Framework Convention for the Protection of National Minorities. The FCNM provides certain rights and protections to a national minority with regard to their minority language.

In 2016, British government funding for the Cornish language ceased, and responsibility transferred to Cornwall Council.

Old Cornish

Until around the middle of the 11th century, Old Cornish scribes used a traditional spelling system shared with Old Breton and Old Welsh, based on the pronunciation of British Latin. By the time of the Vocabularium Cornicum, usually dated to around 1100, Old English spelling conventions, such as the use of thorn (Þ, þ) and eth (Ð, ð) for dental fricatives, and wynn (Ƿ, ƿ) for /w/, had come into use, allowing documents written at this time to be distinguished from Old Welsh, which rarely uses these characters, and Old Breton, which does not use them at all. Old Cornish features include using initial ⟨ch⟩, ⟨c⟩, or ⟨k⟩ for /k/, and, in internal and final position, ⟨p⟩, ⟨t⟩, ⟨c⟩, ⟨b⟩, ⟨d⟩, and ⟨g⟩ are generally used for the phonemes /b/, /d/, /ɡ/, /β/, /ð/, and /ɣ/ respectively, meaning that the results of Brittonic lenition are not usually apparent from the orthography at this time.

Middle Cornish

Middle Cornish orthography has a significant level of variation, and shows influence from Middle English spelling practices. Yogh (Ȝ ȝ) is used in certain Middle Cornish texts, where it is used to represent a variety of sounds, including the dental fricatives /θ/ and /ð/, a usage which is unique to Middle Cornish and is never found in Middle English. Middle Cornish scribes tend to use ⟨c⟩ for /k/ before back vowels, and ⟨k⟩ for /k/ before front vowels, though this is not always true, and this rule is less consistent in certain texts. Middle Cornish scribes almost universally use ⟨wh⟩ to represent /ʍ/ (or /hw/), as in Middle English. Middle Cornish, especially towards the end of this period, tends to use orthographic ⟨g⟩ and ⟨b⟩ in word-final position in stressed monosyllables, and ⟨k⟩ and ⟨p⟩ in word-final position in unstressed final syllables, to represent the reflexes of late Brittonic /ɡ/ and /b/, respectively.

Late Cornish

Written sources from this period are often spelled following English spelling conventions since many of the writers of the time had not been exposed to Middle Cornish texts or the Cornish orthography within them. Around 1700, Edward Lhuyd visited Cornwall, introducing his own partly phonetic orthography that he used in his , which was adopted by some local writers, leading to the use of some Lhuydian features such as the use of circumflexes to denote long vowels, ⟨k⟩ before front vowels, word-final ⟨i⟩, and the use of ⟨dh⟩ to represent the voiced dental fricative /ð/.

Revived Cornish

After the publication of Jenner's "Handbook of the Cornish Language", the earliest revivalists used Jenner's orthography, which was influenced by Lhuyd's system. This system was abandoned following the development by Nance of a "unified spelling", later known as Unified Cornish, a system based on a standardization of the orthography of the early Middle Cornish texts. Nance's system was used by almost all Revived Cornish speakers and writers until the 1970s. Criticism of Nance's system, particularly the relationship of spelling to sounds and the phonological basis of Unified Cornish, resulted in rival orthographies appearing by the early 1980s, including Gendal's Modern Cornish, based on Late Cornish native writers and Lhuyd, and Ken George's Kernewek Kemmyn, a mainly morphophonemic orthography based on George's reconstruction of Middle Cornish , which features a number of orthographic, and phonological, distinctions not found in Unified Cornish. Kernewek Kemmyn is characterised by the use of universal ⟨k⟩ for /k/ (instead of ⟨c⟩ before back vowels as in Unified); ⟨hw⟩ for /hw/, instead of ⟨wh⟩ as in Unified; and ⟨y⟩, ⟨oe⟩, and ⟨eu⟩ to represent the phonemes /ɪ/, /o/, and /œ/ respectively, which are not found in Unified Cornish. Criticism of all of these systems, especially Kernewek Kemmyn, by Nicolas Williams, resulted in the creation of Unified Cornish Revised, a modified version of Nance's orthography, featuring: an additional phoneme not distinguished by Nance, "ö in German schön", represented in the UCR orthography by ⟨ue⟩; replacement of ⟨y⟩ with ⟨e⟩ in many words; internal ⟨h⟩ rather than ⟨gh⟩; and use of final ⟨b⟩, ⟨g⟩, and ⟨dh⟩ in stressed monosyllables. A Standard Written Form, intended as a compromise orthography for official and educational purposes, was introduced in 2008, although a number of previous orthographic systems remain in use and, in response to the publication of the SWF, another new orthography, Kernowek Standard, was created, mainly by Nicholas Williams and Michael Everson, which is proposed as an amended version of the Standard Written Form.

The phonological system of Old Cornish, inherited from Proto-Southwestern Brittonic and originally differing little from Old Breton and Old Welsh, underwent various changes during its Middle and Late phases, eventually resulting in several characteristics not found in the other Brittonic languages. The first sound change to distinguish Cornish from both Breton and Welsh, the assibilation of the dental stops and in medial and final position, had begun by the time of the Vocabularium Cornicum, c. 1100 or earlier. This change, and the subsequent, or perhaps dialectical, palatalization (or occasional rhotacization in a few words) of these sounds, results in orthographic forms such as Middle Cornish 'father', Late Cornish (Welsh ), Middle Cornish 'believe', Late Cornish (Welsh ), and Middle Cornish 'leave', Late Cornish (Welsh ). A further characteristic sound change, pre-occlusion, occurred during the sixteenth century, resulting in the nasals and being realised as and respectively in stressed syllables, and giving Late Cornish forms such as 'head' (Welsh ) and 'crooked' (Welsh ).

As a revitalised language, the phonology of contemporary spoken Cornish is based on a number of sources, including various reconstructions of the sound system of middle and early modern Cornish based on an analysis of internal evidence such as the orthography and rhyme used in the historical texts, comparison with the other Brittonic languages Breton and Welsh, and the work of the linguist Edward Lhuyd, who visited Cornwall in 1700 and recorded the language in a partly phonetic orthography.

Cornish is a Celtic language, and the majority of its vocabulary, when usage frequency is taken into account, at every documented stage of its history is inherited direct from Proto-Celtic, either through the ancestral Proto-Indo-European language, or through vocabulary borrowed from unknown substrate language(s) at some point in the development of the Celtic proto-language from PIE. Examples of the PIE > PCelt. development are various terms related to kinship and people, including 'mother', 'aunt, mother's sister', 'sister', 'son', 'man', 'person, human', and 'people', and words for parts of the body, including 'hand' and 'tooth'. Inherited adjectives with an Indo-European etymology include 'new', 'broad, wide', 'red', 'old', 'young', and 'alive, living'.

Several Celtic or Brittonic words cannot be reconstructed to Proto-Indo-European, and are suggested to have been borrowed from unknown substrate language(s) at an early stage, such as Proto-Celtic or Proto-Brittonic. Proposed examples in Cornish include 'beer' and 'badger'.

Other words in Cornish inherited direct from Proto-Celtic include a number of toponyms, for example 'hill', 'fort', and 'land', and a variety of animal names such as 'mouse', 'wether', 'pigs', and 'bull'.

During the Roman occupation of Britain a large number (around 800) of Latin loan words entered the vocabulary of Common Brittonic, which subsequently developed in a similar way to the inherited lexicon. These include 'arm' (from British Latin ), 'net' (from ), and 'cheese' (from ).

A substantial number of loan words from English and to a lesser extent French entered the Cornish language throughout its history. Whereas only 5% of the vocabulary of the Old Cornish Vocabularium Cornicum is thought to be borrowed from English, and only 10% of the lexicon of the early modern Cornish writer William Rowe, around 42% of the vocabulary of the whole Cornish corpus is estimated to be English loan words, without taking frequency into account. (However when frequency "is" taken into account this figure for the entire corpus drops to 8%.) The many English loanwords, some of which were sufficiently well assimilated to acquire native Cornish verbal or plural suffixes or be affected by the mutation system, include 'to read', 'to understand', 'way', 'boot' and 'art'.

Many Cornish words, such as mining and fishing terms, are specific to the culture of Cornwall. Examples include 'mine waste' and 'to mend fishing nets'. and are different types of pastries. is a 'traditional Cornish dance get-together' and is a specific kind of ceremonial dance that takes place in Cornwall. Certain Cornish words may have several translation equivalents in English, so for instance may be translated into English as either 'book' or 'volume' and can mean either 'hand' or 'fist'.
As in other Celtic languages, Cornish lacks a number of verbs commonly found in other languages, including modals and psych-verbs; examples are 'have', 'like', 'hate', 'prefer', 'must/have to' and 'make/compel to'. These functions are instead fulfilled by periphrastic constructions involving a verb and various prepositional phrases.

The grammar of Cornish shares with other Celtic languages a number of features which, while not unique, are unusual in an Indo-European context. The grammatical features most unfamiliar to English speakers of the language are the initial consonant mutations, the verb–subject–object word order, inflected prepositions, fronting of emphasised syntactic elements and the use of two different forms for 'to be'.

Cornish has initial consonant mutation: The first sound of a Cornish word may change according to grammatical context. As in Breton, there are four types of mutation in Cornish (compared with three in Welsh, two in Irish and Manx and one in Scottish Gaelic). These changes apply to only certain letters (sounds) in particular grammatical contexts, some of which are given below:


Cornish has no indefinite article. can either mean 'harbour' or 'a harbour'. In certain contexts, can be used, with the meaning 'a certain, a particular', e.g. 'a certain harbour'. There is, however, a definite article 'the', which is used for all nouns regardless of their gender or number, e.g. 'the harbour'.

Cornish nouns belong to one of two grammatical genders, masculine and feminine, but are not inflected for case. Nouns may be singular or plural. Plurals can be formed in various ways, depending on the noun:


Some nouns are collective or mass nouns. Singulatives can be formed from collective nouns by the addition of the suffix ⫽-enn⫽ (SWF "-en"):


Verbs are conjugated for person, number, tense and mood. For example, the verbal noun 'see' has derived forms such as 1st person singular present indicative 'I see', 3rd person plural imperfect indicative 'they saw', and 2nd person singular imperative 'see!' Grammatical categories can be indicated either by inflection of the main verb, or by the use of auxiliary verbs such as 'be' or 'do'.

Cornish uses inflected (or conjugated) prepositions: Prepositions are inflected for person and number. For example, (with, by) has derived forms such as 'with me', 'with him', and 'with you (plural)'.

Word order in Cornish is somewhat fluid and varies depending on several factors such as the intended element to be emphasised and whether a statement is negative or affirmative. In a study on Cornish word order in the play Bewnans Meriasek (), Ken George has argued that the most common word order in main clauses in Middle Cornish was, in affirmative statements, SVO, with the verb in the third person singular:

When affirmative statements are in the less common VSO order, they usually begin with an adverb or other element, followed by an affirmative particle, with the verb inflected for person and tense:

In negative statements, the order was usually VSO, with an initial negative particle and the verb conjugated for person and tense:

A similar structure is used for questions:

Elements can be fronted for emphasis:

Sentences can also be constructed periphrastically using auxiliary verbs such as 'be, exist':

As Cornish lacks verbs such as 'to have', possession can also be indicated in this way:

Enquiring about possession is similar, using a different interrogative form of :

Nouns usually precede the adjective, unlike in English:

Some adjectives usually precede the noun, however:

The Celtic Congress and Celtic League are groups that advocate cooperation amongst the Celtic Nations in order to protect and promote Celtic languages and cultures, thus working in the interests of the Cornish language.

There have been films such as , some televised, made entirely, or significantly, in the language. Some businesses use Cornish names.

Cornish has significantly and durably affected Cornwall's place-names as well as Cornish surnames and knowledge of the language helps the understanding of these ancient meanings. Cornish names are adopted for children, pets, houses and boats.

There is Cornish literature, including spoken poetry and song, as well as traditional Cornish chants historically performed in marketplaces during religious holidays and public festivals and gatherings.

There are periodicals solely in the language, such as the monthly , and . BBC Radio Cornwall has a news broadcast in Cornish and sometimes has other programmes and features for learners and enthusiasts. Local newspapers such as the "Western Morning News" have articles in Cornish, and newspapers such as "The Packet", "The West Briton", and "The Cornishman" have also been known to have Cornish features. There is an online radio and TV service in Cornish called , publishing a one-hour podcast each week, based on a magazine format. It includes music in Cornish as well as interviews and features.

The language has financial sponsorship from sources including the Millennium Commission. A number of language organisations exist in Cornwall: (Our Language), the Cornish sub-group of the European Bureau for Lesser-Used Languages, , (the Cornish Language Board) and (the Cornish Language Fellowship).

There are ceremonies, some ancient, some modern, that use the language or are entirely in the language.

Though estimates of the number of Cornish speakers vary, there are thought to be around five hundred today. Currently Cornish is spoken at home, outside the home, in the workplace and at ritual ceremonies. Cornish is also being used in the arts.

Cornwall has had cultural events associated with the language, including the international Celtic Media Festival, hosted in St Ives in 1997. The Old Cornwall Society has promoted the use of the language at events and meetings. Two examples of ceremonies that are performed in both the English and Cornish languages are Crying the Neck and the annual mid-summer bonfires.

Since 1969, there have been three full performances of the Ordinalia, originally written in the Cornish language, the most recent of which took place at the plen-an-gwary in St Just in September 2021. While significantly adapted from the original, as well as using mostly English-speaking actors, the plays used sizable amounts of Cornish, including a character who spoke only in Cornish and another who spoke both English and Cornish. The event drew thousands over two weeks, also serving as a celebration of Celtic culture. The next production, scheduled for 2024, could, in theory, be entirely in Cornish, without English, if assisted by a professional linguist.

Outside of Cornwall, efforts to revive the Cornish language and culture through community events are occurring in Australia. A biennial festival, Kernewek Lowender, takes place in South Australia, where both cultural displays and language lessons are offered.

Cornish is taught in some schools; it was previously taught at degree level at the University of Wales, though the only existing course in the language at university level is as part of a course in Cornish studies at the University of Exeter. In March 2008 a course in the language was started as part of the Celtic Studies curriculum at the University of Vienna, Austria.
The University of Cambridge offers courses in Cornish through its John Trim Resources Centre, which is part of the university's Language Centre. In addition, the Department of Anglo-Saxon, Norse and Celtic (which is part of the Faculty of English) also carries out research into the Cornish language.

In 2015 a university-level course aiming at encouraging and supporting practitioners working with young children to introduce the Cornish language into their settings was launched. The "Cornish Language Practice Project (Early Years)" is a level 4 course approved by Plymouth University and run at Cornwall College. The course is not a Cornish-language course but students will be assessed on their ability to use the Cornish language constructively in their work with young children. The course will cover such topics as "Understanding Bilingualism", "Creating Resources" and "Integrating Language and Play", but the focus of the language provision will be on Cornish. A non-accredited specialist Cornish-language course has been developed to run alongside the level 4 course for those who prefer tutor support to learn the language or develop their skills for use with young children.

Cornwall's first Cornish-language crèche, , was established in 2010 at Cornwall College, Camborne. The nursery teaches children aged between two and five years alongside their parents to ensure the language is also spoken in the home.

A number of dictionaries are available in the various orthographies, including "A Learners' Cornish Dictionary in the Standard Written Form" by Steve Harris (ed.), by Ken George, by Nicholas Williams and "A Practical Dictionary of Modern Cornish" by Richard Gendall. Course books include the three-part series, , and , as well as the more recent and . Several online dictionaries are now available, including one organised by An Akademi Kernewek in SWF.

Classes and conversation groups for adults are available at several locations in Cornwall as well as in London, Cardiff and Bristol. Since the onset of the COVID-19 pandemic a number of conversation groups entitled have been held online, advertised through Facebook and other media. A surge in interest, not just from people in Cornwall but from all over the world, has meant that extra classes have been organised.

William Scawen produced a manuscript on the declining Cornish language that continually evolved until he died in 1689, aged 89. He was one of the first to realise the language was dying out and wrote detailed manuscripts which he started working on when he was 78. The only version that was ever published was a short first draft but the final version, which he worked on until his death, is a few hundred pages long. At the same time a group of scholars led by John Keigwin (nephew of William Scawen) of Mousehole tried to preserve and further the Cornish language and chose to write in Cornish. One of their number, Nicholas Boson, tells how he had been discouraged from using Cornish to servants by his mother. This group left behind a large number of translations of parts of the Bible, proverbs and songs. They were contacted by the Welsh linguist Edward Lhuyd, who came to Cornwall to study the language.

Early Modern Cornish was the subject of a study published by Lhuyd in 1707, and differs from the medieval language in having a considerably simpler structure and grammar. Such differences included sound changes and more frequent use of auxiliary verbs. The medieval language also possessed two additional tenses for expressing past events and an extended set of possessive suffixes.

John Whitaker, the Manchester-born rector of Ruan Lanihorne, studied the decline of the Cornish language. In his 1804 work "the Ancient Cathedral of Cornwall" he concluded that: "[T]he English Liturgy, was not desired by the Cornish, but forced upon them by the tyranny of England, at a time when the English language was yet unknown in Cornwall. This act of tyranny was at once gross barbarity to the Cornish people, and a death blow to the Cornish language."

Robert Williams published the first comprehensive Cornish dictionary in 1865, the . As a result of the discovery of additional ancient Cornish manuscripts, 2000 new words were added to the vocabulary by Whitley Stokes in "A Cornish Glossary". William C. Borlase published "Proverbs and Rhymes in Cornish" in 1866 while "A Glossary of Cornish Names" was produced by John Bannister in the same year. Frederick Jago published his "English–Cornish Dictionary" in 1882.

In 2002, the Cornish language gained new recognition because of the European Charter for Regional and Minority Languages. Conversely, along with government provision was the governmental basis of "New Public Management", measuring quantifiable results as means of determining effectiveness. This put enormous pressure on finding a single orthography that could be used in unison. The revival of Cornish required extensive rebuilding. The Cornish orthographies that were reconstructed may be considered versions of Cornish because they are not traditional sociolinguistic variations. In the middle-to-late twentieth century, the debate over Cornish orthographies angered more people because several language groups received public funding. This caused other groups to sense favouritism as playing a role in the debate.

A governmental policymaking structure called New Public Management (NPM) has helped the Cornish language by managing public life of the Cornish language and people. In 2007, the Cornish Language Partnership MAGA represents separate divisions of government and their purpose is to further enhance the Cornish Language Developmental Plan. MAGA established an Ad-Hoc Group, which resulted in three orthographies being presented. The relations for the Ad-Hoc Group were to obtain consensus among the three orthographies and then develop a "single written form". The result was creating a new form of Cornish, which had to be natural for both new learners and skilled speakers.

In 1981, the Breton library edited (Passion of our lord), a 15th-century Cornish poem. The first complete translation of the Bible into Cornish, translated from English, was published in 2011. Another Bible translation project translating from original languages is underway. The New Testament and Psalms were posted on-line on YouVersion (Bible.com) and Bibles.org in July 2014 by the Bible Society.

A few small publishers produce books in Cornish which are stocked in some local bookshops, as well as in Cornish branches of Waterstones and WH Smith, although publications are becoming increasingly available on the Internet. Printed copies of these may also be found from Amazon. The Truro Waterstones hosts the annual literary awards, established by to recognise publications relating to Cornwall or in the Cornish language. In recent years, a number of Cornish translations of literature have been published, including "Alice's Adventures in Wonderland" (2009), "Around the World in Eighty Days" (2009), "Treasure Island" (2010), "The Railway Children" (2012), "Hound of the Baskervilles" (2012), "The War of the Worlds" (2012), "The Wind in the Willows" (2013), "Three Men in a Boat" (2013), "Alice in Wonderland and Through the Looking-Glass" (2014), and "A Christmas Carol" (which won the 2012 award for Cornish Language books), as well as original Cornish literature such as "" ("The Lyonesse Stone") by Craig Weatherhill. Literature aimed at children is also available, such as ("Where's Spot?"), ("The Beast of Bodmin Moor"), three "Topsy and Tim" titles, two "Tintin" titles and ("Briallen and the Alien"), which won the 2015 award for Cornish Language books for children. In 2014 , Nicholas Williams's translation of J. R. R. Tolkien's "The Hobbit", was published.

In 1983 BBC Radio Cornwall started broadcasting around two minutes of Cornish every week. In 1987, however, they gave over 15 minutes of airtime on Sunday mornings for a programme called ('Holdall'), presented by John King, running until the early 1990s. It was eventually replaced with a five-minute news bulletin called ('The News'). The bulletin was presented every Sunday evening for many years by Rod Lyon, then Elizabeth Stewart, and currently a team presents in rotation. Pirate FM ran short bulletins on Saturday lunchtimes from 1998 to 1999. In 2006, Matthew Clarke who had presented the Pirate FM bulletin, launched a web-streamed news bulletin called ('Weekly News'), which in 2008 was merged into a new weekly magazine podcast (RanG).

Cornish television shows have included a 1982 series by Westward Television with each episode containing a three-minute lesson in Cornish. , an eight-episode series produced by Television South West and broadcast between June and July 1984, later on S4C from May to July 1985, and as a schools programme in 1986. Also by Television South West were two bilingual programmes on Cornish Culture called .
In 2016 Kelly's Ice Cream of Bodmin introduced a light hearted television commercial in the Cornish language and this was repeated in 2017.

The first episode from the third season of the US television program "Deadwood" features a conversation between miners, purportedly in the Cornish language, but really in Irish. One of the miners is then shot by thugs working for businessman George Hearst who justify the murder by saying, "He come at me with his foreign gibberish."

A number of Cornish language films have been made, including "Hwerow Hweg", a 2002 drama film written and directed by Hungarian film-maker Antal Kovacs and "Trengellick Rising", a short film written and directed by Guy Potter.

Screen Cornwall works with Cornwall Council to commission a short film in the Cornish language each year, with their FilmK competition. Their website states "FylmK is an annual contemporary Cornish language short film competition, producing an imaginative and engaging film, in any genre, from distinctive and exciting filmmakers".

A monthly half-hour online TV show began in 2017 called (The Month). It contained news items about cultural events and more mainstream news stories all through Cornish. It also ran a cookery segment called "" ('Esther's Kitchen'). The program has been out of production since March 2023.

English composer Peter Warlock wrote a Christmas carol in Cornish (setting words by Henry Jenner). The Cornish electronic musician Aphex Twin has used Cornish names for track titles, most notably on his "Drukqs" album.

Several traditional Cornish folk songs have been collected and can be sung to various tunes. These include "", "", and "".

In 2018, the singer Gwenno Saunders released an album in Cornish, entitled , saying: "I speak Cornish with my son: if you're comfortable expressing yourself in a language, you want to share it."

The Cornish language features in the toponymy of Cornwall, with a significant contrast between English place-names prevalent in eastern Cornwall and Cornish place-names to the west of the Camel-Fowey river valleys, where English place-names are much less common. Hundreds of Cornish family names have an etymology in the Cornish language, the majority of which are derived from Cornish place-names. Long before the agreement of the Standard Written Form of Cornish in the 21st century, Late Cornish orthography in the Early Modern period usually followed Welsh to English transliteration, phonetically rendering C for K, I for Y, U for W, and Z for S. This meant that place names were adopted into English with spellings such as 'Porthcurno' and 'Penzance'; they are written and in the Standard Written Form of Cornish, agreed upon in 2008. Likewise words such as ('island') can be found spelled as "" as at Ince Castle. These apparent mistransliterations can, however, reveal an insight into how names and places were actually pronounced, explaining, for example, how anglicised is still pronounced [ˈlansǝn] with emphasis on the first element, perhaps from Cornish , though the "Concise Oxford Dictionary of English Place-Names" considers this unlikely.

The following tables present some examples of Cornish place names and surnames and their anglicised versions:

From the Universal Declaration of Human Rights:

From , the Cornish anthem:

From the wrestler's oath:





Complexity theory

Complexity theory may refer to:




Charybdis

Charybdis (; , ; , ) is a sea monster in Greek mythology. She, with the sea monster Scylla, appears as a challenge to epic characters such as Odysseus, Jason, and Aeneas. Scholarship locates her in the Strait of Messina.

The idiom "between Scylla and Charybdis" has come to mean being forced to choose between two similarly dangerous situations.

The sea monster Charybdis was believed to live under a small rock on one side of a narrow channel. Opposite her was Scylla, another sea monster, that lived inside a much larger rock. The sides of the strait were within an arrow-shot of each other, and sailors attempting to avoid one of them would come in reach of the other. To be "between Scylla and Charybdis" therefore means to be presented with two opposite dangers, the task being to find a route that avoids both. Three times a day, Charybdis swallowed a huge amount of water, before belching it back out again, creating large whirlpools capable of dragging a ship underwater. In some variations of the story, Charybdis was simply a large whirlpool instead of a sea monster.

Through the descriptions of Greek mythical chroniclers and Greek historians such as Thucydides, modern scholars generally agree that Charybdis was said to have been located in the Strait of Messina, off the coast of Sicily and opposite a rock on the mainland identified with Scylla. A whirlpool does exist there, caused by currents meeting, but it is dangerous only to small craft in extreme conditions.

Another myth makes Charybdis the daughter of Poseidon and Gaia and living as a loyal servant to her father.

Charybdis aided her father Poseidon in his feud with her paternal uncle Zeus and, as such, helped him engulf lands and islands in water. Zeus, angry over the land she stole from him, sent her to the bottom of the sea with a thunderbolt; from the sea bed, she drank the water from the sea thrice a day, creating whirlpools. She lingered on a rock with Scylla facing her directly on another rock, making a strait.

In some myths, Charybdis was a voracious woman who stole oxen from Heracles, and was hurled by the thunderbolt of Zeus into the sea, where she retained her voracious nature.

 Odysseus faced both Charybdis and Scylla while rowing through a narrow channel. He ordered his men to avoid Charybdis, thus forcing them to pass near Scylla, which resulted in the deaths of six of his men. Later, stranded on a raft, Odysseus was swept back through the strait and passed near Charybdis. His raft was sucked into her maw, but he survived by clinging to a fig tree growing on a rock over her lair. On the next outflow of water, when his raft was expelled, Odysseus recovered it and paddled away safely.

The Argonauts were able to avoid both dangers because Hera ordered the Nereid Thetis to guide them through the perilous passage.
In the "Aeneid", the Trojans are warned by Helenus of Scylla and Charybdis, and are advised to avoid them by sailing around Pachynus point (Cape Passero) rather than risk the strait. Later, however, they find themselves passing Etna, and have to row for their lives to escape Charybdis.

Aristotle mentions in his "Meteorologica" that Aesop once teased a ferryman by telling him a myth concerning Charybdis. With one gulp of the sea, she brought the mountains to view; islands appeared after the next. The third is yet to come and will dry the sea altogether, thus depriving the ferryman of his livelihood.





Carbon monoxide

Carbon monoxide (chemical formula CO) is a poisonous, flammable gas that is colorless, odorless, tasteless, and slightly less dense than air. Carbon monoxide consists of one carbon atom and one oxygen atom connected by a triple bond. It is the simplest carbon oxide. In coordination complexes, the carbon monoxide ligand is called "carbonyl". It is a key ingredient in many processes in industrial chemistry.

The most common source of carbon monoxide is the partial combustion of carbon-containing compounds. Numerous environmental and biological sources generate carbon monoxide. In industry, carbon monoxide is important in the production of many compounds, including drugs, fragrances, and fuels. Upon emission into the atmosphere, carbon monoxide affects several processes that contribute to climate change.

Carbon monoxide has important biological roles across phylogenetic kingdoms. It is produced by many organisms, including humans. In mammalian physiology, carbon monoxide is a classical example of hormesis where low concentrations serve as an endogenous neurotransmitter (gasotransmitter) and high concentrations are toxic resulting in carbon monoxide poisoning. It is isoelectronic with cyanide anion CN.

Humans have maintained a complex relationship with carbon monoxide since first learning to control fire circa 800,000 BC. Early humans probably discovered the toxicity of carbon monoxide poisoning upon introducing fire into their dwellings. The early development of metallurgy and smelting technologies emerging circa 6,000 BC through the Bronze Age likewise plagued humankind from carbon monoxide exposure. Apart from the toxicity of carbon monoxide, indigenous Native Americans may have experienced the neuroactive properties of carbon monoxide through shamanistic fireside rituals.

Early civilizations developed mythological tales to explain the origin of fire, such as Prometheus from Greek mythology who shared fire with humans. Aristotle (384–322 BC) first recorded that burning coals produced toxic fumes. Greek physician Galen (129–199 AD) speculated that there was a change in the composition of the air that caused harm when inhaled, and many others of the era developed a basis of knowledge about carbon monoxide in the context of coal fume toxicity. Cleopatra may have died from carbon monoxide poisoning.

Georg Ernst Stahl mentioned "carbonarii halitus" in 1697 in reference to toxic vapors thought to be carbon monoxide. Friedrich Hoffmann conducted the first modern scientific investigation into carbon monoxide poisoning from coal in 1716. Herman Boerhaave conducted the first scientific experiments on the effect of carbon monoxide (coal fumes) on animals in the 1730s.

Joseph Priestley is considered to have first synthesized carbon monoxide in 1772. Carl Wilhelm Scheele similarly isolated carbon monoxide from charcoal in 1773 and thought it could be the carbonic entity making fumes toxic. Torbern Bergman isolated carbon monoxide from oxalic acid in 1775. Later in 1776, the French chemist produced CO by heating zinc oxide with coke, but mistakenly concluded that the gaseous product was hydrogen, as it burned with a blue flame. In the presence of oxygen, including atmospheric concentrations, carbon monoxide burns with a blue flame, producing carbon dioxide. Antoine Lavoisier conducted similar inconclusive experiments to Lassone in 1777. The gas was identified as a compound containing carbon and oxygen by William Cruickshank in 1800.

Thomas Beddoes and James Watt recognized carbon monoxide (as hydrocarbonate) to brighten venous blood in 1793. Watt suggested coal fumes could act as an antidote to the oxygen in blood, and Beddoes and Watt likewise suggested hydrocarbonate has a greater affinity for animal fiber than oxygen in 1796. In 1854, Adrien Chenot similarly suggested carbon monoxide to remove the oxygen from blood and then be oxidized by the body to carbon dioxide. The mechanism for carbon monoxide poisoning is widely credited to Claude Bernard whose memoirs beginning in 1846 and published in 1857 phrased, "prevents arterials blood from becoming venous". Felix Hoppe-Seyler independently published similar conclusions in the following year.

Carbon monoxide gained recognition as an essential reagent in the 1900s. Three industrial processes illustrate its evolution in industry. In the Fischer–Tropsch process, coal and related carbon-rich feedstocks are converted into liquid fuels via the intermediacy of CO. Originally developed as part of the German war effort to compensate for their lack of domestic petroleum, this technology continues today. Also in Germany, a mixture of CO and hydrogen was found to combine with olefins to give aldehydes. This process, called hydroformylation, is used to produce many large scale chemicals such as surfactants as well as specialty compounds that are popular fragrances and drugs. For example, CO is used in the production of vitamin A. In a third major process, attributed to researchers at Monsanto, CO combines with methanol to give acetic acid. Most acetic acid is produced by the Cativa process. Hydroformylation and the acetic acid syntheses are two of myriad carbonylation processes.

Carbon monoxide is the simplest oxocarbon and is isoelectronic with other triply-bonded diatomic species possessing 10 valence electrons, including the cyanide anion, the nitrosonium cation, boron monofluoride and molecular nitrogen. It has a molar mass of 28.0, which, according to the ideal gas law, makes it slightly less dense than air, whose average molar mass is 28.8.

The carbon and oxygen are connected by a triple bond that consists of a net two pi bonds and one sigma bond. The bond length between the carbon atom and the oxygen atom is 112.8 pm. This bond length is consistent with a triple bond, as in molecular nitrogen (N), which has a similar bond length (109.76 pm) and nearly the same molecular mass. Carbon–oxygen double bonds are significantly longer, 120.8 pm in formaldehyde, for example. The boiling point (82 K) and melting point (68 K) are very similar to those of N (77 K and 63 K, respectively). The bond-dissociation energy of 1072 kJ/mol is stronger than that of N (942 kJ/mol) and represents the strongest chemical bond known.

The ground electronic state of carbon monoxide is a singlet state since there are no unpaired electrons.

Carbon and oxygen together have a total of 10 electrons in the valence shell. Following the octet rule for both carbon and oxygen, the two atoms form a triple bond, with six shared electrons in three bonding molecular orbitals, rather than the usual double bond found in organic carbonyl compounds. Since four of the shared electrons come from the oxygen atom and only two from carbon, one bonding orbital is occupied by two electrons from oxygen, forming a dative or dipolar bond. This causes a C←O polarization of the molecule, with a small negative charge on carbon and a small positive charge on oxygen. The other two bonding orbitals are each occupied by one electron from carbon and one from oxygen, forming (polar) covalent bonds with a reverse C→O polarization since oxygen is more electronegative than carbon. In the free carbon monoxide molecule, a net negative charge δ remains at the carbon end and the molecule has a small dipole moment of 0.122 D.

The molecule is therefore asymmetric: oxygen has more electron density than carbon and is also slightly positively charged compared to carbon being negative. By contrast, the isoelectronic dinitrogen molecule has no dipole moment.

Carbon monoxide has a computed fractional bond order of 2.6, indicating that the "third" bond is important but constitutes somewhat less than a full bond. Thus, in valence bond terms, C≡O is the most important structure, while :C=O is non-octet, but has a neutral formal charge on each atom and represents the second most important resonance contributor. Because of the lone pair and divalence of carbon in this resonance structure, carbon monoxide is often considered to be an extraordinarily stabilized carbene. Isocyanides are compounds in which the O is replaced by an NR (R = alkyl or aryl) group and have a similar bonding scheme.

If carbon monoxide acts as a ligand, the polarity of the dipole may reverse with a net negative charge on the oxygen end, depending on the structure of the coordination complex.
See also the section ""Coordination chemistry"" below.

Theoretical and experimental studies show that, despite the greater electronegativity of oxygen, the dipole moment points from the more-negative carbon end to the more-positive oxygen end. The three bonds are in fact polar covalent bonds that are strongly polarized. The calculated polarization toward the oxygen atom is 71% for the σ-bond and 77% for both π-bonds.

The oxidation state of carbon in carbon monoxide is +2 in each of these structures. It is calculated by counting all the bonding electrons as belonging to the more electronegative oxygen. Only the two non-bonding electrons on carbon are assigned to carbon. In this count, carbon then has only two valence electrons in the molecule compared to four in the free atom.

Carbon monoxide occurs in various natural and artificial environments. Photochemical degradation of plant matter for example generates an estimated 60 million tons/year. Typical concentrations in parts per million are as follows:

Carbon monoxide (CO) is present in small amounts (about 80 ppb) in the Earth's atmosphere. Most of the rest comes from chemical reactions with organic compounds emitted by human activities and natural origins due to photochemical reactions in the troposphere that generate about 5 × 10 kilograms per year. Other natural sources of CO include volcanoes, forest and bushfires, and other miscellaneous forms of combustion such as fossil fuels. Small amounts are also emitted from the ocean, and from geological activity because carbon monoxide occurs dissolved in molten volcanic rock at high pressures in the Earth's mantle. Because natural sources of carbon monoxide vary from year to year, it is difficult to accurately measure natural emissions of the gas.

Carbon monoxide has an indirect effect on radiative forcing by elevating concentrations of direct greenhouse gases, including methane and tropospheric ozone. CO can react chemically with other atmospheric constituents (primarily the hydroxyl radical, OH) that would otherwise destroy methane. Through natural processes in the atmosphere, it is oxidized to carbon dioxide and ozone. Carbon monoxide is short-lived in the atmosphere (with an average lifetime of about one to two months), and spatially variable in concentration.

Due to its long lifetime in the mid-troposphere, carbon monoxide is also used as a tracer for pollutant plumes.

Carbon monoxide is a temporary atmospheric pollutant in some urban areas, chiefly from the exhaust of internal combustion engines (including vehicles, portable and back-up generators, lawnmowers, power washers, etc.), but also from incomplete combustion of various other fuels (including wood, coal, charcoal, oil, paraffin, propane, natural gas, and trash).

Large CO pollution events can be observed from space over cities.

Carbon monoxide is, along with aldehydes, part of the series of cycles of chemical reactions that form photochemical smog. It reacts with hydroxyl radical (OH) to produce a radical intermediate HOCO, which transfers rapidly its radical hydrogen to O to form peroxy radical (HO) and carbon dioxide (). Peroxy radical subsequently reacts with nitrogen oxide (NO) to form nitrogen dioxide (NO) and hydroxyl radical. NO gives O(P) via photolysis, thereby forming O following reaction with O.
Since hydroxyl radical is formed during the formation of NO, the balance of the sequence of chemical reactions starting with carbon monoxide and leading to the formation of ozone is:

Although the creation of NO is the critical step leading to low level ozone formation, it also increases this ozone in another, somewhat mutually exclusive way, by reducing the quantity of NO that is available to react with ozone.

In closed environments, the concentration of carbon monoxide can rise to lethal levels. On average, 170 people in the United States die every year from carbon monoxide produced by non-automotive consumer products.
These products include malfunctioning fuel-burning appliances such as furnaces, ranges, water heaters, and gas and kerosene room heaters; engine-powered equipment such as portable generators (and cars left running in attached garages); fireplaces; and charcoal that is burned in homes and other enclosed areas. Many deaths have occurred during power outages due to severe weather such as Hurricane Katrina and the 2021 Texas power crisis.

Miners refer to carbon monoxide as "whitedamp" or the "silent killer". It can be found in confined areas of poor ventilation in both surface mines and underground mines. The most common sources of carbon monoxide in mining operations are the internal combustion engine and explosives; however, in coal mines, carbon monoxide can also be found due to the low-temperature oxidation of coal. The idiom "Canary in the coal mine" pertained to an early warning of a carbon monoxide presence.

Beyond Earth, carbon monoxide is the second-most common diatomic molecule in the interstellar medium, after molecular hydrogen. Because of its asymmetry, this polar molecule produces far brighter spectral lines than the hydrogen molecule, making CO much easier to detect. Interstellar CO was first detected with radio telescopes in 1970. It is now the most commonly used tracer of molecular gas in general in the interstellar medium of galaxies, as molecular hydrogen can only be detected using ultraviolet light, which requires space telescopes. Carbon monoxide observations provide much of the information about the molecular clouds in which most stars form.

Beta Pictoris, the second brightest star in the constellation Pictor, shows an excess of infrared emission compared to normal stars of its type, which is caused by large quantities of dust and gas (including carbon monoxide) near the star.

In the atmosphere of Venus carbon monoxide occurs as a result of the photodissociation of carbon dioxide by electromagnetic radiation of wavelengths shorter than 169 nm. It has also been identified spectroscopically on the surface of Neptune's moon Triton.

Solid carbon monoxide is a component of comets. The volatile or "ice" component of Halley's Comet is about 15% CO. At room temperature and at atmospheric pressure, carbon monoxide is actually only metastable (see Boudouard reaction) and the same is true at low temperatures where CO and are solid, but nevertheless it can exist for billions of years in comets. There is very little CO in the atmosphere of Pluto, which seems to have been formed from comets. This may be because there is (or was) liquid water inside Pluto.

Carbon monoxide can react with water to form carbon dioxide and hydrogen:

This is called the water-gas shift reaction when occurring in the gas phase, but it can also take place (very slowly) in an aqueous solution.
If the hydrogen partial pressure is high enough (for instance in an underground sea), formic acid will be formed:

These reactions can take place in a few million years even at temperatures such as found on Pluto.

Carbon monoxide has a wide range of functions across all disciplines of chemistry. The four premier categories of reactivity involve metal-carbonyl catalysis, radical chemistry, cation and anion chemistries.

Most metals form coordination complexes containing covalently attached carbon monoxide. Only metals in lower oxidation states will complex with carbon monoxide ligands. This is because there must be sufficient electron density to facilitate back-donation from the metal d-orbital, to the π* molecular orbital from CO. The lone pair on the carbon atom in CO also donates electron density to the d on the metal to form a sigma bond. This electron donation is also exhibited with the cis effect, or the labilization of CO ligands in the cis position. Nickel carbonyl, for example, forms by the direct combination of carbon monoxide and nickel metal:
For this reason, nickel in any tubing or part must not come into prolonged contact with carbon monoxide. Nickel carbonyl decomposes readily back to Ni and CO upon contact with hot surfaces, and this method is used for the industrial purification of nickel in the Mond process.

In nickel carbonyl and other carbonyls, the electron pair on the carbon interacts with the metal; the carbon monoxide donates the electron pair to the metal. In these situations, carbon monoxide is called the carbonyl ligand. One of the most important metal carbonyls is iron pentacarbonyl, Fe(CO):

Many metal–CO complexes are prepared by decarbonylation of organic solvents, not from CO. For instance, iridium trichloride and triphenylphosphine react in boiling 2-methoxyethanol or DMF to afford IrCl(CO)(PPh).

Metal carbonyls in coordination chemistry are usually studied using infrared spectroscopy.

In the presence of strong acids and water, carbon monoxide reacts with alkenes to form carboxylic acids in a process known as the Koch–Haaf reaction. In the Gattermann–Koch reaction, arenes are converted to benzaldehyde derivatives in the presence of CO, AlCl and HCl. Organolithium compounds (e.g. butyl lithium) react with carbon monoxide, but these reactions have little scientific use.

Although CO reacts with carbocations and carbanions, it is relatively nonreactive toward organic compounds without the intervention of metal catalysts.

With main group reagents, CO undergoes several noteworthy reactions. Chlorination of CO is the industrial route to the important compound phosgene. With borane CO forms the adduct HBCO, which is isoelectronic with the acetylium cation [HCCO]. CO reacts with sodium to give products resulting from C−C coupling such as sodium acetylenediolate 2·. It reacts with molten potassium to give a mixture of an organometallic compound, potassium acetylenediolate 2·, potassium benzenehexolate 6, and potassium rhodizonate 2·.

The compounds cyclohexanehexone or triquinoyl (CO) and cyclopentanepentone or leuconic acid (CO), which so far have been obtained only in trace amounts, can be regarded as polymers of carbon monoxide. At pressures exceeding 5 GPa, carbon monoxide converts to polycarbonyl, a solid polymer that is metastable at atmospheric pressure but is explosive.

Carbon monoxide is conveniently produced in the laboratory by the dehydration of formic acid or oxalic acid, for example with concentrated sulfuric acid. Another method is heating an intimate mixture of powdered zinc metal and calcium carbonate, which releases CO and leaves behind zinc oxide and calcium oxide:

Silver nitrate and iodoform also afford carbon monoxide:

Finally, metal oxalate salts release CO upon heating, leaving a carbonate as byproduct:

Thermal combustion is the most common source for carbon monoxide. Carbon monoxide is produced from the partial oxidation of carbon-containing compounds; it forms when there is not enough oxygen to produce carbon dioxide (), such as when operating a stove or an internal combustion engine in an enclosed space.

A large quantity of CO byproduct is formed during the oxidative processes for the production of chemicals. For this reason, the process off-gases have to be purified.

Many methods have been developed for carbon monoxide production.

A major industrial source of CO is producer gas, a mixture containing mostly carbon monoxide and nitrogen, formed by combustion of carbon in air at high temperature when there is an excess of carbon. In an oven, air is passed through a bed of coke. The initially produced equilibrates with the remaining hot carbon to give CO. The reaction of with carbon to give CO is described as the Boudouard reaction. Above 800 °C, CO is the predominant product:

Another source is "water gas", a mixture of hydrogen and carbon monoxide produced via the endothermic reaction of steam and carbon:

Other similar "synthesis gases" can be obtained from natural gas and other fuels.

Carbon monoxide can also be produced by high-temperature electrolysis of carbon dioxide with solid oxide electrolyzer cells. One method developed at DTU Energy uses a cerium oxide catalyst and does not have any issues of fouling of the catalyst.

Carbon monoxide is also a byproduct of the reduction of metal oxide ores with carbon, shown in a simplified form as follows:

Carbon monoxide is also produced by the direct oxidation of carbon in a limited supply of oxygen or air.

Since CO is a gas, the reduction process can be driven by heating, exploiting the positive (favorable) entropy of reaction. The Ellingham diagram shows that CO formation is favored over in high temperatures.

Carbon monoxide is an industrial gas that has many applications in bulk chemicals manufacturing. Large quantities of aldehydes are produced by the hydroformylation reaction of alkenes, carbon monoxide, and H. Hydroformylation is coupled to the Shell higher olefin process to give precursors to detergents.

Phosgene, useful for preparing isocyanates, polycarbonates, and polyurethanes, is produced by passing purified carbon monoxide and chlorine gas through a bed of porous activated carbon, which serves as a catalyst. World production of this compound was estimated to be 2.74 million tonnes in 1989.
Methanol is produced by the hydrogenation of carbon monoxide. In a related reaction, the hydrogenation of carbon monoxide is coupled to C−C bond formation, as in the Fischer–Tropsch process where carbon monoxide is hydrogenated to liquid hydrocarbon fuels. This technology allows coal or biomass to be converted to diesel.

In the Cativa process, carbon monoxide and methanol react in the presence of a homogeneous iridium catalyst and hydroiodic acid to give acetic acid. This process is responsible for most of the industrial production of acetic acid.

Carbon monoxide is a strong reductive agent and has been used in pyrometallurgy to reduce metals from ores since ancient times. Carbon monoxide strips oxygen off metal oxides, reducing them to pure metal in high temperatures, forming carbon dioxide in the process. Carbon monoxide is not usually supplied as is, in the gaseous phase, in the reactor, but rather it is formed in high temperature in presence of oxygen-carrying ore, or a carboniferous agent such as coke, and high temperature. The blast furnace process is a typical example of a process of reduction of metal from ore with carbon monoxide.

Likewise, blast furnace gas collected at the top of blast furnace, still contains some 10% to 30% of carbon monoxide, and is used as fuel on Cowper stoves and on Siemens-Martin furnaces on open hearth steelmaking.

Carbon monoxide has also been used as a lasing medium in high-powered infrared lasers.

Carbon monoxide has been proposed for use as a fuel on Mars. Carbon monoxide/oxygen engines have been suggested for early surface transportation use as both carbon monoxide and oxygen can be straightforwardly produced from the carbon dioxide atmosphere of Mars by zirconia electrolysis, without using any Martian water resources to obtain hydrogen, which would be needed to make methane or any hydrogen-based fuel.

Carbon monoxide is a bioactive molecule which acts as a gaseous signaling molecule. It is naturally produced by many enzymatic and non-enzymatic pathways, the best understood of which is the catabolic action of heme oxygenase on the heme derived from hemoproteins such as hemoglobin. Following the first report that carbon monoxide is a normal neurotransmitter in 1993, carbon monoxide has received significant clinical attention as a biological regulator.

Because of carbon monoxide's role in the body, abnormalities in its metabolism have been linked to a variety of diseases, including neurodegenerations, hypertension, heart failure, and pathological inflammation. In many tissues, carbon monoxide acts as anti-inflammatory, vasodilatory, and encouragers of neovascular growth. In animal model studies, carbon monoxide reduced the severity of experimentally induced bacterial sepsis, pancreatitis, hepatic ischemia/reperfusion injury, colitis, osteoarthritis, lung injury, lung transplantation rejection, and neuropathic pain while promoting skin wound healing. Therefore, there is significant interest in the therapeutic potential of carbon monoxide becoming pharmaceutical agent and clinical standard of care.

Studies involving carbon monoxide have been conducted in many laboratories throughout the world for its anti-inflammatory and cytoprotective properties. These properties have the potential to be used to prevent the development of a series of pathological conditions including ischemia reperfusion injury, transplant rejection, atherosclerosis, severe sepsis, severe malaria, or autoimmunity. Many pharmaceutical drug delivery initiatives have developed methods to safely administer carbon monoxide, and subsequent controlled clinical trials have evaluated the therapeutic effect of carbon monoxide.

Microbiota may also utilize carbon monoxide as a gasotransmitter. Carbon monoxide sensing is a signaling pathway facilitated by proteins such as CooA. The scope of the biological roles for carbon monoxide sensing is still unknown.

The human microbiome produces, consumes, and responds to carbon monoxide. For example, in certain bacteria, carbon monoxide is produced via the reduction of carbon dioxide by the enzyme carbon monoxide dehydrogenase with favorable bioenergetics to power downstream cellular operations. In another example, carbon monoxide is a nutrient for methanogenic archaea which reduce it to methane using hydrogen.

Carbon monoxide has certain antimicrobial properties which have been studied to treat against infectious diseases.

Carbon monoxide is used in modified atmosphere packaging systems in the US, mainly with fresh meat products such as beef, pork, and fish to keep them looking fresh. The benefit is two-fold, carbon monoxide protects against microbial spoilage and it enhances the meat color for consumer appeal. The carbon monoxide combines with myoglobin to form carboxymyoglobin, a bright-cherry-red pigment. Carboxymyoglobin is more stable than the oxygenated form of myoglobin, oxymyoglobin, which can become oxidized to the brown pigment metmyoglobin. This stable red color can persist much longer than in normally packaged meat. Typical levels of carbon monoxide used in the facilities that use this process are between 0.4% and 0.5%.

The technology was first given "generally recognized as safe" (GRAS) status by the U.S. Food and Drug Administration (FDA) in 2002 for use as a secondary packaging system, and does not require labeling. In 2004, the FDA approved CO as primary packaging method, declaring that CO does not mask spoilage odor. The process is currently unauthorized in many other countries, including Japan, Singapore, and the European Union.

Carbon monoxide poisoning is the most common type of fatal air poisoning in many countries. The Centers for Disease Control and Prevention estimates that several thousand people go to hospital emergency rooms every year to be treated for carbon monoxide poisoning. According to the Florida Department of Health, "every year more than 500 Americans die from accidental exposure to carbon monoxide and thousands more across the U.S. require emergency medical care for non-fatal carbon monoxide poisoning." The American Association of Poison Control Centers (AAPCC) reported 15,769 cases of carbon monoxide poisoning resulting in 39 deaths in 2007. In 2005, the CPSC reported 94 generator-related carbon monoxide poisoning deaths.

Carbon monoxide is colorless, odorless, and tasteless. As such, it is relatively undetectable. It readily combines with hemoglobin to produce carboxyhemoglobin which potentially affects gas exchange; therefore exposure can be highly toxic. Concentrations as low as 667 ppm may cause up to 50% of the body's hemoglobin to convert to carboxyhemoglobin. A level of 50% carboxyhemoglobin may result in seizure, coma, and fatality. In the United States, the OSHA limits long-term workplace exposure levels above 50 ppm.

In addition to affecting oxygen delivery, carbon monoxide also binds to other hemoproteins such as myoglobin and mitochondrial cytochrome oxidase, metallic and non-metallic cellular targets to affect many cell operations.

In ancient history, Hannibal executed Roman prisoners with coal fumes during the Second Punic War.

Carbon monoxide had been used for genocide during the Holocaust at some extermination camps, the most notable by gas vans in Chełmno, and in the Action T4 "euthanasia" program.



Conjecture

In mathematics, a conjecture is a conclusion or a proposition that is proffered on a tentative basis without proof. Some conjectures, such as the Riemann hypothesis (still a conjecture) or Fermat's Last Theorem (a conjecture until proven in 1995 by Andrew Wiles), have shaped much of mathematical history as new areas of mathematics are developed in order to prove them.

Formal mathematics is based on "provable" truth. In mathematics, any number of cases supporting a universally quantified conjecture, no matter how large, is insufficient for establishing the conjecture's veracity, since a single counterexample could immediately bring down the conjecture. Mathematical journals sometimes publish the minor results of research teams having extended the search for a counterexample farther than previously done. For instance, the Collatz conjecture, which concerns whether or not certain sequences of integers terminate, has been tested for all integers up to 1.2 × 10 (over a trillion). However, the failure to find a counterexample after extensive search does not constitute a proof that the conjecture is true—because the conjecture might be false but with a very large minimal counterexample.

Nevertheless, mathematicians often regard a conjecture as strongly supported by evidence even though not yet proved. That evidence may be of various kinds, such as verification of consequences of it or strong interconnections with known results.

A conjecture is considered proven only when it has been shown that it is logically impossible for it to be false. There are various methods of doing so; see methods of mathematical proof for more details.

One method of proof, applicable when there are only a finite number of cases that could lead to counterexamples, is known as "brute force": in this approach, all possible cases are considered and shown not to give counterexamples. In some occasions, the number of cases is quite large, in which case a brute-force proof may require as a practical matter the use of a computer algorithm to check all the cases. For example, the validity of the 1976 and 1997 brute-force proofs of the four color theorem by computer was initially doubted, but was eventually confirmed in 2005 by theorem-proving software.

When a conjecture has been proven, it is no longer a conjecture but a theorem. Many important theorems were once conjectures, such as the Geometrization theorem (which resolved the Poincaré conjecture), Fermat's Last Theorem, and others.

Conjectures disproven through counterexample are sometimes referred to as "false conjectures" (cf. the Pólya conjecture and Euler's sum of powers conjecture). In the case of the latter, the first counterexample found for the n=4 case involved numbers in the millions, although it has been subsequently found that the minimal counterexample is actually smaller.

Not every conjecture ends up being proven true or false. The continuum hypothesis, which tries to ascertain the relative cardinality of certain infinite sets, was eventually shown to be independent from the generally accepted set of Zermelo–Fraenkel axioms of set theory. It is therefore possible to adopt this statement, or its negation, as a new axiom in a consistent manner (much as Euclid's parallel postulate can be taken either as true or false in an axiomatic system for geometry).

In this case, if a proof uses this statement, researchers will often look for a new proof that "doesn't" require the hypothesis (in the same way that it is desirable that statements in Euclidean geometry be proved using only the axioms of neutral geometry, i.e. without the parallel postulate). The one major exception to this in practice is the axiom of choice, as the majority of researchers usually do not worry whether a result requires it—unless they are studying this axiom in particular.

Sometimes, a conjecture is called a "hypothesis" when it is used frequently and repeatedly as an assumption in proofs of other results. For example, the Riemann hypothesis is a conjecture from number theory that — amongst other things — makes predictions about the distribution of prime numbers. Few number theorists doubt that the Riemann hypothesis is true. In fact, in anticipation of its eventual proof, some have even proceeded to develop further proofs which are contingent on the truth of this conjecture. These are called "conditional proofs": the conjectures assumed appear in the hypotheses of the theorem, for the time being.

These "proofs", however, would fall apart if it turned out that the hypothesis was false, so there is considerable interest in verifying the truth or falsity of conjectures of this type.

In number theory, Fermat's Last Theorem (sometimes called Fermat's conjecture, especially in older texts) states that no three positive integers formula_1, "formula_2", and "formula_3" can satisfy the equation "formula_4" for any integer value of "formula_5" greater than two.

This theorem was first conjectured by Pierre de Fermat in 1637 in the margin of a copy of "Arithmetica", where he claimed that he had a proof that was too large to fit in the margin. The first successful proof was released in 1994 by Andrew Wiles, and formally published in 1995, after 358 years of effort by mathematicians. The unsolved problem stimulated the development of algebraic number theory in the 19th century, and the proof of the modularity theorem in the 20th century. It is among the most notable theorems in the history of mathematics, and prior to its proof it was in the "Guinness Book of World Records" for "most difficult mathematical problems".

In mathematics, the four color theorem, or the four color map theorem, states that given any separation of a plane into contiguous regions, producing a figure called a "map", no more than four colors are required to color the regions of the map—so that no two adjacent regions have the same color. Two regions are called "adjacent" if they share a common boundary that is not a corner, where corners are the points shared by three or more regions. For example, in the map of the United States of America, Utah and Arizona are adjacent, but Utah and New Mexico, which only share a point that also belongs to Arizona and Colorado, are not.

Möbius mentioned the problem in his lectures as early as 1840. The conjecture was first proposed on October 23, 1852 when Francis Guthrie, while trying to color the map of counties of England, noticed that only four different colors were needed. The five color theorem, which has a short elementary proof, states that five colors suffice to color a map and was proven in the late 19th century; however, proving that four colors suffice turned out to be significantly harder. A number of false proofs and false counterexamples have appeared since the first statement of the four color theorem in 1852.

The four color theorem was ultimately proven in 1976 by Kenneth Appel and Wolfgang Haken. It was the first major theorem to be proved using a computer. Appel and Haken's approach started by showing that there is a particular set of 1,936 maps, each of which cannot be part of a smallest-sized counterexample to the four color theorem (i.e., if they did appear, one could make a smaller counter-example). Appel and Haken used a special-purpose computer program to confirm that each of these maps had this property. Additionally, any map that could potentially be a counterexample must have a portion that looks like one of these 1,936 maps. Showing this with hundreds of pages of hand analysis, Appel and Haken concluded that no smallest counterexample exists because any must contain, yet do not contain, one of these 1,936 maps. This contradiction means there are no counterexamples at all and that the theorem is therefore true. Initially, their proof was not accepted by mathematicians at all because the computer-assisted proof was infeasible for a human to check by hand. However, the proof has since then gained wider acceptance, although doubts still remain.

The Hauptvermutung (German for main conjecture) of geometric topology is the conjecture that any two triangulations of a triangulable space have a common refinement, a single triangulation that is a subdivision of both of them. It was originally formulated in 1908, by Steinitz and Tietze.

This conjecture is now known to be false. The non-manifold version was disproved by John Milnor in 1961 using Reidemeister torsion.

The manifold version is true in dimensions . The cases were proved by Tibor Radó and Edwin E. Moise in the 1920s and 1950s, respectively.

In mathematics, the Weil conjectures were some highly influential proposals by on the generating functions (known as local zeta-functions) derived from counting the number of points on algebraic varieties over finite fields.

A variety "V" over a finite field with "q" elements has a finite number of rational points, as well as points over every finite field with "q" elements containing that field. The generating function has coefficients derived from the numbers "N" of points over the (essentially unique) field with "q" elements.

Weil conjectured that such "zeta-functions" should be rational functions, should satisfy a form of functional equation, and should have their zeroes in restricted places. The last two parts were quite consciously modeled on the Riemann zeta function and Riemann hypothesis. The rationality was proved by , the functional equation by , and the analogue of the Riemann hypothesis was proved by .

In mathematics, the Poincaré conjecture is a theorem about the characterization of the 3-sphere, which is the hypersphere that bounds the unit ball in four-dimensional space. The conjecture states that: An equivalent form of the conjecture involves a coarser form of equivalence than homeomorphism called homotopy equivalence: if a 3-manifold is "homotopy equivalent" to the 3-sphere, then it is necessarily "homeomorphic" to it.

Originally conjectured by Henri Poincaré in 1904, the theorem concerns a space that locally looks like ordinary three-dimensional space but is connected, finite in size, and lacks any boundary (a closed 3-manifold). The Poincaré conjecture claims that if such a space has the additional property that each loop in the space can be continuously tightened to a point, then it is necessarily a three-dimensional sphere. An analogous result has been known in higher dimensions for some time.

After nearly a century of effort by mathematicians, Grigori Perelman presented a proof of the conjecture in three papers made available in 2002 and 2003 on arXiv. The proof followed on from the program of Richard S. Hamilton to use the Ricci flow to attempt to solve the problem. Hamilton later introduced a modification of the standard Ricci flow, called "Ricci flow with surgery" to systematically excise singular regions as they develop, in a controlled way, but was unable to prove this method "converged" in three dimensions. Perelman completed this portion of the proof. Several teams of mathematicians have verified that Perelman's proof is correct.

The Poincaré conjecture, before being proven, was one of the most important open questions in topology.

In mathematics, the Riemann hypothesis, proposed by , is a conjecture that the non-trivial zeros of the Riemann zeta function all have real part 1/2. The name is also used for some closely related analogues, such as the Riemann hypothesis for curves over finite fields.

The Riemann hypothesis implies results about the distribution of prime numbers. Along with suitable generalizations, some mathematicians consider it the most important unresolved problem in pure mathematics. The Riemann hypothesis, along with the Goldbach conjecture, is part of Hilbert's eighth problem in David Hilbert's list of 23 unsolved problems; it is also one of the Clay Mathematics Institute Millennium Prize Problems.

The P versus NP problem is a major unsolved problem in computer science. Informally, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer; it is widely conjectured that the answer is no. It was essentially first mentioned in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether a certain NP-complete problem could be solved in quadratic or linear time. The precise statement of the P=NP problem was introduced in 1971 by Stephen Cook in his seminal paper "The complexity of theorem proving procedures" and is considered by many to be the most important open problem in the field. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute to carry a US$1,000,000 prize for the first correct solution.


Karl Popper pioneered the use of the term "conjecture" in scientific philosophy. Conjecture is related to hypothesis, which in science refers to a testable conjecture.




Christoph Ludwig Agricola

Christoph Ludwig Agricola (5 November 1665 – 8 August 1724) was a German landscape painter and etcher. He was born and died at Regensburg (Ratisbon).

Christoph Ludwig Agricola was born on 5 November 1665 at Regensburg in Germany. He trained, as many painters of the period did, by studying nature.

He spent a great part of his life in travel, visiting England, the Netherlands and France, and residing for a considerable period at Naples, where he may have been influenced by Nicolas Poussin. He also stayed for some years circa 1712 in Venice, where he painted many works for the patron Zaccaria Sagredo.

He died in Regensburg in 1724.

Although he primarily worked in gouache and oils, documentary sources reveal that he also produced a small number of etchings. He was a good draughtsman, used warm lighting and exhibited a warm, masterly brushstroke.

His numerous landscapes, chiefly cabinet pictures, are remarkable for fidelity to nature, and especially for their skilful representation of varied phases of climate, especially nocturnal scenes and weather anomalies such as thunderstorms. In composition his style shows the influence of Nicolas Poussin and his work often displays the idealistic scenes associated with Poussin. In light and colour he imitates Claude Lorrain. His compositions include ruins of ancient buildings in the foreground, but his favourite figure for the foreground was men dressed in Oriental attire. He also produced a series of etchings of birds.

His pictures can be found in Dresden, Braunschweig, Vienna, Florence, Naples and many other towns of both Germany and Italy.

He probably tutored the artist, Johann Theile, and had an enormous influence on him. Art historians have also noted that the work of the landscape painter, Christian Johann Bendeler (1699–1728), was also influenced by Agricola.

Claudius

Tiberius Claudius Caesar Augustus Germanicus (; ; 1 August 10 BC – 13 October AD 54) was a Roman emperor, ruling from AD 41 to 54. A member of the Julio-Claudian dynasty, Claudius was born to Drusus and Antonia Minor at Lugdunum in Roman Gaul, where his father was stationed as a military legate. He was the first Roman emperor to be born outside Italy.

As he had a limp and slight deafness due to sickness at a young age, he was ostracized by his family and was excluded from public office until his consulship (which was shared with his nephew, Caligula, in 37). Claudius's infirmity probably saved him from the fate of many other nobles during the purges throughout the reigns of Tiberius and Caligula, as potential enemies did not see him as a serious threat. His survival led to his being declared emperor by the Praetorian Guard after Caligula's assassination, at which point he was the last adult male of his family.

Despite his lack of experience, Claudius was an able and efficient administrator. He expanded the imperial bureaucracy to include freedmen, and helped restore the empire's finances after the excesses of Caligula's reign. He was also an ambitious builder, constructing new roads, aqueducts, and canals across the Empire. During his reign, the Empire started its successful conquest of Britain. Having a personal interest in law, he presided at public trials, and issued edicts daily. He was seen as vulnerable throughout his reign, particularly by elements of the nobility. Claudius was constantly forced to shore up his position, which resulted in the deaths of many senators. Those events damaged his reputation among the ancient writers, though more recent historians have revised that opinion. Many authors contend that he was murdered by his own wife, Agrippina the Younger. After his death at the age of 63, his grandnephew and legally adopted step-son, Nero, succeeded him as emperor.

Claudius was born on 1 August 10 BC at Lugdunum (modern Lyon, France). He had two older siblings, Germanicus and Livilla. His mother, Antonia Minor, may have had two other children who died young. Claudius's maternal grandparents were Mark Antony and Octavia Minor, Augustus's sister, and he was therefore the great-great-grandnephew of Gaius Julius Caesar. His paternal grandparents were Livia, Augustus's third wife, and Tiberius Claudius Nero. During his reign, Claudius revived the rumor that his father Nero Claudius Drusus was actually the illegitimate son of Augustus, to give the appearance that Augustus was Claudius's paternal grandfather.

In 9 BC, Claudius's father Drusus died on campaign in Germania from a fall from a horse. Claudius was then raised by his mother, who never remarried. When his disability became evident, the relationship with his family turned sour. Antonia referred to him as a monster, and used him as a standard for stupidity. She seems to have passed her son off to his grandmother Livia for a number of years.

Livia was a little kinder, but nevertheless sent Claudius short, angry letters of reproof. He was put under the care of a former mule-driver to keep him disciplined, under the logic that his condition was due to laziness and a lack of willpower. However, by the time he reached his teenage years, his symptoms apparently waned and his family began to take some notice of his scholarly interests. In AD 7, Livy was hired to tutor Claudius in history, with the assistance of Sulpicius Flavus. He spent a lot of his time with the latter, as well as the philosopher Athenodorus. Augustus, according to a letter, was surprised at the clarity of Claudius's oratory.

Claudius' work as an historian damaged his prospects for advancement in public life. According to Vincent Scramuzza and others, he began work on a history of the Civil Wars that was either too truthful or too critical of Octavian, then reigning as Caesar Augustus. In either case, it was far too early for such an account, and may have only served to remind Augustus that Claudius was Antony's descendant. His mother and grandmother quickly put a stop to it, and this may have convinced them that Claudius was not fit for public office, since he could not be trusted to toe the existing party line.

When Claudius returned to the narrative later in life, he skipped over the wars of the Second Triumvirate altogether; but the damage was done, and his family pushed him into the background. When the Arch of Pavia was erected to honor the Imperial clan in AD 8, Claudius's name (now Tiberius Claudius Nero Germanicus after his elevation to "pater familias" of the Claudii Nerones on the adoption of his brother) was inscribed on the edge, past the deceased princes, Gaius and Lucius, and Germanicus's children. There is some speculation that the inscription was added by Claudius himself decades later, and that he originally did not appear at all.

When Augustus died in AD 14, Claudius – then aged 23 – appealed to his uncle Tiberius to allow him to begin the "cursus honorum". Tiberius, the new Emperor, responded by granting Claudius consular ornaments. Claudius requested office once more and was snubbed. Since the new emperor was no more generous than the old, Claudius gave up hope of public office and retired to a scholarly, private life.

Despite the disdain of the Imperial family, it seems that from very early on the general public respected Claudius. At Augustus's death, the "equites", or knights, chose Claudius to head their delegation. When his house burned down, the Senate demanded it be rebuilt at public expense. They also requested that Claudius be allowed to debate in the Senate. Tiberius turned down both motions, but the sentiment remained.

During the period immediately after the death of Tiberius's son, Drusus, Claudius was pushed by some quarters as a potential heir to the throne. This again suggests the political nature of his exclusion from public life. However, as this was also the period during which the power and terror of the commander of the Praetorian Guard, Sejanus, was at its peak, Claudius chose to downplay this possibility. After the death of Tiberius, the new emperor Caligula (the son of Claudius's brother Germanicus) recognized Claudius to be of some use. He appointed Claudius his co-consul in 37 to emphasize the memory of Caligula's deceased father Germanicus.

Despite this, Caligula tormented his uncle: playing practical jokes, charging him enormous sums of money, humiliating him before the Senate, and the like. According to Cassius Dio, Claudius became sickly and thin by the end of Caligula's reign, most likely due to stress. A possible surviving portrait of Claudius from this period may support this.

On 24 January 41, Caligula was assassinated in a conspiracy involving Cassius Chaerea – a military tribune in the Praetorian Guard – and several senators. There is no evidence that Claudius had a direct hand in the assassination, although it has been argued that he knew about the plot – particularly since he left the scene of the crime shortly before his nephew was murdered. However, after the deaths of Caligula's wife and daughter, it became apparent that Cassius intended to go beyond the terms of the conspiracy and wipe out the Imperial family.
In the chaos following the murder, Claudius witnessed the German guard cut down several uninvolved noblemen, including many of his friends. He fled to the palace to hide. According to tradition, a Praetorian named Gratus found him hiding behind a curtain and suddenly declared him "princeps". Claudius was spirited away to the Praetorian camp and put under their protection.

The Senate met and debated a change of government, but this devolved into an argument over which of them would be the new "princeps". When they heard of the Praetorians' claim, they demanded that Claudius be delivered to them for approval, but he refused, sensing the danger that would come with complying. Some historians, particularly Josephus, claim that Claudius was directed in his actions by the Judaean King Herod Agrippa. However, an earlier version of events by the same ancient author downplays Agrippa's role so it remains uncertain. Eventually the Senate was forced to give in. In return, Claudius granted a general amnesty, although he executed a few junior officers involved in the conspiracy. The actual assassins, including Cassius Chaerea and Julius Lupus, the murderer of Caligula's wife and daughter, were put to death to ensure Claudius's own safety and as a future deterrent.

Claudius took several steps to legitimize his rule against potential usurpers, most of them emphasizing his place within the Julio-Claudian family. He adopted the name "Caesar" as a cognomen, as the name still carried great weight with the populace. To do so, he dropped the cognomen "Nero", which he had adopted as "pater familias" of the Claudii Nerones when his brother Germanicus was adopted. As Pharaoh of Egypt, Claudius adopted the royal titulary "Tiberios Klaudios, Autokrator Heqaheqau Meryasetptah, Kanakht Djediakhshuemakhet" ("Tiberius Claudius, Emperor and ruler of rulers, beloved of Isis and Ptah, the strong bull of the stable moon on the horizon").

While Claudius had never been formally adopted either by Augustus or his successors, he was nevertheless the grandson of Augustus's sister Octavia, and so he felt that he had the right of family. He also adopted the name "Augustus" as the two previous emperors had done at their accessions. He kept the honorific "Germanicus" to display the connection with his heroic brother. He deified his paternal grandmother Livia to highlight her position as wife of the divine Augustus. Claudius frequently used the term "filius Drusi" (son of Drusus) in his titles, to remind the people of his legendary father and lay claim to his reputation.

Since Claudius was the first emperor proclaimed on the initiative of the Praetorian Guard instead of the Senate, his repute suffered at the hands of commentators (such as Seneca). Moreover, he was the first emperor who resorted to bribery as a means to secure army loyalty and rewarded the soldiers of the Praetorian Guard that had elevated him with 15,000 sesterces. Tiberius and Augustus had both left gifts to the army and guard in their wills, and upon Caligula's death the same would have been expected, even if no will existed. Claudius remained grateful to the guard, issuing coins with tributes to the Praetorians in the early part of his reign.

Pliny the Elder noted, according to the 1938 Loeb Classical Library translation by Harris Rackham, "... many people do not allow any gems in a signet-ring, and seal with the gold itself; this was a fashion invented when Claudius Cæsar was emperor."

Claudius restored the status of the peaceful Imperial Roman provinces of Macedonia and Achaea as senatorial provinces.

Under Claudius, the Empire underwent its first major expansion since the reign of Augustus. The provinces of Thrace, Noricum, Lycia, and Judea were annexed (or put under direct rule) under various circumstances during his term. The annexation of Mauretania, begun under Caligula, was completed after the defeat of rebel forces, as well as the official division of the former client kingdom into two Imperial provinces. The most far-reaching conquest was that of Britannia.

In 43, Claudius sent Aulus Plautius with four legions to Britain ("Britannia") after an appeal from an ousted tribal ally. Britain was an attractive target for Rome because of its material wealth: mines and the potential of slave labor, as well as being a haven for Gallic rebels. Claudius himself traveled to the island after the completion of initial offensives, bringing with him reinforcements and elephants. The Roman "colonia" of "Colonia Claudia Victricensis" was established as the provincial capital of the newly established province of Britannia at Camulodunum, where a large temple was dedicated in his honour.

He left Britain after 16 days, but remained in the provinces for some time. The Senate granted him a triumph for his efforts. Only members of the Imperial family were allowed such honours, but Claudius subsequently lifted this restriction for some of his conquering generals. He was granted the honorific "Britannicus" but only accepted it on behalf of his son, never using the title himself. When the British general Caractacus was captured in 50, Claudius granted him clemency. Caractacus lived out his days on land provided by the Roman state, an unusual end for an enemy commander.

Claudius conducted a census in 48 that found 5,984,072 (adult male) Roman citizens (women, children, slaves, and free adult males without Roman citizenship were not counted), an increase of around a million since the census conducted at Augustus's death. He had helped increase this number through the foundation of Roman colonies that were granted blanket citizenship. These colonies were often made out of existing communities, especially those with elites who could rally the populace to the Roman cause. Several colonies were placed in new provinces or on the border of the Empire to secure Roman holdings as quickly as possible.

Claudius personally judged many of the legal cases tried during his reign. Ancient historians have many complaints about this, stating that his judgments were variable and sometimes did not follow the law. He was also easily swayed. Nevertheless, Claudius paid detailed attention to the operation of the judicial system. He extended the summer court session, as well as the winter term, by shortening the traditional breaks. Claudius also made a law requiring plaintiffs to remain in the city while their cases were pending, as defendants had previously been required to do. These measures had the effect of clearing out the docket. The minimum age for jurors was also raised to 25 to ensure a more experienced jury pool.

Claudius also settled disputes in the provinces. He freed the island of Rhodes from Roman rule for their good faith and exempted Ilium (Troy) from taxes. Early in his reign, the Greeks and Jews of Alexandria each sent him embassies after riots broke out between the two communities. This resulted in the famous "Letter to the Alexandrians", which reaffirmed Jewish rights in the city but forbade them to move in more families en masse. According to Josephus, he then reaffirmed the rights and freedoms of all the Jews in the Empire.

One of Claudius's investigators discovered that many old Roman citizens based in the city of Tridentum (modern Trento) were not in fact citizens. The Emperor issued a declaration, contained in the "Tabula clesiana", that they would be allowed to hold citizenship from then on, since to strip them of their status would cause major problems. However, in individual cases, Claudius punished the false assumption of citizenship harshly, making it a capital offense. Similarly, any freedmen found to be laying false claim to membership of the Roman equestrian order were sold back into slavery.

Numerous edicts were issued throughout Claudius's reign. These were on a number of topics, everything from medical advice to moral judgments. A famous medical example is one promoting yew juice as a cure for snakebite. Suetonius wrote that he is even said to have thought of an edict allowing public flatulence for good health. One of the more famous edicts concerned the status of sick slaves. Masters had been abandoning ailing slaves at the temple of Aesculapius on Tiber Island to die instead of providing them with medical assistance and care, and then reclaiming them if they lived. Claudius ruled that slaves who were thus abandoned and recovered after such treatment would be free. Furthermore, masters who chose to kill slaves rather than take care of them were liable to be charged with murder.

Claudius embarked on many public works throughout his reign, both in the capital and in the provinces. He built or finished two aqueducts, the Aqua Claudia, begun by Caligula, and the Aqua Anio Novus. These entered the city in 52 and met at the Porta Maggiore. He also restored a third, the Aqua Virgo.

He paid special attention to transportation. Throughout Italy and the provinces he built roads and canals. Among these was a large canal leading from the Rhine to the sea, as well as a road from Italy to Germany – both begun by his father, Drusus. Closer to Rome, he built a navigable canal on the Tiber, leading to Portus, his new port just north of Ostia. This port was constructed in a semicircle with two moles and a lighthouse at its mouth, reducing flooding in Rome.

The port at Ostia was part of Claudius's solution to the constant grain shortages that occurred in winter, after the Roman shipping season. The other part of his solution was to insure the ships of grain merchants who were willing to risk travelling to Egypt in the off-season. He also granted their sailors special privileges, including citizenship and exemption from the Lex Papia Poppaea, a law that regulated marriage. In addition, he repealed the taxes that Caligula had instituted on food, and further reduced taxes on communities suffering drought or famine.

The last part of Claudius's plan to avoid famine was to increase the amount of arable land in Italy. This was to be achieved by draining the Fucine lake, also making the nearby river navigable year-round. A serious famine is mentioned in the book of Acts as taking place during Claudius' reign, and had been prophecied by a Christian called Agabus while visiting Antioch.

A tunnel was dug through the lake bed, but the plan was a failure. The tunnel was crooked and not large enough to carry the water, which caused it to back up when opened. The resultant flood washed out a large gladiatorial exhibition held to commemorate the opening, causing Claudius to run for his life along with the other spectators. The draining of the lake continued to present a problem well into the Middle Ages. It was finally achieved by the Prince Torlonia in the 19th century, producing over of new arable land. He expanded the Claudian tunnel to three times its original size.

Because of the circumstances of his accession, Claudius took great pains to please the Senate. During regular sessions, the Emperor sat among the Senate body, speaking in turn. When introducing a law, he sat on a bench between the consuls in his position as holder of the power of Tribune, (the Emperor could not officially serve as a Tribune of the Plebes since he was a patrician, but this was a power taken by previous rulers, which he continued). He refused to accept all his predecessors' titles (including Imperator) at the beginning of his reign, preferring to earn them in due course. He allowed the Senate to issue its own bronze coinage for the first time since Augustus. He also put the Imperial provinces of Macedonia and Achaea back under Senate control.

Claudius set about remodeling the Senate into a more efficient, representative body. He chided the senators about their reluctance to debate bills introduced by himself, as noted in the fragments of a surviving speech:

In 47, he assumed the office of "censor" with Lucius Vitellius, which had been allowed to lapse for some time. He struck out the names of many senators and "equites" who no longer met qualifications, but showed respect by allowing them to resign in advance. At the same time, he sought to admit to the senate eligible men from the provinces. The Lyon Tablet preserves his speech on the admittance of Gallic senators, in which he addresses the Senate with reverence but also with criticism for their disdain of these men. He even joked about how the Senate had admitted members from beyond Gallia Narbonensis (Lyons), i.e. himself. He also increased the number of patricians by adding new families to the dwindling number of noble lines. Here he followed the precedent of Lucius Junius Brutus and Julius Caesar.

Nevertheless, many in the Senate remained hostile to Claudius, and many plots were made on his life. This hostility carried over into the historical accounts. As a result, Claudius reduced the Senate's power for the sake of efficiency. The administration of Ostia was turned over to an Imperial procurator after construction of the port. Administration of many of the empire's financial concerns was turned over to Imperial appointees and freedmen. This led to further resentment and suggestions that these same freedmen were ruling the Emperor.

Several coup attempts were made during Claudius's reign, resulting in the deaths of many senators. Appius Silanus was executed early in Claudius's reign under questionable circumstances. Shortly after this, a large rebellion was undertaken by the Senator Vinicianus and Scribonianus - governor of Dalmatia - and gained quite a few senatorial supporters. It ultimately failed because of the reluctance of Scribonianus' troops, which led to the suicide of the main conspirators.

Many other senators tried different conspiracies and were condemned. Claudius's son-in-law Pompeius Magnus was executed for his part in a conspiracy with his father Crassus Frugi. Another plot involved the consulars Lusius Saturninus, Cornelius Lupus, and Pompeius Pedo.

In 46, Asinius Gallus, grandson of Asinius Pollio, and Titus Statilius Taurus Corvinus were exiled for a plot hatched with several of Claudius's own freedmen. Valerius Asiaticus was executed without public trial for unknown reasons. Ancient sources say the charge was adultery, and that Claudius was tricked into issuing the punishment. However, Claudius singles out Asiaticus for special damnation in his speech on the Gauls, which dates over a year later, suggesting that the charge must have been much more serious.

Asiaticus had been a claimant to the throne in the chaos following Caligula's death and a co-consul with Titus Statilius Taurus Corvinus. Most of these conspiracies took place before Claudius's term as Censor, and may have induced him to review the Senatorial rolls. The conspiracy of Gaius Silius in the year after his Censorship, 48, is detailed in book 11 of Tacitus' Annal. This section of Tacitus' history narrates the alleged conspiracy of Claudius's third wife, Messalina. Suetonius states that a total of 35 senators and 300 knights were executed for offenses during Claudius's reign. Needless to say, the responses to these conspiracies could not have helped Senate–emperor relations.

Claudius was hardly the first emperor to use freedmen to help with the day-to-day running of the Empire. He was, however, forced to increase their role as the powers of the "princeps" became more centralized and the burden of running the government became larger. Claudius did not want free-born magistrates to serve under him as if they were not peers.

The secretariat was divided into bureaus, with each being placed under the leadership of one freedman. Narcissus was the secretary of correspondence. Pallas became the secretary of the treasury. Callistus became secretary of justice. There was a fourth bureau for miscellaneous issues, which was put under Polybius until his execution for treason. The freedmen could also officially speak for the Emperor, as when Narcissus addressed the troops in Claudius's stead before the conquest of Britain.

Since these were important positions, the senators were aghast at their being placed in the hands of former slaves and "well-known eunuchs". If freedmen had total control of money, letters and law, it seemed it would not be hard for them to manipulate the Emperor. This is exactly the accusation put forth by ancient sources. However, these same sources admit that the freedmen were loyal to Claudius.

He was similarly appreciative of them and gave them due credit for policies where he had used their advice. However, if they showed treasonous inclinations, the Emperor punished them with just force, as in the case of Polybius and Pallas's brother, Felix. There is no evidence that the character of Claudius's policies and edicts changed with the rise and fall of the various freedmen, suggesting that he was firmly in control throughout.

Regardless of the extent of their political power, the freedmen did manage to amass wealth through their positions. Pliny the Elder notes that several of them were richer than Crassus, the richest man of the Republican era.

Claudius, as the author of a treatise on Augustus's religious reforms, felt himself in a good position to institute some of his own. He had strong opinions about the proper form for state religion. He refused the request of Alexandrian Greeks to dedicate a temple to his divinity, saying that only gods may choose new gods. He restored lost days to festivals and got rid of many extraneous celebrations added by Caligula. He re-instituted old observances and archaic language.

Claudius was concerned with the spread of eastern mysteries within the city and searched for more Roman replacements. He emphasized the Eleusinian Mysteries, which had been practiced by so many during the Republic. He expelled foreign astrologers, and at the same time rehabilitated the old Roman soothsayers (known as haruspices) as a replacement. He was especially hard on Druidism, because of its incompatibility with the Roman state religion and its proselytizing activities.

According to Suetonius, Claudius was extraordinarily fond of games. He is said to have risen with the crowd after gladiatorial matches and given unrestrained praise to the fighters. Claudius also presided over many new and original events. Soon after coming into power, Claudius instituted games to be held in honor of his father on the latter's birthday. Annual games were also held in honour of his accession, and took place at the Praetorian camp where Claudius had first been proclaimed Emperor.

Claudius organised a performance of the Secular Games, marking the 800th anniversary of the founding of Rome. Augustus had performed the same games less than a century prior. Augustus's excuse was that the interval for the games was 110 years, not 100, but his date actually did not qualify under either reasoning. Claudius also presented staged naval battles to mark the attempted draining of the Fucine Lake, as well as many other public games and shows.

At Ostia, in front of a crowd of spectators, Claudius fought an orca which was trapped in the harbour. The event was witnessed by Pliny the Elder:

Claudius also restored and adorned many public venues in Rome. At the Circus Maximus, the turning posts and starting stalls were replaced in marble and embellished, and an embankment was probably added to prevent flooding of the track. Claudius also reinforced or extended the seating rules that reserved front seating at the Circus for senators. He rebuilt Pompey's Theatre after it had been destroyed by fire, organising special fights at the re-dedication, which he observed from a special platform in the orchestra box.

Suetonius and the other ancient authors accused Claudius of being dominated by women and wives, and of being a womanizer.

Claudius married four times, after two failed betrothals. The first betrothal was to his distant cousin Aemilia Lepida, but was broken for political reasons. The second was to Livia Medullina Camilla, which ended with Medullina's sudden death on their wedding day.

Plautia Urgulanilla was the granddaughter of Livia's confidant Urgulania. During their marriage she gave birth to a son, Claudius Drusus. Drusus died of asphyxiation in his early teens, shortly after becoming engaged to Junilla, daughter of Sejanus.

Claudius later divorced Urgulanilla for adultery and on suspicion of murdering her sister-in-law Apronia. When Urgulanilla gave birth after the divorce, Claudius repudiated the baby girl, Claudia, as the father was allegedly one of his own freedmen. Later, this action made him the target of criticism by his enemies.

Soon after, (possibly in 28) Claudius married Aelia Paetina, a relative of Sejanus, if not Sejanus's adoptive sister. During their marriage, Claudius and Paetina had a daughter, Claudia Antonia. He later divorced her after the marriage became a political liability. One version suggests that it may have been due to emotional and mental abuse by Paetina.

Some years after divorcing Aelia Paetina, in 38 or early 39, Claudius married Valeria Messalina, who was his first cousin once removed (Claudius's grandmother, Octavia the Younger, was Valeria's great-grandmother on both her mother and father's side) and closely allied with Caligula's circle. Shortly thereafter, she gave birth to a daughter, Claudia Octavia. A son, first named Tiberius Claudius Germanicus, and later known as Britannicus, was born just after Claudius's accession.

This marriage ended in tragedy. The ancient historians allege that Messalina was a nymphomaniac who was regularly unfaithful to Claudius—Tacitus states she went so far as to compete with a prostitute to see who could have more sexual partners in a nightand manipulated his policies to amass wealth. In 48, Messalina married her lover Gaius Silius in a public ceremony while Claudius was at Ostia.
Sources disagree as to whether or not she divorced the Emperor first, and whether the intention was to usurp the throne. Under Roman law, the spouse needed to be informed that he or she had been divorced before a new marriage could take place; the sources state that Claudius was in total ignorance until after the marriage. Scramuzza, in his biography, suggests that Silius may have convinced Messalina that Claudius was doomed, and the union was her only hope of retaining her rank and protecting her children. The historian Tacitus suggests that Claudius's ongoing term as Censor may have prevented him from noticing the affair before it reached such a critical point, after which she was executed.

Claudius married once more. Ancient sources tell that his freedmen put forward three candidates, Caligula's third wife Lollia Paulina, Claudius's divorced second wife Aelia Paetina and Claudius's niece Agrippina the Younger. According to Suetonius, Agrippina won out through her feminine wiles. She gradually seized power from Claudius and successfully conspired to eliminate his son's rivals, opening the way for her son to become emperor.
The truth is probably more political. The attempted coup d'état by Silius and Messalina probably made Claudius realize the weakness of his position as a member of the Claudian (but not the Julian) family. This weakness was compounded by the fact that he did not yet have an obvious adult heir, Britannicus being just a boy. Agrippina was one of the few remaining descendants of Augustus, and her son Lucius Domitius Ahenobarbus (the future Nero) was one of the last males of the Imperial family. Coup attempts might rally around the pair and Agrippina was already showing such ambition. It has been suggested that the Senate may have pushed for the marriage, an attempt to end the feud between the Julian and Claudian branches.

This feud dated back to Agrippina's mother's actions against Tiberius after the death of her husband Germanicus (Claudius's brother), actions that Tiberius had punished. In any case, Claudius accepted Agrippina and later adopted the mature Ahenobarbus as his son, renaming him as 'Nero Claudius Caesar'.

Nero was married to Claudius's daughter Octavia, made joint heir with the underage Britannicus, and promoted; Augustus had similarly named his grandson Postumus Agrippa and his stepson Tiberius as joint heirs, and Tiberius had named Caligula as his joint heir with his grandson Tiberius Gemellus. Adoption of adults or near adults was an old tradition in Rome when a suitable natural adult heir was unavailable, as was the case during Britannicus's minority. Claudius may have previously looked to adopt one of his sons-in-law to protect his own reign.

Faustus Cornelius Sulla Felix, who was married to Claudius's daughter Claudia Antonia, was only descended from Octavia and Antony on one side – not close enough to the Imperial family to ensure his right to be Emperor (although that did not stop others from making him the object of a coup attempt against Nero a few years later), besides being the half-brother of Valeria Messalina, which told against him. Nero was more popular with the general public as both the grandson of Germanicus and the direct descendant of Augustus.

The historian Suetonius describes the physical manifestations of Claudius's condition in relatively good detail. His knees were weak and gave way under him and his head shook. He stammered and his speech was confused. He slobbered and his nose ran when he was excited. The Stoic Seneca states in his "Apocolocyntosis" that Claudius's voice belonged to no land animal, and that his hands were weak as well.
However, he showed no physical deformity, as Suetonius notes that when calm and seated he was a tall, well-built figure of "dignitas". When angered or stressed, his symptoms became worse. Historians agree that this condition improved upon his accession to the throne. Claudius himself claimed that he had exaggerated his ailments to save his life.

Modern assessments of his health have changed several times in the past century. Prior to World War II, infantile paralysis (or polio) was widely accepted as the cause. This is the diagnosis used in Robert Graves's Claudius novels, first published in the 1930s. "The New York Times" wrote in 1934 that Claudius suffered from infantile paralysis (which led to his limp state) and measles (which made him deaf) at seven months of age, among several other ailments. Polio does not explain many of the described symptoms, however, and a more recent theory implicates cerebral palsy as the cause. Tourette syndrome has also been considered a possibility.

As a person, ancient historians described Claudius as generous and lowbrow, a man who sometimes lunched with the plebeians. They also paint him as bloodthirsty and cruel, over-fond of gladiatorial combat and executions, and very quick to anger; Claudius himself acknowledged the latter trait, and apologized publicly for his temper. According to the ancient historians he was also excessively trusting, and easily manipulated by his wives and freedmen, but at the same time they portray him as paranoid and apathetic, dull and easily confused.

Claudius's extant works present a different view, painting a picture of an intelligent, scholarly, well-read, and conscientious administrator with an eye to detail and justice. Thus, Claudius becomes an enigma. Since the discovery of his "Letter to the Alexandrians", much work has been done to rehabilitate Claudius and determine the truth.

Claudius wrote copiously throughout his life. Arnaldo Momigliano states that during the reign of Tiberius, which covers the peak of Claudius's literary career, it became impolitic to speak of republican Rome. The trend among the young historians was either to write about the new empire or about obscure antiquarian topics. Claudius was the rare scholar who covered both.

Besides his history of Augustus' reign that caused him so much grief, his major works included "Tyrrhenika", a twenty-book Etruscan history, and "Carchedonica", an eight-volume history of Carthage, as well as an Etruscan dictionary. He also wrote a book on dice-playing. Despite the general avoidance of the topic of the Republican era, he penned a defense of Cicero against the charges of Asinius Gallus. Modern historians have used this to determine the nature of his politics and of the aborted chapters of his civil war history.
He proposed a reform of the Latin alphabet by the addition of three new letters; he officially instituted the change during his censorship but they did not survive his reign. Claudius also tried to revive the old custom of putting dots between successive words (Classical Latin was written with no spacing). Finally, he wrote an eight-volume autobiography that Suetonius describes as lacking in taste. Claudius (like most of the members of his dynasty) harshly criticized his predecessors and relatives in surviving speeches.

None of the works survived, but other sources' reference to him provide material for the surviving histories of the Julio-Claudian dynasty. Suetonius quotes Claudius's autobiography once and must have used it as a source numerous times. Tacitus uses Claudius's arguments for the orthographical innovations mentioned above and may have used him for some of the more antiquarian passages in his annals. Claudius is the source for numerous passages of Pliny's "Natural History".

The influence of historical study on Claudius is obvious. In his speech on Gallic senators, he uses a version of the founding of Rome identical to that of Livy, his tutor in adolescence. The speech is meticulous in details, a common mark of all his extant works, and he goes into long digressions on related matters. This indicates a deep knowledge of a variety of historical subjects that he shared. Many of the public works instituted in his reign were based on plans first suggested by Julius Caesar. Levick believes this emulation of Caesar may have spread to all aspects of his policies.

His censorship seems to have been based on those of his ancestors, particularly Appius Claudius Caecus, and he used the office to put into place many policies based on those of Republican times. This is when many of his religious reforms took effect; also, his building efforts greatly increased during his tenure. In fact, his assumption of the office of Censor may have been motivated by a desire to see his academic labors bear fruit. For example, he believed (as most Romans did) that Caecus had used the power of the censorship office to introduce the letter "R" and so used his own term to introduce his new letters.

Ancient historians agree that Claudius was murdered by poison – possibly contained in mushrooms or on a feather (ostensibly put down his throat to induce vomiting) – and died in the early hours of 13 October 54.

Nearly all implicate his final and powerful wife, Agrippina, as the instigator. Agrippina and Claudius had become more combative in the months leading up to his death. This carried on to the point where Claudius openly lamented his bad wives, and began to comment on Britannicus' approaching manhood with an eye towards restoring his status within the imperial family. Agrippina had motive in ensuring the succession of Nero before Britannicus could gain power.

Some implicate either his taster Halotus, his doctor Xenophon, or the infamous poisoner Locusta as the administrator of the fatal substance. Some say he died after prolonged suffering following a single dose at dinner, and some have him recovering only to be poisoned again. Among his contemporary sources, Seneca the Younger ascribed the emperor's death to natural causes, while Josephus only spoke of rumors of his poisoning.

Some historians have cast doubt on whether Claudius was murdered or merely died from illness or old age. Evidence against his murder include his serious illnesses in his last years, his unhealthy lifestyle and the fact that his taster Halotus continued to serve in the same position under Nero. Claudius had been so ill the year before that Nero vowed games for his recovery and the year of 54 seems to have been such an unhealthy year that one sitting member of each magistracy died within the span of a few months. He may even have died by eating a naturally poisonous mushroom, possibly Amanita muscaria. On the other hand, some modern scholars claim the near universality of the accusations in ancient texts lends credence to the crime. Claudius's ashes were interred in the Mausoleum of Augustus on 24 October 54, after a funeral similar to that of his great-uncle Augustus 40 years earlier.

Already, while alive, he received the widespread private worship of a living "princeps" and was worshipped in Britannia in his own temple in Camulodunum.

Claudius was deified by Nero and the Senate almost immediately.

Agrippina had sent Narcissus away shortly before Claudius's death, and now had the freedman murdered.

The last act of this secretary of letters was to burn all of Claudius's correspondence – most likely so it could not be used against him and others in an already hostile new regime. Thus Claudius's private words about his own policies and motives were lost to history. Just as Claudius had criticized his predecessors in official edicts, Nero often criticized the deceased Emperor, and many Claudian laws and edicts were disregarded under the reasoning that he was too stupid and senile to have meant them.

Seneca's Apocolocyntosis mocks the deification of Claudius and reinforces the view of Claudius as an unpleasant fool; this remained the official view for the duration of Nero's reign. Eventually Nero stopped referring to his deified adoptive father at all. Claudius's temple was left unfinished after only some of the foundation had been laid down. Eventually the site was overtaken by Nero's Golden House.

The Flavians, who had risen to prominence under Claudius, took a different tack. They needed to shore up their legitimacy, but also justify the fall of the Julio-Claudians. They reached back to Claudius in contrast with Nero, to show that they were associated with a good regime. Commemorative coins were issued of Claudius and his son Britannicus, who had been a friend of Emperor Titus (Titus was born in 39, Britannicus was born in 41). When Nero's Golden House was burned, the Temple of Claudius was finally completed on the Caelian Hill.

However, as the Flavians became established, they needed to emphasize their own credentials more, and their references to Claudius ceased. Instead, he was lumped with the other emperors of the fallen dynasty. His state-cult in Rome probably continued until the abolition of all cults of dead Emperors by Maximinus Thrax in 237–238. The "Feriale Duranum", probably identical to the festival calendars of every regular army unit, assigns him a sacrifice of a steer on his birthday, the Kalends of August. And such commemoration (and consequent feasting) probably continued until the Christianization and disintegration of the army in the late 4th century.

The ancient historians Tacitus, Suetonius (in "The Twelve Caesars"), and Cassius Dio all wrote after the last of the Flavians had gone. All three were senators or "equites". They took the side of the Senate in most conflicts with the Princeps, invariably viewing him as being in the wrong. This resulted in biases, both conscious and unconscious. Suetonius lost access to the official archives shortly after beginning his work. He was forced to rely on second-hand accounts when it came to Claudius (with the exception of Augustus's letters, which had been gathered earlier). Suetonius painted Claudius as a ridiculous figure, belittling many of his acts and crediting his good works to his retinue.

Tacitus wrote a narrative for his fellow senators and fitted each of the emperors into a simple mold of his choosing. He wrote of Claudius as a passive pawn and an idiot in affairs relating to the palace and public life. During his Censorship of 47–48 Tacitus allows the reader a glimpse of a Claudius who is more statesmanlike (XI.23–25), but it is a mere glimpse. Tacitus is usually held to have 'hidden' his use of Claudius's writings and to have omitted Claudius's character from his works. Even his version of Claudius's Lyons tablet speech is edited to be devoid of the emperor's personality. Dio was less biased, but seems to have used Suetonius and Tacitus as sources. Thus, the conception of Claudius as a weak fool, controlled by those he supposedly ruled, was preserved for the ages.

As time passed, Claudius was mostly forgotten outside of the historians' accounts. His books were lost first, as their antiquarian subjects became unfashionable. In the 2nd century, Pertinax, who shared his birthday, became emperor, overshadowing commemoration of Claudius.


In literature, Claudius and his contemporaries appear in the historical novel "The Roman" by Mika Waltari. Canadian-born science fiction writer A. E. van Vogt reimagined Robert Graves's Claudius story, in his two novels, "Empire of the Atom" and "The Wizard of Linn".

The historical novel "Chariot of the Soul" by Linda Proud features Claudius as host and mentor of the young Togidubnus, son of King Verica of the Atrebates, during his ten-year stay in Rome. When Togidubnus returns to Britain in advance of the Roman army, it is with a mission given to him by Claudius.




Cardinal

Cardinal or The Cardinal may refer to:

















Cantor set

In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties. It was discovered in 1874 by Henry John Stephen Smith and mentioned by German mathematician Georg Cantor in 1883.

Through consideration of this set, Cantor and others helped lay the foundations of modern point-set topology. The most common construction is the Cantor ternary set, built by removing the middle third of a line segment and then repeating the process with the remaining shorter segments. Cantor mentioned this ternary construction only in passing, as an example of a perfect set that is nowhere dense (, Anmerkungen zu §10, /p.590).

More generally, in topology, "a" Cantor space is a topological space homeomorphic to the Cantor ternary set (equipped with its subspace topology). By a theorem of L. E. J. Brouwer, this is equivalent to being perfect, nonempty, compact, metrizable and zero dimensional.

The Cantor ternary set formula_1 is created by iteratively deleting the "open" middle third from a set of line segments. One starts by deleting the open middle third formula_2 from the interval formula_3, leaving two line segments: formula_4. Next, the open middle third of each of these remaining segments is deleted, leaving four line segments: formula_5.
The Cantor ternary set contains all points in the interval formula_6 that are not deleted at any step in this infinite process. The same facts can be described recursively by setting
and
for formula_9, so that

The first six steps of this process are illustrated below.

Using the idea of self-similar transformations, formula_14 formula_15 and formula_16 the explicit closed formulas for the Cantor set are
where every middle third is removed as the open interval formula_18 from the closed interval formula_19 surrounding it, or
where the middle third formula_21 of the foregoing closed interval formula_22 is removed by intersecting with formula_23

This process of removing middle thirds is a simple example of a finite subdivision rule. The complement of the Cantor ternary set is an example of a fractal string.

In arithmetical terms, the Cantor set consists of all real numbers of the unit interval formula_6 that do not require the digit 1 in order to be expressed as a ternary (base 3) fraction. As the above diagram illustrates, each point in the Cantor set is uniquely located by a path through an infinitely deep binary tree, where the path turns left or right at each level according to which side of a deleted segment the point lies on. Representing each left turn with 0 and each right turn with 2 yields the ternary fraction for a point.

In The Fractal Geometry of Nature, mathematician Benoit Mandelbrot provides a whimsical thought experiment to assist non-mathematical readers in imagining the construction of formula_1. His narrative begins with imagining a bar, perhaps of lightweight metal, in which the bar's matter "curdles" by iteratively shifting towards its extremities. As the bar's segments become smaller, they become thin, dense slugs that eventually grow too small and faint to see.CURDLING: The construction of the Cantor bar results from the process I call curdling. It begins with a round bar. It is best to think of it as having a very low density. Then matter "curdles" out of this bar's middle third into the end thirds, so that the positions of the latter remain unchanged. Next matter curdles out of the middle third of each end third into its end thirds, and so on ad infinitum until one is left with an infinitely large number of infinitely thin slugs of infinitely high density. These slugs are spaced along the line in the very specific fashion induced by the generating process. In this illustration, curdling (which eventually requires hammering!) stops when both the printer's press and our eye cease to follow; the last line is indistinguishable from the last but one: each of its ultimate parts is seen as a gray slug rather than two parallel black slugs.

Since the Cantor set is defined as the set of points not excluded, the proportion (i.e., measure) of the unit interval remaining can be found by total length removed. This total is the geometric progression

So that the proportion left is 1 − 1 = 0.

This calculation suggests that the Cantor set cannot contain any interval of non-zero length. It may seem surprising that there should be anything left—after all, the sum of the lengths of the removed intervals is equal to the length of the original interval. However, a closer look at the process reveals that there must be something left, since removing the "middle third" of each interval involved removing open sets (sets that do not include their endpoints). So removing the line segment (, ) from the original interval [0, 1] leaves behind the points and . Subsequent steps do not remove these (or other) endpoints, since the intervals removed are always internal to the intervals remaining. So the Cantor set is not empty, and in fact contains an uncountably infinite number of points (as follows from the above description in terms of paths in an infinite binary tree).

It may appear that "only" the endpoints of the construction segments are left, but that is not the case either. The number , for example, has the unique ternary form 0.020202... = . It is in the bottom third, and the top third of that third, and the bottom third of that top third, and so on. Since it is never in one of the middle segments, it is never removed. Yet it is also not an endpoint of any middle segment, because it is not a multiple of any power of 1/3.
All endpoints of segments are "terminating" ternary fractions and are contained in the set
which is a countably infinite set.
As to cardinality, almost all elements of the Cantor set are not endpoints of intervals, nor rational points like 1/4. The whole Cantor set is in fact not countable.

It can be shown that there are as many points left behind in this process as there were to begin with, and that therefore, the Cantor set is uncountable. To see this, we show that there is a function "f" from the Cantor set formula_1 to the closed interval [0,1] that is surjective (i.e. "f" maps from formula_1 onto [0,1]) so that the cardinality of formula_1 is no less than that of [0,1]. Since formula_1 is a subset of [0,1], its cardinality is also no greater, so the two cardinalities must in fact be equal, by the Cantor–Bernstein–Schröder theorem.

To construct this function, consider the points in the [0, 1] interval in terms of base 3 (or ternary) notation. Recall that the proper ternary fractions, more precisely: the elements of formula_32, admit more than one representation in this notation, as for example , that can be written as 0.1 = , but also as 0.0222... = , and , that can be written as 0.2 = but also as 0.1222... = .
When we remove the middle third, this contains the numbers with ternary numerals of the form 0.1xxxxx... where xxxxx... is strictly between 00000... and 22222... So the numbers remaining after the first step consist of

This can be summarized by saying that those numbers with a ternary representation such that the first digit after the radix point is not 1 are the ones remaining after the first step.

The second step removes numbers of the form 0.01xxxx... and 0.21xxxx..., and (with appropriate care for the endpoints) it can be concluded that the remaining numbers are those with a ternary numeral where neither of the first "two" digits is 1.

Continuing in this way, for a number not to be excluded at step "n", it must have a ternary representation whose "n"th digit is not 1. For a number to be in the Cantor set, it must not be excluded at any step, it must admit a numeral representation consisting entirely of 0s and 2s.

It is worth emphasizing that numbers like 1, = 0.1 and = 0.21 are in the Cantor set, as they have ternary numerals consisting entirely of 0s and 2s: 1 = 0.222... = , = 0.0222... = and = 0.20222... = .
All the latter numbers are "endpoints", and these examples are right limit points of formula_1. The same is true for the left limit points of formula_1, e.g. = 0.1222... = = and = 0.21222... = = . All these endpoints are "proper ternary" fractions (elements of formula_35) of the form , where denominator "q" is a power of 3 when the fraction is in its irreducible form. The ternary representation of these fractions terminates (i.e., is finite) or — recall from above that proper ternary fractions each have 2 representations — is infinite and "ends" in either infinitely many recurring 0s or infinitely many recurring 2s. Such a fraction is a left limit point of formula_1 if its ternary representation contains no 1's and "ends" in infinitely many recurring 0s. Similarly, a proper ternary fraction is a right limit point of formula_1 if it again its ternary expansion contains no 1's and "ends" in infinitely many recurring 2s.

This set of endpoints is dense in formula_1 (but not dense in [0, 1]) and makes up a countably infinite set. The numbers in formula_1 which are "not" endpoints also have only 0s and 2s in their ternary representation, but they cannot end in an infinite repetition of the digit 0, nor of the digit 2, because then it would be an endpoint.

The function from formula_1 to [0,1] is defined by taking the ternary numerals that do consist entirely of 0s and 2s, replacing all the 2s by 1s, and interpreting the sequence as a binary representation of a real number. In a formula,

For any number "y" in [0,1], its binary representation can be translated into a ternary representation of a number "x" in formula_1 by replacing all the 1s by 2s. With this, "f"("x") = "y" so that "y" is in the range of "f". For instance if "y" = = 0.100110011001... = , we write "x" = = 0.200220022002... = . Consequently, "f" is surjective. However, "f" is "not" injective — the values for which "f"("x") coincides are those at opposing ends of one of the "middle thirds" removed. For instance, take
so
Thus there are as many points in the Cantor set as there are in the interval [0, 1] (which has the uncountable cardinality However, the set of endpoints of the removed intervals is countable, so there must be uncountably many numbers in the Cantor set which are not interval endpoints. As noted above, one example of such a number is , which can be written as 0.020202... = in ternary notation. In fact, given any formula_47, there exist formula_48 such that formula_49. This was first demonstrated by Steinhaus in 1917, who proved, via a geometric argument, the equivalent assertion that formula_50 for every formula_47. Since this construction provides an injection from formula_52 to formula_53, we have formula_54 as an immediate corollary. Assuming that formula_55 for any infinite set formula_56 (a statement shown to be equivalent to the axiom of choice by Tarski), this provides another demonstration that formula_57.

The Cantor set contains as many points as the interval from which it is taken, yet itself contains no interval of nonzero length. The irrational numbers have the same property, but the Cantor set has the additional property of being closed, so it is not even dense in any interval, unlike the irrational numbers which are dense in every interval.

It has been conjectured that all algebraic irrational numbers are normal. Since members of the Cantor set are not normal, this would imply that all members of the Cantor set are either rational or transcendental.

The Cantor set is the prototype of a fractal. It is self-similar, because it is equal to two copies of itself, if each copy is shrunk by a factor of 3 and translated. More precisely, the Cantor set is equal to the union of two functions, the left and right self-similarity transformations of itself, formula_58 and formula_15, which leave the Cantor set invariant up to homeomorphism: formula_60

Repeated iteration of formula_61 and formula_62 can be visualized as an infinite binary tree. That is, at each node of the tree, one may consider the subtree to the left or to the right. Taking the set formula_63 together with function composition forms a monoid, the dyadic monoid.

The automorphisms of the binary tree are its hyperbolic rotations, and are given by the modular group. Thus, the Cantor set is a homogeneous space in the sense that for any two points formula_64 and formula_65 in the Cantor set formula_1, there exists a homeomorphism formula_67 with formula_68. An explicit construction of formula_69 can be described more easily if we see the Cantor set as a product space of countably many copies of the discrete space formula_70. Then the map formula_71 defined by formula_72 is an involutive homeomorphism exchanging formula_64 and formula_65.

It has been found that some form of conservation law is always responsible behind scaling and self-similarity. In the case of Cantor set it can be seen that the formula_75th moment (where formula_76 is the fractal dimension) of all the surviving intervals at any stage of the construction process is equal to a constant which is one in the case of the Cantor set.
We know that there are formula_77 intervals of size formula_78 present in the system at the formula_79th step of its construction. Then if we label the surviving intervals as formula_80 then the formula_75th moment is formula_82 since formula_83.

The Hausdorff dimension of the Cantor set is equal to ln(2)/ln(3) ≈ 0.631.

Although "the" Cantor set typically refers to the original, middle-thirds Cantor set described above, topologists often talk about "a" Cantor set, which means any topological space that is homeomorphic (topologically equivalent) to it.

As the above summation argument shows, the Cantor set is uncountable but has Lebesgue measure 0. Since the Cantor set is the complement of a union of open sets, it itself is a closed subset of the reals, and therefore a complete metric space. Since it is also totally bounded, the Heine–Borel theorem says that it must be compact.

For any point in the Cantor set and any arbitrarily small neighborhood of the point, there is some other number with a ternary numeral of only 0s and 2s, as well as numbers whose ternary numerals contain 1s. Hence, every point in the Cantor set is an accumulation point (also called a cluster point or limit point) of the Cantor set, but none is an interior point. A closed set in which every point is an accumulation point is also called a perfect set in topology, while a closed subset of the interval with no interior points is nowhere dense in the interval.

Every point of the Cantor set is also an accumulation point of the complement of the Cantor set.

For any two points in the Cantor set, there will be some ternary digit where they differ — one will have 0 and the other 2. By splitting the Cantor set into "halves" depending on the value of this digit, one obtains a partition of the Cantor set into two closed sets that separate the original two points. In the relative topology on the Cantor set, the points have been separated by a clopen set. Consequently, the Cantor set is totally disconnected. As a compact totally disconnected Hausdorff space, the Cantor set is an example of a Stone space.

As a topological space, the Cantor set is naturally homeomorphic to the product of countably many copies of the space formula_84, where each copy carries the discrete topology. This is the space of all sequences in two digits 

which can also be identified with the set of 2-adic integers. The basis for the open sets of the product topology are cylinder sets; the homeomorphism maps these to the subspace topology that the Cantor set inherits from the natural topology on the real line. This characterization of the Cantor space as a product of compact spaces gives a second proof that Cantor space is compact, via Tychonoff's theorem.

From the above characterization, the Cantor set is homeomorphic to the "p"-adic integers, and, if one point is removed from it, to the "p"-adic numbers.

The Cantor set is a subset of the reals, which are a metric space with respect to the ordinary distance metric; therefore the Cantor set itself is a metric space, by using that same metric. Alternatively, one can use the "p"-adic metric on formula_86: given two sequences formula_87, the distance between them is formula_88, where formula_89 is the smallest index such that formula_90; if there is no such index, then the two sequences are the same, and one defines the distance to be zero. These two metrics generate the same topology on the Cantor set.

We have seen above that the Cantor set is a totally disconnected perfect compact metric space. Indeed, in a sense it is the only one: every nonempty totally disconnected perfect compact metric space is homeomorphic to the Cantor set. See Cantor space for more on spaces homeomorphic to the Cantor set.

The Cantor set is sometimes regarded as "universal" in the category of compact metric spaces, since any compact metric space is a continuous image of the Cantor set; however this construction is not unique and so the Cantor set is not universal in the precise categorical sense. The "universal" property has important applications in functional analysis, where it is sometimes known as the "representation theorem for compact metric spaces".

For any integer "q" ≥ 2, the topology on the group G = Z (the countable direct sum) is discrete. Although the Pontrjagin dual Γ is also Z, the topology of Γ is compact. One can see that Γ is totally disconnected and perfect - thus it is homeomorphic to the Cantor set. It is easiest to write out the homeomorphism explicitly in the case "q" = 2. (See Rudin 1962 p 40.)

The Cantor set can be seen as the compact group of binary sequences, and as such, it is endowed with a natural Haar measure. When normalized so that the measure of the set is 1, it is a model of an infinite sequence of coin tosses. Furthermore, one can show that the usual Lebesgue measure on the interval is an image of the Haar measure on the Cantor set, while the natural injection into the ternary set is a canonical example of a singular measure. It can also be shown that the Haar measure is an image of any probability, making the Cantor set a universal probability space in some ways.

In Lebesgue measure theory, the Cantor set is an example of a set which is uncountable and has zero measure. In contrast, the set has a Hausdorff measure of 1 in its dimension of log 2 / log 3.

If we define a Cantor number as a member of the Cantor set, then

The Cantor set is a meagre set (or a set of first category) as a subset of [0,1] (although not as a subset of itself, since it is a Baire space). The Cantor set thus demonstrates that notions of "size" in terms of cardinality, measure, and (Baire) category need not coincide. Like the set formula_91, the Cantor set formula_1 is "small" in the sense that it is a null set (a set of measure zero) and it is a meagre subset of [0,1]. However, unlike formula_91, which is countable and has a "small" cardinality, formula_94, the cardinality of formula_1 is the same as that of [0,1], the continuum formula_96, and is "large" in the sense of cardinality. In fact, it is also possible to construct a subset of [0,1] that is meagre but of positive measure and a subset that is non-meagre but of measure zero: By taking the countable union of "fat" Cantor sets formula_97 of measure formula_98 (see Smith–Volterra–Cantor set below for the construction), we obtain a set formula_99which has a positive measure (equal to 1) but is meagre in [0,1], since each formula_97 is nowhere dense. Then consider the set formula_101. Since formula_102, formula_103 cannot be meagre, but since formula_104, formula_103 must have measure zero.

Instead of repeatedly removing the middle third of every piece as in the Cantor set, we could also keep removing any other fixed percentage (other than 0% and 100%) from the middle. In the case where the middle of the interval is removed, we get a remarkably accessible case — the set consists of all numbers in [0,1] that can be written as a decimal consisting entirely of 0s and 9s. If a fixed percentage is removed at each stage, then the limiting set will have measure zero, since the length of the remainder formula_106 as formula_107 for any formula_108 such that formula_109.

On the other hand, "fat Cantor sets" of positive measure can be generated by removal of smaller fractions of the middle of the segment in each iteration. Thus, one can construct sets homeomorphic to the Cantor set that have positive Lebesgue measure while still being nowhere dense. If an interval of length formula_110 (formula_111) is removed from the middle of each segment at the "n"th iteration, then the total length removed is formula_112, and the limiting set will have a Lebesgue measure of formula_113. Thus, in a sense, the middle-thirds Cantor set is a limiting case with formula_114. If formula_115, then the remainder will have positive measure with formula_116. The case formula_117 is known as the Smith–Volterra–Cantor set, which has a Lebesgue measure of formula_118.

One can modify the construction of the Cantor set by dividing randomly instead of equally. Besides, to incorporate time we can divide only one of the available intervals at each step instead of dividing all the available intervals. In the case of stochastic triadic Cantor set the resulting process can be described by the following rate equation

and for the stochastic dyadic Cantor set

where formula_121 is the number of intervals of size between formula_64 and formula_123. In the case of triadic Cantor set the fractal dimension is formula_124 which is 
less than its deterministic counterpart formula_125. In the case of stochastic dyadic Cantor set
the fractal dimension is formula_126 which is again less than that of its deterministic counterpart formula_127. In the case of stochastic dyadic Cantor set the solution for formula_128 exhibits dynamic scaling as its solution in the long-time limit is formula_129 where the fractal dimension of the stochastic dyadic Cantor set formula_130. In either case, like triadic Cantor set, the formula_75th moment (formula_132) of stochastic triadic and dyadic Cantor set too are conserved quantities.

Cantor dust is a multi-dimensional version of the Cantor set. It can be formed by taking a finite Cartesian product of the Cantor set with itself, making it a Cantor space. Like the Cantor set, Cantor dust has zero measure.

A different 2D analogue of the Cantor set is the Sierpinski carpet, where a square is divided up into nine smaller squares, and the middle one removed. The remaining squares are then further divided into nine each and the middle removed, and so on ad infinitum. One 3D analogue of this is the Menger sponge.

Cantor introduced what we call today the Cantor ternary set formula_133 as an example "of a perfect point-set, which is not everywhere-dense in any interval, however small." Cantor described formula_133 in terms of ternary expansions, as "the set of all real numbers given by the formula: formula_135where the coefficients formula_136 arbitrarily take the two values 0 and 2, and the series can consist of a finite number or an infinite number of elements."

A topological space formula_137 is perfect if all its points are limit points or, equivalently, if it coincides with its derived set formula_138. Subsets of the real line, like formula_133, can be seen as topological spaces under the induced subspace topology.

Cantor was led to the study of derived sets by his results on uniqueness of trigonometric series. The latter did much to set him on the course for developing an abstract, general theory of infinite sets.

Benoit Mandelbrot wrote much on Cantor dusts and their relation to natural fractals and statistical physics. He further reflected on the puzzling or even upsetting nature of such structures to those in the mathematics and physics community. In The Fractal geometry of Nature, he described how "When I started on this topic in 1962, everyone was agreeing that Cantor dusts are at least as monstrous as the Koch and Peano curves," and added that "every self-respecting physicist was automatically turned off by a mention of Cantor, ready to run a mile from anyone claiming formula_133 to be interesting in science."



Cardinal number

In mathematics, a cardinal number, or cardinal for short, is what is commonly called the number of elements of a set. In the case of a finite set, its cardinal number, or cardinality is therefore a natural number. For dealing with the case of infinite sets, the infinite cardinal numbers have been introduced, which are often denoted with the Hebrew letter formula_1 (aleph) marked with subscript indicating their rank among the infinite cardinals.

Cardinality is defined in terms of bijective functions. Two sets have the same cardinality if, and only if, there is a one-to-one correspondence (bijection) between the elements of the two sets. In the case of finite sets, this agrees with the intuitive notion of number of elements. In the case of infinite sets, the behavior is more complex. A fundamental theorem due to Georg Cantor shows that it is possible for infinite sets to have different cardinalities, and in particular the cardinality of the set of real numbers is greater than the cardinality of the set of natural numbers. It is also possible for a proper subset of an infinite set to have the same cardinality as the original set—something that cannot happen with proper subsets of finite sets.

There is a transfinite sequence of cardinal numbers:
This sequence starts with the natural numbers including zero (finite cardinals), which are followed by the aleph numbers. The aleph numbers are indexed by ordinal numbers. If the axiom of choice is true, this transfinite sequence includes every cardinal number. If the axiom of choice is not true (see ), there are infinite cardinals that are not aleph numbers.

Cardinality is studied for its own sake as part of set theory. It is also a tool used in branches of mathematics including model theory, combinatorics, abstract algebra and mathematical analysis. In category theory, the cardinal numbers form a skeleton of the category of sets.

The notion of cardinality, as now understood, was formulated by Georg Cantor, the originator of set theory, in 1874–1884. Cardinality can be used to compare an aspect of finite sets. For example, the sets {1,2,3} and {4,5,6} are not "equal", but have the "same cardinality", namely three. This is established by the existence of a bijection (i.e., a one-to-one correspondence) between the two sets, such as the correspondence {1→4, 2→5, 3→6}.

Cantor applied his concept of bijection to infinite sets (for example the set of natural numbers N = {0, 1, 2, 3, ...}). Thus, he called all sets having a bijection with N "denumerable (countably infinite) sets", which all share the same cardinal number. This cardinal number is called formula_3, aleph-null. He called the cardinal numbers of infinite sets transfinite cardinal numbers.

Cantor proved that any unbounded subset of N has the same cardinality as N, even though this might appear to run contrary to intuition. He also proved that the set of all ordered pairs of natural numbers is denumerable; this implies that the set of all rational numbers is also denumerable, since every rational can be represented by a pair of integers. He later proved that the set of all real algebraic numbers is also denumerable. Each real algebraic number "z" may be encoded as a finite sequence of integers, which are the coefficients in the polynomial equation of which it is a solution, i.e. the ordered n-tuple ("a", "a", ..., "a"), "a" ∈ Z together with a pair of rationals ("b", "b") such that "z" is the unique root of the polynomial with coefficients ("a", "a", ..., "a") that lies in the interval ("b", "b").

In his 1874 paper "On a Property of the Collection of All Real Algebraic Numbers", Cantor proved that there exist higher-order cardinal numbers, by showing that the set of real numbers has cardinality greater than that of N. His proof used an argument with nested intervals, but in an 1891 paper, he proved the same result using his ingenious and much simpler diagonal argument. The new cardinal number of the set of real numbers is called the cardinality of the continuum and Cantor used the symbol formula_4 for it.

Cantor also developed a large portion of the general theory of cardinal numbers; he proved that there is a smallest transfinite cardinal number (formula_3, aleph-null), and that for every cardinal number there is a next-larger cardinal

His continuum hypothesis is the proposition that the cardinality formula_4 of the set of real numbers is the same as formula_8. This hypothesis is independent of the standard axioms of mathematical set theory, that is, it can neither be proved nor disproved from them. This was shown in 1963 by Paul Cohen, complementing earlier work by Kurt Gödel in 1940.

In informal use, a cardinal number is what is normally referred to as a "counting number", provided that 0 is included: 0, 1, 2, ... They may be identified with the natural numbers beginning with 0. The counting numbers are exactly what can be defined formally as the finite cardinal numbers. Infinite cardinals only occur in higher-level mathematics and logic.

More formally, a non-zero number can be used for two purposes: to describe the size of a set, or to describe the position of an element in a sequence. For finite sets and sequences it is easy to see that these two notions coincide, since for every number describing a position in a sequence we can construct a set that has exactly the right size. For example, 3 describes the position of 'c' in the sequence <'a','b','c','d'...>, and we can construct the set {a,b,c}, which has 3 elements.

However, when dealing with infinite sets, it is essential to distinguish between the two, since the two notions are in fact different for infinite sets. Considering the position aspect leads to ordinal numbers, while the size aspect is generalized by the cardinal numbers described here.

The intuition behind the formal definition of cardinal is the construction of a notion of the relative size or "bigness" of a set, without reference to the kind of members which it has. For finite sets this is easy; one simply counts the number of elements a set has. In order to compare the sizes of larger sets, it is necessary to appeal to more refined notions.

A set "Y" is at least as big as a set "X" if there is an injective mapping from the elements of "X" to the elements of "Y". An injective mapping identifies each element of the set "X" with a unique element of the set "Y". This is most easily understood by an example; suppose we have the sets "X" = {1,2,3} and "Y" = {a,b,c,d}, then using this notion of size, we would observe that there is a mapping:
which is injective, and hence conclude that "Y" has cardinality greater than or equal to "X". The element d has no element mapping to it, but this is permitted as we only require an injective mapping, and not necessarily a bijective mapping. The advantage of this notion is that it can be extended to infinite sets.

We can then extend this to an equality-style relation. Two sets "X" and "Y" are said to have the same "cardinality" if there exists a bijection between "X" and "Y". By the Schroeder–Bernstein theorem, this is equivalent to there being "both" an injective mapping from "X" to "Y", "and" an injective mapping from "Y" to "X". We then write |"X"| = |"Y"|. The cardinal number of "X" itself is often defined as the least ordinal "a" with |"a"| = |"X"|. This is called the von Neumann cardinal assignment; for this definition to make sense, it must be proved that every set has the same cardinality as "some" ordinal; this statement is the well-ordering principle. It is however possible to discuss the relative cardinality of sets without explicitly assigning names to objects.

The classic example used is that of the infinite hotel paradox, also called Hilbert's paradox of the Grand Hotel. Supposing there is an innkeeper at a hotel with an infinite number of rooms. The hotel is full, and then a new guest arrives. It is possible to fit the extra guest in by asking the guest who was in room 1 to move to room 2, the guest in room 2 to move to room 3, and so on, leaving room 1 vacant. We can explicitly write a segment of this mapping:
With this assignment, we can see that the set {1,2,3...} has the same cardinality as the set {2,3,4...}, since a bijection between the first and the second has been shown. This motivates the definition of an infinite set being any set that has a proper subset of the same cardinality (i.e., a Dedekind-infinite set); in this case {2,3,4...} is a proper subset of {1,2,3...}.

When considering these large objects, one might also want to see if the notion of counting order coincides with that of cardinal defined above for these infinite sets. It happens that it does not; by considering the above example we can see that if some object "one greater than infinity" exists, then it must have the same cardinality as the infinite set we started out with. It is possible to use a different formal notion for number, called ordinals, based on the ideas of counting and considering each number in turn, and we discover that the notions of cardinality and ordinality are divergent once we move out of the finite numbers.

It can be proved that the cardinality of the real numbers is greater than that of the natural numbers just described. This can be visualized using Cantor's diagonal argument; classic questions of cardinality (for instance the continuum hypothesis) are concerned with discovering whether there is some cardinal between some pair of other infinite cardinals. In more recent times, mathematicians have been describing the properties of larger and larger cardinals.

Since cardinality is such a common concept in mathematics, a variety of names are in use. Sameness of cardinality is sometimes referred to as "equipotence", "equipollence", or "equinumerosity". It is thus said that two sets with the same cardinality are, respectively, "equipotent", "equipollent", or "equinumerous".

Formally, assuming the axiom of choice, the cardinality of a set "X" is the least ordinal number α such that there is a bijection between "X" and α. This definition is known as the von Neumann cardinal assignment. If the axiom of choice is not assumed, then a different approach is needed. The oldest definition of the cardinality of a set "X" (implicit in Cantor and explicit in Frege and "Principia Mathematica") is as the class ["X"] of all sets that are equinumerous with "X". This does not work in ZFC or other related systems of axiomatic set theory because if "X" is non-empty, this collection is too large to be a set. In fact, for "X" ≠ ∅ there is an injection from the universe into ["X"] by mapping a set "m" to {"m"} × "X", and so by the axiom of limitation of size, ["X"] is a proper class. The definition does work however in type theory and in New Foundations and related systems. However, if we restrict from this class to those equinumerous with "X" that have the least rank, then it will work (this is a trick due to Dana Scott: it works because the collection of objects with any given rank is a set).

Von Neumann cardinal assignment implies that the cardinal number of a finite set is the common ordinal number of all possible well-orderings of that set, and cardinal and ordinal arithmetic (addition, multiplication, power, proper subtraction) then give the same answers for finite numbers. However, they differ for infinite numbers. For example, formula_9 in ordinal arithmetic while formula_10 in cardinal arithmetic, although the von Neumann assignment puts formula_11. On the other hand, Scott's trick implies that the cardinal number 0 is formula_12, which is also the ordinal number 1, and this may be confusing. A possible compromise (to take advantage of the alignment in finite arithmetic while avoiding reliance on the axiom of choice and confusion in infinite arithmetic) is to apply von Neumann assignment to the cardinal numbers of finite sets (those which can be well ordered and are not equipotent to proper subsets) and to use Scott's trick for the cardinal numbers of other sets.

Formally, the order among cardinal numbers is defined as follows: |"X"| ≤ |"Y"| means that there exists an injective function from "X" to "Y". The Cantor–Bernstein–Schroeder theorem states that if |"X"| ≤ |"Y"| and |"Y"| ≤ |"X"| then |"X"| = |"Y"|. The axiom of choice is equivalent to the statement that given two sets "X" and "Y", either |"X"| ≤ |"Y"| or |"Y"| ≤ |"X"|.

A set "X" is Dedekind-infinite if there exists a proper subset "Y" of "X" with |"X"| = |"Y"|, and Dedekind-finite if such a subset does not exist. The finite cardinals are just the natural numbers, in the sense that a set "X" is finite if and only if |"X"| = |"n"| = "n" for some natural number "n". Any other set is infinite.

Assuming the axiom of choice, it can be proved that the Dedekind notions correspond to the standard ones. It can also be proved that the cardinal formula_3 (aleph null or aleph-0, where aleph is the first letter in the Hebrew alphabet, represented formula_1) of the set of natural numbers is the smallest infinite cardinal (i.e., any infinite set has a subset of cardinality formula_3). The next larger cardinal is denoted by formula_8, and so on. For every ordinal α, there is a cardinal number formula_17 and this list exhausts all infinite cardinal numbers.

We can define arithmetic operations on cardinal numbers that generalize the ordinary operations for natural numbers. It can be shown that for finite cardinals, these operations coincide with the usual operations for natural numbers. Furthermore, these operations share many properties with ordinary arithmetic.

If the axiom of choice holds, then every cardinal κ has a successor, denoted κ, where κ > κ and there are no cardinals between κ and its successor. (Without the axiom of choice, using Hartogs' theorem, it can be shown that for any cardinal number κ, there is a minimal cardinal κ such that formula_18) For finite cardinals, the successor is simply κ + 1. For infinite cardinals, the successor cardinal differs from the successor ordinal.

If "X" and "Y" are disjoint, addition is given by the union of "X" and "Y". If the two sets are not already disjoint, then they can be replaced by disjoint sets of the same cardinality (e.g., replace "X" by "X"×{0} and "Y" by "Y"×{1}).

Zero is an additive identity "κ" + 0 = 0 + "κ" = "κ".

Addition is associative ("κ" + "μ") + "ν" = "κ" + ("μ" + "ν").

Addition is commutative "κ" + "μ" = "μ" + "κ".

Addition is non-decreasing in both arguments:

Assuming the axiom of choice, addition of infinite cardinal numbers is easy. If either "κ" or "μ" is infinite, then

Assuming the axiom of choice and, given an infinite cardinal "σ" and a cardinal "μ", there exists a cardinal "κ" such that "μ" + "κ" = "σ" if and only if "μ" ≤ "σ". It will be unique (and equal to "σ") if and only if "μ" < "σ".

The product of cardinals comes from the Cartesian product.

"κ"·0 = 0·"κ" = 0.

"κ"·"μ" = 0 → ("κ" = 0 or "μ" = 0).

One is a multiplicative identity "κ"·1 = 1·"κ" = "κ".

Multiplication is associative ("κ"·"μ")·"ν" = "κ"·("μ"·"ν").

Multiplication is commutative "κ"·"μ" = "μ"·"κ".

Multiplication is non-decreasing in both arguments:
"κ" ≤ "μ" → ("κ"·"ν" ≤ "μ"·"ν" and "ν"·"κ" ≤ "ν"·"μ").

Multiplication distributes over addition:
"κ"·("μ" + "ν") = "κ"·"μ" + "κ"·"ν" and
("μ" + "ν")·"κ" = "μ"·"κ" + "ν"·"κ".

Assuming the axiom of choice, multiplication of infinite cardinal numbers is also easy. If either "κ" or "μ" is infinite and both are non-zero, then

Assuming the axiom of choice and, given an infinite cardinal "π" and a non-zero cardinal "μ", there exists a cardinal "κ" such that "μ" · "κ" = "π" if and only if "μ" ≤ "π". It will be unique (and equal to "π") if and only if "μ" < "π".

Exponentiation is given by
where "X" is the set of all functions from "Y" to "X".

Exponentiation is non-decreasing in both arguments:

2 is the cardinality of the power set of the set "X" and Cantor's diagonal argument shows that 2 > |"X"| for any set "X". This proves that no largest cardinal exists (because for any cardinal "κ", we can always find a larger cardinal 2). In fact, the class of cardinals is a proper class. (This proof fails in some set theories, notably New Foundations.)

All the remaining propositions in this section assume the axiom of choice:

If 2 ≤ "κ" and 1 ≤ "μ" and at least one of them is infinite, then:

Using König's theorem, one can prove "κ" < "κ" and "κ" < cf(2) for any infinite cardinal "κ", where cf("κ") is the cofinality of "κ".

Assuming the axiom of choice and, given an infinite cardinal "κ" and a finite cardinal "μ" greater than 0, the cardinal "ν" satisfying formula_25 will be formula_26.

Assuming the axiom of choice and, given an infinite cardinal "κ" and a finite cardinal "μ" greater than 1, there may or may not be a cardinal "λ" satisfying formula_27. However, if such a cardinal exists, it is infinite and less than "κ", and any finite cardinality "ν" greater than 1 will also satisfy formula_28.

The logarithm of an infinite cardinal number "κ" is defined as the least cardinal number "μ" such that "κ" ≤ 2. Logarithms of infinite cardinals are useful in some fields of mathematics, for example in the study of cardinal invariants of topological spaces, though they lack some of the properties that logarithms of positive real numbers possess.

The continuum hypothesis (CH) states that there are no cardinals strictly between formula_3 and formula_30 The latter cardinal number is also often denoted by formula_4; it is the cardinality of the continuum (the set of real numbers). In this case formula_32

Similarly, the generalized continuum hypothesis (GCH) states that for every infinite cardinal formula_26, there are no cardinals strictly between formula_26 and formula_35. Both the continuum hypothesis and the generalized continuum hypothesis have been proved to be independent of the usual axioms of set theory, the Zermelo–Fraenkel axioms together with the axiom of choice (ZFC).

Indeed, Easton's theorem shows that, for regular cardinals formula_26, the only restrictions ZFC places on the cardinality of formula_35 are that formula_38, and that the exponential function is non-decreasing.

Notes
Bibliography

Cardinality

In mathematics, the cardinality of a set is a measure of the number of elements of the set. For example, the set formula_1 contains 3 elements, and therefore formula_2 has a cardinality of 3. Beginning in the late 19th century, this concept was generalized to infinite sets, which allows one to distinguish between different types of infinity, and to perform arithmetic on them. There are two approaches to cardinality: one which compares sets directly using bijections and injections, and another which uses cardinal numbers.
The cardinality of a set may also be called its size, when no confusion with other notions of size is possible.

The cardinality of a set formula_2 is usually denoted formula_4, with a vertical bar on each side; this is the same notation as absolute value, and the meaning depends on context. The cardinality of a set formula_2 may alternatively be denoted by formula_6, formula_2, formula_8, or formula_9.

A crude sense of cardinality, an awareness that groups of things or events compare with other groups by containing more, fewer, or the same number of instances, is observed in a variety of present-day animal species, suggesting an origin millions of years ago. Human expression of cardinality is seen as early as years ago, with equating the size of a group with a group of recorded notches, or a representative collection of other things, such as sticks and shells. The abstraction of cardinality as a number is evident by 3000 BCE, in Sumerian mathematics and the manipulation of numbers without reference to a specific group of things or events.

From the 6th century BCE, the writings of Greek philosophers show hints of the cardinality of infinite sets. While they considered the notion of infinity as an endless series of actions, such as adding 1 to a number repeatedly, they did not consider the size of an infinite set of numbers to be a thing. The ancient Greek notion of infinity also considered the division of things into parts repeated without limit. In Euclid's "Elements", commensurability was described as the ability to compare the length of two line segments, "a" and "b", as a ratio, as long as there were a third segment, no matter how small, that could be laid end-to-end a whole number of times into both "a" and "b". But with the discovery of irrational numbers, it was seen that even the infinite set of all rational numbers was not enough to describe the length of every possible line segment. Still, there was no concept of infinite sets as something that had cardinality.

To better understand infinite sets, a notion of cardinality was formulated circa 1880 by Georg Cantor, the originator of set theory. He examined the process of equating two sets with bijection, a one-to-one correspondence between the elements of two sets based on a unique relationship. In 1891, with the publication of Cantor's diagonal argument, he demonstrated that there are sets of numbers that cannot be placed in one-to-one correspondence with the set of natural numbers, i.e. uncountable sets that contain more elements than there are in the infinite set of natural numbers.

While the cardinality of a finite set is just the number of its elements, extending the notion to infinite sets usually starts with defining the notion of comparison of arbitrary sets (some of which are possibly infinite).

If ≤ and ≤ , then = (a fact known as Schröder–Bernstein theorem). The axiom of choice is equivalent to the statement that ≤ or ≤ for every "A", "B".

In the above section, "cardinality" of a set was defined functionally. In other words, it was not defined as a specific object itself. However, such an object can be defined as follows.

The relation of having the same cardinality is called equinumerosity, and this is an equivalence relation on the class of all sets. The equivalence class of a set "A" under this relation, then, consists of all those sets which have the same cardinality as "A". There are two ways to define the "cardinality of a set":


Assuming the axiom of choice, the cardinalities of the infinite sets are denoted
For each ordinal formula_11, formula_12 is the least cardinal number greater than formula_13.

The cardinality of the natural numbers is denoted aleph-null (formula_14), while the cardinality of the real numbers is denoted by "formula_15" (a lowercase fraktur script "c"), and is also referred to as the cardinality of the continuum. Cantor showed, using the diagonal argument, that formula_16. We can show that formula_17, this also being the cardinality of the set of all subsets of the natural numbers.

The continuum hypothesis says that formula_18, i.e. formula_19 is the smallest cardinal number bigger than formula_14, i.e. there is no set whose cardinality is strictly between that of the integers and that of the real numbers. The continuum hypothesis is independent of ZFC, a standard axiomatization of set theory; that is, it is impossible to prove the continuum hypothesis or its negation from ZFC—provided that ZFC is consistent. For more detail, see § Cardinality of the continuum below.

If the axiom of choice holds, the law of trichotomy holds for cardinality. Thus we can make the following definitions:


Our intuition gained from finite sets breaks down when dealing with infinite sets. In the late 19th century Georg Cantor, Gottlob Frege, Richard Dedekind and others rejected the view that the whole cannot be the same size as the part. One example of this is Hilbert's paradox of the Grand Hotel.
Indeed, Dedekind defined an infinite set as one that can be placed into a one-to-one correspondence with a strict subset (that is, having the same size in Cantor's sense); this notion of infinity is called Dedekind infinite. Cantor introduced the cardinal numbers, and showed—according to his bijection-based definition of size—that some infinite sets are greater than others. The smallest infinite cardinality is that of the natural numbers (formula_14).

One of Cantor's most important results was that the cardinality of the continuum (formula_24) is greater than that of the natural numbers (formula_14); that is, there are more real numbers R than natural numbers N. Namely, Cantor showed that formula_26 (see Beth one) satisfies:

The continuum hypothesis states that there is no cardinal number between the cardinality of the reals and the cardinality of the natural numbers, that is,

However, this hypothesis can neither be proved nor disproved within the widely accepted ZFC axiomatic set theory, if ZFC is consistent.

Cardinal arithmetic can be used to show not only that the number of points in a real number line is equal to the number of points in any segment of that line, but that this is equal to the number of points on a plane and, indeed, in any finite-dimensional space. These results are highly counterintuitive, because they imply that there exist proper subsets and proper supersets of an infinite set "S" that have the same size as "S", although "S" contains elements that do not belong to its subsets, and the supersets of "S" contain elements that are not included in it.

The first of these results is apparent by considering, for instance, the tangent function, which provides a one-to-one correspondence between the interval (−½π, ½π) and R (see also Hilbert's paradox of the Grand Hotel).

The second result was first demonstrated by Cantor in 1878, but it became more apparent in 1890, when Giuseppe Peano introduced the space-filling curves, curved lines that twist and turn enough to fill the whole of any square, or cube, or hypercube, or finite-dimensional space. These curves are not a direct proof that a line has the same number of points as a finite-dimensional space, but they can be used to obtain such a proof.

Cantor also showed that sets with cardinality strictly greater than formula_15 exist (see his generalized diagonal argument and theorem). They include, for instance:

Both have cardinality

The cardinal equalities formula_31 formula_32 and formula_33 can be demonstrated using cardinal arithmetic:


If "A" and "B" are disjoint sets, then

From this, one can show that in general, the cardinalities of unions and intersections are related by the following equation:


